<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [cs.CR](#cs.CR) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation](https://arxiv.org/abs/2508.08257)
*Zacharias Chen,Alexa Cristelle Cahilig,Sarah Dias,Prithu Kolar,Ravi Prakash,Patrick J. Codd*

Main category: eess.SP

TL;DR: 机器人辅助神经手术因提升精确度而受关注，但缺乏自然感官反馈。本研究提出多模态传感融合平台，提升组织分类准确性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人辅助手术中感官反馈不足的问题，特别是肿瘤手术中区分健康与肿瘤组织的需求。

Method: 开发模块化测试台，结合视觉引导、接触麦克风和力传感器，通过交互式图形界面实现实时数据采集与可视化。

Result: 多模态融合显著提高材料分类精度。

Conclusion: 该平台为手术中的传感器融合提供了可扩展的解决方案，展示了多模态方法在实时组织边界描绘中的潜力。

Abstract: Robot-assisted neurological surgery is receiving growing interest due to the
improved dexterity, precision, and control of surgical tools, which results in
better patient outcomes. However, such systems often limit surgeons' natural
sensory feedback, which is crucial in identifying tissues -- particularly in
oncological procedures where distinguishing between healthy and tumorous tissue
is vital. While imaging and force sensing have addressed the lack of sensory
feedback, limited research has explored multimodal sensing options for accurate
tissue boundary delineation. We present a user-friendly, modular test bench
designed to evaluate and integrate complementary multimodal sensors for tissue
identification. Our proposed system first uses vision-based guidance to
estimate boundary locations with visual cues, which are then refined using data
acquired by contact microphones and a force sensor. Real-time data acquisition
and visualization are supported via an interactive graphical interface.
Experimental results demonstrate that multimodal fusion significantly improves
material classification accuracy. The platform provides a scalable
hardware-software solution for exploring sensor fusion in surgical applications
and demonstrates the potential of multimodal approaches in real-time tissue
boundary delineation.

</details>


### [2] [Hardware-friendly IR-HARQ for Polar SCL Decoders](https://arxiv.org/abs/2508.08425)
*Marwan Jalaleddine,Jiajie Li,Warren J. Gross*

Main category: eess.SP

TL;DR: 提出了一种将极性码的增量冗余混合自动重传请求（IR-HARQ）方案从基于集合的操作转换为二进制向量操作的方法，以减少硬件实现中的内存开销和面积开销。


<details>
  <summary>Details</summary>
Motivation: 为了扩展极性码在下一代无线通信系统中的应用，需要支持IR-HARQ方案，但现有方案的硬件实现存在内存访问模式不规则和面积开销大的问题。

Method: 将基于集合的操作转换为二进制向量操作，并引入新的快速节点集成方法以减少快速节点数量。

Result: 提出的方案在内存开销上比不支持IR-HARQ的SCL解码仅增加25-27%。

Conclusion: 通过改进操作方法和节点集成方式，显著提高了硬件兼容性并降低了开销。

Abstract: To extend the applications of polar codes within next-generation wireless
communication systems, it is essential to incorporate support for Incremental
Redundancy (IR) Hybrid Automatic Repeat Request (HARQ) schemes. The baseline
IR-HARQ scheme's reliance on set-based operations leads to irregular memory
access patterns, posing significant challenges for efficient hardware
implementation. Furthermore, the introduction of new bit types increases the
number of fast nodes that are decoded without traversing the sub-tree,
resulting in a substantial area overhead when implemented in hardware. To
address these issues and improve hardware compatibility, we propose
transforming the set-based operations within the polar IR-HARQ scheme into
binary vector operations. Additionally, we introduce a new fast node
integration approach that avoids increasing the number of fast nodes, thereby
minimizing the associated area overhead. Our proposed scheme results in a
memory overhead of 25-27% compared to successive cancellation list (SCL)
decoding without IR-HARQ support.

</details>


### [3] [Tensor-Structured Bayesian Channel Prediction for Upper Mid-Band XL-MIMO Systems](https://arxiv.org/abs/2508.08491)
*Hongwei Hou,Yafei Wang,Xinping Yi,Wenjin Wang,Dirk T. M. Slock,Shi Jin*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的通道预测方法，针对XL-MIMO系统中的信道老化和近场传播问题，通过张量结构建模和贝叶斯推理算法提升性能。


<details>
  <summary>Details</summary>
Motivation: 未来蜂窝系统的上中频带虽然提升了频谱和能量效率，但在移动环境下，信道老化和近场传播问题严重降低了系统性能。因此，需要一种有效的预测方法来解决这些问题。

Method: 方法包括张量结构化的信道建模（空间-频率-时间和波束-延迟-多普勒域）、贝叶斯推理算法，并利用扰动参数和混合波束域策略降低计算复杂度。

Result: 基于近实际信道模拟器的数值模拟显示，提出的算法在信道预测性能上表现优越。

Conclusion: 该方法通过结合张量建模和概率推理，有效提升了信道预测的准确性，同时显著降低了计算负担。

Abstract: The upper mid-band balances coverage and capacity for the future cellular
systems and also embraces XL-MIMO systems, offering enhanced spectral and
energy efficiency. However, these benefits are significantly degraded under
mobility due to channel aging, and further exacerbated by the unique near-field
(NF) and spatial non-stationarity (SnS) propagation in such systems. To address
this challenge, we propose a novel channel prediction approach that
incorporates dedicated channel modeling, probabilistic representations, and
Bayesian inference algorithms for this emerging scenario. Specifically, we
develop tensor-structured channel models in both the spatial-frequency-temporal
(SFT) and beam-delay-Doppler (BDD) domains, which leverage temporal
correlations among multiple pilot symbols for channel prediction. The factor
matrices of multi-linear transformations are parameterized by BDD domain grids
and SnS factors, where beam domain grids are jointly determined by angles and
slopes under spatial-chirp based NF representations. To enable tractable
inference, we replace environment-dependent BDD domain grids with uniformly
sampled ones, and introduce perturbation parameters in each domain to mitigate
grid mismatch. We further propose a hybrid beam domain strategy that integrates
angle-only sampling with slope hyperparameterization to avoid the computational
burden of explicit slope sampling. Based on the probabilistic models, we
develop tensor-structured bi-layer inference (TS-BLI) algorithm under the
expectation-maximization (EM) framework, which reduces computational complexity
via tensor operations by leveraging the bi-layer factor graph for approximate
E-step inference and an alternating strategy with closed-form updates in the
M-step. Numerical simulations based on the near-practical channel simulator
demonstrate the superior channel prediction performance of the proposed
algorithm.

</details>


### [4] [An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets](https://arxiv.org/abs/2508.08506)
*Mehdi Zafari,Divyanshu Pandey,Rahman Doost-Mohammady*

Main category: eess.SP

TL;DR: 本文通过实验和理论分析评估了多用户波束成形（D-MUBF）在存在频率同步误差时的性能，并提供了公开数据集以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 研究分布式多用户波束成形在TDD MU-MIMO系统中面临的频率同步挑战，尤其是本地振荡器漂移导致的残余频率偏移问题。

Method: 提供SINR的闭式表达式，并通过RENEW大规模MIMO测试平台进行实验评估，收集并分析多种场景下的数据集。

Result: 通过实验数据验证了理论分析的正确性，展示了频率同步误差对D-MUBF性能的影响，并公开数据集供进一步研究。

Conclusion: 研究表明频率同步误差对D-MUBF性能有显著影响，公开数据集有助于推动未来研究。

Abstract: Realizing distributed multi-user beamforming (D-MUBF) in time division duplex
(TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One
of the most fundamental challenges is achieving accurate over-the-air (OTA)
timing and frequency synchronization among distributed access points (APs),
particularly due to residual frequency offsets caused by local oscillator (LO)
drifts. Despite decades of research on synchronization for MU-MIMO, there are
only a few experimental studies that evaluate D-MUBF techniques under imperfect
frequency synchronization among distributed antennas. This paper presents an
analytical and experimental assessment of D-MUBF methods in the presence of
frequency synchronization errors. We provide closed-form expressions for
signal-to-interference-plus-noise ratio (SINR) as a function of channel
characteristics and statistical properties of carrier frequency offset (CFO)
among AP antennas. In addition, through experimental evaluations conducted with
the RENEW massive MIMO testbed, we collected comprehensive datasets across
various experimental scenarios. These datasets comprise uplink pilot samples
for channel and CFO estimation, in addition to uplink multi-user data intended
for analyzing D-MUBF techniques. By examining these datasets, we assess the
performance of D-MUBF in the presence of CFO and compare the analytical
predictions with empirical measurements. Furthermore, we make the datasets
publicly available and provide insights on utilizing them for future research
endeavors.

</details>


### [5] [Learning Zero Constellations for Binary MOCZ in Fading Channels](https://arxiv.org/abs/2508.08571)
*Anthony Joseph Perre,Parker Huggins,Alphan Sahin*

Main category: eess.SP

TL;DR: 论文提出了两种设计零星座的方法，用于二进制调制在共轭倒数零上的应用，分别是基于多标签分类的直接零测试解码器和基于神经网络的联合学习方法。结果表明，神经网络解码器在平坦衰落信道中表现优异，计算复杂度虽增加但性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进传统二进制调制的性能，通过学习优化的零星座和解码器设计，以提升信号传输的效率和可靠性。

Method: 方法包括两种：1) 将星座设计视为多标签分类问题，学习零位置用于直接零测试解码器；2) 引入神经网络解码器，联合学习解码器和零星座参数。

Result: 数值模拟显示，学习的零星座优于传统的Huffman BMOCZ星座，神经网络解码器在平坦衰落信道中表现优异，尽管计算复杂度增加。

Conclusion: 结论表明，通过学习优化的零星座和解码器设计，可以显著提升二进制调制的性能，尤其是神经网络解码器的泛化能力在平坦衰落信道中表现突出。

Abstract: In this work, we propose two methods to design zero constellations for binary
modulation on conjugate-reciprocal zeros (BMOCZ). In the first approach, we
treat constellation design as a multi-label binary classification problem and
learn the zero locations for a direct zero-testing (DiZeT) decoder. In the
second approach, we introduce a neural network (NN)-based decoder and jointly
learn the decoder and zero constellation parameters. We show that the NN-based
decoder can directly generalize to flat-fading channels, despite being trained
under additive white Gaussian noise. Furthermore, the results of numerical
simulations demonstrate that learned zero constellations outperform the
canonical, Huffman BMOCZ constellation, with the proposed NN-based decoder
achieving large performance gain at the expense of increased computational
complexity.

</details>


### [6] [Biomedical Signal Processing: EEG and ECG Classification with Discrete Wavelet Transforms, Energy Distribution, and Convolutional Neural Networks](https://arxiv.org/abs/2508.08602)
*Justin London*

Main category: eess.SP

TL;DR: 论文提出了一种多模态深度学习模型，通过离散小波变换预处理信号，并结合图像与特征融合技术，显著提高了生物医学信号分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的手动分析生物医学信号易受人为误差影响，且难以检测细微异常，而深度学习可以提升分析的准确性。

Method: 使用离散小波变换降低噪声，通过多模态图像融合和特征融合框架将数值信号转化为2D和3D图像进行处理，应用于ECG、EEG和人类活动信号。

Result: 多模态方法结合小波变换显著提高了疾病和障碍分类的准确性。

Conclusion: 多模态深度学习模型在生物医学信号处理中表现出色，为疾病诊断和监测提供了更可靠的解决方案。

Abstract: Biomedical signal processing extract meaningful information from
physiological signals like electrocardiograms (ECGs), electroencephalograms
(EEGs), and electromyograms (EMGs) to diagnose, monitor, and treat medical
conditions and diseases such as seizures, cardiomyopathy, and neuromuscular
disorders, respectively. Traditional manual physician analysis of electrical
recordings is prone to human error as subtle anomolies may not be detected.
Recently, advanced deep learning has significantly improved the accuracy of
biomedical signal analysis. A multi-modal deep learning model is proposed that
utilizes discrete wavelet transforms for signal pre-processing to reduce noise.
A multi-modal image fusion and multimodal feature fusion framework is utilized
that converts numeric biomedical signals into 2D and 3D images for image
processing using Gramian angular fields, recurrency plots, and Markov
transition fields. In this paper, deep learning models are applied to ECG, EEG,
and human activity signals using actual medical datasets, brain, and heart
recordings. The results demonstrate that using a multi-modal approach using
wavelet transforms improves the accuracy of disease and disorder
classification.

</details>


### [7] [Agentic Graph Neural Networks for Wireless Communications and Networking Towards Edge General Intelligence: A Survey](https://arxiv.org/abs/2508.08620)
*Yang Lu,Shengli Zhang,Chang Liu,Ruichen Zhang,Bo Ai,Dusit Niyato,Wei Ni,Xianbin Wang,Abbas Jamalipour*

Main category: eess.SP

TL;DR: 本文提出利用代理人工智能（AI）组织图神经网络（GNN），面向边缘通用智能实现任务感知，并综述了GNN在无线通信中的最新应用。


<details>
  <summary>Details</summary>
Motivation: 通信网络的复杂性和多样性需要新的深度学习框架，而传统被动学习的GNN可能无法满足需求。

Method: 通过代理AI整合GNN，实现任务感知；并全面回顾GNN在无线通信中的应用。

Result: 提出了基于大语言模型（LLM）的问答框架，利用综述作为知识库提供GNN相关解答。

Conclusion: 代理AI与GNN的结合为通信网络设计提供了新方向，尤其适合动态环境下的任务需求。

Abstract: The rapid advancement of communication technologies has driven the evolution
of communication networks towards both high-dimensional resource utilization
and multifunctional integration. This evolving complexity poses significant
challenges in designing communication networks to satisfy the growing
quality-of-service and time sensitivity of mobile applications in dynamic
environments. Graph neural networks (GNNs) have emerged as fundamental deep
learning (DL) models for complex communication networks. GNNs not only augment
the extraction of features over network topologies but also enhance scalability
and facilitate distributed computation. However, most existing GNNs follow a
traditional passive learning framework, which may fail to meet the needs of
increasingly diverse wireless systems. This survey proposes the employment of
agentic artificial intelligence (AI) to organize and integrate GNNs, enabling
scenario- and task-aware implementation towards edge general intelligence. To
comprehend the full capability of GNNs, we holistically review recent
applications of GNNs in wireless communications and networking. Specifically,
we focus on the alignment between graph representations and network topologies,
and between neural architectures and wireless tasks. We first provide an
overview of GNNs based on prominent neural architectures, followed by the
concept of agentic GNNs. Then, we summarize and compare GNN applications for
conventional systems and emerging technologies, including physical, MAC, and
network layer designs, integrated sensing and communication (ISAC),
reconfigurable intelligent surface (RIS) and cell-free network architecture. We
further propose a large language model (LLM) framework as an intelligent
question-answering agent, leveraging this survey as a local knowledge base to
enable GNN-related responses tailored to wireless communication research.

</details>


### [8] [Sparse Near-Field Channel Estimation for XL-MIMO via Adaptive Filtering](https://arxiv.org/abs/2508.08663)
*Vidya Bhasker Shukla,Italo Atzeni*

Main category: eess.SP

TL;DR: 研究了在近场（NF）区域运行的XL-MIMO系统的稀疏信道估计，提出了一种基于自适应滤波的极性域零吸引最小均方（PD-ZALMS）方法。


<details>
  <summary>Details</summary>
Motivation: 满足下一代无线应用的需求，解决XL-MIMO系统在近场区域的信道估计问题。

Method: 采用极性域零吸引最小均方（PD-ZALMS）方法进行信道估计。

Result: 该方法在信道估计精度和计算复杂度上显著优于传统方法，并在低至中等信噪比下优于Oracle最小二乘信道估计器。

Conclusion: PD-ZALMS在XL-MIMO系统的近场信道估计中表现出色，具有实际应用潜力。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems
operating at sub-THz carrier frequencies represent a promising solution to meet
the demands of next-generation wireless applications. This work focuses on
sparse channel estimation for XL-MIMO systems operating in the near-field (NF)
regime. Assuming a practical subarray-based architecture, we develop a NF
channel estimation framework based on adaptive filtering, referred to as
\textit{polar-domain zero-attracting least mean squares (PD-ZALMS)}. The
proposed method achieves significantly superior channel estimation accuracy and
lower computational complexity compared with the well-established polar-domain
orthogonal matching pursuit. In addition, the proposed PD-ZALMS is shown to
outperform the oracle least-squares channel estimator at low-to-moderate
signal-to-noise ratio.

</details>


### [9] [VQ-VAE Based Digital Semantic Communication with Importance-Aware OFDM Transmission](https://arxiv.org/abs/2508.08686)
*Ming Lyu,Hao Chen,Dan Wang,Chen Qiu,Guangyin Feng,Nan Ma,Xiaodong Xu*

Main category: eess.SP

TL;DR: 提出了基于VQ-VAE的数字语义通信系统，结合重要性感知OFDM传输，提升语义通信性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的语义通信系统多为模拟传输，缺乏与数字通信的兼容性，因此提出数字语义通信方案。

Method: 使用VQ-VAE生成共享离散码本，提取语义特征并匹配码本以适应数字传输；采用重要性感知OFDM传输策略保护关键特征。

Result: 实验证明，该方案优于传统DeepSC，在低信噪比下重建性能更优。

Conclusion: VQ-VAE结合重要性感知OFDM的数字语义通信系统有效提升传输效率和兼容性。

Abstract: Semantic communication (SemCom) significantly reduces redundant data and
improves transmission efficiency by extracting the latent features of
information. However, most of the conventional deep learning-based SemCom
systems focus on analog transmission and lack in compatibility with practical
digital communications. This paper proposes a vector quantized-variational
autoencoder (VQ-VAE) based digital SemCom system that directly transmits the
semantic features and incorporates the importance-aware orthogonal frequency
division multiplexing (OFDM) transmission to enhance the SemCom performance,
where the VQ-VAE generates a discrete codebook shared between the transmitter
and receiver. At transmitter, the latent semantic features are firstly
extracted by VQ-VAE, and then the shared codebook is adopted to match these
features, which are subsequently transformed into a discrete version to adapt
the digital transmission. To protect the semantic information, an
importance-aware OFDM transmission strategy is proposed to allocate the key
features near the OFDM reference signals, where the feature importance is
derived from the gradient-based method. At the receiver, the features are
rematched with the shared codebook to further correct errors. Finally,
experimental results demonstrate that our proposed scheme outperforms the
conventional DeepSC and achieves better reconstruction performance under low
SNR region.

</details>


### [10] [Evaluating Task Execution Performance Under Energy Measurement Overhead](https://arxiv.org/abs/2508.08757)
*Mateen Ashraf,Shahab Jahanbazi,Onel L. A. López*

Main category: eess.SP

TL;DR: 论文讨论了在能量收集（EH）物联网（IoT）设备中，调整能量测量频率和任务执行频率可以优化任务完成率。若参数选择不当，能量感知（EA）调度可能不如能量盲（EB）调度。


<details>
  <summary>Details</summary>
Motivation: 传统上忽略能量测量成本可能抵消能量感知任务执行的潜在优势，需要研究如何优化参数以提高性能。

Method: 比较能量盲（EB）和能量感知（EA）任务决策方法，分析能量测量频率和任务执行频率对任务完成率的影响。

Result: 发现存在最优的能量测量/任务执行频率，能最大化任务完成率；若参数不当，EA可能表现不如EB。

Conclusion: 合理选择能量测量和任务执行频率对EH-IoT设备的性能至关重要，否则能量测量成本可能降低EA调度的优势。

Abstract: Energy-awareness for adapting task execution behavior can bring several
benefits in terms of performance improvement in energy harvesting (EH) Internet
of Things (IoT) devices. However, the energy measurement cost of acquiring
energy information, which is traditionally ignored, can potentially neutralize
or even reverse the potential benefits. This paper highlights operational
parameters, such as energy measurement frequency and task execution frequency,
which can be tuned to improve the task execution performance of an EH-IoT
device. To this end, we consider energy-blind (EB) and energy-aware (EA) task
decision approaches and compare their task completion rate performance. We show
that, for specific hardware design parameters of an EH-IoT device, there exists
an optimal energy measurement/task execution frequency that can maximize the
task completion rate in both approaches. Moreover, if these parameters are not
chosen appropriately, then energy measurement costs can cause EA scheduling to
underperform compared to EB scheduling.

</details>


### [11] [Wideband Coplanar Waveguide MIMO Antenna for 6G Millimeter-Wave Applications with Defected Ground Structure](https://arxiv.org/abs/2508.08771)
*Atta Ullah,Daniyal Munir,Daniel Lindenschmitt,Hans D. Schotten*

Main category: eess.SP

TL;DR: 本文提出了一种用于6G毫米波频段的新型宽带小天线设计，包括单天线和2x2 MIMO天线，性能优异。


<details>
  <summary>Details</summary>
Motivation: 针对6G无线网络的高频段需求，设计一种宽带小天线以满足毫米波技术的应用。

Method: 采用微带贴片结构和共面波导馈电，结合缺陷地结构（DGS），设计了单天线和2x2 MIMO天线。

Result: 单天线带宽达8.5 GHz，适用于6G毫米波技术的多种应用。

Conclusion: 该天线设计在6G毫米波频段表现出色，具有广阔的应用前景。

Abstract: This research study introduces a novel small antenna with wideband capacity
for the higher frequency range. As a possible contender for 6G wireless
networks, the proposed antenna is designed to target the 6G Millimeter-Wave
(mmWave) operating bands spanning 25 GHz to 33.5 GHz. With a microstrip patch
structure fed by a coplanar waveguide (CPW) with the defected ground structure
(DGS), a single antenna is introduced and then a design of 2 x 2 MIMO antenna
is presented. The single antenna has 2 elements, while the 2 x 2 MIMO antenna
has 8 elements. It achieves remarkably well in terms of return loss of 8.5 GHz
wideband, which is anticipated to be used for several applications in 6G mmWave
technology.

</details>


### [12] [Patient-Adaptive Focused Transmit Beamforming using Cognitive Ultrasound](https://arxiv.org/abs/2508.08782)
*Wessel L. van Nierop,Oisín Nolan,Tristan S. W. Stevens,Ruud J. G. van Sloun*

Main category: eess.SP

TL;DR: 提出了一种基于患者自适应的聚焦发射方案，通过后采样和时间扩散模型减少发射次数，提升超声图像质量，且在2D和3D数据上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统聚焦发射方案在超声心动图中帧率低的问题，同时避免非聚焦发射的缺陷（如运动去相关和谐波成像能力有限）。

Method: 采用后采样和时间扩散模型感知并重建解剖结构，动态选择信息量最大的发射方式。

Result: 在2D和3D数据集上表现优异，对比噪声比优于传统方法，且能在GPU上实时运行。

Conclusion: 该方法显著提升了超声成像的效率和质量，适用于实时应用。

Abstract: Focused transmit beamforming is the most commonly used acquisition scheme for
echocardiograms, but suffers from relatively low frame rates, and in 3D, even
lower volume rates. Fast imaging based on unfocused transmits has disadvantages
such as motion decorrelation and limited harmonic imaging capabilities. This
work introduces a patient-adaptive focused transmit scheme that has the ability
to drastically reduce the number of transmits needed to produce a high-quality
ultrasound image. The method relies on posterior sampling with a temporal
diffusion model to perceive and reconstruct the anatomy based on partial
observations, while subsequently taking an action to acquire the most
informative transmits. This active perception modality outperforms random and
equispaced subsampling on the 2D EchoNet-Dynamic dataset and a 3D Philips
dataset, where we actively select focused elevation planes. Furthermore, we
show it achieves better performance in terms of generalized contrast-to-noise
ratio when compared to the same number of diverging waves transmits on three
in-house echocardiograms. Additionally, we can estimate ejection fraction using
only 2% of the total transmits and show that the method is robust to outlier
patients. Finally, our method can be run in real-time on GPU accelerators from
2023. The code is publicly available at https://tue-bmd.github.io/ulsa/

</details>


### [13] [ReQuestNet: A Foundational Learning model for Channel Estimation](https://arxiv.org/abs/2508.08790)
*Kumar Pratik,Pouriya Sadeghi,Gabriele Cesa,Sanaz Barghi,Joseph B. Soriaga,Yuanning Yu,Supratik Bhattacharjee,Arash Behboodi*

Main category: eess.SP

TL;DR: ReQuestNet是一种新颖的神经网络架构，用于5G及更高版本的无线通信系统中的信道估计，通过统一模型处理多种复杂情况，显著提升性能并简化流程。


<details>
  <summary>Details</summary>
Motivation: 解决传统线性MMSE方法在无线通信系统中信道估计的局限性，适应动态资源分配和多输入多输出（MIMO）场景下的未知预编码问题。

Method: 使用由CoarseNet和RefinementNet组成的双单元结构，分别进行初步信道估计和基于空间维度的精细化估计。

Result: ReQuestNet在多种信道条件下显著优于传统MMSE方法，最高可获得10dB的性能增益，并能有效推广到未见过的信道配置中。

Conclusion: ReQuestNet为5G及更高版本的信道估计提供了高效且灵活的解决方案，尤其适合动态资源分配的复杂场景。

Abstract: In this paper, we present a novel neural architecture for channel estimation
(CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network
(ReQuestNet). It incorporates several practical considerations in wireless
communication systems, such as ability to handle variable number of resource
block (RB), dynamic number of transmit layers, physical resource block groups
(PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a
single unified model, thereby, drastically simplifying the CE pipeline. Besides
it addresses several limitations of the legacy linear MMSE solutions, for
example, by being independent of other reference signals and particularly by
jointly processing MIMO layers and differently precoded channels with unknown
precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet
followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive
(Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet
channel estimate by incorporating correlations across differently precoded
PRGs, and correlation across multiple input multiple output (MIMO) channel
spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet
significantly outperforms genie minimum mean squared error (MMSE) CE across a
wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB
gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen
channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations
under dynamic PRG BS and varying transmit layer allocations.

</details>


### [14] [Iterative Distortion Cancellation Algorithms for Single-Sideband Systems](https://arxiv.org/abs/2508.08796)
*Jun Dong,Tianwai Bo,Zhuo Wang,Haolei Gao,Zhongwei Tan,Yi Dong*

Main category: eess.SP

TL;DR: 提出了一种迭代失真消除算法，用于减轻自动偏置控制模块的双边带抖动信号对Kramers-Kronig接收器的影响，无需修改物理层结构。


<details>
  <summary>Details</summary>
Motivation: 解决双边带抖动信号对Kramers-Kronig接收器性能的影响问题。

Method: 利用KK关系进行初始信号决策，并重建由抖动信号引起的失真。

Result: 实验中，对抖动信号的容忍度提高了10% Vπ，80公里光纤传输中接收灵敏度提升超过1 dB。

Conclusion: 该算法有效改善了接收器的性能。

Abstract: We propose an iterative distortion cancellation algorithm to digitally
mitigate the impact of double-sideband dither signal amplitude from the
automatic bias control module on Kramers-Kronig receivers without modifying
physical layer structures. The algorithm utilizes the KK relation for initial
signal decisions and reconstructs the distortion caused by dither signals.
Experimental tests in back-to-back showed it improved tolerance to dither
amplitudes up to 10% V{\pi}. For 80-km fiber transmission, the algorithm
increased the receiver sensitivity by more than 1 dB, confirming the
effectiveness of the proposed distortion cancellation method.

</details>


### [15] [Trajectory-adaptive Beam Shaping: Towards Beam-Management-Free Near-field Communications](https://arxiv.org/abs/2508.08894)
*Sicong Ye,Yulan Gao,Ming Xiao,Peng Wang,Marios Poulakis,Ulrik Imberg*

Main category: eess.SP

TL;DR: 论文提出了一种新型的自适应波束成形技术TABS，通过预定义用户轨迹来优化毫米波和太赫兹频段的通信性能，减少实时波束管理的开销。


<details>
  <summary>Details</summary>
Motivation: 毫米波和太赫兹频段的高频通信虽然提升了数据传输能力，但由于路径损耗和波束对准问题，尤其在用户移动时，性能受限。传统方法的实时波束管理带来了较高的计算和信令开销。

Method: 提出了轨迹自适应波束成形（TABS）技术，通过预定义用户的轨迹来调整电磁波前，无需实时波束管理，优化了能量分布。

Result: 仿真结果表明，TABS在链路性能、开销减少和实现复杂度方面优于传统方法。

Conclusion: TABS为解决高频移动通信中的波束对准问题提供了一种高效且低开销的解决方案。

Abstract: The quest for higher wireless carrier frequencies spanning the
millimeter-wave (mmWave) and Terahertz (THz) bands heralds substantial
enhancements in data throughput and spectral efficiency for next-generation
wireless networks. However, these gains come at the cost of severe path loss
and a heightened risk of beam misalignment due to user mobility, especially
pronounced in near-field communication. Traditional solutions rely on extremely
directional beamforming and frequent beam updates via beam management, but such
techniques impose formidable computational and signaling overhead. In response,
we propose a novel approach termed trajectory-adaptive beam shaping (TABS) that
eliminates the need for real-time beam management by shaping the
electromagnetic wavefront to follow the user's predefined trajectory. Drawing
inspiration from self-accelerating beams in optics, TABS concentrates energy
along pre-defined curved paths corresponding to the user's motion without
requiring real-time beam reconfiguration. We further introduce a dedicated
quantitative metric to characterize performance under the TABS framework.
Comprehensive simulations substantiate the superiority of TABS in terms of link
performance, overhead reduction, and implementation complexity.

</details>


### [16] [Scalable RIS-Aided Beamforming Strategies for Near-Field MU-MISO via Multi-Antenna Feeder](https://arxiv.org/abs/2508.08993)
*Giulia Torcolacci,Malte Schellmann,Davide Dardari*

Main category: eess.SP

TL;DR: 本文研究了一种用于近场多用户通信的可重构智能表面（RIS）辅助的模块化波束形成框架，提出了一种新型天线架构AT-RIS，能够灵活协调性能和复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了在近场多用户通信中实现灵活的性能与复杂度权衡，提出AT-RIS架构，并探究其在不同配置下的适用性。

Method: 通过结合主动多天线馈源阵列和透射式RIS（T-RIS），设计AT-RIS框架，分析对角与非对角T-RIS架构，并比较多种预编码方案。

Result: 非对角方案在用户少且角度分离高时能最大化和速率，但缺乏公平性和可扩展性；对角方案（尤其是基于聚焦的均匀功率分配）在信道状态信息有限时表现出鲁棒性和可扩展性。

Conclusion: 对角AT-RIS架构是近场多用户系统实用且可扩展的解决方案，揭示了频谱效率、复杂度和公平性之间的权衡。

Abstract: This paper investigates a modular beamforming framework for reconfigurable
intelligent surface (RIS)-aided multi-user (MU) communications in the
near-field regime, built upon a novel antenna architecture integrating an
active multi-antenna feeder (AMAF) array with a transmissive RIS (T-RIS),
referred to as AT-RIS. This decoupling enables coordinated yet independently
configurable designs in the AMAF and T-RIS domains, supporting flexible
strategies with diverse complexity-performance trade-offs. Several
implementations are analyzed, including diagonal and non-diagonal T-RIS
architectures, paired with precoding schemes based on focusing, minimum mean
square error, and eigenmode decomposition. Simulation results demonstrate that
while non-diagonal schemes maximize sum rate in scenarios with a limited number
of User Equipments (UEs) and high angular separability, they exhibit fairness
and scalability limitations as UE density increases. Conversely, diagonal T-RIS
configurations, particularly the proposed focusing-based scheme with uniform
feeder-side power allocation, offer robust, fair, and scalable performance with
minimal channel state information. The findings emphasize the critical impact
of UEs' angular separability and reveal inherent trade-offs among spectral
efficiency, complexity, and fairness, positioning diagonal AT-RIS architectures
as practical solutions for scalable near-field MU multiple-input single-output
systems.

</details>


### [17] [Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information](https://arxiv.org/abs/2508.09020)
*Maria Cecilia Fernández Montefiore,Gustavo González,F. Javier López-Martínez,Fernando Gregorio*

Main category: eess.SP

TL;DR: 本文提出了针对下行链路多用户MIMO系统在不完美信道状态信息（CSIT）下的信号干扰噪声比（SINR）改进统计模型，克服了现有方法低估SINR方差的缺点，并验证了其在多种系统配置下的准确性。


<details>
  <summary>Details</summary>
Motivation: 多用户MIMO系统在下一代无线网络中具有重要地位，但不完美CSIT对其性能的影响尚不明确。因此，准确建模SINR是实现性能分析的关键。

Method: 本文提出了一种改进的SINR统计近似模型，保留了现有方法（如基于Gamma的近似）的解析简单性，同时解决了其低估SINR方差的问题。

Result: 在基于速率分割多址（RSMA）的MIMO下行链路系统中，所提模型在多种配置（如用户数、天线数和CSIT过时程度）下表现出极高的准确性。

Conclusion: 改进的SINR模型为不完美CSIT下的多用户MIMO系统性能分析提供了更可靠的工具，具有广泛的应用潜力。

Abstract: Understanding the performance of multi-user multiple-input multiple-output
(MU-MIMO) systems under imperfect channel state information at the transmitter
(CSIT) remains a critical challenge in next-generation wireless networks. In
this context, accurate statistical modeling of the
signal-to-interference-plus-noise ratio (SINR) is essential for enabling
tractable performance analysis of multi-user systems. This paper presents an
improved statistical approximation of the SINR for downlink (DL) MU-MIMO
systems with imperfect CSIT. The proposed model retains the analytical
simplicity of existing approaches (e.g., Gamma-based approximations) while
overcoming their limitations, particularly the underestimation of SINR
variance. We evaluate the proposed approximation in the context of
Rate-Splitting Multiple Access (RSMA)-enabled MIMO DL systems with outdated
CSIT. The results demonstrate excellent accuracy across a wide range of system
configurations, including varying numbers of users, antennas, and degrees of
CSIT staleness.

</details>


### [18] [Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins](https://arxiv.org/abs/2508.09055)
*Lorenzo Cazzella,Francesco Linsalata,Mahdi Maleki,Damiano Badini,Matteo Matteucci,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 该论文提出了一种名为Chartwin的无监督学习方法，将信道绘图与动态数字网络孪生（DNT）结合，显著降低了定位误差。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统需要空间一致的信道表示以高效执行通信任务，信道绘图是一种有效的无监督学习技术，但如何将其与动态DNT结合尚待研究。

Method: 提出了Chartwin方法，通过半监督信道绘图技术构建空间一致的无线地图，并将其与静态和动态DNT集成。

Result: 静态DNT的定位误差约为4.5米，动态DNT约为6米，验证了DNT辅助信道绘图和定位的性能。

Conclusion: Chartwin方法在扩展城市环境中展示了显著的性能，为无线通信系统提供了有效的空间一致性解决方案。

Abstract: Wireless communication systems can significantly benefit from the
availability of spatially consistent representations of the wireless channel to
efficiently perform a wide range of communication tasks. Towards this purpose,
channel charting has been introduced as an effective unsupervised learning
technique to achieve both locally and globally consistent radio maps. In this
letter, we propose Chartwin, a case study on the integration of
localization-oriented channel charting with dynamic Digital Network Twins
(DNTs). Numerical results showcase the significant performance of
semi-supervised channel charting in constructing a spatially consistent chart
of the considered extended urban environment. The considered method results in
$\approx$ 4.5 m localization error for the static DNT and $\approx$ 6 m in the
dynamic DNT, fostering DNT-aided channel charting and localization.

</details>


### [19] [Spectral Efficiency Considerations for 6G](https://arxiv.org/abs/2508.09117)
*Joseph Boccuzzi*

Main category: eess.SP

TL;DR: 本文介绍了一种新的系统指标——无线资源利用效率（RUE），用于量化未来6G需求下的无线资源效率，并比较了典型蜂窝和无小区Massive MIMO部署的性能。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信向6G发展，如何在提高吞吐量、降低时延和增强可靠性的同时实现高效利用资源成为关键挑战。现有指标如频谱效率（SE）和能量效率（EE）无法全面评估资源利用效率，因此需要引入RUE。

Method: 作者提出RUE指标，并通过比较蜂窝和无小区Massive MIMO部署展示其必要性。通过分析5G无线资源、实际限制（如信道矩阵秩不足）和实现损耗（SINR下降）对SE的影响，验证了RUE的应用价值。

Result: 研究发现，5G的RUE仅为47%，表明6G还有显著改进空间。通过实验验证了实际限制与5G MU-MIMO测量的差异，并提出了扩大带宽至1.6GHz的下一代RAN架构方案。

Conclusion: RUE为6G资源效率评估提供了新视角，未来可通过ML算法和下一代RAN架构优化性能。

Abstract: As wireless connectivity continues to evolve towards 6G, there is an
ever-increasing demand to not only deliver higher throughput, lower latency,
and improved reliability, but also do so as efficiently as possible. To this
point, the term efficiency has been quantified through applications to Spectral
Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new
system metric called Radio Resource Utilization Efficiency (RUE). This metric
quantifies the efficiency of the available radio resources (Spectrum, Access
Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We
compare the system performance of Typical Cellular and Cell-Free Massive MIMO
deployments as a vehicle to demonstrate the need for this new metric. We begin
by providing a concise treatment of items impacting SE by introducing three
categories: 5G Radio Resources, Practical Limitations (such as channel matrix
rank deficiency) and Implementation Losses (SINR degradation). For the example
Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47%
(revealing significant room for improvement when defining 6G). Practical
limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO)
measurements conducted in a commercialized deployment. SE losses are
characterized to offer guidance to advanced algorithms employing Machine
Learning (ML) based techniques. We present the benefits of increasing the
transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next
Generation RAN architecture that can support 6G and AI-RAN.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [20] [Developing a Transferable Federated Network Intrusion Detection System](https://arxiv.org/abs/2508.09060)
*Abu Shafin Mohammad Mahdee Jameel,Shreya Ghosh,Aly El Gamal*

Main category: cs.CR

TL;DR: 本文提出了一种基于深度学习的分布式入侵检测系统，通过最大化已知攻击知识的迁移关系来应对未知攻击，采用CNN模型和两种算法提升性能，展现出优异的迁移能力和通用性。


<details>
  <summary>Details</summary>
Motivation: 提升深度学习模型对未知攻击的检测能力，利用已知攻击知识增强入侵检测系统的迁移性和适应性。

Method: 开发了一种CNN模型，结合两步数据预处理和Block-Based Smart Aggregation (BBSA)算法，最大化迁移关系。

Result: 系统在保持高本地检测率的同时，展现出优异的迁移性能，且在不同数据集和模型上具有通用性。

Conclusion: 提出的方法有效增强了入侵检测系统的迁移能力和适应性，适用于分布式网络环境。

Abstract: Intrusion Detection Systems (IDS) are a vital part of a network-connected
device. In this paper, we develop a deep learning based intrusion detection
system that is deployed in a distributed setup across devices connected to a
network. Our aim is to better equip deep learning models against unknown
attacks using knowledge from known attacks. To this end, we develop algorithms
to maximize the number of transferability relationships. We propose a
Convolutional Neural Network (CNN) model, along with two algorithms that
maximize the number of relationships observed. One is a two step data
pre-processing stage, and the other is a Block-Based Smart Aggregation (BBSA)
algorithm. The proposed system succeeds in achieving superior transferability
performance while maintaining impressive local detection rates. We also show
that our method is generalizable, exhibiting transferability potential across
datasets and even with different backbones. The code for this work can be found
at https://github.com/ghosh64/tabfidsv2.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [21] [Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance](https://arxiv.org/abs/2508.08431)
*Praveen Sumanasekara,Athulya Ratnayake,Buddhi Wijenayake,Keshawa Ratnayake,Roshan Godaliyadda,Parakrama Ekanayake,Vijitha Herath*

Main category: eess.IV

TL;DR: 本文提出了一种预处理算法，用于校正高光谱解混中的光谱尺度变异性，显著提升了现有解混算法的性能。


<details>
  <summary>Details</summary>
Motivation: 光谱变异性（特别是由地形、光照和阴影等引起的大尺度变化）会降低高光谱解混的精度和收敛性，现有方法难以有效处理。

Method: 提出了一种数学框架，用于分离和补偿大尺度乘性效应，作为预处理步骤，优化解混输入数据。

Result: 实验表明，该算法将多种现有解混方法的误差降低了近50%，验证了其普遍性和有效性。

Conclusion: 该算法作为高光谱解混流程中的补充步骤，具有广泛的应用潜力。

Abstract: Spectral variability significantly impacts the accuracy and convergence of
hyperspectral unmixing algorithms. While many methods address complex spectral
variability, large-scale variations in spectral signature scale caused by
factors such as topography, illumination, and shadowing remain a major
challenge. These variations often degrade unmixing performance and complicate
model fitting. In this paper, we propose a novel preprocessing algorithm that
corrects scale-induced spectral variability prior to unmixing. By isolating and
compensating for these large-scale multiplicative effects, the algorithm
provides a cleaner input, enabling unmixing methods to focus more effectively
on modeling nonlinear spectral variability and abundance estimation. We present
a rigorous mathematical framework to describe scale variability and extensive
experimental validation of the proposed algorithm. Furthermore, the algorithm's
impact is evaluated across a broad spectrum of state-of-the-art unmixing
algorithms on two synthetic and two real hyperspectral datasets. The proposed
preprocessing step consistently improves the performance of these algorithms,
including those specifically designed to handle spectral variability, with
error reductions close to 50% in many cases. This demonstrates that scale
correction acts as a complementary step, facilitating more accurate unmixing by
existing methods. The algorithm's generality and significant impact highlight
its potential as a key component in practical hyperspectral unmixing pipelines.
The implementation code will be made publicly available upon publication.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [22] [Audio-Visual Speech Enhancement: Architectural Design and Deployment Strategies](https://arxiv.org/abs/2508.08468)
*Anis Hamadouche,Haifeng Luo,Mathini Sellathurai,Tharm Ratnarajah*

Main category: cs.SD

TL;DR: 本文提出了一种基于AI的音频-视觉语音增强（AVSE）系统，并比较了不同部署架构的性能，发现边缘辅助架构在延迟和语音质量之间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 研究动机是通过多模态融合音频和视觉线索，开发高效的语音增强系统，适用于不同部署场景。

Method: 采用CNN进行频谱特征提取和LSTM进行时序建模，研究了云端、边缘辅助和独立设备等多种部署架构。

Result: 云端部署提供最高质量的语音增强，但边缘辅助架构在5G和Wi-Fi 6下实现了延迟和清晰度的最佳平衡。

Conclusion: 研究结果为不同应用场景（如助听器、远程呈现和工业通信）中的AVSE架构选择和优化提供了实践指导。

Abstract: This paper introduces a new AI-based Audio-Visual Speech Enhancement (AVSE)
system and presents a comparative performance analysis of different deployment
architectures. The proposed AVSE system employs convolutional neural networks
(CNNs) for spectral feature extraction and long short-term memory (LSTM)
networks for temporal modeling, enabling robust speech enhancement through
multimodal fusion of audio and visual cues. Multiple deployment scenarios are
investigated, including cloud-based, edge-assisted, and standalone device
implementations. Their performance is evaluated in terms of speech quality
improvement, latency, and computational overhead. Real-world experiments are
conducted across various network conditions, including Ethernet, Wi-Fi, 4G, and
5G, to analyze the trade-offs between processing delay, communication latency,
and perceptual speech quality. The results show that while cloud deployment
achieves the highest enhancement quality, edge-assisted architectures offer the
best balance between latency and intelligibility, meeting real-time
requirements under 5G and Wi-Fi 6 conditions. These findings provide practical
guidelines for selecting and optimizing AVSE deployment architectures in
diverse applications, including assistive hearing devices, telepresence, and
industrial communications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [23] [FetFIDS: A Feature Embedding Attention based Federated Network Intrusion Detection Algorithm](https://arxiv.org/abs/2508.09056)
*Shreya Ghosh,Abu Shafin Mohammad Mahdee Jameel,Aly El Gamal*

Main category: cs.LG

TL;DR: FetFIDS是一种基于特征嵌入而非位置嵌入的Transformer深度学习系统，旨在提升入侵检测性能，适用于联邦学习环境。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习的发展，入侵检测系统（IDS）的性能得到显著提升。为提高基于Transformer的深度学习系统的检测性能，研究者探索使用特征嵌入代替位置嵌入。

Method: 论文提出FetFIDS模型，采用特征嵌入技术，适用于联邦学习场景，通过多轮通信确保隐私和本地性能提升。

Result: FetFIDS在联邦学习环境中表现优于多种先进入侵检测系统，并展现出对联邦学习的高度适应性。

Conclusion: FetFIDS通过特征嵌入和联邦学习的结合，有效提升了入侵检测性能，适合边缘计算部署。

Abstract: Intrusion Detection Systems (IDS) have an increasingly important role in
preventing exploitation of network vulnerabilities by malicious actors. Recent
deep learning based developments have resulted in significant improvements in
the performance of IDS systems. In this paper, we present FetFIDS, where we
explore the employment of feature embedding instead of positional embedding to
improve intrusion detection performance of a transformer based deep learning
system. Our model is developed with the aim of deployments in edge learning
scenarios, where federated learning over multiple communication rounds can
ensure both privacy and localized performance improvements. FetFIDS outperforms
multiple state-of-the-art intrusion detection systems in a federated
environment and demonstrates a high degree of suitability to federated
learning. The code for this work can be found at
https://github.com/ghosh64/fetfids.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [24] [Exploring Disentangled Neural Speech Codecs from Self-Supervised Representations](https://arxiv.org/abs/2508.08399)
*Ryo Aihara,Yoshiki Masuyama,Gordon Wichern,François G. Germain,Jonathan Le Roux*

Main category: eess.AS

TL;DR: 研究提出了一种能够结构化解耦的离散神经音频编码器，实现了与传统编码器相当的音频重建性能，同时达到了传统语音转换技术的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的神经音频编码器在编码语音时会将语言内容和副语言特征混合编码，限制了灵活性。语音转换任务需要解耦这些特征，本研究旨在开发一种能够解耦的离散编码器。

Method: 受到使用$k$-均值量化和自监督特征解耦语音信息的方法启发，研究者开发了一种能够结构化解耦的离散神经音频编码器。

Result: 实验证明，该编码器在音频重建性能上与传统编码器相当，同时在语音转换任务中达到了传统技术的效果。

Conclusion: 本研究成功实现了结构化解耦的离散神经音频编码器，为下游任务提供了更灵活的表示方式。

Abstract: Neural audio codecs (NACs), which use neural networks to generate compact
audio representations, have garnered interest for their applicability to many
downstream tasks -- especially quantized codecs due to their compatibility with
large language models. However, unlike text, speech conveys not only linguistic
content but also rich paralinguistic features. Encoding these elements in an
entangled fashion may be suboptimal, as it limits flexibility. For instance,
voice conversion (VC) aims to convert speaker characteristics while preserving
the original linguistic content, which requires a disentangled representation.
Inspired by VC methods utilizing $k$-means quantization with self-supervised
features to disentangle phonetic information, we develop a discrete NAC capable
of structured disentanglement. Experimental evaluations show that our approach
achieves reconstruction performance on par with conventional NACs that do not
explicitly perform disentanglement, while also matching the effectiveness of
conventional VC techniques.

</details>


### [25] [MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs](https://arxiv.org/abs/2508.08715)
*Xiaoxue Gao,Huayun Zhang,Nancy F. Chen*

Main category: eess.AS

TL;DR: MultiAiTutor是一种基于LLM架构的多语言生成AI导师，专注于儿童语言学习，支持低资源语言的学习环境。


<details>
  <summary>Details</summary>
Motivation: 当前生成语音模型在个性化教育中有潜力，但在低资源语言和文化背景下生成高质量儿童友好型语音仍具挑战。

Method: 利用LLM架构设计多语言儿童友好型语音生成系统，结合文化相关的图像描述任务支持三种低资源语言。

Result: 实验显示，MultiAiTutor在客观指标和主观评价上均优于基线方法。

Conclusion: MultiAiTutor为低资源语言和文化背景下的儿童语言学习提供了有效的解决方案。

Abstract: Generative speech models have demonstrated significant potential in
personalizing teacher-student interactions, offering valuable real-world
applications for language learning in children's education. However, achieving
high-quality, child-friendly speech generation remains challenging,
particularly for low-resource languages across diverse languages and cultural
contexts. In this paper, we propose MultiAiTutor, an educational multilingual
generative AI tutor with child-friendly designs, leveraging LLM architecture
for speech generation tailored for educational purposes. We propose to
integrate age-appropriate multilingual speech generation using LLM
architectures, facilitating young children's language learning through
culturally relevant image-description tasks in three low-resource languages:
Singaporean-accent Mandarin, Malay, and Tamil. Experimental results from both
objective metrics and subjective evaluations demonstrate the superior
performance of the proposed MultiAiTutor compared to baseline methods.

</details>
