{"id": "2507.00294", "pdf": "https://arxiv.org/pdf/2507.00294", "abs": "https://arxiv.org/abs/2507.00294", "authors": ["Amir Javadi Rad", "Amirafshar Moshtaghpour", "Dongdong Chen", "Angus I. Kirkland"], "title": "Fast Simulation of Damage Diffusion Distribution in Scanning Transmission Electron Microscopy", "categories": ["eess.SP", "cond-mat.mtrl-sci"], "comment": "Presented in ISCS25", "summary": "Scanning Transmission Electron Microscopy (STEM) is a critical tool for\nimaging the properties of materials and biological specimens at atomic scale,\nyet our understanding of relevant electron beam damage mechanisms is\nincomplete. Recent studies suggest that certain types of damage can be modelled\nas a diffusion process. However, numerical simulation of such diffusion\nprocesses has remained computationally intensive. This work introduces a\nhigh-performance C++ framework for simulating damage diffusion process in STEM\nthat combines efficient numerical computation, advanced visualisations, and\nmultithreading to achieve efficient runtime while maintaining accuracy."}
{"id": "2507.00508", "pdf": "https://arxiv.org/pdf/2507.00508", "abs": "https://arxiv.org/abs/2507.00508", "authors": ["Hyeon Seok Rou", "Kengo Ando", "Giuseppe Thadeu Freitas de Abreu", "David Gonz√°lez G"], "title": "Quadrature Over-the-Air-Computing for Multimodal Dual-Stream Signal Processing", "categories": ["eess.SP"], "comment": null, "summary": "We propose a novel quadrature over-the-air computing (Q-OTAC) framework that\nenables the simultaneously computation of two independent functions and/or data\nstream within a single transmission. In contrast to conventional OTAC schemes,\nwhere a single function is computed by treating each complex signal as a single\ncomponent, the proposed Q-OTAC exploits both in-phase and quadrature (IQ)\ncomponents of a complex signal, encoding two distinct functions and/or data\nstreams at the edge devices (EDs) and employing a novel low-complexity\nIQ-decoupled combiner at the access point (AP) to independently recover each\nstream, which effectively doubles the computation rate. A key strength of this\nframework lies in its simplicity and broad compatibility: the extension into\nthe quadrature domain is conceptually straightforward, yet remakably powerful,\nallowing seamless integration into existing OTAC techniques. Simulation results\nvalidate the effectiveness of this approach, including the first demonstration\nof dual-function aggregation (e.g., parallel summation and product),\nhighlighting the potential of Q-OTAC for enabling multi-modal and\nhigh-efficiency beyond fifth generation (B5G) applications."}
{"id": "2507.00529", "pdf": "https://arxiv.org/pdf/2507.00529", "abs": "https://arxiv.org/abs/2507.00529", "authors": ["Ruopeng Xu", "Zhaohui Yang", "Ting Zhang", "Mingzhe Chen", "Chen Zhu", "Zhaoyang Zhang"], "title": "Fair Rate Maximization for Fluid Antenna Relay (FAR)-assisted Multi-user MISO Communications", "categories": ["eess.SP"], "comment": null, "summary": "In this paper, we investigate the problem of max-min rate maximization in\nfluid antenna relay (FAR)-assisted multi-user uplink multiple-input\nsingle-output (MISO) wireless systems, where each user is equipped with a\nsingle fluid antenna (FA) and the base station (BS) is equipped with multiple\nFAs. Unlike most existing relevant work focusing on maximizing sum rate of the\nfluid antenna system (FAS), which may cause unbearable rate loss to weak users,\nwe propose to maximize the minimal rate of the system to ensure fairness. The\nmax-min optimization problem is formulated by jointly optimizing the positions\nof FAs with meeting the minimum distance requirements of FAs, maximum\ntransmitting power limit, and feasible antenna region constraints. To solve\nthis problem, we propose an alternating algorithm with utilizing the successive\nconvex approximation (SCA) method. Simulation results demonstrate that the\nproposed method significantly outperforms conventional methods in terms of\nmaximizing the minimal achievable rate across different signal-to-noise ratios\n(SNRs) and normalized region sizes."}
{"id": "2507.00571", "pdf": "https://arxiv.org/pdf/2507.00571", "abs": "https://arxiv.org/abs/2507.00571", "authors": ["Georgios Kokkinis", "Alexandros Iosifidis", "Qi Zhang"], "title": "Delay Bound Relaxation with Deep Learning-based Haptic Estimation for Tactile Internet", "categories": ["eess.SP"], "comment": "6 pages, 6 figures, 1 table, conference paper submitted in\n  GLOBECOM2025", "summary": "Haptic teleoperation typically demands sub-millisecond latency and ultra-high\nreliability (99.999%) in Tactile Internet. At a 1 kHz haptic signal sampling\nrate, this translates into an extremely high packet transmission rate, posing\nsignificant challenges for timely delivery and introducing substantial\ncomplexity and overhead in radio resource allocation. To address this critical\nchallenge, we introduce a novel DL modelthat estimates force feedback using\nmulti-modal input, i.e. both force measurements from the remote side and local\noperator motion signals. The DL model can capture complex temporal features of\nhaptic time-series with the use of CNN and LSTM layers, followed by a\ntransformer encoder, and autoregressively produce a highly accurate estimation\nof the next force values for different teleoperation activities. By ensuring\nthat the estimation error is within a predefined threshold, the teleoperation\nsystem can safely relax its strict delay requirements. This enables the\nbatching and transmission of multiple haptic packets within a single resource\nblock, improving resource efficiency and facilitating scheduling in resource\nallocation. Through extensive simulations, we evaluated network performance in\nterms of reliability and capacity. Results show that, for both dynamic and\nrigid object interactions, the proposed method increases the number of reliably\nserved users by up to 66%."}
{"id": "2507.00605", "pdf": "https://arxiv.org/pdf/2507.00605", "abs": "https://arxiv.org/abs/2507.00605", "authors": ["Guangyi Zhang", "Yunlong Cai", "Guanding Yu", "Petar Popovski", "Osvaldo Simeone"], "title": "Quantize-Sample-and-Verify: LLM Acceleration via Adaptive Edge-Cloud Speculative Decoding", "categories": ["eess.SP"], "comment": "Submit for review", "summary": "In edge-cloud speculative decoding (SD), edge devices equipped with small\nlanguage models (SLMs) generate draft tokens that are verified by large\nlanguage models (LLMs) in the cloud. A key bottleneck in such systems is the\nlimited communication bandwidth between edge and cloud, which necessitates\nquantization of the information transmitted about generated tokens. In this\nwork, we introduce a novel quantize-sample (Q-S) strategy that provably\npreserves the output distribution of the cloud-based model, ensuring that the\nverified tokens match the distribution of those that would have been generated\ndirectly by the LLM. We develop a throughput model for edge-cloud SD that\nexplicitly accounts for communication latency. Leveraging this model, we\npropose an adaptive mechanism that optimizes token throughput by dynamically\nadjusting the draft length and quantization precision in response to both\nsemantic uncertainty and channel conditions. Simulations demonstrate that the\nproposed Q-S approach significantly improves decoding efficiency in realistic\nedge-cloud deployment scenarios."}
{"id": "2507.00714", "pdf": "https://arxiv.org/pdf/2507.00714", "abs": "https://arxiv.org/abs/2507.00714", "authors": ["Vahid Shahiri", "Guyue Li", "Hamid Behroozi"], "title": "Physical Layer Group Key Generation With the Aid of Reconfigurable Intelligent Surfaces", "categories": ["eess.SP"], "comment": "This manuscript has been submitted to IEEE Transactions on\n  Communications (TCOM) and is currently under review", "summary": "Reconfigurable intelligent surfaces (RIS) have the ability to alter the\nwireless environment by making changes in the impinging signal. Motivated by\nthis ability, in this study, we exploit the RIS to make the aggregate\nreflecting channels of different user terminals (UTs) as similar as possible to\nbe able to extract common group secret keys from their channels. Specifically,\nthe RIS will adjust its parameters to pave the way for group key generation\n(GKG) based on the physical channels of the UTs. Our method exploits the\nalready gathered channel state information (CSI) in the RIS to beneficially\ndesign the phase shifts and does not impose additional probing burden on the\nnetwork. Additionally, this scheme is broadcast-based and does not entail the\noverheads of the pairwise-based key generation. We consider both passive RIS\n(PRIS) and active RIS (ARIS) to generate the group keys. The PRIS is widely\nadopted in physical layer key generation (PLKG) studies due to its use of\npassive elements, whereas the ARIS demonstrates superior capability in aligning\nthe aggregate reflected channels among nodes in the GKG scenario, as\ndemonstrated in this study. We will exploit various optimization methods like\nsuccessive convex approximation (SCA) and semidefinite relaxation with Gaussian\nrandomization (SDR-GR) to address the raised optimization problems. Unlike most\nof the studies in the literature, our scheme can achieve a high GKG rate in\nstatic environments as well. Finally, we will examine the performance of the\nproposed method by normalized mean squared error (NMSE), key error rate (KER),\nkey generation rate (KGR) and key randomness metrics. Our numerical results\nverify that for the equal available power budget, the ARIS significantly\noutperforms PRIS in NMSE and KER, achieving more than four times higher KGR."}
{"id": "2507.00895", "pdf": "https://arxiv.org/pdf/2507.00895", "abs": "https://arxiv.org/abs/2507.00895", "authors": ["Jipeng Gan", "Yucheng Sheng", "Hua Zhang", "Le Liang", "Hao Ye", "Chongtao Guo", "Shi Jin"], "title": "SComCP: Task-Oriented Semantic Communication for Collaborative Perception", "categories": ["eess.SP"], "comment": null, "summary": "Reliable detection of surrounding objects is critical for the safe operation\nof connected automated vehicles (CAVs). However, inherent limitations such as\nthe restricted perception range and occlusion effects compromise the\nreliability of single-vehicle perception systems in complex traffic\nenvironments. Collaborative perception has emerged as a promising approach by\nfusing sensor data from surrounding CAVs with diverse viewpoints, thereby\nimproving environmental awareness. Although collaborative perception holds\ngreat promise, its performance is bottlenecked by wireless communication\nconstraints, as unreliable and bandwidth-limited channels hinder the\ntransmission of sensor data necessary for real-time perception. To address\nthese challenges, this paper proposes SComCP, a novel task-oriented semantic\ncommunication framework for collaborative perception. Specifically, SComCP\nintegrates an importance-aware feature selection network that selects and\ntransmits semantic features most relevant to the perception task, significantly\nreducing communication overhead without sacrificing accuracy. Furthermore, we\ndesign a semantic codec network based on a joint source and channel coding\n(JSCC) architecture, which enables bidirectional transformation between\nsemantic features and noise-tolerant channel symbols, thereby ensuring stable\nperception under adverse wireless conditions. Extensive experiments demonstrate\nthe effectiveness of the proposed framework. In particular, compared to\nexisting approaches, SComCP can maintain superior perception performance across\nvarious channel conditions, especially in low signal-to-noise ratio (SNR)\nscenarios. In addition, SComCP exhibits strong generalization capability,\nenabling the framework to maintain high performance across diverse channel\nconditions, even when trained with a specific channel model."}
{"id": "2507.00928", "pdf": "https://arxiv.org/pdf/2507.00928", "abs": "https://arxiv.org/abs/2507.00928", "authors": ["Ahmed Al-Tahmeesschi", "Yi Chu", "Josh Shackleton", "Swarna Chetty", "Mostafa Rahmani", "David Grace", "Hamed Ahmadi"], "title": "Enhancing Open RAN Digital Twin Through Power Consumption Measurement", "categories": ["eess.SP"], "comment": "Accepted in PIMRC 2025", "summary": "The increasing demand for high-speed, ultra-reliable and low-latency\ncommunications in 5G and beyond networks has led to a significant increase in\npower consumption, particularly within the Radio Access Network (RAN). This\ngrowing energy demand raises operational and sustainability challenges for\nmobile network operators, requiring novel solutions to enhance energy\nefficiency while maintaining Quality of Service (QoS). 5G networks are evolving\ntowards disaggregated, programmable, and intelligent architectures, with Open\nRadio Access Network (O-RAN) spearheaded by the O-RAN Alliance, enabling\ngreater flexibility, interoperability, and cost-effectiveness. However, this\ndisaggregated approach introduces new complexities, especially in terms of\npower consumption across different network components, including Open Radio\nUnits (RUs), Open Distributed Units (DUs) and Open Central Units (CUs).\nUnderstanding the power efficiency of different O-RAN functional splits is\ncrucial for optimising energy consumption and network sustainability. In this\npaper, we present a comprehensive measurement study of power consumption in\nRUs, DUs and CUs under varying network loads, specifically analysing the impact\nof Physical resource block (PRB) utilisation in Split 8 and Split 7.2b. The\nmeasurements were conducted on both software-defined radio (SDR)-based RUs and\ncommercial indoor and outdoor RU, as well as their corresponding DU and CU. By\nevaluating real-world hardware deployments under different operational\nconditions, this study provides empirical insights into the power efficiency of\nvarious O-RAN configurations. The results highlight that power consumption does\nnot scale significantly with network load, suggesting that a large portion of\nenergy consumption remains constant regardless of traffic demand."}
{"id": "2507.00055", "pdf": "https://arxiv.org/pdf/2507.00055", "abs": "https://arxiv.org/abs/2507.00055", "authors": ["Varsha Pendyala", "Pedro Morgado", "William Sethares"], "title": "Leveraging Unlabeled Audio-Visual Data in Speech Emotion Recognition using Knowledge Distillation", "categories": ["cs.LG", "cs.HC", "cs.MM", "eess.AS", "eess.IV", "eess.SP"], "comment": "Accepted at INTERSPEECH 2025", "summary": "Voice interfaces integral to the human-computer interaction systems can\nbenefit from speech emotion recognition (SER) to customize responses based on\nuser emotions. Since humans convey emotions through multi-modal audio-visual\ncues, developing SER systems using both the modalities is beneficial. However,\ncollecting a vast amount of labeled data for their development is expensive.\nThis paper proposes a knowledge distillation framework called LightweightSER\n(LiSER) that leverages unlabeled audio-visual data for SER, using large teacher\nmodels built on advanced speech and face representation models. LiSER transfers\nknowledge regarding speech emotions and facial expressions from the teacher\nmodels to lightweight student models. Experiments conducted on two benchmark\ndatasets, RAVDESS and CREMA-D, demonstrate that LiSER can reduce the dependence\non extensive labeled datasets for SER tasks."}
{"id": "2507.00061", "pdf": "https://arxiv.org/pdf/2507.00061", "abs": "https://arxiv.org/abs/2507.00061", "authors": ["Hoang-Dieu Vu", "Duc-Nghia Tran", "Quang-Tu Pham", "Hieu H. Pham", "Nicolas Vuillerme", "Duc-Tan Tran"], "title": "Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "This paper introduces Smooth-Distill, a novel self-distillation framework\ndesigned to simultaneously perform human activity recognition (HAR) and sensor\nplacement detection using wearable sensor data. The proposed approach utilizes\na unified CNN-based architecture, MTL-net, which processes accelerometer data\nand branches into two outputs for each respective task. Unlike conventional\ndistillation methods that require separate teacher and student models, the\nproposed framework utilizes a smoothed, historical version of the model itself\nas the teacher, significantly reducing training computational overhead while\nmaintaining performance benefits. To support this research, we developed a\ncomprehensive accelerometer-based dataset capturing 12 distinct sleep postures\nacross three different wearing positions, complementing two existing public\ndatasets (MHealth and WISDM). Experimental results show that Smooth-Distill\nconsistently outperforms alternative approaches across different evaluation\nscenarios, achieving notable improvements in both human activity recognition\nand device placement detection tasks. This method demonstrates enhanced\nstability in convergence patterns during training and exhibits reduced\noverfitting compared to traditional multitask learning baselines. This\nframework contributes to the practical implementation of knowledge distillation\nin human activity recognition systems, offering an effective solution for\nmultitask learning with accelerometer data that balances accuracy and training\nefficiency. More broadly, it reduces the computational cost of model training,\nwhich is critical for scenarios requiring frequent model updates or training on\nresource-constrained platforms. The code and model are available at\nhttps://github.com/Kuan2vn/smooth\\_distill."}
{"id": "2507.00102", "pdf": "https://arxiv.org/pdf/2507.00102", "abs": "https://arxiv.org/abs/2507.00102", "authors": ["Bernd Hofmann", "Patrick Bruendl", "Huong Giang Nguyen", "Joerg Franke"], "title": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Ensuring consistent product quality in modern manufacturing is crucial,\nparticularly in safety-critical applications. Conventional quality control\napproaches, reliant on manually defined thresholds and features, lack\nadaptability to the complexity and variability inherent in production data and\nnecessitate extensive domain expertise. Conversely, data-driven methods, such\nas machine learning, demonstrate high detection performance but typically\nfunction as black-box models, thereby limiting their acceptance in industrial\nenvironments where interpretability is paramount. This paper introduces a\nmethodology for industrial fault detection, which is both data-driven and\ntransparent. The approach integrates a supervised machine learning model for\nmulti-class fault classification, Shapley Additive Explanations for post-hoc\ninterpretability, and a do-main-specific visualisation technique that maps\nmodel explanations to operator-interpretable features. Furthermore, the study\nproposes an evaluation methodology that assesses model explanations through\nquantitative perturbation analysis and evaluates visualisations by qualitative\nexpert assessment. The approach was applied to the crimping process, a\nsafety-critical joining technique, using a dataset of univariate, discrete time\nseries. The system achieves a fault detection accuracy of 95.9 %, and both\nquantitative selectivity analysis and qualitative expert evaluations confirmed\nthe relevance and inter-pretability of the generated explanations. This\nhuman-centric approach is designed to enhance trust and interpretability in\ndata-driven fault detection, thereby contributing to applied system design in\nindustrial quality control."}
{"id": "2507.00145", "pdf": "https://arxiv.org/pdf/2507.00145", "abs": "https://arxiv.org/abs/2507.00145", "authors": ["Hasan Yiƒüit"], "title": "AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform\nentropy directly from physical noise, eliminating the need for bulky quantum\ndevices or expensive laboratory-grade RF receivers. Instead, it relies on a\nlow-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and\nthen emits 32-bit high-entropy streams without any quantization step.\n  Unlike deterministic or trained artificial intelligence random number\ngenerators (RNGs), our dynamic inner-outer network couples adaptive natural\nsources and reseeding, yielding truly unpredictable and autonomous sequences.\nGenerated numbers pass the NIST SP 800-22 battery better than a CPU-based\nmethod. It also passes nineteen bespoke statistical tests for both bit- and\ninteger-level analysis. All results satisfy cryptographic standards, while\nforward and backward prediction experiments reveal no exploitable biases. The\nmodel's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft\ncores, as well as suitable for other resource-constrained platforms.\n  By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG\nbroadens the reach of high-integrity random number generators across secure\nsystems, cryptographic protocols, embedded and edge devices, stochastic\nsimulations, and server applications that need randomness."}
{"id": "2507.00155", "pdf": "https://arxiv.org/pdf/2507.00155", "abs": "https://arxiv.org/abs/2507.00155", "authors": ["Richa Namballa", "Agnieszka Roginska", "Magdalena Fuentes"], "title": "Do Music Source Separation Models Preserve Spatial Information in Binaural Audio?", "categories": ["eess.AS", "cs.SD", "eess.SP"], "comment": "6 pages + references, 4 figures, 2 tables, 26th International Society\n  for Music Information Retrieval (ISMIR) Conference", "summary": "Binaural audio remains underexplored within the music information retrieval\ncommunity. Motivated by the rising popularity of virtual and augmented reality\nexperiences as well as potential applications to accessibility, we investigate\nhow well existing music source separation (MSS) models perform on binaural\naudio. Although these models process two-channel inputs, it is unclear how\neffectively they retain spatial information. In this work, we evaluate how\nseveral popular MSS models preserve spatial information on both standard stereo\nand novel binaural datasets. Our binaural data is synthesized using stems from\nMUSDB18-HQ and open-source head-related transfer functions by positioning\ninstrument sources randomly along the horizontal plane. We then assess the\nspatial quality of the separated stems using signal processing and interaural\ncue-based metrics. Our results show that stereo MSS models fail to preserve the\nspatial information critical for maintaining the immersive quality of binaural\naudio, and that the degradation depends on model architecture as well as the\ntarget instrument. Finally, we highlight valuable opportunities for future work\nat the intersection of MSS and immersive audio."}
{"id": "2507.00231", "pdf": "https://arxiv.org/pdf/2507.00231", "abs": "https://arxiv.org/abs/2507.00231", "authors": ["Gennadi Saiko", "Timothy Burton", "Faraz Sadrzadeh-Afsharazar", "Shota Yamashita", "Kenshin Shimono", "Yasuyuki Kakihana", "Alexandre Douplik"], "title": "Observation of Blood Flow in Major Neck Vessels Modulated 1 by Physiological Maneuvers", "categories": ["physics.med-ph", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "Large neck vessels (carotid artery and internal jugular vein, IJV) offer a\nunique opportunity to monitor hemodynamics non-invasively by optical means. The\nprimary shortcoming of past work has been the focus on healthy volunteers in\nnormal physiological conditions and well-controlled environments. To drive the\ntechnology closer to the bedside, testing is required under more re-alistic\nconditions, including in pathologies and real-world environments (e.g., similar\ntoICU or emergency care settings). The primary goal of the current work was to\nextend the range of physiological maneuvers for blood flow modulation by\nintroducing new maneuvers and ob-serving PPG response to them. The data from\nthe necks of two healthy volunteers in a supine position were collected by\nclinical PPG and in-house built PPG sensors, accompanied by ECG signal\ncollection. Seven maneuvers (abdominojugular test, breath holding, Valsalva,\nproximal occlusion of right IJV, distal occlusion of right IJV, proximal\nocclusion of left IJV, distal occlusion of left IJV) were performed in sequence\nwith 1 min allocated for each maneuver. The 1 min was split into three\nsegments: baseline (15 s), experiment (15 s), and recovery (30 s). Thus, the\noverall du-ration of the experiment was 7 min. AC amplitude from clinical PPG,\nDC amplitudes from in-house built PPG, and ECG signal were compared during all\nseven physiological maneuvers. Newly proposed maneuvers (Valsalva and IJV\nocclusions) demonstrated modulation of blood flow, which was more significant\nthan previously reported maneuvers (abdominojugular test and breath holding).\nThe proposed physiological maneuvers demonstrate high potential as instruments\nfor modulating blood flow in major neck vessels."}
{"id": "2507.00366", "pdf": "https://arxiv.org/pdf/2507.00366", "abs": "https://arxiv.org/abs/2507.00366", "authors": ["Jian Xiao", "Ji Wang", "Kunrui Cao", "Xingwang Li", "Zhao Chen", "Chau Yuen"], "title": "Wireless AI Evolution: From Statistical Learners to Electromagnetic-Guided Foundation Models", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "While initial applications of artificial intelligence (AI) in wireless\ncommunications over the past decade have demonstrated considerable potential\nusing specialized models for targeted communication tasks, the revolutionary\ndemands of sixth-generation (6G) networks for holographic communications,\nubiquitous sensing, and native intelligence are propelling a necessary\nevolution towards AI-native wireless networks. The arrival of large AI models\npaves the way for the next phase of Wireless AI, driven by wireless foundation\nmodels (WFMs). In particular, pre-training on universal electromagnetic (EM)\nprinciples equips WFMs with the essential adaptability for a multitude of\ndemanding 6G applications. However, existing large AI models face critical\nlimitations, including pre-training strategies disconnected from EM-compliant\nconstraints leading to physically inconsistent predictions, a lack of embedded\nunderstanding of wave propagation physics, and the inaccessibility of massive\nlabeled datasets for comprehensive EM-aware training. To address these\nchallenges, this article presents an electromagnetic information theory-guided\nself-supervised pre-training (EIT-SPT) framework designed to systematically\ninject EM physics into WFMs. The EIT-SPT framework aims to infuse WFMs with\nintrinsic EM knowledge, thereby enhancing their physical consistency,\ngeneralization capabilities across varied EM landscapes, and overall data\nefficiency. Building upon the proposed EIT-SPT framework, this article first\nelaborates on diverse potential applications in 6G scenarios of WFMs, then\nvalidates the efficacy of the proposed framework through illustrative case\nstudies, and finally summarizes critical open research challenges and future\ndirections for WFMs."}
{"id": "2507.00388", "pdf": "https://arxiv.org/pdf/2507.00388", "abs": "https://arxiv.org/abs/2507.00388", "authors": ["Mengru Wu", "Yu Gao", "Weidang Lu", "Huimei Han", "Lei Sun", "Wanli Ni"], "title": "Accuracy and Security-Guaranteed Participant Selection and Beamforming Design for RIS-Assisted Federated Learning", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "Federated learning (FL) has emerged as an effective approach for training\nneural network models without requiring the sharing of participants' raw data,\nthereby addressing data privacy concerns. In this paper, we propose a\nreconfigurable intelligent surface (RIS)-assisted FL framework in the presence\nof eavesdropping, where partial edge devices are selected to participate in the\nFL training process. In contrast, the remaining devices serve as cooperative\njammers by transmitting jamming signals to disrupt eavesdropping. We aim to\nminimize the training latency in each FL round by jointly optimizing\nparticipant selection, bandwidth allocation, and RIS beamforming design,\nsubject to the convergence accuracy of FL and the secure uploading\nrequirements. To solve the resulting mixed-integer nonlinear programming\nproblem, we propose a twin delayed deep deterministic policy gradient (TD3)\nalgorithm. Simulation results demonstrate that the proposed scheme reduces the\nFL training latency by approximately 27$\\%$ compared to baselines."}
{"id": "2507.00654", "pdf": "https://arxiv.org/pdf/2507.00654", "abs": "https://arxiv.org/abs/2507.00654", "authors": ["Hans van Gorp", "Davide Belli", "Amir Jalalirad", "Bence Major"], "title": "Neural Augmented Kalman Filters for Road Network assisted GNSS positioning", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": "Accepted to ICML 2025 workshop ML4Wireless", "summary": "The Global Navigation Satellite System (GNSS) provides critical positioning\ninformation globally, but its accuracy in dense urban environments is often\ncompromised by multipath and non-line-of-sight errors. Road network data can be\nused to reduce the impact of these errors and enhance the accuracy of a\npositioning system. Previous works employing road network data are either\nlimited to offline applications, or rely on Kalman Filter (KF) heuristics with\nlittle flexibility and robustness. We instead propose training a Temporal Graph\nNeural Network (TGNN) to integrate road network information into a KF. The TGNN\nis designed to predict the correct road segment and its associated uncertainty\nto be used in the measurement update step of the KF. We validate our approach\nwith real-world GNSS data and open-source road networks, observing a 29%\ndecrease in positioning error for challenging scenarios compared to a GNSS-only\nKF. To the best of our knowledge, ours is the first deep learning-based\napproach jointly employing road network data and GNSS measurements to determine\nthe user position on Earth."}
{"id": "2507.00739", "pdf": "https://arxiv.org/pdf/2507.00739", "abs": "https://arxiv.org/abs/2507.00739", "authors": ["An Le", "Hung Nguyen", "Sungbal Seo", "You-Suk Bae", "Truong Nguyen"], "title": "Biorthogonal Tunable Wavelet Unit with Lifting Scheme in Convolutional Neural Network", "categories": ["cs.CV", "eess.IV", "eess.SP"], "comment": null, "summary": "This work introduces a novel biorthogonal tunable wavelet unit constructed\nusing a lifting scheme that relaxes both the orthogonality and equal filter\nlength constraints, providing greater flexibility in filter design. The\nproposed unit enhances convolution, pooling, and downsampling operations,\nleading to improved image classification and anomaly detection in convolutional\nneural networks (CNN). When integrated into an 18-layer residual neural network\n(ResNet-18), the approach improved classification accuracy on CIFAR-10 by 2.12%\nand on the Describable Textures Dataset (DTD) by 9.73%, demonstrating its\neffectiveness in capturing fine-grained details. Similar improvements were\nobserved in ResNet-34. For anomaly detection in the hazelnut category of the\nMVTec Anomaly Detection dataset, the proposed method achieved competitive and\nwellbalanced performance in both segmentation and detection tasks,\noutperforming existing approaches in terms of accuracy and robustness."}
{"id": "2507.00743", "pdf": "https://arxiv.org/pdf/2507.00743", "abs": "https://arxiv.org/abs/2507.00743", "authors": ["An Le", "Nehal Mehta", "William Freeman", "Ines Nagel", "Melanie Tran", "Anna Heinke", "Akshay Agnihotri", "Lingyun Cheng", "Dirk-Uwe Bartsch", "Hung Nguyen", "Truong Nguyen", "Cheolhong An"], "title": "Tunable Wavelet Unit based Convolutional Neural Network in Optical Coherence Tomography Analysis Enhancement for Classifying Type of Epiretinal Membrane Surgery", "categories": ["eess.IV", "cs.CV", "eess.SP"], "comment": null, "summary": "In this study, we developed deep learning-based method to classify the type\nof surgery performed for epiretinal membrane (ERM) removal, either internal\nlimiting membrane (ILM) removal or ERM-alone removal. Our model, based on the\nResNet18 convolutional neural network (CNN) architecture, utilizes\npostoperative optical coherence tomography (OCT) center scans as inputs. We\nevaluated the model using both original scans and scans preprocessed with\nenergy crop and wavelet denoising, achieving 72% accuracy on preprocessed\ninputs, outperforming the 66% accuracy achieved on original scans. To further\nimprove accuracy, we integrated tunable wavelet units with two key adaptations:\nOrthogonal Lattice-based Wavelet Units (OrthLatt-UwU) and Perfect\nReconstruction Relaxation-based Wavelet Units (PR-Relax-UwU). These units\nallowed the model to automatically adjust filter coefficients during training\nand were incorporated into downsampling, stride-two convolution, and pooling\nlayers, enhancing its ability to distinguish between ERM-ILM removal and\nERM-alone removal, with OrthLattUwU boosting accuracy to 76% and PR-Relax-UwU\nincreasing performance to 78%. Performance comparisons showed that our AI model\noutperformed a trained human grader, who achieved only 50% accuracy in\nclassifying the removal surgery types from postoperative OCT scans. These\nfindings highlight the potential of CNN based models to improve clinical\ndecision-making by providing more accurate and reliable classifications. To the\nbest of our knowledge, this is the first work to employ tunable wavelets for\nclassifying different types of ERM removal surgery."}
{"id": "2507.00856", "pdf": "https://arxiv.org/pdf/2507.00856", "abs": "https://arxiv.org/abs/2507.00856", "authors": ["Beining Wu", "Jun Huang", "Qiang Duan", "Liang Dong", "Zhipeng Cai"], "title": "Enhancing Vehicular Platooning with Wireless Federated Learning: A Resource-Aware Control Framework", "categories": ["cs.NI", "eess.SP"], "comment": "Under review at IEEE Transactions on Networking", "summary": "This paper aims to enhance the performance of Vehicular Platooning (VP)\nsystems integrated with Wireless Federated Learning (WFL). In highly dynamic\nenvironments, vehicular platoons experience frequent communication changes and\nresource constraints, which significantly affect information exchange and\nlearning model synchronization. To address these challenges, we first formulate\nWFL in VP as a joint optimization problem that simultaneously considers Age of\nInformation (AoI) and Federated Learning Model Drift (FLMD) to ensure timely\nand accurate control. Through theoretical analysis, we examine the impact of\nFLMD on convergence performance and develop a two-stage Resource-Aware Control\nframework (RACE). The first stage employs a Lagrangian dual decomposition\nmethod for resource configuration, while the second stage implements a\nmulti-agent deep reinforcement learning approach for vehicle selection. The\napproach integrates Multi-Head Self-Attention and Long Short-Term Memory\nnetworks to capture spatiotemporal correlations in communication states.\nExperimental results demonstrate that, compared to baseline methods, the\nproposed framework improves AoI optimization by up to 45%, accelerates learning\nconvergence, and adapts more effectively to dynamic VP environments on the\nAI4MARS dataset."}
{"id": "2507.00902", "pdf": "https://arxiv.org/pdf/2507.00902", "abs": "https://arxiv.org/abs/2507.00902", "authors": ["Feng Wang", "Shengyu Zhang", "Een-Kee Hong", "Tony Q. S. Quek"], "title": "Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks", "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "comment": "To appear in IEEE Communications Magazine", "summary": "Direct-satellite-to-device (DS2D) communication is emerging as a promising\nsolution for global mobile service extension, leveraging the deployment of\nsatellite constellations. However, the challenge of managing DS2D connectivity\nfor multi-constellations becomes outstanding, including high interference and\nfrequent handovers caused by multi-coverage overlap and rapid satellite\nmovement. Moreover, existing approaches primarily operate within\nsingle-constellation shell, which inherently limits the ability to exploit the\nvast potential of multi-constellation connectivity provision, resulting in\nsuboptimal DS2D service performances. To address these challenges, this article\nproposes a Constellation as a Service (CaaS) framework, which treats the entire\nmulti-constellation infrastructure as a shared resource pool and dynamically\nforms optimal sub-constellations (SCs) for each DS2D service region. The\nformation of each SC integrates satellites from various orbits to provide\ntailored connectivity based on user demands, guided by two innovative\nstrategies: predictive satellite beamforming using generative artificial\nintelligence (GenAI) and pre-configured handover path for efficient satellite\naccess and mobility management. Simulation results demonstrate that CaaS\nsignificantly improves satellite service rates while reducing handover\noverhead, making it an efficient and continuable solution for managing DS2D\nconnectivity in multi-constellation environments."}
{"id": "2507.00920", "pdf": "https://arxiv.org/pdf/2507.00920", "abs": "https://arxiv.org/abs/2507.00920", "authors": ["Dang Qua Nguyen", "Morteza Hashemi", "Erik Perrins", "Sergiy A. Vorobyov", "David J. Love", "Taejoon Kim"], "title": "Privacy-Preserving Quantized Federated Learning with Diverse Precision", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Federated learning (FL) has emerged as a promising paradigm for distributed\nmachine learning, enabling collaborative training of a global model across\nmultiple local devices without requiring them to share raw data. Despite its\nadvancements, FL is limited by factors such as: (i) privacy risks arising from\nthe unprotected transmission of local model updates to the fusion center (FC)\nand (ii) decreased learning utility caused by heterogeneity in model\nquantization resolution across participating devices. Prior work typically\naddresses only one of these challenges because maintaining learning utility\nunder both privacy risks and quantization heterogeneity is a non-trivial task.\nIn this paper, our aim is therefore to improve the learning utility of a\nprivacy-preserving FL that allows clusters of devices with different\nquantization resolutions to participate in each FL round. Specifically, we\nintroduce a novel stochastic quantizer (SQ) that is designed to simultaneously\nachieve differential privacy (DP) and minimum quantization error. Notably, the\nproposed SQ guarantees bounded distortion, unlike other DP approaches. To\naddress quantization heterogeneity, we introduce a cluster size optimization\ntechnique combined with a linear fusion approach to enhance model aggregation\naccuracy. Numerical simulations validate the benefits of our approach in terms\nof privacy protection and learning utility compared to the conventional\nLaplaceSQ-FL algorithm."}
