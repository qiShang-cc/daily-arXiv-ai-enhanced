{"id": "2512.06099", "pdf": "https://arxiv.org/pdf/2512.06099", "abs": "https://arxiv.org/abs/2512.06099", "authors": ["Khondakar Ashik Shahriar"], "title": "Why Nonlinear Models Matter: Unified Analysis of Cognitive Load, Stress, and Exercise Using Wearable Physiological Signals", "categories": ["eess.SP"], "comment": "28 pages, 8 tables, 13 figures", "summary": "Wearable physiological signals exhibit strong nonlinear and subject-dependent behavior, challenging traditional linear models. This study provides a unified evaluation of cognitive load, stress, and physical exercise recognition using three public Empatica~E4 datasets. Across all conditions, nonlinear machine learning models consistently outperformed linear baselines, achieving 0.89--0.98 accuracy and 0.96--0.99 ROC--AUC, while linear models remained below 0.70--0.73 AUC. Although Leave-One-Subject-Out validation revealed substantial inter-individual variability, nonlinear models maintained moderate cross-person generalization. Ablation and statistical analyses confirmed the necessity of multimodal fusion, particularly EDA, temperature, and ACC, while SHAP interpretability validated these findings by uncovering physiologically meaningful feature contributions across tasks. Overall, the results demonstrate that physiological state recognition is fundamentally nonlinear and establish a unified benchmark to guide the development of more robust wearable health-monitoring systems."}
{"id": "2512.06234", "pdf": "https://arxiv.org/pdf/2512.06234", "abs": "https://arxiv.org/abs/2512.06234", "authors": ["Canan Cebeci", "Oveys Delafrooz Noroozi", "Upamanyu Madhow"], "title": "Beamspace Dimensionality Reduction for Massive MU-MIMO: Geometric Insights and Information-Theoretic Limits", "categories": ["eess.SP", "cs.IT"], "comment": "13 pages", "summary": "Beamspace dimensionality reduction, a classical tool in array processing, has been shown in recent work to significantly reduce computational complexity and training overhead for adaptive reception in massive multiuser (MU) MIMO. For sparse multipath propagation and uniformly spaced antenna arrays, beamspace transformation, or application of a spatial FFT, concentrates the energy of each user into a small number of spatial frequency bins. Empirical evaluations demonstrate the efficacy of linear Minimum Mean Squared Error (LMMSE) detection performed in parallel using a beamspace window of small, fixed size for each user, even as the number of antennas and users scale up, while being robust to moderate variations in the relative powers of the users. In this paper, we develop a fundamental geometric understanding of this ``unreasonable effectiveness'' in a regime in which zero-forcing solutions do not exist. For simplified channel models, we show that, when we enforce a suitable separation in spatial frequency between users, the interference power falling into a desired user's beamspace window of size $W$ concentrates into a number of dominant eigenmodes smaller than $W$, with the desired user having relatively small projection onto these modes. Thus, linear suppression of dominant interference modes can be accomplished with small noise enhancement. We show that similar observations apply for MIMO-OFDM over wideband multipath channels synthesized from measured 28 GHz data. We propose, and evaluate via information-theoretic benchmarks, per-subcarrier reduced dimension beamspace LMMSE in this setting."}
{"id": "2512.06494", "pdf": "https://arxiv.org/pdf/2512.06494", "abs": "https://arxiv.org/abs/2512.06494", "authors": ["Sandesh Rao Mattu", "Nishant Mehrotra", "Robert Calderbank"], "title": "Non-Equiprobable Signaling for Wireless Channels Subject to Mobility and Delay Spread", "categories": ["eess.SP", "cs.IT"], "comment": "5 pages, 6 figures. Submitted to IEEE Wireless Communications Letters", "summary": "This letter describes how to improve performance of OFDM systems by combining non-equiprobable signaling with low density parity check (LDPC) coding. We partition a standard QAM constellation into annular subconstellations of equal size, and we implement non-equiprobable signaling through a shaping code which selects subconstellations with large average energy less frequently than subconstellations with small average energy. In equiprobable signaling, the LDPC code selects a signal point from the inner subconstellation. In non-equiprobable signaling this inner signal point has a representative in each subconstellation and the shaping code selects the representative for transmission. It is possible to use standard QAM constellations to achieve any desired fractional bit rate with this method of shaping the energy distribution of the transmitted signal. We describe how to combine coding and shaping by integrating shaping into the calculation of log-likelihood ratios (LLRs) necessary for decoding LDPC codes. We present simulation results for non-equiprobable transmission at $1.5$ bits/symbol on a representative Veh-A channel showing gains of $4$ dB at a bit error rate (BER) of $10^{-3}$. As the transmission rate increases, the gains from non-equiprobable signaling diminish, but we show through simulation that they are still significant for $16$-QAM."}
{"id": "2512.06532", "pdf": "https://arxiv.org/pdf/2512.06532", "abs": "https://arxiv.org/abs/2512.06532", "authors": ["Amirmohammad Haddad", "Oveys Delafrooz Noroozi", "Canan Cebeci", "Mark J. W. Rodwell", "Upamanyu Madhow"], "title": "Scaling Wideband Hybrid Beamforming for sub-THz Communication", "categories": ["eess.SP"], "comment": null, "summary": "We investigate the capacity attainable for a multiuser MIMO uplink as we scale both array size and bandwidth for regimes in which all-digital arrays incur excessive hardware complexity and power consumption. We consider a tiled hybrid beamforming architecture in which each tile, or subarray, is a phased array performing analog (or RF) beamforming, followed by DSP on the tile outputs. For parameters compatible with sub-THz fixed access links, we discuss hardware and power consumption considerations for choosing tile size and the number of tiles. Noting that the problem of optimal multiuser MIMO in our wideband regime is open even for the simplest possible channel models, we compare the spectral efficiencies attainable by a number of reasonable strategies for tile-level RF beamforming, assuming flexibility in the digital signal processing (DSP) of the tile outputs. We consider a number of beam broadening approaches for addressing the ``beam squint'' incurred by RF beamforming in our wideband regime, along with strategies for sharing tiles among users. Information-theoretic benchmarks are computed for an idealized MIMO-OFDM system, with linear per-subcarrier multiuser detection compared against an unconstrained complexity receiver."}
{"id": "2512.06002", "pdf": "https://arxiv.org/pdf/2512.06002", "abs": "https://arxiv.org/abs/2512.06002", "authors": ["Evan Conway", "David Porfirio", "David Chan", "Mark Roberts", "Laura M. Hiatt"], "title": "POrTAL: Plan-Orchestrated Tree Assembly for Lookahead", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted to ICRA 26", "summary": "Assigning tasks to robots often involves supplying the robot with an overarching goal, such as through natural language, and then relying on the robot to uncover and execute a plan to achieve that goal. In many settings common to human-robot interaction, however, the world is only partially observable to the robot, requiring that it create plans under uncertainty. Although many probabilistic planning algorithms exist for this purpose, these algorithms can be inefficient if executed with the robot's limited computational resources, or may require more steps than expected to achieve the goal. We thereby created a new, lightweight, probabilistic planning algorithm, Plan-Orchestrated Tree Assembly for Lookahead (POrTAL), that combines the strengths of two baseline planning algorithms, FF-Replan and POMCP. In a series of case studies, we demonstrate POrTAL's ability to quickly arrive at solutions that outperform these baselines in terms of number of steps. We additionally demonstrate how POrTAL performs under varying temporal constraints."}
{"id": "2512.06536", "pdf": "https://arxiv.org/pdf/2512.06536", "abs": "https://arxiv.org/abs/2512.06536", "authors": ["Oveys Delafrooz Noroozi", "Jiyoon Han", "Wei Tang", "Zhengya Zhang", "Upamanyu Madhow"], "title": "Scaling Wideband Massive MIMO Radar via Tiled Beamspace Processing", "categories": ["eess.SP"], "comment": null, "summary": "We present a coordinated tiled architecture for scalable wideband digital beamforming in massive MIMO radar systems. As aperture size increases, conventional full-array MVDR processing becomes prohibitive due to the cubic complexity of covariance estimation and inversion. Building on the principle of energy concentration in beamspace, we introduce a tiled windowed-beamspace MVDR framework that distributes spatial FFT processing across subarrays while performing joint beamforming in a compact global beamspace domain. Each tile applies a 2D spatial DFT followed by an angle-of-arrival dependent beamspace window, producing a reduced-dimensional representation that preserves the dominant spatial structure of the received signal. The windowed outputs from the tiles are concatenated and processed by a centralized MVDR beamformer, enabling coherent full-aperture processing with drastically reduced dimensionality. Our numerical results demonstrate that the proposed architecture achieves detection and interference suppression performance comparable to full-dimensional processing, while substantially lowering computational cost, memory usage, and training requirements. The framework also reveals tradeoffs among tile size, window size, and beamspace resolution that govern overall system scalability."}
{"id": "2512.06017", "pdf": "https://arxiv.org/pdf/2512.06017", "abs": "https://arxiv.org/abs/2512.06017", "authors": ["Laurence Liang"], "title": "Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models", "categories": ["cs.RO", "eess.IV"], "comment": "Accepted at CVIS 2025", "summary": "Pose estimation of a robot arm from visual inputs is a challenging task. However, with the increasing adoption of robot arms for both industrial and residential use cases, reliable joint angle estimation can offer improved safety and performance guarantees, and also be used as a verifier to further train robot policies. This paper introduces using frontier vision-language models (VLMs) as an ``off-the-shelf\" tool to estimate a robot arm's joint angles from a single target image. By evaluating frontier VLMs on both synthetic and real-world image-data pairs, this paper establishes a performance baseline attained by current FLMs. In addition, this paper presents empirical results suggesting that test time scaling or parameter scaling alone does not lead to improved joint angle predictions."}
{"id": "2512.06617", "pdf": "https://arxiv.org/pdf/2512.06617", "abs": "https://arxiv.org/abs/2512.06617", "authors": ["De Bi", "Chengbai Xu", "Lingfeng Chen", "Panhe Hu"], "title": "Teaching large language models to see in radar: aspect-distributed prototypes for few-shot HRRP ATR", "categories": ["eess.SP"], "comment": "PAPER UNDER REVIEW", "summary": "High-resolution range profiles (HRRPs) play a critical role in automatic target recognition (ATR) due to their richinformationregarding target scattering centers (SCs), which encapsulate the geometric and electromagnetic characteristics of thetarget.Under few-shot circumstances, traditional learning-based methods often suffer from overfitting and struggle togeneralizeeffectively. The recently proposed HRRPLLM, which leverages the in-context learning (ICL) capabilities of largelanguagemodels (LLMs) for one-shot HRRP ATR, is limited in few-shot scenarios. This limitation arises because it primarilyutilizesthe distribution of SCs for recognition while neglecting the variance of the samples caused by aspect sensitivity. Thispaperproposes a straightforward yet effective Aspect-Distributed Prototype (ADP) strategy for LLM-based ATRunder few-shotconditions to enhance aspect robustness. Experiments conducted on both simulated and measured aircraft electromagneticdatasets demonstrate that the proposed method significantly outperforms current benchmarks."}
{"id": "2512.06038", "pdf": "https://arxiv.org/pdf/2512.06038", "abs": "https://arxiv.org/abs/2512.06038", "authors": ["Kelsey Fontenot", "Anjali Gorti", "Iva Goel", "Tonio Buonassisi", "Alexander E. Siemenn"], "title": "Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction", "categories": ["cs.RO", "cs.LG"], "comment": "15 pages, 8 figures", "summary": "Self-driving laboratories (SDLs) have accelerated the throughput and automation capabilities for discovering and improving chemistries and materials. Although these SDLs have automated many of the steps required to conduct chemical and materials experiments, a commonly overlooked step in the automation pipeline is the handling and reloading of substrates used to transfer or deposit materials onto for downstream characterization. Here, we develop a closed-loop method of Automated Substrate Handling and Exchange (ASHE) using robotics, dual-actuated dispensers, and deep learning-driven computer vision to detect and correct errors in the manipulation of fragile and transparent substrates for SDLs. Using ASHE, we demonstrate a 98.5% first-time placement accuracy across 130 independent trials of reloading transparent glass substrates into an SDL, where only two substrate misplacements occurred and were successfully detected as errors and automatically corrected. Through the development of more accurate and reliable methods for handling various types of substrates, we move toward an improvement in the automation capabilities of self-driving laboratories, furthering the acceleration of novel chemical and materials discoveries."}
{"id": "2512.06693", "pdf": "https://arxiv.org/pdf/2512.06693", "abs": "https://arxiv.org/abs/2512.06693", "authors": ["Xu Gan", "Xidong Mu", "Yuanwei Liu", "Marco Di Renzo", "Josep Miquel Jornet", "Nuria González Prelcic", "Arman Shojaeifard", "Tie Jun Cui"], "title": "Multi-Functional Programmable Metasurfaces for 6G and Beyond", "categories": ["eess.SP"], "comment": null, "summary": "The sixth-generation and beyond (B6G) networks are envisioned to support advanced applications that demand high-speed communication, high-precision sensing, and high-performance computing. To underpin this multi-functional evolution, energy- and cost-efficient programmable metasurfaces (PMs) have emerged as a promising technology for dynamically manipulating electromagnetic waves. This paper provides a comprehensive survey of representative multi-functional PM paradigms, with a specific focus on achieving \\emph{full-space communication coverage}, \\emph{ubiquitous sensing}, as well as \\emph{intelligent signal processing and computing}. i) For simultaneously transmitting and reflecting surfaces (STARS)-enabled full-space communications, we elaborate on their operational protocols and pivotal applications in supporting efficient communications, physical layer security, unmanned aerial vehicle networks, and wireless power transfer. ii) For PM-underpinned ubiquitous sensing, we formulate the signal models for the PM-assisted architecture and systematically characterize its advantages in near-field and cooperative sensing, while transitioning to the PM-enabled transceiver architecture and demonstrating its superior performance in multi-band operations. iii) For advanced signal processing and computing, we explore the novel paradigm of stacked intelligent metasurfaces (SIMs), investigating their implementation in wave-domain analog processing and over-the-air mathematical computing. Finally, we identify key research challenges and envision future directions for multi-functional PMs towards B6G."}
{"id": "2512.06112", "pdf": "https://arxiv.org/pdf/2512.06112", "abs": "https://arxiv.org/abs/2512.06112", "authors": ["Yifang Xu", "Jiahao Cui", "Feipeng Cai", "Zhihao Zhu", "Hanlin Shang", "Shan Luan", "Mingwang Xu", "Neng Zhang", "Yaoyi Li", "Jia Cai", "Siyu Zhu"], "title": "WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "18 pages, 11 figures", "summary": "We introduce WAM-Flow, a vision-language-action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully parallel, bidirectional denoising, enabling coarse-to-fine refinement with a tunable compute-accuracy trade-off. Specifically, the approach combines a metric-aligned numerical tokenizer that preserves scalar geometry via triplet-margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining parallel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strengthens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autoregressive and diffusion-based VLA baselines, with 1-step inference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results establish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon."}
{"id": "2512.06706", "pdf": "https://arxiv.org/pdf/2512.06706", "abs": "https://arxiv.org/abs/2512.06706", "authors": ["Yuan Xu", "Wenhui Xiong"], "title": "Message Passing Based Demodulation of the Time-Encoded Digital Modulation Signal", "categories": ["eess.SP"], "comment": null, "summary": "This letter proposes a Message Passing (MP) based algorithm for demodulating the time-encoded digital modulation signal. The proposed algorithm processes the spikes generated by the Time-Encoding Machine (TEM) directly on a per-spike basis, which enables \"on-the-fly\" demodulatio with low latency. The computational complexity of our proposed method scales linearly with the number of demodulated symbols, while the computational complexity of the pseudo-inverse-based method scales cubically with the same number of demodulated symbols."}
{"id": "2512.06130", "pdf": "https://arxiv.org/pdf/2512.06130", "abs": "https://arxiv.org/abs/2512.06130", "authors": ["Grant Stagg", "Isaac E. Weintraub", "Cameron K. Peterson"], "title": "Probabilistic Weapon Engagement Zones for a Turn Constrained Pursuer", "categories": ["cs.RO", "eess.SY"], "comment": "Accepted for presentation at AIAA SciTech 2026. 17 pages, 7 figures", "summary": "Curve-straight probabilistic engagement zones (CSPEZ) quantify the spatial regions an evader should avoid to reduce capture risk from a turn-rate-limited pursuer following a curve-straight path with uncertain parameters including position, heading, velocity, range, and maximum turn rate. This paper presents methods for generating evader trajectories that minimize capture risk under such uncertainty. We first derive an analytic solution for the deterministic curve-straight basic engagement zone (CSBEZ), then extend this formulation to a probabilistic framework using four uncertainty-propagation approaches: Monte Carlo sampling, linearization, quadratic approximation, and neural-network regression. We evaluate the accuracy and computational cost of each approximation method and demonstrate how CSPEZ constraints can be integrated into a trajectory-optimization algorithm to produce safe paths that explicitly account for pursuer uncertainty."}
{"id": "2512.06799", "pdf": "https://arxiv.org/pdf/2512.06799", "abs": "https://arxiv.org/abs/2512.06799", "authors": ["Philipp del Hougne"], "title": "Effective Electromagnetic Degrees of Freedom in Backscatter MIMO Systems", "categories": ["eess.SP", "physics.app-ph"], "comment": "10 pages including 4 figures", "summary": "While the definition of the effective electromagnetic degrees of freedom (EEMDOFs) of a static linear multiple-input multiple-output (MIMO) system is well established, the counterpart for a backscatter MIMO (BS-MIMO) system is so far missing. A BS-MIMO system encodes the input information into the loads of backscatter elements. Due to mutual coupling, the mapping from load configuration to observed fields is fundamentally non-linear, which complicates the analysis of BS-EEMDOFs. We introduce a definition of BS-EEMDOFs based on the Jacobian of the observed fields with respect to the load configuration. We derive a closed-form expression from multiport network theory which demonstrates that the number of BS-EEMDOFs is fundamentally a distributed variable, whose distribution depends on the mutual coupling between the backscatter elements and the coherent illumination. The modes associated with BS-EEMDOFs lie in the column space of the end-to-end channel matrix from backscatter array ports to receiver ports, but the number of BS-EEMDOFs is generally different from the number of benchmark EEMDOFs associated with the same array being coherently fed rather than tunably terminated. The dependence on the coherent illumination yields optimized coherent illumination as a control knob for the number of BS-EEMDOFs. We present numerical and experimental results for the evaluation and optimization of the number of BS-EEMDOFs in different radio environments with reconfigurable intelligent surfaces."}
{"id": "2512.06147", "pdf": "https://arxiv.org/pdf/2512.06147", "abs": "https://arxiv.org/abs/2512.06147", "authors": ["Hochul Hwang", "Soowan Yang", "Jahir Sadik Monon", "Nicholas A Giudice", "Sunghoon Ivan Lee", "Joydeep Biswas", "Donghyun Kim"], "title": "GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers", "categories": ["cs.RO", "cs.CV", "cs.HC"], "comment": null, "summary": "While commendable progress has been made in user-centric research on mobile assistive systems for blind and low-vision (BLV) individuals, references that directly inform robot navigation design remain rare. To bridge this gap, we conducted a comprehensive human study involving interviews with 26 guide dog handlers, four white cane users, nine guide dog trainers, and one O\\&M trainer, along with 15+ hours of observing guide dog-assisted walking. After de-identification, we open-sourced the dataset to promote human-centered development and informed decision-making for assistive systems for BLV people. Building on insights from this formative study, we developed GuideNav, a vision-only, teach-and-repeat navigation system. Inspired by how guide dogs are trained and assist their handlers, GuideNav autonomously repeats a path demonstrated by a sighted person using a robot. Specifically, the system constructs a topological representation of the taught route, integrates visual place recognition with temporal filtering, and employs a relative pose estimator to compute navigation actions - all without relying on costly, heavy, power-hungry sensors such as LiDAR. In field tests, GuideNav consistently achieved kilometer-scale route following across five outdoor environments, maintaining reliability despite noticeable scene variations between teach and repeat runs. A user study with 3 guide dog handlers and 1 guide dog trainer further confirmed the system's feasibility, marking (to our knowledge) the first demonstration of a quadruped mobile system retrieving a path in a manner comparable to guide dogs."}
{"id": "2512.06909", "pdf": "https://arxiv.org/pdf/2512.06909", "abs": "https://arxiv.org/abs/2512.06909", "authors": ["Qiankai Shen", "Yuanhao Cui", "Jie Yang", "Xiaojun Jing", "Zhiyong Feng", "Shi Jin"], "title": "Bruxism Recognition via Wireless Signal", "categories": ["eess.SP"], "comment": null, "summary": "Bruxism is an oromandibular movement disorder involving teeth grinding and clenching, which severely impairs sleep quality and dental health. However, its diagnosis remains challenging, as existing methods often cause discomfort or compromise user privacy. To address these limitations, we establish a contactless bruxism recognition system based on millimeter-wave radar. First, we analyzed the potential impact of the movement patterns of teeth grinding on radar echo signals. Based on this analysis, 11 features were extracted. Subsequently, using these features, we performed classification with a Random Forest model on the dataset constructed via millimeter-wave radar. Experimental results demonstrate that the proposed method achieves an accuracy of 96.1% on the test set, with precision, recall, and F1-score all remaining at a relatively high level. This study validates the effectiveness of millimeter-wave radar for SB recognition, providing a non-invasive and privacy-friendly alternative to existing recognition techniques. Future research will focus on enhancing the robustness of the method across diverse populations and environments, as well as striving to mitigate the interference of other facial micro-movements on teeth grinding recognition."}
{"id": "2512.06151", "pdf": "https://arxiv.org/pdf/2512.06151", "abs": "https://arxiv.org/abs/2512.06151", "authors": ["Ratnangshu Das", "Siddhartha Upadhyay", "Pushpak Jagtap"], "title": "Real-Time Spatiotemporal Tubes for Dynamic Unsafe Sets", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This paper presents a real-time control framework for nonlinear pure-feedback systems with unknown dynamics to satisfy reach-avoid-stay tasks within a prescribed time in dynamic environments. To achieve this, we introduce a real-time spatiotemporal tube (STT) framework. An STT is defined as a time-varying ball in the state space whose center and radius adapt online using only real-time sensory input. A closed-form, approximation-free control law is then derived to constrain the system output within the STT, ensuring safety and task satisfaction. We provide formal guarantees for obstacle avoidance and on-time task completion. The effectiveness and scalability of the framework are demonstrated through simulations and hardware experiments on a mobile robot and an aerial vehicle, navigating in cluttered dynamic environments."}
{"id": "2512.07053", "pdf": "https://arxiv.org/pdf/2512.07053", "abs": "https://arxiv.org/abs/2512.07053", "authors": ["Hyunwoo Lee", "Ian P. Roberts", "Jinkyo Jeong", "Daesik Hong"], "title": "Random Access for LEO Satellite Communication Systems via Deep Learning", "categories": ["eess.SP", "eess.SY"], "comment": "12 pages, 8 figures, 4 tables", "summary": "Integrating contention-based random access procedures into low Earth orbit (LEO) satellite communication (SatCom) systems poses new challenges, including long propagation delays, large Doppler shifts, and a large number of simultaneous access attempts. These factors degrade the efficiency and responsiveness of conventional random access schemes, particularly in scenarios such as satellite-based internet of things and direct-to-device services. In this paper, we propose a deep learning-based random access framework designed for LEO SatCom systems. The framework incorporates an early preamble collision classifier that uses multi-antenna correlation features and a lightweight 1D convolutional neural network to estimate the number of collided users at the earliest stage. Based on this estimate, we introduce an opportunistic transmission scheme that balances access probability and resource efficiency to improve success rates and reduce delay. Simulation results under 3GPP-compliant LEO settings confirm that the proposed framework achieves higher access success probability, lower delay, better physical uplink shared channel utilization, and reduced computational complexity compared to existing schemes."}
{"id": "2512.06182", "pdf": "https://arxiv.org/pdf/2512.06182", "abs": "https://arxiv.org/abs/2512.06182", "authors": ["Shuhao Qi", "Qiling Aori", "Luyao Zhang", "Mircea Lazar", "Sofie Haesaert"], "title": "Situation-Aware Interactive MPC Switching for Autonomous Driving", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "To enable autonomous driving in interactive traffic scenarios, various model predictive control (MPC) formulations have been proposed, each employing different interaction models. While higher-fidelity models enable more intelligent behavior, they incur increased computational cost. Since strong interactions are relatively infrequent in traffic, a practical strategy for balancing performance and computational overhead is to invoke an appropriate controller based on situational demands. To achieve this approach, we first conduct a comparative study to assess and hierarchize the interactive capabilities of different MPC formulations. Furthermore, we develop a neural network-based classifier to enable situation-aware switching among controllers with different levels of interactive capability. We demonstrate that this situation-aware switching can both substantially improve overall performance by activating the most advanced interactive MPC in rare but critical situations, and significantly reduce computational load by using a basic MPC in the majority of scenarios."}
{"id": "2512.07054", "pdf": "https://arxiv.org/pdf/2512.07054", "abs": "https://arxiv.org/abs/2512.07054", "authors": ["Yiyan Ma", "Bo Ai", "Jingli Li", "Weijie Yuan", "Boxiang He", "Weiyang Feng", "Zhengyu Zhang", "Qingqing Cheng", "Zhangdui Zhong"], "title": "Integrated Sensing, Communication, Computing, and Control Meets UAV Swarms in 6G", "categories": ["eess.SP"], "comment": null, "summary": "To develop the low-altitude economy, the establishment of the low-altitude wireless network (LAWN) is the first priority. As the number of unmanned aerial vehicles (UAVs) increases, how to support the reliable flying and effective functioning of UAV swarms is challenging. Recently, the integrated sensing, communication, computing, and control (ISCCC) strategy was designed, which could act as effective physical {\\it reflex arc} links in the intelligent LAWN system. Thus, in this article, we outline the challenges and opportunities when ISCCC meets UAV swarm in LAWN in 6G. First, we propose a three-layer ISCCC structure for the UAV swarm, which is categorized according to the UAV swarm's requirements, i.e., flying, self-organizing, and functioning. Second, for different scenarios, we study the basic problem, promising technologies, and challenges to design ISCCC for UAV swarms. Third, through a case study that minimizes the flying trajectory error of the UAV swarm based on the ISCCC principle, we show that ISCCC is promising to simultaneously improve the reliability and efficiency of LAWN via jointly designing four components. Finally, we discuss the promising directions for the ISCCC-based UAV swarm in LAWN."}
{"id": "2512.06192", "pdf": "https://arxiv.org/pdf/2512.06192", "abs": "https://arxiv.org/abs/2512.06192", "authors": ["Takahiro Hattori", "Kento Kawaharazuka", "Temma Suzuki", "Keita Yoneda", "Kei Okada"], "title": "REWW-ARM -- Remote Wire-Driven Mobile Robot: Design, Control, and Experimental Validation", "categories": ["cs.RO"], "comment": "Accepted on Advanced Intelligent Systems", "summary": "Electronic devices are essential for robots but limit their usable environments. To overcome this, methods excluding electronics from the operating environment while retaining advanced electronic control and actuation have been explored. These include the remote hydraulic drive of electronics-free mobile robots, which offer high reachability, and long wire-driven robot arms with motors consolidated at the base, which offer high environmental resistance. To combine the advantages of both, this study proposes a new system, \"Remote Wire Drive.\" As a proof-of-concept, we designed and developed the Remote Wire-Driven robot \"REWW-ARM\", which consists of the following components: 1) a novel power transmission mechanism, the \"Remote Wire Transmission Mechanism\" (RWTM), the key technology of the Remote Wire Drive; 2) an electronics-free distal mobile robot driven by it; and 3) a motor-unit that generates power and provides electronic closed-loop control based on state estimation via the RWTM. In this study, we evaluated the mechanical and control performance of REWW-ARM through several experiments, demonstrating its capability for locomotion, posture control, and object manipulation both on land and underwater. This suggests the potential for applying the Remote Wire-Driven system to various types of robots, thereby expanding their operational range."}
{"id": "2512.07097", "pdf": "https://arxiv.org/pdf/2512.07097", "abs": "https://arxiv.org/abs/2512.07097", "authors": ["David Wang", "Jiale Zhang", "Pei Zhang"], "title": "TagLabel: RFID Based Orientation and Material Sensing for Automated Package Inspection", "categories": ["eess.SP", "cs.SE"], "comment": "10 pages, 17 figures, 5 tables", "summary": "Modern logistics systems face increasing difficulty in identifying counterfeit products, fraudulent returns, and hazardous items concealed within packages, yet current package screening methods remain too slow, expensive, and impractical for widespread use. This paper presents TagLabel, an RFID based system that determines both the orientation and contents of packages using low cost passive UHF tags. By analyzing how materials change RSSI and phase, the system identifies the contents of a package without opening it. Using orientation inferred from phase differences, tag occlusion, and antenna gain patterns, the system selects the tag with the greatest occlusion for accurate material sensing. We evaluate two and three tag configurations, and show that both can deliver high orientation and material sensing performance through the use of machine learning classifiers, even in realistic RF environments. When combined into a unified pipeline, TagLabel achieves more than 80 percent accuracy across all package orientations. Because it requires only standard RFID hardware and offers fast scanning times, this approach provides a practical way to enhance package inspection and improve automation in logistics operations."}
{"id": "2512.06198", "pdf": "https://arxiv.org/pdf/2512.06198", "abs": "https://arxiv.org/abs/2512.06198", "authors": ["Oussama Sifour", "Soulaimane Berkane", "Abdelhamid Tayebi"], "title": "Cascaded Tightly-Coupled Observer Design for Single-Range-Aided Inertial Navigation", "categories": ["cs.RO"], "comment": "8 pages", "summary": "This work introduces a single-range-aided navigation observer that reconstructs the full state of a rigid body using only an Inertial Measurement Unit (IMU), a body-frame vector measurement (e.g., magnetometer), and a distance measurement from a fixed anchor point. The design first formulates an extended linear time-varying (LTV) system to estimate body-frame position, body-frame velocity, and the gravity direction. The recovered gravity direction, combined with the body-frame vector measurement, is then used to reconstruct the full orientation on $\\mathrm{SO}(3)$, resulting in a cascaded observer architecture. Almost Global Asymptotic Stability (AGAS) of the cascaded design is established under a uniform observability condition, ensuring robustness to sensor noise and trajectory variations. Simulation studies on three-dimensional trajectories demonstrate accurate estimation of position, velocity, and orientation, highlighting single-range aiding as a lightweight and effective modality for autonomous navigation."}
{"id": "2512.07167", "pdf": "https://arxiv.org/pdf/2512.07167", "abs": "https://arxiv.org/abs/2512.07167", "authors": ["Samyadip Sarkar", "Arunashish Datta", "Sihun Kim", "Amir Mokhtarpour", "Shweta Katakdhond", "Shovan Maity", "Shreyas Sen"], "title": "Near Field Electric (NFE): Energy-efficient, High-speed Communication at Decimeter-range", "categories": ["eess.SP"], "comment": "10 pages, 14 Figures", "summary": "Near-field technologies enable contactless payments, building access, automotive keyless entry, and supply chain tracking. Existing approaches face fundamental trade-offs: magnetic-based methods (NFC/NFMI) achieve low power but are limited to sub-megabit rates, while millimeter-wave techniques provide gigabits/sec connectivity at higher power consumption and only centimeter-scale ranges. We demonstrate that near-field electric (NFE) communication breaks this trade-off via capacitive coupling enabled by confined electric fields. NFE simultaneously achieves ultra-low power ($<$1 mW per transceiver), high-speed data throughput ($>$3 Mbps), and configurable decimeter-range (5-30 cm) capabilities previously considered mutually exclusive. Systematic measurements across multiple orientations and configurations show NFE can support decimeter communication coverage. The power consumption of 0.4 mW at the transmitter (Tx) and 0.6 mW at the receiver (Rx), when combined is up to $\\sim$24$\\times$ lower than NFC and $\\sim$3$\\times$ lower than NFMI while achieving significantly higher data rates, and a couple of orders of magnitude lower power than mm-wave based technique. Testing with symmetrical electrodes across eight orientations validated consistent performance and robustness for practical deployments. Extended-range experiments achieved stable 2 Mbps throughput at 3.5 meters using conductive media, demonstrating NFE's unique ability to leverage environmental conductors. Optimized device design can facilitate achieving an extended range for Body-assisted NFE up to 1 m. Results establish NFE as foundational for next-generation wireless applications where security, low power, and throughput converge, enabling dense IoT deployments, secure payment systems, and high-speed device-to-device communication previously limited by the power-performance trade-off."}
{"id": "2512.06207", "pdf": "https://arxiv.org/pdf/2512.06207", "abs": "https://arxiv.org/abs/2512.06207", "authors": ["Harshil Suthar", "Dipankar Maity"], "title": "Where to Fly, What to Send: Communication-Aware Aerial Support for Ground Robots", "categories": ["cs.RO"], "comment": "Submitted to conference", "summary": "In this work we consider a multi-robot team operating in an unknown environment where one aerial agent is tasked to map the environment and transmit (a portion of) the mapped environment to a group of ground agents that are trying to reach their goals. The entire operation takes place over a bandwidth-limited communication channel, which motivates the problem of determining what and how much information the assisting agent should transmit and when while simultaneously performing exploration/mapping. The proposed framework enables the assisting aerial agent to decide what information to transmit based on the Value-of-Information (VoI), how much to transmit using a Mixed-Integer Linear Programming (MILP), and how to acquire additional information through an utility score-based environment exploration strategy. We perform a communication-motion trade-off analysis between the total amount of map data communicated by the aerial agent and the navigation cost incurred by the ground agents."}
{"id": "2512.07267", "pdf": "https://arxiv.org/pdf/2512.07267", "abs": "https://arxiv.org/abs/2512.07267", "authors": ["Samuel Rey", "Gonzalo Mateos"], "title": "Non-negative DAG Learning from Time-Series Data", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "This work aims to learn the directed acyclic graph (DAG) that captures the instantaneous dependencies underlying a multivariate time series. The observed data follow a linear structural vector autoregressive model (SVARM) with both instantaneous and time-lagged dependencies, where the instantaneous structure is modeled by a DAG to reflect potential causal relationships. While recent continuous relaxation approaches impose acyclicity through smooth constraint functions involving powers of the adjacency matrix, they lead to non-convex optimization problems that are challenging to solve. In contrast, we assume that the underlying DAG has only non-negative edge weights, and leverage this additional structure to impose acyclicity via a convex constraint. This enables us to cast the problem of non-negative DAG recovery from multivariate time-series data as a convex optimization problem in abstract form, which we solve using the method of multipliers. Crucially, the convex formulation guarantees global optimality of the solution. Finally, we assess the performance of the proposed method on synthetic time-series data, where it outperforms existing alternatives."}
{"id": "2512.06261", "pdf": "https://arxiv.org/pdf/2512.06261", "abs": "https://arxiv.org/abs/2512.06261", "authors": ["Taekyung Kim", "Keyvan Majd", "Hideki Okamoto", "Bardh Hoxha", "Dimitra Panagou", "Georgios Fainekos"], "title": "Safe Model Predictive Diffusion with Shielding", "categories": ["cs.RO"], "comment": "Project page: https://www.taekyung.me/safe-mpd", "summary": "Generating safe, kinodynamically feasible, and optimal trajectories for complex robotic systems is a central challenge in robotics. This paper presents Safe Model Predictive Diffusion (Safe MPD), a training-free diffusion planner that unifies a model-based diffusion framework with a safety shield to generate trajectories that are both kinodynamically feasible and safe by construction. By enforcing feasibility and safety on all samples during the denoising process, our method avoids the common pitfalls of post-processing corrections, such as computational intractability and loss of feasibility. We validate our approach on challenging non-convex planning problems, including kinematic and acceleration-controlled tractor-trailer systems. The results show that it substantially outperforms existing safety strategies in success rate and safety, while achieving sub-second computation times."}
{"id": "2512.07279", "pdf": "https://arxiv.org/pdf/2512.07279", "abs": "https://arxiv.org/abs/2512.07279", "authors": ["Shreyas Jayant Grampurohit", "Satish Mulleti", "Ajit Rajwade"], "title": "Verifiable Deep Quantitative Group Testing", "categories": ["eess.SP", "cs.LG"], "comment": "11 pages, 2 figures, 3 tables", "summary": "We present a neural network-based framework for solving the quantitative group testing (QGT) problem that achieves both high decoding accuracy and structural verifiability. In QGT, the objective is to identify a small subset of defective items among $N$ candidates using only $M \\ll N$ pooled tests, each reporting the number of defectives in the tested subset. We train a multi-layer perceptron to map noisy measurement vectors to binary defect indicators, achieving accurate and robust recovery even under sparse, bounded perturbations. Beyond accuracy, we show that the trained network implicitly learns the underlying pooling structure that links items to tests, allowing this structure to be recovered directly from the network's Jacobian. This indicates that the model does not merely memorize training patterns but internalizes the true combinatorial relationships governing QGT. Our findings reveal that standard feedforward architectures can learn verifiable inverse mappings in structured combinatorial recovery problems."}
{"id": "2512.06423", "pdf": "https://arxiv.org/pdf/2512.06423", "abs": "https://arxiv.org/abs/2512.06423", "authors": ["Leonardo F. Dos Santos", "Elisa G. Vergamini", "Cícero Zanette", "Lucca Maitan", "Thiago Boaventura"], "title": "Leveraging Port-Hamiltonian Theory for Impedance Control Benchmarking", "categories": ["cs.RO", "eess.SY"], "comment": "This is the author's version of the paper accepted for publication in the 2025 International Conference on Advanced Robotics (ICAR). The final version will be available at IEEE Xplore", "summary": "This work proposes PH-based metrics for benchmarking impedance control. A causality-consistent PH model is introduced for mass-spring-damper impedance in Cartesian space. Based on this model, a differentiable, force-torque sensing-independent, n-DoF passivity condition is derived, valid for time-varying references. An impedance fidelity metric is also defined from step-response power in free motion, capturing dynamic decoupling. The proposed metrics are validated in Gazebo simulations with a six-DoF manipulator and a quadruped leg. Results demonstrate the suitability of the PH framework for standardized impedance control benchmarking."}
{"id": "2512.07330", "pdf": "https://arxiv.org/pdf/2512.07330", "abs": "https://arxiv.org/abs/2512.07330", "authors": ["Xuancheng Zhu", "Zhiwen Zhou", "Zhenjun Dong", "Yong Zeng"], "title": "Cost-Effective XL-MIMO Communication with Cylinder Directly-Connected Antenna Array", "categories": ["eess.SP"], "comment": null, "summary": "Extremely large-scale multi-input multi-output (XL-MIMO) is a promising technology for the sixth generation (6G) wireless networks, thanks to its superior spatial resolution and beamforming gains. In order to realize XL-MIMO costeffectively, an innovative ray antenna array (RAA) architecture with directly-connected uniform linear array (ULA) was recently proposed, which achieves flexible beamforming without relying on traditional analog phase shifters or digital beamforming. However, RAA suffers from the signal blockage issue since its ray-configured ULAs are placed in the same plane. To address this issue, this paper proposes a novel antenna array architecture termed cylinder directly-connected antenna array (DCAA), which is achieved via multiple simple uniform circular array (sUCA) with carefully designed orientations in a layered three-dimensional structure. The so-called sUCA partitions the uniform circular array (UCA) into two sub-arrays where each sub-array has all antenna elements directly connected to achieve a desired beam direction corresponding to the sub-array's physical orientation, thus achieving full spatial coverage. Compared with the conventional ULA architecture with hybrid analog/digital beamforming (HBF), the proposed cylinder DCAA can achieve uniform spatial resolution, enhanced communication rate and lower hardware costs. Simulation results are provided to validate the promised gains of cylinder DCAA, demonstrating its great potential for high-frequency systems such as millimeter wave (mmWave) and Terahertz (THz) systems."}
{"id": "2512.06444", "pdf": "https://arxiv.org/pdf/2512.06444", "abs": "https://arxiv.org/abs/2512.06444", "authors": ["Xuehui Ma", "Shiliang Zhang", "Zhiyong Sun"], "title": "Fault Tolerant Control of Mecanum Wheeled Mobile Robots", "categories": ["cs.RO"], "comment": null, "summary": "Mecanum wheeled mobile robots (MWMRs) are highly susceptible to actuator faults that degrade performance and risk mission failure. Current fault tolerant control (FTC) schemes for MWMRs target complete actuator failures like motor stall, ignoring partial faults e.g., in torque degradation. We propose an FTC strategy handling both fault types, where we adopt posterior probability to learn real-time fault parameters. We derive the FTC law by aggregating probability-weighed control laws corresponding to predefined faults. This ensures the robustness and safety of MWMR control despite varying levels of fault occurrence. Simulation results demonstrate the effectiveness of our FTC under diverse scenarios."}
{"id": "2512.07361", "pdf": "https://arxiv.org/pdf/2512.07361", "abs": "https://arxiv.org/abs/2512.07361", "authors": ["Giuseppe Leo", "Paolo Gibertini", "Irem Ilter", "Erika Covi", "Ole Richter", "Elisabetta Chicca"], "title": "An Asynchronous Mixed-Signal Resonate-and-Fire Neuron", "categories": ["eess.SP", "cs.NE"], "comment": null, "summary": "Analog computing at the edge is an emerging strategy to limit data storage and transmission requirements, as well as energy consumption, and its practical implementation is in its initial stages of development. Translating properties of biological neurons into hardware offers a pathway towards low-power, real-time edge processing. Specifically, resonator neurons offer selectivity to specific frequencies as a potential solution for temporal signal processing. Here, we show a fabricated Complementary Metal-Oxide-Semiconductor (CMOS) mixed-signal Resonate-and-Fire (R&F) neuron circuit implementation that emulates the behavior of these neural cells responsible for controlling oscillations within the central nervous system. We integrate the design with asynchronous handshake capabilities, perform comprehensive variability analyses, and characterize its frequency detection functionality. Our results demonstrate the feasibility of large-scale integration within neuromorphic systems, thereby advancing the exploitation of bio-inspired circuits for efficient edge temporal signal processing."}
{"id": "2512.06486", "pdf": "https://arxiv.org/pdf/2512.06486", "abs": "https://arxiv.org/abs/2512.06486", "authors": ["Wanru Gong", "Xinyi Zheng", "Xiaopeng Yang", "Xiaoqing Zhu"], "title": "Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains", "categories": ["cs.RO"], "comment": null, "summary": "Learning is the basis of both biological and artificial systems when it comes to mimicking intelligent behaviors. From the classical PPO (Proximal Policy Optimization), there is a series of deep reinforcement learning algorithms which are widely used in training locomotion policies for quadrupedal robots because of their stability and sample efficiency. However, among all these variants, experiments and simulations often converge prematurely, leading to suboptimal locomotion and reduced task performance. Therefore, in this paper, we introduce Entropy-Controlled Intrinsic Motivation (ECIM), an entropy-based reinforcement learning algorithm in contrast with the PPO series, that can reduce premature convergence by combining intrinsic motivation with adaptive exploration.\n  For experiments, in order to parallel with other baselines, we chose to apply it in Isaac Gym across six terrain categories: upward slopes, downward slopes, uneven rough terrain, ascending stairs, descending stairs, and flat ground as widely used. For comparison, our experiments consistently achieve better performance: task rewards increase by 4--12%, peak body pitch oscillation is reduced by 23--29%, joint acceleration decreases by 20--32%, and joint torque consumption declines by 11--20%. Overall, our model ECIM, by combining entropy control and intrinsic motivation control, achieves better results in stability across different terrains for quadrupedal locomotion, and at the same time reduces energetic cost and makes it a practical choice for complex robotic control tasks."}
{"id": "2512.07411", "pdf": "https://arxiv.org/pdf/2512.07411", "abs": "https://arxiv.org/abs/2512.07411", "authors": ["Zawar Hussain", "Faran Awais Butt", "Ali Hussein Muqaibel", "Saleh Ahmed Alawsh", "Ijaz Haider Naqvi"], "title": "Impact of RIS Orientation on Throughput in UAV-Assisted Wireless Systems", "categories": ["eess.SP"], "comment": null, "summary": "This paper investigates the impact of Reconfigurable Intelligent Surface (RIS) orientation on the throughput performance of Unmanned Aerial Vehicle (UAV)-assisted wireless communication systems. Specifically, we study how physical rotation of the RIS, through controlled azimuth and elevation adjustments, influences the effective channel and data rate. A UAV-mounted RIS enables directional alignment to serve ground users in scenarios where the direct Base Station (BS)-to-user path is blocked. Using the SimRIS channel simulator, we analyze the system under various rotation angles and present performance heatmaps that highlight optimal RIS orientations. The study shows that RIS alignment has a substantial effect on achievable rates, thereby motivating orientation-aware optimization in practical deployments."}
{"id": "2512.06517", "pdf": "https://arxiv.org/pdf/2512.06517", "abs": "https://arxiv.org/abs/2512.06517", "authors": ["Shifa Sulaiman", "Akash Bachhar", "Ming Shen", "Simon Bøgh"], "title": "Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments", "categories": ["cs.RO"], "comment": null, "summary": "Recent advancements in prosthetic technology have increasingly focused on enhancing dexterity and autonomy through intelligent control systems. Vision-based approaches offer promising results for enabling prosthetic hands to interact more naturally with diverse objects in dynamic environments. Building on this foundation, the paper presents a vision-guided grasping algorithm for a prosthetic hand, integrating perception, planning, and control for dexterous manipulation. A camera mounted on the set up captures the scene, and a Bounding Volume Hierarchy (BVH)-based vision algorithm is employed to segment an object for grasping and define its bounding box. Grasp contact points are then computed by generating candidate trajectories using Rapidly-exploring Random Tree Star algorithm, and selecting fingertip end poses based on the minimum Euclidean distance between these trajectories and the objects point cloud. Each finger grasp pose is determined independently, enabling adaptive, object-specific configurations. Damped Least Square (DLS) based Inverse kinematics solver is used to compute the corresponding joint angles, which are subsequently transmitted to the finger actuators for execution. This modular pipeline enables per-finger grasp planning and supports real-time adaptability in unstructured environments. The proposed method is validated in simulation, and experimental integration on a Linker Hand O7 platform."}
{"id": "2512.07512", "pdf": "https://arxiv.org/pdf/2512.07512", "abs": "https://arxiv.org/abs/2512.07512", "authors": ["Zawar Hussain", "Arslan Majal", "Aamir Hussain Chughtai", "Talha Nadeem"], "title": "Dictionary-Based Contrastive Learning for GNSS Jamming Detection", "categories": ["eess.SP"], "comment": null, "summary": "Global Navigation Satellite System (GNSS) signals are fundamental in applications across navigation, transportation, and industrial networks. However, their extremely low received power makes them highly vulnerable to radio-frequency interference (RFI) and intentional jamming. Modern data-driven methods offer powerful representational power for such applications, however real-time and reliable jamming detection on resource-limited embedded receivers remains a key challenge due to the high computational and memory demands of the conventional learning paradigm. To address these challenges, this work presents a dictionary-based contrastive learning (DBCL) framework for GNSS jamming detection that integrates transfer learning, contrastive representation learning, and model compression techniques. The framework combines tuned contrastive and dictionary-based loss functions to enhance feature separability under low-data conditions and applies structured pruning and knowledge distillation to reduce model complexity while maintaining high accuracy. Extensive evaluation across varying data regimes demonstrate that the proposed algorithm consistently outperforms modern CNN, MobileViT, and ResNet-18 architectures. The framework achieves a substantial reduction in memory footprint and inference latency, confirming its suitability for real-time, low-power GNSS interference detection on embedded platforms."}
{"id": "2512.06524", "pdf": "https://arxiv.org/pdf/2512.06524", "abs": "https://arxiv.org/abs/2512.06524", "authors": ["Saekwang Nam", "Bowen Deng", "Loong Yi Lee", "Jonathan M. Rossiter", "Nathan F. Lepora"], "title": "TacFinRay: Soft Tactile Fin-Ray Finger with Indirect Tactile Sensing for Robust Grasping", "categories": ["cs.RO"], "comment": "Accepted in IEEE Robotics Automation Letters. S. Nam, B. Deng co-first authors", "summary": "We present a tactile-sensorized Fin-Ray finger that enables simultaneous detection of contact location and indentation depth through an indirect sensing approach. A hinge mechanism is integrated between the soft Fin-Ray structure and a rigid sensing module, allowing deformation and translation information to be transferred to a bottom crossbeam upon which are an array of marker-tipped pins based on the biomimetic structure of the TacTip vision-based tactile sensor. Deformation patterns captured by an internal camera are processed using a convolutional neural network to infer contact conditions without directly sensing the finger surface. The finger design was optimized by varying pin configurations and hinge orientations, achieving 0.1\\,mm depth and 2mm location-sensing accuracies. The perception demonstrated robust generalization to various indenter shapes and sizes, which was applied to a pick-and-place task under uncertain picking positions, where the tactile feedback significantly improved placement accuracy. Overall, this work provides a lightweight, flexible, and scalable tactile sensing solution suitable for soft robotic structures where the sensing needs situating away from the contact interface."}
{"id": "2512.07649", "pdf": "https://arxiv.org/pdf/2512.07649", "abs": "https://arxiv.org/abs/2512.07649", "authors": ["Hao Jiang", "Chongjun Ouyang", "Zhaolin Wang", "Yuanwei Liu", "Arumugam Nallanathan", "Zhiguo Ding", "Robert Schober"], "title": "Segmented Waveguide-Enabled Pinching-Antenna Systems (SWANs) for ISAC", "categories": ["eess.SP"], "comment": "submitted to IEEE journal for possible publication", "summary": "A segmented waveguide-enabled pinching-antenna system (SWAN)-assisted integrated sensing and communications (ISAC) framework is proposed. Unlike conventional pinching antenna systems (PASS), which use a single long waveguide, SWAN divides the waveguide into multiple short segments, each with a dedicated feed point. Thanks to the segmented structure, SWAN enhances sensing performance by significantly simplifying the reception model and reducing the in-waveguide propagation loss. To balance performance and complexity, three segment controlling protocols are proposed for the transceivers, namely i) \\emph{segment selection} to select a single segment for signal transceiving, ii) \\emph{segment aggregation} to aggregate signals from all segments using a single RF chain, and iii) \\emph{segment multiplexing} to jointly process the signals from all segments using individual RF chains. The theoretical sensing performance limit is first analyzed for different protocols, unveiling how the sensing performance gain of SWAN scales with the number of segments. Based on this performance limit, the Pareto fronts of sensing and communication performance are characterized for the simple one-user one-target case, which is then extended to the general multi-user single-target case based on time-division multiple access (TDMA). Numerical results are presented to verify the correctness of the derivations and the effectiveness of the proposed algorithms, which jointly confirm the advantages of SWAN-assisted ISAC."}
{"id": "2512.06558", "pdf": "https://arxiv.org/pdf/2512.06558", "abs": "https://arxiv.org/abs/2512.06558", "authors": ["Md Mofijul Islam", "Alexi Gladstone", "Sujan Sarker", "Ganesh Nanduru", "Md Fahim", "Keyan Du", "Aman Chadha", "Tariq Iqbal"], "title": "Embodied Referring Expression Comprehension in Human-Robot Interaction", "categories": ["cs.RO"], "comment": "14 pages, 7 figures, accepted at the ACM/IEEE International Conference on Human-Robot Interaction (HRI) 2026", "summary": "As robots enter human workspaces, there is a crucial need for them to comprehend embodied human instructions, enabling intuitive and fluent human-robot interaction (HRI). However, accurate comprehension is challenging due to a lack of large-scale datasets that capture natural embodied interactions in diverse HRI settings. Existing datasets suffer from perspective bias, single-view collection, inadequate coverage of nonverbal gestures, and a predominant focus on indoor environments. To address these issues, we present the Refer360 dataset, a large-scale dataset of embodied verbal and nonverbal interactions collected across diverse viewpoints in both indoor and outdoor settings. Additionally, we introduce MuRes, a multimodal guided residual module designed to improve embodied referring expression comprehension. MuRes acts as an information bottleneck, extracting salient modality-specific signals and reinforcing them into pre-trained representations to form complementary features for downstream tasks. We conduct extensive experiments on four HRI datasets, including the Refer360 dataset, and demonstrate that current multimodal models fail to capture embodied interactions comprehensively; however, augmenting them with MuRes consistently improves performance. These findings establish Refer360 as a valuable benchmark and exhibit the potential of guided residual learning to advance embodied referring expression comprehension in robots operating within human environments."}
{"id": "2512.06457", "pdf": "https://arxiv.org/pdf/2512.06457", "abs": "https://arxiv.org/abs/2512.06457", "authors": ["Huizheng Wang", "Hongbin Wang", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the heavy memory traffic it entails. To address these limitations, this paper proposes BitStopper, a fine-grained algorithm-architecture co-design that operates without a sparsity predictor. First, a bit-serial enable stage fusion (BESF) mechanism is proposed to reuse and minimize the memory access by progressively terminating trivial tokens and merging the prediction stage into the execution stage. Second, a lightweight and adaptive token selection (LATS) strategy is developed to work in concert with the bit-level sparsity speculation. Third, a bit-level asynchronous processing (BAP) strategy is employed to improve compute utilization during the on-demand bit-grained memory fetching. Finally, an elaborate architecture is designed to translate the theoretical complexity reduction into practical performance improvement. Extensive evaluations demonstrate that, compared to state-of-the-art (SOTA) Transformer accelerators, BitStopper achieves 2.03x and 1.89x speedups over Sanger and SOFA, respectively, while delivering 2.4x and 2.1x improvements in energy efficiency."}
{"id": "2512.06571", "pdf": "https://arxiv.org/pdf/2512.06571", "abs": "https://arxiv.org/abs/2512.06571", "authors": ["Zifan Xu", "Myoungkyu Seo", "Dongmyeong Lee", "Hao Fu", "Jiaheng Hu", "Jiaxun Cui", "Yuqian Jiang", "Zhihan Wang", "Anastasiia Brund", "Joydeep Biswas", "Peter Stone"], "title": "Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input", "categories": ["cs.RO"], "comment": null, "summary": "Learning fast and robust ball-kicking skills is a critical capability for humanoid soccer robots, yet it remains a challenging problem due to the need for rapid leg swings, postural stability on a single support foot, and robustness under noisy sensory input and external perturbations (e.g., opponents). This paper presents a reinforcement learning (RL)-based system that enables humanoid robots to execute robust continual ball-kicking with adaptability to different ball-goal configurations. The system extends a typical teacher-student training framework -- in which a \"teacher\" policy is trained with ground truth state information and the \"student\" learns to mimic it with noisy, imperfect sensing -- by including four training stages: (1) long-distance ball chasing (teacher); (2) directional kicking (teacher); (3) teacher policy distillation (student); and (4) student adaptation and refinement (student). Key design elements -- including tailored reward functions, realistic noise modeling, and online constrained RL for adaptation and refinement -- are critical for closing the sim-to-real gap and sustaining performance under perceptual uncertainty. Extensive evaluations in both simulation and on a real robot demonstrate strong kicking accuracy and goal-scoring success across diverse ball-goal configurations. Ablation studies further highlight the necessity of the constrained RL, noise modeling, and the adaptation stage. This work presents a system for learning robust continual humanoid ball-kicking under imperfect perception, establishing a benchmark task for visuomotor skill learning in humanoid whole-body control."}
{"id": "2512.06725", "pdf": "https://arxiv.org/pdf/2512.06725", "abs": "https://arxiv.org/abs/2512.06725", "authors": ["Tian Lan"], "title": "Decoding Motor Behavior Using Deep Learning and Reservoir Computing", "categories": ["cs.LG", "eess.SP"], "comment": "10 pages, 3 figures", "summary": "We present a novel approach to EEG decoding for non-invasive brain machine interfaces (BMIs), with a focus on motor-behavior classification. While conventional convolutional architectures such as EEGNet and DeepConvNet are effective in capturing local spatial patterns, they are markedly less suited for modeling long-range temporal dependencies and nonlinear dynamics. To address this limitation, we integrate an Echo State Network (ESN), a prominent paradigm in reservoir computing into the decoding pipeline. ESNs construct a high-dimensional, sparsely connected recurrent reservoir that excels at tracking temporal dynamics, thereby complementing the spatial representational power of CNNs. Evaluated on a skateboard-trick EEG dataset preprocessed via the PREP pipeline and implemented in MNE-Python, our ESNNet achieves 83.2% within-subject and 51.3% LOSO accuracies, surpassing widely used CNN-based baselines. Code is available at https://github.com/Yutiankunkun/Motion-Decoding-Using-Biosignals"}
{"id": "2512.06578", "pdf": "https://arxiv.org/pdf/2512.06578", "abs": "https://arxiv.org/abs/2512.06578", "authors": ["Waleed Razzaq"], "title": "Error-Centric PID Untrained Neural-Net (EC-PIDUNN) For Nonlinear Robotics Control", "categories": ["cs.RO"], "comment": "Under review at SoftComputing", "summary": "Classical Proportional-Integral-Derivative (PID) control has been widely successful across various industrial systems such as chemical processes, robotics, and power systems. However, as these systems evolved, the increase in the nonlinear dynamics and the complexity of interconnected variables have posed challenges that classical PID cannot effectively handle, often leading to instability, overshooting, or prolonged settling times. Researchers have proposed PIDNN models that combine the function approximation capabilities of neural networks with PID control to tackle these nonlinear challenges. However, these models require extensive, highly refined training data and have significant computational costs, making them less favorable for real-world applications. In this paper, We propose a novel EC-PIDUNN architecture, which integrates an untrained neural network with an improved PID controller, incorporating a stabilizing factor (\\(τ\\)) to generate the control signal. Like classical PID, our architecture uses the steady-state error \\(e_t\\) as input bypassing the need for explicit knowledge of the systems dynamics. By forming an input vector from \\(e_t\\) within the neural network, we increase the dimensionality of input allowing for richer data representation. Additionally, we introduce a vector of parameters \\( ρ_t \\) to shape the output trajectory and a \\textit{dynamic compute} function to adjust the PID coefficients from predefined values. We validate the effectiveness of EC-PIDUNN on multiple nonlinear robotics applications: (1) nonlinear unmanned ground vehicle systems that represent the Ackermann steering mechanism and kinematics control, (2) Pan-Tilt movement system. In both tests, it outperforms classical PID in convergence and stability achieving a nearly critically damped response."}
{"id": "2512.06960", "pdf": "https://arxiv.org/pdf/2512.06960", "abs": "https://arxiv.org/abs/2512.06960", "authors": ["Jitendra K Tugnait"], "title": "Learning Conditional Independence Differential Graphs From Time-Dependent Data", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": "20 pages, 4 figures, 2 tables. To be published in IEEE Access, 2025", "summary": "Estimation of differences in conditional independence graphs (CIGs) of two time series Gaussian graphical models (TSGGMs) is investigated where the two TSGGMs are known to have similar structure. The TSGGM structure is encoded in the inverse power spectral density (IPSD) of the time series. In several existing works, one is interested in estimating the difference in two precision matrices to characterize underlying changes in conditional dependencies of two sets of data consisting of independent and identically distributed (i.i.d.) observations. In this paper we consider estimation of the difference in two IPSDs to characterize the underlying changes in conditional dependencies of two sets of time-dependent data. Our approach accounts for data time dependencies unlike past work. We analyze a penalized D-trace loss function approach in the frequency domain for differential graph learning, using Wirtinger calculus. We consider both convex (group lasso) and non-convex (log-sum and SCAD group penalties) penalty/regularization functions. An alternating direction method of multipliers (ADMM) algorithm is presented to optimize the objective function. We establish sufficient conditions in a high-dimensional setting for consistency (convergence of the inverse power spectral density to true value in the Frobenius norm) and graph recovery. Both synthetic and real data examples are presented in support of the proposed approaches. In synthetic data examples, our log-sum-penalized differential time-series graph estimator significantly outperformed our lasso based differential time-series graph estimator which, in turn, significantly outperformed an existing lasso-penalized i.i.d. modeling approach, with $F_1$ score as the performance metric."}
{"id": "2512.06608", "pdf": "https://arxiv.org/pdf/2512.06608", "abs": "https://arxiv.org/abs/2512.06608", "authors": ["Xinyu Zhou", "Songhao Piao", "Chao Gao", "Liguo Chen"], "title": "A New Trajectory-Oriented Approach to Enhancing Comprehensive Crowd Navigation Performance", "categories": ["cs.RO"], "comment": "8 pages, 6 figures", "summary": "Crowd navigation has garnered considerable research interest in recent years, especially with the proliferating application of deep reinforcement learning (DRL) techniques. Many studies, however, do not sufficiently analyze the relative priorities among evaluation metrics, which compromises the fair assessment of methods with divergent objectives. Furthermore, trajectory-continuity metrics, specifically those requiring $C^2$ smoothness, are rarely incorporated. Current DRL approaches generally prioritize efficiency and proximal comfort, often neglecting trajectory optimization or addressing it only through simplistic, unvalidated smoothness reward. Nevertheless, effective trajectory optimization is essential to ensure naturalness, enhance comfort, and maximize the energy efficiency of any navigation system. To address these gaps, this paper proposes a unified framework that enables the fair and transparent assessment of navigation methods by examining the prioritization and joint evaluation of multiple optimization objectives. We further propose a novel reward-shaping strategy that explicitly emphasizes trajectory-curvature optimization. The resulting trajectory quality and adaptability are significantly enhanced across multi-scale scenarios. Through extensive 2D and 3D experiments, we demonstrate that the proposed method achieves superior performance compared to state-of-the-art approaches."}
{"id": "2512.07405", "pdf": "https://arxiv.org/pdf/2512.07405", "abs": "https://arxiv.org/abs/2512.07405", "authors": ["Amnon Balanov", "Tamir Bendory", "Dan Edidin"], "title": "Orbit recovery under the rigid motions group", "categories": ["cs.IT", "eess.SP"], "comment": null, "summary": "We study the orbit recovery problem under the rigid-motion group SE(n), where the objective is to reconstruct an unknown signal from multiple noisy observations subjected to unknown rotations and translations. This problem is fundamental in signal processing, computer vision, and structural biology.\n  Our main theoretical contribution is bounding the sample complexity of this problem. We show that if the d-th order moment under the rotation group SO(n) uniquely determines the signal orbit, then orbit recovery under SE(n) is achievable with $N\\gtrsim σ^{2d+4}$ samples as the noise variance $σ^2 \\to \\infty$. The key technical insight is that the d-th order SO(n) moments can be explicitly recovered from (d+2)-order SE(n) autocorrelations, enabling us to transfer known results from the rotation-only setting to the rigid-motion case. We further harness this result to derive a matching bound to the sample complexity of the multi-target detection model that serves as an abstract framework for electron-microscopy-based technologies in structural biology, such as single-particle cryo-electron microscopy (cryo-EM) and cryo-electron tomography (cryo-ET).\n  Beyond theory, we present a provable computational pipeline for rigid-motion orbit recovery in three dimensions. Starting from rigid-motion autocorrelations, we extract the SO(3) moments and demonstrate successful reconstruction of a 3-D macromolecular structure. Importantly, this algorithmic approach is valid at any noise level, suggesting that even very small macromolecules, long believed to be inaccessible using structural biology electron-microscopy-based technologies, may, in principle, be reconstructed given sufficient data."}
{"id": "2512.06610", "pdf": "https://arxiv.org/pdf/2512.06610", "abs": "https://arxiv.org/abs/2512.06610", "authors": ["Marvin Harms", "Jaeyoung Lim", "David Rohr", "Friedrich Rockenbauer", "Nicholas Lawrance", "Roland Siegwart"], "title": "Robust Optimization-based Autonomous Dynamic Soaring with a Fixed-Wing UAV", "categories": ["cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Dynamic soaring is a flying technique to exploit the energy available in wind shear layers, enabling potentially unlimited flight without the need for internal energy sources. We propose a framework for autonomous dynamic soaring with a fixed-wing unmanned aerial vehicle (UAV). The framework makes use of an explicit representation of the wind field and a classical approach for guidance and control of the UAV. Robustness to wind field estimation error is achieved by constructing point-wise robust reference paths for dynamic soaring and the development of a robust path following controller for the fixed-wing UAV. The framework is evaluated in dynamic soaring scenarios in simulation and real flight tests. In simulation, we demonstrate robust dynamic soaring flight subject to varied wind conditions, estimation errors and disturbances. Critical components of the framework, including energy predictions and path-following robustness, are further validated in real flights to assure small sim-to-real gap. Together, our results strongly indicate the ability of the proposed framework to achieve autonomous dynamic soaring flight in wind shear."}
{"id": "2512.07557", "pdf": "https://arxiv.org/pdf/2512.07557", "abs": "https://arxiv.org/abs/2512.07557", "authors": ["Jitendra K. Tugnait"], "title": "On Conditional Independence Graph Learning From Multi-Attribute Gaussian Dependent Time Series", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": "16 pages, 3 figures, 4 tables", "summary": "Estimation of the conditional independence graph (CIG) of high-dimensional multivariate Gaussian time series from multi-attribute data is considered. Existing methods for graph estimation for such data are based on single-attribute models where one associates a scalar time series with each node. In multi-attribute graphical models, each node represents a random vector or vector time series. In this paper we provide a unified theoretical analysis of multi-attribute graph learning for dependent time series using a penalized log-likelihood objective function formulated in the frequency domain using the discrete Fourier transform of the time-domain data. We consider both convex (sparse-group lasso) and non-convex (log-sum and SCAD group penalties) penalty/regularization functions. We establish sufficient conditions in a high-dimensional setting for consistency (convergence of the inverse power spectral density to true value in the Frobenius norm), local convexity when using non-convex penalties, and graph recovery. We do not impose any incoherence or irrepresentability condition for our convergence results. We also empirically investigate selection of the tuning parameters based on the Bayesian information criterion, and illustrate our approach using numerical examples utilizing both synthetic and real data."}
{"id": "2512.06628", "pdf": "https://arxiv.org/pdf/2512.06628", "abs": "https://arxiv.org/abs/2512.06628", "authors": ["Ruicheng Zhang", "Mingyang Zhang", "Jun Zhou", "Zhangrui Guo", "Xiaofan Liu", "Zunnan Xu", "Zhizhou Zhong", "Puxin Yan", "Haocheng Luo", "Xiu Li"], "title": "MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Embodied imitation learning is constrained by the scarcity of diverse, long-horizon robotic manipulation data. Existing video generation models for this domain are limited to synthesizing short clips of simple actions and often rely on manually defined trajectories. To this end, we introduce MIND-V, a hierarchical framework designed to synthesize physically plausible and logically coherent videos of long-horizon robotic manipulation. Inspired by cognitive science, MIND-V bridges high-level reasoning with pixel-level synthesis through three core components: a Semantic Reasoning Hub (SRH) that leverages a pre-trained vision-language model for task planning; a Behavioral Semantic Bridge (BSB) that translates abstract instructions into domain-invariant representations; and a Motor Video Generator (MVG) for conditional video rendering. MIND-V employs Staged Visual Future Rollouts, a test-time optimization strategy to enhance long-horizon robustness. To align the generated videos with physical laws, we introduce a GRPO reinforcement learning post-training phase guided by a novel Physical Foresight Coherence (PFC) reward. PFC leverages the V-JEPA world model to enforce physical plausibility by aligning the predicted and actual dynamic evolutions in the feature space. MIND-V demonstrates state-of-the-art performance in long-horizon robotic manipulation video generation, establishing a scalable and controllable paradigm for embodied data synthesis."}
{"id": "2512.06664", "pdf": "https://arxiv.org/pdf/2512.06664", "abs": "https://arxiv.org/abs/2512.06664", "authors": ["Wei-Bin Kou", "Guangxu Zhu", "Jingreng Lei", "Chen Zhang", "Yik-Chung Wu", "Jianping Wang"], "title": "Statistic-Augmented, Decoupled MoE Routing and Aggregating in Autonomous Driving", "categories": ["cs.RO"], "comment": "9 pages", "summary": "Autonomous driving (AD) scenarios are inherently complex and diverse, posing significant challenges for a single deep learning model to effectively cover all possible conditions, such as varying weather, traffic densities, and road types. Large Model (LM)-Driven Mixture of Experts (MoE) paradigm offers a promising solution, where LM serves as the backbone to extract latent features while MoE serves as the downstream head to dynamically select and aggregate specialized experts to adapt to different scenarios. However, routing and aggregating in MoE face intrinsic challenges, including imprecise expert selection due to flawed routing strategy and inefficient expert aggregation leading to suboptimal prediction. To address these issues, we propose a statistic-augmented, decoupled MoE }outing and Aggregating Mechanism (MoE-RAM) driven by LM. Specifically, on the one hand, MoE-RAM enhances expert routing by incorporating statistical retrieval mechanism to match LM-extracted latent features with cached prototypical features of the most relevant experts; on the other hand, MoE-RAM adaptively reweights experts' outputs in fusion by measuring statistical distances of experts' instant features against LM-extracted latent features. Benefiting from the synergy of the statistic-augmented MoE's routing and aggregating, MoE-RAM ultimately improves the prediction performance. We take the AD semantic segmentation task as an example to assess the proposed MoE-RAM. Extensive experiments on AD datasets demonstrate the superiority of MoE-RAM compared to other MoE baselines and conventional single-model approaches."}
{"id": "2512.06676", "pdf": "https://arxiv.org/pdf/2512.06676", "abs": "https://arxiv.org/abs/2512.06676", "authors": ["Wei-Bin Kou", "Guangxu Zhu", "Bingyang Cheng", "Chen Zhang", "Yik-Chung Wu", "Jianping Wang"], "title": "FedDSR: Federated Deep Supervision and Regularization Towards Autonomous Driving", "categories": ["cs.RO", "cs.LG"], "comment": "9 pages", "summary": "Federated Learning (FL) enables collaborative training of autonomous driving (AD) models across distributed vehicles while preserving data privacy. However, FL encounters critical challenges such as poor generalization and slow convergence due to non-independent and identically distributed (non-IID) data from diverse driving environments. To overcome these obstacles, we introduce Federated Deep Supervision and Regularization (FedDSR), a paradigm that incorporates multi-access intermediate layer supervision and regularization within federated AD system. Specifically, FedDSR comprises following integral strategies: (I) to select multiple intermediate layers based on predefined architecture-agnostic standards. (II) to compute mutual information (MI) and negative entropy (NE) on those selected layers to serve as intermediate loss and regularizer. These terms are integrated into the output-layer loss to form a unified optimization objective, enabling comprehensive optimization across the network hierarchy. (III) to aggregate models from vehicles trained based on aforementioned rules of (I) and (II) to generate the global model on central server. By guiding and penalizing the learning of feature representations at intermediate stages, FedDSR enhances the model generalization and accelerates model convergence for federated AD. We then take the semantic segmentation task as an example to assess FedDSR and apply FedDSR to multiple model architectures and FL algorithms. Extensive experiments demonstrate that FedDSR achieves up to 8.93% improvement in mIoU and 28.57% reduction in training rounds, compared to other FL baselines, making it highly suitable for practical deployment in federated AD ecosystems."}
{"id": "2512.06754", "pdf": "https://arxiv.org/pdf/2512.06754", "abs": "https://arxiv.org/abs/2512.06754", "authors": ["Shrreya Rajneesh", "Nikita Pavle", "Rakesh Kumar Sahoo", "Manoranjan Sinha"], "title": "Model-Less Feedback Control of Space-based Continuum Manipulators using Backbone Tension Optimization", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Continuum manipulators offer intrinsic dexterity and safe geometric compliance for navigation within confined and obstacle-rich environments. However, their infinite-dimensional backbone deformation, unmodeled internal friction, and configuration-dependent stiffness fundamentally limit the reliability of model-based kinematic formulations, resulting in inaccurate Jacobian predictions, artificial singularities, and unstable actuation behavior. Motivated by these limitations, this work presents a complete model-less control framework that bypasses kinematic modeling by using an empirically initialized Jacobian refined online through differential convex updates. Tip motion is generated via a real-time quadratic program that computes actuator increments while enforcing tendon slack avoidance and geometric limits. A backbone tension optimization term is introduced in this paper to regulate axial loading and suppress co-activation compression. The framework is validated across circular, pentagonal, and square trajectories, demonstrating smooth convergence, stable tension evolution, and sub-millimeter steady-state accuracy without any model calibration or parameter identification. These results establish the proposed controller as a scalable alternative to model-dependent continuum manipulation in a constrained environment."}
{"id": "2512.06796", "pdf": "https://arxiv.org/pdf/2512.06796", "abs": "https://arxiv.org/abs/2512.06796", "authors": ["Akmaral Moldagalieva", "Keisuke Okumura", "Amanda Prorok", "Wolfgang Hönig"], "title": "db-LaCAM: Fast and Scalable Multi-Robot Kinodynamic Motion Planning with Discontinuity-Bounded Search and Lightweight MAPF", "categories": ["cs.RO"], "comment": null, "summary": "State-of-the-art multi-robot kinodynamic motion planners struggle to handle more than a few robots due to high computational burden, which limits their scalability and results in slow planning time.\n  In this work, we combine the scalability and speed of modern multi-agent path finding (MAPF) algorithms with the dynamic-awareness of kinodynamic planners to address these limitations.\n  To this end, we propose discontinuity-Bounded LaCAM (db-LaCAM), a planner that utilizes a precomputed set of motion primitives that respect robot dynamics to generate horizon-length motion sequences, while allowing a user-defined discontinuity between successive motions.\n  The planner db-LaCAM is resolution-complete with respect to motion primitives and supports arbitrary robot dynamics.\n  Extensive experiments demonstrate that db-LaCAM scales efficiently to scenarios with up to 50 robots, achieving up to ten times faster runtime compared to state-of-the-art planners, while maintaining comparable solution quality.\n  The approach is validated in both 2D and 3D environments with dynamics such as the unicycle and 3D double integrator.\n  We demonstrate the safe execution of trajectories planned with db-LaCAM in two distinct physical experiments involving teams of flying robots and car-with-trailer robots."}
{"id": "2512.06829", "pdf": "https://arxiv.org/pdf/2512.06829", "abs": "https://arxiv.org/abs/2512.06829", "authors": ["Oluwatimilehin Tijani", "Zhuo Chen", "Jiankang Deng", "Shan Luo"], "title": "MagicSkin: Balancing Marker and Markerless Modes in Vision-Based Tactile Sensors with a Translucent Skin", "categories": ["cs.RO"], "comment": "Submitted to ICRA2026", "summary": "Vision-based tactile sensors (VBTS) face a fundamental trade-off in marker and markerless design on the tactile skin: opaque ink markers enable measurement of force and tangential displacement but completely occlude geometric features necessary for object and texture classification, while markerless skin preserves surface details but struggles in measuring tangential displacements effectively. Current practice to solve the above problem via UV lighting or virtual transfer using learning-based models introduces hardware complexity or computing burdens. This paper introduces MagicSkin, a novel tactile skin with translucent, tinted markers balancing the modes of marker and markerless for VBTS. It enables simultaneous tangential displacement tracking, force prediction, and surface detail preservation. This skin is easy to plug into GelSight-family sensors without requiring additional hardware or software tools. We comprehensively evaluate MagicSkin in downstream tasks. The translucent markers impressively enhance rather than degrade sensing performance compared with traditional markerless and inked marker design: it achieves best performance in object classification (99.17\\%), texture classification (93.51\\%), tangential displacement tracking (97\\% point retention) and force prediction (66\\% improvement in total force error). These experimental results demonstrate that translucent skin eliminates the traditional performance trade-off in marker or markerless modes, paving the way for multimodal tactile sensing essential in tactile robotics. See videos at this \\href{https://zhuochenn.github.io/MagicSkin_project/}{link}."}
{"id": "2512.06868", "pdf": "https://arxiv.org/pdf/2512.06868", "abs": "https://arxiv.org/abs/2512.06868", "authors": ["Xingguang Zhong", "Liren Jin", "Marija Popović", "Jens Behley", "Cyrill Stachniss"], "title": "Dynamic Visual SLAM using a General 3D Prior", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages", "summary": "Reliable incremental estimation of camera poses and 3D reconstruction is key to enable various applications including robotics, interactive visualization, and augmented reality. However, this task is particularly challenging in dynamic natural environments, where scene dynamics can severely deteriorate camera pose estimation accuracy. In this work, we propose a novel monocular visual SLAM system that can robustly estimate camera poses in dynamic scenes. To this end, we leverage the complementary strengths of geometric patch-based online bundle adjustment and recent feed-forward reconstruction models. Specifically, we propose a feed-forward reconstruction model to precisely filter out dynamic regions, while also utilizing its depth prediction to enhance the robustness of the patch-based visual SLAM. By aligning depth prediction with estimated patches from bundle adjustment, we robustly handle the inherent scale ambiguities of the batch-wise application of the feed-forward reconstruction model."}
{"id": "2512.06892", "pdf": "https://arxiv.org/pdf/2512.06892", "abs": "https://arxiv.org/abs/2512.06892", "authors": ["Hassan Jardali", "Durgakant Pushp", "Youwei Yu", "Mahmoud Ali", "Ihab S. Mohamed", "Alejandro Murillo-Gonzalez", "Paul D. Coen", "Md. Al-Masrur Khan", "Reddy Charan Pulivendula", "Saeoul Park", "Lingchuan Zhou", "Lantao Liu"], "title": "From Zero to High-Speed Racing: An Autonomous Racing Stack", "categories": ["cs.RO"], "comment": null, "summary": "High-speed, head-to-head autonomous racing presents substantial technical and logistical challenges, including precise localization, rapid perception, dynamic planning, and real-time control-compounded by limited track access and costly hardware. This paper introduces the Autonomous Race Stack (ARS), developed by the IU Luddy Autonomous Racing team for the Indy Autonomous Challenge (IAC). We present three iterations of our ARS, each validated on different tracks and achieving speeds up to 260 km/h. Our contributions include: (i) the modular architecture and evolution of the ARS across ARS1, ARS2, and ARS3; (ii) a detailed performance evaluation that contrasts control, perception, and estimation across oval and road-course environments; and (iii) the release of a high-speed, multi-sensor dataset collected from oval and road-course tracks. Our findings highlight the unique challenges and insights from real-world high-speed full-scale autonomous racing."}
{"id": "2512.06896", "pdf": "https://arxiv.org/pdf/2512.06896", "abs": "https://arxiv.org/abs/2512.06896", "authors": ["Chrysostomos Karakasis", "Camryn Scully", "Robert Salati", "Panagiotis Artemiadis"], "title": "Control of Powered Ankle-Foot Prostheses on Compliant Terrain: A Quantitative Approach to Stability Enhancement", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Walking on compliant terrain presents a substantial challenge for individuals with lower-limb amputation, further elevating their already high risk of falling. While powered ankle-foot prostheses have demonstrated adaptability across speeds and rigid terrains, control strategies optimized for soft or compliant surfaces remain underexplored. This work experimentally validates an admittance-based control strategy that dynamically adjusts the quasi-stiffness of powered prostheses to enhance gait stability on compliant ground. Human subject experiments were conducted with three healthy individuals walking on two bilaterally compliant surfaces with ground stiffness values of 63 and 25 kN/m, representative of real-world soft environments. Controller performance was quantified using phase portraits and two walking stability metrics, offering a direct assessment of fall risk. Compared to a standard phase-variable controller developed for rigid terrain, the proposed admittance controller consistently improved gait stability across all compliant conditions. These results demonstrate the potential of adaptive, stability-aware prosthesis control to reduce fall risk in real-world environments and advance the robustness of human-prosthesis interaction in rehabilitation robotics."}
{"id": "2512.06897", "pdf": "https://arxiv.org/pdf/2512.06897", "abs": "https://arxiv.org/abs/2512.06897", "authors": ["Bradley Hobbs", "Panagiotis Artemiadis"], "title": "Ground Compliance Improves Retention of Visual Feedback-Based Propulsion Training for Gait Rehabilitation", "categories": ["cs.RO"], "comment": null, "summary": "This study investigates whether adding ground compliance to visual feedback (VF) gait training is more effective at increasing push-off force (POF) compared to using VF alone, with implications for gait rehabilitation. Ten healthy participants walked on a custom split-belt treadmill. All participants received real-time visual feedback of their ground reaction forces. One group also experienced changes in ground compliance, while a control group received only visual feedback. Intentional increases in propulsive ground reaction forces (POF) were successfully achieved and sustained post-intervention, especially in the group that experienced ground compliance. This group also demonstrated lasting after-effects in muscle activity and joint kinematics, indicating a more robust learning of natural strategies to increase propulsion. This work demonstrates how visual and proprioceptive systems coordinate during gait adaptation. It uniquely shows that combining ground compliance with visual feedback enhances the learning of propulsive forces, supporting the potential use of compliant terrain in long-term rehabilitation targeting propulsion deficits, such as those following a stroke."}
{"id": "2512.06912", "pdf": "https://arxiv.org/pdf/2512.06912", "abs": "https://arxiv.org/abs/2512.06912", "authors": ["Rushiraj Gadhvi", "Sandeep Manjanna"], "title": "Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields", "categories": ["cs.RO", "cs.LG"], "comment": "Under Review for International Conference on Robotics and Automation (ICRA 2026)", "summary": "For centuries, khalasi have skillfully harnessed ocean currents to navigate vast waters with minimal effort. Emulating this intuition in autonomous systems remains a significant challenge, particularly for Autonomous Surface Vehicles tasked with long duration missions under strict energy budgets. In this work, we present a learning-based approach for energy-efficient surface vehicle navigation in vortical flow fields, where partial observability often undermines traditional path-planning methods. We present an end to end reinforcement learning framework based on Soft Actor Critic that learns flow-aware navigation policies using only local velocity measurements. Through extensive evaluation across diverse and dynamically rich scenarios, our method demonstrates substantial energy savings and robust generalization to previously unseen flow conditions, offering a promising path toward long term autonomy in ocean environments. The navigation paths generated by our proposed approach show an improvement in energy conservation 30 to 50 percent compared to the existing state of the art techniques."}
{"id": "2512.06935", "pdf": "https://arxiv.org/pdf/2512.06935", "abs": "https://arxiv.org/abs/2512.06935", "authors": ["Nicolò Botteghi", "Owen Brook", "Urban Fasel", "Federico Califano"], "title": "Interconnection and Damping Assignment Passivity-Based Control using Sparse Neural ODEs", "categories": ["cs.RO"], "comment": null, "summary": "Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) is a nonlinear control technique that assigns a port-Hamiltonian (pH) structure to a controlled system using a state-feedback law. While IDA-PBC has been extensively studied and applied to many systems, its practical implementation often remains confined to academic examples and, almost exclusively, to stabilization tasks. The main limitation of IDA-PBC stems from the complexity of analytically solving a set of partial differential equations (PDEs), referred to as the matching conditions, which enforce the pH structure of the closed-loop system. However, this is extremely challenging, especially for complex physical systems and tasks.\n  In this work, we propose a novel numerical approach for designing IDA-PBC controllers without solving the matching PDEs exactly. We cast the IDA-PBC problem as the learning of a neural ordinary differential equation. In particular, we rely on sparse dictionary learning to parametrize the desired closed-loop system as a sparse linear combination of nonlinear state-dependent functions. Optimization of the controller parameters is achieved by solving a multi-objective optimization problem whose cost function is composed of a generic task-dependent cost and a matching condition-dependent cost. Our numerical results show that the proposed method enables (i) IDA-PBC to be applicable to complex tasks beyond stabilization, such as the discovery of periodic oscillatory behaviors, (ii) the derivation of closed-form expressions of the controlled system, including residual terms"}
{"id": "2512.06951", "pdf": "https://arxiv.org/pdf/2512.06951", "abs": "https://arxiv.org/abs/2512.06951", "authors": ["Ilia Larchenko", "Gleb Zarin", "Akash Karnatak"], "title": "Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "2025 NeurIPS Behavior Challenge 1st place solution", "summary": "We present a vision-action policy that won 1st place in the 2025 BEHAVIOR Challenge - a large-scale benchmark featuring 50 diverse long-horizon household tasks in photo-realistic simulation, requiring bimanual manipulation, navigation, and context-aware decision making.\n  Building on the Pi0.5 architecture, we introduce several innovations. Our primary contribution is correlated noise for flow matching, which improves training efficiency and enables correlation-aware inpainting for smooth action sequences. We also apply learnable mixed-layer attention and System 2 stage tracking for ambiguity resolution. Training employs multi-sample flow matching to reduce variance, while inference uses action compression and challenge-specific correction rules.\n  Our approach achieves 26% q-score across all 50 tasks on both public and private leaderboards."}
{"id": "2512.06963", "pdf": "https://arxiv.org/pdf/2512.06963", "abs": "https://arxiv.org/abs/2512.06963", "authors": ["Yichao Shen", "Fangyun Wei", "Zhiying Du", "Yaobo Liang", "Yan Lu", "Jiaolong Yang", "Nanning Zheng", "Baining Guo"], "title": "VideoVLA: Video Generators Can Be Generalizable Robot Manipulators", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Project page: https://videovla-nips2025.github.io", "summary": "Generalization in robot manipulation is essential for deploying robots in open-world environments and advancing toward artificial general intelligence. While recent Vision-Language-Action (VLA) models leverage large pre-trained understanding models for perception and instruction following, their ability to generalize to novel tasks, objects, and settings remains limited. In this work, we present VideoVLA, a simple approach that explores the potential of transforming large video generation models into robotic VLA manipulators. Given a language instruction and an image, VideoVLA predicts an action sequence as well as the future visual outcomes. Built on a multi-modal Diffusion Transformer, VideoVLA jointly models video, language, and action modalities, using pre-trained video generative models for joint visual and action forecasting. Our experiments show that high-quality imagined futures correlate with reliable action predictions and task success, highlighting the importance of visual imagination in manipulation. VideoVLA demonstrates strong generalization, including imitating other embodiments' skills and handling novel objects. This dual-prediction strategy - forecasting both actions and their visual consequences - explores a paradigm shift in robot learning and unlocks generalization capabilities in manipulation systems."}
{"id": "2512.06995", "pdf": "https://arxiv.org/pdf/2512.06995", "abs": "https://arxiv.org/abs/2512.06995", "authors": ["Maryam Seraj", "Mohammad Hossein Kamrava", "Carlo Tiseo"], "title": "Parametric Design of a Cable-Driven Coaxial Spherical Parallel Mechanism for Ultrasound Scans", "categories": ["cs.RO", "physics.class-ph"], "comment": null, "summary": "Haptic interfaces play a critical role in medical teleoperation by enabling surgeons to interact with remote environments through realistic force and motion feedback. Achieving high fidelity in such systems requires balancing performance trade-off among workspace, dexterity, stiffness, inertia, and bandwidth, particularly in applications demanding pure rotational motion. This paper presents the design methodology and kinematic analysis of a Cable-Driven Coaxial Spherical Parallel Mechanism (CDC-SPM) developed to address these challenges. The proposed cable-driven interface design allows for reducing the mass placed at the robot arm end-effector, thereby minimizing inertial loads, enhancing stiffness, and improving dynamic responsiveness. Through parallel and coaxial actuation, the mechanism achieves decoupled rotational degrees of freedom with isotropic force and torque transmission. Simulation and analysis demonstrate that the CDC-SPM provides accurate, responsive, and safe motion characteristics suitable for high-precision haptic applications. These results highlight the mechanism's potential for medical teleoperation tasks such as ultrasound imaging, where precise and intuitive manipulation is essential."}
{"id": "2512.07032", "pdf": "https://arxiv.org/pdf/2512.07032", "abs": "https://arxiv.org/abs/2512.07032", "authors": ["Runcong Wang", "Fengyi Wang", "Gordon Cheng"], "title": "A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a hetero-associative sequential memory system for mobile manipulators that learns compact, neuromorphic bindings between robot joint states and tactile observations to produce step-wise action decisions with low compute and memory cost. The method encodes joint angles via population place coding and converts skin-measured forces into spike-rate features using an Izhikevich neuron model; both signals are transformed into bipolar binary vectors and bound element-wise to create associations stored in a large-capacity sequential memory. To improve separability in binary space and inject geometry from touch, we introduce 3D rotary positional embeddings that rotate subspaces as a function of sensed force direction, enabling fuzzy retrieval through a softmax weighted recall over temporally shifted action patterns. On a Toyota Human Support Robot covered by robot skin, the hetero-associative sequential memory system realizes a pseudocompliance controller that moves the link under touch in the direction and with speed correlating to the amplitude of applied force, and it retrieves multi-joint grasp sequences by continuing tactile input. The system sets up quickly, trains from synchronized streams of states and observations, and exhibits a degree of generalization while remaining economical. Results demonstrate single-joint and full-arm behaviors executed via associative recall, and suggest extensions to imitation learning, motion planning, and multi-modal integration."}
{"id": "2512.07041", "pdf": "https://arxiv.org/pdf/2512.07041", "abs": "https://arxiv.org/abs/2512.07041", "authors": ["Hiroki Sawada", "Alexandre Pitti", "Mathias Quoy"], "title": "CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation", "categories": ["cs.RO"], "comment": null, "summary": "Robots interacting with humans must not only generate learned movements in real-time, but also infer the intent behind observed behaviors and estimate the confidence of their own inferences. This paper proposes a unified model that achieves all three capabilities within a single hierarchical predictive-coding recurrent neural network (PC-RNN) equipped with a class embedding vector, CERNet, which leverages a dynamically updated class embedding vector to unify motor generation and recognition. The model operates in two modes: generation and inference. In the generation mode, the class embedding constrains the hidden state dynamics to a class-specific subspace; in the inference mode, it is optimized online to minimize prediction error, enabling real-time recognition. Validated on a humanoid robot across 26 kinesthetically taught alphabets, our hierarchical model achieves 76% lower trajectory reproduction error than a parameter-matched single-layer baseline, maintains motion fidelity under external perturbations, and infers the demonstrated trajectory class online with 68% Top-1 and 81% Top-2 accuracy. Furthermore, internal prediction errors naturally reflect the model's confidence in its recognition. This integration of robust generation, real-time recognition, and intrinsic uncertainty estimation within a compact PC-RNN framework offers a compact and extensible approach to motor memory in physical robots, with potential applications in intent-sensitive human-robot collaboration."}
{"id": "2512.07091", "pdf": "https://arxiv.org/pdf/2512.07091", "abs": "https://arxiv.org/abs/2512.07091", "authors": ["Tomoya Takahashi", "Yusaku Nakajima", "Cristian Camilo Beltran-Hernandez", "Yuki Kuroda", "Kazutoshi Tanaka", "Masashi Hamaya", "Kanta Ono", "Yoshitaka Ushiku"], "title": "A Flexible Funnel-Shaped Robotic Hand with an Integrated Single-Sheet Valve for Milligram-Scale Powder Handling", "categories": ["cs.RO"], "comment": "9 pages, 8 figures", "summary": "Laboratory Automation (LA) has the potential to accelerate solid-state materials discovery by enabling continuous robotic operation without human intervention. While robotic systems have been developed for tasks such as powder grinding and X-ray diffraction (XRD) analysis, fully automating powder handling at the milligram scale remains a significant challenge due to the complex flow dynamics of powders and the diversity of laboratory tasks. To address this challenge, this study proposes a novel, funnel-shaped, flexible robotic hand that preserves the softness and conical sheet designs in prior work while incorporating a controllable valve at the cone apex to enable precise, incremental dispensing of milligram-scale powder quantities. The hand is integrated with an external balance through a feedback control system based on a model of powder flow and online parameter identification. Experimental evaluations with glass beads, monosodium glutamate, and titanium dioxide demonstrated that 80% of the trials achieved an error within 2 mg, and the maximum error observed was approximately 20 mg across a target range of 20 mg to 3 g. In addition, by incorporating flow prediction models commonly used for hoppers and performing online parameter identification, the system is able to adapt to variations in powder dynamics. Compared to direct PID control, the proposed model-based control significantly improved both accuracy and convergence speed. These results highlight the potential of the proposed system to enable efficient and flexible powder weighing, with scalability toward larger quantities and applicability to a broad range of laboratory automation tasks."}
{"id": "2512.07114", "pdf": "https://arxiv.org/pdf/2512.07114", "abs": "https://arxiv.org/abs/2512.07114", "authors": ["Jue Wang", "Mingsong Jiang", "Luis A. Ramirez", "Bilige Yang", "Mujun Zhang", "Esteban Figueroa", "Wenzhong Yan", "Rebecca Kramer-Bottiglio"], "title": "Surrogate compliance modeling enables reinforcement learned locomotion gaits for soft robots", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Adaptive morphogenetic robots adapt their morphology and control policies to meet changing tasks and environmental conditions. Many such systems leverage soft components, which enable shape morphing but also introduce simulation and control challenges. Soft-body simulators remain limited in accuracy and computational tractability, while rigid-body simulators cannot capture soft-material dynamics. Here, we present a surrogate compliance modeling approach: rather than explicitly modeling soft-body physics, we introduce indirect variables representing soft-material deformation within a rigid-body simulator. We validate this approach using our amphibious robotic turtle, a quadruped with soft morphing limbs designed for multi-environment locomotion. By capturing deformation effects as changes in effective limb length and limb center of mass, and by applying reinforcement learning with extensive randomization of these indirect variables, we achieve reliable policy learning entirely in a rigid-body simulation. The resulting gaits transfer directly to hardware, demonstrating high-fidelity sim-to-real performance on hard, flat substrates and robust, though lower-fidelity, transfer on rheologically complex terrains. The learned closed-loop gaits exhibit unprecedented terrestrial maneuverability and achieve an order-of-magnitude reduction in cost of transport compared to open-loop baselines. Field experiments with the robot further demonstrate stable, multi-gait locomotion across diverse natural terrains, including gravel, grass, and mud."}
{"id": "2512.07130", "pdf": "https://arxiv.org/pdf/2512.07130", "abs": "https://arxiv.org/abs/2512.07130", "authors": ["Zebin Xing", "Yupeng Zheng", "Qichao Zhang", "Zhixing Ding", "Pengxuan Yang", "Songen Gu", "Zhongpu Xia", "Dongbin Zhao"], "title": "Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "End-to-end autonomous driving has emerged as a pivotal direction in the field of autonomous systems. Recent works have demonstrated impressive performance by incorporating high-level guidance signals to steer low-level trajectory planners. However, their potential is often constrained by inaccurate high-level guidance and the computational overhead of complex guidance modules. To address these limitations, we propose Mimir, a novel hierarchical dual-system framework capable of generating robust trajectories relying on goal points with uncertainty estimation: (1) Unlike previous approaches that deterministically model, we estimate goal point uncertainty with a Laplace distribution to enhance robustness; (2) To overcome the slow inference speed of the guidance system, we introduce a multi-rate guidance mechanism that predicts extended goal points in advance. Validated on challenging Navhard and Navtest benchmarks, Mimir surpasses previous state-of-the-art methods with a 20% improvement in the driving score EPDMS, while achieving 1.6 times improvement in high-level module inference speed without compromising accuracy. The code and models will be released soon to promote reproducibility and further development. The code is available at https://github.com/ZebinX/Mimir-Uncertainty-Driving"}
{"id": "2512.07137", "pdf": "https://arxiv.org/pdf/2512.07137", "abs": "https://arxiv.org/abs/2512.07137", "authors": ["Kang Yijie", "Hao Yuqing", "Wang Qingyun", "Chen Guanrong"], "title": "Time-Varying Formation Tracking Control of Wheeled Mobile Robots With Region Constraint: A Generalized Udwadia-Kalaba Framework", "categories": ["cs.RO", "cs.MA"], "comment": "10 pages,9 figures", "summary": "In this paper, the time-varying formation tracking control of wheeled mobile robots with region constraint is investigated from a generalized Udwadia-Kalaba framework. The communication topology is directed, weighted and has a spanning tree with the leader being the root. By reformulating the time-varying formation tracking control objective as a constrained equation and transforming the region constraint by a diffeomorphism, the time-varying formation tracking controller with the region constraint is designed under the generalized Udwadia-Kalaba framework. Compared with the existing works on time-varying formation tracking control, the region constraint is takeninto account in this paper, which ensures the safety of the robots.Finally, some numerical simulations are presented to illustrate the effectiveness of the proposed control strategy."}
{"id": "2512.07177", "pdf": "https://arxiv.org/pdf/2512.07177", "abs": "https://arxiv.org/abs/2512.07177", "authors": ["Fanjun Bu", "Melina Tsai", "Audrey Tjokro", "Tapomayukh Bhattacharjee", "Jorge Ortiz", "Wendy Ju"], "title": "Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction", "categories": ["cs.RO"], "comment": null, "summary": "Robots operating in everyday environments must often decide when and whether to engage with people, yet such decisions often hinge on subtle nonverbal cues that unfold over time and are difficult to model explicitly. Drawing on a five-day Wizard-of-Oz deployment of a mobile service robot in a university cafe, we analyze how people signal interaction readiness through nonverbal behaviors and how expert wizards use these cues to guide engagement. Motivated by these observations, we propose a two-stage pipeline in which lightweight perceptual detectors (gaze shifts and proxemics) are used to selectively trigger heavier video-based vision-language model (VLM) queries at socially meaningful moments. We evaluate this pipeline on replayed field interactions and compare two prompting strategies. Our findings suggest that selectively using VLMs as proxies for social reasoning enables socially responsive robot behavior, allowing robots to act appropriately by attending to the cues people naturally provide in real-world interactions."}
{"id": "2512.07221", "pdf": "https://arxiv.org/pdf/2512.07221", "abs": "https://arxiv.org/abs/2512.07221", "authors": ["Zichao Shu", "Shitao Bei", "Lijun Li", "Zetao Chen"], "title": "Spatiotemporal Calibration and Ground Truth Estimation for High-Precision SLAM Benchmarking in Extended Reality", "categories": ["cs.RO"], "comment": null, "summary": "Simultaneous localization and mapping (SLAM) plays a fundamental role in extended reality (XR) applications. As the standards for immersion in XR continue to increase, the demands for SLAM benchmarking have become more stringent. Trajectory accuracy is the key metric, and marker-based optical motion capture (MoCap) systems are widely used to generate ground truth (GT) because of their drift-free and relatively accurate measurements. However, the precision of MoCap-based GT is limited by two factors: the spatiotemporal calibration with the device under test (DUT) and the inherent jitter in the MoCap measurements. These limitations hinder accurate SLAM benchmarking, particularly for key metrics like rotation error and inter-frame jitter, which are critical for immersive XR experiences. This paper presents a novel continuous-time maximum likelihood estimator to address these challenges. The proposed method integrates auxiliary inertial measurement unit (IMU) data to compensate for MoCap jitter. Additionally, a variable time synchronization method and a pose residual based on screw congruence constraints are proposed, enabling precise spatiotemporal calibration across multiple sensors and the DUT. Experimental results demonstrate that our approach outperforms existing methods, achieving the precision necessary for comprehensive benchmarking of state-of-the-art SLAM algorithms in XR applications. Furthermore, we thoroughly validate the practicality of our method by benchmarking several leading XR devices and open-source SLAM algorithms. The code is publicly available at https://github.com/ylab-xrpg/xr-hpgt."}
{"id": "2512.07266", "pdf": "https://arxiv.org/pdf/2512.07266", "abs": "https://arxiv.org/abs/2512.07266", "authors": ["Florian Tretter", "Daniel Flögel", "Alexandru Vasilache", "Max Grobbel", "Jürgen Becker", "Sören Hohmann"], "title": "SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": "8 pages, 6 figures", "summary": "Integrating autonomous mobile robots into human environments requires human-like decision-making and energy-efficient, event-based computation. Despite progress, neuromorphic methods are rarely applied to Deep Reinforcement Learning (DRL) navigation approaches due to unstable training. We address this gap with a hybrid socially integrated DRL actor-critic approach that combines Spiking Neural Networks (SNNs) in the actor with Artificial Neural Networks (ANNs) in the critic and a neuromorphic feature extractor to capture temporal crowd dynamics and human-robot interactions. Our approach enhances social navigation performance and reduces estimated energy consumption by approximately 1.69 orders of magnitude."}
{"id": "2512.07303", "pdf": "https://arxiv.org/pdf/2512.07303", "abs": "https://arxiv.org/abs/2512.07303", "authors": ["Gianpietro Battocletti", "Dimitris Boskos", "Bart De Schutter"], "title": "Efficient Computation of a Continuous Topological Model of the Configuration Space of Tethered Mobile Robots", "categories": ["cs.RO"], "comment": "7 pages, 3 figures, submitted to IFAC World Congress 2026", "summary": "Despite the attention that the problem of path planning for tethered robots has garnered in the past few decades, the approaches proposed to solve it typically rely on a discrete representation of the configuration space and do not exploit a model that can simultaneously capture the topological information of the tether and the continuous location of the robot. In this work, we explicitly build a topological model of the configuration space of a tethered robot starting from a polygonal representation of the workspace where the robot moves. To do so, we first establish a link between the configuration space of the tethered robot and the universal covering space of the workspace, and then we exploit this link to develop an algorithm to compute a simplicial complex model of the configuration space. We show how this approach improves the performances of existing algorithms that build other types of representations of the configuration space. The proposed model can be computed in a fraction of the time required to build traditional homotopy-augmented graphs, and is continuous, allowing to solve the path planning task for tethered robots using a broad set of path planning algorithms."}
{"id": "2512.07316", "pdf": "https://arxiv.org/pdf/2512.07316", "abs": "https://arxiv.org/abs/2512.07316", "authors": ["Gianpietro Battocletti", "Dimitris Boskos", "Bart De Schutter"], "title": "Model Predictive Control for Cooperative Docking Between Autonomous Surface Vehicles with Disturbance Rejection", "categories": ["cs.RO", "eess.SY"], "comment": "7 pages, 4 figures, submitted to IFAC World Congress 2026", "summary": "Uncrewed Surface Vehicles (USVs) are a popular and efficient type of marine craft that find application in a large number of water-based tasks. When multiple USVs operate in the same area, they may be required to dock to each other to perform a shared task. Existing approaches for the docking between autonomous USVs generally consider one USV as a stationary target, while the second one is tasked to reach the required docking pose. In this work, we propose a cooperative approach for USV-USV docking, where two USVs work together to dock at an agreed location. We use a centralized Model Predictive Control (MPC) approach to solve the control problem, obtaining feasible trajectories that also guarantee constraint satisfaction. Owing to its model-based nature, this approach allows the rejection of disturbances, inclusive of exogenous inputs, by anticipating their effect on the USVs through the MPC prediction model. This is particularly effective in case of almost-stationary disturbances such as water currents. In simulations, we demonstrate how the proposed approach allows for a faster and more efficient docking with respect to existing approaches."}
{"id": "2512.07359", "pdf": "https://arxiv.org/pdf/2512.07359", "abs": "https://arxiv.org/abs/2512.07359", "authors": ["Bin Zhao", "Yiwen Lu", "Haohua Zhu", "Xiao Li", "Sheng Yi"], "title": "Multi-Rigid-Body Approximation of Human Hands with Application to Digital Twin", "categories": ["cs.RO", "cs.GR"], "comment": "10 pages, 4 figures. Accepted at ICBSR'25 (International Conference on Biomechanical Systems and Robotics)", "summary": "Human hand simulation plays a critical role in digital twin applications, requiring models that balance anatomical fidelity with computational efficiency. We present a complete pipeline for constructing multi-rigid-body approximations of human hands that preserve realistic appearance while enabling real-time physics simulation. Starting from optical motion capture of a specific human hand, we construct a personalized MANO (Multi-Abstracted hand model with Neural Operations) model and convert it to a URDF (Unified Robot Description Format) representation with anatomically consistent joint axes. The key technical challenge is projecting MANO's unconstrained SO(3) joint rotations onto the kinematically constrained joints of the rigid-body model. We derive closed-form solutions for single degree-of-freedom joints and introduce a Baker-Campbell-Hausdorff (BCH)-corrected iterative method for two degree-of-freedom joints that properly handles the non-commutativity of rotations. We validate our approach through digital twin experiments where reinforcement learning policies control the multi-rigid-body hand to replay captured human demonstrations. Quantitative evaluation shows sub-centimeter reconstruction error and successful grasp execution across diverse manipulation tasks."}
{"id": "2512.07371", "pdf": "https://arxiv.org/pdf/2512.07371", "abs": "https://arxiv.org/abs/2512.07371", "authors": ["Byungju Kim", "Jinu Pahk", "Chungwoo Lee", "Jaejoon Kim", "Jangha Lee", "Theo Taeyeong Kim", "Kyuhwan Shim", "Jun Ki Lee", "Byoung-Tak Zhang"], "title": "ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning", "categories": ["cs.RO", "cs.AI"], "comment": "project page: https://project-espada.github.io/espada/", "summary": "Behavior-cloning based visuomotor policies enable precise manipulation but often inherit the slow, cautious tempo of human demonstrations, limiting practical deployment. However, prior studies on acceleration methods mainly rely on statistical or heuristic cues that ignore task semantics and can fail across diverse manipulation settings. We present ESPADA, a semantic and spatially aware framework that segments demonstrations using a VLM-LLM pipeline with 3D gripper-object relations, enabling aggressive downsampling only in non-critical segments while preserving precision-critical phases, without requiring extra data or architectural modifications, or any form of retraining. To scale from a single annotated episode to the full dataset, ESPADA propagates segment labels via Dynamic Time Warping (DTW) on dynamics-only features. Across both simulation and real-world experiments with ACT and DP baselines, ESPADA achieves approximately a 2x speed-up while maintaining success rates, narrowing the gap between human demonstrations and efficient robot control."}
{"id": "2512.07464", "pdf": "https://arxiv.org/pdf/2512.07464", "abs": "https://arxiv.org/abs/2512.07464", "authors": ["Haolin Song", "Hongbo Zhu", "Tao Yu", "Yan Liu", "Mingqi Yuan", "Wengang Zhou", "Hua Chen", "Houqiang Li"], "title": "Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction", "categories": ["cs.RO"], "comment": null, "summary": "For full-size humanoid robots, even with recent advances in reinforcement learning-based control, achieving reliable locomotion on complex terrains, such as long staircases, remains challenging. In such settings, limited perception, ambiguous terrain cues, and insufficient adaptation of gait timing can cause even a single misplaced or mistimed step to result in rapid loss of balance. We introduce a perceptive locomotion framework that merges terrain sensing, gait regulation, and whole-body control into a single reinforcement learning policy. A downward-facing depth camera mounted under the base observes the support region around the feet, and a compact U-Net reconstructs a dense egocentric height map from each frame in real time, operating at the same frequency as the control loop. The perceptual height map, together with proprioceptive observations, is processed by a unified policy that produces joint commands and a global stepping-phase signal, allowing gait timing and whole-body posture to be adapted jointly to the commanded motion and local terrain geometry. We further adopt a single-stage successive teacher-student training scheme for efficient policy learning and knowledge transfer. Experiments conducted on a 31-DoF, 1.65 m humanoid robot demonstrate robust locomotion in both simulation and real-world settings, including forward and backward stair ascent and descent, as well as crossing a 46 cm gap. Project Page:https://ga-phl.github.io/"}
{"id": "2512.07472", "pdf": "https://arxiv.org/pdf/2512.07472", "abs": "https://arxiv.org/abs/2512.07472", "authors": ["Siyu Xu", "Zijian Wang", "Yunke Wang", "Chenghao Xia", "Tao Huang", "Chang Xu"], "title": "Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models have shown great performance in robotic manipulation by mapping visual observations and language instructions directly to actions. However, they remain brittle under distribution shifts: when test scenarios change, VLAs often reproduce memorized trajectories instead of adapting to the updated scene, which is a failure mode we refer to as the \"Memory Trap\". This limitation stems from the end-to-end design, which lacks explicit 3D spatial reasoning and prevents reliable identification of actionable regions in unfamiliar environments. To compensate for this missing spatial understanding, 3D Spatial Affordance Fields (SAFs) can provide a geometric representation that highlights where interactions are physically feasible, offering explicit cues about regions the robot should approach or avoid. We therefore introduce Affordance Field Intervention (AFI), a lightweight hybrid framework that uses SAFs as an on-demand plug-in to guide VLA behavior. Our system detects memory traps through proprioception, repositions the robot to recent high-affordance regions, and proposes affordance-driven waypoints that anchor VLA-generated actions. A SAF-based scorer then selects trajectories with the highest cumulative affordance. Extensive experiments demonstrate that our method achieves an average improvement of 23.5% across different VLA backbones ($π_{0}$ and $π_{0.5}$) under out-of-distribution scenarios on real-world robotic platforms, and 20.2% on the LIBERO-Pro benchmark, validating its effectiveness in enhancing VLA robustness to distribution shifts."}
{"id": "2512.07482", "pdf": "https://arxiv.org/pdf/2512.07482", "abs": "https://arxiv.org/abs/2512.07482", "authors": ["Florian Lüttner", "Nicole Neis", "Daniel Stadler", "Robin Moss", "Mirjam Fehling-Kaschek", "Matthias Pfriem", "Alexander Stolz", "Jens Ziehn"], "title": "From Real-World Traffic Data to Relevant Critical Scenarios", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 8 figures", "summary": "The reliable operation of autonomous vehicles, automated driving functions, and advanced driver assistance systems across a wide range of relevant scenarios is critical for their development and deployment. Identifying a near-complete set of relevant driving scenarios for such functionalities is challenging due to numerous degrees of freedom involved, each affecting the outcomes of the driving scenario differently. Moreover, with increasing technical complexity of new functionalities, the number of potentially relevant, particularly \"unknown unsafe\" scenarios is increasing. To enhance validation efficiency, it is essential to identify relevant scenarios in advance, starting with simpler domains like highways before moving to more complex environments such as urban traffic. To address this, this paper focuses on analyzing lane change scenarios in highway traffic, which involve multiple degrees of freedom and present numerous safetyrelevant scenarios. We describe the process of data acquisition and processing of real-world data from public highway traffic, followed by the application of criticality measures on trajectory data to evaluate scenarios, as conducted within the AVEAS project (www.aveas.org). By linking the calculated measures to specific lane change driving scenarios and the conditions under which the data was collected, we facilitate the identification of safetyrelevant driving scenarios for various applications. Further, to tackle the extensive range of \"unknown unsafe\" scenarios, we propose a way to generate relevant scenarios by creating synthetic scenarios based on recorded ones. Consequently, we demonstrate and evaluate a processing chain that enables the identification of safety-relevant scenarios, the development of data-driven methods for extracting these scenarios, and the generation of synthetic critical scenarios via sampling on highways."}
{"id": "2512.07507", "pdf": "https://arxiv.org/pdf/2512.07507", "abs": "https://arxiv.org/abs/2512.07507", "authors": ["Yiming Cui", "Shiyu Fang", "Jiarui Zhang", "Yan Huang", "Chengkai Xu", "Bing Zhu", "Hao Zhang", "Peng Hang", "Jian Sun"], "title": "VP-AutoTest: A Virtual-Physical Fusion Autonomous Driving Testing Platform", "categories": ["cs.RO", "cs.SE"], "comment": null, "summary": "The rapid development of autonomous vehicles has led to a surge in testing demand. Traditional testing methods, such as virtual simulation, closed-course, and public road testing, face several challenges, including unrealistic vehicle states, limited testing capabilities, and high costs. These issues have prompted increasing interest in virtual-physical fusion testing. However, despite its potential, virtual-physical fusion testing still faces challenges, such as limited element types, narrow testing scope, and fixed evaluation metrics. To address these challenges, we propose the Virtual-Physical Testing Platform for Autonomous Vehicles (VP-AutoTest), which integrates over ten types of virtual and physical elements, including vehicles, pedestrians, and roadside infrastructure, to replicate the diversity of real-world traffic participants. The platform also supports both single-vehicle interaction and multi-vehicle cooperation testing, employing adversarial testing and parallel deduction to accelerate fault detection and explore algorithmic limits, while OBU and Redis communication enable seamless vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) cooperation across all levels of cooperative automation. Furthermore, VP-AutoTest incorporates a multidimensional evaluation framework and AI-driven expert systems to conduct comprehensive performance assessment and defect diagnosis. Finally, by comparing virtual-physical fusion test results with real-world experiments, the platform performs credibility self-evaluation to ensure both the fidelity and efficiency of autonomous driving testing. Please refer to the website for the full testing functionalities on the autonomous driving public service platform OnSite:https://www.onsite.com.cn."}
{"id": "2512.07582", "pdf": "https://arxiv.org/pdf/2512.07582", "abs": "https://arxiv.org/abs/2512.07582", "authors": ["Guangyan Chen", "Meiling Wang", "Qi Shao", "Zichen Zhou", "Weixin Mao", "Te Cui", "Minzhao Zhu", "Yinan Deng", "Luojie Yang", "Zhanqi Zhang", "Yi Yang", "Hua Chen", "Yufeng Yue"], "title": "See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations", "categories": ["cs.RO"], "comment": null, "summary": "Developing robust and general-purpose manipulation policies represents a fundamental objective in robotics research. While Vision-Language-Action (VLA) models have demonstrated promising capabilities for end-to-end robot control, existing approaches still exhibit limited generalization to tasks beyond their training distributions. In contrast, humans possess remarkable proficiency in acquiring novel skills by simply observing others performing them once. Inspired by this capability, we propose ViVLA, a generalist robotic manipulation policy that achieves efficient task learning from a single expert demonstration video at test time. Our approach jointly processes an expert demonstration video alongside the robot's visual observations to predict both the demonstrated action sequences and subsequent robot actions, effectively distilling fine-grained manipulation knowledge from expert behavior and transferring it seamlessly to the agent. To enhance the performance of ViVLA, we develop a scalable expert-agent pair data generation pipeline capable of synthesizing paired trajectories from easily accessible human videos, further augmented by curated pairs from publicly available datasets. This pipeline produces a total of 892,911 expert-agent samples for training ViVLA. Experimental results demonstrate that our ViVLA is able to acquire novel manipulation skills from only a single expert demonstration video at test time. Our approach achieves over 30% improvement on unseen LIBERO tasks and maintains above 35% gains with cross-embodiment videos. Real-world experiments demonstrate effective learning from human videos, yielding more than 38% improvement on unseen tasks."}
{"id": "2512.07673", "pdf": "https://arxiv.org/pdf/2512.07673", "abs": "https://arxiv.org/abs/2512.07673", "authors": ["Matthias Heyrman", "Chenhao Li", "Victor Klemm", "Dongho Kang", "Stelian Coros", "Marco Hutter"], "title": "Multi-Domain Motion Embedding: Expressive Real-Time Mimicry for Legged Robots", "categories": ["cs.RO"], "comment": "15 pages", "summary": "Effective motion representation is crucial for enabling robots to imitate expressive behaviors in real time, yet existing motion controllers often ignore inherent patterns in motion. Previous efforts in representation learning do not attempt to jointly capture structured periodic patterns and irregular variations in human and animal movement. To address this, we present Multi-Domain Motion Embedding (MDME), a motion representation that unifies the embedding of structured and unstructured features using a wavelet-based encoder and a probabilistic embedding in parallel. This produces a rich representation of reference motions from a minimal input set, enabling improved generalization across diverse motion styles and morphologies. We evaluate MDME on retargeting-free real-time motion imitation by conditioning robot control policies on the learned embeddings, demonstrating accurate reproduction of complex trajectories on both humanoid and quadruped platforms. Our comparative studies confirm that MDME outperforms prior approaches in reconstruction fidelity and generalizability to unseen motions. Furthermore, we demonstrate that MDME can reproduce novel motion styles in real-time through zero-shot deployment, eliminating the need for task-specific tuning or online retargeting. These results position MDME as a generalizable and structure-aware foundation for scalable real-time robot imitation."}
{"id": "2512.07680", "pdf": "https://arxiv.org/pdf/2512.07680", "abs": "https://arxiv.org/abs/2512.07680", "authors": ["P. A. Wigner", "L. Romanello", "A. Hammad", "P. H. Nguyen", "T. Lan", "S. F. Armanini", "B. B. Kocer", "M. Kovac"], "title": "AMBER: Aerial deployable gripping crawler with compliant microspine for canopy manipulation", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents an aerially deployable crawler designed for adaptive locomotion and manipulation within tree canopies. The system combines compliant microspine-based tracks, a dual-track rotary gripper, and an elastic tail, enabling secure attachment and stable traversal across branches of varying curvature and inclination.\n  Experiments demonstrate reliable gripping up to 90 degrees of body roll and inclination, while effective climbing on branches inclined up to 67.5 degrees, achieving a maximum speed of 0.55 body lengths per second on horizontal branches. The compliant tracks allow yaw steering of up to 10 degrees, enhancing maneuverability on irregular surfaces.\n  Power measurements show efficient operation with a dimensionless cost of transport over an order of magnitude lower than typical hovering power consumption in aerial robots. Integrated within a drone-tether deployment system, the crawler provides a robust, low-power platform for environmental sampling and in-canopy sensing, bridging the gap between aerial and surface-based ecological robotics."}
{"id": "2512.07697", "pdf": "https://arxiv.org/pdf/2512.07697", "abs": "https://arxiv.org/abs/2512.07697", "authors": ["Aileen Liao", "Dong-Ki Kim", "Max Olan Smith", "Ali-akbar Agha-mohammadi", "Shayegan Omidshafiei"], "title": "Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "As a robot senses and selects actions, the world keeps changing. This inference delay creates a gap of tens to hundreds of milliseconds between the observed state and the state at execution. In this work, we take the natural generalization from zero delay to measured delay during training and inference. We introduce Delay-Aware Diffusion Policy (DA-DP), a framework for explicitly incorporating inference delays into policy learning. DA-DP corrects zero-delay trajectories to their delay-compensated counterparts, and augments the policy with delay conditioning. We empirically validate DA-DP on a variety of tasks, robots, and delays and find its success rate more robust to delay than delay-unaware methods. DA-DP is architecture agnostic and transfers beyond diffusion policies, offering a general pattern for delay-aware imitation learning. More broadly, DA-DP encourages evaluation protocols that report performance as a function of measured latency, not just task difficulty."}
{"id": "2512.07765", "pdf": "https://arxiv.org/pdf/2512.07765", "abs": "https://arxiv.org/abs/2512.07765", "authors": ["Gustavo A. Cardona", "Shubham S. Kumbhar", "Panagiotis Artemiadis"], "title": "Toward Seamless Physical Human-Humanoid Interaction: Insights from Control, Intent, and Modeling with a Vision for What Comes Next", "categories": ["cs.RO"], "comment": "60 pages, 5 figures, 3 tables", "summary": "Physical Human-Humanoid Interaction (pHHI) is a rapidly advancing field with significant implications for deploying robots in unstructured, human-centric environments. In this review, we examine the current state of the art in pHHI through three core pillars: (i) humanoid modeling and control, (ii) human intent estimation, and (iii) computational human models. For each pillar, we survey representative approaches, identify open challenges, and analyze current limitations that hinder robust, scalable, and adaptive interaction. These include the need for whole-body control strategies capable of handling uncertain human dynamics, real-time intent inference under limited sensing, and modeling techniques that account for variability in human physical states. Although significant progress has been made within each domain, integration across pillars remains limited. We propose pathways for unifying methods across these areas to enable cohesive interaction frameworks. This structure enables us not only to map the current landscape but also to propose concrete directions for future research that aim to bridge these domains. Additionally, we introduce a unified taxonomy of interaction types based on modality, distinguishing between direct interactions (e.g., physical contact) and indirect interactions (e.g., object-mediated), and on the level of robot engagement, ranging from assistance to cooperation and collaboration. For each category in this taxonomy, we provide the three core pillars that highlight opportunities for cross-pillar unification. Our goal is to suggest avenues to advance robust, safe, and intuitive physical interaction, providing a roadmap for future research that will allow humanoid systems to effectively understand, anticipate, and collaborate with human partners in diverse real-world settings."}
{"id": "2512.07775", "pdf": "https://arxiv.org/pdf/2512.07775", "abs": "https://arxiv.org/abs/2512.07775", "authors": ["David Thorne", "Nathan Chan", "Christa S. Robison", "Philip R. Osteen", "Brett T. Lopez"], "title": "OptMap: Geometric Map Distillation via Submodular Maximization", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous robots rely on geometric maps to inform a diverse set of perception and decision-making algorithms. As autonomy requires reasoning and planning on multiple scales of the environment, each algorithm may require a different map for optimal performance. Light Detection And Ranging (LiDAR) sensors generate an abundance of geometric data to satisfy these diverse requirements, but selecting informative, size-constrained maps is computationally challenging as it requires solving an NP-hard combinatorial optimization. In this work we present OptMap: a geometric map distillation algorithm which achieves real-time, application-specific map generation via multiple theoretical and algorithmic innovations. A central feature is the maximization of set functions that exhibit diminishing returns, i.e., submodularity, using polynomial-time algorithms with provably near-optimal solutions. We formulate a novel submodular reward function which quantifies informativeness, reduces input set sizes, and minimizes bias in sequentially collected datasets. Further, we propose a dynamically reordered streaming submodular algorithm which improves empirical solution quality and addresses input order bias via an online approximation of the value of all scans. Testing was conducted on open-source and custom datasets with an emphasis on long-duration mapping sessions, highlighting OptMap's minimal computation requirements. Open-source ROS1 and ROS2 packages are available and can be used alongside any LiDAR SLAM algorithm."}
{"id": "2512.07813", "pdf": "https://arxiv.org/pdf/2512.07813", "abs": "https://arxiv.org/abs/2512.07813", "authors": ["Hari Prakash Thanabalan", "Lars Bengtsson", "Ugo Lafont", "Giovanni Volpe"], "title": "Inchworm-Inspired Soft Robot with Groove-Guided Locomotion", "categories": ["cs.RO"], "comment": null, "summary": "Soft robots require directional control to navigate complex terrains. However, achieving such control often requires multiple actuators, which increases mechanical complexity, complicates control systems, and raises energy consumption. Here, we introduce an inchworm-inspired soft robot whose locomotion direction is controlled passively by patterned substrates. The robot employs a single rolled dielectric elastomer actuator, while groove patterns on a 3D-printed substrate guide its alignment and trajectory. Through systematic experiments, we demonstrate that varying groove angles enables precise control of locomotion direction without the need for complex actuation strategies. This groove-guided approach reduces energy consumption, simplifies robot design, and expands the applicability of bio-inspired soft robots in fields such as search and rescue, pipe inspection, and planetary exploration."}
{"id": "2512.07819", "pdf": "https://arxiv.org/pdf/2512.07819", "abs": "https://arxiv.org/abs/2512.07819", "authors": ["Shubham S. Kumbhar", "Abhijeet M. Kulkarni", "Panagiotis Artemiadis"], "title": "Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation", "categories": ["cs.RO"], "comment": null, "summary": "We present a control framework that enables humanoid robots to perform collaborative transportation tasks with a human partner. The framework supports both translational and rotational motions, which are fundamental to co-transport scenarios. It comprises three components: a high-level planner, a low-level controller, and a stiffness modulation mechanism. At the planning level, we introduce the Interaction Linear Inverted Pendulum (I-LIP), which, combined with an admittance model and an MPC formulation, generates dynamically feasible footstep plans. These are executed by a QP-based whole-body controller that accounts for the coupled humanoid-object dynamics. Stiffness modulation regulates robot-object interaction, ensuring convergence to the desired relative configuration defined by the distance between the object and the robot's center of mass. We validate the effectiveness of the framework through real-world experiments conducted on the Digit humanoid platform. To quantify collaboration quality, we propose an efficiency metric that captures both task performance and inter-agent coordination. We show that this metric highlights the role of compliance in collaborative tasks and offers insights into desirable trajectory characteristics across both high- and low-level control layers. Finally, we showcase experimental results on collaborative behaviors, including translation, turning, and combined motions such as semi circular trajectories, representative of naturally occurring co-transportation tasks."}
{"id": "2512.05996", "pdf": "https://arxiv.org/pdf/2512.05996", "abs": "https://arxiv.org/abs/2512.05996", "authors": ["Yi Liu", "Jingyu Song", "Vedanth Kallakuri", "Katherine A. Skinner"], "title": "FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting", "categories": ["cs.CV", "cs.CY", "cs.RO", "eess.IV"], "comment": "18 pages, under review", "summary": "Analyzing underwater fish imagery is critical for ecological monitoring but remains difficult due to visual degradation and costly annotations. We introduce FishDetector-R1, a unified MLLM-based framework for fish detection, segmentation, and counting under weak supervision. On the DeepFish dataset, our framework achieves substantial gains over baselines, improving AP by 20% and mIoU by 10%, while reducing MAE by 30% and GAME by 35%. These improvements stem from two key components: a novel detect-to-count prompt that enforces spatially consistent detections and counts, and Reinforcement Learning from Verifiable Reward (RLVR) with a complementary scalable paradigm leveraging sparse point labels. Ablation studies further validate the effectiveness of this reward design. Moreover, the improvement generalizes well to other underwater datasets, confirming strong cross-domain robustness. Overall, FishDetector-R1 provides a reliable and scalable solution for accurate marine visual understanding via weak supervision. The project page for FishDetector-R1 is https://umfieldrobotics.github.io/FishDetector-R1."}
{"id": "2512.06013", "pdf": "https://arxiv.org/pdf/2512.06013", "abs": "https://arxiv.org/abs/2512.06013", "authors": ["Wenhao Li", "Chengwei Ma", "Weixin Mao"], "title": "VAT: Vision Action Transformer by Unlocking Full Representation of ViT", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In robot learning, Vision Transformers (ViTs) are standard for visual perception, yet most methods discard valuable information by using only the final layer's features. We argue this provides an insufficient representation and propose the Vision Action Transformer (VAT), a novel architecture that is extended from ViT and unlocks the full feature hierarchy of ViT. VAT processes specialized action tokens with visual features across all transformer layers, enabling a deep and progressive fusion of perception and action generation. On a suite of simulated manipulation tasks, VAT achieves a 98.15\\% average success rate across four LIBERO benchmarks, establishing a new state-of-the-art by outperforming prior methods like OpenVLA-OFT. Our work presents not only a powerful model for imitation learning but also demonstrates the critical importance of leveraging the complete ''representation trajectory'' of vision models to advance robotic policy. The GitHub URL for the project code is https://github.com/sellerbubble/VAT."}
{"id": "2512.06109", "pdf": "https://arxiv.org/pdf/2512.06109", "abs": "https://arxiv.org/abs/2512.06109", "authors": ["Ajinkya Bhole", "Mohammad Mahmoudi Filabadi", "Guillaume Crevecoeur", "Tom Lefebvre"], "title": "Unifying Entropy Regularization in Optimal Control: From and Back to Classical Objectives via Iterated Soft Policies and Path Integral Solutions", "categories": ["math.OC", "cs.LG", "cs.RO", "eess.SY"], "comment": null, "summary": "This paper develops a unified perspective on several stochastic optimal control formulations through the lens of Kullback-Leibler regularization. We propose a central problem that separates the KL penalties on policies and transitions, assigning them independent weights, thereby generalizing the standard trajectory-level KL-regularization commonly used in probabilistic and KL-regularized control. This generalized formulation acts as a generative structure allowing to recover various control problems. These include the classical Stochastic Optimal Control (SOC), Risk-Sensitive Optimal Control (RSOC), and their policy-based KL-regularized counterparts. The latter we refer to as soft-policy SOC and RSOC, facilitating alternative problems with tractable solutions. Beyond serving as regularized variants, we show that these soft-policy formulations majorize the original SOC and RSOC problem. This means that the regularized solution can be iterated to retrieve the original solution. Furthermore, we identify a structurally synchronized case of the risk-seeking soft-policy RSOC formulation, wherein the policy and transition KL-regularization weights coincide. Remarkably, this specific setting gives rise to several powerful properties such as a linear Bellman equation, path integral solution, and, compositionality, thereby extending these computationally favourable properties to a broad class of control problems."}
{"id": "2512.06357", "pdf": "https://arxiv.org/pdf/2512.06357", "abs": "https://arxiv.org/abs/2512.06357", "authors": ["Tony Sallooma", "Okyay Kaynak", "Xinbo Yub", "Wei He"], "title": "Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Engineering Applications of Artificial Intelligence 2022", "summary": "Multi-step time-series prediction is an essential supportive step for decision-makers in several industrial areas. Artificial intelligence techniques, which use a neural network component in various forms, have recently frequently been used to accomplish this step. However, the complexity of the neural network structure still stands up as a critical problem against prediction accuracy. In this paper, a method inspired by the proportional-integral-derivative (PID) control approach is investigated to enhance the performance of neural network models used for multi-step ahead prediction of periodic time-series information while maintaining a negligible impact on the complexity of the system. The PID-based method is applied to the predicted value at each time step to bring that value closer to the real value. The water demand forecasting problem is considered as a case study, where two deep neural network models from the literature are used to prove the effectiveness of the proposed boosting method. Furthermore, to prove the applicability of this PID-based booster to other types of periodic time-series prediction problems, it is applied to enhance the accuracy of a neural network model used for multi-step forecasting of hourly energy consumption. The comparison between the results of the original prediction models and the results after using the proposed technique demonstrates the superiority of the proposed method in terms of prediction accuracy and system complexity."}
{"id": "2512.06387", "pdf": "https://arxiv.org/pdf/2512.06387", "abs": "https://arxiv.org/abs/2512.06387", "authors": ["Yuhang Huang", "Junchao Li", "Boyang Ma", "Xuelong Dai", "Minghui Xu", "Kaidi Xu", "Yue Zhang", "Jianping Wang", "Xiuzhen Cheng"], "title": "Beyond Model Jailbreak: Systematic Dissection of the \"Ten DeadlySins\" in Embodied Intelligence", "categories": ["cs.CR", "cs.RO"], "comment": null, "summary": "Embodied AI systems integrate language models with real world sensing, mobility, and cloud connected mobile apps. Yet while model jailbreaks have drawn significant attention, the broader system stack of embodied intelligence remains largely unexplored. In this work, we conduct the first holistic security analysis of the Unitree Go2 platform and uncover ten cross layer vulnerabilities the \"Ten Sins of Embodied AI Security.\" Using BLE sniffing, traffic interception, APK reverse engineering, cloud API testing, and hardware probing, we identify systemic weaknesses across three architectural layers: wireless provisioning, core modules, and external interfaces. These include hard coded keys, predictable handshake tokens, WiFi credential leakage, missing TLS validation, static SSH password, multilingual safety bypass behavior, insecure local relay channels, weak binding logic, and unrestricted firmware access. Together, they allow adversaries to hijack devices, inject arbitrary commands, extract sensitive information, or gain full physical control.Our findings show that securing embodied AI requires far more than aligning the model itself. We conclude with system level lessons learned and recommendations for building embodied platforms that remain robust across their entire software hardware ecosystem."}
{"id": "2512.06504", "pdf": "https://arxiv.org/pdf/2512.06504", "abs": "https://arxiv.org/abs/2512.06504", "authors": ["Andrii Lysyi", "Anatoliy Sachenko", "Pavlo Radiuk", "Mykola Lysyi", "Oleksandr Melnychenko", "Diana Zahorodnia"], "title": "Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "The subject of this research is the development of an intelligent, integrated framework for the automated inspection of photovoltaic (PV) infrastructure that addresses the critical shortcomings of conventional methods, including thermal palette bias, data redundancy, and high communication bandwidth requirements. The goal of this study is to design, develop, and validate a comprehensive, multi-modal system that fully automates the monitoring workflow, from data acquisition to the generation of actionable, geo-located maintenance alerts, thereby enhancing plant safety and operational efficiency. The methods employed involve a synergistic architecture that begins with a palette-invariant thermal embedding, learned by enforcing representational consistency, which is fused with a contrast-normalized RGB stream via a gated mechanism. This is supplemented by a closed-loop, adaptive re-acquisition controller that uses Rodrigues-based updates for targeted confirmation of ambiguous anomalies and a geospatial deduplication module that clusters redundant alerts using DBSCAN over the haversine distance. In conclusion, this study establishes a powerful new paradigm for proactive PV inspection, with the proposed system achieving a mean Average Precision (mAP@0.5) of 0.903 on the public PVF-10 benchmark, a significant 12-15% improvement over single-modality baselines. Field validation confirmed the system's readiness, achieving 96% recall, while the de-duplication process reduced duplicate-induced false positives by 15-20%, and relevance-only telemetry cut airborne data transmission by 60-70%."}
{"id": "2512.06577", "pdf": "https://arxiv.org/pdf/2512.06577", "abs": "https://arxiv.org/abs/2512.06577", "authors": ["Muhammad Junayed Hasan Zahed", "Hossein Rastgoftar"], "title": "Deep Neural Network-Based Aerial Transport in the Presence of Cooperative and Uncooperative UAS", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "We present a resilient deep neural network (DNN) framework for decentralized transport and coverage using uncrewed aerial systems (UAS) operating in $\\mathbb{R}^n$. The proposed DNN-based mass-transport architecture constructs a layered inter-UAS communication graph from an initial formation, assigns time-varying communication weights through a forward scheduling mechanism that guides the team from the initial to the final configuration, and ensures stability and convergence of the resulting multi-agent transport dynamics. The framework is explicitly designed to remain robust in the presence of uncooperative agents that deviate from or refuse to follow the prescribed protocol. Our method preserves a fixed feed-forward topology but dynamically prunes edges to uncooperative agents, maintains convex, feedforward mentoring among cooperative agents, and computes global desired set points through a sparse linear relation consistent with leader references. The target set is abstracted by $N$ points that become final desired positions, enabling coverage-optimal transport while keeping computation low and guarantees intact. Extensive simulations demonstrate that, under full cooperation, all agents converge rapidly to the target zone with a 10\\% boundary margin and under partial cooperation with uncooperative agents, the system maintains high convergence among cooperative agents with performance degradation localized near the disruptions, evidencing graceful resilience and scalability. These results confirm that forward-weight scheduling, hierarchical mentor--mentee coordination, and on-the-fly DNN restructuring yield robust, provably stable UAS transport in realistic fault scenarios."}
{"id": "2512.06714", "pdf": "https://arxiv.org/pdf/2512.06714", "abs": "https://arxiv.org/abs/2512.06714", "authors": ["Tony Salloom", "Okyay Kaynak", "Wei He"], "title": "A Novel Deep Neural Network Architecture for Real-Time Water Demand Forecasting", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Short-term water demand forecasting (StWDF) is the foundation stone in the derivation of an optimal plan for controlling water supply systems. Deep learning (DL) approaches provide the most accurate solutions for this purpose. However, they suffer from complexity problem due to the massive number of parameters, in addition to the high forecasting error at the extreme points. In this work, an effective method to alleviate the error at these points is proposed. It is based on extending the data by inserting virtual data within the actual data to relieve the nonlinearity around them. To our knowledge, this is the first work that considers the problem related to the extreme points. Moreover, the water demand forecasting model proposed in this work is a novel DL model with relatively low complexity. The basic model uses the gated recurrent unit (GRU) to handle the sequential relationship in the historical demand data, while an unsupervised classification method, K-means, is introduced for the creation of new features to enhance the prediction accuracy with less number of parameters. Real data obtained from two different water plants in China are used to train and verify the model proposed. The prediction results and the comparison with the state-of-the-art illustrate that the method proposed reduces the complexity of the model six times of what achieved in the literature while conserving the same accuracy. Furthermore, it is found that extending the data set significantly reduces the error by about 30%. However, it increases the training time."}
{"id": "2512.06889", "pdf": "https://arxiv.org/pdf/2512.06889", "abs": "https://arxiv.org/abs/2512.06889", "authors": ["Ximing Huang", "Yirui Rao"], "title": "AQUILA: A QUIC-Based Link Architecture for Resilient Long-Range UAV Communication", "categories": ["cs.NI", "cs.RO"], "comment": "13 pages, 10 figures", "summary": "The proliferation of autonomous Unmanned Aerial Vehicles (UAVs) in Beyond Visual Line of Sight (BVLOS) applications is critically dependent on resilient, high-bandwidth, and low-latency communication links. Existing solutions face critical limitations: TCP's head-of-line blocking stalls time-sensitive data, UDP lacks reliability and congestion control, and cellular networks designed for terrestrial users degrade severely for aerial platforms. This paper introduces AQUILA, a cross-layer communication architecture built on QUIC to address these challenges. AQUILA contributes three key innovations: (1) a unified transport layer using QUIC's reliable streams for MAVLink Command and Control (C2) and unreliable datagrams for video, eliminating head-of-line blocking under unified congestion control; (2) a priority scheduling mechanism that structurally ensures C2 latency remains bounded and independent of video traffic intensity; (3) a UAV-adapted congestion control algorithm extending SCReAM with altitude-adaptive delay targeting and telemetry headroom reservation. AQUILA further implements 0-RTT connection resumption to minimize handover blackouts with application-layer replay protection, deployed over an IP-native architecture enabling global operation. Experimental validation demonstrates that AQUILA significantly outperforms TCP- and UDP-based approaches in C2 latency, video quality, and link resilience under realistic conditions, providing a robust foundation for autonomous BVLOS missions."}
{"id": "2512.07219", "pdf": "https://arxiv.org/pdf/2512.07219", "abs": "https://arxiv.org/abs/2512.07219", "authors": ["Sungyong Chung", "Alireza Talebpour", "Samer H. Hamdar"], "title": "Characterizing Lane-Changing Behavior in Mixed Traffic", "categories": ["cs.MA", "cs.GT", "cs.RO", "eess.SY"], "comment": null, "summary": "Characterizing and understanding lane-changing behavior in the presence of automated vehicles (AVs) is crucial to ensuring safety and efficiency in mixed traffic. Accordingly, this study aims to characterize the interactions between the lane-changing vehicle (active vehicle) and the vehicle directly impacted by the maneuver in the target lane (passive vehicle). Utilizing real-world trajectory data from the Waymo Open Motion Dataset (WOMD), this study explores patterns in lane-changing behavior and provides insight into how these behaviors evolve under different AV market penetration rates (MPRs). In particular, we propose a game-theoretic framework to analyze cooperative and defective behaviors in mixed traffic, applied to the 7,636 observed lane-changing events in the WOMD. First, we utilize k-means clustering to classify vehicles as cooperative or defective, revealing that the proportions of cooperative AVs are higher than those of HDVs in both active and passive roles. Next, we jointly estimate the utilities of active and passive vehicles to model their behaviors using the quantal response equilibrium framework. Empirical payoff tables are then constructed based on these utilities. Using these payoffs, we analyze the presence of social dilemmas and examine the evolution of cooperative behaviors using evolutionary game theory. Our results reveal the presence of social dilemmas in approximately 4% and 11% of lane-changing events for active and passive vehicles, respectively, with most classified as Stag Hunt or Prisoner's Dilemma (Chicken Game rarely observed). Moreover, the Monte Carlo simulation results show that repeated lane-changing interactions consistently lead to increased cooperative behavior over time, regardless of the AV penetration rate."}
{"id": "2512.07437", "pdf": "https://arxiv.org/pdf/2512.07437", "abs": "https://arxiv.org/abs/2512.07437", "authors": ["Chenwei Shi", "Xueyu Luan"], "title": "KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "cs.RO"], "comment": "23 pages, 8 figures, 3 tables", "summary": "DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models."}
{"id": "2512.07596", "pdf": "https://arxiv.org/pdf/2512.07596", "abs": "https://arxiv.org/abs/2512.07596", "authors": ["Wenzhen Dong", "Jieming Yu", "Yiming Huang", "Hongqiu Wang", "Lei Zhu", "Albert C. S. Chung", "Hongliang Ren", "Long Bai"], "title": "More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery", "categories": ["cs.CV", "cs.RO"], "comment": "Technical Report", "summary": "The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes."}
{"id": "2512.07609", "pdf": "https://arxiv.org/pdf/2512.07609", "abs": "https://arxiv.org/abs/2512.07609", "authors": ["Nikita Vaibhav Pavle", "Shrreya Rajneesh", "Rakesh Kumar Sahoo", "Manoranjan Sinha"], "title": "Obstacle Avoidance of UAV in Dynamic Environments Using Direction and Velocity-Adaptive Artificial Potential Field", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "The conventional Artificial Potential Field (APF) is fundamentally limited by the local minima issue and its inability to account for the kinematics of moving obstacles. This paper addresses the critical challenge of autonomous collision avoidance for Unmanned Aerial Vehicles (UAVs) operating in dynamic and cluttered airspace by proposing a novel Direction and Relative Velocity Weighted Artificial Potential Field (APF). In this approach, a bounded weighting function, $ω(θ,v_{e})$, is introduced to dynamically scale the repulsive potential based on the direction and velocity of the obstacle relative to the UAV. This robust APF formulation is integrated within a Model Predictive Control (MPC) framework to generate collision-free trajectories while adhering to kinematic constraints. Simulation results demonstrate that the proposed method effectively resolves local minima and significantly enhances safety by enabling smooth, predictive avoidance maneuvers. The system ensures superior path integrity and reliable performance, confirming its viability for autonomous navigation in complex environments."}
{"id": "2512.07698", "pdf": "https://arxiv.org/pdf/2512.07698", "abs": "https://arxiv.org/abs/2512.07698", "authors": ["Arslan Artykov", "Corentin Sautier", "Vincent Lepetit"], "title": "sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Understanding articulated objects is a fundamental challenge in robotics and digital twin creation. To effectively model such objects, it is essential to recover both part segmentation and the underlying joint parameters. Despite the importance of this task, previous work has largely focused on setups like multi-view systems, object scanning, or static cameras. In this paper, we present the first data-driven approach that jointly predicts part segmentation and joint parameters from monocular video captured with a freely moving camera. Trained solely on synthetic data, our method demonstrates strong generalization to real-world objects, offering a scalable and practical solution for articulated object understanding. Our approach operates directly on casually recorded video, making it suitable for real-time applications in dynamic environments. Project webpage: https://aartykov.github.io/sim2art/"}
{"id": "2512.07756", "pdf": "https://arxiv.org/pdf/2512.07756", "abs": "https://arxiv.org/abs/2512.07756", "authors": ["Mayank Anand", "Ujair Alam", "Surya Prakash", "Priya Shukla", "Gora Chand Nandi", "Domenec Puig"], "title": "UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Clinical ultrasound acquisition is highly operator-dependent, where rapid probe motion and brightness fluctuations often lead to reconstruction errors that reduce trust and clinical utility. We present UltrasODM, a dual-stream framework that assists sonographers during acquisition through calibrated per-frame uncertainty, saliency-based diagnostics, and actionable prompts. UltrasODM integrates (i) a contrastive ranking module that groups frames by motion similarity, (ii) an optical-flow stream fused with Dual-Mamba temporal modules for robust 6-DoF pose estimation, and (iii) a Human-in-the-Loop (HITL) layer combining Bayesian uncertainty, clinician-calibrated thresholds, and saliency maps highlighting regions of low confidence. When uncertainty exceeds the threshold, the system issues unobtrusive alerts suggesting corrective actions such as re-scanning highlighted regions or slowing the sweep. Evaluated on a clinical freehand ultrasound dataset, UltrasODM reduces drift by 15.2%, distance error by 12.1%, and Hausdorff distance by 10.1% relative to UltrasOM, while producing per-frame uncertainty and saliency outputs. By emphasizing transparency and clinician feedback, UltrasODM improves reconstruction reliability and supports safer, more trustworthy clinical workflows. Our code is publicly available at https://github.com/AnandMayank/UltrasODM."}
