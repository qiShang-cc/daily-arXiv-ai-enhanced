<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 6]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [math.OC](#math.OC) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [eess.SY](#eess.SY) [Total: 2]
- [cs.CV](#cs.CV) [Total: 3]
- [math.DG](#math.DG) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [CKM-Assisted Physical-Layer Security for Resilience Against Unknown Eavesdropping Location](https://arxiv.org/abs/2508.13681)
*Ladan Khaloopour,Matthias Hollick,Vahid Jamali*

Main category: eess.SP

TL;DR: 该论文提出利用信道知识地图（CKM）优化毫米波多波束传输，提升物理层安全性，无需窃听者位置或信道状态信息假设。


<details>
  <summary>Details</summary>
Motivation: 研究动机是通过CKM提升物理层安全性，解决窃听者位置和信道状态信息未知的问题。

Method: 采用高定向毫米波传输，在多个波束上联合编码机密信息，利用CKM设计时隙和功率分配算法最大化绝对保密率。

Result: 算法在最坏情况下（窃听者位置未知）成功优化了保密率。

Conclusion: CKM可作为高效工具提升无线通信安全性，尤其在毫米波场景中效果显著。

Abstract: Channel Knowledge Map (CKM) is an emerging data-driven toolbox that captures
our awareness of the wireless channel and enables efficient communication and
resource allocation beyond the state of the art. In this work, we consider CKM
for improving physical-layer security (PLS) in the presence of a passive
eavesdropper (Eve), without making any assumptions about Eve's location or
channel state information (CSI). We employ highly directional mmWave
transmissions, with the confidential message jointly encoded across multiple
beams. By exploiting CKM, we derive an algorithm for time and power allocation
among the beams that maximizes the absolute secrecy rate under the worst-case
scenario for Eve's location.

</details>


### [2] [Airy beams for near-field communications: Fundamentals, potentials, and limitations](https://arxiv.org/abs/2508.13714)
*Donatella Darsena,Francesco Verde,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 论文研究了下一代无线网络中的近场区域Airy光束的生成、传播特性及其在非视距（NLoS）场景中的性能优势。


<details>
  <summary>Details</summary>
Motivation: 近场区域的非平面波前为光束形状和方向的调控提供了额外自由度，Airy光束因其自加速、自愈和衍射自由特性成为研究重点。

Method: 通过分析连续孔径场分布生成Airy光束的原理，探讨其生成挑战（如有限能量约束和孔径截断）。比较分析了Airy光束与高斯光束在非视距场景中的传播行为。

Result: 理论及数值结果表明，Airy光束在保持关键特性（如自加速和衍射自由）的情况下，在特定NLoS信道中性能优于高斯光束。

Conclusion: Airy光束在下一代无线网络中具备潜在应用价值，尤其在非视距场景中，但需保证发射孔径足够大以维持其特性。

Abstract: In next-generation wireless networks, the combination of electrically large
radiating apertures and high-frequency transmission extends the radiating
near-field region around the transmitter. In this region, unlike in the far
field, the wavefront is nonplanar, which provides additional degrees of freedom
to shape and steer the transmitted beam in a desired manner. In this paper, we
focus on Airy beams, which may exhibit several highly desirable properties in
the near-field region. Ideally, these beams follow self-accelerating (curved)
trajectories, demonstrate resilience to perturbations through self-healing, and
maintain a consistent intensity profile across all planes perpendicular to the
propagation direction, making them effectively diffraction-free. Specifically,
we first present the underlying principles of self-accelerating beams radiated
by continuous aperture field distributions. We then address several challenges
regarding the generation of Airy beams, including their exponential decay due
to finite energy constraints and spatial truncation of the aperture. Moreover,
we examine their free-space propagation characteristics. The second part of the
paper focuses on the propagation behavior of Airy beams in non-line-of-sight
(NLoS) scenarios. A comparison is also presented between Airy beams and
Gaussian beams. Our theoretical and numerical results show that Airy beams may
offer a performance advantage over Gaussian beams in certain NLoS channels,
provided that their key properties are largely preserved, specifically,
self-acceleration along a parabolic trajectory and diffraction-free
propagation. In the presence of an obstacle, this requires that the portion of
the transmit aperture with a clear line-of-sight to the receiver is
sufficiently large.

</details>


### [3] [Joint AP Selection and Power Allocation for Unicast-Multicast Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13771)
*Mustafa S. Abbas,Zahra Mobini,Hien Quoc Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 论文研究了在无蜂窝大规模MIMO系统中联合单播和多播传输的优化问题，提出了一种基于加速投影梯度的算法，显著提升了系统频谱效率。


<details>
  <summary>Details</summary>
Motivation: 随着物联网网络等无线系统的普及，联合单播和多播传输的需求日益增长，优化此类系统的频谱效率和资源分配成为一个重要问题。

Method: 通过推导单播和多播用户的频谱效率闭式表达式，提出了一个加权和频谱效率最大化问题，并设计了一种基于加速投影梯度的算法来解决非凸优化问题。

Result: 仿真结果表明，提出的联合优化方法在不同系统设置和预编码策略下显著提升了频谱效率，APG算法在保持性能的同时大幅降低了复杂度。

Conclusion: 论文的方法适用于大规模实际部署，尤其是APG算法在复杂度和性能之间取得了良好的平衡。

Abstract: Joint unicast and multicast transmissions are becoming increasingly important
in practical wireless systems, such as Internet of Things networks. This paper
investigates a cell-free massive multiple-input multiple-output system that
simultaneously supports both transmission types, with multicast serving
multiple groups. Exact closed-form expressions for the achievable downlink
spectral efficiency (SE) of both unicast and multicast users are derived for
zero-forcing and maximum ratio precoding designs. Accordingly, a weighted sum
SE (SSE) maximization problem is formulated to jointly optimize the access
point (AP) selection and power allocation. The optimization framework accounts
for practical constraints, including the maximum transmit power per AP,
fronthaul capacity limitations between APs and the central processing unit, and
quality-of-service requirements for all users. The resulting non-convex
optimization problem is reformulated into a tractable structure, and an
accelerated projected gradient (APG)-based algorithm is developed to
efficiently obtain near-optimal solutions. As a performance benchmark, a
successive convex approximation (SCA)-based algorithm is also implemented.
Simulation results demonstrate that the proposed joint optimization approach
significantly enhances the SSE across various system setups and precoding
strategies. In particular, the APG-based algorithm achieves substantial
complexity reduction while maintaining competitive performance, making it
well-suited for large-scale practical deployments.

</details>


### [4] [Robust Optimization for Movable Antenna-aided Cell-Free ISAC with Time Synchronization Errors](https://arxiv.org/abs/2508.13818)
*Yue Xiu,Yang Zhao,Ran Yang,Wanting Lyu,Dusit Niyato,Dong In Kim,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 提出了一种基于可移动天线（MA）的CF-ISAC架构，通过空间多样性增强通信速率和感知精度，降低时间同步误差的影响。


<details>
  <summary>Details</summary>
Motivation: 当前时间同步误差已成为CF-ISAC系统发展的主要挑战，需要一种新架构来提升性能。

Method: 采用流形优化（MO）和最坏情况下感知精度优化问题建模，结合MA-MetaRL算法设计优化变量。

Result: 仿真表明，算法显著提升检测精度，且对时间同步误差具有强鲁棒性，系统容量优于传统固定天线技术。

Conclusion: 基于MA的CF-ISAC架构在通信和感知性能上均表现出显著优势，有效解决了时间同步误差问题。

Abstract: The cell-free integrated sensing and communication (CF-ISAC) system, which
effectively mitigates intra-cell interference and provides precise sensing
accuracy, is a promising technology for future 6G networks. However, to fully
capitalize on the potential of CF-ISAC, accurate time synchronization (TS)
between access points (APs) is critical. Due to the limitations of current
synchronization technologies, TS errors have become a significant challenge in
the development of the CF-ISAC system. In this paper, we propose a novel
CF-ISAC architecture based on movable antennas (MAs), which exploits spatial
diversity to enhance communication rates, maintain sensing accuracy, and reduce
the impact of TS errors. We formulate a worst-case sensing accuracy
optimization problem for TS errors to address this challenge, deriving the
worst-case Cram\'er-Rao lower bound (CRLB). Subsequently, we develop a joint
optimization framework for AP beamforming and MA positions to satisfy
communication rate constraints while improving sensing accuracy. A robust
optimization framework is designed for the highly complex and non-convex
problem. Specifically, we employ manifold optimization (MO) to solve the
worst-case sensing accuracy optimization problem. Then, we propose an
MA-enabled meta-reinforcement learning (MA-MetaRL) to design optimization
variables while satisfying constraints on MA positions, communication rate, and
transmit power, thereby improving sensing accuracy. The simulation results
demonstrate that the proposed robust optimization algorithm significantly
improves the accuracy of the detection and is strong against TS errors.
Moreover, compared to conventional fixed position antenna (FPA) technologies,
the proposed MA-aided CF-ISAC architecture achieves higher system capacity,
thus validating its effectiveness.

</details>


### [5] [Distributed Distortion-Aware Robust Optimization for Movable Antenna-aided Cell-Free ISAC Systems](https://arxiv.org/abs/2508.13839)
*Yue Xiu,Yang Zhao,Ran Yang,Zheng Dong,Wanting Lyu,Zeyuan Zhang,Dusit Niyato,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可移动天线（MA）的CF-ISAC系统，以解决非线性功率放大器失真问题，并通过分布式鲁棒优化和SACGNN算法显著提升通信与感知的性能。


<details>
  <summary>Details</summary>
Motivation: 6G网络中的CF-ISAC架构面临硬件非线性失真问题，影响通信与感知性能，本研究旨在通过MA和优化框架解决这一问题。

Method: 采用第三阶无记忆多项式建模PA非线性，设计分布式鲁棒优化框架，并开发SACGNN算法联合优化波束成形和MA位置。

Result: 仿真表明，该方法在失真情况下显著提升了通信-感知权衡，并优于固定天线基准。

Conclusion: MA辅助的CF-ISAC系统在硬件失真下表现出更强的鲁棒性和性能优势，为6G部署提供了有效解决方案。

Abstract: The cell-free integrated sensing and communication (CF-ISAC) architecture is
a promising enabler for 6G, offering spectrum efficiency and ubiquitous
coverage. However, real deployments suffer from hardware impairments,
especially nonlinear distortion from power amplifiers (PAs), which degrades
both communication and sensing. To address this, we propose a movable antenna
(MA)-aided CF-ISAC system that mitigates distortion and enhances robustness.
The PAs nonlinearities are modeled by a third-order memoryless polynomial,
where the third-order distortion coefficients (3RDCs) vary across access points
(APs) due to hardware differences, aging, and environmental conditions. We
design a distributed distortion-aware worst-case robust optimization framework
that explicitly incorporates uncertainty in 3RDCs. First, we analyze the
worst-case impact of PA distortion on both the Cramer-Rao lower bound (CRLB)
and communication rate. Then, to address the resulting non-convexity, we apply
successive convex approximation (SCA) for estimating the 3RDCs. With these, we
jointly optimize beamforming and MA positions under transmit power and sensing
constraints. To efficiently solve this highly non-convex problem, we develop an
MA-enabled self-attention convolutional graph neural network (SACGNN)
algorithm. Simulations demonstrate that our method substantially enhances the
communication-sensing trade-off under distortion and outperforms fixed-position
antenna baselines in terms of robustness and capacity, thereby highlighting the
advantages of MA-aided CF-ISAC systems.

</details>


### [6] [Evaluating Particle Filtering for RSS-Based Target Localization under Varying Noise Levels and Sensor Geometries](https://arxiv.org/abs/2508.13937)
*Halim Lee,Jongmin Park,Kwansik Park*

Main category: eess.SP

TL;DR: 粒子滤波在RSS目标定位中的性能优于传统三角测量，尤其在传感器几何分布不理想和高噪声条件下表现更优。


<details>
  <summary>Details</summary>
Motivation: 目标定位在多种应用中至关重要，但目前缺乏对粒子滤波在RSS目标定位中性能的系统分析。

Method: 设计并评估了一种基于粒子滤波的算法，用于定位静止目标，并与传统的RSS三角测量方法进行对比。

Result: 仿真结果表明，粒子滤波比三角测量更准确，尤其是在传感器几何分布不理想和高噪声情况下。

Conclusion: 粒子滤波是RSS目标定位的有效方法，特别适用于复杂环境。

Abstract: Target localization is a critical task in various applications, such as
search and rescue, surveillance, and wireless sensor networks. When a target
emits a radio frequency (RF) signal, spatially distributed sensors can collect
signal measurements to estimate the target's location. Among various
measurement modalities, received signal strength (RSS) is particularly
attractive due to its low cost, low power consumption, and ease of deployment.
While particle filtering has previously been applied to RSS-based target
localization, few studies have systematically analyzed its performance under
varying sensor geometries and RSS noise levels. This paper addresses this gap
by designing and evaluating a particle filtering algorithm for localizing a
stationary target. The proposed method is compared with a conventional
RSS-based trilateration approach across different sensor configurations and
noise conditions. Simulation results indicate that particle filtering provides
more accurate target localization than trilateration, particularly in scenarios
with unfavorable sensor geometries and high RSS noise.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [7] [Diff-MSM: Differentiable MusculoSkeletal Model for Simultaneous Identification of Human Muscle and Bone Parameters](https://arxiv.org/abs/2508.13303)
*Yingfan Zhou,Philip Sanderink,Sigurd Jager Lemming,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了Diff-MSM方法，通过自动微分技术同时识别肌肉和骨骼参数，无需直接测量关节扭矩，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 个性化人体肌肉骨骼模型对模拟人机交互系统行为至关重要，但直接测量内部生物力学参数（如关节扭矩）困难。

Method: 使用Diff-MSM，通过自动微分技术从可测量的肌肉激活到观测运动的端到端识别肌肉和骨骼参数。

Result: 仿真结果显示，Diff-MSM在肌肉参数估计上误差低至0.05%，显著优于现有方法。

Conclusion: Diff-MSM不仅提升肌肉骨骼模型精度，还在肌肉健康监测、康复和运动科学中有广泛应用潜力。

Abstract: High-fidelity personalized human musculoskeletal models are crucial for
simulating realistic behavior of physically coupled human-robot interactive
systems and verifying their safety-critical applications in simulations before
actual deployment, such as human-robot co-transportation and rehabilitation
through robotic exoskeletons. Identifying subject-specific Hill-type muscle
model parameters and bone dynamic parameters is essential for a personalized
musculoskeletal model, but very challenging due to the difficulty of measuring
the internal biomechanical variables in vivo directly, especially the joint
torques. In this paper, we propose using Differentiable MusculoSkeletal Model
(Diff-MSM) to simultaneously identify its muscle and bone parameters with an
end-to-end automatic differentiation technique differentiating from the
measurable muscle activation, through the joint torque, to the resulting
observable motion without the need to measure the internal joint torques.
Through extensive comparative simulations, the results manifested that our
proposed method significantly outperformed the state-of-the-art baseline
methods, especially in terms of accurate estimation of the muscle parameters
(i.e., initial guess sampled from a normal distribution with the mean being the
ground truth and the standard deviation being 10% of the ground truth could end
up with an average of the percentage errors of the estimated values as low as
0.05%). In addition to human musculoskeletal modeling and simulation, the new
parameter identification technique with the Diff-MSM has great potential to
enable new applications in muscle health monitoring, rehabilitation, and sports
science.

</details>


### [8] [A Surveillance Based Interactive Robot](https://arxiv.org/abs/2508.13319)
*Kshitij Kavimandan,Pooja Mangal,Devanshi Mehta*

Main category: cs.RO

TL;DR: 构建了一个移动监控机器人，实时视频流与语音交互，用户可通过手机或浏览器监控和操控。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、易于复制的移动监控机器人，具备实时视频传输和语音交互功能，适用于室内环境。

Method: 使用两个树莓派4单元，前端单元配备摄像头、麦克风和扬声器，中央单元负责视频流和感知处理。采用FFmpeg传输视频，YOLOv3进行物体检测，Python库实现语音识别与多语言交互，Kinect传感器提供视觉和障碍物信息。

Result: 在室内测试中，机器人能以交互帧率检测常见物体，可靠识别语音指令并翻译为动作，无需手动控制。

Conclusion: 系统基于现成硬件和开源软件，易于复制。未来可扩展包括传感器融合、GPU加速及人脸和文本识别。

Abstract: We build a mobile surveillance robot that streams video in real time and
responds to speech so a user can monitor and steer it from a phone or browser.
The system uses two Raspberry Pi 4 units: a front unit on a differential drive
base with camera, mic, and speaker, and a central unit that serves the live
feed and runs perception. Video is sent with FFmpeg. Objects in the scene are
detected using YOLOv3 to support navigation and event awareness. For voice
interaction, we use Python libraries for speech recognition, multilingual
translation, and text-to-speech, so the robot can take spoken commands and read
back responses in the requested language. A Kinect RGB-D sensor provides visual
input and obstacle cues. In indoor tests the robot detects common objects at
interactive frame rates on CPU, recognises commands reliably, and translates
them to actions without manual control. The design relies on off-the-shelf
hardware and open software, making it easy to reproduce. We discuss limits and
practical extensions, including sensor fusion with ultrasonic range data, GPU
acceleration, and adding face and text recognition.

</details>


### [9] [Incremental Generalized Hybrid A*](https://arxiv.org/abs/2508.13392)
*Sidharth Talia,Oren Salzman,Siddhartha Srinivasa*

Main category: cs.RO

TL;DR: IGHA*是一种动态组织顶点扩展的树搜索框架，用于高效路径规划，比HA*减少6倍的扩展次数，在复杂动力学下实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂动力学下，传统路径规划方法（如HA*）因网格分辨率选择困难导致的效率问题。

Method: 引入增量广义混合A*（IGHA*），动态组织顶点扩展而不依赖刚性修剪，适用于复杂动力学路径规划。

Result: IGHA*在模拟和实际实验中，相比优化版HA*，扩展次数减少6倍，实现实时性能。

Conclusion: IGHA*显著提升路径规划效率，适用于复杂动力学场景，可实现实时性能和鲁棒性。

Abstract: We address the problem of efficiently organizing search over very large
trees, which arises in many applications ranging from autonomous driving to
aerial vehicles. Here, we are motivated by off-road autonomy, where real-time
planning is essential. Classical approaches use graphs of motion primitives and
exploit dominance to mitigate the curse of dimensionality and prune expansions
efficiently. However, for complex dynamics, repeatedly solving two-point
boundary-value problems makes graph construction too slow for fast kinodynamic
planning. Hybrid A* (HA*) addressed this challenge by searching over a tree of
motion primitives and introducing approximate pruning using a grid-based
dominance check. However, choosing the grid resolution is difficult: too coarse
risks failure, while too fine leads to excessive expansions and slow planning.
We propose Incremental Generalized Hybrid A* (IGHA*), an anytime tree-search
framework that dynamically organizes vertex expansions without rigid pruning.
IGHA* provably matches or outperforms HA*. For both on-road kinematic and
off-road kinodynamic planning queries for a car-like robot, variants of IGHA*
use 6x fewer expansions to the best solution compared to an optimized version
of HA*. In simulated off-road experiments in a high fidelity simulator, IGHA*
outperforms HA*M when both are used in the loop with a model predictive
controller. We demonstrate real-time performance both in simulation and on a
small-scale off-road vehicle, enabling fast, robust planning under complex
dynamics. Code: https://github.com/personalrobotics/IGHAStar

</details>


### [10] [Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of Bipedal Navigation using Benders Decomposition](https://arxiv.org/abs/2508.13407)
*Jiming Ren,Xuan Lin,Roman Mineyev,Karen M. Feigh,Samuel Coogan,Ye Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于Benders分解的方法，用于解决双足机器人运动规划中的混合整数规划问题，通过迭代切割平面技术，显著提高了规划速度。


<details>
  <summary>Details</summary>
Motivation: 双足机器人运动规划中的混合整数规划问题因非凸约束（如运动可达性和步态旋转）导致计算复杂度极高，传统方法难以高效求解。

Method: 采用Benders分解技术，将问题分为主问题（任务规划）和子问题（运动学和动力学可行性检查），通过迭代切割平面优化。

Result: 实验表明，该方法在处理非线性约束时比传统算法规划速度更快。

Conclusion: Benders分解为解决复杂任务与运动规划问题提供了一种高效解决方案。

Abstract: Task and motion planning under Signal Temporal Logic constraints is known to
be NP-hard. A common class of approaches formulates these hybrid problems,
which involve discrete task scheduling and continuous motion planning, as
mixed-integer programs (MIP). However, in applications for bipedal locomotion,
introduction of non-convex constraints such as kinematic reachability and
footstep rotation exacerbates the computational complexity of MIPs. In this
work, we present a method based on Benders Decomposition to address scenarios
where solving the entire monolithic optimization problem is prohibitively
intractable. Benders Decomposition proposes an iterative cutting-plane
technique that partitions the problem into a master problem to prototype a plan
that meets the task specification, and a series of subproblems for kinematics
and dynamics feasibility checks. Our experiments demonstrate that this method
achieves faster planning compared to alternative algorithms for solving the
resulting optimization program with nonlinear constraints.

</details>


### [11] [Switch4EAI: Leveraging Console Game Platform for Benchmarking Robotic Athletics](https://arxiv.org/abs/2508.13444)
*Tianyu Li,Jeonghwan Kim,Wontaek Kim,Donghoon Baek,Seungeun Rho,Sehoon Ha*

Main category: cs.RO

TL;DR: 论文提出了一种低成本且易部署的管道Switch4EAI，利用体感游戏评估全身机器人控制策略，并在人形机器人Unitree G1上验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化基准来评估机器人运动性能，Switch4EAI旨在填补这一空白，通过与人类玩家直接比较，为机器人性能提供定量基准。

Method: 通过Nintendo Switch游戏（如Just Dance）捕捉、重建并重新定向舞蹈动作，供机器人执行，利用开源全身控制器验证系统。

Result: 在Unitree G1人形机器人上的实验证明了该系统的可行性，并为机器人性能提供了量化基准。

Conclusion: Switch4EAI展示了商用游戏平台作为物理基准的潜力，并为未来评估具身AI提供了新方向。

Abstract: Recent advances in whole-body robot control have enabled humanoid and legged
robots to execute increasingly agile and coordinated movements. However,
standardized benchmarks for evaluating robotic athletic performance in
real-world settings and in direct comparison to humans remain scarce. We
present Switch4EAI(Switch-for-Embodied-AI), a low-cost and easily deployable
pipeline that leverages motion-sensing console games to evaluate whole-body
robot control policies. Using Just Dance on the Nintendo Switch as a
representative example, our system captures, reconstructs, and retargets
in-game choreography for robotic execution. We validate the system on a Unitree
G1 humanoid with an open-source whole-body controller, establishing a
quantitative baseline for the robot's performance against a human player. In
the paper, we discuss these results, which demonstrate the feasibility of using
commercial games platform as physically grounded benchmarks and motivate future
work to for benchmarking embodied AI.

</details>


### [12] [CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models](https://arxiv.org/abs/2508.13446)
*Catherine Glossop,William Chen,Arjun Bhorkar,Dhruv Shah,Sergey Levine*

Main category: cs.RO

TL;DR: 论文提出了一种通过生成反事实标签来增强机器人数据集的方法，以提升视觉-语言-动作模型执行细粒度指令的能力。实验结果显示了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在执行用户细粒度指令时表现不佳，主要是由于机器人数据集中缺乏语义多样性和语言基础。

Method: 利用视觉语言模型生成反事实标签，增强数据集的多样性和细粒度任务的语言基础。

Result: 实验显示，反事实重标记显著提升了模型遵循指令的能力，导航任务的成功率提高了27%。

Conclusion: 无需额外数据收集，该方法显著提升了模型的性能，使其达到与最先进方法竞争的水平。

Abstract: Generalist robots should be able to understand and follow user instructions,
but current vision-language-action (VLA) models struggle with following
fine-grained commands despite providing a powerful architecture for mapping
open-vocabulary natural language instructions to robot actions. One cause for
this is a lack of semantic diversity and language grounding in existing robot
datasets and, specifically, a lack of fine-grained task diversity for similar
observations. To address this, we present a novel method to augment existing
robot datasets by leveraging vision language models to create counterfactual
labels. Our method improves the language-following capabilities of VLAs by
increasing the diversity and granularity of language grounding for robot
datasets by generating counterfactual language and actions. We evaluate the
resulting model's ability to follow language instructions, ranging from simple
object-centric commands to complex referential tasks, by conducting visual
language navigation experiments in 3 different indoor and outdoor environments.
Our experiments demonstrate that counterfactual relabeling, without any
additional data collection, significantly improves instruction-following in VLA
policies, making them competitive with state-of-the-art methods and increasing
success rate by 27% on navigation tasks.

</details>


### [13] [Modeling and Control of AWOISV: A Filtered Tube-Based MPC Approach for Simultaneous Tracking of Lateral Position and Heading Angle](https://arxiv.org/abs/2508.13457)
*Xu Yang,Jun Ni,Hengyang Feng,Feiyu Wang,Tiezhen Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种全轮全向独立转向车辆（AWOISV）的广义动态模型和控制策略，实现高精度位置和航向角跟踪。


<details>
  <summary>Details</summary>
Motivation: 研究全轮全向独立转向车辆（AWOISV）的独特机动性需求，提出通用动态模型和鲁棒控制方法。

Method: 基于瞬时旋转中心定义运动模式，开发广义动态模型，并设计滤波管基线性时变MPC（FT-LTVMPC）控制策略。

Result: 通过仿真和硬件在环实验验证，FT-LTVMPC实现高精度控制和实时性能。

Conclusion: 提出的FT-LTVMPC方法有效解决了AWOISV的多模式运动和鲁棒控制问题。

Abstract: An all-wheel omni-directional independent steering vehicle (AWOISV) is a
specialized all-wheel independent steering vehicle with each wheel capable of
steering up to 90{\deg}, enabling unique maneuvers like yaw and diagonal
movement. This paper introduces a theoretical steering radius angle and
sideslip angle (\( \theta_R \)-\(\beta_R \)) representation, based on the
position of the instantaneous center of rotation relative to the wheel rotation
center, defining the motion modes and switching criteria for AWOISVs. A
generalized \( v\)-\(\beta\)-\(r \) dynamic model is developed with forward
velocity \(v\), sideslip angle \(\beta\), and yaw rate \(r\) as states, and
\(\theta_R\) and \(\beta_R\) as control inputs. This model decouples
longitudinal and lateral motions into forward and rotational motions, allowing
seamless transitions across all motion modes under specific conditions. A
filtered tube-based linear time-varying MPC (FT-LTVMPC) strategy is proposed,
achieving simultaneous tracking of lateral position and arbitrary heading
angles, with robustness to model inaccuracies and parameter uncertainties.
Co-simulation and hardware-in-loop (HIL) experiments confirm that FT-LTVMPC
enables high-precision control of both position and heading while ensuring
excellent real-time performance.

</details>


### [14] [Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms](https://arxiv.org/abs/2508.13459)
*Rohan Chandra,Shubham Singh,Abhishek Jha,Dannon Andrade,Hriday Sainathuni,Katia Sycara*

Main category: cs.RO

TL;DR: 本文探讨了“最后一英里挑战”中“社交迷你游戏（SMGs）”的导航问题，提出需要专门的分类和评价标准。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人导航方法在SMGs中表现不佳，且现有研究假设和目标不一致，需要统一框架。

Method: 首次提出使用明确定义的分类法对SMG导航方法进行系统分类和评价。

Result: 建立了统一的SMG导航研究框架，为未来研究提供了基础。

Conclusion: 统一的分类和评价标准有助于推动SMG导航研究的进一步发展。

Abstract: The ``Last Mile Challenge'' has long been considered an important, yet
unsolved, challenge for autonomous vehicles, public service robots, and
delivery robots. A central issue in this challenge is the ability of robots to
navigate constrained and cluttered environments (e.g., doorways, hallways,
corridor intersections), often while competing for space with other robots and
humans. We refer to these environments as ``Social Mini-Games'' (SMGs). SMGs
are tightly coupled, high-agency interactions that arise within general
multi-robot navigation (MRN) scenarios. They are identified through certain
distinct characteristics and require specialized metrics to evaluate them.
Traditional navigation approaches designed for MRN do not perform well in SMGs,
which has led to focused research on dedicated SMG solvers (navigation methods
specialized to navigate in SMGs), which has flourished in recent years.
However, publications on SMG navigation research make different assumptions (on
centralized versus decentralized, observability, communication, cooperation,
etc.), and have different objective functions (safety versus liveness). These
assumptions and objectives are sometimes implicitly assumed or described
informally. This makes it difficult to establish appropriate baselines for
comparison in research papers, as well as making it difficult for practitioners
to find the papers relevant to their concrete application. Such ad-hoc
representation of the field also presents a barrier to new researchers wanting
to start research in this area. SMG navigation research requires its own
taxonomy, definitions, and evaluation protocols to guide effective research
moving forward. This survey is the first to catalog SMG solvers using a
well-defined and unified taxonomy and to classify existing methods accordingly.

</details>


### [15] [ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments](https://arxiv.org/abs/2508.13488)
*Jingwen Yu,Jiayi Yang,Anjun Hu,Jiankun Wang,Ping Tan,Hong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为ROVER的闭环验证方法，利用历史轨迹作为先验约束，在重复环境中减少误检测。


<details>
  <summary>Details</summary>
Motivation: 现有闭环验证方法主要依赖外观特征，忽略了机器人的时空运动线索（轨迹），导致在重复环境中误检率高。

Method: ROVER通过位姿图优化估计轨迹，并利用评分机制评估闭环候选是否与无闭环的轨迹先验一致。

Result: 实验表明，ROVER在基准测试和真实环境中均有效，且成功集成到先进SLAM系统中。

Conclusion: ROVER通过结合轨迹先验，有效提升了闭环验证的准确性和鲁棒性。

Abstract: Loop closure detection is important for simultaneous localization and mapping
(SLAM), which associates current observations with historical keyframes,
achieving drift correction and global relocalization. However, a falsely
detected loop can be fatal, and this is especially difficult in repetitive
environments where appearance-based features fail due to the high similarity.
Therefore, verification of a loop closure is a critical step in avoiding false
positive detections. Existing works in loop closure verification predominantly
focus on learning invariant appearance features, neglecting the prior knowledge
of the robot's spatial-temporal motion cue, i.e., trajectory. In this letter,
we propose ROVER, a loop closure verification method that leverages the
historical trajectory as a prior constraint to reject false loops in
challenging repetitive environments. For each loop candidate, it is first used
to estimate the robot trajectory with pose-graph optimization. This trajectory
is then submitted to a scoring scheme that assesses its compliance with the
trajectory without the loop, which we refer to as the trajectory prior, to
determine if the loop candidate should be accepted. Benchmark comparisons and
real-world experiments demonstrate the effectiveness of the proposed method.
Furthermore, we integrate ROVER into state-of-the-art SLAM systems to verify
its robustness and efficiency. Our source code and self-collected dataset are
available at https://github.com/jarvisyjw/ROVER.

</details>


### [16] [Unified Hierarchical MPC in Task Executing for Modular Manipulators across Diverse Morphologies](https://arxiv.org/abs/2508.13513)
*Maolin Lei,Edoardo Romiti,Arturo Laurenzi,Cheng Zhou,Wanli Xing,Liang Lu,Nikos G. Tsagarakis*

Main category: cs.RO

TL;DR: 提出了一种统一的分层模型预测控制（H-MPC）方法，适用于不同形态的模块化机械臂，无需大量参数调整即可适应不同配置执行任务。


<details>
  <summary>Details</summary>
Motivation: 解决模块化机械臂在不同形态下的控制问题，减少控制器参数调整的复杂性。

Method: 将控制过程分为高层和低层MPC：高层预测未来状态并提供轨迹信息，低层基于高层信息优化控制动作，同时引入二次线性化提高模型精度。

Result: 实验验证了该方法在不同形态机械臂上的有效性，成功执行了实际场景中的取放任务。

Conclusion: H-MPC通过分层结构和二次线性化，提高了控制精度和可靠性，适用于多样化的机械臂配置。

Abstract: This work proposes a unified Hierarchical Model Predictive Control (H-MPC)
for modular manipulators across various morphologies, as the controller can
adapt to different configurations to execute the given task without extensive
parameter tuning in the controller. The H-MPC divides the control process into
two levels: a high-level MPC and a low-level MPC. The high-level MPC predicts
future states and provides trajectory information, while the low-level MPC
refines control actions by updating the predictive model based on this
high-level information. This hierarchical structure allows for the integration
of kinematic constraints and ensures smooth joint-space trajectories, even near
singular configurations. Moreover, the low-level MPC incorporates secondary
linearization by leveraging predictive information from the high-level MPC,
effectively capturing the second-order Taylor expansion information of the
kinematic model while still maintaining a linearized model formulation. This
approach not only preserves the simplicity of a linear control model but also
enhances the accuracy of the kinematic representation, thereby improving
overall control precision and reliability. To validate the effectiveness of the
control policy, we conduct extensive evaluations across different manipulator
morphologies and demonstrate the execution of pick-and-place tasks in
real-world scenarios.

</details>


### [17] [A Three-Level Whole-Body Disturbance Rejection Control Framework for Dynamic Motions in Legged Robots](https://arxiv.org/abs/2508.13531)
*Bolin Li,Gewei Zuo,Zhixiang Wang,Xiaotian Ke,Lijun Zhu,Han Ding*

Main category: cs.RO

TL;DR: 本文提出了一种控制框架，通过三级全身扰动抑制控制（T-WB-DRC）和新型移动水平扩展状态观测器（MH-ESO），提高了腿式机器人在不确定条件下的稳定性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在面对模型不确定性、外部扰动和故障时，需要更稳定和鲁棒的控制方法。

Method: 提出MH-ESO用于估计不确定性并抑制噪声，设计T-WB-DRC框架以同时考虑无扰动和有扰动的动态规划。

Result: 仿真和实验验证了T-WB-DRC在提高稳定性、鲁棒性和容错性方面的有效性。

Conclusion: T-WB-DRC显著提升了腿式机器人在不确定环境中的性能，适用于多种扰动条件。

Abstract: This paper presents a control framework designed to enhance the stability and
robustness of legged robots in the presence of uncertainties, including model
uncertainties, external disturbances, and faults. The framework enables the
full-state feedback estimator to estimate and compensate for uncertainties in
whole-body dynamics of the legged robots. First, we propose a novel moving
horizon extended state observer (MH-ESO) to estimate uncertainties and mitigate
noise in legged systems, which can be integrated into the framework for
disturbance compensation. Second, we introduce a three-level whole-body
disturbance rejection control framework (T-WB-DRC). Unlike the previous
two-level approach, this three-level framework considers both the plan based on
whole-body dynamics without uncertainties and the plan based on dynamics with
uncertainties, significantly improving payload transportation, external
disturbance rejection, and fault tolerance. Third, simulations of both humanoid
and quadruped robots in the Gazebo simulator demonstrate the effectiveness and
versatility of T-WB-DRC. Finally, extensive experimental trials on a quadruped
robot validate the robustness and stability of the system when using T-WB-DRC
under various disturbance conditions.

</details>


### [18] [MimicFunc: Imitating Tool Manipulation from a Single Human Video via Functional Correspondence](https://arxiv.org/abs/2508.13534)
*Chao Tang,Anxing Xiao,Yuhong Deng,Tianrun Hu,Wenlong Dong,Hanbo Zhang,David Hsu,Hong Zhang*

Main category: cs.RO

TL;DR: MimicFunc框架通过功能帧实现机器人从单一人机视频中模仿工具操作技能，并推广到新工具。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过观察快速模仿工具操作技能并将其推广到不同工具，而机器人目前难以达到这种泛化水平。

Method: 提出MimicFunc框架，利用功能帧（基于关键点的抽象）建立功能级对应关系。

Result: 实验证明MimicFunc能有效实现单次RGB-D视频的技能泛化，并用于训练视觉运动策略。

Conclusion: MimicFunc为解决工具几何差异带来的功能对应问题提供了可行方案，并减少对人工标注数据的依赖。

Abstract: Imitating tool manipulation from human videos offers an intuitive approach to
teaching robots, while also providing a promising and scalable alternative to
labor-intensive teleoperation data collection for visuomotor policy learning.
While humans can mimic tool manipulation behavior by observing others perform a
task just once and effortlessly transfer the skill to diverse tools for
functionally equivalent tasks, current robots struggle to achieve this level of
generalization. A key challenge lies in establishing function-level
correspondences, considering the significant geometric variations among
functionally similar tools, referred to as intra-function variations. To
address this challenge, we propose MimicFunc, a framework that establishes
functional correspondences with function frame, a function-centric local
coordinate frame constructed with keypoint-based abstraction, for imitating
tool manipulation skills. Experiments demonstrate that MimicFunc effectively
enables the robot to generalize the skill from a single RGB-D human video to
manipulating novel tools for functionally equivalent tasks. Furthermore,
leveraging MimicFunc's one-shot generalization capability, the generated
rollouts can be used to train visuomotor policies without requiring
labor-intensive teleoperation data collection for novel objects. Our code and
video are available at https://sites.google.com/view/mimicfunc.

</details>


### [19] [Assessing Pedestrian Behavior Around Autonomous Cleaning Robots in Public Spaces: Findings from a Field Observation](https://arxiv.org/abs/2508.13699)
*Maren Raab,Linda Miller,Zhe Zeng,Pascal Jansen,Martin Baumann,Johannes Kraus*

Main category: cs.RO

TL;DR: 研究探讨了不同类型和移动方式的自主清洁机器人对分散和未分散行人行为的影响，发现行人对机器人的行为反应主要受机器人大小和移动模式影响，而非注意力状态。


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共场所的普及，如何设计机器人的通信策略以增强透明度和减少临界情况变得重要。本研究旨在填补关于机器人与行人行为交互的研究空白。

Method: 通过实地观察，记录行人与两种自主清洁机器人（大小不同、移动模式不同）互动时的行为，分析分散和未分散行人的反应。

Result: 行人的注意力状态（是否分心）对行为无显著影响，但机器人大小和移动模式（如矩形偏移路径）显著影响行人的横向调整。

Conclusion: 研究为公共场所机器人与行人互动的设计提供了初步见解，强调了机器人物理特性和移动模式的重要性。

Abstract: As autonomous robots become more common in public spaces, spontaneous
encounters with laypersons are more frequent. For this, robots need to be
equipped with communication strategies that enhance momentary transparency and
reduce the probability of critical situations. Adapting these robotic
strategies requires consideration of robot movements, environmental conditions,
and user characteristics and states. While numerous studies have investigated
the impact of distraction on pedestrians' movement behavior, limited research
has examined this behavior in the presence of autonomous robots. This research
addresses the impact of robot type and robot movement pattern on distracted and
undistracted pedestrians' movement behavior. In a field setting, unaware
pedestrians were videotaped while moving past two working, autonomous cleaning
robots. Out of N=498 observed pedestrians, approximately 8% were distracted by
smartphones. Distracted and undistracted pedestrians did not exhibit
significant differences in their movement behaviors around the robots. Instead,
both the larger sweeping robot and the offset rectangular movement pattern
significantly increased the number of lateral adaptations compared to the
smaller cleaning robot and the circular movement pattern. The offset
rectangular movement pattern also led to significantly more close lateral
adaptations. Depending on the robot type, the movement patterns led to
differences in the distances of lateral adaptations. The study provides initial
insights into pedestrian movement behavior around an autonomous cleaning robot
in public spaces, contributing to the growing field of HRI research.

</details>


### [20] [Blast Hole Seeking and Dipping -- The Navigation and Perception Framework in a Mine Site Inspection Robot](https://arxiv.org/abs/2508.13785)
*Liyang Liu,Ehsan Mihankhah,Nathan Wallace,Javier Martinez,Andrew J. Hill*

Main category: cs.RO

TL;DR: 论文提出了一种自主爆破孔检测机器人系统“DIPPeR”，通过LiDAR和图像处理技术实现精准定位和导航，显著提高了露天矿坑爆破孔检测的效率。


<details>
  <summary>Details</summary>
Motivation: 传统人工检测爆破孔效率低、成本高且难以获取孔洞的几何和地质特性，因此需要开发自主检测系统以优化物料处理成本。

Method: 结合LiDAR点云数据处理，提取爆破孔的三维锥形区域，并通过虚拟深度图像实现2D分割，利用检测模块精准定位孔中心，实现自主导航与传感器定位。

Result: 系统在高保真仿真和实地测试中均表现出色，能够持续跟踪目标孔洞并完成精准检测。

Conclusion: DIPPeR系统通过自动化技术显著提升了爆破孔检测的效率和精度，为露天矿坑的物料管理提供了有效解决方案。

Abstract: In open-pit mining, holes are drilled into the surface of the excavation site
and detonated with explosives to facilitate digging. These blast holes need to
be inspected internally for investigation of downhole material types and
properties. Knowing these properties can lead to significant savings in
material handling costs in downstream processes. Manual hole inspection is slow
and expensive, with major limitations in revealing the geometric and geological
properties of the holes and their contents. This has been the motivation for
the development of our autonomous mine-site inspection robot - "DIPPeR". In
this paper, the automation aspect of the project is explained. We present a
robust blast hole seeking and detection framework that enables target-based
navigation and accurate down-hole sensor positioning. The pipeline first
processes point-cloud data collected by the on-board LiDAR sensors, extracting
the cone-shaped volume of drill-waste above the ground. By projecting the 3D
cone points into a virtual depth image, segmentation is achieved in the 2D
domain, yielding a circular hole at the image centre and a collared cone face.
We then identify the hole centre using a robust detection module while
suppressing non-maximum candidates, ensuring precise sensor placement for
down-hole inspection and avoiding collisions with the cavity wall. To enable
autonomous hole-seeking, the pipeline automatically adjusts its projection
parameters during robot navigation to account for variations in point sparsity
and hole opening size, ensuring a consistent hole appearance in 2D images. This
allows continuous tracking of the target hole as the robot approaches the goal
point. We demonstrate the effectiveness of our navigation and perception system
in both high-fidelity simulation environments and on-site field tests. A
demonstration video is available at
"https://www.youtube.com/watch?v=fRNbcBcaSqE".

</details>


### [21] [Trajectory Tracking and Stabilization of Quadrotors Using Deep Koopman Model Predictive Control](https://arxiv.org/abs/2508.13795)
*Haitham El-Hussieny*

Main category: cs.RO

TL;DR: 本文提出了一种结合深度Koopman算子和模型预测控制（DK-MPC）的数据驱动控制框架，用于四旋翼系统，展现了更高的跟踪精度和更低计算成本的优势。


<details>
  <summary>Details</summary>
Motivation: 为了解决四旋翼非线性动力学控制中的复杂性和实时性问题，提出了一种基于数据驱动的方法，以实现更高效和准确的控制。

Method: 训练深度Koopman算子从飞行数据中学习高维线性表示，并将其与模型预测控制（MPC）结合，实现非线性动力学的线性化控制。

Result: 在轨迹跟踪和点稳定实验中，DK-MPC表现出比传统非线性MPC更高的跟踪精度和更低的计算时间。

Conclusion: Koopman学习方法在处理复杂四旋翼动力学时具有潜力，未来将优化框架以应对更敏捷的飞行场景和外部干扰。

Abstract: This paper presents a data-driven control framework for quadrotor systems
that integrates a deep Koopman operator with model predictive control (DK-MPC).
The deep Koopman operator is trained on sampled flight data to construct a
high-dimensional latent representation in which the nonlinear quadrotor
dynamics are approximated by linear models. This linearization enables the
application of MPC to efficiently optimize control actions over a finite
prediction horizon, ensuring accurate trajectory tracking and stabilization.
The proposed DK-MPC approach is validated through a series of
trajectory-following and point-stabilization numerical experiments, where it
demonstrates superior tracking accuracy and significantly lower computation
time compared to conventional nonlinear MPC. These results highlight the
potential of Koopman-based learning methods to handle complex quadrotor
dynamics while meeting the real-time requirements of embedded flight control.
Future work will focus on extending the framework to more agile flight
scenarios and improving robustness against external disturbances.

</details>


### [22] [Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer](https://arxiv.org/abs/2508.13877)
*Rathnam Vidushika Rasanji,Jin Wei-Kocsis,Jiansong Zhang,Dongming Gan,Ragu Athinarayanan,Paul Asunda*

Main category: cs.RO

TL;DR: 论文提出了一种名为SGDT的新框架，结合了神经符号机制和因果变换器，用于多机器人协作任务。


<details>
  <summary>Details</summary>
Motivation: 增强学习在机器人操作中潜力巨大，但其数据密集性和依赖于MDP假设限制了其在复杂动态和长期依赖场景中的应用。

Method: SGDT框架通过神经符号规划器生成高级任务导向计划，指导目标条件决策变换器进行低级序列决策。

Result: SGDT在零样本和少样本任务场景中表现出色，实现了结构化、可解释和可泛化的决策。

Conclusion: SGDT是首个探索基于决策变换器的多机器人操作技术，为解决复杂协作任务提供了新思路。

Abstract: Reinforcement learning (RL) has demonstrated great potential in robotic
operations. However, its data-intensive nature and reliance on the Markov
Decision Process (MDP) assumption limit its practical deployment in real-world
scenarios involving complex dynamics and long-term temporal dependencies, such
as multi-robot manipulation. Decision Transformers (DTs) have emerged as a
promising offline alternative by leveraging causal transformers for sequence
modeling in RL tasks. However, their applications to multi-robot manipulations
still remain underexplored. To address this gap, we propose a novel framework,
Symbolically-Guided Decision Transformer (SGDT), which integrates a
neuro-symbolic mechanism with a causal transformer to enable deployable
multi-robot collaboration. In the proposed SGDT framework, a neuro-symbolic
planner generates a high-level task-oriented plan composed of symbolic
subgoals. Guided by these subgoals, a goal-conditioned decision transformer
(GCDT) performs low-level sequential decision-making for multi-robot
manipulation. This hierarchical architecture enables structured, interpretable,
and generalizable decision making in complex multi-robot collaboration tasks.
We evaluate the performance of SGDT across a range of task scenarios, including
zero-shot and few-shot scenarios. To our knowledge, this is the first work to
explore DT-based technology for multi-robot manipulation.

</details>


### [23] [Driving Style Recognition Like an Expert Using Semantic Privileged Information from Large Language Models](https://arxiv.org/abs/2508.13881)
*Zhaokun Chen,Chaopeng Zhang,Xiaohan Li,Wenshuo Wang,Gentiane Venture,Junqiang Xi*

Main category: cs.RO

TL;DR: 本文提出一种新框架，通过整合大语言模型生成的语义特权信息（SPI），将驾驶行为识别与人类可理解的推理对齐，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶风格识别系统依赖低层传感器特征，忽略了人类专家的语义推理能力，导致算法分类与专家判断不一致。

Method: 提出DriBehavGPT模块生成自然语言描述，通过嵌入和降维将其转换为机器学习可处理的表示，并结合SVM+进行训练。

Result: 实验表明，该框架在多种驾驶场景中表现优异，F1分数提升7.6%（跟车）和7.9%（变道）。

Conclusion: 语义行为表征对提高识别准确性和推动以人为本的驾驶系统至关重要，且训练后仅需传感器数据推理。

Abstract: Existing driving style recognition systems largely depend on low-level
sensor-derived features for training, neglecting the rich semantic reasoning
capability inherent to human experts. This discrepancy results in a fundamental
misalignment between algorithmic classifications and expert judgments. To
bridge this gap, we propose a novel framework that integrates Semantic
Privileged Information (SPI) derived from large language models (LLMs) to align
recognition outcomes with human-interpretable reasoning. First, we introduce
DriBehavGPT, an interactive LLM-based module that generates natural-language
descriptions of driving behaviors. These descriptions are then encoded into
machine learning-compatible representations via text embedding and
dimensionality reduction. Finally, we incorporate them as privileged
information into Support Vector Machine Plus (SVM+) for training, enabling the
model to approximate human-like interpretation patterns. Experiments across
diverse real-world driving scenarios demonstrate that our SPI-enhanced
framework outperforms conventional methods, achieving F1-score improvements of
7.6% (car-following) and 7.9% (lane-changing). Importantly, SPI is exclusively
used during training, while inference relies solely on sensor data, ensuring
computational efficiency without sacrificing performance. These results
highlight the pivotal role of semantic behavioral representations in improving
recognition accuracy while advancing interpretable, human-centric driving
systems.

</details>


### [24] [Multimodal Data Storage and Retrieval for Embodied AI: A Survey](https://arxiv.org/abs/2508.13901)
*Yihao Lu,Hao Tang*

Main category: cs.RO

TL;DR: 这篇论文系统地评估了五种存储架构和五种检索范式，以解决具身AI（EAI）的数据管理需求，揭示了长期语义一致性与实时响应性之间的权衡，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的数据管理系统难以处理具身AI生成的多模态、动态扩展的数据流，因此需要探索更适合的存储和检索方案。

Method: 论文通过对180多项相关研究的综述，评估了五种存储架构和五种检索范式的适用性，并分析了其对EAI核心需求的满足程度。

Result: 研究发现，存储和检索在满足EAI需求时存在关键瓶颈，如物理基础差距、跨模态集成挑战等，并提出了未来研究方向。

Conclusion: 论文为未来具身AI的高性能数据管理框架设计提供了严格的研究路线图和标准化基准测试建议。

Abstract: Embodied AI (EAI) agents continuously interact with the physical world,
generating vast, heterogeneous multimodal data streams that traditional
management systems are ill-equipped to handle. In this survey, we first
systematically evaluate five storage architectures (Graph Databases,
Multi-Model Databases, Data Lakes, Vector Databases, and Time-Series
Databases), focusing on their suitability for addressing EAI's core
requirements, including physical grounding, low-latency access, and dynamic
scalability. We then analyze five retrieval paradigms (Fusion Strategy-Based
Retrieval, Representation Alignment-Based Retrieval, Graph-Structure-Based
Retrieval, Generation Model-Based Retrieval, and Efficient Retrieval-Based
Optimization), revealing a fundamental tension between achieving long-term
semantic coherence and maintaining real-time responsiveness. Based on this
comprehensive analysis, we identify key bottlenecks, spanning from the
foundational Physical Grounding Gap to systemic challenges in cross-modal
integration, dynamic adaptation, and open-world generalization. Finally, we
outline a forward-looking research agenda encompassing physics-aware data
models, adaptive storage-retrieval co-optimization, and standardized
benchmarking, to guide future research toward principled data management
solutions for EAI. Our survey is based on a comprehensive review of more than
180 related studies, providing a rigorous roadmap for designing the robust,
high-performance data management frameworks essential for the next generation
of autonomous embodied systems.

</details>


### [25] [Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation](https://arxiv.org/abs/2508.13964)
*Martijn Cramer,Yanming Wu,David De Schepper,Eric Demeester*

Main category: cs.RO

TL;DR: 论文探讨了利用3D物体识别和定位技术将协作机器人转化为移动可重构生产助手的机遇与挑战，并以实际案例为参考。


<details>
  <summary>Details</summary>
Motivation: 高混合低批量生产模式下，中小企业面临小批量多变订单的挑战，标准自动化解决方案难以满足需求，导致生产效率低下和技术人才潜能未被充分释放。

Method: 通过整合3D物体识别和定位等现有技术，将协作机器人转化为移动可重构的生产助手，并结合实际案例进行验证。

Result: 研究展示了在工业环境中增强协作机器人系统的可行性和关键步骤。

Conclusion: 该项目为中小企业提供了可行的自动化解决方案，优化生产流程并提升技术人才利用率。

Abstract: Due to high-mix-low-volume production, sheet-metal workshops today are
challenged by small series and varying orders. As standard automation solutions
tend to fall short, SMEs resort to repetitive manual labour impacting
production costs and leading to tech-skilled workforces not being used to their
full potential. The COOCK+ ROBUST project aims to transform cobots into mobile
and reconfigurable production assistants by integrating existing technologies,
including 3D object recognition and localisation. This article explores both
the opportunities and challenges of enhancing cobotic systems with these
technologies in an industrial setting, outlining the key steps involved in the
process. Additionally, insights from a past project, carried out by the ACRO
research unit in collaboration with an industrial partner, serves as a concrete
implementation example throughout.

</details>


### [26] [Toward an Interaction-Centered Approach to Robot Trustworthiness](https://arxiv.org/abs/2508.13976)
*Carlo Mazzola,Hassan Ali,Kristína Malinovská,Igor Farkaš*

Main category: cs.RO

TL;DR: 提出了一个基于交互的框架，通过人类与机器人之间的相互理解来建立信任，强调人类意识和透明度，并引入四个关键组件以减少信任与实际能力之间的差距。


<details>
  <summary>Details</summary>
Motivation: 随着机器人更多地融入人类环境，建立可信赖的机器人代理对于安全有效的人机交互至关重要。

Method: 提出了一个交互框架，包括人类意识和透明度两大支柱，以及四个关键组件。

Result: 通过该框架，机器人可以更好地满足人类期望，同时让人类理解和控制机器人行为。

Conclusion: 该框架有助于减少人类与机器人之间的信任偏差，提升人机交互的安全性与效果。

Abstract: As robots get more integrated into human environments, fostering
trustworthiness in embodied robotic agents becomes paramount for an effective
and safe human-robot interaction (HRI). To achieve that, HRI applications must
promote human trust that aligns with robot skills and avoid misplaced trust or
overtrust, which can pose safety risks and ethical concerns. To achieve that,
HRI applications must promote human trust that aligns with robot skills and
avoid misplaced trust or overtrust, which can pose safety risks and ethical
concerns. In this position paper, we outline an interaction-based framework for
building trust through mutual understanding between humans and robots. We
emphasize two main pillars: human awareness and transparency, referring to the
robot ability to interpret human actions accurately and to clearly communicate
its intentions and goals, respectively. By integrating these two pillars,
robots can behave in a manner that aligns with human expectations and needs
while providing their human partners with both comprehension and control over
their actions. We also introduce four components that we think are important
for bridging the gap between a human-perceived sense of trust and a robot true
capabilities.

</details>


### [27] [The Social Context of Human-Robot Interactions](https://arxiv.org/abs/2508.13982)
*Sydney Thompson,Kate Candon,Marynel Vázquez*

Main category: cs.RO

TL;DR: 该论文通过调查HRI文献中“社交情境”的定义和使用，提出了一个描述人机交互社交情境的概念模型，并探讨了其应用和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: HRI领域中“社交情境”一词使用不统一，导致沟通障碍和研究难以连接，因此需要明确其定义和模型。

Method: 通过文献调查梳理“社交情境”的现有定义和使用，提出一个概念模型，并将其应用于现有研究。

Result: 提出了一个社交情境的概念模型，帮助研究人员规划交互、开发机器人行为模型及事后分析。

Conclusion: 总结了社交情境建模的开放研究问题，为未来研究提供了方向。

Abstract: The Human-Robot Interaction (HRI) community often highlights the social
context of an interaction as a key consideration when designing, implementing,
and evaluating robot behavior. Unfortunately, researchers use the term "social
context" in varied ways. This can lead to miscommunication, making it
challenging to draw connections between related work on understanding and
modeling the social contexts of human-robot interactions. To address this gap,
we survey the HRI literature for existing definitions and uses of the term
"social context". Then, we propose a conceptual model for describing the social
context of a human-robot interaction. We apply this model to existing work, and
we discuss a range of attributes of social contexts that can help researchers
plan for interactions, develop behavior models for robots, and gain insights
after interactions have taken place. We conclude with a discussion of open
research questions in relation to understanding and modeling the social
contexts of human-robot interactions.

</details>


### [28] [Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation](https://arxiv.org/abs/2508.13998)
*Yifu Yuan,Haiqin Cui,Yaoting Huang,Yibin Chen,Fei Ni,Zibin Dong,Pengyi Li,Yan Zheng,Jianye Hao*

Main category: cs.RO

TL;DR: 该论文提出了一种基于“指向”作为统一中间表示的解决方案，以解决具身AI中的“看到到做到”差距问题。通过设计Embodied-R1模型和大型数据集Embodied-Points-200K，结合强化微调方法，模型在多个基准测试中表现出色，并展现出强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中因数据稀缺和具身异构性导致的泛化问题，通过统一的中间表示“指向”来弥合视觉语言理解与低级动作之间的差距。

Method: 提出Embodied-R1模型，构建大型数据集Embodied-Points-200K，采用两阶段强化微调（RFT）训练方法。

Result: 模型在11个具身空间和指向基准测试中达到最优性能，零样本泛化能力显著（SIMPLEREnv中56.2%成功率，8个XArm任务中87.5%成功率），62%的相对性能提升。

Conclusion: 指向为中心的表示与RFT训练范式为机器人中感知-动作差距提供了高效且可泛化的解决方案。

Abstract: Generalization in embodied AI is hindered by the "seeing-to-doing gap," which
stems from data scarcity and embodiment heterogeneity. To address this, we
pioneer "pointing" as a unified, embodiment-agnostic intermediate
representation, defining four core embodied pointing abilities that bridge
high-level vision-language comprehension with low-level action primitives. We
introduce Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed
for embodied reasoning and pointing. We use a wide range of embodied and
general visual reasoning datasets as sources to construct a large-scale
dataset, Embodied-Points-200K, which supports key embodied pointing
capabilities. We then train Embodied-R1 using a two-stage Reinforced
Fine-tuning (RFT) curriculum with a specialized multi-task reward design.
Embodied-R1 achieves state-of-the-art performance on 11 embodied spatial and
pointing benchmarks. Critically, it demonstrates robust zero-shot
generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5%
across 8 real-world XArm tasks without any task-specific fine-tuning,
representing a 62% improvement over strong baselines. Furthermore, the model
exhibits high robustness against diverse visual disturbances. Our work shows
that a pointing-centric representation, combined with an RFT training paradigm,
offers an effective and generalizable pathway to closing the perception-action
gap in robotics.

</details>


### [29] [Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation](https://arxiv.org/abs/2508.14042)
*Zhuoling Li,Xiaoyang Wu,Zhenhua Xu,Hengshuang Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种名为GEM的熵基理论框架，用于在少量演示的情况下实现动态物体操纵的强泛化能力，实验证明其在不同环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于动态物体操纵在提升制造效率中的重要性，而传统方法需要大量演示，本文旨在探索是否可以通过少量演示实现强泛化能力。

Method: 开发了一个熵基理论框架，并基于该框架提出了GEM系统。

Result: GEM在模拟和真实任务中表现优异，成功应用于真实餐厅的餐具收集任务，成功率超过97%。

Conclusion: GEM证明了在少量演示下实现强泛化能力的可行性，为动态物体操纵提供了高效解决方案。

Abstract: Realizing generalizable dynamic object manipulation is important for
enhancing manufacturing efficiency, as it eliminates specialized engineering
for various scenarios. To this end, imitation learning emerges as a promising
paradigm, leveraging expert demonstrations to teach a policy manipulation
skills. Although the generalization of an imitation learning policy can be
improved by increasing demonstrations, demonstration collection is
labor-intensive. To address this problem, this paper investigates whether
strong generalization in dynamic object manipulation is achievable with only a
few demonstrations. Specifically, we develop an entropy-based theoretical
framework to quantify the optimization of imitation learning. Based on this
framework, we propose a system named Generalizable Entropy-based Manipulation
(GEM). Extensive experiments in simulated and real tasks demonstrate that GEM
can generalize across diverse environment backgrounds, robot embodiments,
motion dynamics, and object geometries. Notably, GEM has been deployed in a
real canteen for tableware collection. Without any in-scene demonstration, it
achieves a success rate of over 97% across more than 10,000 operations.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [30] [Low-power, Energy-efficient, Cardiologist-level Atrial Fibrillation Detection for Wearable Devices](https://arxiv.org/abs/2508.13181)
*Dominik Loroch,Johannes Feldmann,Vladimir Rybalkin,Norbert Wehn*

Main category: cs.AR

TL;DR: 本文提出了一种新型可穿戴设备，通过FPGA和深度学习技术实现低功耗、高精度的房颤检测，性能超越专家水平。


<details>
  <summary>Details</summary>
Motivation: 房颤（AF）是一种常见的心律失常，但其检测技术的普及仍面临挑战，亟需一种可扩展、可靠的解决方案。

Method: 采用FPGA硬件与深度学习算法协同设计，结合硬件感知的神经架构搜索优化功耗管理。

Result: 设备功耗低至3.8mW，可连续运行三周以上，检测准确率达95%，优于专家水平。

Conclusion: 该设备为房颤监测的可扩展性和可持续性提供了重要突破。

Abstract: Atrial fibrillation (AF) is a common arrhythmia and major risk factor for
cardiovascular complications. While commercially available devices and
supporting Artificial Intelligence (AI) algorithms exist for reliable detection
of AF, the scaling of this technology to the amount of people who need this
diagnosis is still a major challenge. This paper presents a novel wearable
device, designed specifically for the early and reliable detection of AF. We
present an FPGA-based patch-style wearable monitor with embedded deep
learning-based AF detection. Operating with 3.8mW system power, which is 1-3
orders of magnitude lower than the state-of-the-art, the device enables
continuous AF detection for over three weeks while achieving 95% accuracy,
surpassing cardiologist-level performance. A key innovation is the combination
of energy-efficient hardware-software co-design and optimized power management
through the application of hardware-aware neural architecture search. This
advancement represents a significant step toward scalable, reliable, and
sustainable AF monitoring.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [31] [Power and Rate Allocations for Positive-rate Covert Communications in Block-Fading Channels](https://arxiv.org/abs/2508.13555)
*Yubo Zhang,Hassan ZivariFard,Xiaodong Wang*

Main category: cs.IT

TL;DR: 提出了一种在瑞利块衰落信道中实现无密钥隐蔽通信的方法，解决了功率分配和速率分配问题。


<details>
  <summary>Details</summary>
Motivation: 研究在信道状态信息（CSI）限制下实现隐蔽通信的需求，特别是在非因果和因果CSI条件下。

Method: 采用三步法解决非因果CSI问题，并使用深度双Q网络（DDQN）方法解决因果CSI问题。

Result: 仿真结果表明所提出的功率和速率分配方法有效，并提供了不同方案之间的性能比较。

Conclusion: 提出的方法在隐蔽通信中表现出色，尤其是非因果CSI条件下的三步法以及因果CSI条件下的DDQN方法。

Abstract: We aim to achieve keyless covert communication with a positive-rate in
Rayleigh block-fading channels. Specifically, the transmitter and the
legitimate receiver are assumed to have either causal or non-causal knowledge
of the \ac{CSI} for both the legitimate and the warden channels, while the
warden only knows the statistical distribution of the \ac{CSI}. Two problem
formulations are considered in this work: (a) Power allocation: maximizing the
sum covert rate subject to a maximum power constraint, and (b) Rate allocation:
minimizing the power consumption subject to a minimum covert rate constraint.
Both problems are formulated based on recent information theoretical results on
covert communication over state-dependent channels. When the \ac{CSI} of each
fading block is known non-causally, we propose a novel three-step method to
solve both the power and rate allocation problems. In the case where the
\ac{CSI} is known causally, the power allocation problem can be formulated as
\ac{MDP} and be solved using a \ac{DDQN} approach. Although the rate allocation
problem under causal \ac{CSI} does not directly conform to an \ac{MDP}
structure, it can be approximately solved using the \ac{DDQN} trained for power
allocation. Simulation results demonstrate the effectiveness of the proposed
power and rate allocation methods and provide comprehensive performance
comparisons across different allocation schemes.

</details>


### [32] [Joint Beamforming Design for RIS-Empowered NOMA-ISAC Systems](https://arxiv.org/abs/2508.13842)
*Chunjie Wang,Xuhui Zhang,Jinke Ren,Wenchao Liu,Shuqiang Wang,Yanyan Shen,Kejiang Ye,Chengzhong Xu,Dusit Niyato*

Main category: cs.IT

TL;DR: 论文研究了RIS辅助的ISAC系统，提出基于NOMA的联合通信与感知波束成形设计，通过优化DFBS的主动波束成形、RIS的反射系数和雷达接收滤波器，最大化用户的总速率。


<details>
  <summary>Details</summary>
Motivation: 为了在RIS辅助的ISAC系统中同时服务多用户和多目标感知，并最大化用户总速率。

Method: 提出了一种基于交替优化框架的有效迭代算法，联合优化DFBS的主动波束成形、RIS的反射系数和雷达接收滤波器。

Result: 仿真结果表明，所提算法优于基线算法，展现了在RIS赋能的NOMA-ISAC系统中的独特优势。

Conclusion: 该研究为RIS赋能的ISAC系统设计提供了有效的解决方案，优化性能显著。

Abstract: This paper investigates a reconfigurable intelligent surface (RIS)-assisted
integrated sensing and communication (ISAC) system and proposes a joint
communication and sensing beamforming design based on non-orthogonal multiple
access (NOMA) technology. The system employs a dual-functional base station
(DFBS) to simultaneously serve multiple users and sense multiple targets with
the aid of RIS. To maximize the sum-rate of users, we jointly optimize the
DFBS's active beamforming, the RIS's reflection coefficients, and the radar
receive filters. The optimization is performed under constraints including the
radar signal-to-noise ratio thresholds, the user
signal-to-interference-plus-noise ratio requirements, the phase shifts of the
RIS, the total transmit power, the receive filters, and the successive
interference cancellation decoding order. To tackle the complex
interdependencies and non-convex nature of the optimization problem, we
introduce an effective iterative algorithm based on the alternating
optimization framework. Simulation results demonstrate that the proposed
algorithm outperforms baseline algorithms, highlighting its distinct advantages
in the considered RIS-empowered NOMA-ISAC systems.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [33] [Observed Control -- Linearly Scalable Nonlinear Model Predictive Control with Adaptive Horizons](https://arxiv.org/abs/2508.13339)
*Eugene T. Hamzezadeh,Andrew J. Petruska*

Main category: math.OC

TL;DR: 该论文探讨了状态估计方法与模型预测控制之间的对偶关系，提出了一种高效的预测控制器，具备计算效率高、自适应时间范围和早期终止优化等特点。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用状态估计与模型预测控制的对偶性，开发一种高效且易实现的控制器，适用于线性和非线性系统。

Method: 方法包括使用卡尔曼平滑器作为优化框架，将线性模型预测控制分解为反应性和前瞻性两部分，并扩展到非线性系统。

Result: 数值研究表明，非线性滤波器（如扩展卡尔曼滤波和无迹卡尔曼滤波）成功将提出的控制方法扩展到非线性系统和目标。

Conclusion: 提出的控制器在计算效率和稳定性方面表现出色，适用于广泛的系统和时间范围。

Abstract: This work highlights the duality between state estimation methods and model
predictive control. A predictive controller, observed control, is presented
that uses this duality to efficiently compute control actions with linear
time-horizon length scalability. The proposed algorithms provide exceptional
computational efficiency, adaptive time horizon lengths, and early optimization
termination criteria. The use of Kalman smoothers as the backend optimization
framework provides for a straightforward implementation supported by strong
theoretical guarantees. Additionally, a formulation is presented that separates
linear model predictive control into purely reactive and anticipatory
components, enabling any-time any-horizon observed control while ensuring
controller stability for short time horizons. Finally, numerical case studies
confirm that nonlinear filter extensions, i.e., the extended Kalman filter and
unscented Kalman filter, effectively extend observed control to nonlinear
systems and objectives.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [Towards No-Code Programming of Cobots: Experiments with Code Synthesis by Large Code Models for Conversational Programming](https://arxiv.org/abs/2409.11041)
*Chalamalasetti Kranti,Sherzod Hakimov,David Schlangen*

Main category: cs.CL

TL;DR: 研究探索利用大型语言模型（LLMs）通过自然语言对话生成代码，以解决传统协作机器人编程的局限性。定义了RATS任务，创建数据集评估LLMs的能力，发现其在生成基本指令序列上表现良好，但在抽象代码生成上仍有困难。


<details>
  <summary>Details</summary>
Motivation: 传统协作机器人编程需要专家或手动指导，限制了灵活性和表达性。研究希望通过自然语言编程解决这些问题。

Method: 定义RATS任务，创建数据集，利用LLMs进行上下文学习，生成代码并评估其能力。

Result: LLMs能生成准确的指令序列（一级代码），但在生成抽象代码（如函数、循环）上表现不佳。

Conclusion: LLMs在简单任务上表现良好，但需进一步改进以支持更复杂的编程需求。

Abstract: While there has been a lot of research recently on robots in household
environments, at the present time, most robots in existence can be found on
shop floors, and most interactions between humans and robots happen there.
``Collaborative robots'' (cobots) designed to work alongside humans on assembly
lines traditionally require expert programming, limiting ability to make
changes, or manual guidance, limiting expressivity of the resulting programs.
To address these limitations, we explore using Large Language Models (LLMs),
and in particular, their abilities of doing in-context learning, for
conversational code generation. As a first step, we define RATS, the
``Repetitive Assembly Task'', a 2D building task designed to lay the foundation
for simulating industry assembly scenarios. In this task, a `programmer'
instructs a cobot, using natural language, on how a certain assembly is to be
built; that is, the programmer induces a program, through natural language. We
create a dataset that pairs target structures with various example instructions
(human-authored, template-based, and model-generated) and example code. With
this, we systematically evaluate the capabilities of state-of-the-art LLMs for
synthesising this kind of code, given in-context examples. Evaluating in a
simulated environment, we find that LLMs are capable of generating accurate
`first order code' (instruction sequences), but have problems producing
`higher-order code' (abstractions such as functions, or use of loops).

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [35] [BioGAP-Ultra: A Modular Edge-AI Platform for Wearable Multimodal Biosignal Acquisition and Processing](https://arxiv.org/abs/2508.13728)
*Sebastian Frey,Giusy Spacone,Andrea Cossettini,Marco Guermandi,Philipp Schilk,Luca Benini,Victor Kartsch*

Main category: eess.SY

TL;DR: BioGAP-Ultra是一款先进的生物传感平台，支持多模态信号同步采集与嵌入式AI处理，具有高能效、低功耗和开源特性。


<details>
  <summary>Details</summary>
Motivation: 满足实时生理监测和人机交互的需求，提升穿戴式设备的灵活性和智能化。

Method: 扩展了BioGAP设计，增加了存储、无线带宽和信号通道，并开发了配套的实时可视化分析软件。

Result: 平台在多种穿戴设备中表现出高效能（如头带、袖套和胸带），功耗分别低至32.8 mW、26.7 mW和9.3 mW。

Conclusion: BioGAP-Ultra为实时生物信号采集和边缘智能提供了高效、可配置的开源解决方案。

Abstract: The growing demand for continuous physiological monitoring and human-machine
interaction in real-world settings calls for wearable platforms that are
flexible, low-power, and capable of on-device intelligence. This work presents
BioGAP-Ultra, an advanced multimodal biosensing platform that supports
synchronized acquisition of diverse electrophysiological and hemodynamic
signals such as EEG, EMG, ECG, and PPG while enabling embedded AI processing at
state-of-the-art energy efficiency. BioGAP-Ultra is a major extension of our
previous design, BioGAP [1], aimed at meeting the rapidly growing requirements
of wearable biosensing applications. It features (i) increased on-device
storage (x2 SRAM, x4 FLASH), (ii) improved wireless connectivity (1.4 Mbit/s
bandwidth, x4 higher than BioGAP), (iii) enhanced number of signal modalities
(from 3 to 5) and analog input channels (x2). Further, it is complemented by a
complete real-time visualization and analysis software suite, providing access
to raw data and real-time configurability on a mobile phone. Electrical
characterization and multiple case studies confirm the platform's robustness,
configurability, and suitability for real-world multimodal biosignal
acquisition and edge intelligence. Finally, we demonstrate the system's
versatility through integration into various wearable form factors: an EEG-PPG
headband consuming 32.8 mW, an EMG sleeve at 26.7 mW, and an ECG-PPG chest band
requiring only 9.3 mW, tailored for diverse biosignal applications. All
hardware and software design files are also released open-source with a
permissive license.

</details>


### [36] [AutoMPC: A Code Generator for MPC-based Automated Driving](https://arxiv.org/abs/2508.13656)
*Georg Schildbach,Jasper Pflughaupt*

Main category: eess.SY

TL;DR: AutoMPC软件包通过自动代码生成和高效的C代码实现，解决了非线性MPC的高计算需求和实现复杂性，适用于多种驾驶场景。


<details>
  <summary>Details</summary>
Motivation: MPC在工业车辆集成中面临计算需求和实现复杂性的挑战，AutoMPC旨在解决这些问题。

Method: 采用鲁棒化的主动集算法，嵌入车辆轨迹跟踪框架，支持自动代码生成和自定义配置。

Result: AutoMPC在多种仿真场景中表现出高效性、鲁棒性和可行性，适用于高速和低速驾驶。

Conclusion: AutoMPC为非线性MPC的工业应用提供了一种高效且易于部署的解决方案。

Abstract: Model Predictive Control (MPC) is a powerful technique to control nonlinear,
multi-input multi-output systems subject to input and state constraints. It is
now a standard tool for trajectory tracking control of automated vehicles. As
such it has been used in many research and development projects. However, MPC
faces several challenges to be integrated into industrial production vehicles.
The most important ones are its high computational demands and the complexity
of implementation. The software packages AutoMPC aims to address both of these
challenges. It builds on a robustified version of an active set algorithm for
Nonlinear MPC. The algorithm is embedded into a framework for vehicle
trajectory tracking, which makes it easy to used, yet highly customizable.
Automatic code generation transforms the selections into a standalone,
computationally efficient C-code file with static memory allocation. As such it
can be readily deployed on a wide range of embedded platforms, e.g., based on
Matlab/Simulink or Robot Operating System (ROS). Compared to a previous version
of the code, the vehicle model and the numerical integration method can be
manually specified, besides basic algorithm parameters. All of this information
and all specifications are directly baked into the generated C-code. The
algorithm is suitable driving scenarios at low or high speeds, even drifting,
and supports direction changes. Multiple simulation scenarios show the
versatility and effectiveness of the AutoMPC code, with the guarantee of a
feasible solution, a high degree of robustness, and computational efficiency.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [37] [The 9th AI City Challenge](https://arxiv.org/abs/2508.13564)
*Zheng Tang,Shuo Wang,David C. Anastasiu,Ming-Ching Chang,Anuj Sharma,Quan Kong,Norimasa Kobori,Munkhjargal Gochoo,Ganzorig Batnasan,Munkh-Erdene Otgonbold,Fady Alnajjar,Jun-Wei Hsieh,Tomasz Kornuta,Xiaolong Li,Yilin Zhao,Han Zhang,Subhashree Radhakrishnan,Arihant Jain,Ratnesh Kumar,Vidya N. Murali,Yuxing Wang,Sameer Satish Pusegaonkar,Yizhou Wang,Sujit Biswas,Xunlei Wu,Zhedong Zheng,Pranamesh Chakraborty,Rama Chellappa*

Main category: cs.CV

TL;DR: 2025年AI City挑战赛聚焦计算机视觉在交通、工业自动化和公共安全中的实际应用，包含四个赛道，参赛团队显著增加，数据集下载量超过3万次。


<details>
  <summary>Details</summary>
Motivation: 推动计算机视觉和AI在交通、工业自动化及公共安全领域的实际应用，促进技术发展与创新。

Method: 通过四个赛道（3D多目标跟踪、交通视频问答、仓储空间推理、鱼眼摄像头目标检测），利用多样化数据集和评估框架进行竞赛。

Result: 参赛团队数量增加17%，多个团队取得顶尖成绩，并在多个任务中设立新标杆。

Conclusion: 挑战赛成功推动了技术进步和实际应用，数据集和评估框架为未来研究提供了基础。

Abstract: The ninth AI City Challenge continues to advance real-world applications of
computer vision and AI in transportation, industrial automation, and public
safety. The 2025 edition featured four tracks and saw a 17% increase in
participation, with 245 teams from 15 countries registered on the evaluation
server. Public release of challenge datasets led to over 30,000 downloads to
date. Track 1 focused on multi-class 3D multi-camera tracking, involving
people, humanoids, autonomous mobile robots, and forklifts, using detailed
calibration and 3D bounding box annotations. Track 2 tackled video question
answering in traffic safety, with multi-camera incident understanding enriched
by 3D gaze labels. Track 3 addressed fine-grained spatial reasoning in dynamic
warehouse environments, requiring AI systems to interpret RGB-D inputs and
answer spatial questions that combine perception, geometry, and language. Both
Track 1 and Track 3 datasets were generated in NVIDIA Omniverse. Track 4
emphasized efficient road object detection from fisheye cameras, supporting
lightweight, real-time deployment on edge devices. The evaluation framework
enforced submission limits and used a partially held-out test set to ensure
fair benchmarking. Final rankings were revealed after the competition
concluded, fostering reproducibility and mitigating overfitting. Several teams
achieved top-tier results, setting new benchmarks in multiple tasks.

</details>


### [38] [MR6D: Benchmarking 6D Pose Estimation for Mobile Robots](https://arxiv.org/abs/2508.13775)
*Anas Gouda,Shrutarv Awasthi,Christian Blesing,Lokeshwaran Manohar,Frank Hoffmann,Alice Kirchheim*

Main category: cs.CV

TL;DR: MR6D数据集针对工业环境中的移动机器人6D姿态估计，解决了现有数据集主要关注小型家用物体的局限性，涵盖了远距离视角、大物体尺寸和复杂遮挡等问题。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计数据集主要针对小型家用物体，无法满足移动机器人在工业环境中的需求。

Method: 介绍了MR6D数据集，包含92个真实场景和16个独特物体，涵盖静态和动态交互，特别关注远距离视角、大物体尺寸和复杂遮挡模式。

Result: 实验表明，现有6D姿态估计方法在这些环境下表现不佳，特别是2D分割成为瓶颈。

Conclusion: MR6D为移动机器人的姿态估计方法开发和评估提供了基础，填补了研究空白。

Abstract: Existing 6D pose estimation datasets primarily focus on small household
objects typically handled by robot arm manipulators, limiting their relevance
to mobile robotics. Mobile platforms often operate without manipulators,
interact with larger objects, and face challenges such as long-range
perception, heavy self-occlusion, and diverse camera perspectives. While recent
models generalize well to unseen objects, evaluations remain confined to
household-like settings that overlook these factors. We introduce MR6D, a
dataset designed for 6D pose estimation for mobile robots in industrial
environments. It includes 92 real-world scenes featuring 16 unique objects
across static and dynamic interactions. MR6D captures the challenges specific
to mobile platforms, including distant viewpoints, varied object
configurations, larger object sizes, and complex occlusion/self-occlusion
patterns. Initial experiments reveal that current 6D pipelines underperform in
these settings, with 2D segmentation being another hurdle. MR6D establishes a
foundation for developing and evaluating pose estimation methods tailored to
the demands of mobile robotics. The dataset is available at
https://huggingface.co/datasets/anas-gouda/mr6d.

</details>


### [39] [ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans](https://arxiv.org/abs/2508.14006)
*Mohamed Abouagour,Eleftherios Garyfallidis*

Main category: cs.CV

TL;DR: ResPlan 是一个包含 17,000 份详细住宅平面图的大规模数据集，旨在推动空间 AI 研究，提供高保真结构和多样性的标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有数据集如 RPLAN 和 MSD 存在视觉保真度和结构多样性不足的问题，ResPlan 旨在解决这些局限性。

Method: 数据集包含几何和图形两种格式的平面图，提供开源工具链用于几何清理和对齐，并支持基于图的推理任务。

Result: ResPlan 在规模、真实性和实用性方面显著进步，为下一代空间智能系统提供了坚实基础。

Conclusion: ResPlan 通过增强的数据质量和多样性，为多领域研究提供了通用资源，并支持开放基准任务的开发。

Abstract: We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally
rich, and realistic residential floor plans, created to advance spatial AI
research. Each plan includes precise annotations of architectural elements
(walls, doors, windows, balconies) and functional spaces (such as kitchens,
bedrooms, and bathrooms). ResPlan addresses key limitations of existing
datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024)
by offering enhanced visual fidelity and greater structural diversity,
reflecting realistic and non-idealized residential layouts. Designed as a
versatile, general-purpose resource, ResPlan supports a wide range of
applications including robotics, reinforcement learning, generative AI, virtual
and augmented reality, simulations, and game development. Plans are provided in
both geometric and graph-based formats, enabling direct integration into
simulation engines and fast 3D conversion. A key contribution is an open-source
pipeline for geometry cleaning, alignment, and annotation refinement.
Additionally, ResPlan includes structured representations of room connectivity,
supporting graph-based spatial reasoning tasks. Finally, we present comparative
analyses with existing benchmarks and outline several open benchmark tasks
enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale,
realism, and usability, providing a robust foundation for developing and
benchmarking next-generation spatial intelligence systems.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [40] [A Screw Approach to the Approximation of the Local Geometry of the Configuration Space and of the set of Configurations of Certain Rank of Lower Pair Linkages](https://arxiv.org/abs/2508.13802)
*Andreas Mueller*

Main category: math.DG

TL;DR: 论文提出了一种高阶局部移动性分析方法，基于几何约束映射的高阶泰勒展开，并给出了以关节螺旋表示的递归代数表达式。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设所有运动都是光滑的，限制了其通用性，因此需要一种更通用的高阶局部移动性分析方法。

Method: 基于高阶泰勒级数展开的几何约束映射，并利用关节螺旋的递归代数表达式进行分析。

Result: 通过局部近似分析了约束奇异点集，并展示了平面4杆机构和三环机构的示例。

Conclusion: 该方法可以处理现有方法无法处理的复杂奇异点，如c-space中的尖点。

Abstract: A motion of a mechanism is a curve in its configuration space (c-space).
Singularities of the c-space are kinematic singularities of the mechanism. Any
mobility analysis of a particular mechanism amounts to investigating the
c-space geometry at a given configuration. A higher-order analysis is necessary
to determine the finite mobility. To this end, past research lead to approaches
using higher-order time derivatives of loop closure constraints assuming
(implicitly) that all possible motions are smooth. This continuity assumption
limits the generality of these methods. In this paper an approach to the
higher-order local mobility analysis of lower pair multi-loop linkages is
presented. This is based on a higher-order Taylor series expansion of the
geometric constraint mapping, for which a recursive algebraic expression in
terms of joint screws is presented. An exhaustive local analysis includes
analysis of the set of constraint singularities (configurations where the
constraint Jacobian has certain corank). A local approximation of the set of
configurations with certain rank is presented, along with an explicit
expression for the differentials of Jacobian minors in terms of instantaneous
joint screws. The c-space and the set of points of certain corank are therewith
locally approximated by an algebraic variety determined algebraically from the
mechanism's screw system. Results are shown for a simple planar 4-bar linkage,
which exhibits a bifurcation singularity, and for a planar three-loop linkage
exhibiting a cusp in c-space. The latter cannot be treated by the higher-order
local analysis methods proposed in the literature.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [41] [Encoding Optimization for Low-Complexity Spiking Neural Network Equalizers in IM/DD Systems](https://arxiv.org/abs/2508.13783)
*Eike-Manuel Edelmann,Alexander von Bank,Laurent Schmalen*

Main category: cs.NE

TL;DR: 提出一种基于强化学习的算法优化SNN中的神经编码参数，应用于IM/DD系统后，性能提升且计算负载和网络规模减小。


<details>
  <summary>Details</summary>
Motivation: 目前SNN的神经编码参数通常通过启发式方法设置，缺乏优化机制。

Method: 采用强化学习算法优化SNN的神经编码参数。

Result: 在IM/DD系统的SNN均衡器和解映射器中应用，性能提升，计算负载和网络规模降低。

Conclusion: 强化学习优化SNN编码参数是一种有效方法，可提升性能并降低资源消耗。

Abstract: Neural encoding parameters for spiking neural networks (SNNs) are typically
set heuristically. We propose a reinforcement learning-based algorithm to
optimize them. Applied to an SNN-based equalizer and demapper in an IM/DD
system, the method improves performance while reducing computational load and
network size.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [42] [AI-Augmented Photon-Trapping Spectrometer-on-a-Chip on Silicon Platform with Extended Near-Infrared Sensitivity](https://arxiv.org/abs/2508.13521)
*Ahasan Ahamed,Htet Myat,Amita Rawat,Lisa N McPhillips,M Saif Islam*

Main category: physics.optics

TL;DR: 提出了一种紧凑、抗噪声的片上重构光谱仪，实现了高达1100nm的近红外高分辨率成像，通过AI增强和光子阱纹理技术，性能优于传统光谱仪。


<details>
  <summary>Details</summary>
Motivation: 传统光谱仪在超过950nm的波段性能下降，且体积大、噪声敏感。需要开发一种更紧凑、抗噪声且覆盖更长波段的解决方案。

Method: 采用单片集成的硅光电二极管，结合光子阱表面纹理（PTST）提高近红外响应率，并使用全连接神经网络从16个独特设计的探测器精确重建光谱。

Result: 光谱重建误差<0.05 RMSE，分辨率为8nm，信噪比>30dB，动态范围50dB，响应时间57ps，适用于便携式和低光应用。

Conclusion: 该工作为基于CMOS的高性能超光谱传感提供了新途径，适用于生物医学、环境监测和遥感等领域。

Abstract: We present a compact, noise-resilient reconstructive spectrometer-on-a-chip
that achieves high-resolution hyperspectral imaging across an extended
near-infrared (NIR) range up to 1100nm. The device integrates monolithically
fabricated silicon photodiodes enhanced with photon-trapping surface textures
(PTST), enabling improved responsivity in the low-absorption NIR regime.
Leveraging a fully connected neural network, we demonstrate accurate spectral
reconstruction from only 16 uniquely engineered detectors, achieving <0.05 RMSE
and 8nm resolution over a wide spectral range of 640nm to 1100nm. Our system
outperforms conventional spectrometers, maintaining signal-to-noise ratio above
30dB even with 40dB of added detector noise; extending functionality to longer
wavelengths up to 1100nm, while the traditional spectrometers fail to perform
beyond 950nm due to poor detector efficiency and noise performance. With a
footprint of 0.4mm2, dynamic range of 50dB, ultrafast time response (57ps), and
high photodiode gain (>7000), this AI-augmented silicon spectrometer is
well-suited for portable, real-time, and low-light applications in biomedical
imaging, environmental monitoring, and remote sensing. The results establish a
pathway toward fully integrated, high-performance hyperspectral sensing in a
CMOS-compatible platform.

</details>
