{"id": "2510.11867", "pdf": "https://arxiv.org/pdf/2510.11867", "abs": "https://arxiv.org/abs/2510.11867", "authors": ["Zelin Gan", "Henrique Buglia", "Romulo Aparecido", "Mindaugas Jarmolovičius", "Eric Sillekens", "Jiaqian Yang", "Ronit Sohanpal", "Robert I. Killey", "Polina Bayvel"], "title": "A Closed-form Expression of the Gaussian Noise Model Supporting O-Band Transmission", "categories": ["eess.SP"], "comment": "13 pages, 10 figures", "summary": "We present a novel closed-form model for nonlinear interference (NLI)\nestimation in low-dispersion O-band transmission systems. The formulation\nincorporates the four-wave mixing (FWM) efficiency term as well as the coherent\ncontributions of self- and cross-phase modulation (SPM/XPM) across multiple\nidentical spans. This extension enables accurate evaluation of the NLI in\nscenarios where conventional closed-form Gaussian Noise (GN) models are\nlimited. The proposed model is validated against split-step Fourier method\n(SSFM) simulations and numerical integration across 41-161 channels, with a 96\nGBaud symbol rate, bandwidths of up to 16.1 THz, and transmission distances\nfrom 80 to 800 km. Results show a mean absolute error of the NLI\nsignal-to-noise ratio (SNR) below 0.22 dB. The proposed closed-form model\noffers an efficient and accurate tool for system optimisation in O-band\ncoherent transmission."}
{"id": "2510.11891", "pdf": "https://arxiv.org/pdf/2510.11891", "abs": "https://arxiv.org/abs/2510.11891", "authors": ["Haoran He"], "title": "Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems", "categories": ["eess.SP"], "comment": "4 pages, 8 figures, ISCIPT 2025", "summary": "This paper proposes a machine learning-assisted channel estimation approach\nfor massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE\nmethods. In 5G and beyond, accurate channel estimation mitigates pilot\ncontamination and high mobility issues that harm system reliability. The\nproposed DNN architecture includes multi-layer perceptrons with ReLU\nactivation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam\noptimizer (learning rate 1e-4) and MSE loss function. It learns from pilot\nsignals to predict channel matrices, achieving lower NMSE and BER across\ndifferent SNR levels. Simulations use the COST 2100 public standard dataset (a\nwell-recognized MIMO channel dataset for 5G, not synthetic datasets) with\n10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show\nthe DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust\nperformance in high-mobility scenarios. The study evaluates metrics like NMSE\nvs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations,\nand computational complexity. The DNN has 2.3 GFlOPs computational complexity,\n15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying\ndeployment feasibility. This work advances ML integration in wireless\ncommunications, facilitating efficient resource allocation and improved\nspectral efficiency in next-generation networks. Future work may use more\nreal-world datasets and hybrid architectures for better generalization."}
{"id": "2510.11925", "pdf": "https://arxiv.org/pdf/2510.11925", "abs": "https://arxiv.org/abs/2510.11925", "authors": ["Yanan Du", "Zeyang Sun", "Yilan Zhang", "Sai Xu", "Beiyuan Liu"], "title": "Using STAR-IRS to Secure Indoor Communications Through Symbol-Level Random Phase Modulation", "categories": ["eess.SP"], "comment": null, "summary": "This paper proposes a secure indoor communication scheme based on\nsimultaneous transmitting and reflecting intelligent reflecting surface\n(STAR-IRS). Specifically, a transmitter (Alice) sends confidential information\nto its intended user (Bob) indoors, while several eavesdroppers (Eves) lurk\noutside. To safeguard the transmission from eavesdropping, the STAR-IRS is\ndeployed on walls or windows. Upon impinging on the STAR-IRS, the incoming\nelectromagnetic wave is dynamically partitioned into two components, enabling\nboth transmission through and reflection from the surface. The reflected signal\nis controlled to enhance reception at Bob, while the transmitted signal is\nmodulated with symbol-level random phase shifts to degrade the signal quality\nat Eves. Based on such a setting, the secrecy rate maximization problem is\nformulated. To solve it, a graph neural network (GNN)-based scheme is\ndeveloped. Furthermore, a field-programmable gate array (FPGA)-based GNN\naccelerator is designed to reduce computational latency. Simulation results\ndemonstrate that the proposed strategy outperforms both the conventional scheme\nand the reflection-only scheme in terms of secrecy performance. Moreover, the\nGNN-based approach achieves superior results compared to benchmark techniques\nsuch as maximum ratio transmission (MRT), zero forcing (ZF), and minimum mean\nsquare error (MMSE) in solving the optimization problem. Finally, experimental\nevaluations confirm that the FPGA-based accelerator enables low inference\nlatency."}
{"id": "2510.11994", "pdf": "https://arxiv.org/pdf/2510.11994", "abs": "https://arxiv.org/abs/2510.11994", "authors": ["Yinan Wang", "Byeongjin Kim", "Nishanth Ravi", "Kapil Saha", "Supratik Dasgupta", "Vakhtang Chulukhadze", "Eugene Kwon", "Lezli Matto", "Pietro Simeoni", "Omar Barrera", "Ian Anderson", "Tzu-Hsuan Hsu", "Jue Hou", "Matteo Rinaldi", "Mark S. Goorsky", "Ruochen Lu"], "title": "62.6 GHz ScAlN Solidly Mounted Acoustic Resonators", "categories": ["eess.SP"], "comment": "6 Pages, 7 Figures, 3 Tables", "summary": "We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator\n(SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N)\npiezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode,\npositioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2\nnm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and\npiezoelectric stack above are designed to confine a third-order\nthickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently\ntransducing with thickness-field excitation. The fabricated SMR exhibits an\nextracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode\nquality factor (Q) of 51 at 63 GHz, representing the highest operating\nfrequency reported for an SMR to date. These results establish a pathway toward\nmmWave SMR devices for filters and resonators in next-generation RF front ends."}
{"id": "2510.12090", "pdf": "https://arxiv.org/pdf/2510.12090", "abs": "https://arxiv.org/abs/2510.12090", "authors": ["Hakan Ceylan", "Edoardo Sinibaldi", "Sanjay Misra", "Pankaj J. Pasricha", "Dietmar W. Hutmacher"], "title": "Translating Milli/Microrobots with A Value-Centered Readiness Framework", "categories": ["cs.RO", "cs.ET"], "comment": null, "summary": "Untethered mobile milli/microrobots hold transformative potential for\ninterventional medicine by enabling more precise and entirely non-invasive\ndiagnosis and therapy. Realizing this promise requires bridging the gap between\ngroundbreaking laboratory demonstrations and successful clinical integration.\nDespite remarkable technical progress over the past two decades, most\nmillirobots and microrobots remain confined to laboratory proof-of-concept\ndemonstrations, with limited real-world feasibility. In this Review, we\nidentify key factors that slow translation from bench to bedside, focusing on\nthe disconnect between technical innovation and real-world application. We\nargue that the long-term impact and sustainability of the field depend on\naligning development with unmet medical needs, ensuring applied feasibility,\nand integrating seamlessly into existing clinical workflows, which are\nessential pillars for delivering meaningful patient outcomes. To support this\nshift, we introduce a strategic milli/microrobot Technology Readiness Level\nframework (mTRL), which maps system development from initial conceptualization\nto clinical adoption through clearly defined milestones and their associated\nstepwise activities. The mTRL model provides a structured gauge of\ntechnological maturity, a common language for cross-disciplinary collaboration\nand actionable guidance to accelerate translational development toward new,\nsafer and more efficient interventions."}
{"id": "2510.12179", "pdf": "https://arxiv.org/pdf/2510.12179", "abs": "https://arxiv.org/abs/2510.12179", "authors": ["Abdullahi Mohammad", "Bdah Eya", "Bassant Selim"], "title": "A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation", "categories": ["eess.SP"], "comment": "6, 5", "summary": "Impulsive noise poses a significant challenge to the reliability of wireless\ncommunication systems, necessitating accurate estimation of its statistical\nparameters for effective mitigation. This paper introduces a multitask learning\n(MTL) framework based on a CNN-LSTM architecture enhanced with an attention\nmechanism for the joint estimation of impulsive noise parameters. The proposed\nmodel leverages a unified weighted-loss function to enable simultaneous\nlearning of multiple parameters within a shared representation space, improving\nlearning efficiency and generalization across related tasks. Experimental\nresults show that the proposed MTL framework achieves stable convergence,\nfaster training, and enhanced scalability with modest computational overhead.\nBenchmarking against conventional single-task learning (STL) models confirms\nits favorable complexity-performance trade-off and significant memory savings,\nindicating the effectiveness of the MTL approach for real-time impulsive noise\nparameter estimation in wireless systems."}
{"id": "2510.12101", "pdf": "https://arxiv.org/pdf/2510.12101", "abs": "https://arxiv.org/abs/2510.12101", "authors": ["Pengyu Yin", "Shenghai Yuan", "Haozhi Cao", "Xingyu Ji", "Ruofei Bai", "Siyu Chen", "Lihua Xie"], "title": "Gaussian Semantic Field for One-shot LiDAR Global Localization", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "We present a one-shot LiDAR global localization algorithm featuring semantic\ndisambiguation ability based on a lightweight tri-layered scene graph. While\nlandmark semantic registration-based methods have shown promising performance\nimprovements in global localization compared with geometric-only methods,\nlandmarks can be repetitive and misleading for correspondence establishment. We\npropose to mitigate this problem by modeling semantic distributions with\ncontinuous functions learned from a population of Gaussian processes. Compared\nwith discrete semantic labels, the continuous functions capture finer-grained\ngeo-semantic information and also provide more detailed metric information for\ncorrespondence establishment. We insert this continuous function as the middle\nlayer between the object layer and the metric-semantic layer, forming a\ntri-layered 3D scene graph, serving as a light-weight yet performant backend\nfor one-shot localization. We term our global localization pipeline Outram-GSF\n(Gaussian semantic field) and conduct a wide range of experiments on publicly\navailable data sets, validating the superior performance against the current\nstate-of-the-art."}
{"id": "2510.12204", "pdf": "https://arxiv.org/pdf/2510.12204", "abs": "https://arxiv.org/abs/2510.12204", "authors": ["Zhen Du", "Jingjing Xu", "Yifeng Xiong", "Jie Wang", "Musa Furkan Keskin", "Henk Wymeersch", "Fan Liu", "Shi Jin"], "title": "Probabilistic Constellation Shaping for OFDM ISAC Signals Under Temporal-Frequency Filtering", "categories": ["eess.SP"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Integrated sensing and communications (ISAC) is considered an innovative\ntechnology in sixth-generation (6G) wireless networks, where utilizing\northogonal frequency division multiplexing (OFDM) communication signals for\nsensing provides a cost-effective solution for implementing ISAC. However, the\nsensing performance of matched and mismatched filtering schemes can be\nsignificantly deteriorated due to the signaling randomness induced by\nfinite-alphabet modulations with nonconstant modulus, such as quadrature\namplitude modulation (QAM) constellations. Therefore, improving sensing\nperformance without significantly compromising communication capability (i.e.,\nmaintaining randomness), remains a challenging task. To that end, we propose a\nunified probabilistic constellation shaping (PCS) framework that is compatible\nwith both matched and mismatched filtering schemes, by maximizing the\ncommunication rate while imposing constraints on mean square error (MSE) of\nsensing channel state information (CSI), power, and probability distribution.\nSpecifically, the MSE of sensing CSI is leveraged to optimize sensing\ncapability, which is illustrated to be a more comprehensive metric compared to\nthe output SNR after filtering (SNRout) and integrated sidelobes ratio (ISLR).\nAdditionally, the internal relationships among these three sensing metrics are\nexplicitly analyzed. Finally, both simulations and field measurements validate\nthe efficiency of proposed PCS approach in achieving a flexible S&C trade-off,\nas well as its credibility in enhancing 6G wireless transmission in real-world\nscenarios."}
{"id": "2510.12169", "pdf": "https://arxiv.org/pdf/2510.12169", "abs": "https://arxiv.org/abs/2510.12169", "authors": ["Akshay Naik", "William R. Norris", "Dustin Nottage", "Ahmet Soylemezoglu"], "title": "Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\\(^{*}\\) Exploration and VD--D\\(^{*}\\) Lite Repair", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Autonomous ground vehicles operating off-road must plan curvature-feasible\npaths while accounting for spatially varying soil strength and slope hazards in\nreal time. We present a continuous state--cost metric that combines a Bekker\npressure--sinkage model with elevation-derived slope and attitude penalties.\nThe resulting terrain cost field is analytic, bounded, and monotonic in soil\nmodulus and slope, ensuring well-posed discretization and stable updates under\nsensor noise. This metric is evaluated on a lattice with exact steering\nprimitives: Dubins and Reeds--Shepp motions for differential drive and\ntime-parameterized bicycle arcs for Ackermann steering. Global exploration is\nperformed using Vehicle-Dynamics RRT\\(^{*}\\), while local repair is managed by\nVehicle-Dynamics D\\(^{*}\\) Lite, enabling millisecond-scale replanning without\nheuristic smoothing. By separating the terrain--vehicle model from the planner,\nthe framework provides a reusable basis for deterministic, sampling-based, or\nlearning-driven planning in deformable terrain. Hardware trials on an off-road\nplatform demonstrate real-time navigation across soft soil and slope\ntransitions, supporting reliable autonomy in unstructured environments."}
{"id": "2510.12279", "pdf": "https://arxiv.org/pdf/2510.12279", "abs": "https://arxiv.org/abs/2510.12279", "authors": ["Benedikt Böck", "Amar Kasibovic", "Wolfgang Utschick"], "title": "Wireless Channel Modeling for Machine Learning -- A Critical View on Standardized Channel Models", "categories": ["eess.SP"], "comment": null, "summary": "Standardized (link-level) channel models such as the 3GPP TDL and CDL models\nare frequently used to evaluate machine learning (ML)-based physical-layer\nmethods. However, in this work, we argue that a link-level perspective\nincorporates limiting assumptions, causing unwanted distributional shifts or\nnecessitating impractical online training. An additional drawback is that this\nperspective leads to (near-)Gaussian channel characteristics. Thus, ML-based\nmodels, trained on link-level channel data, do not outperform classical\napproaches for a variety of physical-layer applications. Particularly, we\ndemonstrate the optimality of simple linear methods for channel compression,\nestimation, and modeling, revealing the unsuitability of link-level channel\nmodels for evaluating ML models. On the upside, adopting a scenario-level\nperspective offers a solution to this problem and unlocks the relative gains\nenabled by ML."}
{"id": "2510.12206", "pdf": "https://arxiv.org/pdf/2510.12206", "abs": "https://arxiv.org/abs/2510.12206", "authors": ["Pin-Lun Chen", "Chi-Hsi Kung", "Che-Han Chang", "Wei-Chen Chiu", "Yi-Ting Chen"], "title": "Controllable Collision Scenario Generation via Collision Pattern Prediction", "categories": ["cs.RO", "cs.LG"], "comment": "8 pages, 3 figures. Submitted to IEEE International Conference on\n  Robotics and Automation (ICRA) 2026", "summary": "Evaluating the safety of autonomous vehicles (AVs) requires diverse,\nsafety-critical scenarios, with collisions being especially important yet rare\nand unsafe to collect in the real world. Therefore, the community has been\nfocusing on generating safety-critical scenarios in simulation. However,\ncontrolling attributes such as collision type and time-to-accident (TTA)\nremains challenging. We introduce a new task called controllable collision\nscenario generation, where the goal is to produce trajectories that realize a\nuser-specified collision type and TTA, to investigate the feasibility of\nautomatically generating desired collision scenarios. To support this task, we\npresent COLLIDE, a large-scale collision scenario dataset constructed by\ntransforming real-world driving logs into diverse collisions, balanced across\nfive representative collision types and different TTA intervals. We propose a\nframework that predicts Collision Pattern, a compact and interpretable\nrepresentation that captures the spatial configuration of the ego and the\nadversarial vehicles at impact, before rolling out full adversarial\ntrajectories. Experiments show that our approach outperforms strong baselines\nin both collision rate and controllability. Furthermore, generated scenarios\nconsistently induce higher planner failure rates, revealing limitations of\nexisting planners. We demonstrate that these scenarios fine-tune planners for\nrobustness improvements, contributing to safer AV deployment in different\ncollision scenarios."}
{"id": "2510.12315", "pdf": "https://arxiv.org/pdf/2510.12315", "abs": "https://arxiv.org/abs/2510.12315", "authors": ["Piyush Priyanshu", "Sudhan Majhi", "Subhabrata Paul"], "title": "A New Method of Constructing Hadamard Matrices, Circulant Hadamard Matrices, CZCS, GCS, CCC, and CZCSS", "categories": ["eess.SP"], "comment": null, "summary": "A Hadamard matrix $H$ is a square matrix of order $n$ with entries $\\pm 1$,\nsuch that $HH^\\top=nI_{n}$, where $I_n$ is an identity matrix of order $n$. A\ncirculant Hadamard matrix $H$ is a Hadamard matrix that has rows of entries in\ncyclic order. There exist only $8$ circulant Hadamard matrices of order 4, and\nhere, we provide a novel construction of all such $8$ circulant Hadamard\nmatrices using a linear operator and generalized Boolean function (GBF). The\nconstructed circulant Hadamard matrices are used recursively to construct a\nbinary cross Z-complementary set (CZCS) of all lengths with an even phase, a\nbinary Golay complementary set (GCS) of all lengths, and Hadamard matrices of\norder $2^{n+2}$, where $n\\geq1$. The construction of a binary CZCS covering all\nlengths was not available before. We also propose an alternative,\nlower-complexity construction of binary GCSs of all lengths and Hadamard\nmatrices of order $2^{a+1}10^b26^c$ using circulant matrices, where $ a,b,c\n\\geq 0$. The proposed binary GCS covers all lengths with a flexible flock size.\nThe constructions of GCS are further extended to form binary complete\ncomplementary code (CCC) of the parameter $(2N,2N,2N)-CCC$ where\n$N=2^a10^b26^c, a,b,c \\geq 0$. The constructed binary CCC provides a flexible\nflock size. The construction of CZCS is further extended to form a binary\noptimal cross-Z complementary sequence set (CZCSS) of the parameter $(2^{n+2},\n2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$, where $n\\geq1$. Finally, we provide a\nrelation between Hadamard matrices and GCS, which enables the study of the\nHadamard conjecture in a new direction. We also provided a few properties of\ncirculant matrices over aperiodic cross-correlation (ACCF) and aperiodic\nauto-correlation (AACF), which are used to prove the theorems. All proposed\nconstructions are novel, and their parameters are compared with the existing\nstate-of-the-art."}
{"id": "2510.12215", "pdf": "https://arxiv.org/pdf/2510.12215", "abs": "https://arxiv.org/abs/2510.12215", "authors": ["Chanwoo Kim", "Jihwan Yoon", "Hyeonseong Kim", "Taemoon Jeong", "Changwoo Yoo", "Seungbeen Lee", "Soohwan Byeon", "Hoon Chung", "Matthew Pan", "Jean Oh", "Kyungjae Lee", "Sungjoon Choi"], "title": "Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications", "categories": ["cs.RO"], "comment": "For more videos, see https://chanwookim971024.github.io/PioneeR/", "summary": "Mobile robot navigation in dynamic human environments requires policies that\nbalance adaptability to diverse behaviors with compliance to safety\nconstraints. We hypothesize that integrating data-driven rewards with\nrule-based objectives enables navigation policies to achieve a more effective\nbalance of adaptability and safety. To this end, we develop a framework that\nlearns a density-based reward from positive and negative demonstrations and\naugments it with rule-based objectives for obstacle avoidance and goal\nreaching. A sampling-based lookahead controller produces supervisory actions\nthat are both safe and adaptive, which are subsequently distilled into a\ncompact student policy suitable for real-time operation with uncertainty\nestimates. Experiments in synthetic and elevator co-boarding simulations show\nconsistent gains in success rate and time efficiency over baselines, and\nreal-world demonstrations with human participants confirm the practicality of\ndeployment. A video illustrating this work can be found on our project page\nhttps://chanwookim971024.github.io/PioneeR/."}
{"id": "2510.12366", "pdf": "https://arxiv.org/pdf/2510.12366", "abs": "https://arxiv.org/abs/2510.12366", "authors": ["Zheyu Wu", "Matteo Nerini", "Bruno Clerckx"], "title": "Beyond-Diagonal RIS Architecture Design and Optimization under Physics-Consistent Models", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": "13 pages, 5 figures, submitted for possible publication", "summary": "Reconfigurable intelligent surface (RIS) is a promising technology for future\nwireless communication systems. Conventional RIS is constrained to a diagonal\nscattering matrix, which limits its flexibility. Recently, beyond-diagonal RIS\n(BD-RIS) has been proposed as a more general RIS architecture class that allows\ninter-element connections and shows great potential for performance\nimprovement. Despite extensive progress on BD-RIS, most existing studies rely\non simplified channel models that ignore practical electromagnetic (EM) effects\nsuch as mutual coupling and impedance mismatching. To address this gap, this\npaper investigates the architecture design and optimization of BD-RIS under the\ngeneral physics-consistent model derived with multiport network theory in\nrecent literature. Building on a compact reformulation of this model, we show\nthat band-connected RIS achieves the same channel-shaping capability as\nfully-connected RIS, which extends existing results obtained for conventional\nchannel models. We then develop optimization methods under the general\nphysics-consistent model; specifically, we derive closed-form solutions for\nsingle-input single-output (SISO) systems, propose a globally optimal\nsemidefinite relaxation (SDR)-based algorithm for single-stream multi-input\nmulti-output (MIMO) systems, and design an efficient alternating direction\nmethod of multipliers (ADMM)-based algorithm for multiuser MIMO systems. Using\nthe proposed algorithms, we conduct comprehensive simulations to evaluate the\nimpact of various EM effects and approximations, including mutual coupling\namong RIS antennas and the commonly adopted unilateral approximation, on system\nperformance."}
{"id": "2510.12276", "pdf": "https://arxiv.org/pdf/2510.12276", "abs": "https://arxiv.org/abs/2510.12276", "authors": ["Fuhao Li", "Wenxuan Song", "Han Zhao", "Jingbo Wang", "Pengxiang Ding", "Donglin Wang", "Long Zeng", "Haoang Li"], "title": "Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model", "categories": ["cs.RO"], "comment": null, "summary": "Vision-language-action (VLA) models have recently shown strong potential in\nenabling robots to follow language instructions and execute precise actions.\nHowever, most VLAs are built upon vision-language models pretrained solely on\n2D data, which lack accurate spatial awareness and hinder their ability to\noperate in the 3D physical world. Existing solutions attempt to incorporate\nexplicit 3D sensor inputs such as depth maps or point clouds, but these\napproaches face challenges due to sensor noise, hardware heterogeneity, and\nincomplete depth coverage in existing datasets. Alternative methods that\nestimate 3D cues from 2D images also suffer from the limited performance of\ndepth estimators.We propose Spatial Forcing (SF), a simple yet effective\nalignment strategy that implicitly forces VLA models to develop spatial\ncomprehension capabilities without relying on explicit 3D inputs or depth\nestimators. SF aligns intermediate visual embeddings of VLAs with geometric\nrepresentations produced by pretrained 3D foundation models. By enforcing\nalignment at intermediate layers, SF guides VLAs to encode richer spatial\nrepresentations that enhance action precision.Extensive experiments in\nsimulation and real-world environments demonstrate that SF achieves\nstate-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further\naccelerates training by up to 3.8x and improves data efficiency across diverse\nrobotic tasks. Project page is at https://spatial-forcing.github.io/"}
{"id": "2510.12515", "pdf": "https://arxiv.org/pdf/2510.12515", "abs": "https://arxiv.org/abs/2510.12515", "authors": ["Zhige Chen", "Chengxuan Qin", "Wenlong You", "Rui Liu", "Congying Chu", "Rui Yang", "Kay Chen Tan", "Jibin Wu"], "title": "HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation", "categories": ["eess.SP"], "comment": null, "summary": "Electroencephalography (EEG) is an essential technique for neuroscience\nresearch and brain-computer interface (BCI) applications. Recently, large-scale\nEEG foundation models have been developed, exhibiting robust generalization\ncapabilities across diverse tasks and subjects. However, the heterogeneity of\nEEG devices not only hinders the widespread adoption of these models but also\nposes significant challenges to their further scaling and development. In this\npaper, we introduce HEAR, the first EEG foundation model explicitly designed to\nsupport heterogeneous EEG devices, accommodating varying electrode layouts and\nelectrode counts. HEAR employs a learnable, coordinate-based spatial embedding\nto map electrodes with diverse layouts and varying counts into a unified\nrepresentational space. This unified spatial representation is then processed\nby a novel spatially-guided transformer, which effectively captures\nspatiotemporal dependencies across electrodes. To support the development of\nHEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data\ncollected from over 150 distinct electrode layouts with up to 1,132 electrodes.\nExperimental results demonstrate that HEAR substantially outperforms existing\nEEG foundation models in supporting heterogeneous EEG devices and generalizing\nacross diverse cognitive tasks and subjects."}
{"id": "2510.12332", "pdf": "https://arxiv.org/pdf/2510.12332", "abs": "https://arxiv.org/abs/2510.12332", "authors": ["Mohammadreza Kasaei", "Mostafa Ghobadi", "Mohsen Khadem"], "title": "Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a shape-aware whole-body control framework for\ntendon-driven continuum robots with direct application to endoluminal surgical\nnavigation. Endoluminal procedures, such as bronchoscopy, demand precise and\nsafe navigation through tortuous, patient-specific anatomy where conventional\ntip-only control often leads to wall contact, tissue trauma, or failure to\nreach distal targets. To address these challenges, our approach combines a\nphysics-informed backbone model with residual learning through an Augmented\nNeural ODE, enabling accurate shape estimation and efficient Jacobian\ncomputation. A sampling-based Model Predictive Path Integral (MPPI) controller\nleverages this representation to jointly optimize tip tracking, backbone\nconformance, and obstacle avoidance under actuation constraints. A task manager\nfurther enhances adaptability by allowing real-time adjustment of objectives,\nsuch as wall clearance or direct advancement, during tele-operation. Extensive\nsimulation studies demonstrate millimeter-level accuracy across diverse\nscenarios, including trajectory tracking, dynamic obstacle avoidance, and\nshape-constrained reaching. Real-robot experiments on a bronchoscopy phantom\nvalidate the framework, showing improved lumen-following accuracy, reduced wall\ncontacts, and enhanced adaptability compared to joystick-only navigation and\nexisting baselines. These results highlight the potential of the proposed\nframework to increase safety, reliability, and operator efficiency in minimally\ninvasive endoluminal surgery, with broader applicability to other confined and\nsafety-critical environments."}
{"id": "2510.12648", "pdf": "https://arxiv.org/pdf/2510.12648", "abs": "https://arxiv.org/abs/2510.12648", "authors": ["Abdelali Arous", "Hamza Haif", "Arman Farhang", "Huseyin Arslan"], "title": "A Unified Framework for Adaptive Waveform Processing in Next Generation Wireless Networks", "categories": ["eess.SP"], "comment": null, "summary": "The emergence of alternative multiplexing domains to the time-frequency\ndomains, e.g., the delay-Doppler and chirp domains, offers a promising approach\nfor addressing the challenges posed by complex propagation environments and\nnext-generation applications. Unlike the time and frequency domains, these\ndomains offer unique channel representations which provide additional degrees\nof freedom (DoF) for modeling, characterizing, and exploiting wireless channel\nfeatures. This article provides a comprehensive analysis of channel\ncharacteristics, including delay, Doppler shifts, and channel coefficients\nacross various domains, with an emphasis on their inter-domain relationships,\nshared characteristics, and domain-specific distinctions. We further evaluate\nthe comparative advantages of each domain under specific channel conditions.\nBuilding on this analysis, we propose a generalized and adaptive transform\ndomain framework that leverages the pre- and post-processing of the discrete\nFourier transform (DFT) matrix, to enable dynamic transitions between various\ndomains in response to the channel conditions and system requirements. Finally,\nseveral representative use cases are presented to demonstrate the applicability\nof the proposed cross-domain waveform processing framework in diverse\nscenarios, along with future directions and challenges."}
{"id": "2510.12340", "pdf": "https://arxiv.org/pdf/2510.12340", "abs": "https://arxiv.org/abs/2510.12340", "authors": ["Nicky Mol", "Luka Peternel", "Alessandro Ianniello", "Denis Zatyagov", "Auke Nachenius", "Stephan Balvert", "J. Micah Prendergast", "Sara Muscolo", "Olger Siebinga", "Eva Verhoef", "Deborah Forster", "David A. Abbink"], "title": "Achieving Meaningful Collaboration: Worker-centered Design of a Physical Human-Robot Collaborative Blending Task", "categories": ["cs.RO"], "comment": "3 pages, 1 figure, ICRA@40 (Extended abstract)", "summary": "The use of robots in industrial settings continues to grow, driven by the\nneed to address complex societal challenges such as labor shortages, aging\npopulations, and ever-increasing production demands. In this abstract, we\nadvocate for (and demonstrate) a transdisciplinary approach when considering\nrobotics in the workplace. Transdisciplinarity emphasizes the integration of\nacademic research with pragmatic expertise and embodied experiential knowledge,\nthat prioritize values such as worker wellbeing and job attractiveness. In the\nfollowing, we describe an ongoing multi-pronged effort to explore the potential\nof collaborative robots in the context of airplane engine repair and\nmaintenance operations."}
{"id": "2510.12651", "pdf": "https://arxiv.org/pdf/2510.12651", "abs": "https://arxiv.org/abs/2510.12651", "authors": ["Axel Janson", "Joakim Andén"], "title": "Moment-based Posterior Sampling for Multi-reference Alignment", "categories": ["eess.SP"], "comment": null, "summary": "We propose a Bayesian approach to the problem of multi-reference alignment --\nthe recovery of signals from noisy, randomly shifted observations. While\nexisting frequentist methods accurately recover the signal at arbitrarily low\nsignal-to-noise ratios, they require a large number of samples to do so. In\ncontrast, our proposed method leverages diffusion models as data-driven\nplug-and-play priors, conditioning these on the sample power spectrum (a\nshift-invariant statistic) enabling both accurate posterior sampling and\nuncertainty quantification. The use of an appropriate prior significantly\nreduces the required number of samples, as illustrated in simulation\nexperiments with comparisons to state-of-the-art methods such as\nexpectation--maximization and bispectrum inversion. These findings establish\nour approach as a promising framework for other orbit recovery problems, such\nas cryogenic electron microscopy (cryo-EM)."}
{"id": "2510.12346", "pdf": "https://arxiv.org/pdf/2510.12346", "abs": "https://arxiv.org/abs/2510.12346", "authors": ["Bingquan Li", "Ning Wang", "Tianwei Zhang", "Zhicheng He", "Yucong Wu"], "title": "PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing", "categories": ["cs.RO"], "comment": null, "summary": "Recently, biped robot walking technology has been significantly developed,\nmainly in the context of a bland walking scheme. To emulate human walking,\nrobots need to step on the positions they see in unknown spaces accurately. In\nthis paper, we present PolyMap, a perception-based locomotion planning\nframework for humanoid robots to climb stairs. Our core idea is to build a\nreal-time polygonal staircase plane semantic map, followed by a footstep planar\nusing these polygonal plane segments. These plane segmentation and visual\nodometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The\nproposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz\nwhole-body motion planning output. Both indoor and outdoor real-scene\nexperiments indicate that our method is efficient and robust for humanoid robot\nstair climbing."}
{"id": "2510.12711", "pdf": "https://arxiv.org/pdf/2510.12711", "abs": "https://arxiv.org/abs/2510.12711", "authors": ["Muhammad Talha", "Besma Smida", "David González G"], "title": "Enhanced Angle-Range Cluster Parameter Estimation in Full-Duplex ISAC Systems", "categories": ["eess.SP"], "comment": "8 pages, 5 figures", "summary": "This work studies an integrated sensing and communication (ISAC) framework\nfor targets that are spread both in the angle and range domains. We model each\ntarget using a cluster of rays parameterized by a specific density function,\nand propose a truncated Multiple Signal Classification (MUSIC) spread (TMS)\nalgorithm to accurately estimate the parameters of the density function. Unlike\nthe conventional MUSIC spread (CMS), TMS restricts the signal subspace rank\nbased on the eigen decomposition of the received-signal autocorrelation. We\nalso propose a discrete Fourier transform (DFT) based algorithm for estimating\nthe distance and range spread of each target. Leveraging these estimates, we\nthen develop a dynamic transmit beamforming algorithm that successfully\nilluminates multiple targets while also serving multiple downlink (DL) users.\nSimulation results demonstrate the superiority of our proposed algorithms over\nbaseline schemes in both low and high signal-to-noise ratio (SNR) regimes as\nwell as under a wide angular spread regime."}
{"id": "2510.12363", "pdf": "https://arxiv.org/pdf/2510.12363", "abs": "https://arxiv.org/abs/2510.12363", "authors": ["Jiale Fan", "Andrei Cramariuc", "Tifanny Portela", "Marco Hutter"], "title": "Pretraining in Actor-Critic Reinforcement Learning for Robot Motion Control", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted to ICLR 2026", "summary": "The pretraining-finetuning paradigm has facilitated numerous transformative\nadvancements in artificial intelligence research in recent years. However, in\nthe domain of reinforcement learning (RL) for robot motion control, individual\nskills are often learned from scratch despite the high likelihood that some\ngeneralizable knowledge is shared across all task-specific policies belonging\nto a single robot embodiment. This work aims to define a paradigm for\npretraining neural network models that encapsulate such knowledge and can\nsubsequently serve as a basis for warm-starting the RL process in classic\nactor-critic algorithms, such as Proximal Policy Optimization (PPO). We begin\nwith a task-agnostic exploration-based data collection algorithm to gather\ndiverse, dynamic transition data, which is then used to train a Proprioceptive\nInverse Dynamics Model (PIDM) through supervised learning. The pretrained\nweights are loaded into both the actor and critic networks to warm-start the\npolicy optimization of actual tasks. We systematically validated our proposed\nmethod on seven distinct robot motion control tasks, showing significant\nbenefits to this initialization strategy. Our proposed approach on average\nimproves sample efficiency by 40.1% and task performance by 7.5%, compared to\nrandom initialization. We further present key ablation studies and empirical\nanalyses that shed light on the mechanisms behind the effectiveness of our\nmethod."}
{"id": "2510.12763", "pdf": "https://arxiv.org/pdf/2510.12763", "abs": "https://arxiv.org/abs/2510.12763", "authors": ["Saurabh Sihag", "Gonzalo Mateos", "Alejandro Ribeiro"], "title": "Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective", "categories": ["eess.SP", "cs.AI", "q-bio.QM"], "comment": "Accepted for publication in IEEE Signal Processing Magazine", "summary": "Neurodegeneration, characterized by the progressive loss of neuronal\nstructure or function, is commonly assessed in clinical practice through\nreductions in cortical thickness or brain volume, as visualized by structural\nMRI. While informative, these conventional approaches lack the statistical\nsophistication required to fully capture the spatially correlated and\nheterogeneous nature of neurodegeneration, which manifests both in healthy\naging and in neurological disorders. To address these limitations, brain age\ngap has emerged as a promising data-driven biomarker of brain health. The brain\nage gap prediction (BAGP) models estimate the difference between a person's\npredicted brain age from neuroimaging data and their chronological age. The\nresulting brain age gap serves as a compact biomarker of brain health, with\nrecent studies demonstrating its predictive utility for disease progression and\nseverity. However, practical adoption of BAGP models is hindered by their\nmethodological obscurities and limited generalizability across diverse clinical\npopulations. This tutorial article provides an overview of BAGP and introduces\na principled framework for this application based on recent advancements in\ngraph signal processing (GSP). In particular, we focus on graph neural networks\n(GNNs) and introduce the coVariance neural network (VNN), which leverages the\nanatomical covariance matrices derived from structural MRI. VNNs offer strong\ntheoretical grounding and operational interpretability, enabling robust\nestimation of brain age gap predictions. By integrating perspectives from GSP,\nmachine learning, and network neuroscience, this work clarifies the path\nforward for reliable and interpretable BAGP models and outlines future research\ndirections in personalized medicine."}
{"id": "2510.12370", "pdf": "https://arxiv.org/pdf/2510.12370", "abs": "https://arxiv.org/abs/2510.12370", "authors": ["Wenli Shi", "Clemence Grislain", "Olivier Sigaud", "Mohamed Chetouani"], "title": "Controlling Intent Expressiveness in Robot Motion with Diffusion Models", "categories": ["cs.RO"], "comment": "Using diffusion models trained on quality diversity datasets for\n  generating robot motions with adjustable legibility levels", "summary": "Legibility of robot motion is critical in human-robot interaction, as it\nallows humans to quickly infer a robot's intended goal. Although traditional\ntrajectory generation methods typically prioritize efficiency, they often fail\nto make the robot's intentions clear to humans. Meanwhile, existing approaches\nto legible motion usually produce only a single \"most legible\" trajectory,\noverlooking the need to modulate intent expressiveness in different contexts.\nIn this work, we propose a novel motion generation framework that enables\ncontrollable legibility across the full spectrum, from highly legible to highly\nambiguous motions. We introduce a modeling approach based on an Information\nPotential Field to assign continuous legibility scores to trajectories, and\nbuild upon it with a two-stage diffusion framework that first generates paths\nat specified legibility levels and then translates them into executable robot\nactions. Experiments in both 2D and 3D reaching tasks demonstrate that our\napproach produces diverse and controllable motions with varying degrees of\nlegibility, while achieving performance comparable to SOTA. Code and project\npage: https://legibility-modulator.github.io."}
{"id": "2510.12338", "pdf": "https://arxiv.org/pdf/2510.12338", "abs": "https://arxiv.org/abs/2510.12338", "authors": ["Mohamed Abdalmoaty", "Verena Häberle", "Xiuqiang He", "Florian Dörfler"], "title": "Ultrafast Grid Impedance Identification in $dq$-Asymmetric Three-Phase Power Systems", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": null, "summary": "We propose a non-parametric frequency-domain method to identify small-signal\n$dq$-asymmetric grid impedances, over a wide frequency band, using\ngrid-connected converters. Existing identification methods are faced with\nsignificant trade-offs: e.g., passive approaches rely on ambient harmonics and\nrare grid events and thus can only provide estimates at a few frequencies,\nwhile many active approaches that intentionally perturb grid operation require\nlong time series measurement and specialized equipment. Although active\ntime-domain methods reduce the measurement time, they either make crude\nsimplifying assumptions or require laborious model order tuning. Our approach\neffectively addresses these challenges: it does not require specialized\nexcitation signals or hardware and achieves ultrafast ($<1$ s) identification,\ndrastically reducing measurement time. Being non-parametric, our approach also\nmakes no assumptions on the grid structure. A detailed electromagnetic\ntransient simulation is used to validate the method and demonstrate its clear\nsuperiority over existing alternatives."}
{"id": "2510.12392", "pdf": "https://arxiv.org/pdf/2510.12392", "abs": "https://arxiv.org/abs/2510.12392", "authors": ["Junhyuk So", "Chiwoong Lee", "Shinyoung Lee", "Jungseul Ok", "Eunhyeok Park"], "title": "Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted at NeurIPS25", "summary": "Generative Behavior Cloning (GBC) is a simple yet effective framework for\nrobot learning, particularly in multi-task settings. Recent GBC methods often\nemploy diffusion policies with open-loop (OL) control, where actions are\ngenerated via a diffusion process and executed in multi-step chunks without\nreplanning. While this approach has demonstrated strong success rates and\ngeneralization, its inherent stochasticity can result in erroneous action\nsampling, occasionally leading to unexpected task failures. Moreover, OL\ncontrol suffers from delayed responses, which can degrade performance in noisy\nor dynamic environments. To address these limitations, we propose two novel\ntechniques to enhance the consistency and reactivity of diffusion policies: (1)\nself-guidance, which improves action fidelity by leveraging past observations\nand implicitly promoting future-aware behavior; and (2) adaptive chunking,\nwhich selectively updates action sequences when the benefits of reactivity\noutweigh the need for temporal consistency. Extensive experiments show that our\napproach substantially improves GBC performance across a wide range of\nsimulated and real-world robotic manipulation tasks. Our code is available at\nhttps://github.com/junhyukso/SGAC"}
{"id": "2510.12539", "pdf": "https://arxiv.org/pdf/2510.12539", "abs": "https://arxiv.org/abs/2510.12539", "authors": ["Zhanle Zhao", "Son Dinh-Van", "Yuen Kwan Mo", "Siddartha Khastgir", "Matthew D. Higgins"], "title": "Optimising Communication Control Factors for Energy Consumption in Rural LOS V2X", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": null, "summary": "Connected braking can reduce fatal collisions in connected and autonomous\nvehicles (CAVs) by using reliable, low-latency 5G New Radio (NR) links,\nespecially NR Sidelink Vehicle-to-Everything (V2X). In rural areas, road side\nunits are sparse and power-constrained or off-grid, so energy efficiency must\nbe considered alongside safety. This paper studies how three communication\ncontrol factors including subcarrier spacing ($\\mathrm{SCS}$), modulation and\ncoding scheme ($\\mathrm{MCS}$), and transmit power ($P_{\\mathrm{t}}$) should be\nconfigured to balance safety and energy consumption in rural line-of-sight\n(LOS) scenarios in light and heavy traffic scenarios. Safety is quantified by\nthe packet receive ratio ($\\mathrm{PRR}$) against the minimum communication\ndistance $D_{\\mathrm{comm}}$, defined as the distance that the vehicle travels\nduring the transmission of the safety message. Results show that, under heavy\ntraffic, increasing $P_{\\mathrm{t}}$ and selecting a low-rate $\\mathrm{MCS}$ at\n$\\mathrm{SCS} = 30$ kHz sustains high $\\mathrm{PRR}$ at $D_{\\mathrm{comm}}$,\nalbeit with higher energy cost. In light traffic, maintaining lower\n$P_\\mathrm{t}$ with low $\\mathrm{MCS}$ levels achieves a favorable\nreliability-energy trade-off while preserving acceptable $\\mathrm{PRR}$ at\n$D_{\\mathrm{comm}}$. These findings demonstrate the necessity of adaptive,\nenergy-aware strategy to guarantee both safety and energy efficiency in rural\nV2X systems."}
{"id": "2510.12403", "pdf": "https://arxiv.org/pdf/2510.12403", "abs": "https://arxiv.org/abs/2510.12403", "authors": ["Francesco Capuano", "Caroline Pascal", "Adil Zouitine", "Thomas Wolf", "Michel Aractingi"], "title": "Robot Learning: A Tutorial", "categories": ["cs.RO", "cs.LG"], "comment": "Tutorial on Robot Learning using LeRobot, the end-to-end robot\n  learning library developed by Hugging Face", "summary": "Robot learning is at an inflection point, driven by rapid advancements in\nmachine learning and the growing availability of large-scale robotics data.\nThis shift from classical, model-based methods to data-driven, learning-based\nparadigms is unlocking unprecedented capabilities in autonomous systems. This\ntutorial navigates the landscape of modern robot learning, charting a course\nfrom the foundational principles of Reinforcement Learning and Behavioral\nCloning to generalist, language-conditioned models capable of operating across\ndiverse tasks and even robot embodiments. This work is intended as a guide for\nresearchers and practitioners, and our goal is to equip the reader with the\nconceptual understanding and practical tools necessary to contribute to\ndevelopments in robot learning, with ready-to-use examples implemented in\n$\\texttt{lerobot}$."}
{"id": "2510.12754", "pdf": "https://arxiv.org/pdf/2510.12754", "abs": "https://arxiv.org/abs/2510.12754", "authors": ["Diwakara Reddy", "Christian Herglotz", "André Kaup"], "title": "A High-Level Feature Model to Predict the Encoding Energy of a Hardware Video Encoder", "categories": ["eess.IV", "eess.SP"], "comment": "Accepted for Picture Coding Symposium (PCS) 2025", "summary": "In today's society, live video streaming and user generated content streamed\nfrom battery powered devices are ubiquitous. Live streaming requires real-time\nvideo encoding, and hardware video encoders are well suited for such an\nencoding task. In this paper, we introduce a high-level feature model using\nGaussian process regression that can predict the encoding energy of a hardware\nvideo encoder. In an evaluation setup restricted to only P-frames and a single\nkeyframe, the model can predict the encoding energy with a mean absolute\npercentage error of approximately 9%. Further, we demonstrate with an ablation\nstudy that spatial resolution is a key high-level feature for encoding energy\nprediction of a hardware encoder. A practical application of our model is that\nit can be used to perform a prior estimation of the energy required to encode a\nvideo at various spatial resolutions, with different coding standards and codec\npresets."}
{"id": "2510.12419", "pdf": "https://arxiv.org/pdf/2510.12419", "abs": "https://arxiv.org/abs/2510.12419", "authors": ["Shunnosuke Yoshimura", "Kento Kawaharazuka", "Kei Okada"], "title": "M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing", "categories": ["cs.RO"], "comment": "Accepted to IROS2025, Website:\n  https://ssk-yoshimura.github.io/M3D-skin/", "summary": "Tactile sensors have a wide range of applications, from utilization in\nrobotic grippers to human motion measurement. If tactile sensors could be\nfabricated and integrated more easily, their applicability would further\nexpand. In this study, we propose a tactile sensor-M3D-skin-that can be easily\nfabricated with high versatility by leveraging the infill patterns of a\nmulti-material fused deposition modeling (FDM) 3D printer as the sensing\nprinciple. This method employs conductive and non-conductive flexible filaments\nto create a hierarchical structure with a specific infill pattern. The flexible\nhierarchical structure deforms under pressure, leading to a change in\nelectrical resistance, enabling the acquisition of tactile information. We\nmeasure the changes in characteristics of the proposed tactile sensor caused by\nmodifications to the hierarchical structure. Additionally, we demonstrate the\nfabrication and use of a multi-tile sensor. Furthermore, as applications, we\nimplement motion pattern measurement on the sole of a foot, integration with a\nrobotic hand, and tactile-based robotic operations. Through these experiments,\nwe validate the effectiveness of the proposed tactile sensor."}
{"id": "2510.12477", "pdf": "https://arxiv.org/pdf/2510.12477", "abs": "https://arxiv.org/abs/2510.12477", "authors": ["Gaoyuan Liu", "Joris de Winter", "Kelly Merckaert", "Denis Steckelmacher", "Ann Nowe", "Bram Vanderborght"], "title": "A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation", "categories": ["cs.RO"], "comment": null, "summary": "In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the\ntwo core properties to evaluate robot performance. However, safety mechanisms\nusually hinder task efficiency since human intervention will cause backup\nmotions and goal failures of the robot. Frequent motion replanning will\nincrease the computational load and the chance of failure. In this paper, we\npresent a hybrid Reinforcement Learning (RL) planning framework which is\ncomprised of an interactive motion planner and a RL task planner. The RL task\nplanner attempts to choose statistically safe and efficient task sequences\nbased on the feedback from the motion planner, while the motion planner keeps\nthe task execution process collision-free by detecting human arm motions and\ndeploying new paths when the previous path is not valid anymore. Intuitively,\nthe RL agent will learn to avoid dangerous tasks, while the motion planner\nensures that the chosen tasks are safe. The proposed framework is validated on\nthe cobot in both simulation and the real world, we compare the planner with\nhard-coded task motion planning methods. The results show that our planning\nframework can 1) react to uncertain human motions at both joint and task\nlevels; 2) reduce the times of repeating failed goal commands; 3) reduce the\ntotal number of replanning requests."}
{"id": "2510.12483", "pdf": "https://arxiv.org/pdf/2510.12483", "abs": "https://arxiv.org/abs/2510.12483", "authors": ["Jingkai Jia", "Tong Yang", "Xueyao Chen", "Chenhuan Liu", "Wenqiang Zhang"], "title": "Fast Visuomotor Policy for Robotic Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "We present a fast and effective policy framework for robotic manipulation,\nnamed Energy Policy, designed for high-frequency robotic tasks and\nresource-constrained systems. Unlike existing robotic policies, Energy Policy\nnatively predicts multimodal actions in a single forward pass, enabling\nhigh-precision manipulation at high speed. The framework is built upon two core\ncomponents. First, we adopt the energy score as the learning objective to\nfacilitate multimodal action modeling. Second, we introduce an energy MLP to\nimplement the proposed objective while keeping the architecture simple and\nefficient. We conduct comprehensive experiments in both simulated environments\nand real-world robotic tasks to evaluate the effectiveness of Energy Policy.\nThe results show that Energy Policy matches or surpasses the performance of\nstate-of-the-art manipulation methods while significantly reducing\ncomputational overhead. Notably, on the MimicGen benchmark, Energy Policy\nachieves superior performance with at a faster inference compared to existing\napproaches."}
{"id": "2510.12509", "pdf": "https://arxiv.org/pdf/2510.12509", "abs": "https://arxiv.org/abs/2510.12509", "authors": ["Gaoyuan Liu", "Bas Boom", "Naftali Slob", "Yuri Durodié", "Ann Nowé", "Bram Vanderborght"], "title": "Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge", "categories": ["cs.RO"], "comment": null, "summary": "Pruning is an essential agricultural practice for orchards. Proper pruning\ncan promote healthier growth and optimize fruit production throughout the\norchard's lifespan. Robot manipulators have been developed as an automated\nsolution for this repetitive task, which typically requires seasonal labor with\nspecialized skills. While previous research has primarily focused on the\nchallenges of perception, the complexities of manipulation are often\noverlooked. These challenges involve planning and control in both joint and\nCartesian spaces to guide the end-effector through intricate, obstructive\nbranches. Our work addresses the behavior planning challenge for a robotic\npruning system, which entails a multi-level planning problem in environments\nwith complex collisions. In this paper, we formulate the planning problem for a\nhigh-dimensional robotic arm in a pruning scenario, investigate the system's\nintrinsic redundancies, and propose a comprehensive pruning workflow that\nintegrates perception, modeling, and holistic planning. In our experiments, we\ndemonstrate that more comprehensive planning methods can significantly enhance\nthe performance of the robotic manipulator. Finally, we implement the proposed\nworkflow on a real-world robot. As a result, this work complements previous\nefforts on robotic pruning and motivates future research and development in\nplanning for pruning applications."}
{"id": "2510.12528", "pdf": "https://arxiv.org/pdf/2510.12528", "abs": "https://arxiv.org/abs/2510.12528", "authors": ["Muxing Huang", "Zibin Chen", "Weiliang Xu", "Zilan Li", "Yuanzhi Zhou", "Guoyuan Zhou", "Wenjing Chen", "Xinming Li"], "title": "Two-stream network-driven vision-based tactile sensor for object feature extraction and fusion perception", "categories": ["cs.RO", "physics.app-ph"], "comment": null, "summary": "Tactile perception is crucial for embodied intelligent robots to recognize\nobjects. Vision-based tactile sensors extract object physical attributes\nmultidimensionally using high spatial resolution; however, this process\ngenerates abundant redundant information. Furthermore, single-dimensional\nextraction, lacking effective fusion, fails to fully characterize object\nattributes. These challenges hinder the improvement of recognition accuracy. To\naddress this issue, this study introduces a two-stream network feature\nextraction and fusion perception strategy for vision-based tactile systems.\nThis strategy employs a distributed approach to extract internal and external\nobject features. It obtains depth map information through three-dimensional\nreconstruction while simultaneously acquiring hardness information by measuring\ncontact force data. After extracting features with a convolutional neural\nnetwork (CNN), weighted fusion is applied to create a more informative and\neffective feature representation. In standard tests on objects of varying\nshapes and hardness, the force prediction error is 0.06 N (within a 12 N\nrange). Hardness recognition accuracy reaches 98.0%, and shape recognition\naccuracy reaches 93.75%. With fusion algorithms, object recognition accuracy in\nactual grasping scenarios exceeds 98.5%. Focused on object physical attributes\nperception, this method enhances the artificial tactile system ability to\ntransition from perception to cognition, enabling its use in embodied\nperception applications."}
{"id": "2510.12611", "pdf": "https://arxiv.org/pdf/2510.12611", "abs": "https://arxiv.org/abs/2510.12611", "authors": ["Lukas Pries", "Markus Ryll"], "title": "Learning Robust Agile Flight Control with Stability Guarantees", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "In the evolving landscape of high-speed agile quadrotor flight, achieving\nprecise trajectory tracking at the platform's operational limits is paramount.\nControllers must handle actuator constraints, exhibit robustness to\ndisturbances, and remain computationally efficient for safety-critical\napplications. In this work, we present a novel neural-augmented feedback\ncontroller for agile flight control. The controller addresses individual\nlimitations of existing state-of-the-art control paradigms and unifies their\nstrengths. We demonstrate the controller's capabilities, including the accurate\ntracking of highly aggressive trajectories that surpass the feasibility of the\nactuators. Notably, the controller provides universal stability guarantees,\nenhancing its robustness and tracking performance even in exceedingly\ndisturbance-prone settings. Its nonlinear feedback structure is highly\nefficient enabling fast computation at high update rates. Moreover, the\nlearning process in simulation is both fast and stable, and the controller's\ninherent robustness allows direct deployment to real-world platforms without\nthe need for training augmentations or fine-tuning."}
{"id": "2510.12630", "pdf": "https://arxiv.org/pdf/2510.12630", "abs": "https://arxiv.org/abs/2510.12630", "authors": ["Ajith Anil Meera", "Abian Torres", "Pablo Lanillos"], "title": "Designing Tools with Control Confidence", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Prehistoric humans invented stone tools for specialized tasks by not just\nmaximizing the tool's immediate goal-completion accuracy, but also increasing\ntheir confidence in the tool for later use under similar settings. This factor\ncontributed to the increased robustness of the tool, i.e., the least\nperformance deviations under environmental uncertainties. However, the current\nautonomous tool design frameworks solely rely on performance optimization,\nwithout considering the agent's confidence in tool use for repeated use. Here,\nwe take a step towards filling this gap by i) defining an optimization\nframework for task-conditioned autonomous hand tool design for robots, where\nii) we introduce a neuro-inspired control confidence term into the optimization\nroutine that helps the agent to design tools with higher robustness. Through\nrigorous simulations using a robotic arm, we show that tools designed with\ncontrol confidence as the objective function are more robust to environmental\nuncertainties during tool use than a pure accuracy-driven objective. We further\nshow that adding control confidence to the objective function for tool design\nprovides a balance between the robustness and goal accuracy of the designed\ntools under control perturbations. Finally, we show that our CMAES-based\nevolutionary optimization strategy for autonomous tool design outperforms other\nstate-of-the-art optimizers by designing the optimal tool within the fewest\niterations. Code: https://github.com/ajitham123/Tool_design_control_confidence."}
{"id": "2510.12662", "pdf": "https://arxiv.org/pdf/2510.12662", "abs": "https://arxiv.org/abs/2510.12662", "authors": ["Oz Gitelson", "Satya Prakash Nayak", "Ritam Raha", "Anne-Kathrin Schmuck"], "title": "Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop", "categories": ["cs.RO"], "comment": null, "summary": "We present a novel framework for human-robot \\emph{logical} interaction that\nenables robots to reliably satisfy (infinite horizon) temporal logic tasks\nwhile effectively collaborating with humans who pursue independent and unknown\ntasks. The framework combines two key capabilities: (i) \\emph{maximal\nadaptation} enables the robot to adjust its strategy \\emph{online} to exploit\nhuman behavior for cooperation whenever possible, and (ii) \\emph{minimal\ntunable feedback} enables the robot to request cooperation by the human online\nonly when necessary to guarantee progress. This balance minimizes human-robot\ninterference, preserves human autonomy, and ensures persistent robot task\nsatisfaction even under conflicting human goals. We validate the approach in a\nreal-world block-manipulation task with a Franka Emika Panda robotic arm and in\nthe Overcooked-AI benchmark, demonstrating that our method produces rich,\n\\emph{emergent} cooperative behaviors beyond the reach of existing approaches,\nwhile maintaining strong formal guarantees."}
{"id": "2510.12684", "pdf": "https://arxiv.org/pdf/2510.12684", "abs": "https://arxiv.org/abs/2510.12684", "authors": ["Alvaro Belmonte-Baeza", "Miguel Cazorla", "Gabriel J. García", "Carlos J. Pérez-Del-Pulgar", "Jorge Pomares"], "title": "Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "This is the authors version of the paper accepted for publication in\n  The IEEE International Conference on Space Robotics 2025. The final version\n  link will be added here after conference proceedings are published", "summary": "Robotics plays a pivotal role in planetary science and exploration, where\nautonomous and reliable systems are crucial due to the risks and challenges\ninherent to space environments. The establishment of permanent lunar bases\ndemands robotic platforms capable of navigating and manipulating in the harsh\nlunar terrain. While wheeled rovers have been the mainstay for planetary\nexploration, their limitations in unstructured and steep terrains motivate the\nadoption of legged robots, which offer superior mobility and adaptability. This\npaper introduces a constrained reinforcement learning framework designed for\nautonomous quadrupedal mobile manipulators operating in lunar environments. The\nproposed framework integrates whole-body locomotion and manipulation\ncapabilities while explicitly addressing critical safety constraints, including\ncollision avoidance, dynamic stability, and power efficiency, in order to\nensure robust performance under lunar-specific conditions, such as reduced\ngravity and irregular terrain. Experimental results demonstrate the framework's\neffectiveness in achieving precise 6D task-space end-effector pose tracking,\nachieving an average positional accuracy of 4 cm and orientation accuracy of\n8.1 degrees. The system consistently respects both soft and hard constraints,\nexhibiting adaptive behaviors optimized for lunar gravity conditions. This work\neffectively bridges adaptive learning with essential mission-critical safety\nrequirements, paving the way for advanced autonomous robotic explorers for\nfuture lunar missions."}
{"id": "2510.12710", "pdf": "https://arxiv.org/pdf/2510.12710", "abs": "https://arxiv.org/abs/2510.12710", "authors": ["Baicheng Li", "Dong Wu", "Zike Yan", "Xinchen Liu", "Zecui Zeng", "Lusong Li", "Hongbin Zha"], "title": "Reflection-Based Task Adaptation for Self-Improving VLA", "categories": ["cs.RO"], "comment": null, "summary": "Pre-trained Vision-Language-Action (VLA) models represent a major leap\ntowards general-purpose robots, yet efficiently adapting them to novel,\nspecific tasks in-situ remains a significant hurdle. While reinforcement\nlearning (RL) is a promising avenue for such adaptation, the process often\nsuffers from low efficiency, hindering rapid task mastery. We introduce\nReflective Self-Adaptation, a framework for rapid, autonomous task adaptation\nwithout human intervention. Our framework establishes a self-improving loop\nwhere the agent learns from its own experience to enhance both strategy and\nexecution.\n  The core of our framework is a dual-pathway architecture that addresses the\nfull adaptation lifecycle. First, a Failure-Driven Reflective RL pathway\nenables rapid learning by using the VLM's causal reasoning to automatically\nsynthesize a targeted, dense reward function from failure analysis. This\nprovides a focused learning signal that significantly accelerates policy\nexploration. However, optimizing such proxy rewards introduces a potential risk\nof \"reward hacking,\" where the agent masters the reward function but fails the\nactual task. To counteract this, our second pathway, Success-Driven\nQuality-Guided SFT, grounds the policy in holistic success. It identifies and\nselectively imitates high-quality successful trajectories, ensuring the agent\nremains aligned with the ultimate task goal. This pathway is strengthened by a\nconditional curriculum mechanism to aid initial exploration.\n  We conduct experiments in challenging manipulation tasks. The results\ndemonstrate that our framework achieves faster convergence and higher final\nsuccess rates compared to representative baselines. Our work presents a robust\nsolution for creating self-improving agents that can efficiently and reliably\nadapt to new environments."}
{"id": "2510.12717", "pdf": "https://arxiv.org/pdf/2510.12717", "abs": "https://arxiv.org/abs/2510.12717", "authors": ["Se Hwan Jeon", "Ho Jae Lee", "Seungwoo Hong", "Sangbae Kim"], "title": "Residual MPC: Blending Reinforcement Learning with GPU-Parallelized Model Predictive Control", "categories": ["cs.RO"], "comment": "TRO submission preprint", "summary": "Model Predictive Control (MPC) provides interpretable, tunable locomotion\ncontrollers grounded in physical models, but its robustness depends on frequent\nreplanning and is limited by model mismatch and real-time computational\nconstraints. Reinforcement Learning (RL), by contrast, can produce highly\nrobust behaviors through stochastic training but often lacks interpretability,\nsuffers from out-of-distribution failures, and requires intensive reward\nengineering. This work presents a GPU-parallelized residual architecture that\ntightly integrates MPC and RL by blending their outputs at the torque-control\nlevel. We develop a kinodynamic whole-body MPC formulation evaluated across\nthousands of agents in parallel at 100 Hz for RL training. The residual policy\nlearns to make targeted corrections to the MPC outputs, combining the\ninterpretability and constraint handling of model-based control with the\nadaptability of RL. The model-based control prior acts as a strong bias,\ninitializing and guiding the policy towards desirable behavior with a simple\nset of rewards. Compared to standalone MPC or end-to-end RL, our approach\nachieves higher sample efficiency, converges to greater asymptotic rewards,\nexpands the range of trackable velocity commands, and enables zero-shot\nadaptation to unseen gaits and uneven terrain."}
{"id": "2510.12724", "pdf": "https://arxiv.org/pdf/2510.12724", "abs": "https://arxiv.org/abs/2510.12724", "authors": ["Xin Fei", "Zhixuan Xu", "Huaicong Fang", "Tianrui Zhang", "Lin Shao"], "title": "T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping", "categories": ["cs.RO"], "comment": "12 pages, 14 figures", "summary": "Dexterous grasping remains a central challenge in robotics due to the\ncomplexity of its high-dimensional state and action space. We introduce T(R,O)\nGrasp, a diffusion-based framework that efficiently generates accurate and\ndiverse grasps across multiple robotic hands. At its core is the T(R,O) Graph,\na unified representation that models spatial transformations between robotic\nhands and objects while encoding their geometric properties. A graph diffusion\nmodel, coupled with an efficient inverse kinematics solver, supports both\nunconditioned and conditioned grasp synthesis. Extensive experiments on a\ndiverse set of dexterous hands show that T(R,O) Grasp achieves average success\nrate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per\nsecond on an NVIDIA A100 40GB GPU, substantially outperforming existing\nbaselines. In addition, our approach is robust and generalizable across\nembodiments while significantly reducing memory consumption. More importantly,\nthe high inference speed enables closed-loop dexterous manipulation,\nunderscoring the potential of T(R,O) Grasp to scale into a foundation model for\ndexterous grasping."}
{"id": "2510.12733", "pdf": "https://arxiv.org/pdf/2510.12733", "abs": "https://arxiv.org/abs/2510.12733", "authors": ["Hang Yu", "Julian Jordan", "Julian Schmidt", "Silvan Lindner", "Alessandro Canevaro", "Wilhelm Stork"], "title": "HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Safe and interpretable motion planning in complex urban environments needs to\nreason about bidirectional multi-agent interactions. This reasoning requires to\nestimate the costs of potential ego driving maneuvers. Many existing planners\ngenerate initial trajectories with sampling-based methods and refine them by\noptimizing on learned predictions of future environment states, which requires\na cost function that encodes the desired vehicle behavior. Designing such a\ncost function can be very challenging, especially if a wide range of complex\nurban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego\nproposal-conditioned predictions, a planner that integrates multimodal\ntrajectory proposals from a learned proposal model as heuristic priors into a\nMonte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,\nwe introduce an ego-conditioned occupancy prediction model, enabling\nconsistent, scene-aware reasoning. Our design significantly simplifies cost\nfunction design in refinement by considering proposal-driven guidance,\nrequiring only minimalistic grid-based cost terms. Evaluations on large-scale\nreal-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves\nstate-of-the-art performance, especially in safety and adaptability."}
{"id": "2510.11754", "pdf": "https://arxiv.org/pdf/2510.11754", "abs": "https://arxiv.org/abs/2510.11754", "authors": ["Dongrong Yang", "Xin Wu", "Yibo Xie", "Xinyi Li", "Qiuwen Wu", "Jackie Wu", "Yang Sheng"], "title": "Zero-Shot Large Language Model Agents for Fully Automated Radiotherapy Treatment Planning", "categories": ["physics.med-ph", "cs.AI", "cs.RO"], "comment": "Accepted for poster presentation at the NeurIPS 2025 Workshop on\n  GenAI for Health: Potential, Trust, and Policy Compliance", "summary": "Radiation therapy treatment planning is an iterative, expertise-dependent\nprocess, and the growing burden of cancer cases has made reliance on manual\nplanning increasingly unsustainable, underscoring the need for automation. In\nthis study, we propose a workflow that leverages a large language model\n(LLM)-based agent to navigate inverse treatment planning for\nintensity-modulated radiation therapy (IMRT). The LLM agent was implemented to\ndirectly interact with a clinical treatment planning system (TPS) to\niteratively extract intermediate plan states and propose new constraint values\nto guide inverse optimization. The agent's decision-making process is informed\nby current observations and previous optimization attempts and evaluations,\nallowing for dynamic strategy refinement. The planning process was performed in\na zero-shot inference setting, where the LLM operated without prior exposure to\nmanually generated treatment plans and was utilized without any fine-tuning or\ntask-specific training. The LLM-generated plans were evaluated on twenty\nhead-and-neck cancer cases against clinical manual plans, with key dosimetric\nendpoints analyzed and reported. The LLM-generated plans achieved comparable\norgan-at-risk (OAR) sparing relative to clinical plans while demonstrating\nimproved hot spot control (Dmax: 106.5% vs. 108.8%) and superior conformity\n(conformity index: 1.18 vs. 1.39 for boost PTV; 1.82 vs. 1.88 for primary PTV).\nThis study demonstrates the feasibility of a zero-shot, LLM-driven workflow for\nautomated IMRT treatment planning in a commercial TPS. The proposed approach\nprovides a generalizable and clinically applicable solution that could reduce\nplanning variability and support broader adoption of AI-based planning\nstrategies."}
{"id": "2510.12072", "pdf": "https://arxiv.org/pdf/2510.12072", "abs": "https://arxiv.org/abs/2510.12072", "authors": ["Zixing Lei", "Sheng Yin", "Yichen Xiong", "Yuanzhuo Ding", "Wenhao Huang", "Yuxi Wei", "Qingyao Xu", "Yiming Li", "Weixin Li", "Yunhong Wang", "Siheng Chen"], "title": "EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making", "categories": ["cs.AI", "cs.RO"], "comment": "10 pages 8 figures", "summary": "Embodied decision-making enables agents to translate high-level goals into\nexecutable actions through continuous interactions within the physical world,\nforming a cornerstone of general-purpose embodied intelligence. Large language\nmodels (LLMs), with their general decision-making capabilities, offer a\npromising path to realize this potential; however, LLMs trained solely on\nlanguage lack exposure to physical environments, limiting their true embodied\nunderstanding. To bridge this gap, we propose the concept of a training ground:\na comprehensive infrastructure that provides task and scene simulation,\nembodied interaction, and feedback signals, offering a one-stop solution for\nLLM acquire genuine embodied decision-making skills. In this work, we present\nEmboMatrix, the first training ground of its kind, providing massive and\ndiverse tasks with efficient simulation and precise rewards. EmboMatrix\nincorporates a series of novel techniques: a multi-agent data engine for\nlarge-scale task and scene generation, a distributed heterogeneous-hardware\nsystem for scalable simulation, and a multi-level reward architecture for\nprecise supervision. Leveraging EmboMatrix, we cultivate EmboBrain, an LLM\nwhose embodied decision-making abilities emerge from extensive embodied\ninteractions. Experiments show that EmboBrain-7B surpasses the 671B DeepSeek-R1\nbaseline by 9.5\\% on two challenging embodied decision-making benchmarks,\ndemonstrating the power of interactive, environment-grounded learning for\nbuilding truly intelligent embodied agents."}
{"id": "2510.12174", "pdf": "https://arxiv.org/pdf/2510.12174", "abs": "https://arxiv.org/abs/2510.12174", "authors": ["Yusen Xie", "Zhenmin Huang", "Jianhao Jiao", "Dimitrios Kanoulas", "Jun Ma"], "title": "UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In this paper, we propose UniGS, a unified map representation and\ndifferentiable framework for high-fidelity multimodal 3D reconstruction based\non 3D Gaussian Splatting. Our framework integrates a CUDA-accelerated\nrasterization pipeline capable of rendering photo-realistic RGB images,\ngeometrically accurate depth maps, consistent surface normals, and semantic\nlogits simultaneously. We redesign the rasterization to render depth via\ndifferentiable ray-ellipsoid intersection rather than using Gaussian centers,\nenabling effective optimization of rotation and scale attribute through\nanalytic depth gradients. Furthermore, we derive the analytic gradient\nformulation for surface normal rendering, ensuring geometric consistency among\nreconstructed 3D scenes. To improve computational and storage efficiency, we\nintroduce a learnable attribute that enables differentiable pruning of\nGaussians with minimal contribution during training. Quantitative and\nqualitative experiments demonstrate state-of-the-art reconstruction accuracy\nacross all modalities, validating the efficacy of our geometry-aware paradigm.\nSource code and multimodal viewer will be available on GitHub."}
{"id": "2510.12360", "pdf": "https://arxiv.org/pdf/2510.12360", "abs": "https://arxiv.org/abs/2510.12360", "authors": ["Weijie Ren", "Haowen Liu", "Guang-Ren Duan"], "title": "A Unidirectionally Connected FAS Approach for 6-DOF Quadrotor Control", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "This paper has been submitted to 2026 IFAC World Congress.\n  Corresponding author: Guang-Ren Duan", "summary": "This paper proposes a unidirectionally connected fully actuated system\n(UC-FAS) approach for the sub-stabilization and tracking control of 6-DOF\nquadrotors, tackling limitations both in state-space and FAS framework to some\nextent. The framework systematically converts underactuated quadrotor dynamics\ninto a UC-FAS model, unifying the existing different FAS transformation ways.\nBy eliminating estimation of the high-order derivatives of control inputs, a\ndrawback of current methods, the UC-FAS model simplifies controller design and\nenables direct eigenstructure assignment for closed-loop dynamics. Simulations\ndemonstrate precise 6-DOF tracking performance. This work bridges theoretical\nFAS approach advancements with practical implementation needs, offering a\nstandardized paradigm for nonlinear quadrotor control."}
{"id": "2510.12560", "pdf": "https://arxiv.org/pdf/2510.12560", "abs": "https://arxiv.org/abs/2510.12560", "authors": ["Xiaoji Zheng", "Ziyuan Yang", "Yanhao Chen", "Yuhang Peng", "Yuanrong Tang", "Gengyuan Liu", "Bokui Chen", "Jiangtao Gong"], "title": "CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "18 pages, 17 figures", "summary": "End-to-end autonomous driving models trained solely with imitation learning\n(IL) often suffer from poor generalization. In contrast, reinforcement learning\n(RL) promotes exploration through reward maximization but faces challenges such\nas sample inefficiency and unstable convergence. A natural solution is to\ncombine IL and RL. Moving beyond the conventional two-stage paradigm (IL\npretraining followed by RL fine-tuning), we propose CoIRL-AD, a competitive\ndual-policy framework that enables IL and RL agents to interact during\ntraining. CoIRL-AD introduces a competition-based mechanism that facilitates\nknowledge exchange while preventing gradient conflicts. Experiments on the\nnuScenes dataset show an 18% reduction in collision rate compared to baselines,\nalong with stronger generalization and improved performance on long-tail\nscenarios. Code is available at: https://github.com/SEU-zxj/CoIRL-AD."}
{"id": "2510.12687", "pdf": "https://arxiv.org/pdf/2510.12687", "abs": "https://arxiv.org/abs/2510.12687", "authors": ["Kunyu Peng", "Di Wen", "Kailun Yang", "Jia Fu", "Yufan Chen", "Ruiping Liu", "Jiamin Wu", "Junwei Zheng", "M. Saquib Sarfraz", "Luc Van Gool", "Danda Pani Paudel", "Rainer Stiefelhagen"], "title": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "The source code is available at https://github.com/KPeng9510/ERELIFM", "summary": "Open-Set Domain Generalization (OSDG) aims to enable deep learning models to\nrecognize unseen categories in new domains, which is crucial for real-world\napplications. Label noise hinders open-set domain generalization by corrupting\nsource-domain knowledge, making it harder to recognize known classes and reject\nunseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL)\nusing hyperbolic prototype-guided meta-learning, they struggle to bridge domain\ngaps, especially with limited clean labeled data. In this paper, we propose\nEvidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first\nintroduce an unsupervised two-stage evidential loss clustering method to\npromote label reliability awareness. Then, we propose a residual flow matching\nmechanism that models structured domain- and category-conditioned residuals,\nenabling diverse and uncertainty-aware transfer paths beyond\ninterpolation-based augmentation. During this meta-learning process, the model\nis optimized such that the update direction on the clean set maximizes the loss\ndecrease on the noisy set, using pseudo labels derived from the most confident\npredicted class for supervision. Experimental results show that EReLiFM\noutperforms existing methods on OSDG-NL, achieving state-of-the-art\nperformance. The source code is available at\nhttps://github.com/KPeng9510/ERELIFM."}
