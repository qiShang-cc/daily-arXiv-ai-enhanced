{"id": "2601.08922", "pdf": "https://arxiv.org/pdf/2601.08922", "abs": "https://arxiv.org/abs/2601.08922", "authors": ["Ayda Nodel Hokmabadi", "Chadi Assi"], "title": "Joint Beamforming and Position Optimization for Movable-Antenna and Movable-Element RIS-Aided Full-Duplex 6G MISO Systems", "categories": ["eess.SP"], "comment": null, "summary": "Full-duplex communication substantially enhances spectral efficiency by enabling simultaneous transmission and reception on the same time-frequency resources. However, its practical deployment remains hindered by strong residual self-interference and inter-user interference, which severely degrade system performance. This work investigates a full-duplex MISO network that leverages movable-antenna base stations (MA-BS) and movable-element reconfigurable intelligent surfaces (ME-RIS) to overcome these limitations in next-generation 6G systems. Unlike conventional fixed-geometry architectures, the proposed framework jointly optimizes antenna and RIS element positions, together with RIS phase shifts, to strengthen desired links while suppressing interference. Our design objective is to maximize the system sum rate through the joint optimization of transmit and receive beamforming vectors, uplink transmit powers, RIS phase shifts, and the spatial locations of both the BS antennas and RIS elements. To solve this challenging nonconvex problem, an alternating optimization algorithm is developed, employing semidefinite relaxation for beamforming design and successive convex approximation for position optimization. Simulation results demonstrate that the proposed ME-RIS-assisted architecture with movable BS antennas offers substantial gains over conventional fixed-position full-duplex networks. These findings highlight the potential of integrating movable antennas with movable RIS elements as a key enabler for high-performance full-duplex operation in future 6G wireless systems."}
{"id": "2601.08946", "pdf": "https://arxiv.org/pdf/2601.08946", "abs": "https://arxiv.org/abs/2601.08946", "authors": ["Konstantinos D. Katsanos", "George C. Alexandropoulos"], "title": "Robust Consensus-Based Distributed Beamforming for Wideband Cell-free Multi-RIS MISO Systems", "categories": ["eess.SP", "cs.IT"], "comment": "5 pages, 1 figure, presented in Asilomar 2025", "summary": "The cell-free networking paradigm constitutes a revolutionary architecture for future generations of wireless networks, which has been recently considered in synergy with Reconfigurable Intelligent Surfaces (RISs), a promising physical-layer technology for signal propagation programmability. In this paper, we focus on wideband cell-free multi-RIS-empowered Multiple-Input Single-Output (MISO) systems and present a decentralized cooperative active and passive beamforming scheme, aiming to provide an efficient alternative towards the cooperation overhead of available centralized schemes depending on central processing unit. Considering imperfect channel information availability and realistic frequency selectivity behavior of each RIS's element response, we devise a distributed optimization approach based on consensus updates for the RISs' phase configurations. Our simulation results showcase that the proposed distributed design is superior to centralized schemes that are based on various Lorentzian-type wideband modeling approaches for the RISs."}
{"id": "2601.09148", "pdf": "https://arxiv.org/pdf/2601.09148", "abs": "https://arxiv.org/abs/2601.09148", "authors": ["Zihan Shen", "Jiaqi Li", "Xudong Dong", "Xiaofei Zhang"], "title": "Joint DOA and Non-circular Phase Estimation of Non-circular Signals for Antenna Arrays: Block Sparse Bayesian Learning Method", "categories": ["eess.SP"], "comment": null, "summary": "This letter proposes a block sparse Bayesian learning (BSBL) algorithm of non-circular (NC) signals for direction-of-arrival (DOA) estimation, which is suitable for arbitrary unknown NC phases. The block sparse NC signal representation model is constructed through a permutation strategy, capturing the available intra-block structure information to enhance recovery performance. After that, we create the sparse probability model and derive the cost function under BSBL framework. Finally, the fast marginal likelihood maximum (FMLM) algorithm is introduced, enabling the rapid implementation of signal recovery by the addition and removal of basis functions. Simulation results demonstrate the effectiveness and the superior performance of our proposed method."}
{"id": "2601.09168", "pdf": "https://arxiv.org/pdf/2601.09168", "abs": "https://arxiv.org/abs/2601.09168", "authors": ["Sojeong Park", "Yeongjun Kim", "Hyun Jong Yang"], "title": "User-Centric Stream Sensing for Grant-Free Access: Deep Learning with Covariance Differencing", "categories": ["eess.SP"], "comment": null, "summary": "Grant-free (GF) access is essential for massive connectivity but faces collision risks due to uncoordinated transmissions. While user-side sensing can mitigate these collisions by enabling autonomous transmission decisions, conventional methods become ineffective in overloaded scenarios where active streams exceed receive antennas. To address this problem, we propose a differential stream sensing framework that reframes the problem from estimating the total stream count to isolating newly activated streams via covariance differencing. We analyze the covariance deviation induced by channel variations to establish a theoretical bound based on channel correlation for determining the sensing window size. To mitigate residual interference from finite sampling, a deep learning (DL) classifier is integrated. Simulations across both independent and identically distributed flat Rayleigh fading and standardized channel environments demonstrate that the proposed method consistently outperforms non-DL baselines and remains robust in overloaded scenarios."}
{"id": "2601.09179", "pdf": "https://arxiv.org/pdf/2601.09179", "abs": "https://arxiv.org/abs/2601.09179", "authors": ["Haotian Zhang", "Shijian Gao", "Xiang Cheng"], "title": "WiFo-M$^2$: Plug-and-Play Multi-Modal Sensing via Foundation Model to Empower Wireless Communications", "categories": ["eess.SP"], "comment": "13 pages, 8 figures, 7 tables", "summary": "The growing adoption of sensor-rich intelligent systems has boosted the use of multi-modal sensing to improve wireless communications. However, traditional methods require extensive manual design of data preprocessing, network architecture, and task-specific fine-tuning, which limits both development scalability and real-world deployment. To address this, we propose WiFo-M$^2$, a foundation model that can be easily plugged into existing deep learning-based transceivers for universal performance gains. To extract generalizable out-of-band (OOB) channel features from multi-modal sensing, we introduce ContraSoM, a contrastive pre-training strategy. Once pre-trained, WiFo-M$^2$ infers future OOB channel features from historical sensor data and strengthens feature robustness via modality-specific data augmentation. Experiments show that WiFo-M$^2$ improves performance across multiple transceiver designs and demonstrates strong generalization to unseen scenarios."}
{"id": "2601.08953", "pdf": "https://arxiv.org/pdf/2601.08953", "abs": "https://arxiv.org/abs/2601.08953", "authors": ["Le Liu", "Bangguo Yu", "Nynke Vellinga", "Ming Cao"], "title": "Fairness risk and its privacy-enabled solution in AI-driven robotic applications", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments."}
{"id": "2601.09186", "pdf": "https://arxiv.org/pdf/2601.09186", "abs": "https://arxiv.org/abs/2601.09186", "authors": ["Weibo Wen", "Shijian Gao", "Haotian Zhang", "Xiang Cheng", "Liuqing Yang"], "title": "WiFo-E: A Scalable Wireless Foundation Model for End-to-End FDD Precoding in Communication Networks", "categories": ["eess.SP"], "comment": null, "summary": "Accurate precoding in massive multiple-input multiple-output (MIMO) frequency-division duplexing (FDD) systems relies on efficient channel state information (CSI) acquisition. End-to-end learning frameworks improve performance by jointly optimizing this process, but they lack scalability and fail to generalize across different system configurations, such as varying numbers of antennas and users. To overcome this limitation, we introduce WiFo-E, a wireless foundation model designed for scalable end-to-end precoding. WiFo-E employs multi-task pretraining on a diverse set of configurations to learn transferable representations of underlying wireless principles. Central to the model is a sparse Mixture-of-Experts (MoE) Transformer architecture, which mitigates task interference and enhances training efficiency by activating specialized parameter subsets adaptively. Extensive simulations demonstrate that WiFo-E outperforms conventional per-configuration training and shows strong generalization to unseen system configurations, providing a flexible and efficient foundation for adaptive massive MIMO precoding."}
{"id": "2601.09031", "pdf": "https://arxiv.org/pdf/2601.09031", "abs": "https://arxiv.org/abs/2601.09031", "authors": ["Xuetao Li", "Wenke Huang", "Mang Ye", "Jifeng Xuan", "Bo Du", "Sheng Liu", "Miao Li"], "title": "Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. However, precise scene understanding and sample-efficient learning from human demonstrations remain critical challenges, severely hindering the applicability and generalizability of existing frameworks. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. To ground high-level reasoning in physical reality, we leverage lightweight 2D geometric inductive biases to enable precise 3D scene understanding within the vision-language model. Specifically, we construct a Long-horizon Geometric Prior Skill Selector that effectively aligns the semantic instructions with spatial constraints, ultimately achieving robust generalization in unseen environments. For the data efficiency issue in robotic action generation, we introduce a Recursive Adaptive Spiking Network. We parameterize robot-object interactions via recursive spiking for spatiotemporal consistency, fully distilling long-horizon dynamic features while mitigating the overfitting issue in sparse demonstration scenarios. Extensive experiments are conducted across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems, encompassing a custom-developed humanoid, a desktop manipulator, and a commercial robotic platform. Empirical results substantiate the superiority of our method over state-of-the-art baselines and validate the efficacy of the proposed modules in diverse generalization scenarios. To facilitate reproducibility, the source code and video demonstrations are publicly available at https://github.com/xtli12/RGMP-S.git."}
{"id": "2601.09205", "pdf": "https://arxiv.org/pdf/2601.09205", "abs": "https://arxiv.org/abs/2601.09205", "authors": ["Ruisi He", "Mi Yang", "Zhengyu Zhang", "Bo Ai", "Zhangdui Zhong"], "title": "Artificial Intelligence Empowered Channel Prediction: A New Paradigm for Propagation Channel Modeling", "categories": ["eess.SP"], "comment": null, "summary": "This paper proposes a novel paradigm centered on Artificial Intelligence (AI)-empowered propagation channel prediction to address the limitations of traditional channel modeling. We present a comprehensive framework that deeply integrates heterogeneous environmental data and physical propagation knowledge into AI models for site-specific channel prediction, which referred to as channel inference. By leveraging AI to infer site-specific wireless channel states, the proposed paradigm enables accurate prediction of channel characteristics at both link and area levels, capturing spatio-temporal evolution of radio propagation. Some novel strategies to realize the paradigm are introduced and discussed, including AI-native and AI-hybrid inference approaches. This paper also investigates how to enhance model generalization through transfer learning and improve interpretability via explainable AI techniques. Our approach demonstrates significant practical efficacy, achieving an average path loss prediction root mean square error (RMSE) of $\\sim$ 4 dB and reducing training time by 60\\%-75\\%. This new modeling paradigm provides a foundational pathway toward high-fidelity, generalizable, and physically consistent propagation channel prediction for future communication networks."}
{"id": "2601.09104", "pdf": "https://arxiv.org/pdf/2601.09104", "abs": "https://arxiv.org/abs/2601.09104", "authors": ["Ko Yamamoto", "Kyosuke Ishibashi", "Hiroki Ishikawa", "Osamu Azami"], "title": "Design Methodology of Hydraulically-driven Soft Robotic Gripper for a Large and Heavy Object", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a design methodology of a hydraulically-driven soft robotic gripper for grasping a large and heavy object -- approximately 10 - 20 kg with 20 - 30 cm diameter. Most existing soft grippers are pneumatically actuated with several hundred kPa pressure, and cannot generate output force sufficient for such a large and heavy object. Instead of pneumatic actuation, hydraulic actuation has a potential to generate much larger power by several MPa pressure. In this study, we develop a hydraulically-driven soft gripper, in which its basic design parameters are determined based on a mathematical model that represents the relationship among the driving pressure, bending angle, object mass and grasping force. Moreover, we selected materials suitable for grasping a heavier object, based on the finite element analysis result of the detailed design. We report experimental results on a 20 kg object grasping and closed-loop control of the finger bending angle."}
{"id": "2601.09317", "pdf": "https://arxiv.org/pdf/2601.09317", "abs": "https://arxiv.org/abs/2601.09317", "authors": ["Nadav Neuberger", "Simon Kollecker", "Martin Kaeske"], "title": "Range-Doppler-Acceleration Estimation for Fast-Moving and Accelerating Targets", "categories": ["eess.SP"], "comment": null, "summary": "A central aspect of every pulsed radar signal processor is the targets Range-Doppler estimation within a Coherent Processing Interval. Conventional methods typically rely on simplifying assumptions, such as linear target motion, narrowband operation, or constant velocity, to enable fast computation. However, these assumptions break down in scenarios involving quadratic range-time behavior, high radial velocities or accelerations, or wideband signals, leading to undesired effects such as intra-pulse Doppler shift/stretch and target migration across Range-Doppler cells. This paper presents a generalized waveform-independent Range-Doppler compression approach that compensates for these effects while maintaining minimal Signal-to-Noise-Ratio loss and practical computational efficiency. The performance limits of the proposed method are analyzed and expressed through a unified metric that depends on both scene and system parameters. Comparison with other approaches is presented, showing their estimation bias and performance degradation."}
{"id": "2601.09163", "pdf": "https://arxiv.org/pdf/2601.09163", "abs": "https://arxiv.org/abs/2601.09163", "authors": ["Tong Wu", "Shoujie Li", "Junhao Gong", "Changqing Guo", "Xingting Li", "Shilong Mu", "Wenbo Ding"], "title": "CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space", "categories": ["cs.RO"], "comment": null, "summary": "Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \\CEI introduces the concept of \\textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \\CEI transfers data and policies from a Franka Panda robot to \\textbf{16} different embodiments across \\textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \\textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\\%. Finally, we demonstrate that \\CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/"}
{"id": "2601.09336", "pdf": "https://arxiv.org/pdf/2601.09336", "abs": "https://arxiv.org/abs/2601.09336", "authors": ["Gabriele Bertoli", "Kai Schroeter", "Rossella Arcucci", "Enrica Caporali"], "title": "A Hybrid Machine Learning Framework for Improved Short-Term Peak-Flow Forecasting", "categories": ["eess.SP"], "comment": "Comments: 16 pages, 6 figures. Revised version in preparation for journal submission", "summary": "Reliable river flow forecasting is an essential component of flood risk management and early warning systems. It enables improved emergency response coordination and is critical for protecting infrastructure, communities, and ecosystems from extreme hydrological events. Process-based hydrological models and purely data-driven approaches often underperform during extreme events, particularly in forecasting peak flows. To address this limitation, this study introduces a hybrid forecasting framework that couples Extreme Gradient Boosting (XGBoost) and Random Forest (RF). XGBoost is employed for continuous streamflow forecasting, while RF is specifically trained for peak-flow prediction, and the two outputs are combined into an enhanced forecast. The approach is implemented across 857 catchments of the LamaH-CE dataset, using rainfall and discharge observations at 6-hour resolution. Results demonstrate consistently high skill, with 71% of catchments achieving a Kling-Gupta Efficiency (KGE) greater than 0.90. Peak-flow detection reaches 87%, with a false-alarm rate of 13%. Compared to the European Flood Awareness System (EFAS), the framework achieves lower peak-magnitude errors, fewer false alarms, and improved streamflow and peak-flow forecasting accuracy. The proposed framework is computationally lightweight, scalable, and easily transferable across watersheds, with training times of only seconds on standard CPUs. These findings highlight the potential of integrating hydrological understanding with efficient machine learning to improve the accuracy and reliability of operational flood forecasting, and outline future directions for hybrid hydrological-machine learning model development."}
{"id": "2601.09178", "pdf": "https://arxiv.org/pdf/2601.09178", "abs": "https://arxiv.org/abs/2601.09178", "authors": ["Paul Brunzema", "Thomas Lew", "Ray Zhang", "Takeru Shirasawa", "John Subosits", "Marcus Greiff"], "title": "Vision-Conditioned Variational Bayesian Last Layer Dynamics Models", "categories": ["cs.RO"], "comment": "9 pages, 7 figures, currently under review", "summary": "Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications."}
{"id": "2601.09364", "pdf": "https://arxiv.org/pdf/2601.09364", "abs": "https://arxiv.org/abs/2601.09364", "authors": ["Radim Zedka", "Roman Marsalek", "Marek Bobula", "Arman Farhang"], "title": "Unique Word Channel Estimation for Oversampled OTFS", "categories": ["eess.SP"], "comment": "17 pages", "summary": "Practical aspects of orthogonal time frequency space (OTFS), such as channel estimation and its performance in fractional delay-Doppler (DD) channels, are a lively topic in the OTFS community. Oversampling and pulse shaping are also discussed in the existing literature, but not in the context of channel estimation. To the best of our knowledge, this paper is the first to address the problem of data-to-pilot and vice versa energy leakage caused by oversampling and pulse shaping in OTFS. Theoretical analysis is performed on an oversampled, pulse-shaped OTFS implementing the embedded pilot channel estimation technique, revealing a trade-off between the amount of energy leakage and excess bandwidth introduced by the pulse shape. Next, a novel variant of OTFS is introduced, called UW-OTFS, which is designed to overcome the leakage problem by placing the pilot in the oversampled time domain instead of the DD domain. The unique structure of UW-OTFS offers 36 percent higher spectral efficiency than the OTFS with embedded pilot. UW-OTFS also outperforms traditional OTFS in terms of bit error ratio and out-of-band emissions."}
{"id": "2601.09231", "pdf": "https://arxiv.org/pdf/2601.09231", "abs": "https://arxiv.org/abs/2601.09231", "authors": ["Shuoye Li", "Zhiyuan Song", "Yulin Li", "Zhihai Bi", "Jun Ma"], "title": "Online Trajectory Optimization for Arbitrary-Shaped Mobile Robots via Polynomial Separating Hypersurfaces", "categories": ["cs.RO"], "comment": null, "summary": "An emerging class of trajectory optimization methods enforces collision avoidance by jointly optimizing the robot's configuration and a separating hyperplane. However, as linear separators only apply to convex sets, these methods require convex approximations of both the robot and obstacles, which becomes an overly conservative assumption in cluttered and narrow environments. In this work, we unequivocally remove this limitation by introducing nonlinear separating hypersurfaces parameterized by polynomial functions. We first generalize the classical separating hyperplane theorem and prove that any two disjoint bounded closed sets in Euclidean space can be separated by a polynomial hypersurface, serving as the theoretical foundation for nonlinear separation of arbitrary geometries. Building on this result, we formulate a nonlinear programming (NLP) problem that jointly optimizes the robot's trajectory and the coefficients of the separating polynomials, enabling geometry-aware collision avoidance without conservative convex simplifications. The optimization remains efficiently solvable using standard NLP solvers. Simulation and real-world experiments with nonconvex robots demonstrate that our method achieves smooth, collision-free, and agile maneuvers in environments where convex-approximation baselines fail."}
{"id": "2601.09384", "pdf": "https://arxiv.org/pdf/2601.09384", "abs": "https://arxiv.org/abs/2601.09384", "authors": ["Utku Uçak", "Fariba Armandoust", "Matthias Mehlhose", "Daniel Schäufele", "Jochen Fink", "Renato L. G. Cavalcante", "Sławomir Stańczak"], "title": "Uplink Multi-User MIMO Implementation in OpenAirInterface for a Cell-Free O-RAN Testbed", "categories": ["eess.SP"], "comment": "7 pages, 7 figures. Submitted to IEEE ICC 2026", "summary": "Cell-Free Multiple-Input Multiple-Output (MIMO) and Open Radio Access Network (O-RAN) have been active research topics in the wireless communication community in recent years. As an open-source software implementation of the 3rd Generation Partnership Project (3GPP) 5th Generation (5G) protocol stack, OpenAirInterface (OAI) has become a valuable tool for deploying and testing new ideas in wireless communication systems. In this paper, we present our OAI based real-time uplink Multi-User MIMO (MU-MIMO) testbed developed at Fraunhofer HHI. As a part of our Cell-Free MIMO testbed development, we built a 2x2 MU-MIMO system using general purpose computers and commercially available software defined radios (SDRs). Using a modified OAI next-Generation Node-B (gNB) and two unmodified OAI user equipment (UE), we show that it is feasible to use Sounding Reference Signal (SRS) channel estimates to compute uplink combiners. Our results verify that this method can be used to separate and decode signals from two users transmitting in nonorthogonal time-frequency resources. This work serves as an important verification step to build a complete Cell-Free MU-MIMO system that leverages time domain duplexing (TDD) reciprocity to do downlink beamforming over multiple cells."}
{"id": "2601.09318", "pdf": "https://arxiv.org/pdf/2601.09318", "abs": "https://arxiv.org/abs/2601.09318", "authors": ["Ro'i Lang", "Elon Rimon"], "title": "Feedback-Based Mobile Robot Navigation in 3-D Environments Using Artificial Potential Functions Technical Report", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This technical report presents the construction and analysis of polynomial navigation functions for motion planning in 3-D workspaces populated by spherical and cylindrical obstacles. The workspace is modeled as a bounded spherical region, and obstacles are encoded using smooth polynomial implicit functions. We establish conditions under which the proposed navigation functions admit a unique non-degenerate minimum at the target while avoiding local minima, including in the presence of pairwise intersecting obstacles. Gradient and Hessian analyses are provided, and the theoretical results are validated through numerical simulations in obstacle rich 3-D environments."}
{"id": "2601.09426", "pdf": "https://arxiv.org/pdf/2601.09426", "abs": "https://arxiv.org/abs/2601.09426", "authors": ["Heedong Do", "Angel Lozano"], "title": "Beamforming Gain with Nonideal Phase Shifters", "categories": ["eess.SP"], "comment": null, "summary": "This research sets forth a universal framework to characterize the beamforming gain achievable with arbitrarily nonideal phase shifters. Precisely, the maximum possible shortfall relative to the gain attainable with ideal phase shifters is established. Such shortfall is shown to be fundamentally determined by the perimeter of the convex hull of the set of feasible beamforming coefficients on the complex plane. This result holds regardless of whether the beamforming is at the transmitter, at the receiver, or at a reconfigurable intelligent surface. In i.i.d. fading channels, the shortfall hardens to the maximum possible shortfall as the number of antennas grows."}
{"id": "2601.09377", "pdf": "https://arxiv.org/pdf/2601.09377", "abs": "https://arxiv.org/abs/2601.09377", "authors": ["Xuemei Yao", "Xiao Yang", "Jianbin Sun", "Liuwei Xie", "Xuebin Shao", "Xiyu Fang", "Hang Su", "Kewei Yang"], "title": "ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving", "categories": ["cs.RO"], "comment": "Accepted by AAAI 2026", "summary": "Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe trajectory prediction when vehicles operate near their physical limits. In this paper, we introduce ReflexDiffusion, a novel inference-stage framework that enhances diffusion-based trajectory planners through reflective adjustment. Our method introduces a gradient-based adjustment mechanism during the iterative denoising process: after each standard trajectory update, we compute the gradient between the conditional and unconditional noise predictions to explicitly amplify critical conditioning signals, including road curvature and lateral vehicle dynamics. This amplification enforces strict adherence to physical constraints, particularly improving stability during high-lateral-acceleration maneuvers where precise vehicle-road interaction is paramount. Evaluated on the nuPlan Test14-hard benchmark, ReflexDiffusion achieves a 14.1% improvement in driving score for high-lateral-acceleration scenarios over the state-of-the-art (SOTA) methods. This demonstrates that inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The framework's architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering a practical solution for improving autonomous vehicle safety in challenging driving conditions."}
{"id": "2601.09463", "pdf": "https://arxiv.org/pdf/2601.09463", "abs": "https://arxiv.org/abs/2601.09463", "authors": ["Ying Gao", "Qingqing Wu", "Ziyuan Zheng", "Yanze Zhu", "Wen Chen", "Xin Lin", "Shanpu Shen"], "title": "Two-Scale Spatial Deployment for Cost-Effective Wireless Networks via Cooperative IRSs and Movable Antennas", "categories": ["eess.SP", "eess.SY"], "comment": "13 pages, 7 figures, submitted to an IEEE journal for possible publication", "summary": "This paper proposes a two-scale spatial deployment strategy to ensure reliable coverage for multiple target areas, integrating macroscopic intelligent reflecting surfaces (IRSs) and fine-grained movable antennas (MAs). Specifically, IRSs are selectively deployed from candidate sites to shape the propagation geometry, while MAs are locally repositioned among discretized locations to exploit small-scale channel variations. The objective is to minimize the total deployment cost of MAs and IRSs by jointly optimizing the IRS site selection, MA positions, transmit precoding, and IRS phase shifts, subject to the signal-to-noise ratio (SNR) requirements for all target areas. This leads to a challenging mixed-integer non-convex optimization problem that is intractable to solve directly. To address this, we first formulate an auxiliary problem to verify the feasibility. A penalty-based double-loop algorithm integrating alternating optimization and successive convex approximation (SCA) is developed to solve this feasibility issue, which is subsequently adapted to obtain a suboptimal solution for the original cost minimization problem. Finally, based on the obtained solution, we formulate an element refinement problem to further reduce the deployment cost, which is solved by a penalty-based SCA algorithm. Simulation results demonstrate that the proposed designs consistently outperform benchmarks relying on independent area planning or full IRS deployment in terms of cost-efficiency. Moreover, for cost minimization, MA architectures are preferable in large placement apertures, whereas fully populated FPA architectures excel in compact ones; for worst-case SNR maximization, MA architectures exhibit a lower cost threshold for feasibility, while FPA architectures can attain peak SNR at a lower total cost."}
{"id": "2601.09444", "pdf": "https://arxiv.org/pdf/2601.09444", "abs": "https://arxiv.org/abs/2601.09444", "authors": ["Lauri Suomela", "Naoki Takahata", "Sasanka Kuruppu Arachchige", "Harry Edelman", "Joni-Kristian Kämäräinen"], "title": "Data Scaling for Navigation in Unknown Environments", "categories": ["cs.RO"], "comment": null, "summary": "Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robots operating in four countries, covering 125 km of autonomous driving.\n  Our results show that large-scale training data enables zero-shot navigation in unknown environments, approaching the performance of policies trained with environment-specific demonstrations. Critically, we find that data diversity is far more important than data quantity. Doubling the number of geographical locations in a training set decreases navigation errors by ~15%, while performance benefit from adding data from existing locations saturates with very little data. We also observe that, with noisy crowd-sourced data, simple regression-based models outperform generative and sequence-based architectures. We release our policies, evaluation setup and example videos on the project page."}
{"id": "2601.09484", "pdf": "https://arxiv.org/pdf/2601.09484", "abs": "https://arxiv.org/abs/2601.09484", "authors": ["Marouan Mizmizi", "Stefano Tebaldini", "Umberto Spagnolini"], "title": "Echo-Side Integrated Sensing and Communication via Space-Time Reconfigurable Intelligent Surfaces", "categories": ["eess.SP", "eess.SY"], "comment": null, "summary": "This paper presents an echo-side modulation framework for integrated sensing and communication (ISAC) systems. A space-time reconfigurable intelligent surface (ST-RIS) impresses a continuous-phase modulation onto the radar echo, enabling uplink data transmission with a phase modulation of the transmitted radar-like waveform. The received signal is a multiplicative composition of the sensing waveform and the phase for communication. Both functionalities share the same physical signal and perceive each other as impairments.\n  The achievable communication rate is expressed as a function of a coupling parameter that links sensing accuracy to phase error accumulation. Under a fixed bandwidth constraint, the sensing and communication figures of merit define a convex Pareto frontier. The optimal bandwidth allocation satisfying a minimum sensing requirement is derived in closed form. The modified Cramer-Rao bound (MCRB) for range estimation is derived in closed form; this parameter must be estimated to compensate for the frequency offset before data demodulation. Frame synchronization is formulated as a generalized likelihood ratio test (GLRT), and the detection probability is obtained through characteristic function inversion, accounting for residual frequency errors from imperfect range estimation. Numerical results validate the theoretical bounds and characterize the trade-off across the operating range."}
{"id": "2601.09512", "pdf": "https://arxiv.org/pdf/2601.09512", "abs": "https://arxiv.org/abs/2601.09512", "authors": ["Ralf Römer", "Yi Zhang", "Angela P. Schoellig"], "title": "CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion", "categories": ["cs.RO", "cs.LG"], "comment": "Project page: https://tum-lsy.github.io/clare. 9 pages, 5 figures", "summary": "To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare."}
{"id": "2601.09701", "pdf": "https://arxiv.org/pdf/2601.09701", "abs": "https://arxiv.org/abs/2601.09701", "authors": ["Fahimeh Orvati Nia", "Shima Salehi", "Joshua Peeples"], "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems", "categories": ["eess.SP"], "comment": "Accepted to IEEE Texas Power and Energy Conference (TPEC) 2026. 6 pages, 5 figures. Code available at https://github.com/fahimehorvatinia/GAN-LSTM-Smart-Meter-Anomaly-Detection", "summary": "Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly available"}
{"id": "2601.09518", "pdf": "https://arxiv.org/pdf/2601.09518", "abs": "https://arxiv.org/abs/2601.09518", "authors": ["Wei-Jin Huang", "Yue-Yi Zhang", "Yi-Lin Wei", "Zhi-Wei Xia", "Juantao Tan", "Yuan-Ming Li", "Zhilin Zhao", "Wei-Shi Zheng"], "title": "Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data."}
{"id": "2601.09008", "pdf": "https://arxiv.org/pdf/2601.09008", "abs": "https://arxiv.org/abs/2601.09008", "authors": ["Amar Kavuri", "Howard C. Gifford", "Mini Das"], "title": "Changes in Visual Attention Patterns for Detection Tasks due to Dependencies on Signal and Background Spatial Frequencies", "categories": ["cs.CV", "eess.IV", "eess.SP", "physics.med-ph"], "comment": "21 pages, 7 images", "summary": "We aim to investigate the impact of image and signal properties on visual attention mechanisms during a signal detection task in digital images. The application of insight yielded from this work spans many areas of digital imaging where signal or pattern recognition is involved in complex heterogenous background. We used simulated tomographic breast images as the platform to investigate this question. While radiologists are highly effective at analyzing medical images to detect and diagnose diseases, misdiagnosis still occurs. We selected digital breast tomosynthesis (DBT) images as a sample medical images with different breast densities and structures using digital breast phantoms (Bakic and XCAT). Two types of lesions (with distinct spatial frequency properties) were randomly inserted in the phantoms during projections to generate abnormal cases. Six human observers participated in observer study designed for a locating and detection of an 3-mm sphere lesion and 6-mm spicule lesion in reconstructed in-plane DBT slices. We collected eye-gaze data to estimate gaze metrics and to examine differences in visual attention mechanisms. We found that detection performance in complex visual environments is strongly constrained by later perceptual stages, with decision failures accounting for the largest proportion of errors. Signal detectability is jointly influenced by both target morphology and background complexity, revealing a critical interaction between local signal features and global anatomical noise. Increased fixation duration on spiculated lesions suggests that visual attention is differentially engaged depending on background and signal spatial frequency dependencies."}
{"id": "2601.09578", "pdf": "https://arxiv.org/pdf/2601.09578", "abs": "https://arxiv.org/abs/2601.09578", "authors": ["Jiajun Sun", "Yangyi Ou", "Haoyuan Zheng", "Chao yang", "Yue Ma"], "title": "Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping", "categories": ["cs.RO", "cs.CV"], "comment": "5 pages,7 figures. Under review", "summary": "In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance."}
{"id": "2601.09025", "pdf": "https://arxiv.org/pdf/2601.09025", "abs": "https://arxiv.org/abs/2601.09025", "authors": ["Tong Wu", "Tayab Uddin Wara", "Daniel Hernandez", "Sidong Lei"], "title": "Universal Latent Homeomorphic Manifolds: Cross-Domain Representation Learning via Homeomorphism Verification", "categories": ["eess.IV", "cs.LG", "eess.SP"], "comment": null, "summary": "We present the Universal Latent Homeomorphic Manifold (ULHM), a framework that unifies semantic representations (e.g., human descriptions, diagnostic labels) and observation-driven machine representations (e.g., pixel intensities, sensor readings) into a single latent structure. Despite originating from fundamentally different pathways, both modalities capture the same underlying reality. We establish \\emph{homeomorphism}, a continuous bijection preserving topological structure, as the mathematical criterion for determining when latent manifolds induced by different semantic-observation pairs can be rigorously unified. This criterion provides theoretical guarantees for three critical applications: (1) semantic-guided sparse recovery from incomplete observations, (2) cross-domain transfer learning with verified structural compatibility, and (3) zero-shot compositional learning via valid transfer from semantic to observation space. Our framework learns continuous manifold-to-manifold transformations through conditional variational inference, avoiding brittle point-to-point mappings. We develop practical verification algorithms, including trust, continuity, and Wasserstein distance metrics, that empirically validate homeomorphic structure from finite samples. Experiments demonstrate: (1) sparse image recovery from 5\\% of CelebA pixels and MNIST digit reconstruction at multiple sparsity levels, (2) cross-domain classifier transfer achieving 86.73\\% accuracy from MNIST to Fashion-MNIST without retraining, and (3) zero-shot classification on unseen classes achieving 89.47\\% on MNIST, 84.70\\% on Fashion-MNIST, and 78.76\\% on CIFAR-10. Critically, the homeomorphism criterion correctly rejects incompatible datasets, preventing invalid unification and providing a feasible way to principled decomposition of general foundation models into verified domain-specific components."}
{"id": "2601.08868", "pdf": "https://arxiv.org/pdf/2601.08868", "abs": "https://arxiv.org/abs/2601.08868", "authors": ["Yi Wang", "Yinfeng Yu", "Bin Ren"], "title": "Residual Cross-Modal Fusion Networks for Audio-Visual Navigation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Main paper (10 pages). Accepted for publication by the 14th international conference on Computational Visual Media (CVM 2026)", "summary": "Audio-visual embodied navigation aims to enable an agent to autonomously localize and reach a sound source in unseen 3D environments by leveraging auditory cues. The key challenge of this task lies in effectively modeling the interaction between heterogeneous features during multimodal fusion, so as to avoid single-modality dominance or information degradation, particularly in cross-domain scenarios. To address this, we propose a Cross-Modal Residual Fusion Network, which introduces bidirectional residual interactions between audio and visual streams to achieve complementary modeling and fine-grained alignment, while maintaining the independence of their representations. Unlike conventional methods that rely on simple concatenation or attention gating, CRFN explicitly models cross-modal interactions via residual connections and incorporates stabilization techniques to improve convergence and robustness. Experiments on the Replica and Matterport3D datasets demonstrate that CRFN significantly outperforms state-of-the-art fusion baselines and achieves stronger cross-domain generalization. Notably, our experiments also reveal that agents exhibit differentiated modality dependence across different datasets. The discovery of this phenomenon provides a new perspective for understanding the cross-modal collaboration mechanism of embodied agents."}
{"id": "2601.09076", "pdf": "https://arxiv.org/pdf/2601.09076", "abs": "https://arxiv.org/abs/2601.09076", "authors": ["Zhoubin Kou", "Zihan Chen", "Jing Yang", "Cong Shen"], "title": "Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "cs.NI", "eess.SP"], "comment": null, "summary": "Split Federated Learning (SFL) enables collaborative training between resource-constrained edge devices and a compute-rich server. Communication overhead is a central issue in SFL and can be mitigated with auxiliary networks. Yet, the fundamental client-side computation challenge remains, as back-propagation requires substantial memory and computation costs, severely limiting the scale of models that edge devices can support. To enable more resource-efficient client computation and reduce the client-server communication, we propose HERON-SFL, a novel hybrid optimization framework that integrates zeroth-order (ZO) optimization for local client training while retaining first-order (FO) optimization on the server. With the assistance of auxiliary networks, ZO updates enable clients to approximate local gradients using perturbed forward-only evaluations per step, eliminating memory-intensive activation caching and avoiding explicit gradient computation in the traditional training process. Leveraging the low effective rank assumption, we theoretically prove that HERON-SFL's convergence rate is independent of model dimensionality, addressing a key scalability concern common to ZO algorithms. Empirically, on ResNet training and language model (LM) fine-tuning tasks, HERON-SFL matches benchmark accuracy while reducing client peak memory by up to 64% and client-side compute cost by up to 33% per step, substantially expanding the range of models that can be trained or adapted on resource-limited devices."}
{"id": "2601.09107", "pdf": "https://arxiv.org/pdf/2601.09107", "abs": "https://arxiv.org/abs/2601.09107", "authors": ["Lachlan Holden", "Feras Dayoub", "Alberto Candela", "David Harvey", "Tat-Jun Chin"], "title": "Vision Foundation Models for Domain Generalisable Cross-View Localisation in Planetary Ground-Aerial Robotic Teams", "categories": ["cs.CV", "cs.RO"], "comment": "7 pages, 10 figures. Presented at the International Conference on Space Robotics (iSpaRo) 2025 in Sendai, Japan. Dataset available: https://doi.org/10.5281/zenodo.17364038", "summary": "Accurate localisation in planetary robotics enables the advanced autonomy required to support the increased scale and scope of future missions. The successes of the Ingenuity helicopter and multiple planetary orbiters lay the groundwork for future missions that use ground-aerial robotic teams. In this paper, we consider rovers using machine learning to localise themselves in a local aerial map using limited field-of-view monocular ground-view RGB images as input. A key consideration for machine learning methods is that real space data with ground-truth position labels suitable for training is scarce. In this work, we propose a novel method of localising rovers in an aerial map using cross-view-localising dual-encoder deep neural networks. We leverage semantic segmentation with vision foundation models and high volume synthetic data to bridge the domain gap to real images. We also contribute a new cross-view dataset of real-world rover trajectories with corresponding ground-truth localisation data captured in a planetary analogue facility, plus a high volume dataset of analogous synthetic image pairs. Using particle filters for state estimation with the cross-view networks allows accurate position estimation over simple and complex trajectories based on sequences of ground-view images."}
{"id": "2601.09098", "pdf": "https://arxiv.org/pdf/2601.09098", "abs": "https://arxiv.org/abs/2601.09098", "authors": ["Yifeng Qin", "Jing Chen", "Zhi Hao Jiang", "Zhi Ning Chen", "Yongming Huang"], "title": "Overcoming the Shadow: Bending Airy Beams for Radiative Near-Field Multi-User Access in Half-Space Blockage Scenarios", "categories": ["cs.IT", "eess.SP", "physics.optics"], "comment": null, "summary": "The move to next-generation wireless communications with extremely large-scale antenna arrays (ELAAs) brings the communications into the radiative near-field (RNF) region, where distance-aware focusing is feasible. However, high-frequency RNF links are highly vulnerable to blockage in indoor environments dominated by half-space obstacles (walls, corners) that create knife-edge shadows. Conventional near-field focused beams offer high gain in line-of-sight (LoS) scenarios but suffer from severe energy truncation and effective-rank collapse in shadowed regions, making hardware remedies such as reconfigurable intelligent surfaces (RIS) impractical. We propose a beamforming strategy that exploits the auto-bending property of Airy beams to mitigate half-space blockage without additional hardware. The Airy beam is designed to ``ride'' the diffraction edge, accelerating its main lobe into the shadow to restore connectivity. Our contributions are threefold: (i) a Green's function-based RNF multi-user channel model that analytically reveals singular-value collapse behind knife-edge obstacles; (ii) an Airy analog beamforming scheme that optimizes the bending trajectory to recover the effective channel rank; and (iii) an Airy null-steering method that aligns oscillatory nulls with bright-region users to suppress interference in mixed shadow/bright scenarios. Simulations show that the proposed edge-riding Airy strategy achieves an SNR improvement of over 20 dB and restores full-rank connectivity in shadowed links compared to conventional RNF focusing, virtually eliminating outage in geometric shadows and increasing multi-user spectral efficiency by approximately 35\\% under typical indoor ELAA configurations. These results demonstrate robust RNF multi-user access in half-space blockage scenarios without relying on RIS."}
{"id": "2601.09605", "pdf": "https://arxiv.org/pdf/2601.09605", "abs": "https://arxiv.org/abs/2601.09605", "authors": ["Jeremiah Coholich", "Justin Wit", "Robert Azarcon", "Zsolt Kira"], "title": "Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Vision-based policies for robot manipulation have achieved significant recent success, but are still brittle to distribution shifts such as camera viewpoint variations. Robot demonstration data is scarce and often lacks appropriate variation in camera viewpoints. Simulation offers a way to collect robot demonstrations at scale with comprehensive coverage of different viewpoints, but presents a visual sim2real challenge. To bridge this gap, we propose MANGO -- an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. We find that these elements are crucial for maintaining viewpoint consistency during sim2real translation. When training MANGO, we only require a small amount of fixed-camera data from the real world, but show that our method can generate diverse unseen viewpoints by translating simulated observations. In this domain, MANGO outperforms all other image translation methods we tested. Imitation-learning policies trained on data augmented by MANGO are able to achieve success rates as high as 60\\% on views that the non-augmented policy fails completely on."}
{"id": "2601.09287", "pdf": "https://arxiv.org/pdf/2601.09287", "abs": "https://arxiv.org/abs/2601.09287", "authors": ["Dafne Lozano-Paredes", "Luis Bote-Curiel", "Juan Ramón Feijóo-Martínez", "Ismael Gómez-Talal", "José Luis Rojo-Álvarez"], "title": "Explainable Autoencoder-Based Anomaly Detection in IEC 61850 GOOSE Networks", "categories": ["cs.CR", "cs.LG", "eess.SP"], "comment": null, "summary": "The IEC 61850 Generic Object-Oriented Substation Event (GOOSE) protocol plays a critical role in real-time protection and automation of digital substations, yet its lack of native security mechanisms can expose power systems to sophisticated cyberattacks. Traditional rule-based and supervised intrusion detection techniques struggle to detect protocol-compliant and zero-day attacks under significant class imbalance and limited availability of labeled data. This paper proposes an explainable, unsupervised multi-view anomaly detection framework for IEC 61850 GOOSE networks that explicitly separates semantic integrity and temporal availability. The approach employs asymmetric autoencoders trained only on real operational GOOSE traffic to learn distinct latent representations of sequence-based protocol semantics and timing-related transmission dynamics in normal traffic. Anomaly detection is implemented using reconstruction errors mixed with statistically grounded thresholds, enabling robust detection without specified attack types. Feature-level reconstruction analysis provides intrinsic explainability by directly linking detection outcomes to IEC 61850 protocol characteristics. The proposed framework is evaluated using real substation traffic for training and a public dataset containing normal traffic and message suppression, data manipulation, and denial-of-service attacks for testing. Experimental results show attack detection rates above 99% with false positives remaining below 5% of total traffic, demonstrating strong generalization across environments and effective operation under extreme class imbalance and interpretable anomaly attribution."}
{"id": "2601.09708", "pdf": "https://arxiv.org/pdf/2601.09708", "abs": "https://arxiv.org/abs/2601.09708", "authors": ["Chi-Pin Huang", "Yunze Man", "Zhiding Yu", "Min-Hung Chen", "Jan Kautz", "Yu-Chiang Frank Wang", "Fu-En Yang"], "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project page: https://jasper0314-huang.github.io/fast-thinkact/", "summary": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery."}
{"id": "2601.09641", "pdf": "https://arxiv.org/pdf/2601.09641", "abs": "https://arxiv.org/abs/2601.09641", "authors": ["Seyed Bagher Hashemi Natanzi", "Hossein Mohammadi", "Vuk Marojevic", "Bo Tang"], "title": "FairShare: Auditable Geographic Fairness for Multi-Operator LEO Spectrum Sharing", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Dynamic spectrum sharing (DSS) among multi-operator low Earth orbit (LEO) mega-constellations is essential for coexistence, yet prevailing policies focus almost exclusively on interference mitigation, leaving geographic equity largely unaddressed. This work investigates whether conventional DSS approaches inadvertently exacerbate the rural digital divide. Through large-scale, 3GPP-compliant non-terrestrial network (NTN) simulations with geographically distributed users, we systematically evaluate standard allocation policies. The results uncover a stark and persistent structural bias: SNR-priority scheduling induces a 1.65x urban-rural access disparity, privileging users with favorable satellite geometry. Counter-intuitively, increasing system bandwidth amplifies rather than alleviates this gap, with disparity rising from 1.0x to 1.65x as resources expand. To remedy this, we propose FairShare, a lightweight, quota-based framework that enforces geographic fairness. FairShare not only reverses the bias, achieving an affirmative disparity ratio of Delta_geo = 0.72x, but also reduces scheduler runtime by 3.3%. This demonstrates that algorithmic fairness can be achieved without trading off efficiency or complexity. Our work provides regulators with both a diagnostic metric for auditing fairness and a practical, enforceable mechanism for equitable spectrum governance in next-generation satellite networks."}
