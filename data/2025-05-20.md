<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 17]
- [cs.DC](#cs.DC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.IT](#cs.IT) [Total: 3]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [eess.SY](#eess.SY) [Total: 3]
- [math.NA](#math.NA) [Total: 1]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Joint Precoding and Probabilistic Constellation Shaping using Arithmetic Distribution Matching](https://arxiv.org/abs/2505.11759)
*Babaee Ramin,Oveis Gharan Shahab,Bouchard Martin*

Main category: eess.SP

TL;DR: 论文研究了联合成形和预编码问题，通过引入统计依赖性来优化星座成形，并最小化通过预编码滤波器后的总发射功率。


<details>
  <summary>Details</summary>
Motivation: 动机在于通过优化发射符号的转移概率，避免与预编码滤波器卷积时产生高能量序列。

Method: 提出了一种静态马尔可夫模型和基于算术编码的新算法，用于生成符合给定转移概率的成形符号序列。

Result: 新算法有效地生成了满足性能要求的成形符号序列。

Conclusion: 该方法在优化星座成形和预编码性能方面具有潜力。

Abstract: The problem of joint shaping and precoding is studied in this paper. We
introduce statistical dependencies among consecutive symbols to shape the
constellation while minimizing the total transmit power when the signal goes
through the precoding filter. We propose a stationary Markovian model for
optimizing the transition probability of transmit symbols to avoid high-energy
sequences when convolved with the precoding filter. A new algorithm based on
arithmetic coding is proposed to generate a shaped sequence of symbols with the
given Markov model transition probabilities.

</details>


### [2] [S-Crescendo: A Nested Transformer Weaving Framework for Scalable Nonlinear System in S-Domain Representation](https://arxiv.org/abs/2505.11843)
*Junlang Huang,Hao Chen,Li Luo,Yong Cai,Lexin Zhang,Tianhao Ma,Yitian Zhang,Zhong Guan*

Main category: eess.SP

TL;DR: S-Crescendo是一种结合S域和神经算子的嵌套Transformer框架，用于高效预测高阶非线性网络的时间域行为，显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现代VLSI后端设计中，高阶非线性系统的模拟需要大量计算资源，尤其是分岔诱导的不稳定性和混沌瞬态行为带来挑战。

Method: 通过将n阶传递函数分解为一阶模态项，避免了传统的Jacobian矩阵迭代，计算复杂度从O(n^3)降至O(n)。结合S域编码器和注意力校正算子，有效捕捉高阶非线性。

Result: 在1阶到10阶网络上验证，达到0.99的测试集R²精度，仿真速度提升18倍。

Conclusion: S-Crescendo提供了一个可扩展、物理感知的高维非线性建模框架，显著提升了计算效率。

Abstract: Simulation of high-order nonlinear system requires extensive computational
resources, especially in modern VLSI backend design where bifurcation-induced
instability and chaos-like transient behaviors pose challenges. We present
S-Crescendo - a nested transformer weaving framework that synergizes S-domain
with neural operators for scalable time-domain prediction in high-order
nonlinear networks, alleviating the computational bottlenecks of conventional
solvers via Newton-Raphson method. By leveraging the partial-fraction
decomposition of an n-th order transfer function into first-order modal terms
with repeated poles and residues, our method bypasses the conventional Jacobian
matrix-based iterations and efficiently reduces computational complexity from
cubic $O(n^3)$ to linear $O(n)$.The proposed architecture seamlessly integrates
an S-domain encoder with an attention-based correction operator to
simultaneously isolate dominant response and adaptively capture higher-order
non-linearities. Validated on order-1 to order-10 networks, our method achieves
up to 0.99 test-set ($R^2$) accuracy against HSPICE golden waveforms and
accelerates simulation by up to 18(X), providing a scalable, physics-aware
framework for high-dimensional nonlinear modeling.

</details>


### [3] [Fine-Grained ECG-Text Contrastive Learning via Waveform Understanding Enhancement](https://arxiv.org/abs/2505.11939)
*Haitao Li,Che Liu,Zhengyao Ding,Ziyi Liu,Zhengxing Huang*

Main category: eess.SP

TL;DR: FG-CLEP通过恢复心电图中未记录的波形特征，解决了现有ECG-文本对比学习方法因报告不完整导致的问题，并引入了语义相似度矩阵和Sigmoid损失函数，显著提升了零样本预测和线性探测性能。


<details>
  <summary>Details</summary>
Motivation: 现有ECG-文本对比学习方法因报告中波形特征缺失，导致模型无法充分捕捉ECG特征和诊断推理。FG-CLEP旨在通过大型语言模型恢复这些特征，并解决幻觉和非双射关系的挑战。

Method: FG-CLEP利用大型语言模型从报告中恢复缺失的波形特征，引入语义相似度矩阵以减少常见诊断的假阴性，并采用Sigmoid损失函数适应多标签任务。

Result: 在六个数据集上的实验表明，FG-CLEP在零样本预测和线性探测中均优于现有方法。

Conclusion: FG-CLEP通过恢复波形特征和改进对比学习方法，显著提升了ECG诊断任务的表现。

Abstract: Electrocardiograms (ECGs) are essential for diagnosing cardiovascular
diseases. While previous ECG-text contrastive learning methods have shown
promising results, they often overlook the incompleteness of the reports. Given
an ECG, the report is generated by first identifying key waveform features and
then inferring the final diagnosis through these features. Despite their
importance, these waveform features are often not recorded in the report as
intermediate results. Aligning ECGs with such incomplete reports impedes the
model's ability to capture the ECG's waveform features and limits its
understanding of diagnostic reasoning based on those features. To address this,
we propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which
aims to recover these waveform features from incomplete reports with the help
of large language models (LLMs), under the challenges of hallucinations and the
non-bijective relationship between waveform features and diagnoses.
Additionally, considering the frequent false negatives due to the prevalence of
common diagnoses in ECGs, we introduce a semantic similarity matrix to guide
contrastive learning. Furthermore, we adopt a sigmoid-based loss function to
accommodate the multi-label nature of ECG-related tasks. Experiments on six
datasets demonstrate that FG-CLEP outperforms state-of-the-art methods in both
zero-shot prediction and linear probing across these datasets.

</details>


### [4] [OFDM Based Bistatic Integrated Sensing and Communication: Sensing Beyond CP Limit](https://arxiv.org/abs/2505.12166)
*Cuneyd Ozturk,Cagri Goken*

Main category: eess.SP

TL;DR: 本文研究了双静态OFDM集成感知与通信系统，提出了一种基于滑动窗口的接收架构，通过利用时频格中的导频符号扩展无码间干扰的感知范围，并验证了其在距离和速度估计上的性能接近克拉美-罗界。


<details>
  <summary>Details</summary>
Motivation: 研究双静态OFDM系统中的集成感知与通信（ISAC）性能，特别是在直视（LOS）存在和遮挡情况下的表现，以提升感知范围与精度。

Method: 提出了一种滑动窗口接收架构，通过利用导频符号扩展无码间干扰的感知范围，并对比克拉美-罗界（CRBs）评估性能。

Result: 在高信噪比（SNR）下，所提方法的估计性能接近克拉美-罗界，验证了其有效性。

Conclusion: 滑动窗口接收架构显著提升了双静态ISAC系统的感知能力，尤其在LOS存在和遮挡场景下表现优异。

Abstract: This work investigates a bistatic OFDM-based integrated sensing and
communication (ISAC) system under a single-target scenario, considering both
line-of-sight (LOS) presence and LOS blockage cases. A sliding window-based
sensing receiver architecture is proposed to extend the intersymbol
interference (ISI)-free sensing range beyond the cyclic prefix (CP) duration by
exploiting pilot symbols embedded in the time-frequency grid. The performance
of the proposed receiver is evaluated in terms of range and velocity estimation
accuracy and is compared against the Cramer-Rao bounds (CRBs) for the bi-static
ISAC setting. Numerical results confirm that the proposed method achieves
estimation performance that closely approaches the CRBs in the high
signal-to-noise ratio (SNR) regime.

</details>


### [5] [UAV-Enabled Joint Sensing, Communication, Powering and Backhaul Transmission in Maritime Monitoring Networks](https://arxiv.org/abs/2505.12190)
*Bohan Li,Jiahao Liu,Yujun Liang,Qian Li,Haochen Liu,Yaoyuan Zhang,Junsheng Mu,Shahid Mumtaz,Sheng Chen*

Main category: eess.SP

TL;DR: 该论文提出了一种无人机支持的集成感知、通信、供电和回传方案，用于解决能源受限的海上监测网络问题。通过联合优化时间分配、无人机轨迹、无人机-浮标关联和功率调度，实现了数据收集性能的最大化。


<details>
  <summary>Details</summary>
Motivation: 海上监测网络面临能源约束的挑战，传统方法难以满足需求。通过无人机集成多功能方案可提升效率。

Method: 采用交替优化、二次变换和增广一阶泰勒逼近的新优化框架，联合优化时间分配、无人机轨迹等。

Result: 仿真结果显示，浮标在服务质量约束下平均数据速率超过22bps/Hz，每时隙收获功率约2mW，验证了方案的有效性。

Conclusion: 该方案在海上监测中表现出高效性和鲁棒性，尤其在感知与多功
能传输之间实现了平衡。

Abstract: This paper addresses the challenge of energy-constrained maritime monitoring
networks by proposing an unmanned aerial vehicle (UAV)-enabled integrated
sensing, communication, powering and backhaul transmission scheme with a
tailored time-division duplex frame structure. Within each time slot, the UAV
sequentially implements sensing, wireless charging and uplink receiving with
buoys, and lastly forwards part of collected data to the central ship via
backhaul links. Considering the tight coupling among these functions, we
jointly optimize time allocation, UAV trajectory, UAV-buoy association, and
power scheduling to maximize the performance of data collection, with the
practical consideration of sea clutter effects during UAV sensing. A novel
optimization framework combining alternating optimization, quadratic transform
and augmented first-order Taylor approximation is developed, which demonstrates
good convergence behavior and robustness. Simulation results show that under
sensing quality-of-service constraint, buoys are able to achieve an average
data rate over 22bps/Hz using around 2mW harvested power per active time slot,
validating the scheme's effectiveness for open-sea monitoring. Additionally, it
is found that under the influence of sea clutters, the optimal UAV trajectory
always keeps a certain distance with buoys to strike a balance between sensing
and other multi-functional transmissions.

</details>


### [6] [Simultaneously Exposing and Jamming Covert Communications via Disco Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2505.12213)
*Huan Huang,Hongliang Zhang,Yi Cai,Dusit Niyato,A. Lee Swindlehurst,Zhu Han*

Main category: eess.SP

TL;DR: 该论文研究了在有DRIS（disco RIS）存在的隐蔽通信场景中，DRIS通过随机时变的反射系数干扰通信，破坏了信道互易性假设，并分析了其对隐蔽通信的影响。


<details>
  <summary>Details</summary>
Motivation: 隐蔽通信提供比加密和物理层安全更强的隐私保护，但过去的研究假设信道互易性成立。本文探究DRIS引入的时变完全被动干扰（FPJ）对隐蔽通信的影响。

Method: 提出在DRIS引入的时变FPJ下设计Willie的检测规则，定义检测错误概率和SJNR作为性能指标，分析DRIS对隐蔽通信的影响。

Result: 推导了Willie的检测阈值及错误概率的理论分析，揭示了DRIS-FPJ的独特性质，并通过数值结果验证理论分析。

Conclusion: DRIS通过FPJ破坏信道互易性，影响隐蔽通信性能，研究结果为隐蔽通信的设计提供了新视角。

Abstract: Covert communications provide a stronger privacy protection than cryptography
and physical-layer security (PLS). However, previous works on covert
communications have implicitly assumed the validity of channel reciprocity,
i.e., wireless channels remain constant or approximately constant during their
coherence time. In this work, we investigate covert communications in the
presence of a disco RIS (DRIS) deployed by the warden Willie, where the DRIS
with random and time-varying reflective coefficients acts as a "disco ball",
introducing timevarying fully-passive jamming (FPJ). Consequently, the channel
reciprocity assumption no longer holds. The DRIS not only jams the covert
transmissions between Alice and Bob, but also decreases the error probabilities
of Willie's detections, without either Bob's channel knowledge or additional
jamming power. To quantify the impact of the DRIS on covert communications, we
first design a detection rule for the warden Willie in the presence of
time-varying FPJ introduced by the DRIS. Then, we define the detection error
probabilities, i.e., the false alarm rate (FAR) and the missed detection rate
(MDR), as the monitoring performance metrics for Willie's detections, and the
signal-to-jamming-plusnoise ratio (SJNR) as a communication performance metric
for the covert transmissions between Alice and Bob. Based on the detection
rule, we derive the detection threshold for the warden Willie to detect whether
communications between Alice and Bob is ongoing, considering the time-varying
DRIS-based FPJ. Moreover, we conduct theoretical analyses of the FAR and the
MDR at the warden Willie, as well as SJNR at Bob, and then present unique
properties of the DRIS-based FPJ in covert communications. We present numerical
results to validate the derived theoretical analyses and evaluate the impact of
DRIS on covert communications.

</details>


### [7] [Toward Near-Space Communication Network in the 6G and Beyond Era](https://arxiv.org/abs/2505.12379)
*Xinhua Liu,Zhen Gao,Ziwei Wan,Zhonghuai Wu,Tuan Li,Tianqi Mao,Xiao Liang,Dezhi Zheng,Jun Zhang*

Main category: eess.SP

TL;DR: 该论文综述了近空间通信网络（NS-ComNet）在6G及以后的移动通信系统中的重要性，探讨了其优势、挑战及关键技术，强调了人工智能技术的应用，并展望了未来的智能协作网络。


<details>
  <summary>Details</summary>
Motivation: 近空间通信网络（NS-ComNet）因其广域覆盖、高空长期运行和灵活部署等优势，成为6G和SAGSIN的重要组成部分，亟需系统化研究和技术支撑。

Method: 通过对比卫星、低空无人机和地面通信，分析了NS-ComNet的整合背景；总结了近空间平台的发展现状，并提出了解决挑战的关键技术，如拓扑设计、资源管理和多目标联合优化。

Result: 提出了人工智能技术在NS-ComNet中的应用，并展望了NS-ComNet与卫星-无人机-地面系统的智能协作网络。

Conclusion: 该论文为NS-ComNet在6G及以后时代的系统化构建和深度部署提供了技术见解和研究基础。

Abstract: Near-space communication network (NS-ComNet), as an indispensable component
of sixth-generation (6G) and beyond mobile communication systems and the
space-air-ground-sea integrated network (SAGSIN), demonstrates unique
advantages in wide-area coverage, long-endurance high-altitude operation, and
highly flexible deployment. This paper presents a comprehensive review of
NS-ComNet for 6G and beyond era. Specifically, by contrasting satellite,
low-altitude unmanned-aerial-vehicle (UAV), and terrestrial communications, we
first elucidate the background and motivation for integrating NS-ComNet into 6G
network architectures. Subsequently, we review the developmental status of
near-space platforms, including high-altitude balloons, solar-powered UAVs, and
stratospheric airships, and analyze critical challenges faced by NS-ComNet. To
address these challenges, the research focuses on key enabling technologies
such as topology design, resource and handover management, multi-objective
joint optimization, etc., with particular emphasis on artificial intelligence
techniques for NS-ComNet. Finally, envisioning future intelligent collaborative
networks that integrate NS-ComNet with satellite-UAV-terrestrial systems, we
explore promising directions. This paper aims to provide technical insights and
research foundations for the systematic construction of NS-ComNet and its deep
deployment in the 6G and beyond era.

</details>


### [8] [Resolving the Double Near-Far Problem via Wireless Powered Pinching-Antenna Networks](https://arxiv.org/abs/2505.12403)
*Vasilis K. Papanikolaou,Gui Zhou,Brikena Kaziu,Ata Khalili,Panagiotis D. Diamantoulakis,George K. Karagiannidis,Robert Schober*

Main category: eess.SP

TL;DR: 提出了一种新型无线供电通信系统（WPPAN），利用单波导和夹持天线解决无线供电网络中的双近远问题。通过三种复杂度不同的方法优化资源分配，仿真表明系统有效提升了能量采集和数据传输。


<details>
  <summary>Details</summary>
Motivation: 解决无线供电网络中的双近远问题，并通过优化资源分配提高系统性能。

Method: 使用单波导和夹持天线设计WPPAN系统，提出三种方法简化资源分配问题，并采用凸优化方法高效求解。

Result: 仿真结果验证系统能有效缓解双近远问题，提升下行能量采集和上行数据传输性能。

Conclusion: WPPAN系统通过优化资源分配和天线布局，显著改善了无线供电网络的性能。

Abstract: This letter introduces a novel wireless powered communication system,
referred to as a wireless powered pinching-antenna network (WPPAN), utilizing a
single waveguide with pinching antennas to address the double near-far problem
inherent in wireless powered networks. In the proposed WPPAN, users harvest
energy from spatially distributed pinching antennas in the downlink and use the
collected power to transmit messages in the uplink. Furthermore, to manage the
combinatorial complexity associated with activating the pinching antennas, we
propose three approaches of varying complexity to simplify the original
resource allocation problem and then solve it efficiently using convex
optimization methods. Simulation results confirm that the proposed WPPAN system
effectively mitigates the double near-far problem by providing antenna
resources closer to the users, thereby enhancing both downlink energy
harvesting and uplink data transmission.

</details>


### [9] [Bistatic Sensing in 5G NR](https://arxiv.org/abs/2505.12555)
*Rajeev Gangula,Sakthivel Velumani,Tommaso Melodia*

Main category: eess.SP

TL;DR: 提出并评估了一种5G NR双基地ISaC系统的性能，利用现有蜂窝网络的数据通道实现传感，无需大幅修改收发器设计。


<details>
  <summary>Details</summary>
Motivation: 通过双基地方法在现有蜂窝网络中实现传感功能，避免全双工单基地系统的复杂性。

Method: 利用数据通道（如PUSCH）进行传感，提出了延迟和多普勒参数的最大似然估计器，并推导了单目标场景下的MSE下界。

Result: 链路级仿真表明，系统在保持高吞吐量的同时，能准确估计传感参数，且揭示了参考符号数量、传感性能与吞吐量之间的权衡关系。

Conclusion: 5G NR双基地ISaC系统在不显著修改现有设计的情况下，实现了高效的通信与传感功能。

Abstract: In this work, we propose and evaluate the performance of a 5th generation
(5G) New Radio (NR) bistatic Integrated Sensing and Communication (ISaC)
system. Unlike the full-duplex monostatic ISaC systems, the bistatic approach
enables sensing in the current cellular networks without significantly
modifying the transceiver design. The sensing utilizes data channels, such as
the Physical Uplink Shared Channel (PUSCH), which carries information on the
air interface. We provide the maximum likelihood estimator for the delay and
Doppler parameters and derive a lower bound on the Mean Square Error (MSE) for
a single target scenario. Link-level simulations show that it is possible to
achieve significant throughput while accurately estimating the sensing
parameters with PUSCH. Moreover, the results reveal an interesting tradeoff
between the number of reference symbols, sensing performance, and throughput in
the proposed 5G NR bistatic ISaC system.

</details>


### [10] [Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design](https://arxiv.org/abs/2505.12664)
*Ziqing Xing,Zhaoyang Zhang,Zirui Chen,Hongning Ruan,Zhaohui Yang*

Main category: eess.SP

TL;DR: 论文提出一种基于多视图CSI的目标感知框架，结合物理知识与深度学习方法，通过双分支神经网络和条件扩散模型实现高精度重构。


<details>
  <summary>Details</summary>
Motivation: 多视图CSI在目标感知中具有潜力，但现有方法未能充分利用其物理特性与生成能力，需结合物理知识与深度学习提升性能。

Method: 设计双分支神经网络，第一部分编码多视图CSI的潜在特征，第二部分用条件扩散模型生成目标点云，并引入空间位置嵌入捕捉CSI的物理相关性。

Result: 实验表明，提出的Gen-MV框架在目标形状和电磁特性重构上表现优异，灵活性强且性能显著提升。

Conclusion: 结合物理知识与生成模型的多视图感知框架能够高效利用CSI数据，显著提升目标重构质量。

Abstract: In this paper, we incorporate physical knowledge into learning-based
high-precision target sensing using the multi-view channel state information
(CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind
of multi-view sensing problem can be naturally cast into a conditional
generation framework. To this end, we design a bipartite neural network
architecture, the first part of which uses an elaborately designed encoder to
fuse the latent target features embedded in the multi-view CSI, and then the
second uses them as conditioning inputs of a powerful generative model to guide
the target's reconstruction. Specifically, the encoder is designed to capture
the physical correlation between the CSI and the target, and also be adaptive
to the numbers and positions of BS-UE pairs. Therein the view-specific nature
of CSI is assimilated by introducing a spatial positional embedding scheme,
which exploits the structure of electromagnetic(EM)-wave propagation channels.
Finally, a conditional diffusion model with a weighted loss is employed to
generate the target's point cloud from the fused features. Extensive numerical
results demonstrate that the proposed generative multi-view (Gen-MV) sensing
framework exhibits excellent flexibility and significant performance
improvement on the reconstruction quality of target's shape and EM properties.

</details>


### [11] [Bridging the Modality Gap: Enhancing Channel Prediction with Semantically Aligned LLMs and Knowledge Distillation](https://arxiv.org/abs/2505.12729)
*Zhaoyang Li,Qianqian Yang,Zehui Xiong,Zhiguo Shi,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该论文提出了一种基于语义对齐大型模型的信道预测框架CSI-ALM，通过跨模态融合和语义对齐技术解决了传统方法的预测误差累积和泛化能力不足问题，并提出了轻量化版本CSI-ALM-Light。


<details>
  <summary>Details</summary>
Motivation: 在大规模MIMO系统中，现有信道预测方法存在误差累积和动态环境泛化能力不足的问题，而大型语言模型（LLMs）虽具潜力但面临模态差距和参数过多的挑战。

Method: 设计了跨模态融合模块，对齐CSI表示与语言知识，并通过知识蒸馏策略提出轻量化版本CSI-ALM-Light。

Result: 实验表明，CSI-ALM比现有深度学习方法性能提升1 dB，轻量化版本在参数减少的情况下仍保持高性能。

Conclusion: CSI-ALM框架有效解决了信道预测中的模态差距问题，并通过轻量化设计实现了实际部署的可行性。

Abstract: Accurate channel prediction is essential in massive multiple-input
multiple-output (m-MIMO) systems to improve precoding effectiveness and reduce
the overhead of channel state information (CSI) feedback. However, existing
methods often suffer from accumulated prediction errors and poor generalization
to dynamic wireless environments. Large language models (LLMs) have
demonstrated remarkable modeling and generalization capabilities in tasks such
as time series prediction, making them a promising solution. Nevertheless, a
significant modality gap exists between the linguistic knowledge embedded in
pretrained LLMs and the intrinsic characteristics of CSI, posing substantial
challenges for their direct application to channel prediction. Moreover, the
large parameter size of LLMs hinders their practical deployment in real-world
communication systems with stringent latency constraints. To address these
challenges, we propose a novel channel prediction framework based on
semantically aligned large models, referred to as CSI-ALM, which bridges the
modality gap between natural language and channel information. Specifically, we
design a cross-modal fusion module that aligns CSI representations .
Additionally, we maximize the cosine similarity between word embeddings and CSI
embeddings to construct semantic cues. To reduce complexity and enable
practical implementation, we further introduce a lightweight version of the
proposed approach, called CSI-ALM-Light. This variant is derived via a
knowledge distillation strategy based on attention matrices. Extensive
experimental results demonstrate that CSI-ALM achieves a 1 dB gain over
state-of-the-art deep learning methods. Moreover, under limited training data
conditions, CSI-ALM-Light, with only 0.34M parameters, attains performance
comparable to CSI-ALM and significantly outperforms conventional deep learning
approaches.

</details>


### [12] [Multi-Reference and Adaptive Nonlinear Transform Source-Channel Coding for Wireless Image Semantic Transmission](https://arxiv.org/abs/2505.12740)
*Cheng Yuan,Yufei Jiang,Xu Zhu*

Main category: eess.SP

TL;DR: 提出了一种多参考自适应非线性变换源信道编码系统（MA-NTSCC），通过引入多维度上下文到熵模型中，显著提升了无线图像语义传输的率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有NTSCC系统在低带宽约束下，尤其是高分辨率图像传输中，率失真性能不足。为了提升性能并适应不同信道条件，需要引入多维度上下文和多参考熵模型。

Method: 采用多参考熵模型，利用潜在表示的空间和通道维度相关性。空间维度上，通过棋盘格模式划分锚点与非锚点；通道维度上，分组分析特征互相信息。同时引入轻量自适应模块以适应不同信道条件。

Result: 在高分辨率图像传输和低带宽约束下，MA-NTSCC显著提升了率失真性能，并在不同信道条件下表现优越，优于现有方法。

Conclusion: MA-NTSCC通过多参考模型和自适应模块，有效提升了无线图像语义传输的性能和适应性，优于传统方法。

Abstract: We propose a multi-reference and adaptive nonlinear transform source-channel
coding (MA-NTSCC) system for wireless image semantic transmission to improve
rate-distortion (RD) performance by introducing multi-dimensional contexts into
the entropy model of the state-of-the-art (SOTA) NTSCC system. Improvements in
RD performance of the proposed MA-NTSCC system are particularly significant in
high-resolution image transmission under low bandwidth constraints. The
proposed multi-reference entropy model leverages correlations within the latent
representation in both spatial and channel dimensions. In the spatial
dimension, the latent representation is divided into anchors and non-anchors in
a checkerboard pattern, where anchors serve as reference to estimate the mutual
information between anchors and non-anchors. In the channel dimension, the
latent representation is partitioned into multiple groups, and features in
previous groups are analyzed to estimate the mutual information between
features in previous and current groups. Taking mutual information into
account, the entropy model provides an accurate estimation on the entropy,
which enables efficient bandwidth allocation and enhances RD performance.
Additionally, the proposed lightweight adaptation modules enable the proposed
MA-NTSCC model to achieve transmission quality comparable to separately trained
models across various channel conditions and bandwidth requirements. In
contrast, traditional NTSCC models provide signal-to-noise ratio
(SNR)-distortion performance degrading with channel quality deviating from the
fixed training SNR, and consume inflexible bandwidth to transmit an image.
Comprehensive experiments are conducted to verify the peak signal-to-noise
ratio (PSNR) performance and adaptability of the proposed MA-NTSCC model
superior to SOTA methods over both additive white Gaussian noise channel and
Rayleigh fading channel.

</details>


### [13] [Algorithms for Nonlinear Mixed-Integer Location Estimation](https://arxiv.org/abs/2505.12980)
*Ophir Uziel,Efi Fogel,Dan Halperin,Sivan Toledo*

Main category: eess.SP

TL;DR: 论文提出新算法解决非线性混合整数最小二乘问题，适用于地面和室内定位，解决了线性化算法失败的问题。


<details>
  <summary>Details</summary>
Motivation: 现有算法在户外GNSS定位中表现良好，但在室内和地面环境中线性化算法失败，因此需要开发新方法。

Method: 提出消除非线性项的算法和几何排列方法，简化定位问题，专注于非线性与整数参数的分离。

Result: 新算法在近距离范围有效，解决了线性化算法的失败问题。

Conclusion: 新算法在地面和室内定位中表现优于线性化算法，解决了核心难题。

Abstract: For three decades, carrier-phase observations have been used to obtain the
most accurate location estimates using global navigation satellite systems
(GNSS). These estimates are computed by minimizing a nonlinear mixed-integer
least-squares problem. Existing algorithms linearize the problem, orthogonally
project it to eliminate real variables, and then solve the integer least-square
problem. There is now considerable interest in developing similar localization
techniques for terrestrial and indoor settings. We show that algorithms that
linearize first fail in these settings and we propose several algorithms for
computing the estimates. Some of our algorithms are elimination algorithms that
start by eliminating the non-linear terms in the constraints; others construct
a geometric arrangement that allows us to efficiently enumerate integer
solutions (in polynomial time). We focus on simplified localization problems in
which the measurements are range (distance) measurements and carrier phase
range measurements, with no nuisance parameters. The simplified problem allows
us to focus on the core question of untangling the nonlinearity and the integer
nature of some parameters. We show using simulations that the new algorithms
are effective at close ranges at which the linearize-first approach fails.

</details>


### [14] [The role of data partitioning on the performance of EEG-based deep learning models in supervised cross-subject analysis: a preliminary study](https://arxiv.org/abs/2505.13021)
*Federico Del Pup,Andrea Zanola,Louis Fabrice Tshimanga,Alessandra Bertoldo,Livio Finos,Manfredo Atzori*

Main category: eess.SP

TL;DR: 深度学习在脑电图（EEG）数据分析中表现优异，但数据划分和交叉验证方法的差异可能导致结果不可比和性能高估。本文通过比较多种交叉验证设置和模型，提出了优化实验策略的建议。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于当前缺乏对EEG深度学习模型中数据划分和交叉验证方法的全面评估，这导致了不可比的研究和可能高估的性能结果。

Method: 方法包括比较五种交叉验证设置，应用于三个跨受试者分类任务（BCI、帕金森病和阿尔茨海默病检测）和四种复杂程度递增的模型架构。

Result: 结果显示，基于受试者的交叉验证策略对评估EEG模型至关重要，且嵌套方法（N-LNSO）比非嵌套方法更具可靠性，能避免数据泄漏。

Conclusion: 结论是为EEG深度学习研究提供了数据划分和交叉验证的分析，并提出了避免数据泄漏和性能高估的指导原则。

Abstract: Deep learning is significantly advancing the analysis of
electroencephalography (EEG) data by effectively discovering highly nonlinear
patterns within the signals. Data partitioning and cross-validation are crucial
for assessing model performance and ensuring study comparability, as they can
produce varied results and data leakage due to specific signal properties
(e.g., biometric). Such variability leads to incomparable studies and,
increasingly, overestimated performance claims, which are detrimental to the
field. Nevertheless, no comprehensive guidelines for proper data partitioning
and cross-validation exist in the domain, nor is there a quantitative
evaluation of their impact on model accuracy, reliability, and
generalizability. To assist researchers in identifying optimal experimental
strategies, this paper thoroughly investigates the role of data partitioning
and cross-validation in evaluating EEG deep learning models. Five
cross-validation settings are compared across three supervised cross-subject
classification tasks (BCI, Parkinson's, and Alzheimer's disease detection) and
four established architectures of increasing complexity (ShallowConvNet,
EEGNet, DeepConvNet, and Temporal-based ResNet). The comparison of over 100,000
trained models underscores, first, the importance of using subject-based
cross-validation strategies for evaluating EEG deep learning models, except
when within-subject analyses are acceptable (e.g., BCI). Second, it highlights
the greater reliability of nested approaches (N-LNSO) compared to non-nested
counterparts, which are prone to data leakage and favor larger models
overfitting to validation data. In conclusion, this work provides EEG deep
learning researchers with an analysis of data partitioning and cross-validation
and offers guidelines to avoid data leakage, currently undermining the domain
with potentially overestimated performance claims.

</details>


### [15] [Simplicity is Key: An Unsupervised Pretraining Approach for Sparse Radio Channels](https://arxiv.org/abs/2505.13055)
*Jonathan Ott,Maximilian Stahlke,Tobias Feigl,Bjoern M. Eskofier,Christopher Mutschler*

Main category: eess.SP

TL;DR: 介绍了SpaRTran，一种基于压缩感知的无监督表示学习方法，专注于无线电传播的物理特性，为下游任务提供最佳基础。


<details>
  <summary>Details</summary>
Motivation: 旨在提高无线电信号的表示学习效率，减少标签成本，并增强模型对不同无线电任务的适应性。

Method: 使用稀疏门控自编码器学习稀疏表示，并构建原子特征字典以提高信号重建的灵活性。

Result: 相比现有方法，SpaRTran在无线电指纹任务中错误率降低85%，且训练更高效灵活。

Conclusion: SpaRTran是一种高效且通用的基础模型，适用于多种无线电下游任务，显著提升了性能和泛化能力。

Abstract: We introduce the Sparse pretrained Radio Transformer (SpaRTran), an
unsupervised representation learning approach based on the concept of
compressed sensing for radio channels. Our approach learns embeddings that
focus on the physical properties of radio propagation, to create the optimal
basis for fine-tuning on radio-based downstream tasks. SpaRTran uses a sparse
gated autoencoder that induces a simplicity bias to the learned
representations, resembling the sparse nature of radio propagation. For signal
reconstruction, it learns a dictionary that holds atomic features, which
increases flexibility across signal waveforms and spatiotemporal signal
patterns. Our experiments show that SpaRTran reduces errors by up to 85 %
compared to state-of-the-art methods when fine-tuned on radio fingerprinting, a
challenging downstream task. In addition, our method requires less pretraining
effort and offers greater flexibility, as we train it solely on individual
radio signals. SpaRTran serves as an excellent base model that can be
fine-tuned for various radio-based downstream tasks, effectively reducing the
cost for labeling. In addition, it is significantly more versatile than
existing methods and demonstrates superior generalization.

</details>


### [16] [Distributed Beamforming Using Decentralized Time Synchronization in a Six-Element Array](https://arxiv.org/abs/2505.13248)
*Naim Shandi,Jason M. Merlo,Jeffrey A. Nanzer*

Main category: eess.SP

TL;DR: 论文展示了一种分布式波束成形和波束控制技术，通过完全无线协调和分散时间同步实现六节点分布式相控阵。


<details>
  <summary>Details</summary>
Motivation: 在分布式波束成形等无线应用中，高精度的时间同步对实现高相干增益至关重要。

Method: 采用基于平均共识算法和双向时间传输方法的分散时间同步技术，结合集中式无线频率传输方法实现完全无线协调。

Result: 实验表明，在1.05 GHz载频下，系统平均相干增益达到理想增益的98%，时间同步精度平均低于36 ps。

Conclusion: 该技术证明了完全无线协调的分布式相控阵在高精度时间同步和波束成形中的有效性。

Abstract: We demonstrate a distributed beamforming and beamsteering from a six-node
distributed phased array using fully wireless coordination with decentralized
time synchronization. In wireless applications such as distributed beamforming,
high-accuracy time synchronization across the array is crucial for high
coherent gain. The decentralized time synchronization method employed is based
on the average consensus algorithm and the two-way time transfer method
presented in our previous work, which achieved picosecond time synchronization
with a cabled frequency reference. The system presented in this paper utilizes
a centralized wireless frequency transfer method to achieve wireless frequency
syntonization in a fully wireless coordination and a distributed computing
system architecture. We experimentally evaluate system performance through
beamforming and beamsteering to a receiver 16.3 m away from the six-node
non-uniformly distributed antenna array, achieving an average coherent gain of
98% of the ideal gain at a carrier frequency of 1.05 GHz. The average time
synchronization accuracy achieved was less than 36 ps.

</details>


### [17] [Beyond-Diagonal RIS Prototype and Performance Evaluation](https://arxiv.org/abs/2505.13392)
*Jean Tapie,Matteo Nerini,Bruno Clerckx,Philipp del Hougne*

Main category: eess.SP

TL;DR: 首次实验性原型展示了具有可重构互连的智能反射面（BD-RIS），验证了互连在性能上的优势。


<details>
  <summary>Details</summary>
Motivation: 探索智能反射面中可重构互连的性能影响及其在优化中的重要性。

Method: 使用天线阵列，通过可调负载网络实现三种独立的负载或相邻天线端口的互连。

Result: 实验证明互连有益于性能，但硬件约束对性能、互连优势及耦合感知优化有显著影响。

Conclusion: 可重构互连在智能反射面中具有潜力，但需考虑硬件约束和耦合优化的影响。

Abstract: We present the first experimental prototype of a reflective beyond-diagonal
reconfigurable intelligent surface (BD-RIS), i.e., a RIS with reconfigurable
inter-element connections. Our BD-RIS consists of an antenna array whose ports
are terminated by a tunable load network. The latter can terminate each antenna
port with three distinct individual loads or connect it to an adjacent antenna
port. Extensive performance evaluations in a rich-scattering environment
validate that inter-element connections are beneficial. Moreover, we observe
that our tunable load network's mentioned hardware constraints significantly
influence, first, the achievable performance, second, the benefits of having
inter-element connections, and, third, the importance of mutual-coupling
awareness during optimization.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [18] [Communication-Efficient Hybrid Language Model via Uncertainty-Aware Opportunistic and Compressed Transmission](https://arxiv.org/abs/2505.11788)
*Seungeun Oh,Jinhyuk Kim,Jihong Park,Seung-Woo Ko,Jinho Choi,Tony Q. S. Quek,Seong-Lyun Kim*

Main category: cs.DC

TL;DR: 论文提出了一种通信高效且不确定性感知的混合语言模型（CU-HLM），通过仅在SLM不确定性高时传输截断词汇分布，显著减少了通信开销并提升了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 原始混合语言模型（HLM）因需上传完整的词汇分布导致高通信开销，且资源浪费在大概率被接受的令牌验证上。

Method: CU-HLM通过SLM仅在输出不确定性高时传输截断词汇分布，并优化不确定性阈值和词汇截断策略。

Result: CU-HLM相比标准HLM，吞吐量提升206倍，跳过74.8%传输并压缩97.4%词汇，同时保持97.4%准确率。

Conclusion: CU-HLM是一种高效的解决方案，显著降低了HLM的通信和计算资源消耗，同时保持了模型性能。

Abstract: To support emerging language-based applications using dispersed and
heterogeneous computing resources, the hybrid language model (HLM) offers a
promising architecture, where an on-device small language model (SLM) generates
draft tokens that are validated and corrected by a remote large language model
(LLM). However, the original HLM suffers from substantial communication
overhead, as the LLM requires the SLM to upload the full vocabulary
distribution for each token. Moreover, both communication and computation
resources are wasted when the LLM validates tokens that are highly likely to be
accepted. To overcome these limitations, we propose communication-efficient and
uncertainty-aware HLM (CU-HLM). In CU-HLM, the SLM transmits truncated
vocabulary distributions only when its output uncertainty is high. We validate
the feasibility of this opportunistic transmission by discovering a strong
correlation between SLM's uncertainty and LLM's rejection probability.
Furthermore, we theoretically derive optimal uncertainty thresholds and optimal
vocabulary truncation strategies. Simulation results show that, compared to
standard HLM, CU-HLM achieves up to 206$\times$ higher token throughput by
skipping 74.8% transmissions with 97.4% vocabulary compression, while
maintaining 97.4% accuracy.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [19] [Acoustic Field Reconstruction in Tubes via Physics-Informed Neural Networks](https://arxiv.org/abs/2505.12557)
*Xinmeng Luan,Kazuya Yokota,Gary Scavone*

Main category: eess.AS

TL;DR: 论文研究了物理信息神经网络（PINNs）在声学管逆向问题中的应用，重点从噪声和有限数据中重建声场，并提出PINN-FTM方法。


<details>
  <summary>Details</summary>
Motivation: 探索在辐射模型未知且仅有管端压力数据的情况下，如何有效重建声场。

Method: 提出PINNs框架及PINN-FTM方法，并与传统优化方法（TOM）对比。

Result: PINNs在噪声条件下能有效重建声场，PINN-FTM表现优于TOM，具有鲁棒性。

Conclusion: PINN-FTM在声场重建中表现出色，适用于未知辐射参数和噪声场景。

Abstract: This study investigates the application of Physics-Informed Neural Networks
(PINNs) to inverse problems in acoustic tube analysis, focusing on
reconstructing acoustic fields from noisy and limited observation data.
Specifically, we address scenarios where the radiation model is unknown, and
pressure data is only available at the tube's radiation end. A PINNs framework
is proposed to reconstruct the acoustic field, along with the PINN Fine-Tuning
Method (PINN-FTM) and a traditional optimization method (TOM) for predicting
radiation model coefficients. The results demonstrate that PINNs can
effectively reconstruct the tube's acoustic field under noisy conditions, even
with unknown radiation parameters. PINN-FTM outperforms TOM by delivering
balanced and reliable predictions and exhibiting robust noise-tolerance
capabilities.

</details>


### [20] [Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning](https://arxiv.org/abs/2505.13017)
*Dang Thoai Phan,Tuan Anh Huynh,Van Tuan Pham,Cao Minh Tran,Van Thuan Mai,Ngoc Quy Tran*

Main category: eess.AS

TL;DR: 论文提出了一种优化连续小波变换（CWT）的方法，通过调整小波核长度和标量图输出步长降低计算成本，同时保持声学识别性能。


<details>
  <summary>Details</summary>
Motivation: 连续小波变换（CWT）在非平稳音频的特征提取中表现优异，但其高计算成本限制了其应用，研究者常选择STFT等替代方法。

Method: 优化小波核长度和标量图输出步长以降低CWT计算复杂度。

Result: 实验表明该方法显著降低计算成本，同时保持模型的稳健性能。

Conclusion: 提出的方法有效解决了CWT的计算效率问题，为声学识别任务提供了一种高效方案。

Abstract: The Continuous Wavelet Transform (CWT) is an effective tool for feature
extraction in acoustic recognition using Convolutional Neural Networks (CNNs),
particularly when applied to non-stationary audio. However, its high
computational cost poses a significant challenge, often leading researchers to
prefer alternative methods such as the Short-Time Fourier Transform (STFT). To
address this issue, this paper proposes a method to reduce the computational
complexity of CWT by optimizing the length of the wavelet kernel and the hop
size of the output scalogram. Experimental results demonstrate that the
proposed approach significantly reduces computational cost while maintaining
the robust performance of the trained model in acoustic recognition tasks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [21] [WaLRUS: Wavelets for Long-range Representation Using SSMs](https://arxiv.org/abs/2505.12161)
*Hossein Babaei,Mel White,Sina Alemohammad,Richard G. Baraniuk*

Main category: eess.IV

TL;DR: 论文介绍了WaLRUS，一种基于Daubechies小波的SaFARi实现，用于扩展SSM家族的能力。


<details>
  <summary>Details</summary>
Motivation: 现有SSM方法（如HiPPO）依赖于特定基的闭式解，限制了多样性。SaFARi框架旨在克服这一限制。

Method: 利用Daubechies小波构建WaLRUS，作为SaFARi的具体实现，支持任意框架的SSM建模。

Result: WaLRUS通过小波基扩展了SSM家族的多样性，提供了更灵活的建模能力。

Conclusion: WaLRUS为长程依赖建模提供了新的工具，丰富了SSM的应用潜力。

Abstract: State-Space Models (SSMs) have proven to be powerful tools for modeling
long-range dependencies in sequential data. While the recent method known as
HiPPO has demonstrated strong performance, and formed the basis for machine
learning models S4 and Mamba, it remains limited by its reliance on closed-form
solutions for a few specific, well-behaved bases. The SaFARi framework
generalized this approach, enabling the construction of SSMs from arbitrary
frames, including non-orthogonal and redundant ones, thus allowing an infinite
diversity of possible "species" within the SSM family. In this paper, we
introduce WaLRUS (Wavelets for Long-range Representation Using SSMs), a new
implementation of SaFARi built from Daubechies wavelets.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [22] [Improving Open-Set Semantic Segmentation in 3D Point Clouds by Conditional Channel Capacity Maximization: Preliminary Results](https://arxiv.org/abs/2505.11521)
*Wang Fang,Shirin Rahimi,Olivia Bennett,Sophie Carter,Mitra Hassani,Xu Lan,Omid Javadi,Lucas Mitchell*

Main category: cs.CV

TL;DR: 提出了一种用于开放式三维语义分割的即插即用框架，通过条件马尔可夫链建模和新的正则化项3CM，增强了模型对未见类别的识别能力。


<details>
  <summary>Details</summary>
Motivation: 当前深度架构在大规模数据集上的封闭集性能出色，但难以识别或分割训练类别之外的物体，这激发了开放式语义分割（O3S）的研究。

Method: 将分割流程建模为条件马尔可夫链，提出条件通道容量最大化（3CM）正则化项，增强特征与预测的条件互信息。

Result: 实验证明所提方法在检测未见物体方面表现优异。

Conclusion: 该方法为动态开放世界适应和高效信息论估计提供了未来研究方向。

Abstract: Point-cloud semantic segmentation underpins a wide range of critical
applications. Although recent deep architectures and large-scale datasets have
driven impressive closed-set performance, these models struggle to recognize or
properly segment objects outside their training classes. This gap has sparked
interest in Open-Set Semantic Segmentation (O3S), where models must both
correctly label known categories and detect novel, unseen classes. In this
paper, we propose a plug and play framework for O3S. By modeling the
segmentation pipeline as a conditional Markov chain, we derive a novel
regularizer term dubbed Conditional Channel Capacity Maximization (3CM), that
maximizes the mutual information between features and predictions conditioned
on each class. When incorporated into standard loss functions, 3CM encourages
the encoder to retain richer, label-dependent features, thereby enhancing the
network's ability to distinguish and segment previously unseen categories.
Experimental results demonstrate effectiveness of proposed method on detecting
unseen objects. We further outline future directions for dynamic open-world
adaptation and efficient information-theoretic estimation.

</details>


### [23] [Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets](https://arxiv.org/abs/2505.12532)
*Ahmet Bilican,M. Akın Yılmaz,A. Murat Tekalp,R. Gökberk Cinbiş*

Main category: cs.CV

TL;DR: 论文提出了一种名为WaveFT的新型参数高效微调方法，通过在小波域学习高度稀疏的更新，显著优于现有方法（如LoRA），尤其是在极低参数量下表现出色。


<details>
  <summary>Details</summary>
Motivation: 在大规模基础模型的适应过程中，计算和内存资源通常受限，现有方法（如LoRA）在极低参数量下的表现不足。

Method: WaveFT在小波域学习稀疏更新，实现对可训练参数的精确控制，提供细粒度的容量调整。

Result: 在个性化文本到图像生成任务中，WaveFT在低参数量下显著优于LoRA和其他PEFT方法，表现出更高的主题保真度、提示对齐和图像多样性。

Conclusion: WaveFT是一种高效且灵活的PEFT方法，特别适合极端参数受限的场景。

Abstract: Efficiently adapting large foundation models is critical, especially with
tight compute and memory budgets. Parameter-Efficient Fine-Tuning (PEFT)
methods such as LoRA offer limited granularity and effectiveness in
few-parameter regimes. We propose Wavelet Fine-Tuning (WaveFT), a novel PEFT
method that learns highly sparse updates in the wavelet domain of residual
matrices. WaveFT allows precise control of trainable parameters, offering
fine-grained capacity adjustment and excelling with remarkably low parameter
count, potentially far fewer than LoRA's minimum -- ideal for extreme
parameter-efficient scenarios. In order to demonstrate the effect of the
wavelet transform, we compare WaveFT with a special case, called SHiRA, that
entails applying sparse updates directly in the weight domain. Evaluated on
personalized text-to-image generation using Stable Diffusion XL as baseline,
WaveFT significantly outperforms LoRA and other PEFT methods, especially at low
parameter counts; achieving superior subject fidelity, prompt alignment, and
image diversity.

</details>


### [24] [Event-based Star Tracking under Spacecraft Jitter: the e-STURT Dataset](https://arxiv.org/abs/2505.12588)
*Samya Bagchi,Peter Anastasiou,Matthew Tetlow,Tat-Jun Chin,Yasir Latif*

Main category: cs.CV

TL;DR: 介绍了首个基于事件相机的星跟踪数据集e-STURT，用于模拟航天器抖动条件下的星观测，包含200个序列，并提出了一种高频抖动估计算法。


<details>
  <summary>Details</summary>
Motivation: 航天器抖动影响光学通信等精细指向能力，需高保真传感器数据进行抖动估计与补偿算法开发。

Method: 使用压电执行器模拟多种抖动源，结合事件相机生成高时间分辨率的星观测数据集。

Result: 生成了200个序列的公开数据集，并提出了一种基于事件流的高频抖动估计算法。

Conclusion: e-STURT数据集将支持开发任务关键型事件传感应用的抖动感知算法。

Abstract: Jitter degrades a spacecraft's fine-pointing ability required for optical
communication, earth observation, and space domain awareness. Development of
jitter estimation and compensation algorithms requires high-fidelity sensor
observations representative of on-board jitter. In this work, we present the
Event-based Star Tracking Under Jitter (e-STURT) dataset -- the first event
camera based dataset of star observations under controlled jitter conditions.
Specialized hardware employed for the dataset emulates an event-camera
undergoing on-board jitter. While the event camera provides asynchronous, high
temporal resolution star observations, systematic and repeatable jitter is
introduced using a micrometer accurate piezoelectric actuator. Various jitter
sources are simulated using distinct frequency bands and utilizing both axes of
motion. Ground-truth jitter is captured in hardware from the piezoelectric
actuator. The resulting dataset consists of 200 sequences and is made publicly
available. This work highlights the dataset generation process, technical
challenges and the resulting limitations. To serve as a baseline, we propose a
high-frequency jitter estimation algorithm that operates directly on the event
stream. The e-STURT dataset will enable the development of jitter aware
algorithms for mission critical event-based space sensing applications.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [25] [Study of Robust Resource Allocation in Cell-Free Multiple-Antenna Networks](https://arxiv.org/abs/2505.11778)
*S. Mashdour,A. Flores,R. C. de Lamare*

Main category: cs.IT

TL;DR: 提出了一种用于用户为中心的免小区大规模MIMO网络的鲁棒资源分配框架，通过用户调度和功率分配算法优化网络性能，解决了不完美CSI带来的问题。


<details>
  <summary>Details</summary>
Motivation: 免小区网络优于蜂窝网络，但其效率受不完美CSI影响，需设计鲁棒的资源分配策略以提升性能。

Method: 采用顺序资源分配策略，包括鲁棒用户调度算法和两种鲁棒功率分配算法，分别优化网络总速率和最小化均方误差。

Result: 仿真结果表明，所提算法性能提升高达30%，优于现有技术。

Conclusion: 该框架有效解决了不完美CSI问题，显著提升了免小区网络的性能。

Abstract: Cell-free networks outperform cellular networks in many aspects, yet their
efficiency is affected by imperfect channel state information (CSI). In order
to address this issue, this work presents a robust resource allocation
framework designed for the downlink of user-centric cell-free massive
multi-input multi-output (CF-mMIMO) networks. This framework employs a
sequential resource allocation strategy with a robust user scheduling algorithm
designed to maximize the sum-rate of the network and two robust power
allocation algorithms aimed at minimizing the mean square error, which are
developed to mitigate the effects of imperfect CSI. An analysis of the proposed
robust resource allocation problems is developed along with a study of their
computational cost. Simulation results demonstrate the effectiveness of the
proposed robust resource allocation algorithms, showing a performance
improvement of up to 30\% compared to existing techniques.

</details>


### [26] [An Information-Theoretic Framework for Receiver Quantization in Communication](https://arxiv.org/abs/2505.12258)
*Jing Zhou,Shuqin Pang,Wenyi Zhang*

Main category: cs.IT

TL;DR: 研究了接收端量化对通信的影响，重点关注分辨率从高到低的降低效果，提出了在一般量化规则下的可达速率，并分析了性能与量化加载因子的关系。


<details>
  <summary>Details</summary>
Motivation: 探讨量化对通信系统性能的影响，尤其是分辨率降低带来的速率损失，为设计高效量化方案提供理论基础。

Method: 采用标准收发架构，结合广义互信息（GMI）分析量化规则下的可达速率，并通过渐近分析研究性能。

Result: 发现前端增益控制对性能的影响随分辨率降低增加，证明了最小化MSE的加载因子能最大化GMI，并给出了不可速率损失表达式。

Conclusion: 揭示了量化性能与MSE最小化的一致性仅限于某些情况下，为实际系统设计提供了理论指导。

Abstract: We investigate information-theoretic limits and design of communication under
receiver quantization. Unlike most existing studies, this work is more focused
on the impact of resolution reduction from high to low. We consider a standard
transceiver architecture, which includes i.i.d. complex Gaussian codebook at
the transmitter, and a symmetric quantizer cascaded with a nearest neighbor
decoder at the receiver. Employing the generalized mutual information (GMI), an
achievable rate under general quantization rules is obtained in an analytical
form, which shows that the rate loss due to quantization is
$\log\left(1+\gamma\mathsf{SNR}\right)$, where $\gamma$ is determined by
thresholds and levels of the quantizer. Based on this result, the performance
under uniform receiver quantization is analyzed comprehensively. We show that
the front-end gain control, which determines the loading factor of
quantization, has an increasing impact on performance as the resolution
decreases. In particular, we prove that the unique loading factor that
minimizes the MSE also maximizes the GMI, and the corresponding irreducible
rate loss is given by $\log\left(1+\mathsf {mmse}\cdot\mathsf{SNR}\right)$,
where mmse is the minimum MSE normalized by the variance of quantizer input,
and is equal to the minimum of $\gamma$. A geometrical interpretation for the
optimal uniform quantization at the receiver is further established. Moreover,
by asymptotic analysis, we characterize the impact of biased gain control,
including how small rate losses decay to zero and achievable rate
approximations under large bias. From asymptotic expressions of the optimal
loading factor and mmse, approximations and several per-bit rules for
performance are also provided. Finally we discuss more types of receiver
quantization and show that the consistency between achievable rate maximization
and MSE minimization does not hold in general.

</details>


### [27] [Generative Diffusion Model Driven Massive Random Access in Massive MIMO Systems](https://arxiv.org/abs/2505.12382)
*Keke Ying,Zhen Gao,Sheng Chen,Tony Q. S. Quek,H. Vincent Poor*

Main category: cs.IT

TL;DR: 论文研究了大规模MIMO系统中的随机接入问题，利用深度学习技术解决用户检测、信道估计和数据检测的挑战，提出了基于Transformer的用户检测方案和生成扩散模型驱动的迭代框架，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决下一代无线通信系统中超大规模连接的关键挑战，包括用户检测、信道估计和数据检测。

Method: 提出Transformer-AUD方案适应可变导频长度，并设计生成扩散模型驱动的迭代信道估计和数据检测框架。

Result: 仿真结果表明，所提方法在用户检测、信道估计和数据检测方面显著优于基线方法。

Conclusion: 深度学习技术在大规模MIMO系统中的随机接入问题上表现优异，具有广泛应用前景。

Abstract: Massive random access is an important technology for achieving ultra-massive
connectivity in next-generation wireless communication systems. It aims to
address key challenges during the initial access phase, including active user
detection (AUD), channel estimation (CE), and data detection (DD). This paper
examines massive access in massive multiple-input multiple-output (MIMO)
systems, where deep learning is used to tackle the challenging AUD, CE, and DD
functions. First, we introduce a Transformer-AUD scheme tailored for variable
pilot-length access. This approach integrates pilot length information and a
spatial correlation module into a Transformer-based detector, enabling a single
model to generalize across various pilot lengths and antenna numbers. Next, we
propose a generative diffusion model (GDM)-driven iterative CE and DD
framework. The GDM employs a score function to capture the posterior
distributions of massive MIMO channels and data symbols. Part of the score
function is learned from the channel dataset via neural networks, while the
remaining score component is derived in a closed form by applying the symbol
prior constellation distribution and known transmission model. Utilizing these
posterior scores, we design an asynchronous alternating CE and DD framework
that employs a predictor-corrector sampling technique to iteratively generate
channel estimation and data detection results during the reverse diffusion
process. Simulation results demonstrate that our proposed approaches
significantly outperform baseline methods with respect to AUD, CE, and DD.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [28] [Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges](https://arxiv.org/abs/2505.11618)
*Pengrui Quan,Brian Wang,Kang Yang,Liying Han,Mani Srivastava*

Main category: cs.AI

TL;DR: 本文提出了一个名为STARK的分层次时空推理基准，用于系统评估LLM和LRM在不同复杂度任务中的表现，结果显示LLM在几何推理任务中表现有限，而LRM表现更强且在部分任务中超过传统方法。


<details>
  <summary>Details</summary>
Motivation: 探索LLM和LRM在复杂时空信号推理中的能力差异，为智能CPS的未来研究提供结构化的评估框架。

Method: 通过STARK基准（包含26项任务和14,552个挑战）评估3种LRM和8种LLM，任务分为状态估计、时空关系推理和世界知识推理三个层次。

Result: LLM在需要几何推理的任务中表现较差，而LRM在各种难度任务中表现稳健且优于传统方法；在需要世界知识的任务中，LLM与LRM的差距缩小。

Conclusion: STARK为识别LLM和LRM在时空推理中的局限性提供了框架，并激励未来在模型架构和推理范式上的创新。

Abstract: Spatiotemporal reasoning plays a key role in Cyber-Physical Systems (CPS).
Despite advances in Large Language Models (LLMs) and Large Reasoning Models
(LRMs), their capacity to reason about complex spatiotemporal signals remains
underexplored. This paper proposes a hierarchical SpatioTemporal reAsoning
benchmaRK, STARK, to systematically evaluate LLMs across three levels of
reasoning complexity: state estimation (e.g., predicting field variables,
localizing and tracking events in space and time), spatiotemporal reasoning
over states (e.g., inferring spatial-temporal relationships), and
world-knowledge-aware reasoning that integrates contextual and domain knowledge
(e.g., intent prediction, landmark-aware navigation). We curate 26 distinct
spatiotemporal tasks with diverse sensor modalities, comprising 14,552
challenges where models answer directly or by Python Code Interpreter.
Evaluating 3 LRMs and 8 LLMs, we find LLMs achieve limited success in tasks
requiring geometric reasoning (e.g., multilateration or triangulation),
particularly as complexity increases. Surprisingly, LRMs show robust
performance across tasks with various levels of difficulty, often competing or
surpassing traditional first-principle-based methods. Our results show that in
reasoning tasks requiring world knowledge, the performance gap between LLMs and
LRMs narrows, with some LLMs even surpassing LRMs. However, the LRM o3 model
continues to achieve leading performance across all evaluated tasks, a result
attributed primarily to the larger size of the reasoning models. STARK
motivates future innovations in model architectures and reasoning paradigms for
intelligent CPS by providing a structured framework to identify limitations in
the spatiotemporal reasoning of LLMs and LRMs.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [29] [LLM-guided DRL for Multi-tier LEO Satellite Networks with Hybrid FSO/RF Links](https://arxiv.org/abs/2505.11978)
*Jiahui Li,Geng Sun,Zemin Sun,Jiacheng Wang,Yinqiu Liu,Ruichen Zhang,Dusit Niyato,Shiwen Mao*

Main category: cs.NI

TL;DR: 提出了一种结合LEO卫星、HAPs和地面终端的三层网络架构，通过优化配置和切换决策，提升覆盖范围和连接可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决远程地区覆盖不足和自然灾害中的网络可靠性问题。

Method: 设计了混合FSO和RF链路的三层网络，并提出了LTQC-DAM算法优化网络性能。

Result: LTQC-DAM算法在收敛、下行传输速率和切换频率方面优于基线算法。

Conclusion: 混合链路和LTQC-DAM算法能有效提升网络性能，且DeepSeek在LLM中表现最佳。

Abstract: Despite significant advancements in terrestrial networks, inherent
limitations persist in providing reliable coverage to remote areas and
maintaining resilience during natural disasters. Multi-tier networks with low
Earth orbit (LEO) satellites and high-altitude platforms (HAPs) offer promising
solutions, but face challenges from high mobility and dynamic channel
conditions that cause unstable connections and frequent handovers. In this
paper, we design a three-tier network architecture that integrates LEO
satellites, HAPs, and ground terminals with hybrid free-space optical (FSO) and
radio frequency (RF) links to maximize coverage while maintaining connectivity
reliability. This hybrid approach leverages the high bandwidth of FSO for
satellite-to-HAP links and the weather resilience of RF for HAP-to-ground
links. We formulate a joint optimization problem to simultaneously balance
downlink transmission rate and handover frequency by optimizing network
configuration and satellite handover decisions. The problem is highly dynamic
and non-convex with time-coupled constraints. To address these challenges, we
propose a novel large language model (LLM)-guided truncated quantile critics
algorithm with dynamic action masking (LTQC-DAM) that utilizes dynamic action
masking to eliminate unnecessary exploration and employs LLMs to adaptively
tune hyperparameters. Simulation results demonstrate that the proposed LTQC-DAM
algorithm outperforms baseline algorithms in terms of convergence, downlink
transmission rate, and handover frequency. We also reveal that compared to
other state-of-the-art LLMs, DeepSeek delivers the best performance through
gradual, contextually-aware parameter adjustments.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [30] [MSCEKF-MIO: Magnetic-Inertial Odometry Based on Multi-State Constraint Extended Kalman Filter](https://arxiv.org/abs/2505.12634)
*Jiazhu Li,Jian Kuang,Xiaoji,Niu*

Main category: cs.RO

TL;DR: 提出了一种基于磁力计阵列辅助惯性导航的新型室内里程计方法 MSCEKF-MIO，通过融合磁力计和惯性导航数据，实现了高精度的室内定位。


<details>
  <summary>Details</summary>
Motivation: 解决现有室内里程计技术在精度、成本效益和鲁棒性方面难以兼顾的问题。

Method: 利用磁力计阵列拟合磁场模型，结合多状态约束扩展卡尔曼滤波（MSCEKF）融合惯性导航数据。

Result: 在150-250米轨迹上平均水平定位误差约2.5米，磁场特征显著区域速度估计精度达0.07米/秒。

Conclusion: 该方法提供了一种低功耗、低成本、高可靠性的室内定位解决方案。

Abstract: To overcome the limitation of existing indoor odometry technologies which
often cannot simultaneously meet requirements for accuracy cost-effectiveness,
and robustness-this paper proposes a novel magnetometer array-aided inertial
odometry approach, MSCEKF-MIO (Multi-State Constraint Extended Kalman
Filter-based Magnetic-Inertial Odometry). We construct a magnetic field model
by fitting measurements from the magnetometer array and then use temporal
variations in this model-extracted from continuous observations-to estimate the
carrier's absolute velocity. Furthermore, we implement the MSCEKF framework to
fuse observed magnetic field variations with position and attitude estimates
from inertial navigation system (INS) integration, thereby enabling autonomous,
high-precision indoor relative positioning. Experimental results demonstrate
that the proposed algorithm achieves superior velocity estimation accuracy and
horizontal positioning precision relative to state-of-the-art magnetic
array-aided INS algorithms (MAINS). On datasets with trajectory lengths of
150-250m, the proposed method yields an average horizontal position RMSE of
approximately 2.5m. In areas with distinctive magnetic features, the
magneto-inertial odometry achieves a velocity estimation accuracy of 0.07m/s.
Consequently, the proposed method offers a novel positioning solution
characterized by low power consumption, cost-effectiveness, and high
reliability in complex indoor environments.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [31] [Time-Continuous Frequency Allocation for Feeder Links of Mega Constellations with Multi-Antenna Gateway Stations](https://arxiv.org/abs/2505.12429)
*Zijun Liu,Yafei Wang,Tianhao Fang,Wenjin Wang,Zhili Sun*

Main category: eess.SY

TL;DR: 提出了一种基于图着色的频率分配方法，以解决巨型低地球轨道卫星系统中的干扰问题，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 巨型低地球轨道卫星系统的密集部署导致干扰加剧，需要有效的干扰缓解方法。

Method: 首先将干扰问题转化为$K$-着色问题，提出两种图着色算法（GG和CTS），并进一步改进以实现连续频率分配，同时设计了星座分解和子信道利用方法。

Result: 仿真结果表明，所提方法在Starlink星座场景下能有效缓解干扰并提升系统容量。

Conclusion: 该研究为巨型低地球轨道卫星系统提供了一种高效的干扰缓解和频谱利用率提升方案。

Abstract: With the recent rapid advancement of mega low earth orbit (LEO) satellite
constellations, multi-antenna gateway station (MAGS) has emerged as a key
enabler to support extremely high system capacity via massive feeder links.
However, the densification of both space and ground segment leads to reduced
spatial separation between links, posing unprecedented challenges of
interference exacerbation. This paper investigates graph coloring-based
frequency allocation methods for interference mitigation (IM) of mega LEO
systems. We first reveal the characteristics of MAGS interference pattern and
formulate the IM problem into a $K$-coloring problem using an adaptive
threshold method. Then we propose two tailored graph coloring algorithms,
namely Generalized Global (GG) and Clique-Based Tabu Search (CTS), to solve
this problem. GG employs a low-complexity greedy conflict avoidance strategy,
while CTS leverages the unique clique structure brought by MAGSs to enhance IM
performance. Subsequently, we innovatively modify them to achieve
time-continuous frequency allocation, which is crucial to ensure the stability
of feeder links. Moreover, we further devise two mega constellation
decomposition methods to alleviate the complexity burden of satellite
operators. Finally, we propose a list coloring-based vacant subchannel
utilization method to further improve spectrum efficiency and system capacity.
Simulation results on Starlink constellation of the first and second
generations with 34396 satellites demonstrate the effectiveness and superiority
of the proposed methodology.

</details>


### [32] [Secrecy Capacity of Hybrid VLC-RF Systems with Light Energy Harvesting](https://arxiv.org/abs/2505.12739)
*Tuan A. Hoang,Thanh V. Pham,Chuyen T. Nguyen*

Main category: eess.SY

TL;DR: 研究了在多用户混合异构可见光通信（VLC）和射频（RF）无线通信系统中，结合同时光波信息和功率传输（SLIPT）的物理层安全（PLS）性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在同时进行信息和能量传输的系统中，确保上行链路（UL）信息的机密性，防止未经授权用户的窃听。

Method: 采用时分多址（TDMA）支持多用户，在下行链路（DL）分配时隙进行信息接收和能量收集，上行链路（UL）利用收集的能量传输信号，并通过优化DL和UL时隙分配来最大化PLS性能。

Result: 问题被转化为差凸函数（DC）规划，可通过DC算法（DCA）高效求解。

Conclusion: 该方法有效提升了系统在PLS性能下的表现，同时满足了目标下行链路总速率的要求。

Abstract: This paper studies the performance of physical layer security (PLS) in a
multi-user hybrid heterogeneous visible light communication (VLC) and radio
frequency (RF) wireless communication system with simultaneous lightwave
information and power transfer (SLIPT). In the considered system, VLC is used
for downlink (DL) while RF is employed for uplink (UL) transmission. In
addition, to support multiple users, time division multiple access (TDMA) is
assumed for both DL and UL channels. In the DL, each user receives information
during its allocated time slot of the TDMA frame and harvests energy from the
received signal outside the time slot. The harvested energy is then used for
transmitting the signal over the UL channel, which is subject to eavesdropping
by an unauthorized user. Therefore, PLS is employed to protect the
confidentiality of the UL information. Then, an optimization problem is
formulated to solve the optimal DL and UL time slots that maximize the PLS
performance given a target sum rate of the DL. We show that the problem can be
cast as a difference of convex functions (DC) program, which can be solved
efficiently using the DC algorithm (DCA).

</details>


### [33] [Frequency-Dependent Power Consumption Modeling of CMOS Transmitters for WNoC Architectures](https://arxiv.org/abs/2505.13310)
*Mohammad Shahmoradi,Korkut Kaan Tokgöz,Eduard Alarcón,Sergi Abadal*

Main category: eess.SY

TL;DR: 本文提出了一个行为模型，用于量化无线片上网络（WNoC）系统中振荡器、混频器和功率放大器在不同频率下的功耗，帮助选择最优工作频率。


<details>
  <summary>Details</summary>
Motivation: 无线片上网络（WNoC）系统需要高效、高速的微型收发器，但由于频率增加带来的带宽、面积和能效之间的权衡，寻找最优频率设计点具有挑战性。

Method: 基于大量实验数据，构建了振荡器、混频器和功率放大器的行为模型，并将其整合为全面的功耗模型。

Result: 提出了一个能够量化不同频率下子模块功耗的综合模型，为WNoC系统的最优频率选择提供支持。

Conclusion: 该行为模型为WNoC系统的频率设计提供了实用工具，有助于实现高效的系统性能。

Abstract: Wireless Network-on-Chip (WNoC) systems, which wirelessly interconnect the
chips of a computing system, have been proposed as a complement to existing
chip-to-chip wired links. However, their feasibility depends on the
availability of custom-designed high-speed, tiny, ultra-efficient transceivers.
This represents a challenge due to the tradeoffs between bandwidth, area, and
energy efficiency that are found as frequency increases, which suggests that
there is an optimal frequency region. To aid in the search for such an optimal
design point, this paper presents a behavioral model that quantifies the
expected power consumption of oscillators, mixers, and power amplifiers as a
function of frequency. The model is built on extensive surveys of the
respective sub-blocks, all based on experimental data. By putting together the
models of the three sub-blocks, a comprehensive power model is obtained, which
will aid in selecting the optimal operating frequency for WNoC systems.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [34] [Identifiability of Nonnegative Tucker Decompositions -- Part I: Theory](https://arxiv.org/abs/2505.12713)
*Subhayan Saha,Giovanni Barbarino,Nicolas Gillis*

Main category: math.NA

TL;DR: 本文研究了非负Tucker分解（nTD）的可识别性，通过借鉴非负矩阵分解（NMF）的方法，提出了在稀疏性条件下确保nTD唯一性的理论，并通过最小化核心张量的展开或切片体积来实现可识别性。


<details>
  <summary>Details</summary>
Motivation: 尽管Tucker分解（TD）在数据科学中广泛应用，但其通常不具备可识别性。本文旨在研究非负Tucker分解（nTD）的可识别性，以解决这一局限性。

Method: 通过将非负矩阵分解（NMF）的可识别性结果扩展到nTD，并假设矩阵因子具有一定的稀疏性（如可分离性或充分散射条件），同时核心张量的某些展开或切片需具有满列秩（但不要求非负性），提出了基于展开或切片体积最小化的方法。

Result: 在满足稀疏性和秩条件下，所提出的方法能够实现nTD的可识别性，并提供了多种实现途径。

Conclusion: 本文为非负Tucker分解的可识别性提供了理论支持，并通过优化核心张量的展开或切片体积实现了实际应用中的唯一性。

Abstract: Tensor decompositions have become a central tool in data science, with
applications in areas such as data analysis, signal processing, and machine
learning. A key property of many tensor decompositions, such as the canonical
polyadic decomposition, is identifiability: the factors are unique, up to
trivial scaling and permutation ambiguities. This allows one to recover the
groundtruth sources that generated the data. The Tucker decomposition (TD) is a
central and widely used tensor decomposition model. However, it is in general
not identifiable. In this paper, we study the identifiability of the
nonnegative TD (nTD). By adapting and extending identifiability results of
nonnegative matrix factorization (NMF), we provide uniqueness results for nTD.
Our results require the nonnegative matrix factors to have some degree of
sparsity (namely, satisfy the separability condition, or the sufficiently
scattered condition), while the core tensor only needs to have some slices (or
linear combinations of them) or unfoldings with full column rank (but does not
need to be nonnegative). Under such conditions, we derive several procedures,
using either unfoldings or slices of the input tensor, to obtain identifiable
nTDs by minimizing the volume of unfoldings or slices of the core tensor.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [35] [Multi-Attribute Graph Estimation with Sparse-Group Non-Convex Penalties](https://arxiv.org/abs/2505.11984)
*Jitendra K Tugnait*

Main category: stat.ML

TL;DR: 该论文研究了从多属性数据中推断高维高斯向量的条件独立图（CIG）的问题，提出了一种基于惩罚对数似然目标函数的统一理论分析，并比较了凸与非凸惩罚函数的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大多数图形估计方法基于单属性模型，而多属性图形模型中每个节点代表一个随机向量，研究多属性图形学习有助于更全面地建模数据关系。

Method: 提出了一种基于交替方向乘子法（ADMM）和局部线性近似的优化方法，用于优化惩罚对数似然目标函数，涵盖了凸和非凸惩罚函数（如稀疏组套索、log-sum和SCAD）。

Result: 在合成数据实验中，稀疏组log-sum惩罚函数的表现显著优于套索和SCAD惩罚函数，使用了F1分数和汉明距离作为评估指标。

Conclusion: 论文提供了多属性图形学习的统一理论分析，展示了非凸惩罚函数在支持恢复和精度矩阵估计中的优势，尤其是在高维设置下。

Abstract: We consider the problem of inferring the conditional independence graph (CIG)
of high-dimensional Gaussian vectors from multi-attribute data. Most existing
methods for graph estimation are based on single-attribute models where one
associates a scalar random variable with each node. In multi-attribute
graphical models, each node represents a random vector. In this paper we
provide a unified theoretical analysis of multi-attribute graph learning using
a penalized log-likelihood objective function. We consider both convex
(sparse-group lasso) and sparse-group non-convex (log-sum and smoothly clipped
absolute deviation (SCAD) penalties) penalty/regularization functions. An
alternating direction method of multipliers (ADMM) approach coupled with local
linear approximation to non-convex penalties is presented for optimization of
the objective function. For non-convex penalties, theoretical analysis
establishing local consistency in support recovery, local convexity and
precision matrix estimation in high-dimensional settings is provided under two
sets of sufficient conditions: with and without some irrepresentability
conditions. We illustrate our approaches using both synthetic and real-data
numerical examples. In the synthetic data examples the sparse-group log-sum
penalized objective function significantly outperformed the lasso penalized as
well as SCAD penalized objective functions with $F_1$-score and Hamming
distance as performance metrics.

</details>


### [36] [T-Rex: Fitting a Robust Factor Model via Expectation-Maximization](https://arxiv.org/abs/2505.12117)
*Daniel Cederberg*

Main category: stat.ML

TL;DR: 提出了一种基于 Tyler's M-estimator 的 EM 算法，用于鲁棒拟合统计因子模型，解决了传统方法对异常值和高尾部数据敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 传统统计因子模型拟合方法（如 PCA 或高斯假设下的最大似然估计）对异常值和重尾数据敏感，需要更鲁棒的方法。

Method: 基于 Tyler's M-estimator 的 EM 算法，通过结构约束强制低秩加对角协方差结构。

Result: 数值实验表明，该方法在非均匀噪声中的到达方向估计和子空间恢复方面具有鲁棒性。

Conclusion: 所提方法在多种场景下显著提升了统计因子模型的鲁棒性。

Abstract: Over the past decades, there has been a surge of interest in studying
low-dimensional structures within high-dimensional data. Statistical factor
models $-$ i.e., low-rank plus diagonal covariance structures $-$ offer a
powerful framework for modeling such structures. However, traditional methods
for fitting statistical factor models, such as principal component analysis
(PCA) or maximum likelihood estimation assuming the data is Gaussian, are
highly sensitive to heavy tails and outliers in the observed data. In this
paper, we propose a novel expectation-maximization (EM) algorithm for robustly
fitting statistical factor models. Our approach is based on Tyler's M-estimator
of the scatter matrix for an elliptical distribution, and consists of solving
Tyler's maximum likelihood estimation problem while imposing a structural
constraint that enforces the low-rank plus diagonal covariance structure. We
present numerical experiments on both synthetic and real examples,
demonstrating the robustness of our method for direction-of-arrival estimation
in nonuniform noise and subspace recovery.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Joint Graph Estimation and Signal Restoration for Robust Federated Learning](https://arxiv.org/abs/2505.11648)
*Tsutahiro Fukuhara,Junya Hara,Hiroshi Higashi,Yuichi Tanaka*

Main category: cs.LG

TL;DR: 提出了一种联邦学习中针对噪声通信的鲁棒参数聚合方法，通过图学习和信号恢复提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的参数在收集、训练和通信过程中可能存在噪声或缺失值，导致模型性能下降。

Method: 通过学习客户端模型参数间的图关系，将问题转化为DC优化，并通过近端DC算法求解。

Result: 在MNIST和CIFAR-10数据集上，新方法在噪声和偏斜数据分布下比现有方法精度提升2-5%。

Conclusion: 该方法有效提升了联邦学习在噪声环境下的模型精度和鲁棒性。

Abstract: We propose a robust aggregation method for model parameters in federated
learning (FL) under noisy communications. FL is a distributed machine learning
paradigm in which a central server aggregates local model parameters from
multiple clients. These parameters are often noisy and/or have missing values
during data collection, training, and communication between the clients and
server. This may cause a considerable drop in model accuracy. To address this
issue, we learn a graph that represents pairwise relationships between model
parameters of the clients during aggregation. We realize it with a joint
problem of graph learning and signal (i.e., model parameters) restoration. The
problem is formulated as a difference-of-convex (DC) optimization, which is
efficiently solved via a proximal DC algorithm. Experimental results on MNIST
and CIFAR-10 datasets show that the proposed method outperforms existing
approaches by up to $2$--$5\%$ in classification accuracy under biased data
distributions and noisy conditions.

</details>


### [38] [Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast](https://arxiv.org/abs/2505.13102)
*Ji Qi,Tam Thuc Do,Mingxiao Liu,Zhuoshi Pan,Yuzhe Li,Gene Cheung,H. Vicky Zhao*

Main category: cs.LG

TL;DR: 该论文提出了一种轻量级且可解释的类Transformer神经网络，用于预测具有时空维度的交通流量，通过混合图优化算法的展开实现，参数少且性能优越。


<details>
  <summary>Details</summary>
Motivation: 为了同时捕捉空间和时间维度的交通流量特征，作者提出了一种基于混合图的优化方法，并将它展开为神经网络，以实现高效的参数学习和预测性能。

Method: 构建无向图和有向图分别捕捉空间和时间相关性，设计了新的平滑信号变分项，通过ADMM迭代算法展开为前馈网络，并插入类似Transformer自注意力机制的图学习模块。

Result: 实验表明，该方法在交通流量预测任务中与现有最优方案效果相当，同时显著减少了参数数量。

Conclusion: 该方法提供了一种轻量且高效的方式，成功解决了交通流量预测中的时空特征建模问题。

Abstract: To forecast traffic with both spatial and temporal dimensions, we unroll a
mixed-graph-based optimization algorithm into a lightweight and interpretable
transformer-like neural net. Specifically, we construct two graphs: an
undirected graph $\mathcal{G}^u$ capturing spatial correlations across
geography, and a directed graph $\mathcal{G}^d$ capturing sequential
relationships over time. We formulate a prediction problem for the future
samples of signal $\mathbf{x}$, assuming it is "smooth" with respect to both
$\mathcal{G}^u$ and $\mathcal{G}^d$, where we design new $\ell_2$ and
$\ell_1$-norm variational terms to quantify and promote signal smoothness
(low-frequency reconstruction) on a directed graph. We construct an iterative
algorithm based on alternating direction method of multipliers (ADMM), and
unroll it into a feed-forward network for data-driven parameter learning. We
insert graph learning modules for $\mathcal{G}^u$ and $\mathcal{G}^d$, which
are akin to the self-attention mechanism in classical transformers. Experiments
show that our unrolled networks achieve competitive traffic forecast
performance as state-of-the-art prediction schemes, while reducing parameter
counts drastically. Our code is available in
https://github.com/SingularityUndefined/Unrolling-GSP-STForecast.

</details>
