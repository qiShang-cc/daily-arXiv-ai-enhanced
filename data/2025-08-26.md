<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 18]
- [cs.RO](#cs.RO) [Total: 37]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [eess.SY](#eess.SY) [Total: 3]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Notes on Deterministic and Stochastic Approaches in Electromagnetic Information Theory](https://arxiv.org/abs/2508.16601)
*Marco Donald Migliore*

Main category: eess.SP

TL;DR: 论文研究了电磁信息理论中确定性模型与随机模型的自由度数量关系，发现两者在空间非相干且均匀源条件下具有相同的自由度、特征值和基函数。


<details>
  <summary>Details</summary>
Motivation: 旨在验证确定性模型与随机模型在电磁信息理论中的等价性，以解释确定方法在该领域的有效性。

Method: 比较确定性模型和空间非相干均匀源的随机模型中的自由度数量、特征值和基函数。

Result: 发现两种模型在所述条件下表现出完全相同的自由度、特征值和基函数。

Conclusion: 这一等价性不仅验证了确定性方法的有效性，还支持了经典电磁方法在新学科中的应用。

Abstract: This paper investigates the relationship between the Number of Degrees of
Freedom ($N_{\rm DoF}$) of the field in deterministic and stochastic source
models within Electromagnetic Information Theory (EIT). Our findings
demonstrate a fundamental connection between these two approaches.
Specifically, we show that a deterministic model and a stochastic model with a
spatially incoherent and homogeneous source yield not only the same $N_{\rm
DoF}$ but also identical eigenvalues and basis functions for field
representation. This key equivalence not only explains the effectiveness of
deterministic approaches in EIT but also corroborates the use of classical
electromagnetic methods within this new discipline.

</details>


### [2] [A Practical Approach to the Design of an S-Band Image-Rejecting Dual-Conversion Super-Heterodyne RF Chain of a Receiver Considering Spur Signals](https://arxiv.org/abs/2508.16735)
*Seyed Mohammad Amin Shirinbayan,Gholamreza Moradi*

Main category: eess.SP

TL;DR: 论文提出了一种用于雷达接收机射频部分的双变频架构设计，通过两种MATLAB代码消除杂散信号，优化SFDR与动态范围，并降低实现成本。


<details>
  <summary>Details</summary>
Motivation: 解决超外差双变频架构中杂散信号对射频链动态范围的负面影响。

Method: 使用两种相互验证的MATLAB代码优化杂散信号，并结合微波软件和全波分析进行详细设计。

Result: 通过优化组件选择和滤波器设计，显著提高了链路的SFDR并降低了实现成本。

Conclusion: 该方法有效减少了杂散信号的影响，优化了系统性能，适用于多种混频器的超外差配置。

Abstract: This paper presents a typical design of the RF section of a radar receiver,
the chain within a superheterodyne dual-conversion architecture. A significant
challenge in this framework is the occurrence of spur signals, which negatively
impact the dynamic range of the RF chain. When addressing this issue, the paper
introduces an innovative approach to mitigate (or even wipe out) these
undesired effects, utilizing two mutually verifying MATLAB codes. These codes
have been tested with two distinct commercial mixers and could be applied to
any superheterodyne configuration with various mixers. The presented method
makes the Spurious-Free Dynamic Range (SFDR) of the chain the least different
from the dynamic range of the chain. Also, the selection of other components
gets optimized to align with spurious signals consideration, with explanations
provided for these choices. Moreover, two filters of the RF chain, the second
and the third, have been designed to reduce implementation costs. Various
Microwave software and full-wave analyses were employed for detailed design and
analysis, with the results compared to evaluate their performance.

</details>


### [3] [Dual Orthogonal Projections-Based Multiuser Interference Cancellation for mmWave Beamforming in XL-MIMO Systems](https://arxiv.org/abs/2508.16888)
*Jiazhe Li,Nicolò Decarli,Francesco Guidi,Anna Guerra,Alessandro Bazzi,Zhuoming Li*

Main category: eess.SP

TL;DR: 论文提出了一种名为迭代双正交投影（DOP）的线性算法，用于毫米波XL-MIMO系统中的多用户干扰消除，通过交替正交投影提升频谱效率，性能接近理论最优。


<details>
  <summary>Details</summary>
Motivation: 研究超大规模多输入多输出（XL-MIMO）通信系统中毫米波波束成形技术的多用户干扰（MUI）消除问题。

Method: 提出迭代双正交投影（DOP）算法，通过交替执行消除MUI和优化组合器的正交投影，单调提升频谱效率。

Result: 理论分析和仿真显示，算法每次迭代均单调提升用户信号功率、降低等效噪声，频谱效率快速收敛并接近理论最优，性能优于现有线性算法。

Conclusion: DOP算法在XL-MIMO系统中有效解决了MUI问题，频谱效率显著提升且接近理论极限，为毫米波通信提供了高效解决方案。

Abstract: This paper investigates multiuser interference (MUI) cancellation for
millimeter-wave (mmWave) beamforming in extremely large-scale multiple-input
multiple-output (XL-MIMO) communication systems. We propose a linear algorithm,
termed iterative dual orthogonal projections (DOP), which alternates between
two orthogonal projections: one to eliminate MUI and the other to refine
combiners, ensuring a monotonic increase in spectral efficiency. Theoretical
analysis and simulation results show that, with each iteration, the signal
power for each user increases monotonically, the equivalent noise power after
receive combining decreases monotonically, and the spectral efficiency improves
accordingly and converges rapidly, closely approaching the theoretical optimum
determined by dirty paper coding (DPC), outperforming existing linear
algorithms in spectral efficiency.

</details>


### [4] [Spatially Correlated Blockage Aware Placement of RIS in IIoT Networks](https://arxiv.org/abs/2508.16946)
*Rashmi Kumari,Gourab Ghatak,Abhishek K. Gupta*

Main category: eess.SP

TL;DR: 研究RIS在IIoT网络中减少覆盖盲区、提升传输可靠性的作用，分析单块和多块遮挡场景下SNR分布及性能比较。


<details>
  <summary>Details</summary>
Motivation: 在工业物联网网络中，遮挡问题可能导致连接中断，研究RIS如何解决这一问题并提高可靠性。

Method: 通过单块和多块遮挡场景建模，分析RIS与用户间链路的遮挡相关性，推导SNR分布，并与中继系统比较。

Result: 多块遮挡下，RIS能有效改善性能，但中继在更高遮挡阈值下表现更优；增加RIS数量可缓解其劣势。

Conclusion: RIS在遮挡密集的IIoT网络中具有潜力，设计时需平衡RIS数量与中继系统的选择。

Abstract: We study the impact of deploying reconfigurable intelligent surfaces (RISs)
in mitigating coverage gaps and enhancing transmission reliability in an
industrial internet of things (IIoT) network. First, we consider a single
blockage scenario and characterize the correlation between blocking events of
the base station (BS)-user and the RIS-user links and study its impact on the
probability of establishing a viable reflected link. Then, by considering
multiple blockages, we derive the distribution of the signal to noise ratio
(SNR) as a function of data size, blockage density, the number of RISs, and the
deployment area. We analyze the impact of normalized blockage radius and
identify the threshold beyond which the assumption of independent blockages
deviates from the ground truth of correlated blocking. Finally, we compare the
outage performance of this RIS-assisted system with that operated with network-
controlled relays, and demonstrate that while the relays provide a higher
reliability beyond a certain blockage threshold, increasing the number of RISs
may help mitigate this effect. These insights offer valuable design guidelines
for deploying RIS-aided IIoT networks in dense blockage environments.

</details>


### [5] [Radio Frequency Identification: Decades at a Time](https://arxiv.org/abs/2508.17051)
*Christopher Saetia,Daniel M. Dobkin,Gregory Durgin*

Main category: eess.SP

TL;DR: 本文回顾了射频识别（RFID）技术的发展历史、应用现状以及未来可能的路径，包括UHF和HF NFC技术的比较，以及RFID与AI、数字孪生等技术的结合前景。


<details>
  <summary>Details</summary>
Motivation: 探讨RFID技术从早期愿景到当前实际应用的发展历程，并提出未来可能的创新方向。

Method: 通过回顾历史、比较现有应用和技术，分析未来RFID技术的潜在发展方向。

Result: 总结了RFID在不同领域的应用成功案例，并提出了未来技术整合（如AI、数字孪生）的可能性。

Conclusion: RFID技术在未来仍有许多发展潜力，但也面临诸多挑战。

Abstract: In this article, we briefly review the history of the use of radio signals to
identify objects, and of the key Radio Frequency Identification (RFID)
standards for ultra-high-frequency (UHF) and near-field communications that
enabled broad use of these technologies in daily life. We will compare the
vision for the future presented by the Auto-ID Lab in the early 21st century
with the reality we see today, two decades and a little after. We will review
some of the applications in which UHF RFID technology has become hugely
successful, others where High Frequency Near-field Communications (HF NFC) is
preferred, and applications where optical identification or active wireless
communications are dominant.
  We will then examine some possible future paths for RFID technology. We
anticipate that UHF read capability will become widely available for
cellphones, making it as universal as NFC and Bluetooth are today. We will look
at more sophisticated radio interfaces, such as multiple-antenna phased arrays
for readers, and tunnel diode reflection for tags. We will discuss the
integration of information from Artificial Intelligence (AI)-based image
processing, barcodes, NFC and UHF tags, into a digital twin of the real
environment experienced by the human user. We will examine the role of RFID
with sensing in improving the management of perishable goods. The role that
RFID might play in a truly circular economy, with intelligent recycling and
reuse, will be discussed. Finally, we survey the many hazards and obstacles
that obstruct the path to an RF-informed future.

</details>


### [6] [Graphon Signal Processing for Spiking and Biological Neural Networks](https://arxiv.org/abs/2508.17246)
*Takuma Sumi,Georgi S. Medvedev*

Main category: eess.SP

TL;DR: 该论文提出了一种基于图论信号处理（GSP）和图子（Graphons）的信号处理方法（GnSP），用于解决计算和生物神经网络中的刺激识别问题（SIP），并在实验中验证了其鲁棒性和分类性能。


<details>
  <summary>Details</summary>
Motivation: 图信号处理（GSP）在图结构数据中有广泛应用，但缺乏对大规模网络和随机性的稳定处理。图子（Graphons）能够解决这些问题，因此论文引入GnSP框架，并首次将其应用于生物神经网络中。

Method: 论文使用GnSP框架，通过图子的谱投影方法，从网络输出中推断未知刺激。方法分别在模拟的脉冲神经网络和钙成像记录中验证，并与主成分分析（PCA）和离散GSP基线进行对比。

Result: 实验结果证实，基于图子的低维嵌入在刺激分类上优于PCA和离散GSP，且在网络规模和噪声变化下表现稳定。

Conclusion: 论文首次将GnSP应用于生物神经网络，证明了其在解决SIP问题中的有效性，为神经科学的图子分析开辟了新方向。

Abstract: Graph Signal Processing (GSP) extends classical signal processing to signals
defined on graphs, enabling filtering, spectral analysis, and sampling of data
generated by networks of various kinds. Graphon Signal Processing (GnSP)
develops this framework further by employing the theory of graphons. Graphons
are measurable functions on the unit square that represent graphs and limits of
convergent graph sequences. The use of graphons provides stability of GSP
methods to stochastic variability in network data and improves computational
efficiency for very large networks. We use GnSP to address the stimulus
identification problem (SIP) in computational and biological neural networks.
The SIP is an inverse problem that aims to infer the unknown stimulus s from
the observed network output f. We first validate the approach in spiking neural
network simulations and then analyze calcium imaging recordings. Graphon-based
spectral projections yield trial-invariant, lowdimensional embeddings that
improve stimulus classification over Principal Component Analysis and discrete
GSP baselines. The embeddings remain stable under variations in network
stochasticity, providing robustness to different network sizes and noise
levels. To the best of our knowledge, this is the first application of GnSP to
biological neural networks, opening new avenues for graphon-based analysis in
neuroscience.

</details>


### [7] [Toward Multi-Functional LAWNs with ISAC: Opportunities, Challenges, and the Road Ahead](https://arxiv.org/abs/2508.17354)
*Jun Wu,Weijie Yuan,Xiaoqi Zhang,Yaohuan Yu,Yuanhao Cui,Fan Liu,Geng Sun,Jiacheng Wang,Dusit Niyato,Dong In Kim*

Main category: eess.SP

TL;DR: 本文探讨了集成感知与通信（ISAC）在未来低空无线网络（LAWNs）中的作用，提出了多功能框架并展示了其优势。


<details>
  <summary>Details</summary>
Motivation: 研究ISAC技术在LAWNs中的应用，以满足实时环境感知和空地系统数据交换的需求。

Method: 从节点和网络层面分析ISAC的作用，提出多功能框架（包括控制、计算、无线能量传输和LLM智能）。

Result: 通过分层集成与合作实现性能提升，展示了ISAC-enabled LAWN的潜力。

Conclusion: ISAC技术在LAWNs中具有广阔前景，未来研究应关注其多功能扩展和实际应用。

Abstract: Integrated sensing and communication (ISAC) has been envisioned as a
foundational technology for future low-altitude wireless networks (LAWNs),
enabling real-time environmental perception and data exchange across
aerial-ground systems. In this article, we first explore the roles of ISAC in
LAWNs from both node-level and network-level perspectives. We highlight the
performance gains achieved through hierarchical integration and cooperation,
wherein key design trade-offs are demonstrated. Apart from physical-layer
enhancements, emerging LAWN applications demand broader functionalities. To
this end, we propose a multi-functional LAWN framework that extends ISAC with
capabilities in control, computation, wireless power transfer, and large
language model (LLM)-based intelligence. We further provide a representative
case study to present the benefits of ISAC-enabled LAWNs and the promising
research directions are finally outlined.

</details>


### [8] [Near-Field Integrated Imaging and Communication in Distributed MIMO Networks](https://arxiv.org/abs/2508.17526)
*Kangda Zhi,Tianyu Yang,Shuangyang Li,Yi Song,Amir Rezaei,Giuseppe Caire*

Main category: eess.SP

TL;DR: 提出了一种适用于分布式MIMO宽带通信系统的无线成像框架，针对室内和室外场景分别设计了高分辨率成像和粗分辨率3D环境重构的算法。


<details>
  <summary>Details</summary>
Motivation: 解决分布式MIMO系统中非各向同性目标和近场传播效应的无线成像问题。

Method: 室内场景采用基于RMA的方案；室外场景采用基于SBL的算法解决MMV问题。

Result: 数值结果表明算法能高分辨率成像小物体并准确重构大尺度环境。

Conclusion: 提出的框架和算法有效解决了不同场景下的无线成像需求。

Abstract: In this work, we propose a general framework for wireless imaging in
distributed MIMO wideband communication systems, considering multi-view
non-isotropic targets and near-field propagation effects. For indoor scenarios
where the objective is to image small-scale objects with high resolution, we
propose a range migration algorithm (RMA)-based scheme using three kinds of
array architectures: the full array, boundary array, and distributed boundary
array. With non-isotropic near-field channels, we establish the Fourier
transformation (FT)-based relationship between the imaging reflectivity and the
distributed spatial-domain signals and discuss the corresponding theoretical
properties. Next, for outdoor scenarios where the objective is to reconstruct
the large-scale three-dimensional (3D) environment with coarse resolution, we
propose a sparse Bayesian learning (SBL)-based algorithm to solve the multiple
measurement vector (MMV) problem, which further addresses the non-isotropic
reflectivity across different subcarriers. Numerical results demonstrate the
effectiveness of the proposed algorithms in acquiring high-resolution small
objects and accurately reconstructing large-scale environments.

</details>


### [9] [Steerable Invariant Beamformer Using a Differential Line Array of Omnidirectional and Directional Microphones with Null Constraints](https://arxiv.org/abs/2508.17607)
*Yankai Zhang,Jiafeng Ding,Jingjing Ning,Qiaoxi Zhu*

Main category: eess.SP

TL;DR: 本文提出了一种基于零约束的方法，用于设计频率和方向不变差分波束成形器，克服了传统方法的局限性，具有更高的设计自由度和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的Jacobi-Anger展开方法依赖于理想的波束模式解析表达和截断顺序选择，实际应用中存在限制。本文旨在提出一种更灵活、实用的方法。

Method: 采用多约束优化框架，基于指定的零点和期望方向确定参考滤波器和理想波束模式，结合白噪声增益约束和波束模式约束，通过优化滤波器中各约束条件，实现性能平衡。

Result: 仿真和实验表明，新方法在有效范围、主瓣和零点对齐以及设计灵活性上优于传统方法，无需解析波束模式表达。

Conclusion: 零约束方法解决了传统方法的局限性，提升了差分波束成形的鲁棒性和实用性，为实际应用提供了更大自由度。

Abstract: Line differential microphone arrays have attracted attention for their
ability to achieve frequency-invariant beampatterns and high directivity.
Recently, the Jacobi-Anger expansion-based approach has enabled the design of
fully steerable-invariant differential beamformers for line arrays combining
omnidirectional and directional microphones. However, this approach relies on
the analytical expression of the ideal beam pattern and the proper selection of
truncation order, which is not always practical. This paper introduces a
null-constraint-based method for designing frequency- and steerable-invariant
differential beamformers using a line array of omnidirectional and directional
microphones. The approach employs a multi-constraint optimisation framework,
where the reference filter and ideal beam pattern are first determined based on
specified nulls and desired direction. Subsequently, the white noise gain
constraint is derived from the reference filter, and the beampattern constraint
is from the ideal beam pattern. The optimal filter is then obtained by
considering constraints related to the beampattern, nulls, and white noise
gain. This method achieves a balance between white noise gain and mean square
error, allowing robust, frequency- and steerableinvariant differential
beamforming performance. It addresses limitations in beam pattern flexibility
and truncation errors, offering greater design freedom and improved practical
applicability. Simulations and experiments demonstrate that this method
outperforms the Jacobi-Anger expansion-based approach in three key aspects: an
extended effective range, improved main lobe and null alignment, and greater
flexibility in microphone array configuration and beam pattern design,
requiring only steering direction and nulls instead of an analytic beam pattern
expression.

</details>


### [10] [Multimodal Radio and Vision Fusion for Robust Localization in Urban V2I Communications](https://arxiv.org/abs/2508.17640)
*Can Zheng,Jiguang He,Chung G. Kang,Guofa Cai,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出了一种基于多模态对比学习回归的V2I定位框架，结合CSI与视觉信息以提高精度。


<details>
  <summary>Details</summary>
Motivation: 城市环境中GPS信号易受遮挡，需要替代方案确保定位精度，适用于自动驾驶和智慧城市。

Method: 利用无线和视觉数据的互补性，建立多模态对比学习回归模型。

Result: 仿真结果显示，该模型在复杂城市环境中显著优于传统方法和单模态模型。

Conclusion: 结合CSI与视觉的多模态方法为V2I应用提供了更可靠的定位解决方案。

Abstract: Accurate localization is critical for vehicle-to-infrastructure (V2I)
communication systems, especially in urban areas where GPS signals are often
obstructed by tall buildings, leading to significant positioning errors,
necessitating alternative or complementary techniques for reliable and precise
positioning in applications like autonomous driving and smart city
infrastructure. This paper proposes a multimodal contrastive learning
regression based localization framework for V2I scenarios that combines channel
state information (CSI) with visual information to achieve improved accuracy
and reliability. The approach leverages the complementary strengths of wireless
and visual data to overcome the limitations of traditional localization
methods, offering a robust solution for V2I applications. Simulation results
demonstrate that the proposed CSI and vision fusion model significantly
outperforms traditional methods and single modal models, achieving superior
localization accuracy and precision in complex urban environments.

</details>


### [11] [Symbol Detection Using an Integrate-and-Fire Time Encoding Receiver](https://arxiv.org/abs/2508.17704)
*Neil Irwin Bernardo*

Main category: eess.SP

TL;DR: 提出了一种基于IF-TEM采样器的接收机架构，直接从时间编码中估计符号序列，无需波形重构。


<details>
  <summary>Details</summary>
Motivation: 探索事件驱动采样（如IF-TEM）在低功耗系统中的符号检测效率。

Method: 开发了一种直接从时间编码估计符号序列的接收机架构，并通过分析近似计算符号错误概率（SEP）。

Result: 分析结果与蒙特卡洛模拟的SEP匹配，且发现缩小传输脉冲成形滤波器的3 dB带宽会降低接收机性能。

Conclusion: 该接收机直接利用时间编码检测符号，但需要在频谱效率和错误恢复之间权衡。

Abstract: Event-driven sampling is a promising alternative to uniform sampling methods,
particularly for systems constrained by power and hardware cost. A notable
example of this sampling approach is the integrate-and-fire time encoding
machine (IF-TEM), which encodes an analog signal into a sequence of time stamps
by generating an event each time the integral of the input signal reaches a
fixed threshold. In this paper, we propose a receiver architecture that
estimates the sequence of transmitted symbols directly from the encoded time
stamps, called time encodings, produced by the IF-TEM sampler on the received
signal. We show that waveform reconstruction from time encodings is not
necessary for symbol detection. We develop an analytical approximation for the
symbol error probability (SEP) of the proposed IF-TEM-based receiver and show
that it closely matches the SEP results obtained through Monte Carlo
simulations. Additionally, we demonstrate that narrowing the 3 dB bandwidth of
the transmit pulse shaping filter degrades the proposed IF-TEM receiver's
performance, highlighting a trade-off between spectral efficiency and error
resilience.

</details>


### [12] [Blind Channel Estimation for RIS-Assisted Millimeter Wave Communication Systems](https://arxiv.org/abs/2508.17710)
*Dianhao Jia,Wenqian Shen,Jianping An,Byonghyo Shim*

Main category: eess.SP

TL;DR: 提出了一种基于压缩感知的盲信道估计方法，用于RIS辅助的多用户毫米波通信系统，无需发送导频序列即可实现精确信道估计和信号恢复。


<details>
  <summary>Details</summary>
Motivation: RIS辅助通信系统中，信道估计对性能优化至关重要。传统盲估计方法在RIS两跳信道中面临新挑战，需减少导频开销。

Method: 采用分块传输方案，通过重新配置RIS元件优化级联信道估计；每个块内将用户数据映射为码字，同时实现信号恢复和等效信道估计。

Result: 仿真结果显示，该方法能显著提升信道估计和信号恢复的精度。

Conclusion: 该方法为RIS辅助通信系统提供了一种高效的盲信道估计方案。

Abstract: In the research of RIS-assisted communication systems, channel estimation is
a problem of vital importance for further performance optimization. In order to
reduce the pilot overhead to the greatest extent, blind channel estimation
methods are required, which can estimate the channel and the transmit signals
at the same time without transmitting pilot sequence. Different from existing
researches in traditional MIMO systems, the RIS-assisted two-hop channel brings
new challenges to the blind channel estimation design. Hence, a novel blind
channel estimation method based on compressed sensing for RIS-assisted
multiuser millimeter wave communication systems is proposed for the first time
in this paper. Specifically, for accurately estimating the RIS-assisted two-hop
channel without transmitting pilots, we propose a block-wise transmission
scheme. Among different blocks of data transmission, RIS elements are
reconfigured for better estimating the cascade channel. Inside each block, data
for each user are mapped to a codeword for realizing the transmit signal
recovery and equivalent channel estimation simultaneously. Simulation results
demonstrate that our method can achieve a considerable accuracy of channel
estimation and transmit signal recovery.

</details>


### [13] [EEG-FM-Bench: A Comprehensive Benchmark for the Systematic Evaluation of EEG Foundation Models](https://arxiv.org/abs/2508.17742)
*Wei Xiong,Jiangtong Li,Jie Li,Kun Zhu*

Main category: eess.SP

TL;DR: EEG-FM-Bench是首个用于系统化评估EEG基础模型的基准测试，旨在解决当前评估标准缺失的问题，促进模型比较和科研效率。


<details>
  <summary>Details</summary>
Motivation: 当前EEG基础模型快速发展，但缺乏标准化评估基准，导致模型比较困难，科研效率低下。

Method: 提出EEG-FM-Bench，包含一系列标准化下游任务和数据集，并对现有模型进行基准测试和表征分析。

Result: 发现细粒度时空特征交互、多任务统一训练和神经心理学先验可以提升模型性能和泛化能力。

Conclusion: EEG-FM-Bench为EEG基础模型提供了公平比较和可重复研究的平台，推动更鲁棒和通用模型的发展。

Abstract: Electroencephalography (EEG) foundation models are poised to significantly
advance brain signal analysis by learning robust representations from
large-scale, unlabeled datasets. However, their rapid proliferation has
outpaced the development of standardized evaluation benchmarks, which
complicates direct model comparisons and hinders systematic scientific
progress. This fragmentation fosters scientific inefficiency and obscures
genuine architectural advancements. To address this critical gap, we introduce
EEG-FM-Bench, the first comprehensive benchmark for the systematic and
standardized evaluation of EEG foundation models (EEG-FMs). Our contributions
are threefold: (1) we curate a diverse suite of downstream tasks and datasets
from canonical EEG paradigms, implementing standardized processing and
evaluation protocols within a unified open-source framework; (2) we benchmark
prominent state-of-the-art foundation models to establish comprehensive
baseline results for a clear comparison of the current landscape; (3) we
perform qualitative analyses of the learned representations to provide insights
into model behavior and inform future architectural design. Through extensive
experiments, we find that fine-grained spatio-temporal feature interaction,
multitask unified training and neuropsychological priors would contribute to
enhancing model performance and generalization capabilities. By offering a
unified platform for fair comparison and reproducible research, EEG-FM-Bench
seeks to catalyze progress and guide the community toward the development of
more robust and generalizable EEG-FMs. Code is released at
https://github.com/xw1216/EEG-FM-Bench.

</details>


### [14] [Cross-Domain Lifelong Reinforcement Learning for Wireless Sensor Networks](https://arxiv.org/abs/2508.17852)
*Hossein Mohammadi Firouzjaei,Rafaela Scaciota,Sumudu Samarakoon,Beatriz Lorenzo*

Main category: eess.SP

TL;DR: 该论文提出了一种跨域终身强化学习框架（CD-L2RL），用于解决能量采集无线传感器网络（WSN）在动态环境中的高效设计问题。


<details>
  <summary>Details</summary>
Motivation: 6G系统中的WSN需要持续运行和高效能源利用，但动态环境（如能量采集条件、网络规模和流量变化）给部署带来挑战。

Method: 提出CD-L2RL框架，利用先验知识加速跨任务和领域的适应，而非传统的马尔可夫决策或李雅普诺夫优化方法。

Result: 仿真显示，该方法比标准强化学习适应速度快35%，比李雅普诺夫优化快70%，且总采集能量更高。

Conclusion: CD-L2RL在动态6G WSN中具有显著应用潜力。

Abstract: Wireless sensor networks (WSNs) with energy harvesting (EH) are expected to
play a vital role in intelligent 6G systems, especially in industrial sensing
and control, where continuous operation and sustainable energy use are
critical. Given limited energy resources, WSNs must operate efficiently to
ensure long-term performance. Their deployment, however, is challenged by
dynamic environments where EH conditions, network scale, and traffic rates
change over time. In this work, we address system dynamics that yield different
learning tasks, where decision variables remain fixed but strategies vary, as
well as learning domains, where both decision space and strategies evolve. To
handle such scenarios, we propose a cross-domain lifelong reinforcement
learning (CD-L2RL) framework for energy-efficient WSN design. Our CD-L2RL
algorithm leverages prior experience to accelerate adaptation across tasks and
domains. Unlike conventional approaches based on Markov decision processes or
Lyapunov optimization, which assume relatively stable environments, our
solution achieves rapid policy adaptation by reusing knowledge from past tasks
and domains to ensure continuous operations. We validate the approach through
extensive simulations under diverse conditions. Results show that our method
improves adaptation speed by up to 35% over standard reinforcement learning and
up to 70% over Lyapunov-based optimization, while also increasing total
harvested energy. These findings highlight the strong potential of CD-L2RL for
deployment in dynamic 6G WSNs.

</details>


### [15] [Compressed Learning for Nanosurface Deficiency Recognition Using Angle-resolved Scatterometry Data](https://arxiv.org/abs/2508.17873)
*Mehdi Abdollahpour,Carsten Bockelmann,Tajim Md Hasibur Rahman,Armin Dekorsy,Andreas Fischer*

Main category: eess.SP

TL;DR: 提出了一种基于粒子群优化的压缩学习框架，用于角分辨散射仪的快速纳米表面缺陷检测，显著减少了数据采集时间并保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 纳米制造需要高精度的表面检测，传统方法如电子显微镜耗时且不适合在线检测，角分辨散射仪虽适合在线使用但数据采集速度较慢。

Method: 使用粒子群优化算法结合针对散射模式的自定义采样方案，选择最优采样点以最大化缺陷检测准确率。

Result: 仅采样1%数据时准确率达86%，采样6%时提升至94%，同时有效识别关键采样区域。

Conclusion: 该方法在数据减少和分类性能之间取得了良好平衡，适用于噪声环境下的高效纳米表面缺陷检测。

Abstract: Nanoscale manufacturing requires high-precision surface inspection to
guarantee the quality of the produced nanostructures. For production
environments, angle-resolved scatterometry offers a non- invasive and in-line
compatible alternative to traditional surface inspection methods, such as
scanning electron microscopy. However, angle-resolved scatterometry currently
suffers from long data acquisition time. Our study addresses the issue of slow
data acquisition by proposing a compressed learning framework for the accurate
recognition of nanosurface deficiencies using angle-resolved scatterometry
data. The framework uses the particle swarm optimization algorithm with a
sampling scheme customized for scattering patterns. This combination allows the
identification of optimal sampling points in scatterometry data that maximize
the detection accuracy of five different levels of deficiency in ZnO
nanosurfaces. The proposed method significantly reduces the amount of sampled
data while maintaining a high accuracy in deficiency detection, even in noisy
environments. Notably, by sampling only 1% of the data, the method achieves an
accuracy of over 86%, which further improves to 94% when the sampling rate is
increased to 6%. These results demonstrate a favorable balance between data
reduction and classification performance. The obtained results also show that
the compressed learning framework effectively identifies critical sampling
areas.

</details>


### [16] [Synchrosqueezed X-Ray Wavelet-Chirplet Transform for Accurate Chirp Rate Estimation and Retrieval of Modes from Multicomponent Signals with Crossover Instantaneous Frequencies](https://arxiv.org/abs/2508.17942)
*Qingtang Jiang,Shuixin Li,Jiecheng Chen,Lin Li*

Main category: eess.SP

TL;DR: 本文提出了一种基于X射线变换的XWCT方法，显著提高了沿chirprate方向的衰减速度，并通过三阶同步压缩技术实现了高精度的瞬时频率和chirprate估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法在chirprate估计上的精度不足，主要由于沿chirprate方向的衰减较慢。

Method: 引入X射线变换的XWCT，并开发其三阶同步压缩变体。

Result: XWCT沿chirprate方向的衰减显著加快，三阶同步压缩XWCT无需多次操作即可高精度估计。

Conclusion: XWCT及其三阶同步压缩变体在信号处理中表现出优越性能。

Abstract: Recent advances in the chirplet transform and wavelet-chirplet transform
(WCT) have enabled the estimation of instantaneous frequencies (IFs) and
chirprates, as well as mode retrieval from multicomponent signals with
crossover IF curves. However, chirprate estimation via these approaches remains
less accurate than IF estimation, primarily due to the slow decay of the
chirplet transform or WCT along the chirprate direction. To address this, the
synchrosqueezed chirplet transform (SCT) and multiple SCT methods were
proposed, achieving moderate improvements in IF and chirprate estimation
accuracy. Nevertheless, a novel approach is still needed to enhance the
transform's decay along the chirprate direction.
  This paper introduces an X-ray transform-based wavelet-chirprate transform,
termed the X-ray wavelet-chirplet transform (XWCT), which exhibits superior
decay along the chirprate direction compared to the WCT. Furthermore,
third-order synchrosqueezed variants of the WCT and XWCT are developed to yield
sharp time-frequency-chirprate representations of signals. Experimental results
demonstrate that the XWCT achieves significantly faster decay along the
chirprate axis, while the third-order synchrosqueezed XWCT enables accurate IF
and chirprate estimation, as well as mode retrieval, without requiring multiple
synchrosqueezing operations.

</details>


### [17] [A Unified Transformer Architecture for Low-Latency and Scalable Wireless Signal Processing](https://arxiv.org/abs/2508.17960)
*Yuto Kawai,Rajeev Koodli*

Main category: eess.SP

TL;DR: 提出了一种基于Transformer的无线信号处理统一架构，替代传统模块化设计，实现低延迟、任务自适应的实时部署。


<details>
  <summary>Details</summary>
Motivation: 传统无线信号处理采用模块化设计，延迟高且灵活性不足，本文旨在通过数据驱动的Transformer架构提升效率和适应性。

Method: 设计了一个集成信道估计、插值和解调的统一注意力驱动架构，支持动态输出格式调整，通过实验验证其性能。

Result: 在端到端接收、信道频率插值和信道估计三个核心用例中，均超越了传统方法，表现出更高的准确性、鲁棒性和计算效率。

Conclusion: 该架构为下一代无线通信系统的智能信号处理提供了一个可部署的解决方案，奠定了软件定义信号处理的基础。

Abstract: We propose a unified Transformer-based architecture for wireless signal
processing tasks, offering a low-latency, task-adaptive alternative to
conventional receiver pipelines. Unlike traditional modular designs, our model
integrates channel estimation, interpolation, and demapping into a single,
compact attention-driven architecture designed for real-time deployment. The
model's structure allows dynamic adaptation to diverse output formats by simply
modifying the final projection layer, enabling consistent reuse across receiver
subsystems. Experimental results demonstrate strong generalization to varying
user counts, modulation schemes, and pilot configurations, while satisfying
latency constraints imposed by practical systems. The architecture is evaluated
across three core use cases: (1) an End-to-End Receiver, which replaces the
entire baseband processing pipeline from pilot symbols to bit-level decisions;
(2) Channel Frequency Interpolation, implemented and tested within a
3GPP-compliant OAI+Aerial system; and (3) Channel Estimation, where the model
infers full-band channel responses from sparse pilot observations. In all
cases, our approach outperforms classical baselines in terms of accuracy,
robustness, and computational efficiency. This work presents a deployable,
data-driven alternative to hand-engineered PHY-layer blocks, and lays the
foundation for intelligent, software-defined signal processing in
next-generation wireless communication systems.

</details>


### [18] [Positioning via Probabilistic Graphical Models in RIS-Aided Systems with Channel Estimation Errors](https://arxiv.org/abs/2508.18009)
*Leonardo Tercas,Markku Juntti*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯的6D定位框架，用于估计室内RIS辅助系统中移动站的位置和旋转角度，显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决在室内RIS辅助系统中，移动站位置和旋转角度的精确估计问题，尤其是在存在信道参数估计误差的情况下。

Method: 使用概率图模型表示随机变量的联合概率分布，并采用NUTS采样器近似后验分布，同时推导了CRLB来评估系统性能。

Result: 结果表明，RIS可以显著提高定位精度，系统在有RIS和无RIS情况下的性能对比证明了这一点。

Conclusion: 提出的6D定位框架在RIS辅助下能够有效提升移动站的定位和旋转角度估计精度。

Abstract: We propose a 6D Bayesian-based localization framework to estimate the
position and rotation angles of a mobile station (MS) within an indoor
reconfigurable intelligent surface (RIS)-aided system. This framework relies on
a probabilistic graphical model to represent the joint probability distribution
of random variables through their conditional dependencies and employs the
No-U-Turn Sampler (NUTS) to approximate the posterior distribution based on the
estimated channel parameters. Our framework estimates both the position and
rotation of the mobile station (MS), in the presence of channel parameter
estimation errors. We derive the Cramer-Rao lower bound (CRLB) for the proposed
scenario and use it to evaluate the system's position error bound (PEB) and
rotation error bound (REB). We compare the system performances with and without
RIS. The results demonstrate that the RIS can enhance positioning accuracy
significantly.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [COSMO-Bench: A Benchmark for Collaborative SLAM Optimization](https://arxiv.org/abs/2508.16731)
*Daniel McGann,Easton R. Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: 该论文介绍了针对多机器人协作SLAM（C-SLAM）的分布式优化算法研究中缺乏标准基准数据集的问题，并提出了一个名为COSMO-Bench的开放基准数据集。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人C-SLAM研究中缺乏标准基准数据集的问题，以促进该领域的研究发展。

Method: 设计和发布COSMO-Bench，包含24个数据集，基于先进的C-SLAM前端算法和真实LiDAR数据。

Result: COSMO-Bench为多机器人C-SLAM研究提供了一个公开可用的基准数据集。

Conclusion: COSMO-Bench填补了多机器人C-SLAM研究中的数据集空白，有望推动该领域的进步。

Abstract: Recent years have seen a focus on research into distributed optimization
algorithms for multi-robot Collaborative Simultaneous Localization and Mapping
(C-SLAM). Research in this domain, however, is made difficult by a lack of
standard benchmark datasets. Such datasets have been used to great effect in
the field of single-robot SLAM, and researchers focused on multi-robot problems
would benefit greatly from dedicated benchmark datasets. To address this gap,
we design and release the Collaborative Open-Source Multi-robot Optimization
Benchmark (COSMO-Bench) -- a suite of 24 datasets derived from a
state-of-the-art C-SLAM front-end and real-world LiDAR data. Data DOI:
https://doi.org/10.1184/R1/29652158

</details>


### [20] [A Dataset and Benchmark for Robotic Cloth Unfolding Grasp Selection: The ICRA 2024 Cloth Competition](https://arxiv.org/abs/2508.16749)
*Victor-Louis De Gusseme,Thomas Lips,Remko Proesmans,Julius Hietala,Giwan Lee,Jiyoung Choi,Jeongil Choi,Geon Kim,Phayuth Yonrith,Domen Tabernik,Andrej Gams,Peter Nimac,Matej Urbas,Jon Muhovič,Danijel Skočaj,Matija Mavsar,Hyojeong Yu,Minseo Kwon,Young J. Kim,Yang Cong,Ronghan Chen,Yu Ren,Supeng Diao,Jiawei Weng,Jiayue Liu,Haoran Sun,Linhan Yang,Zeqing Zhang,Ning Guo,Lei Yang,Fang Wan,Chaoyang Song,Jia Pan,Yixiang Jin,Yong A,Jun Shi,Dingzhe Li,Yong Yang,Kakeru Yamasaki,Takumi Kajiwara,Yuki Nakadera,Krati Saxena,Tomohiro Shibata,Chongkun Xia,Kai Mo,Yanzhao Yu,Qihao Lin,Binqiang Ma,Uihun Sagong,JungHyun Choi,JeongHyun Park,Dongwoo Lee,Yeongmin Kim,Myun Joong Hwang,Yusuke Kuribayashi,Naoki Hiratsuka,Daisuke Tanaka,Solvi Arnold,Kimitoshi Yamazaki,Carlos Mateo-Agullo,Andreas Verleysen,Francis Wyffels*

Main category: cs.RO

TL;DR: 该论文提出了一个关于机器人布料操作的标准化基准和数据集，并组织了ICRA 2024布料竞赛，评估了不同团队的表现和方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人布料操作领域缺乏标准化的基准和共享数据集，导致难以评估和比较不同方法。

Method: 创建了一个基准数据集，组织了竞赛，邀请了11个团队参与，使用真实机器人布料展开任务的数据集设计方法。

Result: 分析了竞赛结果，揭示了抓取成功率和覆盖范围的权衡，手工设计方法的出色表现，以及与实验室结果的显著差异。

Conclusion: 该数据集和竞赛结果为未来基准提供了基础，对数据驱动的机器人布料操作研究有重要价值。数据及代码已公开。

Abstract: Robotic cloth manipulation suffers from a lack of standardized benchmarks and
shared datasets for evaluating and comparing different approaches. To address
this, we created a benchmark and organized the ICRA 2024 Cloth Competition, a
unique head-to-head evaluation focused on grasp pose selection for in-air
robotic cloth unfolding. Eleven diverse teams participated in the competition,
utilizing our publicly released dataset of real-world robotic cloth unfolding
attempts and a variety of methods to design their unfolding approaches.
Afterwards, we also expanded our dataset with 176 competition evaluation
trials, resulting in a dataset of 679 unfolding demonstrations across 34
garments. Analysis of the competition results revealed insights about the
trade-off between grasp success and coverage, the surprisingly strong
achievements of hand-engineered methods and a significant discrepancy between
competition performance and prior work, underscoring the importance of
independent, out-of-the-lab evaluation in robotic cloth manipulation. The
associated dataset is a valuable resource for developing and evaluating grasp
selection methods, particularly for learning-based approaches. We hope that our
benchmark, dataset and competition results can serve as a foundation for future
benchmarks and drive further progress in data-driven robotic cloth
manipulation. The dataset and benchmarking code are available at
https://airo.ugent.be/cloth_competition.

</details>


### [21] [Autonomous UAV Flight Navigation in Confined Spaces: A Reinforcement Learning Approach](https://arxiv.org/abs/2508.16807)
*Marco S. Tayar,Lucas K. de Oliveira,Juliano D. Negri,Thiago H. Segreto,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 论文比较了两种DRL算法（PPO和SAC）在GPS-denied环境中无人机导航的表现，发现PPO表现更稳定。


<details>
  <summary>Details</summary>
Motivation: 人类检查工业基础设施（如通风井）效率低且危险，无人机是一种替代方案，但缺乏GPS时需要稳健的控制策略。

Method: 使用Genesis模拟环境生成管道环境，设计奖励函数引导无人机通过路径点并避免碰撞，比较PPO和SAC的表现。

Result: PPO学会的稳定策略能完成所有评估且无碰撞，而SAC表现较差。

Conclusion: 在危险环境中，PPO的稳定性优于SAC的样本效率；高保真模拟是开发导航策略的有效测试平台。

Abstract: Inspecting confined industrial infrastructure, such as ventilation shafts, is
a hazardous and inefficient task for humans. Unmanned Aerial Vehicles (UAVs)
offer a promising alternative, but GPS-denied environments require robust
control policies to prevent collisions. Deep Reinforcement Learning (DRL) has
emerged as a powerful framework for developing such policies, and this paper
provides a comparative study of two leading DRL algorithms for this task: the
on-policy Proximal Policy Optimization (PPO) and the off-policy Soft
Actor-Critic (SAC). The training was conducted with procedurally generated duct
environments in Genesis simulation environment. A reward function was designed
to guide a drone through a series of waypoints while applying a significant
penalty for collisions. PPO learned a stable policy that completed all
evaluation episodes without collision, producing smooth trajectories. By
contrast, SAC consistently converged to a suboptimal behavior that traversed
only the initial segments before failure. These results suggest that, in
hazard-dense navigation, the training stability of on-policy methods can
outweigh the nominal sample efficiency of off-policy algorithms. More broadly,
the study provides evidence that procedurally generated, high-fidelity
simulations are effective testbeds for developing and benchmarking robust
navigation policies.

</details>


### [22] [A Workflow for Map Creation in Autonomous Vehicle Simulations](https://arxiv.org/abs/2508.16856)
*Zubair Islam,Ahmaad Ansari,George Daoud,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 论文提出了一种简化自动驾驶车辆开发中地图生成的定制工作流程，并通过生成安大略理工大学的3D停车场地图进行了验证。未来工作将关注SLAM技术的集成和优化。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆研究中，精确且可适应的地图是开发的关键，但现有方法资源密集且灵活性不足。

Method: 提出了一种定制的工作流程，用于简化和优化仿真就绪地图的生成。

Result: 成功生成了安大略理工大学停车场的3D地图，验证了工作流程的有效性。

Conclusion: 该工作流程为自动驾驶开发提供了更高效的地图生成方法，未来将进一步优化以增强兼容性和准确性。

Abstract: The fast development of technology and artificial intelligence has
significantly advanced Autonomous Vehicle (AV) research, emphasizing the need
for extensive simulation testing. Accurate and adaptable maps are critical in
AV development, serving as the foundation for localization, path planning, and
scenario testing. However, creating simulation-ready maps is often difficult
and resource-intensive, especially with simulators like CARLA (CAR Learning to
Act). Many existing workflows require significant computational resources or
rely on specific simulators, limiting flexibility for developers. This paper
presents a custom workflow to streamline map creation for AV development,
demonstrated through the generation of a 3D map of a parking lot at Ontario
Tech University. Future work will focus on incorporating SLAM technologies,
optimizing the workflow for broader simulator compatibility, and exploring more
flexible handling of latitude and longitude values to enhance map generation
accuracy.

</details>


### [23] [Relative Navigation and Dynamic Target Tracking for Autonomous Underwater Proximity Operations](https://arxiv.org/abs/2508.16901)
*David Baxter,Aldo Terán Espinoza,Antonio Terán Espinoza,Amy Loutfi,John Folkesson,Peter Sigray,Stephanie Lowry,Jakob Kuttenkeuler*

Main category: cs.RO

TL;DR: 提出了一个基于李群切线空间的广义恒定扭曲运动先验，用于水下接近操作中的6自由度目标运动估计，解决了稀疏、噪声和部分观测的问题。


<details>
  <summary>Details</summary>
Motivation: 在水下接近操作中，由于缺乏目标端的本体感知，且观测数据稀疏、噪声大且部分缺失（如USBL位置），6自由度目标运动估计变得困难。

Method: 提出了一种广义恒定扭曲运动先验，基于李群切线空间，确保时间一致的轨迹；设计了三元因子及其闭式雅可比，适用于任意李群轨迹。

Result: 在真实动态停靠场景数据集上的验证表明，该方法能通过USBL和光学相对测量段实现一致的目标轨迹估计，提高了相对跟踪精度。

Conclusion: 该方法基于标准李群操作，具有可移植性，适用于多种状态流形和感知模态。

Abstract: Estimating a target's 6-DoF motion in underwater proximity operations is
difficult because the chaser lacks target-side proprioception and the available
relative observations are sparse, noisy, and often partial (e.g., Ultra-Short
Baseline (USBL) positions). Without a motion prior, factor-graph maximum a
posteriori estimation is underconstrained: consecutive target states are weakly
linked and orientation can drift. We propose a generalized constant-twist
motion prior defined on the tangent space of Lie groups that enforces
temporally consistent trajectories across all degrees of freedom; in SE(3) it
couples translation and rotation in the body frame. We present a ternary factor
and derive its closed-form Jacobians based on standard Lie group operations,
enabling drop-in use for trajectories on arbitrary Lie groups. We evaluate two
deployment modes: (A) an SE(3)-only representation that regularizes orientation
even when only position is measured, and (B) a mode with boundary factors that
switches the target representation between SE(3) and 3D position while applying
the same generalized constant-twist prior across representation changes.
Validation on a real-world dynamic docking scenario dataset shows consistent
ego-target trajectory estimation through USBL-only and optical relative
measurement segments with an improved relative tracking accuracy compared to
the noisy measurements to the target. Because the construction relies on
standard Lie group primitives, it is portable across state manifolds and
sensing modalities.

</details>


### [24] [HumanoidVerse: A Versatile Humanoid for Vision-Language Guided Multi-Object Rearrangement](https://arxiv.org/abs/2508.16943)
*Haozhuo Zhang,Jingkai Sun,Michele Caprio,Jian Tang,Shanghang Zhang,Qiang Zhang,Wei Pan*

Main category: cs.RO

TL;DR: HumanoidVerse是一个新型框架，通过视觉-语言引导实现人形机器人控制，支持多物体长时间重排任务。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在固定场景和单物体交互中的局限性，实现更复杂的多物体连续操作任务。

Method: 采用多阶段课程学习和双教师蒸馏管道训练，结合自然语言指令和RGB视觉输入。

Result: 在Isaac Gym模拟器中显著优于现有技术，任务成功率和空间精度均有提升，且泛化能力强。

Conclusion: 该框架为实现复杂、顺序任务执行的真实世界机器人代理迈出关键一步。

Abstract: We introduce HumanoidVerse, a novel framework for vision-language guided
humanoid control that enables a single physically simulated robot to perform
long-horizon, multi-object rearrangement tasks across diverse scenes. Unlike
prior methods that operate in fixed settings with single-object interactions,
our approach supports consecutive manipulation of multiple objects, guided only
by natural language instructions and egocentric camera RGB observations.
HumanoidVerse is trained via a multi-stage curriculum using a dual-teacher
distillation pipeline, enabling fluid transitions between sub-tasks without
requiring environment resets. To support this, we construct a large-scale
dataset comprising 350 multi-object tasks spanning four room layouts. Extensive
experiments in the Isaac Gym simulator demonstrate that our method
significantly outperforms prior state-of-the-art in both task success rate and
spatial precision, and generalizes well to unseen environments and
instructions. Our work represents a key step toward robust, general-purpose
humanoid agents capable of executing complex, sequential tasks under real-world
sensory constraints. The video visualization results can be found on the
project page: https://haozhuo-zhang.github.io/HumanoidVerse-project-page/.

</details>


### [25] [Drive As You Like: Strategy-Level Motion Planning Based on A Multi-Head Diffusion Model](https://arxiv.org/abs/2508.16947)
*Fan Ding,Xuewen Luo,Hwa Hui Tew,Ruturaj Reddy,Xikun Wang,Junn Yong Loo*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的多头轨迹规划器（M-diffusion planner），通过GRPO微调预训练模型，实现多样性策略行为，并结合LLM动态选择策略，在nuPlan基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶轨迹规划器在监督训练后策略固定，行为僵化，难以反映人类偏好或适应动态需求。

Method: 采用扩散模型多头轨迹规划器，前阶段共享权重学习高质量轨迹，后阶段通过GRPO微调实现多样性策略，并引入LLM动态选择策略。

Result: 在nuPlan val14基准测试中达到SOTA性能，生成的轨迹具有明显多样性，满足多模态驾驶需求。

Conclusion: M-diffusion planner在保持强规划能力的同时，实现了动态、指令感知的规划，满足多样驾驶行为需求。

Abstract: Recent advances in motion planning for autonomous driving have led to models
capable of generating high-quality trajectories. However, most existing
planners tend to fix their policy after supervised training, leading to
consistent but rigid driving behaviors. This limits their ability to reflect
human preferences or adapt to dynamic, instruction-driven demands. In this
work, we propose a diffusion-based multi-head trajectory planner(M-diffusion
planner). During the early training stage, all output heads share weights to
learn to generate high-quality trajectories. Leveraging the probabilistic
nature of diffusion models, we then apply Group Relative Policy Optimization
(GRPO) to fine-tune the pre-trained model for diverse policy-specific
behaviors. At inference time, we incorporate a large language model (LLM) to
guide strategy selection, enabling dynamic, instruction-aware planning without
switching models. Closed-loop simulation demonstrates that our post-trained
planner retains strong planning capability while achieving state-of-the-art
(SOTA) performance on the nuPlan val14 benchmark. Open-loop results further
show that the generated trajectories exhibit clear diversity, effectively
satisfying multi-modal driving behavior requirements. The code and related
experiments will be released upon acceptance of the paper.

</details>


### [26] [LLM-based Human-like Traffic Simulation for Self-driving Tests](https://arxiv.org/abs/2508.16962)
*Wendi Li,Hao Wu,Han Gao,Bing Mao,Fengyuan Xu,Sheng Zhong*

Main category: cs.RO

TL;DR: HDSim框架结合认知理论与大语言模型，生成更具多样性和真实性的交通场景，提升自动驾驶系统测试的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有人工驾驶行为模拟方法多样性和真实性不足，需改进以更准确评估自动驾驶系统的可靠性。

Method: 提出HDSim框架，采用分层驾驶员模型和大语言模型间接引导行为，生成多样化且真实的交通场景。

Result: 实验表明，HDSim显著提高安全关键故障检测率（达68%），并提供一致的真实事故解释性。

Conclusion: HDSim通过认知理论和LLM结合，为自动驾驶测试提供更真实和可解释的交通场景生成方法。

Abstract: Ensuring realistic traffic dynamics is a prerequisite for simulation
platforms to evaluate the reliability of self-driving systems before deployment
in the real world. Because most road users are human drivers, reproducing their
diverse behaviors within simulators is vital. Existing solutions, however,
typically rely on either handcrafted heuristics or narrow data-driven models,
which capture only fragments of real driving behaviors and offer limited
driving style diversity and interpretability. To address this gap, we introduce
HDSim, an HD traffic generation framework that combines cognitive theory with
large language model (LLM) assistance to produce scalable and realistic traffic
scenarios within simulation platforms. The framework advances the state of the
art in two ways: (i) it introduces a hierarchical driver model that represents
diverse driving style traits, and (ii) it develops a Perception-Mediated
Behavior Influence strategy, where LLMs guide perception to indirectly shape
driver actions. Experiments reveal that embedding HDSim into simulation
improves detection of safety-critical failures in self-driving systems by up to
68% and yields realism-consistent accident interpretability.

</details>


### [27] [DualReg: Dual-Space Filtering and Reinforcement for Rigid Registration](https://arxiv.org/abs/2508.17034)
*Jiayi Li,Yuxin Yao,Qiuhang Lu,Juyong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种新的双空间方法，结合特征匹配和几何匹配的优点，通过高效筛选机制和优化目标函数，实现了高效且精确的刚性配准。


<details>
  <summary>Details</summary>
Motivation: 刚性配准在SLAM和3D重建中至关重要，但面对噪声、部分重叠数据和实时处理需求时，现有方法的局限性（如特征匹配精度低、几何匹配依赖初始变换）亟需解决。

Method: 提出双空间范式，先通过单点RANSAC和细化模块过滤不可靠特征匹配，再基于几何代理和定制求解器优化变换估计。

Result: 实验表明，在KITTI数据集上实现了最高32倍的CPU时间加速，同时保持可比的精度。

Conclusion: 双空间方法有效结合了特征和几何匹配的优势，显著提升了刚性配准的效率和精度。

Abstract: Rigid registration, aiming to estimate a rigid transformation to align source
and target data, play a crucial role in applications such as SLAM and 3D
reconstruction. However, noisy, partially overlapping data and the need for
real-time processing pose major challenges for rigid registration. Considering
that feature-based matching can handle large transformation differences but
suffers from limited accuracy, while local geometry-based matching can achieve
fine-grained local alignment but relies heavily on a good initial
transformation, we propose a novel dual-space paradigm to fully leverage the
strengths of both approaches. First, we introduce an efficient filtering
mechanism that incorporates a computationally lightweight single-point RANSAC
algorithm followed by a refinement module to eliminate unreliable feature-based
correspondences. Subsequently, we treat filtered correspondences as anchor
points, extract geometric proxies, and formulates an effective objective
function with a tailored solver to estimate the transformation. Experiments
verify our method's effectiveness, as shown by achieving up to a 32x CPU-time
speedup over MAC on KITTI with comparable accuracy.

</details>


### [28] [A Rapid Iterative Trajectory Planning Method for Automated Parking through Differential Flatness](https://arxiv.org/abs/2508.17038)
*Zhouheng Li,Lei Xie,Cheng Hu,Hongye Su*

Main category: cs.RO

TL;DR: 提出了一种基于PVD的快速迭代轨迹规划方法（RITP），解决了自动驾驶停车中的轨迹规划问题，平衡了时间效率与精确碰撞避免，并通过终端平滑约束提升了轨迹控制可行性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶停车需求增加，但现有PVD轨迹规划方法在快速、精确的碰撞避免和轨迹控制可行性方面存在挑战。

Method: 采用RITP方法，结合车辆运动学模型和终端平滑约束，通过差分平坦性和TSC提升轨迹规划效率和控制可行性。

Result: 仿真和实车实验显示，RITP在时间效率和跟踪误差上优于其他方法，验证了其实际应用价值。

Conclusion: RITP方法有效解决了PVD轨迹规划中的关键问题，为自动驾驶停车提供了可靠解决方案。

Abstract: As autonomous driving continues to advance, automated parking is becoming
increasingly essential. However, significant challenges arise when implementing
path velocity decomposition (PVD) trajectory planning for automated parking.
The primary challenge is ensuring rapid and precise collision-free trajectory
planning, which is often in conflict. The secondary challenge involves
maintaining sufficient control feasibility of the planned trajectory,
particularly at gear shifting points (GSP). This paper proposes a PVD-based
rapid iterative trajectory planning (RITP) method to solve the above
challenges. The proposed method effectively balances the necessity for time
efficiency and precise collision avoidance through a novel collision avoidance
framework. Moreover, it enhances the overall control feasibility of the planned
trajectory by incorporating the vehicle kinematics model and including terminal
smoothing constraints (TSC) at GSP during path planning. Specifically, the
proposed method leverages differential flatness to ensure the planned path
adheres to the vehicle kinematic model. Additionally, it utilizes TSC to
maintain curvature continuity at GSP, thereby enhancing the control feasibility
of the overall trajectory. The simulation results demonstrate superior time
efficiency and tracking errors compared to model-integrated and other
iteration-based trajectory planning methods. In the real-world experiment, the
proposed method was implemented and validated on a ROS-based vehicle,
demonstrating the applicability of the RITP method for real vehicles.

</details>


### [29] [LaGarNet: Goal-Conditioned Recurrent State-Space Models for Pick-and-Place Garment Flattening](https://arxiv.org/abs/2508.17070)
*Halid Abdulrahim Kadi,Kasim Terzić*

Main category: cs.RO

TL;DR: GC-RSSM模型LaGarNet用于学习衣物抓放操作的潜在动态，性能媲美现有基于网格的方法，并通过覆盖对齐奖励和混合策略数据训练，减少了归纳偏差。


<details>
  <summary>Details</summary>
Motivation: 解决衣物抓放操作的复杂动态建模问题，减少传统方法中的归纳偏差。

Method: 使用GC-RSSM模型LaGarNet，结合覆盖对齐奖励和混合策略（随机策略与扩散策略）数据训练。

Result: LaGarNet在仿真和现实环境中对四种衣物实现平整操作，性能与现有方法相当。

Conclusion: LaGarNet首次成功将状态空间模型应用于复杂衣物操作，为减少归纳偏差提供了新思路。

Abstract: We present a novel goal-conditioned recurrent state space (GC-RSSM) model
capable of learning latent dynamics of pick-and-place garment manipulation. Our
proposed method LaGarNet matches the state-of-the-art performance of mesh-based
methods, marking the first successful application of state-space models on
complex garments. LaGarNet trains on a coverage-alignment reward and a dataset
collected through a general procedure supported by a random policy and a
diffusion policy learned from few human demonstrations; it substantially
reduces the inductive biases introduced in the previous similar methods. We
demonstrate that a single-policy LaGarNet achieves flattening on four different
types of garments in both real-world and simulation settings.

</details>


### [30] [OVITA: Open-Vocabulary Interpretable Trajectory Adaptations](https://arxiv.org/abs/2508.17260)
*Anurag Maurya,Tashmoy Ghosh,Anh Nguyen,Ravi Prakash*

Main category: cs.RO

TL;DR: OVITA是一种基于自然语言的框架，用于动态调整机器人轨迹，整合预训练大语言模型（LLMs）生成代码策略，支持非专家用户直观交互。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，适应动态情境和用户偏好的轨迹调整对机器人操作至关重要，自然语言交互为这一目标提供了便利。

Method: OVITA结合多种预训练LLMs，将用户指令融入轨迹生成或演示学习，并通过代码策略调整路径点，另一LLM作为代码解释器简化交互。

Result: 通过多种机器人平台（如KUKA IIWA、Clearpath Jackal、CrazyFlie）的仿真和实际环境测试，验证了OVITA的有效性和实用性。

Conclusion: OVITA框架通过语言驱动的交互方式，为非专家用户提供了灵活且直观的机器人轨迹调整方案。

Abstract: Adapting trajectories to dynamic situations and user preferences is crucial
for robot operation in unstructured environments with non-expert users. Natural
language enables users to express these adjustments in an interactive manner.
We introduce OVITA, an interpretable, open-vocabulary, language-driven
framework designed for adapting robot trajectories in dynamic and novel
situations based on human instructions. OVITA leverages multiple pre-trained
Large Language Models (LLMs) to integrate user commands into trajectories
generated by motion planners or those learned through demonstrations. OVITA
employs code as an adaptation policy generated by an LLM, enabling users to
adjust individual waypoints, thus providing flexible control. Another LLM,
which acts as a code explainer, removes the need for expert users, enabling
intuitive interactions. The efficacy and significance of the proposed OVITA
framework is demonstrated through extensive simulations and real-world
environments with diverse tasks involving spatiotemporal variations on
heterogeneous robotic platforms such as a KUKA IIWA robot manipulator,
Clearpath Jackal ground robot, and CrazyFlie drone.

</details>


### [31] [Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges](https://arxiv.org/abs/2508.17449)
*Zezeng Li,Alexandre Chapin,Enda Xiang,Rui Yang,Bruno Machado,Na Lei,Emmanuel Dellandrea,Di Huang,Liming Chen*

Main category: cs.RO

TL;DR: 这篇论文调查了机器人操作（RM）中的模仿学习方法，总结了相关研究的技术实现、分类及发展历程，并提供了定性和定量评估。


<details>
  <summary>Details</summary>
Motivation: 通过模仿学习让机器人掌握复杂操作技能，促进自主机器人在现实环境中的应用。

Method: 分析影响力大的研究，提供结构化总结，包括技术实现、分类、输入格式等，并进行定量比较。

Result: 总结了模仿学习在RM领域的技术进展、现有方法的优缺点及挑战。

Conclusion: 该综述为研究者提供了资源，指出了模仿学习在RM领域的现状和未来挑战。

Abstract: Robotic Manipulation (RM) is central to the advancement of autonomous robots,
enabling them to interact with and manipulate objects in real-world
environments. This survey focuses on RM methodologies that leverage imitation
learning, a powerful technique that allows robots to learn complex manipulation
skills by mimicking human demonstrations. We identify and analyze the most
influential studies in this domain, selected based on community impact and
intrinsic quality. For each paper, we provide a structured summary, covering
the research purpose, technical implementation, hierarchical classification,
input formats, key priors, strengths and limitations, and citation metrics.
Additionally, we trace the chronological development of imitation learning
techniques within RM policy (RMP), offering a timeline of key technological
advancements. Where available, we report benchmark results and perform
quantitative evaluations to compare existing methods. By synthesizing these
insights, this review provides a comprehensive resource for researchers and
practitioners, highlighting both the state of the art and the challenges that
lie ahead in the field of robotic manipulation through imitation learning.

</details>


### [32] [Evolutionary Brain-Body Co-Optimization Consistently Fails to Select for Morphological Potential](https://arxiv.org/abs/2508.17464)
*Alican Mertan,Nick Cheney*

Main category: cs.RO

TL;DR: 该研究通过详尽映射形态-适应度景观，揭示了大脑-身体协同优化算法的局限性，发现算法难以稳定找到接近最优解，并提出算法低估新突变体适应度的现象。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决大脑-身体协同优化这一具有挑战性的问题，通过详尽映射形态-适应度景观来深入理解算法的工作原理。

Method: 方法是在包含1,305,840种不同形态的设计空间中，为每种可行形态训练控制器，并分析进化算法在形态空间中的表现。

Result: 结果显示，实验算法无法稳定找到接近最优解，且在形态-适应度景观中效率低下，常低估新突变体的适应度。

Conclusion: 结论是该工作为大脑-身体协同优化的挑战提供了具体证据，并为未来研究提供了有价值的见解。

Abstract: Brain-body co-optimization remains a challenging problem, despite increasing
interest from the community in recent years. To understand and overcome the
challenges, we propose exhaustively mapping a morphology-fitness landscape to
study it. To this end, we train controllers for each feasible morphology in a
design space of 1,305,840 distinct morphologies, constrained by a computational
budget. First, we show that this design space constitutes a good model for
studying the brain-body co-optimization problem, and our attempt to
exhaustively map it roughly captures the landscape. We then proceed to analyze
how evolutionary brain-body co-optimization algorithms work in this design
space. The complete knowledge of the morphology-fitness landscape facilitates a
better understanding of the results of evolutionary brain-body co-optimization
algorithms and how they unfold over evolutionary time in the morphology space.
This investigation shows that the experimented algorithms cannot consistently
find near-optimal solutions. The search, at times, gets stuck on morphologies
that are sometimes one mutation away from better morphologies, and the
algorithms cannot efficiently track the fitness gradient in the
morphology-fitness landscape. We provide evidence that experimented algorithms
regularly undervalue the fitness of individuals with newly mutated bodies and,
as a result, eliminate promising morphologies throughout evolution. Our work
provides the most concrete demonstration of the challenges of evolutionary
brain-body co-optimization. Our findings ground the trends in the literature
and provide valuable insights for future work.

</details>


### [33] [Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation](https://arxiv.org/abs/2508.17466)
*Dilermando Almeida,Guilherme Lazzarini,Juliano Negri,Thiago H. Segreto,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种深度学习框架，通过模拟数据训练增强四足机器人臂的抓取能力，实现高效的非结构化环境操作。


<details>
  <summary>Details</summary>
Motivation: 四足机器人结合臂部能完成复杂任务，但动态环境中的精确抓取仍面临校准和预编程配置的挑战。

Method: 采用模拟到现实的方法，在Genesis模拟环境中生成合成数据集，训练U-Net结构CNN处理多模态输入，生成抓取质量热图。

Result: 成功验证了完整的抓取框架，实现了自主导航、感知、预测最优抓取姿势并精确抓取的目标任务。

Conclusion: 模拟训练结合先进感知是解决机器人对象操作的可扩展且高效的方法。

Abstract: Quadruped robots have emerged as highly efficient and versatile platforms,
excelling in navigating complex and unstructured terrains where traditional
wheeled robots might fail. Equipping these robots with manipulator arms unlocks
the advanced capability of loco-manipulation to perform complex physical
interaction tasks in areas ranging from industrial automation to
search-and-rescue missions. However, achieving precise and adaptable grasping
in such dynamic scenarios remains a significant challenge, often hindered by
the need for extensive real-world calibration and pre-programmed grasp
configurations. This paper introduces a deep learning framework designed to
enhance the grasping capabilities of quadrupeds equipped with arms, focusing on
improved precision and adaptability. Our approach centers on a sim-to-real
methodology that minimizes reliance on physical data collection. We developed a
pipeline within the Genesis simulation environment to generate a synthetic
dataset of grasp attempts on common objects. By simulating thousands of
interactions from various perspectives, we created pixel-wise annotated
grasp-quality maps to serve as the ground truth for our model. This dataset was
used to train a custom CNN with a U-Net-like architecture that processes
multi-modal input from an onboard RGB and depth cameras, including RGB images,
depth maps, segmentation masks, and surface normal maps. The trained model
outputs a grasp-quality heatmap to identify the optimal grasp point. We
validated the complete framework on a four-legged robot. The system
successfully executed a full loco-manipulation task: autonomously navigating to
a target object, perceiving it with its sensors, predicting the optimal grasp
pose using our model, and performing a precise grasp. This work proves that
leveraging simulated training with advanced sensing offers a scalable and
effective solution for object handling.

</details>


### [34] [Morphological Cognition: Classifying MNIST Digits Through Morphological Computation Alone](https://arxiv.org/abs/2508.17469)
*Alican Mertan,Nick Cheney*

Main category: cs.RO

TL;DR: 论文探讨了通过模拟物理身体的简单固定部分行为如何产生可被外部观察者分类为认知的涌现行为，展示了无需神经网络即可实现图像分类的机器人。


<details>
  <summary>Details</summary>
Motivation: 旨在研究智能行为的多样化机制，特别是关注被忽视的智能行为中的体现（embodiment）作用。

Method: 通过模拟具有固定行为的体素组合成机器人，使其在面对MNIST数字图像时表现出不同方向的移动行为。

Result: 首次展示了无需神经电路即能完成图像分类等高级认知功能的机器人，称之为‘形态认知’。

Conclusion: 该研究为智能行为的不同模型提供了概念验证，希望能促进更多相关研究。

Abstract: With the rise of modern deep learning, neural networks have become an
essential part of virtually every artificial intelligence system, making it
difficult even to imagine different models for intelligent behavior. In
contrast, nature provides us with many different mechanisms for intelligent
behavior, most of which we have yet to replicate. One of such underinvestigated
aspects of intelligence is embodiment and the role it plays in intelligent
behavior. In this work, we focus on how the simple and fixed behavior of
constituent parts of a simulated physical body can result in an emergent
behavior that can be classified as cognitive by an outside observer.
Specifically, we show how simulated voxels with fixed behaviors can be combined
to create a robot such that, when presented with an image of an MNIST digit
zero, it moves towards the left; and when it is presented with an image of an
MNIST digit one, it moves towards the right. Such robots possess what we refer
to as ``morphological cognition'' -- the ability to perform cognitive behavior
as a result of morphological processes. To the best of our knowledge, this is
the first demonstration of a high-level mental faculty such as image
classification performed by a robot without any neural circuitry. We hope that
this work serves as a proof-of-concept and fosters further research into
different models of intelligence.

</details>


### [35] [Variational Shape Inference for Grasp Diffusion on SE(3)](https://arxiv.org/abs/2508.17482)
*S. Talha Bukhari,Kaivalya Agrawal,Zachary Kingston,Aniket Bera*

Main category: cs.RO

TL;DR: 该论文提出了一种结合变分形状推理和扩散模型的多模态抓取合成方法，通过几何特征学习提升鲁棒性，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人抓取任务中多样稳定抓取合成的需求，尤其是在几何特征学习中对噪声和稀疏性的鲁棒性问题。

Method: 使用变分自编码器进行形状推理，结合扩散模型在SE(3)流形上生成抓取分布，并引入测试时优化技术。

Result: 在ACRONYM数据集上性能提升6.3%，且在点云稀疏情况下更鲁棒；实际抓取成功率达34%提升。

Conclusion: 所提出的框架显著提升了多模态抓取合成的性能，展示了在实际场景中的零样本迁移能力。

Abstract: Grasp synthesis is a fundamental task in robotic manipulation which usually
has multiple feasible solutions. Multimodal grasp synthesis seeks to generate
diverse sets of stable grasps conditioned on object geometry, making the robust
learning of geometric features crucial for success. To address this challenge,
we propose a framework for learning multimodal grasp distributions that
leverages variational shape inference to enhance robustness against shape noise
and measurement sparsity. Our approach first trains a variational autoencoder
for shape inference using implicit neural representations, and then uses these
learned geometric features to guide a diffusion model for grasp synthesis on
the SE(3) manifold. Additionally, we introduce a test-time grasp optimization
technique that can be integrated as a plugin to further enhance grasping
performance. Experimental results demonstrate that our shape inference for
grasp synthesis formulation outperforms state-of-the-art multimodal grasp
synthesis methods on the ACRONYM dataset by 6.3%, while demonstrating
robustness to deterioration in point cloud density compared to other
approaches. Furthermore, our trained model achieves zero-shot transfer to
real-world manipulation of household objects, generating 34% more successful
grasps than baselines despite measurement noise and point cloud calibration
errors.

</details>


### [36] [LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations](https://arxiv.org/abs/2508.17547)
*Weikang Wan,Jiawei Fu,Xiaodi Yuan,Yifeng Zhu,Hao Su*

Main category: cs.RO

TL;DR: 本文提出了一种名为LodeStar的学习框架，利用基础模型将任务演示分解为语义化技能，并通过强化学习生成多样化合成数据，显著提升了复杂长时程操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 开发具备人类水平灵巧性的机器人系统需要解决物理灵巧性和技能序列化问题，而传统模仿学习的数据集获取成本高。

Method: 提出LodeStar框架，利用基础模型分解任务演示为语义化技能，并通过强化学习生成合成数据，使用SRT策略链式调用技能。

Result: 在三个真实世界复杂任务上的实验表明，该方法显著提升了任务性能和鲁棒性。

Conclusion: LodeStar通过自动分解技能和合成数据，有效解决了长时程灵巧操作任务的挑战。

Abstract: Developing robotic systems capable of robustly executing long-horizon
manipulation tasks with human-level dexterity is challenging, as such tasks
require both physical dexterity and seamless sequencing of manipulation skills
while robustly handling environment variations. While imitation learning offers
a promising approach, acquiring comprehensive datasets is resource-intensive.
In this work, we propose a learning framework and system LodeStar that
automatically decomposes task demonstrations into semantically meaningful
skills using off-the-shelf foundation models, and generates diverse synthetic
demonstration datasets from a few human demos through reinforcement learning.
These sim-augmented datasets enable robust skill training, with a Skill Routing
Transformer (SRT) policy effectively chaining the learned skills together to
execute complex long-horizon manipulation tasks. Experimental evaluations on
three challenging real-world long-horizon dexterous manipulation tasks
demonstrate that our approach significantly improves task performance and
robustness compared to previous baselines. Videos are available at
lodestar-robot.github.io.

</details>


### [37] [GWM: Towards Scalable Gaussian World Models for Robotic Manipulation](https://arxiv.org/abs/2508.17600)
*Guanxing Lu,Baoxiong Jia,Puhao Li,Yixin Chen,Ziwei Wang,Yansong Tang,Siyuan Huang*

Main category: cs.RO

TL;DR: 提出了一种名为Gaussian World Model (GWM)的新世界模型，用于机器人操作，通过高斯基元传播预测未来状态，结合Diffusion Transformer和3D变分自编码器。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的世界模型缺乏对三维世界的稳定几何信息理解，因此需要一种能更精确预测未来状态的模型。

Method: GWM使用高斯基元传播和Diffusion Transformer与3D变分自编码器的结合，实现精细的未来状态重建。

Result: GWM在模拟和真实实验中精确预测未来场景，并训练出优于现有技术的策略。

Conclusion: GWM展示了3D世界模型的数据扩展潜力，能够有效提升机器人操作性能。

Abstract: Training robot policies within a learned world model is trending due to the
inefficiency of real-world interactions. The established image-based world
models and policies have shown prior success, but lack robust geometric
information that requires consistent spatial and physical understanding of the
three-dimensional world, even pre-trained on internet-scale video sources. To
this end, we propose a novel branch of world model named Gaussian World Model
(GWM) for robotic manipulation, which reconstructs the future state by
inferring the propagation of Gaussian primitives under the effect of robot
actions. At its core is a latent Diffusion Transformer (DiT) combined with a 3D
variational autoencoder, enabling fine-grained scene-level future state
reconstruction with Gaussian Splatting. GWM can not only enhance the visual
representation for imitation learning agent by self-supervised future
prediction training, but can serve as a neural simulator that supports
model-based reinforcement learning. Both simulated and real-world experiments
depict that GWM can precisely predict future scenes conditioned on diverse
robot actions, and can be further utilized to train policies that outperform
the state-of-the-art by impressive margins, showcasing the initial data scaling
potential of 3D world model.

</details>


### [38] [SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation](https://arxiv.org/abs/2508.17643)
*Krishna Vinod,Prithvi Jai Ramesh,Pavan Kumar B N,Bharatesh Chakravarthi*

Main category: cs.RO

TL;DR: 论文介绍了一个开源v2e ROS工具包，用于在Gazebo中生成事件流，评估事件驱动的机器人导航与操作策略。


<details>
  <summary>Details</summary>
Motivation: 事件相机在复杂条件下具有优势，但模拟环境中相关研究较少，阻碍了事件驱动方法在机器人任务中的评估。

Method: 开发了v2e ROS工具包，通过RGB图像生成事件流，并训练基于Transformer的事件驱动策略（ERP），用于导航与操作任务。

Result: 实验证明，事件驱动策略在移动机器人跟随和机械臂抓取任务中表现优于RGB方法。

Conclusion: 事件驱动感知在实时机器人任务中具有潜力，为事件相机在机器人策略学习中的广泛应用提供了基础。

Abstract: Event cameras offer microsecond latency, high dynamic range, and low power
consumption, making them ideal for real-time robotic perception under
challenging conditions such as motion blur, occlusion, and illumination
changes. However, despite their advantages, synthetic event-based vision
remains largely unexplored in mainstream robotics simulators. This lack of
simulation setup hinders the evaluation of event-driven approaches for robotic
manipulation and navigation tasks. This work presents an open-source,
user-friendly v2e robotics operating system (ROS) package for Gazebo simulation
that enables seamless event stream generation from RGB camera feeds. The
package is used to investigate event-based robotic policies (ERP) for real-time
navigation and manipulation. Two representative scenarios are evaluated: (1)
object following with a mobile robot and (2) object detection and grasping with
a robotic manipulator. Transformer-based ERPs are trained by behavior cloning
and compared to RGB-based counterparts under various operating conditions.
Experimental results show that event-guided policies consistently deliver
competitive advantages. The results highlight the potential of event-driven
perception to improve real-time robotic navigation and manipulation, providing
a foundation for broader integration of event cameras into robotic policy
learning. The GitHub repo for the dataset and code:
https://eventbasedvision.github.io/SEBVS/

</details>


### [39] [MEVITA: Open-Source Bipedal Robot Assembled from E-Commerce Components via Sheet Metal Welding](https://arxiv.org/abs/2508.17684)
*Kento Kawaharazuka,Shogo Sawaguchi,Ayumu Iwata,Keita Yoneda,Temma Suzuki,Kei Okada*

Main category: cs.RO

TL;DR: 开源双足机器人MEVITA，通过电商可购零件和金属板材焊接简化组装，并通过强化学习实现稳健行走。


<details>
  <summary>Details</summary>
Motivation: 解决现有开源双足机器人因3D打印限制导致的脆弱性，以及金属机器人因零件复杂导致的组装难题。

Method: 采用金属板材焊接技术减少组件数量，通过强化学习和仿真到现实的迁移技术训练机器人。

Result: 实现了在各种环境中的稳健行走，验证了设计的有效性。

Conclusion: MEVITA为开源双足机器人提供了一种易于组装且性能可靠的解决方案。

Abstract: Various bipedal robots have been developed to date, and in recent years,
there has been a growing trend toward releasing these robots as open-source
platforms. This shift is fostering an environment in which anyone can freely
develop bipedal robots and share their knowledge, rather than relying solely on
commercial products. However, most existing open-source bipedal robots are
designed to be fabricated using 3D printers, which limits their scalability in
size and often results in fragile structures. On the other hand, some
metal-based bipedal robots have been developed, but they typically involve a
large number of components, making assembly difficult, and in some cases, the
parts themselves are not readily available through e-commerce platforms. To
address these issues, we developed MEVITA, an open-source bipedal robot that
can be built entirely from components available via e-commerce. Aiming for the
minimal viable configuration for a bipedal robot, we utilized sheet metal
welding to integrate complex geometries into single parts, thereby
significantly reducing the number of components and enabling easy assembly for
anyone. Through reinforcement learning in simulation and Sim-to-Real transfer,
we demonstrated robust walking behaviors across various environments,
confirming the effectiveness of our approach. All hardware, software, and
training environments can be obtained from https://github.com/haraduka/mevita .

</details>


### [40] [Talking to Robots: A Practical Examination of Speech Foundation Models for HRI Applications](https://arxiv.org/abs/2508.17753)
*Theresa Pekarek Rosin,Julia Gachot,Henri-Leon Kordt,Matthias Kerzel,Stefan Wermter*

Main category: cs.RO

TL;DR: 评估四种ASR系统在多种困难维度下的性能，揭示其在HRI中的局限性和潜在影响。


<details>
  <summary>Details</summary>
Motivation: 解决ASR系统在真实场景（如HRI）中对不完美音频和多用户群体的适应性问题。

Method: 在八种公开数据集上测试四种前沿ASR系统，涵盖六种困难维度。

Result: 性能差异显著，存在幻觉倾向和固有偏见，标准基准得分相近但实际表现不同。

Conclusion: ASR系统的局限可能影响HRI的任务执行、信任和安全，需进一步改进。

Abstract: Automatic Speech Recognition (ASR) systems in real-world settings need to
handle imperfect audio, often degraded by hardware limitations or environmental
noise, while accommodating diverse user groups. In human-robot interaction
(HRI), these challenges intersect to create a uniquely challenging recognition
environment. We evaluate four state-of-the-art ASR systems on eight publicly
available datasets that capture six dimensions of difficulty: domain-specific,
accented, noisy, age-variant, impaired, and spontaneous speech. Our analysis
demonstrates significant variations in performance, hallucination tendencies,
and inherent biases, despite similar scores on standard benchmarks. These
limitations have serious implications for HRI, where recognition errors can
interfere with task performance, user trust, and safety.

</details>


### [41] [Adaptive Output Steps: FlexiSteps Network for Dynamic Trajectory Prediction](https://arxiv.org/abs/2508.17797)
*Yunxiang Liu,Hongkuo Niu,Jianlin Zhu*

Main category: cs.RO

TL;DR: 提出 FlexiSteps 网络（FSN），动态调整预测输出时间步，以适应动态现实场景。


<details>
  <summary>Details</summary>
Motivation: 传统模型的固定长度预测输出限制了其在动态场景中的适应性。

Method: 结合预训练的自适应预测模块（APM）和动态解码器（DD），设计评分机制平衡预测时间步和准确性。

Result: 在 Argoverse 和 INTERACTION 数据集上验证了 FSN 的有效性和灵活性。

Conclusion: FSN 框架能够动态调整预测步长，显著提升预测准确性和适应性。

Abstract: Accurate trajectory prediction is vital for autonomous driving, robotics, and
intelligent decision-making systems, yet traditional models typically rely on
fixed-length output predictions, limiting their adaptability to dynamic
real-world scenarios. In this paper, we introduce the FlexiSteps Network (FSN),
a novel framework that dynamically adjusts prediction output time steps based
on varying contextual conditions. Inspired by recent advancements addressing
observation length discrepancies and dynamic feature extraction, FSN
incorporates an pre-trained Adaptive Prediction Module (APM) to evaluate and
adjust the output steps dynamically, ensuring optimal prediction accuracy and
efficiency. To guarantee the plug-and-play of our FSN, we also design a Dynamic
Decoder(DD). Additionally, to balance the prediction time steps and prediction
accuracy, we design a scoring mechanism, which not only introduces the
Fr\'echet distance to evaluate the geometric similarity between the predicted
trajectories and the ground truth trajectories but the length of predicted
steps is also considered. Extensive experiments conducted on benchmark datasets
including Argoverse and INTERACTION demonstrate the effectiveness and
flexibility of our proposed FSN framework.

</details>


### [42] [Effect of Performance Feedback Timing on Motor Learning for a Surgical Training Task](https://arxiv.org/abs/2508.17830)
*Mary Kate Gale,Kailana Baker-Matsuoka,Ilana Nisky,Allison Okamura*

Main category: cs.RO

TL;DR: 实时多感官错误反馈比任务回放或无反馈更能提高虚拟手术任务的学习效果。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人辅助微创手术（RMIS）中实时错误反馈对手术新手学习速度和错误率的影响。

Method: 42名手术新手完成虚拟手术任务，分为实时反馈、回放反馈和无反馈三组。

Result: 实时反馈组在环的定位准确性上表现最佳，回放反馈组在直线路径上优于无反馈组。

Conclusion: 实时多感官错误反馈能显著提升训练效果，适用于手术技能培训。

Abstract: Objective: Robot-assisted minimally invasive surgery (RMIS) has become the
gold standard for a variety of surgical procedures, but the optimal method of
training surgeons for RMIS is unknown. We hypothesized that real-time, rather
than post-task, error feedback would better increase learning speed and reduce
errors. Methods: Forty-two surgical novices learned a virtual version of the
ring-on-wire task, a canonical task in RMIS training. We investigated the
impact of feedback timing with multi-sensory (haptic and visual) cues in three
groups: (1) real-time error feedback, (2) trial replay with error feedback, and
(3) no error feedback. Results: Participant performance was evaluated based on
the accuracy of ring position and orientation during the task. Participants who
received real-time feedback outperformed other groups in ring orientation.
Additionally, participants who received feedback in replay outperformed
participants who did not receive any error feedback on ring orientation during
long, straight path sections. There were no significant differences between
groups for ring position overall, but participants who received real-time
feedback outperformed the other groups in positional accuracy on tightly curved
path sections. Conclusion: The addition of real-time haptic and visual error
feedback improves learning outcomes in a virtual surgical task over error
feedback in replay or no error feedback at all. Significance: This work
demonstrates that multi-sensory error feedback delivered in real time leads to
better training outcomes as compared to the same feedback delivered after task
completion. This novel method of training may enable surgical trainees to
develop skills with greater speed and accuracy.

</details>


### [43] [CubeDN: Real-time Drone Detection in 3D Space from Dual mmWave Radar Cubes](https://arxiv.org/abs/2508.17831)
*Yuan Fang,Fangzhan Shi,Xijia Wei,Qingchao Chen,Kevin Chetty,Simon Julier*

Main category: cs.RO

TL;DR: 论文提出CubeDN，一种单阶段端到端毫米波雷达网络，用于无人机3D检测与定位，克服了现有2D系统的不足。


<details>
  <summary>Details</summary>
Motivation: 随着无人机的普及，安全需求增加，但光学传感器在恶劣条件下性能下降，毫米波雷达在2D检测中表现优异但缺乏3D能力，因此需要改进。

Method: CubeDN采用双雷达配置和新型深度学习管道，解决低仰角分辨率问题，实现无人机的检测、定位与分类。

Result: 在近距离实现分米级跟踪精度，平均精度95%，平均召回率85%，处理速度达10Hz，适合实际应用。

Conclusion: CubeDN填补了3D无人机检测的技术空白，表现出高精度与实用性。

Abstract: As drone use has become more widespread, there is a critical need to ensure
safety and security. A key element of this is robust and accurate drone
detection and localization. While cameras and other optical sensors like LiDAR
are commonly used for object detection, their performance degrades under
adverse lighting and environmental conditions. Therefore, this has generated
interest in finding more reliable alternatives, such as millimeter-wave
(mmWave) radar. Recent research on mmWave radar object detection has
predominantly focused on 2D detection of road users. Although these systems
demonstrate excellent performance for 2D problems, they lack the sensing
capability to measure elevation, which is essential for 3D drone detection. To
address this gap, we propose CubeDN, a single-stage end-to-end radar object
detection network specifically designed for flying drones. CubeDN overcomes
challenges such as poor elevation resolution by utilizing a dual radar
configuration and a novel deep learning pipeline. It simultaneously detects,
localizes, and classifies drones of two sizes, achieving decimeter-level
tracking accuracy at closer ranges with overall $95\%$ average precision (AP)
and $85\%$ average recall (AR). Furthermore, CubeDN completes data processing
and inference at 10Hz, making it highly suitable for practical applications.

</details>


### [44] [Egocentric Instruction-oriented Affordance Prediction via Large Multimodal Model](https://arxiv.org/abs/2508.17922)
*Bokai Ji,Jie Gu,Xiaokang Ma,Chu Tang,Jingmin Chen,Guangxia Li*

Main category: cs.RO

TL;DR: 本文提出了任务/指令依赖的affordance概念，并构建了一个包含大量object-instruction-affordance三元组的数据集，同时通过“search against verifiers”框架利用大模型预测affordance。


<details>
  <summary>Details</summary>
Motivation: 传统的affordance研究忽略了任务或指令的依赖性，导致预测结果与实际情况不符。本文旨在解决这一问题。

Method: 构建了一个包含15,000个三元组的数据集，并设计了“search against verifiers”框架，通过迭代验证逐步预测affordance。

Result: 实验表明，该方法不仅能实现指令导向的affordance预测，还取得了广泛的优异性能。

Conclusion: 任务/指令依赖性对affordance预测至关重要，该方法为智能机器人提供了新的工具。

Abstract: Affordance is crucial for intelligent robots in the context of object
manipulation. In this paper, we argue that affordance should be
task-/instruction-dependent, which is overlooked by many previous works. That
is, different instructions can lead to different manipulation regions and
directions even for the same object. According to this observation, we present
a new dataset comprising fifteen thousand object-instruction-affordance
triplets. All scenes in the dataset are from an egocentric viewpoint, designed
to approximate the perspective of a human-like robot. Furthermore, we
investigate how to enable large multimodal models (LMMs) to serve as affordance
predictors by implementing a ``search against verifiers'' pipeline. An LMM is
asked to progressively predict affordances, with the output at each step being
verified by itself during the iterative process, imitating a reasoning process.
Experiments show that our method not only unlocks new instruction-oriented
affordance prediction capabilities, but also achieves outstanding performance
broadly.

</details>


### [45] [A holistic perception system of internal and external monitoring for ground autonomous vehicles: AutoTRUST paradigm](https://arxiv.org/abs/2508.17969)
*Alexandros Gkillas,Christos Anagnostopoulos,Nikos Piperigkos,Dimitris Tsiktsiris,Theofilos Christodoulou,Theofanis Siamatras,Dimitrios Triantafyllou,Christos Basdekis,Theoktisti Marinopoulou,Panagiotis Lepentsiotis,Elefterios Blitsis,Aggeliki Zacharaki,Nearchos Stylianidis,Leonidas Katelaris,Lamberto Salvan,Aris S. Lalos,Christos Laoudias,Antonios Lalas,Konstantinos Votis*

Main category: cs.RO

TL;DR: 论文提出了一种全面的自动驾驶车辆内外监测感知系统，展示了通过AI驱动的自适应框架优化车内感知与体验的目标。


<details>
  <summary>Details</summary>
Motivation: 通过内外监测系统提升自动驾驶车辆的安全与舒适性，优化乘客体验。

Method: 内部监测系统采用多摄像头和大型语言模型识别驾驶员行为，并结合智能传感器分析车内环境；外部监测系统通过LiDAR进行高效的语义分割和点云超分辨率处理。

Result: 系统在真实电动车上部署并通过实验验证，显示出各模块的性能和效率提升。

Conclusion: 该框架为自动驾驶车辆提供了全面的感知解决方案，具有实际应用价值。

Abstract: This paper introduces a holistic perception system for internal and external
monitoring of autonomous vehicles, with the aim of demonstrating a novel
AI-leveraged self-adaptive framework of advanced vehicle technologies and
solutions that optimize perception and experience on-board. Internal monitoring
system relies on a multi-camera setup designed for predicting and identifying
driver and occupant behavior through facial recognition, exploiting in addition
a large language model as virtual assistant. Moreover, the in-cabin monitoring
system includes AI-empowered smart sensors that measure air-quality and perform
thermal comfort analysis for efficient on and off-boarding. On the other hand,
external monitoring system perceives the surrounding environment of vehicle,
through a LiDAR-based cost-efficient semantic segmentation approach, that
performs highly accurate and efficient super-resolution on low-quality raw 3D
point clouds. The holistic perception framework is developed in the context of
EU's Horizon Europe programm AutoTRUST, and has been integrated and deployed on
a real electric vehicle provided by ALKE. Experimental validation and
evaluation at the integration site of Joint Research Centre at Ispra, Italy,
highlights increased performance and efficiency of the modular blocks of the
proposed perception architecture.

</details>


### [46] [Integration of Computer Vision with Adaptive Control for Autonomous Driving Using ADORE](https://arxiv.org/abs/2508.17985)
*Abu Shad Ahammed,Md Shahi Amran Hossain,Sayeri Mukherjee,Roman Obermaisser,Md. Ziaur Rahman*

Main category: cs.RO

TL;DR: 论文提出了一种结合上下文感知CV模型与自适应控制ADORE框架的自动驾驶系统，在CARLA模拟器中验证了其在复杂天气下的鲁棒性和低延迟适应性。


<details>
  <summary>Details</summary>
Motivation: 解决在天气变化或未见物体等不确定条件下自动驾驶系统的感知与决策性能下降问题。

Method: 使用ADORE框架结合上下文感知CV模型，在CARLA模拟器中通过ROS桥进行实时通信，设计测试案例验证性能。

Result: 系统在复杂天气下表现出鲁棒检测性能，ADORE成功适应速度限制和障碍物，具有低响应延迟。

Conclusion: 结合深度学习感知与基于规则的自适应决策能提升自动驾驶安全关键系统的性能。

Abstract: Ensuring safety in autonomous driving requires a seamless integration of
perception and decision making under uncertain conditions. Although computer
vision (CV) models such as YOLO achieve high accuracy in detecting traffic
signs and obstacles, their performance degrades in drift scenarios caused by
weather variations or unseen objects. This work presents a simulated autonomous
driving system that combines a context aware CV model with adaptive control
using the ADORE framework. The CARLA simulator was integrated with ADORE via
the ROS bridge, allowing real-time communication between perception, decision,
and control modules. A simulated test case was designed in both clear and drift
weather conditions to demonstrate the robust detection performance of the
perception model while ADORE successfully adapted vehicle behavior to speed
limits and obstacles with low response latency. The findings highlight the
potential of coupling deep learning-based perception with rule-based adaptive
decision making to improve automotive safety critical system.

</details>


### [47] [No Need to Look! Locating and Grasping Objects by a Robot Arm Covered with Sensitive Skin](https://arxiv.org/abs/2508.17986)
*Karel Bartunek,Lukas Rustler,Matej Hoffmann*

Main category: cs.RO

TL;DR: 该论文探讨了在完全无视觉输入的情况下，利用机器人全身触觉反馈进行物体定位与抓取的方法。通过分阶段搜索和实验验证，证明了方法的有效性和高效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决视觉感知受限环境（如光线不足、遮挡等）下的物体定位与抓取问题，探索触觉反馈的潜力。

Method: 分两阶段：1) 利用全身敏感皮肤进行粗略探索；2) 用末端执行器的力/力矩传感器精确定位。在仿真和真实机器人上进行了系统评估。

Result: 真实机器人上单物体成功率为85.7%，全身触觉方法的效率是仅用末端触觉的6倍。展示了多物体定位与抓取能力。

Conclusion: 该方法适用于任何具备全身触觉感知的机器人平台，在视觉受限场景（如农业采摘）中有广泛应用潜力。

Abstract: Locating and grasping of objects by robots is typically performed using
visual sensors. Haptic feedback from contacts with the environment is only
secondary if present at all. In this work, we explored an extreme case of
searching for and grasping objects in complete absence of visual input, relying
on haptic feedback only. The main novelty lies in the use of contacts over the
complete surface of a robot manipulator covered with sensitive skin. The search
is divided into two phases: (1) coarse workspace exploration with the complete
robot surface, followed by (2) precise localization using the end-effector
equipped with a force/torque sensor. We systematically evaluated this method in
simulation and on the real robot, demonstrating that diverse objects can be
located, grasped, and put in a basket. The overall success rate on the real
robot for one object was 85.7\% with failures mainly while grasping specific
objects. The method using whole-body contacts is six times faster compared to a
baseline that uses haptic feedback only on the end-effector. We also show
locating and grasping multiple objects on the table. This method is not
restricted to our specific setup and can be deployed on any platform with the
ability of sensing contacts over the entire body surface. This work holds
promise for diverse applications in areas with challenging visual perception
(due to lighting, dust, smoke, occlusion) such as in agriculture when fruits or
vegetables need to be located inside foliage and picked.

</details>


### [48] [Modeling and Control Framework for Autonomous Space Manipulator Handover Operations](https://arxiv.org/abs/2508.18039)
*Diego Quevedo,Sarah Hudson,Donghoon Kim*

Main category: cs.RO

TL;DR: 该论文研究了双机械臂空间操作系统的动态模型及其跟踪控制策略，以支持自主机器间任务关键对象交接。


<details>
  <summary>Details</summary>
Motivation: 未来空间任务中，自主空间机器人对在轨服务、组装与制造（ISAM）至关重要，而机器间交接任务关键对象是其核心能力之一。

Method: 提出了一种双机械臂系统的动态模型，并比较了多种跟踪控制策略。

Result: 开发了协作机械臂动态模型，并对控制策略进行了比较分析。

Conclusion: 该研究为自主R2R交接在ISAM场景中的应用提供了支持。

Abstract: Autonomous space robotics is poised to play a vital role in future space
missions, particularly for In-space Servicing, Assembly, and Manufacturing
(ISAM). A key capability in such missions is the Robot-to-Robot (R2R) handover
of mission-critical objects. This work presents a dynamic model of a dual-arm
space manipulator system and compares various tracking control laws. The key
contributions of this work are the development of a cooperative manipulator
dynamic model and the comparative analysis of control laws to support
autonomous R2R handovers in ISAM scenarios.

</details>


### [49] [Arnold: a generalist muscle transformer policy](https://arxiv.org/abs/2508.18066)
*Alberto Silvio Chiappa,Boshi An,Merkourios Simos,Chengkun Li,Alexander Mathis*

Main category: cs.RO

TL;DR: 本文开发了名为Arnold的通用策略，结合行为克隆和PPO微调，在14项复杂控制任务中实现专家级表现。关键创新是其感知运动词汇和Transformer架构，支持多任务和多体现学习。


<details>
  <summary>Details</summary>
Motivation: 目前的高维非线性肌肉骨骼模型控制多为单一任务专家，缺乏通用性。本文旨在开发能处理多任务和多体现的通用策略。

Method: 结合行为克隆和PPO微调，引入感知运动词汇和Transformer架构，处理可变观察和动作空间。

Result: Arnold在14项任务中表现优异，支持快速适应新任务，并揭示了肌肉协同作用在任务间的有限可转移性。

Conclusion: Arnold为通用控制策略提供了新方法，同时在生物运动控制研究中有启示意义。

Abstract: Controlling high-dimensional and nonlinear musculoskeletal models of the
human body is a foundational scientific challenge. Recent machine learning
breakthroughs have heralded policies that master individual skills like
reaching, object manipulation and locomotion in musculoskeletal systems with
many degrees of freedom. However, these agents are merely "specialists",
achieving high performance for a single skill. In this work, we develop Arnold,
a generalist policy that masters multiple tasks and embodiments. Arnold
combines behavior cloning and fine-tuning with PPO to achieve expert or
super-expert performance in 14 challenging control tasks from dexterous object
manipulation to locomotion. A key innovation is Arnold's sensorimotor
vocabulary, a compositional representation of the semantics of heterogeneous
sensory modalities, objectives, and actuators. Arnold leverages this vocabulary
via a transformer architecture to deal with the variable observation and action
spaces of each task. This framework supports efficient multi-task,
multi-embodiment learning and facilitates rapid adaptation to novel tasks.
Finally, we analyze Arnold to provide insights into biological motor control,
corroborating recent findings on the limited transferability of muscle
synergies across tasks.

</details>


### [50] [The Effects of Communication Delay on Human Performance and Neurocognitive Responses in Mobile Robot Teleoperation](https://arxiv.org/abs/2508.18074)
*Zhaokun Chen,Wenshuo Wang,Wenzhuo Liu,Yichen Liu,Junqiang Xi*

Main category: cs.RO

TL;DR: 移动机器人远程操作中的通信延迟对人与机器协作有负面影响。研究首次通过人机实验结合EEG和机器人行为数据，系统探究了延迟对人的操作表现和神经认知的影响。


<details>
  <summary>Details</summary>
Motivation: 解决通信延迟对协作的负面影响，填补了以往研究对延迟效应的认知空白。

Method: 10名参与者的人机实验，EEG和行为数据结合，延迟从0到500 ms以100 ms递增。

Result: 200-300 ms延迟显著影响任务效率和准确性；EEG特征显示延迟依赖关系，阈值窗口为100-200 ms；超过400 ms时认知资源分配达到生理极限。

Conclusion: 首次揭示了人类在远程操作中的感知和认知延迟阈值，为延迟补偿策略设计提供了关键的神经认知依据。

Abstract: Communication delays in mobile robot teleoperation adversely affect
human-machine collaboration. Understanding delay effects on human operational
performance and neurocognition is essential for resolving this issue. However,
no previous research has explored this. To fill this gap, we conduct a
human-in-the-loop experiment involving 10 participants, integrating
electroencephalography (EEG) and robot behavior data under varying delays
(0-500 ms in 100 ms increments) to systematically investigate these effects.
Behavior analysis reveals significant performance degradation at 200-300 ms
delays, affecting both task efficiency and accuracy. EEG analysis discovers
features with significant delay dependence: frontal $\theta/\beta$-band and
parietal $\alpha$-band power. We also identify a threshold window (100-200 ms)
for early perception of delay in humans, during which these EEG features first
exhibit significant differences. When delay exceeds 400 ms, all features
plateau, indicating saturation of cognitive resource allocation at
physiological limits. These findings provide the first evidence of perceptual
and cognitive delay thresholds during teleoperation tasks in humans, offering
critical neurocognitive insights for the design of delay compensation
strategies.

</details>


### [51] [Analysis of Harpy's Constrained Trotting and Jumping Maneuver](https://arxiv.org/abs/2508.18139)
*Prathima Ananda Kumar*

Main category: cs.RO

TL;DR: 对Harpy（一种带推进器的双足机器人）的实验数据进行分析，揭示了其通过腿部和推进器的协同实现稳定运动的关键原理。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解混合腿-推进器运动的基本原理，以及如何实现稳定、可控的运动。

Method: 通过分析机器人行走和跳跃的数据，研究其运动模式、关节行为和能量分配。

Result: Harpy表现出稳定的关节行为、精准的足部定位和对称的运动，推进器提供了额外的空中控制，腿部主导推进。

Conclusion: 混合驱动方法在稳定性和控制性方面表现出色，验证了腿-推进器协同的有效性。

Abstract: This study presents an analysis of experimental data from Harpy, a
thruster-assisted bipedal robot developed at Northeastern University. The study
examines data sets from trotting and jumping experiments to understand the
fundamental principles governing hybrid leg-thruster locomotion. Through data
analysis across multiple locomotion modes, this research reveals that Harpy
achieves stable locomotion with bounded trajectories and consistent foot
placement through strategic leg-thruster synergy. The results demonstrate
controlled joint behavior with low torques and symmetric tracking, accurate
foot placement within kinematic constraints despite phase-transition
perturbations, and underactuated degree-of-freedom stability without
divergence. Energy level analysis reveals that legs provide primary propulsion,
while the thrusters enable additional aerial phase control. The analysis
identifies critical body-leg coupling dynamics during aerial phases that
require phase-specific control strategies. Consistent repeatability and
symmetry across experiments validate the robustness of the hybrid actuation
approach.

</details>


### [52] [DANCeRS: A Distributed Algorithm for Negotiating Consensus in Robot Swarms with Gaussian Belief Propagation](https://arxiv.org/abs/2508.18153)
*Aalok Patwardhan,Andrew J. Davison*

Main category: cs.RO

TL;DR: 论文提出了一种名为DANCeRS的统一分布式算法，利用高斯置信传播（GBP）在离散和连续决策空间中达成共识，适用于多机器人系统。


<details>
  <summary>Details</summary>
Motivation: 解决机器人群体在形状形成和决策制定中需要统一方法的问题，避免现有方法将离散和连续决策视为独立问题。

Method: 通过将群体表示为因子图，使用纯对等消息传递实现分布式共识，确保在动态环境中的可扩展性和鲁棒性。

Result: 实验表明，DANCeRS在路径规划、碰撞避障和离散决策形成中表现出高效和可扩展性，优于现有方法。

Conclusion: DANCeRS为多机器人系统提供了一种通用的分布式共识解决方案，适用于多种应用场景。

Abstract: Robot swarms require cohesive collective behaviour to address diverse
challenges, including shape formation and decision-making. Existing approaches
often treat consensus in discrete and continuous decision spaces as distinct
problems. We present DANCeRS, a unified, distributed algorithm leveraging
Gaussian Belief Propagation (GBP) to achieve consensus in both domains. By
representing a swarm as a factor graph our method ensures scalability and
robustness in dynamic environments, relying on purely peer-to-peer message
passing. We demonstrate the effectiveness of our general framework through two
applications where agents in a swarm must achieve consensus on global behaviour
whilst relying on local communication. In the first, robots must perform path
planning and collision avoidance to create shape formations. In the second, we
show how the same framework can be used by a group of robots to form a
consensus over a set of discrete decisions. Experimental results highlight our
method's scalability and efficiency compared to recent approaches to these
problems making it a promising solution for multi-robot systems requiring
distributed consensus. We encourage the reader to see the supplementary video
demo.

</details>


### [53] [Scene-Agnostic Traversability Labeling and Estimation via a Multimodal Self-supervised Framework](https://arxiv.org/abs/2508.18249)
*Zipeng Fang,Yanbo Wang,Lei Zhao,Weidong Chen*

Main category: cs.RO

TL;DR: 提出了一种多模态自监督框架，用于地形可穿越性标注与估计，结合视觉基础模型和多模态数据，提升了可穿越性识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有自监督方法未能充分捕捉不可穿越区域的特征，且多数仅关注单一模态，未能利用多模态互补优势。

Method: 整合足迹、LiDAR和相机数据作为视觉基础模型的提示，生成可穿越性标签；训练双流网络结合多模态学习；引入稀疏LiDAR监督以减少伪标签噪声。

Result: 自动标注方法在多样数据集中达到约88% IoU；多模态网络比现有最佳方法提升1.6-3.5% IoU。

Conclusion: 多模态自监督框架显著提升可穿越性估计性能，适用于多种环境。

Abstract: Traversability estimation is critical for enabling robots to navigate across
diverse terrains and environments. While recent self-supervised learning
methods achieve promising results, they often fail to capture the
characteristics of non-traversable regions. Moreover, most prior works
concentrate on a single modality, overlooking the complementary strengths
offered by integrating heterogeneous sensory modalities for more robust
traversability estimation. To address these limitations, we propose a
multimodal self-supervised framework for traversability labeling and
estimation. First, our annotation pipeline integrates footprint, LiDAR, and
camera data as prompts for a vision foundation model, generating traversability
labels that account for both semantic and geometric cues. Then, leveraging
these labels, we train a dual-stream network that jointly learns from different
modalities in a decoupled manner, enhancing its capacity to recognize diverse
traversability patterns. In addition, we incorporate sparse LiDAR-based
supervision to mitigate the noise introduced by pseudo labels. Finally,
extensive experiments conducted across urban, off-road, and campus environments
demonstrate the effectiveness of our approach. The proposed automatic labeling
method consistently achieves around 88% IoU across diverse datasets. Compared
to existing self-supervised state-of-the-art methods, our multimodal
traversability estimation network yields consistently higher IoU, improving by
1.6-3.5% on all evaluated datasets.

</details>


### [54] [SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation](https://arxiv.org/abs/2508.18268)
*Haoyuan Deng,Wenkai Guo,Qianzhun Wang,Zhenyu Wu,Ziwei Wang*

Main category: cs.RO

TL;DR: SafeBimanual 是一种针对双机械臂操作的测试时间轨迹优化框架，通过引入安全约束和动态成本函数，显著提高了任务成功率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散策略的双机械臂操作方法忽视了物理安全约束，可能导致危险行为，因此需要一种能够动态优化轨迹以确保安全的方法。

Method: 设计了多样化的成本函数来约束不同双机械臂协作模式中的安全问题，并利用视觉语言模型动态生成最优安全约束。

Result: 在模拟任务中，成功率提高了13.7%，不安全交互减少了18.8%；在真实任务中，成功率提高了32.5%。

Conclusion: SafeBimanual 能够在保证安全性的同时显著提升双机械臂操作的成功率，具有实际应用价值。

Abstract: Bimanual manipulation has been widely applied in household services and
manufacturing, which enables the complex task completion with coordination
requirements. Recent diffusion-based policy learning approaches have achieved
promising performance in modeling action distributions for bimanual
manipulation. However, they ignored the physical safety constraints of bimanual
manipulation, which leads to the dangerous behaviors with damage to robots and
objects. To this end, we propose a test-time trajectory optimization framework
named SafeBimanual for any pre-trained diffusion-based bimanual manipulation
policies, which imposes the safety constraints on bimanual actions to avoid
dangerous robot behaviors with improved success rate. Specifically, we design
diverse cost functions for safety constraints in different dual-arm cooperation
patterns including avoidance of tearing objects and collision between arms and
objects, which optimizes the manipulator trajectories with guided sampling of
diffusion denoising process. Moreover, we employ a vision-language model (VLM)
to schedule the cost functions by specifying keypoints and corresponding
pairwise relationship, so that the optimal safety constraint is dynamically
generated in the entire bimanual manipulation process. SafeBimanual
demonstrates superiority on 8 simulated tasks in RoboTwin with a 13.7% increase
in success rate and a 18.8% reduction in unsafe interactions over
state-of-the-art diffusion-based methods. Extensive experiments on 4 real-world
tasks further verify its practical value by improving the success rate by
32.5%.

</details>


### [55] [FlowVLA: Thinking in Motion with a Visual Chain of Thought](https://arxiv.org/abs/2508.18269)
*Zhide Zhong,Haodong Yan,Junfeng Li,Xiangchen Liu,Xin Gong,Wenxuan Song,Jiayi Chen,Haoang Li*

Main category: cs.RO

TL;DR: FlowVLA通过引入视觉链式思维（Visual CoT），在预测未来帧之前先生成中间光流表示，从而解耦静态外观与动态运动，提升了视觉预测和策略学习的效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于下一帧预测的VLA模型在物理推理上表现不佳，因为其将静态外观与动态运动混为一谈，导致视觉预测不合理且策略学习效率低下。

Method: FlowVLA采用Visual CoT框架，通过“当前帧→光流→未来帧”的链式推理过程，在单自回归Transformer中生成解耦的动态表示。

Result: 在机器人操作基准测试中，FlowVLA实现了最优性能，并显著提升了样本效率。

Conclusion: FlowVLA通过解耦动态与静态信息，为世界建模提供了更高效和合理的基础。

Abstract: Many Vision-Language-Action (VLA) models rely on an internal world model
trained via next-frame prediction. This approach, however, struggles with
physical reasoning as it entangles static appearance with dynamic motion, often
resulting in implausible visual forecasts and inefficient policy learning. To
address these limitations, we introduce the Visual Chain of Thought (Visual
CoT): a pre-training framework that encourages a model to reason about how a
scene evolves before predicting what it will look like. We instantiate this
principle in FlowVLA, which predicts a future frame ($v_{t+1}$) only after
generating an intermediate optical flow representation ($f_t$) that encodes
motion dynamics. This ``$v_t \rightarrow f_t \rightarrow v_{t+1}$'' reasoning
process is implemented within a single autoregressive Transformer, guiding the
model to learn disentangled dynamics. As a result, FlowVLA produces coherent
visual predictions and facilitates more efficient policy learning. Experiments
on challenging robotics manipulation benchmarks demonstrate state-of-the-art
performance with substantially improved sample efficiency, pointing toward a
more principled foundation for world modeling. Project page:
https://irpn-lab.github.io/FlowVLA/

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [56] [Social Identity in Human-Agent Interaction: A Primer](https://arxiv.org/abs/2508.16609)
*Katie Seaborn*

Main category: physics.soc-ph

TL;DR: 摘要综述了社会身份理论（SIT）和社会分类理论（SCT），并探讨了这些理论如何应用于人工智能社交代理。作者认为并非所有人类模型都适用，并呼吁专家警惕技术的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 随着社交机器人和大型语言模型（LLM）等技术的进步，研究人工智能代理如何参与社会身份活动变得重要。

Method: 通过案例研究和想象示例，将SIT和SCT理论应用于人工智能社交代理。

Result: 指出并非所有人际模型都适用于人工智能，且专家需警惕技术的潜在影响。

Conclusion: 人工智能作为社交实体的角色需进一步研究，专家应保持批判态度以确保技术发展符合人类利益。

Abstract: Social identity theory (SIT) and social categorization theory (SCT) are two
facets of the social identity approach (SIA) to understanding social phenomena.
SIT and SCT are models that describe and explain how people interact with one
another socially, connecting the individual to the group through an
understanding of underlying psychological mechanisms and intergroup behaviour.
SIT, originally developed in the 1970s, and SCT, a later, more general
offshoot, have been broadly applied to a range of social phenomena among
people. The rise of increasingly social machines embedded in daily life has
spurned efforts on understanding whether and how artificial agents can and do
participate in SIA activities. As agents like social robots and chatbots
powered by sophisticated large language models (LLMs) advance, understanding
the real and potential roles of these technologies as social entities is
crucial. Here, I provide a primer on SIA and extrapolate, through case studies
and imagined examples, how SIT and SCT can apply to artificial social agents. I
emphasize that not all human models and sub-theories will apply. I further
argue that, given the emerging competence of these machines and our tendency to
be taken in by them, we experts may need to don the hat of the uncanny killjoy,
for our own good.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [57] [Observations of atypical users from a pilot deployment of a public-space social robot in a church](https://arxiv.org/abs/2508.16622)
*Andrew Blair,Peggy Gregory,Mary Ellen Foster*

Main category: cs.HC

TL;DR: 论文探讨了在真实公共空间中社交机器人与用户的非典型互动，提出了改进HRI的理论与实践策略。


<details>
  <summary>Details</summary>
Motivation: 研究目标是解决社交机器人在真实公共空间中与多样性用户互动的不可预测性及挑战。

Method: 通过三天在教堂和游客景点的试点部署，观察非典型用户与机器人的互动情况。

Result: 发现了许多未在其他情境中讨论的意外互动行为，提出了理论和实践上的改进策略。

Conclusion: 研究为社交机器人在公共空间的部署提供了实证见解和可行性建议。

Abstract: Though a goal of HRI is the natural integration of social robots into
everyday public spaces, real-world studies still occur mostly within controlled
environments with predetermined participants. True public spaces present an
environment which is largely unconstrained and unpredictable, frequented by a
diverse range of people whose goals can often conflict with those of the robot.
When combined with the general unfamiliarity most people have with social
robots, this leads to unexpected human-robot interactions in these public
spaces that are rarely discussed or detected in other contexts. In this paper,
we describe atypical users we observed interacting with our robot, and those
who did not, during a three-day pilot deployment within a large working church
and visitor attraction. We then discuss theoretical future advances in the
field that could address these challenges, as well as immediate practical
mitigations and strategies to help improve public space human-robot
interactions in the present. This work contributes empirical insights into the
dynamics of human-robot interaction in public environments and offers
actionable guidance for more effective future deployments for social robot
designers.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [58] [Collaborative-Online-Learning-Enabled Distributionally Robust Motion Control for Multi-Robot Systems](https://arxiv.org/abs/2508.17173)
*Chao Ning,Han Wang,Longyan Li,Yang Shi*

Main category: math.OC

TL;DR: 提出了一种新颖的协作在线学习（COOL）框架，用于多机器人系统的运动控制，以避免在随机移动障碍物中发生碰撞，并通过高效的数据交换和优化方法实现了性能与计算时间的平衡。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在随机移动障碍物环境中的碰撞避免是一个重要问题，尤其是在障碍物运动分布部分可见且数据获取受限的情况下。

Method: 采用基于狄利克雷过程混合模型的COOL方法提取运动分布信息，构建数据流驱动的障碍物运动模糊集，并提出模糊集传播方法和压缩方案以优化控制性能。

Result: 通过数值模拟验证了该方法在碰撞避免和跟踪性能上的优越性。

Conclusion: 该框架在多机器人系统的运动控制中表现优异，实现了高效的数据处理和可靠的碰撞避免。

Abstract: This paper develops a novel COllaborative-Online-Learning (COOL)-enabled
motion control framework for multi-robot systems to avoid collision amid
randomly moving obstacles whose motion distributions are partially observable
through decentralized data streams. To address the notable challenge of data
acquisition due to occlusion, a COOL approach based on the Dirichlet process
mixture model is proposed to efficiently extract motion distribution
information by exchanging among robots selected learning structures. By
leveraging the fine-grained local-moment information learned through COOL, a
data-stream-driven ambiguity set for obstacle motion is constructed. We then
introduce a novel ambiguity set propagation method, which theoretically admits
the derivation of the ambiguity sets for obstacle positions over the entire
prediction horizon by utilizing obstacle current positions and the ambiguity
set for obstacle motion. Additionally, we develop a compression scheme with its
safety guarantee to automatically adjust the complexity and granularity of the
ambiguity set by aggregating basic ambiguity sets that are close in a measure
space, thereby striking an attractive trade-off between control performance and
computation time. Then the probabilistic collision-free trajectories are
generated through distributionally robust optimization problems. The
distributionally robust obstacle avoidance constraints based on the compressed
ambiguity set are equivalently reformulated by deriving separating hyperplanes
through tractable semi-definite programming. Finally, we establish the
probabilistic collision avoidance guarantee and the long-term tracking
performance guarantee for the proposed framework. The numerical simulations are
used to demonstrate the efficacy and superiority of the proposed approach
compared with state-of-the-art methods.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [59] [Performance Validation of Coded Wavefront Sensing for Quantitative Phase Imaging of Static and Dynamic Specimens Using Digital Holographic Microscopy](https://arxiv.org/abs/2508.17143)
*Syed Muhammad Kazim,Franziska Strasser,Mia Kvåle Løvmo,Andrii Nehrych,Simon Moser,Michał Ziemczonok,Wolfgang Heidrich,Ivo Ihrke,Monika Ritsch-Marte*

Main category: physics.optics

TL;DR: 该论文研究了一种称为Coded-WFS的定量相位成像技术，通过静态硅珠和动态HEK细胞实验验证其相位恢复准确性，并与数字全息显微镜（DHM）进行对比。


<details>
  <summary>Details</summary>
Motivation: 验证Coded-WFS技术在定量相位成像中的准确性，尤其是在生物样本中的应用。

Method: 使用Coded-WFS对静态硅珠和动态HEK细胞进行定量相位成像，并与DHM的成像结果进行对比验证。

Result: 通过实验表明Coded-WFS能够准确恢复相位，并与DHM的结果一致。

Conclusion: Coded-WFS是一种有效的定量相位成像技术，适合用于生物样本的相位恢复。

Abstract: Coded wavefront sensing (Coded-WFS) is a snapshot quantitative phase imaging
(QPI) technique that has been shown to successfully leverage the memory effect
to retrieve the phase of biological specimens. In this paper, we perform QPI on
static silica beads and dynamic HEK cells using Coded-WFS. The accuracy of the
retrieved phase map is validated using digital holographic microscopy (DHM) for
the same specimens. We report comparisons of simultaneous bright-field
intensity and optical path delay.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [60] [SoK: Cybersecurity Assessment of Humanoid Ecosystem](https://arxiv.org/abs/2508.17481)
*Priyanka Prakash Surve,Asaf Shabtai,Yuval Elovici*

Main category: cs.CR

TL;DR: 该论文提出了一种系统性的人形机器人安全模型，整合了39种攻击和35种防御措施，并通过定量分析评估了三种真实机器人的安全性。


<details>
  <summary>Details</summary>
Motivation: 由于人形机器人在多个领域的广泛应用及其独特的网络安全风险，现有研究往往局限于特定威胁，缺乏对攻击在系统中连锁效应的全面分析。

Method: 通过知识系统化（SoK）构建了七层安全模型，设计了39x35的攻击-防御矩阵，并采用蒙特卡洛分析验证。

Result: 评估了三种机器人（Pepper、G1 EDU、Digit），安全成熟度得分范围为39.9%至79.5%。

Conclusion: 该方法提供了结构化、基于证据的安全评估，支持跨平台安全基准测试和投资优先级设定。

Abstract: Humanoids are progressing toward practical deployment across healthcare,
industrial, defense, and service sectors. While typically considered
cyber-physical systems (CPSs), their dependence on traditional networked
software stacks (e.g., Linux operating systems), robot operating system (ROS)
middleware, and over-the-air update channels, creates a distinct security
profile that exposes them to vulnerabilities conventional CPS models do not
fully address. Prior studies have mainly examined specific threats, such as
LiDAR spoofing or adversarial machine learning (AML). This narrow focus
overlooks how an attack targeting one component can cascade harm throughout the
robot's interconnected systems. We address this gap through a systematization
of knowledge (SoK) that takes a comprehensive approach, consolidating
fragmented research from robotics, CPS, and network security domains. We
introduce a seven-layer security model for humanoid robots, organizing 39 known
attacks and 35 defenses across the humanoid ecosystem-from hardware to
human-robot interaction. Building on this security model, we develop a
quantitative 39x35 attack-defense matrix with risk-weighted scoring, validated
through Monte Carlo analysis. We demonstrate our method by evaluating three
real-world robots: Pepper, G1 EDU, and Digit. The scoring analysis revealed
varying security maturity levels, with scores ranging from 39.9% to 79.5%
across the platforms. This work introduces a structured, evidence-based
assessment method that enables systematic security evaluation, supports
cross-platform benchmarking, and guides prioritization of security investments
in humanoid robotics.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [61] [Random-phase Gaussian Wave Splatting for Computer-generated Holography](https://arxiv.org/abs/2508.17480)
*Brian Chao,Jacqueline Yang,Suyeon Choi,Manu Gopakumar,Ryota Koiso,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 随机相位高斯波撒射（GWS-RP）通过改进带宽利用率和新的波前合成方法，显著提升了近眼全息显示的质量和应用效果。


<details>
  <summary>Details</summary>
Motivation: GWS方法在平滑相位假设下无法准确建模视角依赖效应和散焦模糊，限制了SLM的空间带宽利用率。GWS-RP旨在解决这些问题。

Method: 提出GWS-RP，包括新的波前合成方法和针对随机相位高斯的alpha混合方案，并首次严格推导了随机相位高斯的应用算法。

Result: 通过仿真和实验验证，GWS-RP实现了全带宽光场CGH，支持准确的视差和散焦，提供了先进的图像质量和感知真实的3D全息图。

Conclusion: GWS-RP通过随机相位和时间复用技术，显著提升了近眼全息显示的性能，为下一代设备提供了高质量的解决方案。

Abstract: Holographic near-eye displays offer ultra-compact form factors for virtual
and augmented reality systems, but rely on advanced computer-generated
holography (CGH) algorithms to convert 3D scenes into interference patterns
that can be displayed on spatial light modulators (SLMs). Gaussian Wave
Splatting (GWS) has recently emerged as a powerful CGH paradigm that allows for
the conversion of Gaussians, a state-of-the-art neural 3D representation, into
holograms. However, GWS assumes smooth-phase distributions over the Gaussian
primitives, limiting their ability to model view-dependent effects and
reconstruct accurate defocus blur, and severely under-utilizing the
space-bandwidth product of the SLM. In this work, we propose random-phase GWS
(GWS-RP) to improve bandwidth utilization, which has the effect of increasing
eyebox size, reconstructing accurate defocus blur and parallax, and supporting
time-multiplexed rendering to suppress speckle artifacts.
  At the core of GWS-RP are (1) a fundamentally new wavefront compositing
procedure and (2) an alpha-blending scheme specifically designed for
random-phase Gaussian primitives, ensuring physically correct color
reconstruction and robust occlusion handling. Additionally, we present the
first formally derived algorithm for applying random phase to Gaussian
primitives, grounded in rigorous statistical optics analysis and validated
through practical near-eye display applications. Through extensive simulations
and experimental validations, we demonstrate that these advancements,
collectively with time-multiplexing, uniquely enables full-bandwith light field
CGH that supports accurate accurate parallax and defocus, yielding
state-of-the-art image quality and perceptually faithful 3D holograms for
next-generation near-eye displays.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [62] [Riemannian Change Point Detection on Manifolds with Robust Centroid Estimation](https://arxiv.org/abs/2508.18045)
*Xiuheng Wang,Ricardo Borsoi,Arnaud Breloy,Cédric Richard*

Main category: cs.LG

TL;DR: 该论文提出了一种非参数化的流式时空数据变点检测方法，利用流形上的鲁棒质心来减少对步长调优的依赖，并通过与经典Karcher均值的对比提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在流式时空数据中使用质心变化检测变点时，需要精细的步长调优。论文旨在通过引入鲁棒质心来减少这种依赖性。

Method: 提出了一种基于M估计理论的鲁棒质心方法，通过比较Karcher均值（对变化敏感）和基于Huber函数的鲁棒质心（对变化鲁棒）来定义测试统计量。

Result: 在两种典型流形上的模拟和真实数据实验中，该方法表现出优越性能。

Conclusion: 该研究为流式时空数据中的非参数变点检测提供了更鲁棒且高效的方法。

Abstract: Non-parametric change-point detection in streaming time series data is a
long-standing challenge in signal processing. Recent advancements in statistics
and machine learning have increasingly addressed this problem for data residing
on Riemannian manifolds. One prominent strategy involves monitoring abrupt
changes in the center of mass of the time series. Implemented in a streaming
fashion, this strategy, however, requires careful step size tuning when
computing the updates of the center of mass. In this paper, we propose to
leverage robust centroid on manifolds from M-estimation theory to address this
issue. Our proposal consists of comparing two centroid estimates: the classical
Karcher mean (sensitive to change) versus one defined from Huber's function
(robust to change). This comparison leads to the definition of a test statistic
whose performance is less sensitive to the underlying estimation method. We
propose a stochastic Riemannian optimization algorithm to estimate both robust
centroids efficiently. Experiments conducted on both simulated and real-world
data across two representative manifolds demonstrate the superior performance
of our proposed method.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [63] [Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.17971)
*Pu Feng,Size Wang,Yuhong Cao,Junkang Liang,Rongye Shi,Wenjun Wu*

Main category: cs.AI

TL;DR: 论文提出了一种结合神经算法推理器（NAR）和大语言模型（LLM）的新框架LLM-NAR，用于解决多智能体路径规划（MAPF）问题，显著提升了现有LLM方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在多智能体路径规划任务中表现不佳，亟需一种结合规划与多智能体协调的新方法。

Method: 提出了LLM-NAR框架，包含LLM、图神经网络NAR和交叉注意力机制，首次将GNN与地图信息结合用于指导LLM。

Result: 仿真和真实实验表明，该方法在多智能体路径规划任务中显著优于现有LLM方法。

Conclusion: LLM-NAR框架通过结合神经算法推理器，有效提升了LLM在多智能体路径规划中的性能，且易于适配不同LLM模型。

Abstract: The development and application of large language models (LLM) have
demonstrated that foundational models can be utilized to solve a wide array of
tasks. However, their performance in multi-agent path finding (MAPF) tasks has
been less than satisfactory, with only a few studies exploring this area. MAPF
is a complex problem requiring both planning and multi-agent coordination. To
improve the performance of LLM in MAPF tasks, we propose a novel framework,
LLM-NAR, which leverages neural algorithmic reasoners (NAR) to inform LLM for
MAPF. LLM-NAR consists of three key components: an LLM for MAPF, a pre-trained
graph neural network-based NAR, and a cross-attention mechanism. This is the
first work to propose using a neural algorithmic reasoner to integrate GNNs
with the map information for MAPF, thereby guiding LLM to achieve superior
performance. LLM-NAR can be easily adapted to various LLM models. Both
simulation and real-world experiments demonstrate that our method significantly
outperforms existing LLM-based approaches in solving MAPF problems.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [64] [Blind Deconvolution of Nonstationary Graph Signals over Shift-Invariant Channels](https://arxiv.org/abs/2508.17210)
*Ali Zare,Yao Shi,Qiyu Sun*

Main category: cs.IT

TL;DR: 研究非平稳图信号在未知恒定信道中的盲反卷积问题，使用温度数据集验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 解决非平稳图信号在未知信道中的盲反卷积问题，假设已知原始信号的协方差结构。

Method: 通过盲反卷积和信道估计技术处理信号，利用温度数据集进行数值实验验证。

Result: 实验结果表明方法的有效性。

Conclusion: 盲反卷积方法可用于非平稳图信号的恢复，为实际应用提供了可能。

Abstract: In this paper, we investigate blind deconvolution of nonstationary graph
signals from noisy observations, transmitted through an unknown shift-invariant
channel. The deconvolution process assumes that the observer has access to the
covariance structure of the original graph signals. To evaluate the
effectiveness of our channel estimation and blind deconvolution method, we
conduct numerical experiments using a temperature dataset in the Brest region
of France.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [65] [Physical Embodiment Enables Information Processing Beyond Explicit Sensing in Active Matter](https://arxiv.org/abs/2508.17921)
*Diptabrata Paul,Nikola Milosevic,Nico Scherf,Frank Cichos*

Main category: cond-mat.soft

TL;DR: 合成活性粒子通过物理体现（无需明确感知机制）适应隐藏的流体动力学扰动，利用强化学习实现自主导航，揭示物理动态可作为隐含感知机制。


<details>
  <summary>Details</summary>
Motivation: 研究如何在合成活性物质中复制生物体的环境感知与适应能力，以解决自主微机器人系统的信息处理挑战。

Method: 使用强化学习控制自热泳粒子，训练它们在未观测到的流场中学习导航策略。

Result: 粒子能够成功应对未包含在输入状态中的扰动，验证物理动态可作为隐含感知机制。

Conclusion: 物理体现为活性物质提供了一种新的信息处理资源，对自主微机器人和仿生计算具有重要启示。

Abstract: Living microorganisms have evolved dedicated sensory machinery to detect
environmental perturbations, processing these signals through biochemical
networks to guide behavior. Replicating such capabilities in synthetic active
matter remains a fundamental challenge. Here, we demonstrate that synthetic
active particles can adapt to hidden hydrodynamic perturbations through
physical embodiment alone, without explicit sensing mechanisms. Using
reinforcement learning to control self-thermophoretic particles, we show that
they learn navigation strategies to counteract unobserved flow fields by
exploiting information encoded in their physical dynamics. Remarkably,
particles successfully navigate perturbations that are not included in their
state inputs, revealing that embodied dynamics can serve as an implicit sensing
mechanism. This discovery establishes physical embodiment as a computational
resource for information processing in active matter, with implications for
autonomous microrobotic systems and bio-inspired computation.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [66] [In-Memory Computing Enabled Deep MIMO Detection to Support Ultra-Low-Latency Communications](https://arxiv.org/abs/2508.17820)
*Tingyu Ding,Qunsong Zeng,Kaibin Huang*

Main category: cs.AR

TL;DR: 本文提出了一种基于内存计算的深度MIMO检测器（IM-MIMO），以应对6G网络对低延迟和高可靠性的需求，通过模块化设计和定制化训练方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 6G网络对MIMO系统的延迟和可靠性提出更高要求，现有算法和硬件设计无法满足需求，需要结合内存计算和深度学习改进。

Method: 提出IM-MIMO检测器架构，将计算模块分为信道相关和无关部分以减少延迟，并开发定制化训练方法增强对编程噪声的鲁棒性。

Result: 通过实验评估了检测器在精度、延迟和硬件复杂度方面的表现，量化了误差与信道噪声、编程噪声及网络规模的关系。

Conclusion: IM-MIMO检测器结合内存计算和深度学习，显著提升了6G网络下的MIMO检测性能，为未来通信系统提供了有效解决方案。

Abstract: The development of sixth-generation (6G) mobile networks imposes
unprecedented latency and reliability demands on multiple-input multiple-output
(MIMO) communication systems, a key enabler of high-speed radio access.
Recently, deep unfolding-based detectors, which map iterative algorithms onto
neural network architectures, have emerged as a promising approach, combining
the strengths of model-driven and data-driven methods to achieve high detection
accuracy with relatively low complexity. However, algorithmic innovation alone
is insufficient; software-hardware co-design is essential to meet the extreme
latency requirements of 6G (i.e., 0.1 milliseconds). This motivates us to
propose leveraging in-memory computing, which is an analog computing technology
that integrates memory and computation within memristor circuits, to perform
the intensive matrix-vector multiplication (MVM) operations inherent in deep
MIMO detection at the nanosecond scale. Specifically, we introduce a novel
architecture, called the deep in-memory MIMO (IM-MIMO) detector, characterized
by two key features. First, each of its cascaded computational blocks is
decomposed into channel-dependent and channel-independent neural network
modules. Such a design minimizes the latency of memristor reprogramming in
response to channel variations, which significantly exceeds computation time.
Second, we develop a customized detector-training method that exploits prior
knowledge of memristor-value statistics to enhance robustness against
programming noise. Furthermore, we conduct a comprehensive analysis of the
IM-MIMO detector's performance, evaluating detection accuracy, processing
latency, and hardware complexity. Our study quantifies detection error as a
function of various factors, including channel noise, memristor programming
noise, and neural network size.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [67] [Beamforming Control in RIS-Aided Wireless Communications: A Predictive Physics-Based Approach](https://arxiv.org/abs/2508.16980)
*Luis C. Mathias,Atefeh Termehchi,Taufik Abrão,Ekram Hossain*

Main category: eess.SY

TL;DR: 本文提出一种基于物理学的解决方案，通过运动观测器和预测器实现RIS的主动控制，以解决移动用户位置变化导致的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 传统RIS波束成形控制因更新延迟导致信道条件变化，尤其在移动用户快速运动时，难以实时调整波束方向。

Method: 提出基于运动观测器和预测器的方案，利用低频位置估计推断用户速度和加速度，预测未来位置并实时调整RIS。

Result: 数值结果显示，该方案在快速移动场景下能实现低计算复杂度的实时RIS调整。

Conclusion: 该方案有效解决了移动用户位置变化导致的RIS控制延迟问题，具有实用性和可扩展性。

Abstract: Integrating reconfigurable intelligent surfaces (RIS) into wireless
communication systems is a promising approach for enhancing coverage and data
rates by intelligently redirecting signals, through a process known as
beamforming. However, the process of RIS beamforming (or passive beamforming)
control is associated with multiple latency-inducing factors. As a result, by
the time the beamforming is effectively updated, the channel conditions may
have already changed. For example, the low update rate of localization systems
becomes a critical limitation, as a mobile UE's position may change
significantly between two consecutive measurements. To address this issue, this
work proposes a practical and scalable physics-based solution that is effective
across a wide range of UE movement models. Specifically, we propose a kinematic
observer and predictor to enable proactive RIS control. From low-rate position
estimates provided by a localizer, the kinematic observer infers the UE's speed
and acceleration. These motion parameters are then used by a predictor to
estimate the UE's future positions at a higher rate, allowing the RIS to adjust
promptly and compensate for inherent delays in both the RIS control and
localization systems. Numerical results validate the effectiveness of the
proposed approach, demonstrating real-time RIS adjustments with low
computational complexity, even in scenarios involving rapid UE movement.

</details>


### [68] [Enhancing Energy and Spectral Efficiency in IoT-Cellular Networks via Active SIM-Equipped LEO Satellites](https://arxiv.org/abs/2508.17149)
*Rahman Saadat Yeganeh,Hamid Behroozi,Mohammad Javad Omidi,Mohammad Robat Mili,Eduard A. Jorswieck,Symeon Chatzinotas*

Main category: eess.SY

TL;DR: 本文研究了通过主动堆叠智能超表面（ASIM）增强的低地球轨道（LEO）卫星通信系统，提出了一种高效利用卫星空间并降低功率需求的解决方案。


<details>
  <summary>Details</summary>
Motivation: 旨在提升LEO卫星通信的效率与性能，解决卫星空间有限和功率需求高的问题。

Method: 采用ASIM技术并结合多用户访问策略（RSMA）和物联网设备共生网络，通过三种优化算法（BCD-SCA、MA-CSAC、MCPPO）进行性能优化。

Result: 实验结果显示，不同的优化算法在不同场景下表现各异，但整体上ASIM与优化算法结合可显著提升频谱和能量效率。

Conclusion: 研究表明，多层ASIM结合合适的优化算法为下一代LEO卫星通信提供了可扩展、高能效且高性能的解决方案。

Abstract: This paper investigates a low Earth orbit (LEO) satellite communication
system enhanced by an active stacked intelligent metasurface (ASIM), mounted on
the backplate of the satellite solar panels to efficiently utilize limited
onboard space and reduce the main satellite power amplifier requirements. The
system serves multiple ground users via rate-splitting multiple access (RSMA)
and IoT devices through a symbiotic radio network. Multi-layer sequential
processing in the ASIM improves effective channel gains and suppresses
inter-user interference, outperforming active RIS and beyond-diagonal RIS
designs. Three optimization approaches are evaluated: block coordinate descent
with successive convex approximation (BCD-SCA), model-assisted multi-agent
constraint soft actor-critic (MA-CSAC), and multi-constraint proximal policy
optimization (MCPPO). Simulation results show that BCD-SCA converges fast and
stably in convex scenarios without learning, MCPPO achieves rapid initial
convergence with moderate stability, and MA-CSAC attains the highest long-term
spectral and energy efficiency in large-scale networks. Energy-spectral
efficiency trade-offs are analyzed for different ASIM elements, satellite
antennas, and transmit power. Overall, the study demonstrates that integrating
multi-layer ASIM with suitable optimization algorithms offers a scalable,
energy-efficient, and high-performance solution for next-generation LEO
satellite communications.

</details>


### [69] [Dimension-Decomposed Learning for Quadrotor Geometric Attitude Control with Almost Global Exponential Convergence on SO(3)](https://arxiv.org/abs/2508.14422)
*Tianhua Gao,Masashi Izumita,Kohji Tomita,Akiya Kamimura*

Main category: eess.SY

TL;DR: 提出了一种轻量级且可解释的在线学习方法DiD-L，用于四旋翼几何姿态控制中的扰动识别，包含模块SANM。通过分解高维映射为低维子任务，解决了欠拟合问题，并在不满足PE条件的情况下实现了指数收敛。


<details>
  <summary>Details</summary>
Motivation: 针对四旋翼控制中的扰动识别问题，传统方法难以在实时性和轻量化上满足要求，且缺乏可解释性。

Method: 提出了DiD-L框架及其模块SANM，将高维映射分解为低维子任务，利用浅层神经网络和自适应律在线更新。

Result: 在不满足PE条件的情况下，实现了状态解的指数收敛，且方法足够轻量化，可在MCU上实时运行。

Conclusion: DiD-L是首个在四旋翼控制领域同时满足轻量化、实时性和可解释性的在线学习方法。

Abstract: This paper introduces a lightweight and interpretable online learning
approach called Dimension-Decomposed Learning (DiD-L) for disturbance
identification in quadrotor geometric attitude control. As a module instance of
DiD-L, we propose the Sliced Adaptive-Neuro Mapping (SANM). Specifically, to
address underlying underfitting problems, the high-dimensional mapping for
online identification is axially ``sliced" into multiple low-dimensional
submappings (slices). In this way, the complex high-dimensional problem is
decomposed into a set of simple low-dimensional subtasks addressed by shallow
neural networks and adaptive laws. These neural networks and adaptive laws are
updated online via Lyapunov-based adaptation without the persistent excitation
(PE) condition. To enhance the interpretability of the proposed approach, we
prove that the state solution of the rotational error dynamics exponentially
converges into an arbitrarily small ball within an almost global attraction
domain, despite time-varying disturbances and inertia uncertainties. This
result is novel as it demonstrates exponential convergence without requiring
pre-training for unseen disturbances and specific knowledge of the model. To
our knowledge in the quadrotor control field, DiD-L is the first online
learning approach that is lightweight enough to run in real-time at 400 Hz on
microcontroller units (MCUs) such as STM32, and has been validated through
real-world experiments.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [70] [Fiducial Marker Splatting for High-Fidelity Robotics Simulations](https://arxiv.org/abs/2508.17012)
*Diram Tabaa,Gianni Di Caro*

Main category: cs.CV

TL;DR: 提出了一种结合高斯泼溅和结构化标记的混合框架，用于高保真3D仿真，特别适用于复杂环境如温室。


<details>
  <summary>Details</summary>
Motivation: 传统基于网格的仿真方法在复杂环境中表现不佳，而现有神经渲染方法虽真实但缺乏标记灵活性，无法满足机器人定位需求。

Method: 采用高斯泼溅与结构化标记结合的混合框架，开发了高效生成高斯泼溅标记的新算法。

Result: 实验表明，该方法在效率和姿态估计精度上优于传统图像拟合技术，并在温室仿真中验证了其潜力。

Conclusion: 该框架在复杂环境中表现出色，具有实际应用价值，尤其是在农业等挑战性场景中。

Abstract: High-fidelity 3D simulation is critical for training mobile robots, but its
traditional reliance on mesh-based representations often struggle in complex
environments, such as densely packed greenhouses featuring occlusions and
repetitive structures. Recent neural rendering methods, like Gaussian Splatting
(GS), achieve remarkable visual realism but lack flexibility to incorporate
fiducial markers, which are essential for robotic localization and control. We
propose a hybrid framework that combines the photorealism of GS with structured
marker representations. Our core contribution is a novel algorithm for
efficiently generating GS-based fiducial markers (e.g., AprilTags) within
cluttered scenes. Experiments show that our approach outperforms traditional
image-fitting techniques in both efficiency and pose-estimation accuracy. We
further demonstrate the framework's potential in a greenhouse simulation. This
agricultural setting serves as a challenging testbed, as its combination of
dense foliage, similar-looking elements, and occlusions pushes the limits of
perception, thereby highlighting the framework's value for real-world
applications.

</details>


### [71] [M3DMap: Object-aware Multimodal 3D Mapping for Dynamic Environments](https://arxiv.org/abs/2508.17044)
*Dmitry Yudin*

Main category: cs.CV

TL;DR: 该论文提出了一种用于构建多模态3D地图的分类方法，并提出了一个模块化方法M3DMap，用于静态和动态场景的3D地图构建。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中3D地图构建的挑战，缺乏多模态数据的通用表示方法。

Method: 提出分类法（taxonomy）和模块化方法M3DMap，包含目标分割与跟踪、里程计估计、地图构建与更新以及多模态数据检索模块。

Result: 展示了M3DMap在多种实际任务中的优势，并验证了多模态数据和基础模型对3D地图构建的积极影响。

Conclusion: 论文为实现动态环境下多模态3D地图构建提供了理论和方法支持。

Abstract: 3D mapping in dynamic environments poses a challenge for modern researchers
in robotics and autonomous transportation. There are no universal
representations for dynamic 3D scenes that incorporate multimodal data such as
images, point clouds, and text. This article takes a step toward solving this
problem. It proposes a taxonomy of methods for constructing multimodal 3D maps,
classifying contemporary approaches based on scene types and representations,
learning methods, and practical applications. Using this taxonomy, a brief
structured analysis of recent methods is provided. The article also describes
an original modular method called M3DMap, designed for object-aware
construction of multimodal 3D maps for both static and dynamic scenes. It
consists of several interconnected components: a neural multimodal object
segmentation and tracking module; an odometry estimation module, including
trainable algorithms; a module for 3D map construction and updating with
various implementations depending on the desired scene representation; and a
multimodal data retrieval module. The article highlights original
implementations of these modules and their advantages in solving various
practical tasks, from 3D object grounding to mobile manipulation. Additionally,
it presents theoretical propositions demonstrating the positive effect of using
multimodal data and modern foundational models in 3D mapping methods. Details
of the taxonomy and method implementation are available at
https://yuddim.github.io/M3DMap.

</details>


### [72] [DeltaFlow: An Efficient Multi-frame Scene Flow Estimation Method](https://arxiv.org/abs/2508.17054)
*Qingwen Zhang,Xiaomeng Zhu,Yushan Zhang,Yixi Cai,Olov Andersson,Patric Jensfelt*

Main category: cs.CV

TL;DR: DeltaFlow（ΔFlow）是一个轻量级的3D框架，通过Δ方案高效捕捉运动线索，引入类别平衡损失和实例一致性损失解决场景流估计中的问题，实现性能和效率的提升。


<details>
  <summary>Details</summary>
Motivation: 现有场景流估计方法主要依赖两帧输入，忽略时间域信息；多帧方法计算成本高，因此需要更高效的框架。

Method: 提出ΔFlow框架，利用Δ方案低成本提取时间特征，并引入类别平衡损失和实例一致性损失。

Result: 在Argoverse 2和Waymo数据集上表现优异，误差降低22%，推理速度提升2倍，且具有强跨域泛化能力。

Conclusion: DeltaFlow在性能和效率上均优于现有方法，解决了多帧计算成本和场景流估计中的分布与一致性挑战。

Abstract: Previous dominant methods for scene flow estimation focus mainly on input
from two consecutive frames, neglecting valuable information in the temporal
domain. While recent trends shift towards multi-frame reasoning, they suffer
from rapidly escalating computational costs as the number of frames grows. To
leverage temporal information more efficiently, we propose DeltaFlow
($\Delta$Flow), a lightweight 3D framework that captures motion cues via a
$\Delta$ scheme, extracting temporal features with minimal computational cost,
regardless of the number of frames. Additionally, scene flow estimation faces
challenges such as imbalanced object class distributions and motion
inconsistency. To tackle these issues, we introduce a Category-Balanced Loss to
enhance learning across underrepresented classes and an Instance Consistency
Loss to enforce coherent object motion, improving flow accuracy. Extensive
evaluations on the Argoverse 2 and Waymo datasets show that $\Delta$Flow
achieves state-of-the-art performance with up to 22% lower error and $2\times$
faster inference compared to the next-best multi-frame supervised method, while
also demonstrating a strong cross-domain generalization ability. The code is
open-sourced at https://github.com/Kin-Zhang/DeltaFlow along with trained model
weights.

</details>


### [73] [SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality](https://arxiv.org/abs/2508.17255)
*Yuzhi Lai,Shenghai Yuan,Peizheng Li,Jun Lou,Andreas Zell*

Main category: cs.CV

TL;DR: SEER-VAR是一种用于车辆AR的新框架，结合语义分解、上下文感知SLAM分支和LLM驱动的推荐，提升驾驶场景的AR效果。


<details>
  <summary>Details</summary>
Motivation: 现有的AR系统假设静态或单视图设置，无法适应动态驾驶场景的需求，因此提出SEER-VAR以解决这一问题。

Method: 通过深度引导的视觉-语言基础动态分离驾驶舱和道路场景，使用两条SLAM分支跟踪运动，并利用GPT生成上下文感知的AR叠加内容。

Result: 实验表明，SEER-VAR在多样化环境中实现了鲁棒的空间对齐和感知一致的AR渲染，并通过用户研究验证了其效果。

Conclusion: SEER-VAR为未来基于LLM的AR研究提供了有效基础，代码和数据集将开源。

Abstract: We present SEER-VAR, a novel framework for egocentric vehicle-based augmented
reality (AR) that unifies semantic decomposition, Context-Aware SLAM Branches
(CASB), and LLM-driven recommendation. Unlike existing systems that assume
static or single-view settings, SEER-VAR dynamically separates cabin and road
scenes via depth-guided vision-language grounding. Two SLAM branches track
egocentric motion in each context, while a GPT-based module generates
context-aware overlays such as dashboard cues and hazard alerts. To support
evaluation, we introduce EgoSLAM-Drive, a real-world dataset featuring
synchronized egocentric views, 6DoF ground-truth poses, and AR annotations
across diverse driving scenarios. Experiments demonstrate that SEER-VAR
achieves robust spatial alignment and perceptually coherent AR rendering across
varied environments. As one of the first to explore LLM-based AR recommendation
in egocentric driving, we address the lack of comparable systems through
structured prompting and detailed user studies. Results show that SEER-VAR
enhances perceived scene understanding, overlay relevance, and driver ease,
providing an effective foundation for future research in this direction. Code
and dataset will be made open source.

</details>


### [74] [Robust Point Cloud Registration via Geometric Overlapping Guided Rotation Search](https://arxiv.org/abs/2508.17427)
*Zhao Zheng,Jingfan Fan,Long Shao,Hong Song,Danni Ai,Tianyu Fu,Deqiang Xiao,Yongtian Wang,Jian Yang*

Main category: cs.CV

TL;DR: 本文提出了一种基于旋转-only BnB搜索的几何最大重叠配准框架，通过分解刚性变换并利用区间查询和线段树算法，显著提升了点云配准的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高离群比情况下性能受限，或因计算复杂度高而难以实用。

Method: 使用Chasles定理分解刚性变换，通过BnB搜索最优旋转轴和角度，并将残余参数作为区间查询问题解决。

Result: 在3DMatch等数据集上表现优于现有方法，时间和空间复杂度更优。

Conclusion: 该方法在精度和效率上均优于SOTA，且复杂度更低。

Abstract: Point cloud registration based on correspondences computes the rigid
transformation that maximizes the number of inliers constrained within the
noise threshold. Current state-of-the-art (SOTA) methods employing spatial
compatibility graphs or branch-and-bound (BnB) search mainly focus on
registration under high outlier ratios. However, graph-based methods require at
least quadratic space and time complexity for graph construction, while
multi-stage BnB search methods often suffer from inaccuracy due to local optima
between decomposed stages. This paper proposes a geometric maximum overlapping
registration framework via rotation-only BnB search. The rigid transformation
is decomposed using Chasles' theorem into a translation along rotation axis and
a 2D rigid transformation. The optimal rotation axis and angle are searched via
BnB, with residual parameters formulated as range maximum query (RMQ) problems.
Firstly, the top-k candidate rotation axes are searched within a hemisphere
parameterized by cube mapping, and the translation along each axis is estimated
through interval stabbing of the correspondences projected onto that axis.
Secondly, the 2D registration is relaxed to 1D rotation angle search with 2D
RMQ of geometric overlapping for axis-aligned rectangles, which is solved
deterministically in polynomial time using sweep line algorithm with segment
tree. Experimental results on 3DMatch, 3DLoMatch, and KITTI datasets
demonstrate superior accuracy and efficiency over SOTA methods, while the time
complexity is polynomial and the space complexity increases linearly with the
number of points, even in the worst case.

</details>


### [75] [A Synthetic Dataset for Manometry Recognition in Robotic Applications](https://arxiv.org/abs/2508.17468)
*Pedro Antonio Rabelo Saraiva,Enzo Ferreira de Souza,Joao Manoel Herrera Pinheiro,Thiago H. Segreto,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.CV

TL;DR: 提出了一种结合程序渲染与AI驱动视频生成的混合数据合成方法，用于解决工业环境中数据稀缺和高成本问题，显著提升目标检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂工业环境（如海上石油平台）中收集真实数据的困难和成本高昂问题，推动自主检测系统的发展。

Method: 采用BlenderProc生成逼真图像，结合NVIDIA的Cosmos-Predict2模型合成物理合理的视频序列，通过域随机化和混合真实数据训练YOLO模型。

Result: 混合真实与合成数据的训练显著优于仅用真实数据训练的模型，尤其是1:1比例效果最佳。

Conclusion: 合成数据优先方法为安全关键且资源有限的工业应用提供了一种高效、经济且可靠的解决方案。

Abstract: This work addresses the challenges of data scarcity and high acquisition
costs for training robust object detection models in complex industrial
environments, such as offshore oil platforms. The practical and economic
barriers to collecting real-world data in these hazardous settings often hamper
the development of autonomous inspection systems. To overcome this, in this
work we propose and validate a hybrid data synthesis pipeline that combines
procedural rendering with AI-driven video generation. Our methodology leverages
BlenderProc to create photorealistic images with precise annotations and
controlled domain randomization, and integrates NVIDIA's Cosmos-Predict2
world-foundation model to synthesize physically plausible video sequences with
temporal diversity, capturing rare viewpoints and adverse conditions. We
demonstrate that a YOLO-based detection network trained on a composite dataset,
blending real images with our synthetic data, achieves superior performance
compared to models trained exclusively on real-world data. Notably, a 1:1
mixture of real and synthetic data yielded the highest accuracy, surpassing the
real-only baseline. These findings highlight the viability of a synthetic-first
approach as an efficient, cost-effective, and safe alternative for developing
reliable perception systems in safety-critical and resource-constrained
industrial applications.

</details>


### [76] [BirdRecorder's AI on Sky: Safeguarding birds of prey by detection and classification of tiny objects around wind turbines](https://arxiv.org/abs/2508.18136)
*Nico Klar,Nizam Gifary,Felix P. G. Ziegler,Frank Sehnke,Anton Kaifel,Eric Price,Aamir Ahmad*

Main category: cs.CV

TL;DR: 开发了AI驱动的防碰撞系统BirdRecorder，以减少风力发电对濒危鸟类的威胁。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源（尤其是风能）扩张与野生动物保护之间的冲突，保护濒危鸟类如红鸢。

Method: 结合机器人技术、遥测技术和高性能AI算法，采用SSD检测器和硬件加速，实现实时图像处理与鸟类追踪。

Result: BirdRecorder在精度和效率上优于现有方法，能有效减少风机与鸟类的碰撞。

Conclusion: BirdRecorder为可再生能源与自然保护的可持续共存提供了解决方案。

Abstract: The urgent need for renewable energy expansion, particularly wind power, is
hindered by conflicts with wildlife conservation. To address this, we developed
BirdRecorder, an advanced AI-based anti-collision system to protect endangered
birds, especially the red kite (Milvus milvus). Integrating robotics,
telemetry, and high-performance AI algorithms, BirdRecorder aims to detect,
track, and classify avian species within a range of 800 m to minimize
bird-turbine collisions.
  BirdRecorder integrates advanced AI methods with optimized hardware and
software architectures to enable real-time image processing. Leveraging Single
Shot Detector (SSD) for detection, combined with specialized hardware
acceleration and tracking algorithms, our system achieves high detection
precision while maintaining the speed necessary for real-time decision-making.
By combining these components, BirdRecorder outperforms existing approaches in
both accuracy and efficiency.
  In this paper, we summarize results on field tests and performance of the
BirdRecorder system. By bridging the gap between renewable energy expansion and
wildlife conservation, BirdRecorder contributes to a more sustainable
coexistence of technology and nature.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [77] [TSPC-PFD: TSPC-Based Low-Power High-Resolution CMOS Phase Frequency Detector](https://arxiv.org/abs/2508.16933)
*Dhandeep Challagundla,Venkata Krishna Vamsi Sundarapu,Ignatius Bezzam,Riadul Islam*

Main category: cs.ET

TL;DR: 该论文提出了一种新型低功耗的TSPC基相频检测器（PFD），解决了传统PFD的死区和盲区问题。


<details>
  <summary>Details</summary>
Motivation: 传统PFD在高频应用中存在显著的死区和盲区，影响了相位检测精度并增加了抖动，因此需要改进设计。

Method: 采用TSMC 28纳米技术实现了一种基于True Single-Phase Clock (TSPC)的新型PFD设计。

Result: 新型PFD完全消除了盲区，死区仅为40 ps，功耗低至4.41 uW（3 GHz输入频率），布局面积为10.42 μm²。

Conclusion: 该设计在高频应用中表现出色，解决了传统PFD的局限性，具有低功耗和小面积的优势。

Abstract: Phase Frequency Detectors (PFDs) are essential components in Phase-Locked
Loop (PLL) and Delay-Locked Loop (DLL) systems, responsible for comparing phase
and frequency differences and generating up/down signals to regulate charge
pumps and/or, consequently, Voltage-Controlled Oscillators (VCOs). Conventional
PFD designs often suffer from significant dead zones and blind zones, which
degrade phase detection accuracy and increase jitter in high-speed
applications. This paper addresses PFD design challenges and presents a novel
low-power True Single-Phase Clock (TSPC)-based PFD. The proposed design
eliminates the blind zone entirely while achieving a minimal dead zone of 40
ps. The proposed PFD, implemented using TSMC 28 nm technology, demonstrates a
low-power consumption of 4.41 uW at 3 GHz input frequency with a layout area of
$10.42\mu m^2$.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [78] [Localization using Angle-of-Arrival Triangulation](https://arxiv.org/abs/2508.16908)
*Amod K. Agrawal*

Main category: eess.AS

TL;DR: 介绍了一种基于语音信号的被动室内定位系统GCC+，通过智能设备捕捉声音并计算到达角和位置，无需硬件修改或用户配合，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决移动计算中室内定位的挑战，支持智能环境下的位置感知应用。

Method: 扩展GCC-PHAT方法估计到达角，结合稳健三角测量和子样本插值技术提高精度。

Result: 实验显示中位到达角误差2.2度，定位误差1.25米。

Conclusion: 音频定位在现实环境中可行且有效，适用于隐私保护的智能场景。

Abstract: Indoor localization is a long-standing challenge in mobile computing, with
significant implications for enabling location-aware and intelligent
applications within smart environments such as homes, offices, and retail
spaces. As AI assistants such as Amazon Alexa and Google Nest become
increasingly pervasive, microphone-equipped devices are emerging as key
components of everyday life and home automation. This paper introduces a
passive, infrastructure-light system for localizing human speakers using speech
signals captured by two or more spatially distributed smart devices. The
proposed approach, GCC+, extends the Generalized Cross-Correlation with Phase
Transform (GCC-PHAT) method to estimate the Angle-of-Arrival (AoA) of audio
signals at each device and applies robust triangulation techniques to infer the
speaker's two-dimensional position. To further improve temporal resolution and
localization accuracy, feature-space expansion and subsample interpolation
techniques are employed for precise Time Difference of Arrival (TDoA)
estimation. The system operates without requiring hardware modifications, prior
calibration, explicit user cooperation, or knowledge of the speaker's signal
content, thereby offering a highly practical solution for real-world
deployment. Experimental evaluation in a real-world home environment yields a
median AoA estimation error of 2.2 degrees and a median localization error of
1.25 m, demonstrating the feasibility and effectiveness of audio-based
localization for enabling context-aware, privacy-preserving ambient
intelligence.

</details>
