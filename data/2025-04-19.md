<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.SY](#eess.SY) [Total: 8]
- [cs.IT](#cs.IT) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.RO](#cs.RO) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Attention-Infused Autoencoder for Massive MIMO CSI Compression](https://arxiv.org/abs/2504.12440)
*Kangzhi Lou,Xiping Wu*

Main category: eess.SP

TL;DR: 该论文提出了一种名为AiANet的新型基于自动编码器的学习方法，通过注意力融合机制并行自适应地提取CSI的信道和空间特征，提高了跨场景的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着6G系统中MIMO天线数量的增加，CSI压缩对减少反馈开销至关重要。现有学习方法泛化能力有限，无法适应不同场景的信道特性差异。

Method: 提出AiANet，结合注意力机制提取全局和局部空间模式，并使用混合训练方案提升跨场景泛化能力。

Result: AiANet在同一场景下性能优于现有方法（NMSE提升达3.42 dB），并在跨场景测试中表现更优。

Conclusion: AiANet通过注意力机制和混合训练方案，显著提升了CSI压缩的性能和泛化能力。

Abstract: As the number of multiple-input multiple-output (MIMO) antennas increases
drastically with the development towards 6G systems, channel state information
(CSI) compression becomes crucial for mitigating feedback overhead. In recent
years, learning models such as autoencoders (AE) have been studied for CSI
compression, aiming to eliminate model assumptions and reduce compression loss.
However, current learning methods are often designed and trained mainly for
individual channel scenarios, with limited generalizability across different
scenarios, of which the channel characteristics are prominently discrepant.
Motivated by this, we propose a novel AE-based learning method named
attention-infused autoencoder network (AiANet), which can parallelly and
adaptively extract channel-wise and spatial features of CSI with an attention
fusion mechanism. In addition, a locally-aware self-attention mechanism is
developed to extract both global and local spatial patterns, to better capture
the unique CSI features of different scenarios. Moreover, a mixed-training
scheme is introduced to enable the proposed AiANet to gain generalizability
across indoor and outdoor scenarios. Results show that when trained and tested
in the same scenario, AiANet can substantially outperform the existing AE-based
methods such as ACRNet, with an improvement of up to 3.42 dB in terms of
normalized mean squared error (NMSE). With the mixed-training scheme, AiANet
exhibits superior cross-scenario generalizability compared to the benchmark
methods which are trained in one scenario and misused in another.

</details>


### [2] [Fast Computation of the Discrete Fourier Transform Rectangular Index Coefficients](https://arxiv.org/abs/2504.12551)
*Saulo Queiroz,João P. Vilela,Benjamin Koon Kei Ng,Chan-Tong Lam,Edmundo Monteiro*

Main category: eess.SP

TL;DR: 该论文将方形索引系数（SICs）推广为矩形索引系数（RICs），提出一种无乘法压缩算法，显著加速特定DFT系数的计算。


<details>
  <summary>Details</summary>
Motivation: 基于SICs的压缩方法，进一步扩展到更通用的RICs，以提升特定频率分析的效率。

Method: 提出一种将N点信号压缩为C点信号的算法，仅需O(N)加法运算，无乘法运算。

Result: 通过压缩信号和FFT结合，以O(C log C)时间计算所有RICs，适用于谐波分析等场景。

Conclusion: RICs算法在特定频率分析中表现出高效性，尤其适用于N为2的幂的情况。

Abstract: In~\cite{sic-magazine-2025}, the authors show that the square index
coefficients (SICs) of the \(N\)-point discrete Fourier transform (DFT) -- that
is, the coefficients \(X_{k\sqrt{N}}\) for \(k = 0, 1, \ldots, \sqrt{N} - 1\)
-- can be losslessly compressed from \(N\) to \(\sqrt{N}\) points, thereby
accelerating the computation of these specific DFT coefficients accordingly.
Following up on that, in this article we generalize SICs into what we refer to
as rectangular index coefficients (RICs) of the DFT, formalized as $X_{kL},
k=0,1,\cdots,C-1$, in which the integers $C$ and $L$ are generic roots of $N$
such that $N=LC$. We present an algorithm to compress the $N$-point input
signal $\mathbf{x}$ into a $C$-point signal $\mathbf{\hat{x}}$ at the expense
of $\mathcal{O}(N)$ complex sums and no complex multiplication. We show that a
DFT on $\mathbf{\hat{x}}$ is equivalent to a DFT on the RICs of $\mathbf{x}$.
In cases where specific frequencies of \(\mathbf{x}\) are of interest -- as in
harmonic analysis -- one can conveniently adjust the signal parameters (e.g.,
frequency resolution) to align the RICs with those frequencies, and use the
proposed algorithm to compute them significantly faster. If $N$ is a power of
two -- as required by the fast Fourier transform (FFT) algorithm -- then $C$
can be any power of two in the range $[2, N/2]$ and one can use our algorithm
along with FFT to compute all RICs in $\mathcal{O}(C\log C)$ time complexity.

</details>


### [3] [AI for CSI Prediction in 5G-Advanced and Beyond](https://arxiv.org/abs/2504.12571)
*Chengyong Jiang,Jiajia Guo,Xiangyi Li,Shi Jin,Jun Zhang*

Main category: eess.SP

TL;DR: 本文探讨了人工智能（AI）在5G-Advanced和6G系统中信道状态信息（CSI）预测中的作用，综述了AI驱动的CSI预测的关键要素，并展望了未来无线通信系统中的应用前景。


<details>
  <summary>Details</summary>
Motivation: AI在5G-Advanced和6G系统中的重要性日益凸显，特别是在信道状态信息（CSI）预测方面。本文旨在为这一新兴领域的研究提供参考。

Method: 通过对AI驱动的CSI预测进行全面综述，分析其准确性、泛化能力和复杂性，并探讨模型管理的实际应用。

Result: 总结出AI在CSI预测中的关键技术和未来发展方向，包括与反馈的集成设计、多任务协同和快速场景预测等。

Conclusion: 本文为AI在无线通信系统中的应用奠定了基础，并指出了未来的研究方向。

Abstract: Artificial intelligence (AI) is pivotal in advancing fifth-generation
(5G)-Advanced and sixth-generation systems, capturing substantial research
interest. Both the 3rd Generation Partnership Project (3GPP) and leading
corporations champion AI's standardization in wireless communication. This
piece delves into AI's role in channel state information (CSI) prediction, a
sub-use case acknowledged in 5G-Advanced by the 3GPP. We offer an exhaustive
survey of AI-driven CSI prediction, highlighting crucial elements like
accuracy, generalization, and complexity. Further, we touch on the practical
side of model management, encompassing training, monitoring, and data
gathering. Moreover, we explore prospects for CSI prediction in future wireless
communication systems, entailing integrated design with feedback, multitasking
synergy, and predictions in rapid scenarios. This article seeks to be a
touchstone for subsequent research in this burgeoning domain.

</details>


### [4] [Sub-Scalp Brain-Computer Interface Device Design and Fabrication](https://arxiv.org/abs/2504.12578)
*Timothy B. Mahoney,David B. Grayden,Sam E. John*

Main category: eess.SP

TL;DR: 论文提出了一种新型皮下脑电图（EEG）系统（SAFE），用于解决现有BCI设备在通道数、采样率等方面的不足，并在动物模型中验证了其低噪声记录能力。


<details>
  <summary>Details</summary>
Motivation: 当前脑机接口（BCI）在信号采集方面存在局限，缺乏适用于BCI的皮下EEG设备。论文旨在填补这一空白。

Method: 设计了SAFE系统，包括定制放大器和无线发射器，具备6通道、1024 Hz采样率和蓝牙低功耗传输功能，并在动物模型中验证。

Result: 验证结果显示SAFE系统能够实现低噪声记录，未来将用于BCI信号质量评估。

Conclusion: SAFE系统为未来人类临床试验奠定了基础，有望帮助残障人士实现长期居家BCI应用。

Abstract: Current brain-computer interfaces (BCI) face limitations in signal
acquisition. While sub-scalp EEG offers a potential solution, existing devices
prioritize chronic seizure monitoring and lack features suited for BCI
applications. This work addresses this gap by outlining key specifications for
sub-scalp BCI devices, focusing on channel count, sampling rate, power
efficiency, and form factor. We present the Set-And-Forget EEG (SAFE) system, a
custom-built amplifier and wireless transmitter meeting these criteria. This
compact (12x12 mm), six-channel device offers 1024 Hz sampling and Bluetooth
Low Energy data transmission. Validation using generated sinusoids and
electrocorticography recordings of visual evoked potentials in sheep models
demonstrated low noise recording. Future animal studies will assess sub-scalp
EEG signal quality for BCI applications. This data lays the groundwork for
human trials, ultimately paving the way for chronic, in-home BCIs that empower
individuals with physical disabilities.

</details>


### [5] [High-Resolution Multipath Angle Estimation Based on Power-Angle-Delay Profile for Directional Scanning Sounding](https://arxiv.org/abs/2504.12698)
*Huixin Xu,Jianhua Zhang,Pan Tang,Hongbo Xing,Lei Tian,Qixing Wang*

Main category: eess.SP

TL;DR: 提出了一种基于功率-角度-延迟剖面（PADP）的高分辨率多径分量（MPC）角度估计方法，显著提高了角度和幅度估计精度，无需增加测量复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有DSS角度采样间隔限制了MPC角度估计的分辨率，需要一种更高精度的方法。

Method: 利用PADP中相邻角度功率差与MPC偏移角的映射关系，优化角度估计分辨率。

Result: 数值模拟显示，角度和幅度估计的均方误差比传统全向合成方法低一个数量级，接近Cramér-Rao下界（CRLB）。室内37.5 GHz实验验证了方法的实用性。

Conclusion: 该方法显著提升了MPC角度和幅度估计的精度，适用于实际应用。

Abstract: Directional scanning sounding (DSS) has become widely adopted for
high-frequency channel measurements because it effectively compensates for
severe path loss. However, the resolution of existing multipath component (MPC)
angle estimation methods is constrained by the DSS angle sampling interval.
Therefore, this communication proposes a high-resolution MPC angle estimation
method based on power-angle-delay profile (PADP) for DSS. By exploiting the
mapping relationship between the power difference of adjacent angles in the
PADP and MPC offset angle, the resolution of MPC angle estimation is refined,
significantly enhancing the accuracy of MPC angle and amplitude estimation
without increasing measurement complexity. Numerical simulation results
demonstrate that the proposed method reduces the mean squared estimation errors
of angle and amplitude by one order of magnitude compared to traditional
omnidirectional synthesis methods. Furthermore, the estimation errors approach
the Cram\'er-Rao Lower Bounds (CRLBs) derived for wideband DSS, thereby
validating its superior performance in MPC angle and amplitude estimation.
Finally, experiments conducted in an indoor scenario at 37.5 GHz validate the
excellent performance of the proposed method in practical applications.

</details>


### [6] [Universal Approximation with XL MIMO Systems: OTA Classification via Trainable Analog Combining](https://arxiv.org/abs/2504.12758)
*Kyriakos Stylianopoulos,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 论文提出了一种基于超大规模MIMO系统的无线网络架构，通过模拟组合器实现类似神经网络的通用函数逼近器，显著降低了复杂度和功耗。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用超大规模MIMO系统的特性实现高效的无线边缘推理，避免传统数字处理的复杂性和能耗。

Method: 将MIMO信道系数视为隐藏层节点，模拟组合器作为可训练输出层，基于极限学习机（ELM）框架实现端到端系统。

Result: XL-MIMO-ELM实现了近乎瞬时训练和高效分类，与传统深度学习和ELM相比，性能相当但复杂度大幅降低。

Conclusion: 提出了一种新型无线边缘推理范式，超大规模MIMO系统兼具通信和神经网络功能，适用于超低功耗设备。

Abstract: In this paper, we demonstrate that an eXtremely Large (XL) Multiple-Input
Multiple-Output (MIMO) wireless system with appropriate analog combining
components exhibits the properties of a universal function approximator,
similar to a feedforward neural network. By treating the XL MIMO channel
coefficients as the random nodes of a hidden layer, and the receiver's analog
combiner as a trainable output layer, we cast the end-to-end system to the
Extreme Learning Machine (ELM) framework, leading to a novel formulation for
Over-The-Air (OTA) edge inference without requiring traditional digital
processing nor pre-processing at the transmitter. Through theoretical analysis
and numerical evaluation, we showcase that XL-MIMO-ELM enables
near-instantaneous training and efficient classification, suggesting the
paradigm shift of beyond massive MIMO systems as neural networks alongside
their profound communications role. Compared to deep learning approaches and
conventional ELMs, the proposed framework achieves on par performance with
orders of magnitude lower complexity, making it highly attractive for ultra low
power wireless devices.

</details>


### [7] [Distributed Intelligent Sensing and Communications for 6G: Architecture and Use Cases](https://arxiv.org/abs/2504.12765)
*Kyriakos Stylianopoulos,Giyyarpuram Madhusudan,Guillaume Jornod,Sami Mekki,Francesca Costanzo,Hui Chen,Placido Mursia,Maurizio Crozzoli,Emilio Calvanese Strinati,George C. Alexandropoulos,Henk Wymeersch*

Main category: eess.SP

TL;DR: DISAC框架通过分布式架构提升6G的集成感知与通信能力，增强了可扩展性、适应性和资源效率，支持异构设备和语义集成，验证案例展示其在精度、安全性和效率上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 为应对6G网络中集成感知与通信（ISAC）的需求，DISAC框架旨在解决传统系统在可扩展性、适应性和资源效率方面的不足，特别是在动态和复杂环境中。

Method: DISAC框架采用分布式架构，包括智能数据处理、分布式协调、可重构智能表面（RIS）等新兴技术，支持异构设备和语义集成。通过两个实际用例（智能工厂车间和智能交叉路口VRU保护）验证其效果。

Result: DISAC在精度、安全性和运行效率上显著优于传统ISAC系统，满足了6G网络对传感准确性、延迟和实时决策的严格要求。

Conclusion: DISAC因其在动态和复杂环境中的创新性表现，成为下一代无线网络的基石框架。

Abstract: The Distributed Intelligent Sensing and Communication (DISAC) framework
redefines Integrated Sensing and Communication (ISAC) for 6G by leveraging
distributed architectures to enhance scalability, adaptability, and resource
efficiency. This paper presents key architectural enablers, including advanced
data representation, seamless target handover, support for heterogeneous
devices, and semantic integration. Two use cases illustrate the transformative
potential of DISAC: smart factory shop floors and Vulnerable Road User (VRU)
protection at smart intersections. These scenarios demonstrate significant
improvements in precision, safety, and operational efficiency compared to
traditional ISAC systems. The preliminary DISAC architecture incorporates
intelligent data processing, distributed coordination, and emerging
technologies such as Reconfigurable Intelligent Surfaces (RIS) to meet 6G's
stringent requirements. By addressing critical challenges in sensing accuracy,
latency, and real-time decision-making, DISAC positions itself as a cornerstone
for next-generation wireless networks, advancing innovation in dynamic and
complex environments.

</details>


### [8] [Supporting Urban Low-Altitude Economy: Channel Gain Map Inference Based on 3D Conditional GAN](https://arxiv.org/abs/2504.12794)
*Yonghao Wang,Ruoguang Li,Di Wu,Jiaqi Chen,Yong Zeng*

Main category: eess.SP

TL;DR: 论文提出了一种基于3D-CGAN的低空经济通信信道增益地图推断方法，以减少在线开销并提升准确性。


<details>
  <summary>Details</summary>
Motivation: 低空经济（LAE）的快速发展需要可靠的通信保障飞行安全，而信道知识图（CKM）能提供环境感知的通信支持。3D城市环境下的基站部署需要高效构建CKM以减少开销。

Method: 提出了一种基于3D条件生成对抗网络（3D-CGAN）的信道增益地图（CGM）推断方法，利用现有CGM数据集训练模型，仅需基站坐标即可推断CGM。

Result: 仿真结果表明，3D-CGAN推断的CGM优于基准方案，能准确反映3D环境中的无线电传播条件。

Conclusion: 3D-CGAN为低空经济中的通信信道知识图构建提供了一种高效且准确的解决方案。

Abstract: The advancement of advanced air mobility (AAM) in recent years has given rise
to the concept of low-altitude economy (LAE). However, the diverse flight
activities associated with the emerging LAE applications in urban scenarios
confront complex physical environments, which urgently necessitates ubiquitous
and reliable communication to guarantee the operation safety of the
low-altitude aircraft. As one of promising technologies for the sixth
generation (6G) mobile networks, channel knowledge map (CKM) enables the
environment-aware communication by constructing a site-specific dataset,
thereby providing a priori on-site information for the aircraft to obtain the
channel state information (CSI) at arbitrary locations with much reduced online
overhead. Diverse base station (BS) deployments in the three-dimensional (3D)
urban low-altitude environment require efficient 3D CKM construction to capture
spatial channel characteristics with less overhead. Towards this end, this
paper proposes a 3D channel gain map (CGM) inference method based on a 3D
conditional generative adversarial network (3D-CGAN). Specifically, we first
analyze the potential deployment types of BSs in urban low-altitude scenario,
and investigate the CGM representation with the corresponding 3D channel gain
model. The framework of the proposed 3D-CGAN is then discussed, which is
trained by a dataset consisting of existing CGMs. Consequently, the trained
3D-CGAN is capable of inferring the corresponding CGM only based on the BS
coordinate without additional measurement. The simulation results demonstrate
that the CGMs inferred by the proposed 3D-CGAN outperform those of the
benchmark schemes, which can accurately reflect the radio propagation condition
in 3D environment.

</details>


### [9] [RIS-Assisted Beamfocusing in Near-Field IoT Communication Systems: A Transformer-Based Approach](https://arxiv.org/abs/2504.12889)
*Quan Zhou,Jingjing Zhao,Kaiquan Cai,Yanbo Zhu*

Main category: eess.SP

TL;DR: 论文提出了一种基于Transformer的两阶段波束训练算法，用于RIS辅助的波束聚焦，通过粗搜索和精细搜索提升空间分辨率，实验显示在20 dB SNR下准确率达97%。


<details>
  <summary>Details</summary>
Motivation: 极大规模天线阵列系统（ELAA）中的天线数量庞大，使物联网通信系统的信号传播机制转向近场球面波传播，设计包含角度和距离域的二维波束码本具有挑战性。

Method: 采用Transformer架构的两阶段波束训练算法：粗搜索阶段用简单码本估计设备位置，确定是否在波束聚焦范围（BFR）；精细搜索阶段用精确码本进行细粒度波束搜索。

Result: 实验结果显示，该方法在20 dB信噪比（SNR）下的波束选择准确率达到97%，并在不同SNR下比基线方法提高10%至50%。

Conclusion: 提出的RIS辅助波束聚焦机制显著提升了精确性，为近场球面波传播提供了高效解决方案。

Abstract: The massive number of antennas in extremely large aperture array (ELAA)
systems shifts the propagation regime of signals in internet of things (IoT)
communication systems towards near-field spherical wave propagation. We propose
a reconfigurable intelligent surfaces (RIS)-assisted beamfocusing mechanism,
where the design of the two-dimensional beam codebook that contains both the
angular and distance domains is challenging. To address this issue, we
introduce a novel Transformer-based two-stage beam training algorithm, which
includes the coarse and fine search phases. The proposed mechanism provides a
fine-grained codebook with enhanced spatial resolution, enabling precise
beamfocusing. Specifically, in the first stage, the beam training is performed
to estimate the approximate location of the device by using a simple codebook,
determining whether it is within the beamfocusing range (BFR) or the
none-beamfocusing range (NBFR). In the second stage, by using a more precise
codebook, a fine-grained beam search strategy is conducted. Experimental
results unveil that the precision of the RIS-assisted beamfocusing is greatly
improved. The proposed method achieves beam selection accuracy up to 97% at
signal-to-noise ratio (SNR) of 20 dB, and improves 10% to 50% over the baseline
method at different SNRs.

</details>


### [10] [Optic Fingerprint(OFP): Enhancing Security in Li-Fi Networks](https://arxiv.org/abs/2504.12956)
*Ziqi Liu,Xuanbang Chen,Xun Zhang*

Main category: eess.SP

TL;DR: 提出了一个基于IEEE 802.15.7协议的LiFi网络硬件集成安全框架，通过设备指纹提取实现高精度认证。


<details>
  <summary>Details</summary>
Motivation: 针对可见光通信中的安全问题，提出一种利用LED非线性特性生成指纹的方法，以实现物理层认证。

Method: 开发了Optic Fingerprint（OFP）模型，通过在时域和频域提取基于幅度的特征向量，利用LED固有非线性特性。

Result: 实验结果显示，该模型在39种商用LED上实现了90.36%的分类准确率，且在SNR 10-30 dB范围内表现稳定。

Conclusion: OFP模型为可见光通信提供了一种实用且符合标准的物理层认证解决方案。

Abstract: We present a hardware-integrated security framework for LiFi networks through
device fingerprint extraction within the IEEE 802.15.7 protocol. Our Optic
Fingerprint (OFP) model utilizes inherent LED nonlinearities to generate
amplitude-based feature vectors in time and frequency domains, specifically
designed for optical wireless systems. Experimental results with 39 commercial
LEDs demonstrate 90.36% classification accuracy across SNR 10-30 dB while
maintaining standard compliance, offering a practical physical-layer
authentication solution for visible light communication.

</details>


### [11] [Simultaneous Polysomnography and Cardiotocography Reveal Temporal Correlation Between Maternal Obstructive Sleep Apnea and Fetal Hypoxia](https://arxiv.org/abs/2504.13010)
*Jingyu Wang,Donglin Xie,Jingying Ma,Yunliang Sun,Linyan Zhang,Rui Bai,Zelin Tu,Liyue Xu,Jun Wei,Jingjing Yang,Yanan Liu,Huijie Yi,Bing Zhou,Long Zhao,Xueli Zhang,Mengling Feng,Xiaosong Dong,Guoli Liu,Fang Han,Shenda Hong*

Main category: eess.SP

TL;DR: 孕期母体缺氧与胎儿心率变化显著相关，短暂缺氧可能引起胎心加速，而长时间缺氧则与减速相关。


<details>
  <summary>Details</summary>
Motivation: 探究孕期阻塞性睡眠呼吸暂停综合症（OSAS）对胎儿心率（FHR）的即时影响。

Method: 采用时间和同步多导睡眠监测（PSG）和胎心监护（CTG）数据，通过广义线性模型（GLM）分析母体缺氧与FHR变化的关系。

Result: 118名孕妇数据显示，短暂缺氧与胎心加速相关，长时间缺氧或SpO2下降显著与胎心减速相关。胎心变化在缺氧事件缓解后恢复基线。

Conclusion: 母体缺氧显著影响胎心，提示OSAS可能导致胎儿缺氧，需关注母婴交互作用以指导干预措施。

Abstract: Background: Obstructive sleep apnea syndrome (OSAS) during pregnancy is
common and can negatively affect fetal outcomes. However, studies on the
immediate effects of maternal hypoxia on fetal heart rate (FHR) changes are
lacking. Methods: We used time-synchronized polysomnography (PSG) and
cardiotocography (CTG) data from two cohorts to analyze the correlation between
maternal hypoxia and FHR changes (accelerations or decelerations). Maternal
hypoxic event characteristics were analyzed using generalized linear modeling
(GLM) to assess their associations with different FHR changes. Results: A total
of 118 pregnant women participated. FHR changes were significantly associated
with maternal hypoxia, primarily characterized by accelerations. A longer
hypoxic duration correlated with more significant FHR accelerations (P < 0.05),
while prolonged hypoxia and greater SpO2 drop were linked to FHR decelerations
(P < 0.05). Both cohorts showed a transient increase in FHR during maternal
hypoxia, which returned to baseline after the event resolved. Conclusion:
Maternal hypoxia significantly affects FHR, suggesting that maternal OSAS may
contribute to fetal hypoxia. These findings highlight the importance of
maternal-fetal interactions and provide insights for future interventions.

</details>


### [12] [ORIS allocation to minimize the outage probability in a multi-user VLC scenario](https://arxiv.org/abs/2504.13016)
*Borja Genoves Guzman,Maïté Brandt-Pearce*

Main category: eess.SP

TL;DR: 该论文探讨了在多用户可见光通信（VLC）系统中，通过优化光学可重构智能表面（ORISs）与LED和用户的关联，显著降低了中断概率。


<details>
  <summary>Details</summary>
Motivation: 随着LED的普及，VLC成为满足无线数据增长需求的潜在解决方案，但链路阻塞问题限制了其应用。ORISs被提出以缓解这一问题。

Method: 研究通过优化算法确定ORISs与LED及用户的最佳关联，以减少中断概率，同时控制ORISs的使用数量。

Result: 数值结果显示，使用ORISs的中断概率比未使用ORISs的场景降低了85%。

Conclusion: ORISs在多用户VLC系统中能有效减少中断概率，优化算法展示了其实际应用潜力。

Abstract: Visible Light Communication (VLC) is a promising solution to address the
growing demand for wireless data, leveraging the widespread use of
light-emitting diodes (LEDs) as transmitters. However, its deployment is
challenged by link blockages that cause connectivity outages. Optical
reconfigurable intelligent surfaces (ORISs) have recently emerged as a solution
to mitigate these disruptions. This work considers a multi-user VLC system and
investigates the optimal association of ORISs to LEDs and users to minimize the
outage probability while limiting the number of ORISs used. Numerical results
from our proposed optimization algorithm demonstrate that using ORISs can
reduce the outage probability by up to 85% compared to a no-ORIS scenario.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [13] [Enhanced Battery Capacity Estimation in Data-Limited Scenarios through Swarm Learning](https://arxiv.org/abs/2504.12444)
*Jiawei Zhang,Yu Zhang,Wei Xu,Yifei Zhang,Weiran Jiang,Qi Jiao,Yao Ren,Ziyou Song*

Main category: eess.SY

TL;DR: 论文提出了一种基于群学习（SL）的分散式电池管理系统，通过可信权重模型合并机制提升数据有限场景下的电池容量估计精度，同时确保数据隐私和安全。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在数据有限场景下性能不足，而共享数据又缺乏隐私和容错性保障，因此需要一种新的管理框架。

Method: 采用分散式群学习框架和基于可信权重的模型合并机制，在不同数据分布场景下验证电池容量估计性能。

Result: 群学习在所有数据有限场景下提升了估计精度，且在数据充足时达到与集中学习相近的准确性。

Conclusion: 群学习框架为电池管理提供了数据隐私和安全保障，同时在数据有限场景下表现优异。

Abstract: Data-driven methods have shown potential in electric-vehicle battery
management tasks such as capacity estimation, but their deployment is
bottlenecked by poor performance in data-limited scenarios. Sharing battery
data among algorithm developers can enable accurate and generalizable
data-driven models. However, an effective battery management framework that
simultaneously ensures data privacy and fault tolerance is still lacking. This
paper proposes a swarm battery management system that unites a decentralized
swarm learning (SL) framework and credibility weight-based model merging
mechanism to enhance battery capacity estimation in data-limited scenarios
while ensuring data privacy and security. The effectiveness of the SL framework
is validated on a dataset comprising 66 commercial LiNiCoAlO2 cells cycled
under various operating conditions. Specifically, the capacity estimation
performance is validated in four cases, including data-balanced, volume-biased,
feature-biased, and quality-biased scenarios. Our results show that SL can
enhance the estimation accuracy in all data-limited cases and achieve a similar
level of accuracy with central learning where large amounts of data are
available.

</details>


### [14] [Robust Visual Servoing under Human Supervision for Assembly Tasks](https://arxiv.org/abs/2504.12506)
*Victor Nan Fernandez-Ayala,Jorge Silva,Meng Guo,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 提出了一种框架，使移动机械臂能够可靠地完成从建筑模块组装结构的拾取和放置任务。


<details>
  <summary>Details</summary>
Motivation: 实现可靠的拾取和放置任务对于建筑结构组装至关重要，同时确保视觉标记的可见性和结构稳定性。

Method: 结合眼在手视觉伺服控制器和眼到手设置，使用控制屏障函数确保标记可见性，并在环中人机交互提高灵活性。

Result: 实验验证了该框架在6自由度移动机械臂上的有效性，并针对相机位姿误差提出了适应性屏障函数。

Conclusion: 该框架能够有效支持建筑模块的组装任务，具备鲁棒性和灵活性。

Abstract: We propose a framework enabling mobile manipulators to reliably complete
pick-and-place tasks for assembling structures from construction blocks. The
picking uses an eye-in-hand visual servoing controller for object tracking with
Control Barrier Functions (CBFs) to ensure fiducial markers in the blocks
remain visible. An additional robot with an eye-to-hand setup ensures precise
placement, critical for structural stability. We integrate human-in-the-loop
capabilities for flexibility and fault correction and analyze robustness to
camera pose errors, proposing adapted barrier functions to handle them. Lastly,
experiments validate the framework on 6-DoF mobile arms.

</details>


### [15] [Optimizing Utility-Scale Solar Siting for Local Economic Benefits and Regional Decarbonization](https://arxiv.org/abs/2504.12508)
*Papa Yaw Owusu-Obeng,Steven R. Miller,Sarah Banas Mills,Michael T. Craig*

Main category: eess.SY

TL;DR: 该研究将地方经济影响纳入电力系统规划模型，评估其对太阳能选址的影响，并考虑农田转用的机会成本，发现经济规模大且农田生产力低的县具有更高的经济效益。


<details>
  <summary>Details</summary>
Motivation: 传统电力规划未充分整合地方经济影响，导致太阳能选址决策忽视农田转用的机会成本。

Method: 通过结合地方经济指标和多目标优化框架，分析大湖地区各县的经济效益与太阳能选址关系。

Result: 经济规模大的县每兆瓦太阳能容量的经济效益更高，但农田生产力的损失会减少效益；优化选址可增加110亿美元经济效益。

Conclusion: 将经济考量纳入太阳能规划有助于协调脱碳目标与地方经济发展。

Abstract: The Midwest, with its vast agricultural lands, is rapidly emerging as a key
region for utility-scale solar expansion. However, traditional power planning
has yet to integrate local economic impact directly into capacity expansion to
guide optimal siting decisions. Moreover, existing economic assessments tend to
emphasize local benefits while overlooking the opportunity costs of converting
productive farmland for solar development. This study addresses these gaps by
endogenously incorporating local economic metrics into a power system planning
model to evaluate how economic impacts influence solar siting, accounting for
the cost of lost agricultural output. We analyze all counties within the Great
Lakes region, constructing localized supply and marginal benefit curves that
are embedded within a multi-objective optimization framework aimed at
minimizing system costs and maximizing community economic benefits. Our
findings show that counties with larger economies and lower farmland
productivity deliver the highest local economic benefit per megawatt (MW) of
installed solar capacity. In Ohio, for example, large counties generate up to
$34,500 per MW, driven in part by high property tax revenues, while smaller
counties yield 31% less. Accounting for the opportunity cost of displaced
agricultural output reduces local benefits by up to 16%, depending on farmland
quality. A scenario prioritizing solar investment in counties with higher
economic returns increases total economic benefits by $1 billion (or 11%) by
2040, with solar investment shifting away from Michigan and Wisconsin (down by
39%) toward Ohio and Indiana (up by 75%), with only a marginal increase of 0.5%
in system-wide costs. These findings underscore the importance of integrating
economic considerations into utility-scale solar planning to better align
decarbonization goals with regional and local economic development.

</details>


### [16] [Spike-Kal: A Spiking Neuron Network Assisted Kalman Filter](https://arxiv.org/abs/2504.12703)
*Xun Xiao,Junbo Tie,Jinyue Zhao,Ziqi Wang,Yuan Li,Qiang Dou,Lei Wang*

Main category: eess.SY

TL;DR: 提出了一种利用脉冲神经网络（SNN）优化卡尔曼滤波的新方法，减少对噪声统计特性的依赖，提高计算效率和估计精度，平均误差降低18%-65%。


<details>
  <summary>Details</summary>
Motivation: 卡尔曼滤波的性能依赖于准确的系统建模和噪声统计特性，而这些在实际中难以获得。深度学习的强大非线性建模能力和自动特征提取能力为改进卡尔曼滤波提供了新机会。

Method: 通过设计SNN与卡尔曼滤波的集成策略，训练SNN直接从观测数据中逼近最优增益矩阵，减少复杂矩阵运算的计算负担。

Result: 与传统方法相比，平均误差降低了18%-65%，同时保持了状态估计的准确性和鲁棒性。

Conclusion: 该方法展示了SNN在优化卡尔曼滤波中的潜力，能够适应时变噪声的统计特性，并提高计算效率。

Abstract: Kalman filtering can provide an optimal estimation of the system state from
noisy observation data. This algorithm's performance depends on the accuracy of
system modeling and noise statistical characteristics, which are usually
challenging to obtain in practical applications. The powerful nonlinear
modeling capabilities of deep learning, combined with its ability to extract
features from large amounts of data automatically, offer new opportunities for
improving the Kalman filter. This paper proposes a novel method that leverages
the Spiking Neural Network to optimize the Kalman filter. Our approach aims to
reduce the reliance on prior knowledge of system and observation noises,
allowing for adaptation to varying statistical characteristics of time-varying
noise. Furthermore, we investigate the potential of SNNs in improving the
computational efficiency of the Kalman filter. In our method, we design an
integration strategy between the SNN and the Kalman filter. The SNN is trained
to directly approximate the optimal gain matrix from observation data, thereby
alleviating the computational burden of complex matrix operations inherent in
traditional Kalman filtering while maintaining the accuracy and robustness of
state estimation. Its average error has been reduced by 18\%-65\% compared with
other methods.

</details>


### [17] [Incorporating a Deep Neural Network into Moving Horizon Estimation for Embedded Thermal Torque Derating of an Electric Machine](https://arxiv.org/abs/2504.12736)
*Alexander Winkler,Pranav Shah,Katrin Baumgärtner,Vasu Sharma,David Gordon,Jakob Andert*

Main category: eess.SY

TL;DR: 本文提出了一种结合深度神经网络（DNN）和移动视界估计（MHE）的新型状态估计框架，用于替代传统基于物理的模型。通过LSTM节点和合成数据训练，框架在永磁同步电机热管理中表现出色，仿真验证了其准确性及实时性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种结合数据驱动和模型方法的状态估计框架，以提高实时性和准确性，适用于安全关键应用。

Method: 使用LSTM节点训练DNN模型，集成到MHE框架中，并通过acados实现非线性规划问题。

Result: 仿真显示框架能准确估计温度，即使传感器存在噪声或故障，嵌入式硬件上达到三倍实时性能。

Conclusion: 研究证明了DNN-based MHE框架的可行性，为实时安全关键应用提供了新思路。

Abstract: This study introduces a novel state estimation framework that incorporates
Deep Neural Networks (DNNs) into Moving Horizon Estimation (MHE), shifting from
traditional physics-based models to rapidly developed data-driven techniques. A
DNN model with Long Short-Term Memory (LSTM) nodes is trained on synthetic data
generated by a high-fidelity thermal model of a Permanent Magnet Synchronous
Machine (PMSM), which undergoes thermal derating as part of the torque control
strategy in a battery electric vehicle. The MHE is constructed by integrating
the trained DNN with a simplified driving dynamics model in a discrete-time
formulation, incorporating the LSTM hidden and cell states in the state vector
to retain system dynamics. The resulting optimal control problem (OCP) is
formulated as a nonlinear program (NLP) and implemented using the acados
framework. Model-in-the-loop (MiL) simulations demonstrate accurate temperature
estimation, even under noisy sensor conditions or failures. Achieving threefold
real-time capability on embedded hardware confirms the feasibility of the
approach for practical deployment. The primary focus of this study is to assess
the feasibility of the MHE framework using a DNN-based plant model instead of
focusing on quantitative comparisons of vehicle performance. Overall, this
research highlights the potential of DNN-based MHE for real-time,
safety-critical applications by combining the strengths of model-based and
data-driven methods.

</details>


### [18] [Market-Driven Flexibility Provision: A Tri-Level Optimization Approach for Carbon Reduction](https://arxiv.org/abs/2504.12877)
*Shijie Pan,Gerrit Rolofs,Luca Pontecorvi,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 该论文提出了一种新框架，通过激励电价和三层次优化模型，鼓励用户参与电力市场并根据碳排放强度调整用电行为，结果表明该方法能有效引导用户低碳用电。


<details>
  <summary>Details</summary>
Motivation: 电力系统中可再生能源的波动性和不确定性需要灵活性管理，而当前实时电价与碳排放强度模式的不匹配可能导致用户在高碳时段用电。

Method: 采用激励电价和三层次优化模型，用户提交灵活性报价并获得奖励，通过市场运营平台与用户的动态互动实现优化。

Result: 在IEEE-33总线系统上的仿真表明，框架能有效引导用户行为与低碳目标对齐。

Conclusion: 该框架为电力系统中用户参与和低碳目标提供了一种可行解决方案。

Abstract: The integration of renewable energy resources (RES) in the power grid can
reduce carbon intensity, but also presents certain challenges. The uncertainty
and intermittent nature of RES emphasize the need for flexibility in power
systems. Moreover, there are noticeable mismatches between real-time
electricity prices and carbon intensity patterns throughout the day. These
discrepancies may lead customers to schedule energy-intensive tasks during the
early hours of the day, a period characterized by lower electricity prices but
higher carbon intensity. This paper introduces a novel and comprehensive
framework aimed at encouraging customer participation in electricity markets
and aligning their flexibility with carbon intensity trends. The proposed
approach integrates an incentive-based tariff with a tri-level optimization
model, where customers are motivated to submit flexibility bids and, in return,
receive financial rewards based on their contributions. The tri-level model
ensures a dynamic interaction between the market operation platform (MOP) and
end-users. Simulations are performed on a modified IEEE-33 bus system,
supported by two scenarios with different RES generations and customer
behaviors. Results demonstrate the effectiveness of the proposed framework in
guiding the customers' consumption behaviors towards low carbon intensity.

</details>


### [19] [Safe Physics-Informed Machine Learning for Dynamics and Control](https://arxiv.org/abs/2504.12952)
*Jan Drgona,Truong X. Nghiem,Thomas Beckers,Mahyar Fazlyab,Enrique Mallada,Colin Jones,Draguna Vrabie,Steven L. Brunton,Rolf Findeisen*

Main category: eess.SY

TL;DR: 本教程论文探讨了如何在动力学与控制中实现安全的物理信息机器学习，整合物理模型与安全保证。


<details>
  <summary>Details</summary>
Motivation: 机器学习在复杂动态系统建模与控制中的应用日益广泛，但安全性和稳定性仍是一个关键挑战，尤其是在自动驾驶、机器人、医疗决策和能源系统等安全关键领域。

Method: 论文研究了多种嵌入和确保安全约束的方法，如结构先验、Lyapunov函数、控制屏障函数、预测控制、投影和鲁棒优化技术，同时探讨了不确定性量化与安全验证方法。

Result: 通过实例展示了如何结合数据驱动方法与物理原理，实现复杂动态系统的安全控制。

Conclusion: 论文为安全控制复杂动态系统提供了一个综合框架，强调了物理模型与机器学习结合的重要性。

Abstract: This tutorial paper focuses on safe physics-informed machine learning in the
context of dynamics and control, providing a comprehensive overview of how to
integrate physical models and safety guarantees. As machine learning techniques
enhance the modeling and control of complex dynamical systems, ensuring safety
and stability remains a critical challenge, especially in safety-critical
applications like autonomous vehicles, robotics, medical decision-making, and
energy systems. We explore various approaches for embedding and ensuring safety
constraints, such as structural priors, Lyapunov functions, Control Barrier
Functions, predictive control, projections, and robust optimization techniques,
ensuring that the learned models respect stability and safety criteria.
Additionally, we delve into methods for uncertainty quantification and safety
verification, including reachability analysis and neural network verification
tools, which help validate that control policies remain within safe operating
bounds even in uncertain environments. The paper includes illustrative examples
demonstrating the implementation aspects of safe learning frameworks that
combine the strengths of data-driven approaches with the rigor of physical
principles, offering a path toward the safe control of complex dynamical
systems.

</details>


### [20] [Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode Control of a 7-DOF Robotic Manipulator](https://arxiv.org/abs/2504.13056)
*L. Wan,S. Smith,Y. -J. Pan,E. Witrant*

Main category: eess.SY

TL;DR: 提出了一种具有自适应增益的非奇异终端超螺旋滑模控制器（NT-STSM），用于7自由度机械臂的鲁棒轨迹跟踪，解决了抖动、未知干扰和旋转运动跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 解决高自由度机械臂在灵巧操作任务中面临的抖动、未知干扰和旋转运动跟踪等挑战。

Method: 提出自适应增益的NT-STSM控制器，提供有界性证明和增益选择指南。

Result: 仿真和硬件实验表明，该控制器在未知干扰下比其他控制器具有更强的鲁棒性和精确跟踪能力，减少控制抖动。

Conclusion: NT-STSM控制器能够有效减少复杂运动中的抖动和不稳定性，适用于灵巧机器人操作和工业应用。

Abstract: This paper presents a new task-space Non-singular Terminal Super-Twisting
Sliding Mode (NT-STSM) controller with adaptive gains for robust trajectory
tracking of a 7-DOF robotic manipulator. The proposed approach addresses the
challenges of chattering, unknown disturbances, and rotational motion tracking,
making it suited for high-DOF manipulators in dexterous manipulation tasks. A
rigorous boundedness proof is provided, offering gain selection guidelines for
practical implementation. Simulations and hardware experiments with external
disturbances demonstrate the proposed controller's robust, accurate tracking
with reduced control effort under unknown disturbances compared to other
NT-STSM and conventional controllers. The results demonstrated that the
proposed NT-STSM controller mitigates chattering and instability in complex
motions, making it a viable solution for dexterous robotic manipulations and
various industrial applications.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [21] [Optimizing Movable Antennas in Wideband Multi-User MIMO With Hardware Impairments](https://arxiv.org/abs/2504.12885)
*Amna Irshad,Emil Björnson,Alva Kosasih,Vitaly Petrov*

Main category: cs.IT

TL;DR: 该研究探讨了可移动天线在宽带MIMO系统中的性能优势，并通过优化天线位置提升了数据速率。


<details>
  <summary>Details</summary>
Motivation: 可移动天线是通信研究的新兴领域，尤其是在天线数量有限时，可提升MIMO系统的数据速率。目前研究多局限于窄带设置，本文旨在量化其在宽带系统中的效益。

Method: 研究首先提出了一个考虑硬件损伤的上行宽带系统模型，然后通过粒子群优化算法优化天线位置以最大化平均和速率。

Result: 数值研究表明，可移动天线的性能提升受硬件损伤程度、多径环境复杂性和子载波数量的显著影响。

Conclusion: 研究为可移动天线在未来宽带系统中最适合的应用场景提供了重要见解。

Abstract: Movable antennas represent an emerging field in telecommunication research
and a potential approach to achieving higher data rates in multiple-input
multiple-output (MIMO) communications when the total number of antennas is
limited. Most solutions and analyses to date have been limited to
\emph{narrowband} setups. This work complements the prior studies by
quantifying the benefit of using movable antennas in \emph{wideband} MIMO
communication systems. First, we derive a novel uplink wideband system model
that also accounts for distortion from transceiver hardware impairments. We
then formulate and solve an optimization task to maximize the average sum rate
by adjusting the antenna positions using particle swarm optimization. Finally,
the performance with movable antennas is compared with fixed uniform arrays and
the derived theoretical upper bound. The numerical study concludes that the
data rate improvement from movable antennas over other arrays heavily depends
on the level of hardware impairments, the richness of the multi-path
environments, and the number of subcarriers. The present study provides vital
insights into the most suitable use cases for movable antennas in future
wideband systems.

</details>


### [22] [Degrees of Freedom of Holographic MIMO -- Fundamental Theory and Analytical Methods](https://arxiv.org/abs/2504.13031)
*Juan Carlos Ruiz-Sicilia,Marco Di Renzo,Placido Mursia,Vincenzo Sciancalepore,Merouane Debbah*

Main category: cs.IT

TL;DR: 论文比较了两种分析全息多输入多输出（MIMO）技术极限的常用方法：割集积分和自伴算子，并探讨了它们的优缺点。


<details>
  <summary>Details</summary>
Motivation: 全息多输入多输出（MIMO）未来6G网络的关键技术，需研究其基本极限以提升空间复用增益。

Method: 对割集积分和自伴算子两种常用分析方法进行比较，详细描述其原理和应用。

Result: 分析了两种方法的优势和局限性，为全息MIMO的研究提供了方法学支持。

Conclusion: 研究为全息MIMO技术的基础极限提供了重要见解，并指导未来技术优化。

Abstract: Holographic multiple-input multiple-output (MIMO) is envisioned as one of the
most promising technology enablers for future sixth-generation (6G) networks.
The use of electrically large holographic surface (HoloS) antennas has the
potential to significantly boost the spatial multiplexing gain by increasing
the number of degrees of freedom (DoF), even in line-of-sight (LoS) channels.
In this context, the research community has shown a growing interest in
characterizing the fundamental limits of this technology. In this paper, we
compare the two analytical methods commonly utilized in the literature for this
purpose: the cut-set integral and the self-adjoint operator. We provide a
detailed description of both methods and discuss their advantages and
limitations.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [23] [Benchmarking Audio Deepfake Detection Robustness in Real-world Communication Scenarios](https://arxiv.org/abs/2504.12423)
*Haohan Shi,Xiyu Shi,Safak Dogan,Saif Alzubi,Tianjin Huang,Yunxiao Zhang*

Main category: eess.AS

TL;DR: 论文针对音频伪造检测在真实通信场景中的鲁棒性问题，提出了新的测试数据集和增强策略。


<details>
  <summary>Details</summary>
Motivation: 现有音频伪造检测系统在音频编码压缩和信道传输影响下泛化能力不足。

Method: 开发了新测试数据集ADD-C评估系统鲁棒性，并提出数据增强策略。

Result: 实验显示ADD-C数据集显著提升了系统性能。

Conclusion: 该基准测试有助于未来构建鲁棒性更强的音频伪造检测系统。

Abstract: Existing Audio Deepfake Detection (ADD) systems often struggle to generalise
effectively due to the significantly degraded audio quality caused by audio
codec compression and channel transmission effects in real-world communication
scenarios. To address this challenge, we developed a rigorous benchmark to
evaluate ADD system performance under such scenarios. We introduced ADD-C, a
new test dataset to evaluate the robustness of ADD systems under diverse
communication conditions, including different combinations of audio codecs for
compression and Packet Loss Rates (PLR). Benchmarking on three baseline ADD
models with the ADD-C dataset demonstrated a significant decline in robustness
under such conditions. A novel data augmentation strategy was proposed to
improve the robustness of ADD systems. Experimental results demonstrated that
the proposed approach increases the performance of ADD systems significantly
with the proposed ADD-C dataset. Our benchmark can assist future efforts
towards building practical and robustly generalisable ADD systems.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [24] [Integral control of the proximal gradient method for unbiased sparse optimization](https://arxiv.org/abs/2504.12814)
*V. Cerone,S. M. Fosson,A. Re,D. Regruto*

Main category: math.OC

TL;DR: 提出了一种通过反馈控制超参数来改进近端梯度方法的新方法，能够在合理迭代次数内获得无偏解。


<details>
  <summary>Details</summary>
Motivation: 近端梯度方法因其简单易用而在稀疏优化中流行，但其解存在偏差且收敛慢，因此需要改进。

Method: 设计了一种积分控制机制，不显著增加计算复杂度，用于动态调整超参数。

Result: 理论分析和数值模拟表明，该方法在强凸和非强凸问题中均能有效收敛到无偏解。

Conclusion: 所提出的反馈控制机制显著提升了近端梯度方法的性能，适用于更广泛的问题。

Abstract: Proximal gradient methods are popular in sparse optimization as they are
straightforward to implement. Nevertheless, they achieve biased solutions,
requiring many iterations to converge. This work addresses these issues through
a suitable feedback control of the algorithm's hyperparameter. Specifically, by
designing an integral control that does not substantially impact the
computational complexity, we can reach an unbiased solution in a reasonable
number of iterations. In the paper, we develop and analyze the convergence of
the proposed approach for strongly-convex problems. Moreover, numerical
simulations validate and extend the theoretical results to the non-strongly
convex framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [25] [TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations](https://arxiv.org/abs/2504.12721)
*Yihang Lu,Yangyang Xu,Qitao Qing,Xianwei Meng*

Main category: cs.LG

TL;DR: 论文提出了一种名为TimeCapsule的简化框架，通过高维信息压缩统一了冗余减少和多尺度建模等关键技术，在长期时间序列预测中表现出色。


<details>
  <summary>Details</summary>
Motivation: 复杂的深度学习模型在长期时间序列预测中表现不佳，而简单的模型如线性模型或MLPs反而更有效。作者希望通过简化现有技术，提升深度学习的效率。

Method: 提出了TimeCapsule模型，将时间序列建模为3D张量（时间、变量、层级维度），并通过模式生产捕获多模依赖关系，同时实现维度压缩。结合JEPA架构监控预测表示的学习。

Result: 在多个基准测试中，TimeCapsule展现了卓越的适应性和性能，达到了目前最先进的水平。

Conclusion: TimeCapsule通过简化和统一现有技术，提供了一种高效且灵活的长期时间序列预测解决方案。

Abstract: Recent deep learning models for Long-term Time Series Forecasting (LTSF)
often emphasize complex, handcrafted designs, while simpler architectures like
linear models or MLPs have often outperformed these intricate solutions. In
this paper, we revisit and organize the core ideas behind several key
techniques, such as redundancy reduction and multi-scale modeling, which are
frequently employed in advanced LTSF models. Our goal is to streamline these
ideas for more efficient deep learning utilization. To this end, we introduce
TimeCapsule, a model built around the principle of high-dimensional information
compression that unifies these techniques in a generalized yet simplified
framework. Specifically, we model time series as a 3D tensor, incorporating
temporal, variate, and level dimensions, and leverage mode production to
capture multi-mode dependencies while achieving dimensionality compression. We
propose an internal forecast within the compressed representation domain,
supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the
learning of predictive representations. Extensive experiments on challenging
benchmarks demonstrate the versatility of our method, showing that TimeCapsule
can achieve state-of-the-art performance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [26] [Learning-based Delay Compensation for Enhanced Control of Assistive Soft Robots](https://arxiv.org/abs/2504.12428)
*Adrià Mompó Alepuz,Dimitrios Papageorgiou,Silvia Tolu*

Main category: cs.RO

TL;DR: 提出了基于学习的方法（KRLST和LDN）来改进软机器人的跟踪性能，用于辅助护理。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人因非线性动力学和时延导致的控制难题，提升其辅助护理能力。

Method: 结合KRLST在线学习系统动力学，利用LDN压缩历史输入以补偿时延。

Result: 实验显示跟踪性能显著优于基线非线性控制器，计算高效且适应性强。

Conclusion: 方法实用性强，有望提升软机器人在辅助护理中的安全性和精准性。

Abstract: Soft robots are increasingly used in healthcare, especially for assistive
care, due to their inherent safety and adaptability. Controlling soft robots is
challenging due to their nonlinear dynamics and the presence of time delays,
especially in applications like a soft robotic arm for patient care. This paper
presents a learning-based approach to approximate the nonlinear state predictor
(Smith Predictor), aiming to improve tracking performance in a two-module soft
robot arm with a short inherent input delay. The method uses Kernel Recursive
Least Squares Tracker (KRLST) for online learning of the system dynamics and a
Legendre Delay Network (LDN) to compress past input history for efficient delay
compensation. Experimental results demonstrate significant improvement in
tracking performance compared to a baseline model-based non-linear controller.
Statistical analysis confirms the significance of the improvements. The method
is computationally efficient and adaptable online, making it suitable for
real-world scenarios and highlighting its potential for enabling safer and more
accurate control of soft robots in assistive care applications.

</details>


### [27] [Learning Transferable Friction Models and LuGre Identification via Physics Informed Neural Networks](https://arxiv.org/abs/2504.12441)
*Asutay Ozmen,João P. Hespanha,Katie Byl*

Main category: cs.RO

TL;DR: 提出了一种物理启发的摩擦估计框架，结合经典模型与可学习组件，仅需少量通用数据即可准确模拟动态摩擦特性，并能迁移到未训练的系统上。


<details>
  <summary>Details</summary>
Motivation: 目前机器人模拟器中使用的简化摩擦模型或启发式方法可能在计算效率与准确性之间产生显著差异，导致模拟与实际性能不一致。

Method: 采用物理启发的摩擦估计框架，结合经典摩擦模型与可学习组件，仅需少量通用测量数据即可训练模型。

Result: 在欠驱动和非线性系统上验证，学习的摩擦模型能准确模拟动态摩擦特性，缩小模拟与实际差距，并能迁移到未训练的系统。

Conclusion: 该方法为机器人中的模拟与实际差距提供了一种可扩展且可解释的解决方案，适用于复杂任务。

Abstract: Accurately modeling friction in robotics remains a core challenge, as
robotics simulators like Mujoco and PyBullet use simplified friction models or
heuristics to balance computational efficiency with accuracy, where these
simplifications and approximations can lead to substantial differences between
simulated and physical performance. In this paper, we present a
physics-informed friction estimation framework that enables the integration of
well-established friction models with learnable components-requiring only
minimal, generic measurement data. Our approach enforces physical consistency
yet retains the flexibility to adapt to real-world complexities. We
demonstrate, on an underactuated and nonlinear system, that the learned
friction models, trained solely on small and noisy datasets, accurately
simulate dynamic friction properties and reduce the sim-to-real gap. Crucially,
we show that our approach enables the learned models to be transferable to
systems they are not trained on. This ability to generalize across multiple
systems streamlines friction modeling for complex, underactuated tasks,
offering a scalable and interpretable path toward bridging the sim-to-real gap
in robotics and control.

</details>


### [28] [Practical Insights on Grasp Strategies for Mobile Manipulation in the Wild](https://arxiv.org/abs/2504.12512)
*Isabella Huang,Richard Cheng,Sangwoon Kim,Dan Kruse,Carolyn Matl,Lukas Kaul,JC Hancock,Shanmuga Harikumar,Mark Tjersland,James Borders,Dan Helmick*

Main category: cs.RO

TL;DR: SHOPPER是一个移动操作机器人平台，旨在提升非结构化环境中可靠和泛化的抓取策略，并在真实杂货店环境中进行了测试和分析。


<details>
  <summary>Details</summary>
Motivation: 尽管移动操作机器人的抓取能力在进步，但在非结构化环境中可靠抓取物品的能力仍存在重大差距，限制了其广泛应用。

Method: 设计并部署了SHOPPER平台，开发通用抓取策略，并在真实杂货店环境（具有多样性和挑战性）中进行测试。

Result: 通过数百次抓取尝试的详细分析，识别了关键失败模式和抓取挑战，提供了实用见解。

Conclusion: 研究为机器人社区提供了有价值的方向，指出了领域中亟待解决的关键问题。

Abstract: Mobile manipulation robots are continuously advancing, with their grasping
capabilities rapidly progressing. However, there are still significant gaps
preventing state-of-the-art mobile manipulators from widespread real-world
deployments, including their ability to reliably grasp items in unstructured
environments. To help bridge this gap, we developed SHOPPER, a mobile
manipulation robot platform designed to push the boundaries of reliable and
generalizable grasp strategies. We develop these grasp strategies and deploy
them in a real-world grocery store -- an exceptionally challenging setting
chosen for its vast diversity of manipulable items, fixtures, and layouts. In
this work, we present our detailed approach to designing general grasp
strategies towards picking any item in a real grocery store. Additionally, we
provide an in-depth analysis of our latest real-world field test, discussing
key findings related to fundamental failure modes over hundreds of distinct
pick attempts. Through our detailed analysis, we aim to offer valuable
practical insights and identify key grasping challenges, which can guide the
robotics community towards pressing open problems in the field.

</details>


### [29] [Graph-based Path Planning with Dynamic Obstacle Avoidance for Autonomous Parking](https://arxiv.org/abs/2504.12616)
*Farhad Nawaz,Minjun Sung,Darshan Gadginmath,Jovin D'sa,Sangjae Bae,David Isele,Nadia Figueroa,Nikolai Matni,Faizan M. Tariq*

Main category: cs.RO

TL;DR: 论文提出了一种基于时间索引的混合A*算法，通过动态障碍物预测和自适应中间目标，提高了停车场景中的路径规划效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 停车场景中充满静态和动态障碍物，现有的路径规划方法在处理动态障碍物时效率不足，需要一种更安全的解决方案。

Method: 开发了一种时间索引的混合A*算法，通过预测动态障碍物并集成到规划过程中，结合在线规划框架和自适应中间目标实现动态避障。

Result: 在多种停车场景中（垂直、斜列、平行停车）验证了方法的有效性，相比现有的样条规划方法，显著提高了效率和安全性。

Conclusion: 所提方法在停车场景中表现出优越性能，能够高效生成无碰撞路径，适用于复杂动态环境。

Abstract: Safe and efficient path planning in parking scenarios presents a significant
challenge due to the presence of cluttered environments filled with static and
dynamic obstacles. To address this, we propose a novel and computationally
efficient planning strategy that seamlessly integrates the predictions of
dynamic obstacles into the planning process, ensuring the generation of
collision-free paths. Our approach builds upon the conventional Hybrid A star
algorithm by introducing a time-indexed variant that explicitly accounts for
the predictions of dynamic obstacles during node exploration in the graph, thus
enabling dynamic obstacle avoidance. We integrate the time-indexed Hybrid A
star algorithm within an online planning framework to compute local paths at
each planning step, guided by an adaptively chosen intermediate goal. The
proposed method is validated in diverse parking scenarios, including
perpendicular, angled, and parallel parking. Through simulations, we showcase
our approach's potential in greatly improving the efficiency and safety when
compared to the state of the art spline-based planning method for parking
situations.

</details>


### [30] [Biasing the Driving Style of an Artificial Race Driver for Online Time-Optimal Maneuver Planning](https://arxiv.org/abs/2504.12744)
*Sebastiano Taddei,Mattia Piccinini,Francesco Biral*

Main category: cs.RO

TL;DR: 提出了一种新颖的方法，通过非线性模型预测控制（MPC）优化自动驾驶赛车的轨迹规划，实现了接近最优的在线圈速时间。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过优化轨迹规划，使人工赛车驾驶员（ARD）能够实时调整驾驶风格（如早顶点或晚顶点），并理解人类驾驶员选择这些策略的原因。

Method: 采用非线性模型预测控制（MPC），结合时间最小化和终点速度最大化的目标，并提出基于前一步轨迹的新终端成本公式。

Result: 方法计算高效，能实现接近离线最优圈速的在线圈速，且比传统在线最小时间MPC方案更快。

Conclusion: 该方法为理解人类驾驶员的驾驶风格选择提供了新途径，并为实时轨迹规划提供了高效解决方案。

Abstract: In this work, we present a novel approach to bias the driving style of an
artificial race driver (ARD) for online time-optimal trajectory planning. Our
method leverages a nonlinear model predictive control (MPC) framework that
combines time minimization with exit speed maximization at the end of the
planning horizon. We introduce a new MPC terminal cost formulation based on the
trajectory planned in the previous MPC step, enabling ARD to adapt its driving
style from early to late apex maneuvers in real-time. Our approach is
computationally efficient, allowing for low replan times and long planning
horizons. We validate our method through simulations, comparing the results
against offline minimum-lap-time (MLT) optimal control and online minimum-time
MPC solutions. The results demonstrate that our new terminal cost enables ARD
to bias its driving style, and achieve online lap times close to the MLT
solution and faster than the minimum-time MPC solution. Our approach paves the
way for a better understanding of the reasons behind human drivers' choice of
early or late apex maneuvers.

</details>


### [31] [Imperative MPC: An End-to-End Self-Supervised Learning with Differentiable MPC for UAV Attitude Control](https://arxiv.org/abs/2504.13088)
*Haonan He,Yuheng Qiu,Junyi Geng*

Main category: cs.RO

TL;DR: 该论文提出了一种结合自监督学习和可微分模型预测控制（d-MPC）的混合框架，用于无人机姿态控制，解决了传统方法的保守假设和数据驱动方法的数据效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统模块化控制方法由于保守假设和参数调优繁琐而表现不佳，纯数据驱动方法则存在样本效率低和依赖大量数据的问题，因此需要一种结合两者优势的混合方法。

Method: 采用自监督学习框架，结合学习式惯性里程计（IO）和可微分MPC（d-MPC），通过双层优化（BLO）实现无人机姿态控制。IO模块用于去噪IMU数据并预测姿态，MPC优化控制动作。

Result: 该方法在强风条件下仍表现有效，同时提升了MPC参数学习和IMU预测性能。

Conclusion: 结合学习式感知和模型控制的方法在无人机姿态控制中展示了高效性和鲁棒性，为混合控制策略提供了新思路。

Abstract: Modeling and control of nonlinear dynamics are critical in robotics,
especially in scenarios with unpredictable external influences and complex
dynamics. Traditional cascaded modular control pipelines often yield suboptimal
performance due to conservative assumptions and tedious parameter tuning. Pure
data-driven approaches promise robust performance but suffer from low sample
efficiency, sim-to-real gaps, and reliance on extensive datasets. Hybrid
methods combining learning-based and traditional model-based control in an
end-to-end manner offer a promising alternative. This work presents a
self-supervised learning framework combining learning-based inertial odometry
(IO) module and differentiable model predictive control (d-MPC) for Unmanned
Aerial Vehicle (UAV) attitude control. The IO denoises raw IMU measurements and
predicts UAV attitudes, which are then optimized by MPC for control actions in
a bi-level optimization (BLO) setup, where the inner MPC optimizes control
actions and the upper level minimizes discrepancy between real-world and
predicted performance. The framework is thus end-to-end and can be trained in a
self-supervised manner. This approach combines the strength of learning-based
perception with the interpretable model-based control. Results show the
effectiveness even under strong wind. It can simultaneously enhance both the
MPC parameter learning and IMU prediction performance.

</details>


### [32] [A New Semidefinite Relaxation for Linear and Piecewise-Affine Optimal Control with Time Scaling](https://arxiv.org/abs/2504.13170)
*Lujie Yang,Tobia Marcucci,Pablo A. Parrilo,Russ Tedrake*

Main category: cs.RO

TL;DR: 提出了一种用于线性系统时间尺度最优控制的半定松弛方法，结合图凸集方法处理分段仿射系统。


<details>
  <summary>Details</summary>
Motivation: 解决线性系统最优控制问题中的非凸性和计算复杂度问题，尤其是涉及时间尺度和分段仿射系统的场景。

Method: 通过选择部分双线性项和变量变换实现紧致的半定松弛，并扩展到分段仿射系统，将其建模为图凸集的最短路径问题。

Result: 该方法能够在保持计算效率的同时，提供紧致的松弛效果，并通过单一半定程序求解分段仿射最优控制问题。

Conclusion: 所提出的方法为复杂控制系统优化提供了一种高效且紧致的解决方案，适用于实际应用中的非凸问题。

Abstract: We introduce a semidefinite relaxation for optimal control of linear systems
with time scaling. These problems are inherently nonconvex, since the system
dynamics involves bilinear products between the discretization time step and
the system state and controls. The proposed relaxation is closely related to
the standard second-order semidefinite relaxation for quadratic constraints,
but we carefully select a subset of the possible bilinear terms and apply a
change of variables to achieve empirically tight relaxations while keeping the
computational load light. We further extend our method to handle
piecewise-affine (PWA) systems by formulating the PWA optimal-control problem
as a shortest-path problem in a graph of convex sets (GCS). In this GCS,
different paths represent different mode sequences for the PWA system, and the
convex sets model the relaxed dynamics within each mode. By combining a tight
convex relaxation of the GCS problem with our semidefinite relaxation with time
scaling, we can solve PWA optimal-control problems through a single
semidefinite program.

</details>
