<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 7]
- [cs.RO](#cs.RO) [Total: 23]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.CV](#cs.CV) [Total: 5]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Error Analysis for Over-the-Air Federated Learning under Misaligned and Time-Varying Channels](https://arxiv.org/abs/2508.20277)
*Xiaoyan Ma,Shahryar Zehtabi,Taejoon Kim,Christopher G. Brinton*

Main category: eess.SP

TL;DR: 该研究探讨了基于OFDM的空中联邦学习(OTA-FL)系统中，移动设备高机动性导致的信道估计不完美及模型参数对齐问题，首次量化了这些因素对全局模型更新的影响，并通过数值模拟验证了理论分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决多移动设备（如无人机）在高机动性下进行OTA-FL时，由于信道估计不完美和时变上传信道导致的模型参数对齐问题及其对模型训练的失真影响。

Method: 方法包括推导单轮全局模型更新的闭式表达式，量化信道不完美和时变信道的影响，进而扩展到多轮全局更新的误差累积分析。

Result: 通过数值模拟验证了理论分析的正确性，表明高机动性和信道不完美会显著影响OTA-FL的模型性能。

Conclusion: 结论指出，高机动性和信道不完美会导致OTA-FL训练过程中的失真，提出未来需要进一步优化信道估计和模型对齐机制。

Abstract: This paper investigates an OFDM-based over-the-air federated learning
(OTA-FL) system, where multiple mobile devices, e.g., unmanned aerial vehicles
(UAVs), transmit local machine learning (ML) models to a central parameter
server (PS) for global model aggregation. The high mobility of local devices
results in imperfect channel estimation, leading to a misalignment problem,
i.e., the model parameters transmitted from different local devices do not
arrive at the central PS simultaneously. Moreover, the mobility introduces
time-varying uploading channels, which further complicates the aggregation
process. All these factors collectively cause distortions in the OTA-FL
training process which are underexplored. To quantify these effects, we first
derive a closed-form expression for a single-round global model update in terms
of these channel imperfections. We then extend our analysis to capture multiple
rounds of global updates, yielding a bound on the accumulated error in OTA-FL.
We validate our theoretical results via extensive numerical simulations, which
corroborate our derived analysis.

</details>


### [2] [Dual-IRS Aided Near-/Hybrid-Field SWIPT: Passive Beamforming and Independent Antenna Power Splitting Design](https://arxiv.org/abs/2508.20531)
*Chaoying Huang,Wen Chen,Qingqing Wu,Xusheng Zhu,Zhendong Li,Ying Wang,Jinhong Yuan*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的双智能反射面（IRS）辅助的干扰限制同时无线信息和能量传输（SWIPT）系统，采用独立功率分割（PS），并通过近场和混合场信道模型评估性能增益。


<details>
  <summary>Details</summary>
Motivation: 为了在信息传输和能量收集之间实现更优的权衡，同时考虑近场和混合场通信场景的实际需求。

Method: 分别建立近场和混合场信道模型，提出交替优化算法和凸优化方法来解决问题。

Result: 数值结果验证了双IRS辅助的SWIPT系统性能优于其他基准方案。

Conclusion: 双IRS结合独立PS的SWIPT系统在性能和灵活性上具有显著优势，尤其适用于近场和混合场场景。

Abstract: This paper proposes a novel dual-intelligent reflecting surface (IRS) aided
interference-limited simultaneous wireless information and power transfer
(SWIPT) system with independent power splitting (PS), where each receiving
antenna applies different PS factors to offer an advantageous trade-off between
the useful information and harvested energy. We separately establish the near-
and hybrid-field channel models for IRS-reflected links to evaluate the
performance gain more precisely and practically. Specifically, we formulate an
optimization problem of maximizing the harvested power by jointly optimizing
dual-IRS phase shifts, independent PS ratio, and receive beamforming vector in
both near- and hybrid-field cases. In the near-field case, the alternating
optimization algorithm is proposed to solve the non-convex problem by applying
the Lagrange duality method and the difference-of-convex (DC) programming. In
the hybrid-field case, we first present an interesting result that the
AP-IRS-user channel gains are invariant to the phase shifts of dual-IRS, which
allows the optimization problem to be transformed into a convex one. Then, we
derive the asymptotic performance of the combined channel gains in closed-form
and analyze the characteristics of the dual-IRS. Numerical results validate our
analysis and indicate the performance gains of the proposed scheme that
dual-IRS-aided SWIPT with independent PS over other benchmark schemes.

</details>


### [3] [Towards Automated EEG-Based Detection Using Deep Convolutional Autoencoders](https://arxiv.org/abs/2508.20535)
*Annika Stiehl,Nicolas Weeger,Christian Uhl,Dominic Bechtold,Nicole Ille,Stefan Geißelsöder*

Main category: eess.SP

TL;DR: 该论文提出了一种深度卷积自编码器（DCAE），通过结合时域和频域损失函数提取EEG信号的低维潜在表示，以提高癫痫检测的敏感性和降低误报率。


<details>
  <summary>Details</summary>
Motivation: 癫痫是常见的神经系统疾病，需要可靠的发作检测方法。现有深度学习方法的敏感性和误报率存在问题，且缺乏一致的EEG输入表示。

Method: 使用DCAE提取EEG信号的低维潜在表示，通过比较时域和频域的重建误差评估模型性能，并训练不同损失函数的自编码器。

Result: 结合时域和频域损失的DCAE模型表现最佳，表明单一表示的深度学习模型可能无法保留信号的完整特征。

Conclusion: 研究揭示了深度学习模型处理EEG数据的机制，表明频域信息在时域信号输入中未被完全捕获，为未来研究提供了新方向。

Abstract: Epilepsy is one of the most common neurological disorders. This disease
requires reliable and efficient seizure detection methods.
Electroencephalography (EEG) is the gold standard for seizure monitoring, but
its manual analysis is a time-consuming task that requires expert knowledge. In
addition, there are no well-defined features that allow fully automated
analysis. Existing deep learning-based approaches struggle to achieve high
sensitivity while maintaining a low false alarm rate per hour (FAR/h) and lack
consistency in the optimal EEG input representation, whether in the time or
frequency domain. To address these issues, we propose a Deep Convolutional
Autoencoder (DCAE) to extract low-dimensional latent representations that
preserve essential EEG signal features. The ability of the model to preserve
relevant information was evaluated by comparing reconstruction errors based on
both time series and frequency-domain representations. Several autoencoders
with different loss functions based on time and frequency were trained and
evaluated to determine their effectiveness in reconstructing EEG features. Our
results show that the DCAE model taking both time series and frequency losses
into account achieved the best reconstruction performance. This indicates that
Deep Neural Networks with a single representation might not preserve the
relevant signal properties. This work provides insight into how deep learning
models process EEG data and examines whether frequency information is captured
when time series signals are used as input.

</details>


### [4] [Removing motion artifacts from mechanomyographic signals: an innovative filtering method applied to human movement analysis](https://arxiv.org/abs/2508.20602)
*Matthieu Correa,Nicolas Vignais,Isabelle A. Siegler,Maxime Projetti*

Main category: eess.SP

TL;DR: 该论文提出了一种基于自适应滤波的MMG信号处理方法，能有效分离动态条件下的运动伪影，相比传统方法效果更优，但需谨慎处理躯干和下肢肌肉信号。


<details>
  <summary>Details</summary>
Motivation: MMG在测量肌肉活动方面具有潜力，但运动伪影的敏感性限制了其应用，因此需要一种更有效的方法来处理动态条件下的信号。

Method: 研究采用基于完全集成经验模态分解的自适应滤波方法，结合自适应噪声和谱模糊熵，隔离动态条件下的MMG信号中的运动伪影。

Result: 相比传统带通滤波技术，新方法在三角肌和竖脊肌的信号重构上表现更优（R² = 0.907和0.842），能动态过滤5-20 Hz带宽的伪影。

Conclusion: 新方法在动态过滤运动伪影方面具有优势，但需注意躯干和下肢肌肉信号中仍存在与冲击相关的加速度，其具体影响尚需进一步量化。

Abstract: Mechanomyography (MMG) is a promising tool for measuring muscle activity in
the field but its sensitivity to motion artifacts limits its application. In
this study, we proposed an adaptative filtering method for MMG accelerometers
based on the complete ensemble empirical mode decomposition, with adaptative
noise and spectral fuzzy entropy, to isolate motions artefacts from the MMG
signal in dynamic conditions. We compared our method with the traditional
band-pass filtering technique, demonstrating better results concerning motion
recomposition for deltoid and erector spinae muscles (R${}^2$ = 0.907 and
0.842). Thus, this innovative method allows the filtering of motion artifacts
dynamically in the 5-20 Hz bandwidth, which is not achievable with traditional
method. However, the interpretation of accelerometric MMG signals from the
trunk and lower-limb muscles during walking or running should be approached
with great caution as impact-related accelerations are still present, though
their exact quantity still needs to be quantified.

</details>


### [5] [Weighted Bayesian Cram$\acute{\text{e}}$r-Rao Bound for Mixed-Resolution Parameter Estimation](https://arxiv.org/abs/2508.20761)
*Yaniv Mazor,Tirza Routtenberg*

Main category: eess.SP

TL;DR: 论文研究了混合分辨率系统中的参数估计问题，提出了加权贝叶斯Cramer-Rao界（WBCRB）来量化性能极限，并通过分区方法近似均方误差（MSE）。


<details>
  <summary>Details</summary>
Motivation: 混合分辨率系统结合了高分辨率和粗量化数据，以降低硬件成本和功耗，但粗量化数据在参数估计中引入了性能折衷。论文旨在为这类系统推导性能下限，并提供更精确的MSE估计方法。

Method: 提出了加权贝叶斯Cramer-Rao界（WBCRB），涵盖经典BCRB和其他两种特殊加权形式。通过将估计问题分为信息区和饱和区，采用不同区域的WBCRB近似方法，组合出更准确的MSE估计。

Result: 在LGO模型中的仿真结果表明，WBCRB优于BCRB，且基于BFIM逆加权的版本接近最优WBCRB。WBCRB的MSE近似更紧，能准确预测量化误差下MSE的非单调行为。

Conclusion: 论文提出的WBCRB和分区MSE近似方法为混合分辨率系统的参数估计提供了有效的性能分析工具，特别是在量化误差存在的情况下。

Abstract: Mixed-resolution architectures, combining high-resolution (analog) data with
coarsely quantized (e.g., 1-bit) data, are widely employed in emerging
communication and radar systems to reduce hardware costs and power consumption.
However, the use of coarsely quantized data introduces non-trivial tradeoffs in
parameter estimation tasks. In this paper, we investigate the derivation of
lower bounds for such systems. In particular, we develop the weighted Bayesian
Cramer-Rao bound (WBCRB) for the mixed-resolution setting with a general weight
function. We demonstrate the special cases of: (i) the classical BCRB; (ii) the
WBCRB that is based on the Bayesian Fisher information matrix (BFIM)-Inverse
weighting; and (iii) the Aharon-Tabrikian tightest WBCRB with an optimal weight
function. Based on the developed WBCRB, we propose a new method to approximate
the mean-squared-error (MSE) by partitioning the estimation problem into two
regions: (a) where the 1-bit quantized data is informative; and (b) where it is
saturated. We apply region-specific WBCRB approximations in these regions to
achieve an accurate composite MSE estimate. We derive the bounds and MSE
approximation for the linear Gaussian orthonormal (LGO) model, which is
commonly used in practical signal processing applications. Our simulation
results demonstrate the use of the proposed bounds and approximation method in
the LGO model with a scalar unknown parameter. It is shown that the WBCRB
outperforms the BCRB, where the BFIM-Inverse weighting version approaches the
optimal WBCRB. Moreover, it is shown that the WBCRB-based MSE approximation is
tighter and accurately predicts the non-monotonic behavior of the MSE in the
presence of quantization errors.

</details>


### [6] [Breaking Barriers in Health Monitoring: Multi-Scenario Vital Sign Detection Using Mm-Wave MIMO FMCW Radar](https://arxiv.org/abs/2508.20864)
*Ehsan Sadeghi,Paul Havinga*

Main category: eess.SP

TL;DR: 论文探讨了毫米波FMCW雷达在多场景下进行生命体征检测的部署，通过改进信号处理技术克服传统方法的局限性，提出基于Prony和MUSIC算法的实时监测技术，显著提升了非接触监测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 克服传统生命体征监测方法的局限性，提供更准确、可靠的非接触式监测解决方案，尤其在临床和紧急场景中。

Method: 采用改进的Prony和MUSIC算法，针对实时心率和呼吸率监测进行优化，有效抑制噪声和谐波干扰。

Result: MUSIC和Prony算法在心率检测中的平均绝对误差分别为1.8和0.81，呼吸率检测中分别为1.01和0.8，展示了较高的准确性和鲁棒性。

Conclusion: FMCW雷达结合改进算法为非接触式生命体征监测提供了可靠解决方案，尤其在传统接触式监测不适用的场景中具有重要应用潜力。

Abstract: This paper explores the deployment of mm-wave Frequency Modulated Continuous
Wave (FMCW) radar for vital sign detection across multiple scenarios. We focus
on overcoming the limitations of traditional sensing methods by enhancing
signal processing techniques to capture subtle physiological changes
effectively. Our study introduces novel adaptations of the Prony and MUSIC
algorithms tailored for real-time heart and respiration rate monitoring,
significantly advancing the accuracy and reliability of non-contact vital sign
monitoring using radar technologies. Notably, these algorithms demonstrate a
robust ability to suppress noise and harmonic interference. For instance, the
mean absolute errors (MAE) for MUSIC and Prony in heart rate detection are 1.8
and 0.81, respectively, while for respiration rate, the MAEs are 1.01 and 0.8,
respectively. These results underscore the potential of FMCW radar as a
reliable, non-invasive solution for continuous vital sign monitoring in
healthcare settings, particularly in clinical and emergency scenarios where
traditional contact-based monitoring is impractical.

</details>


### [7] [A Correction for the Paper "Symplectic geometry mode decomposition and its application to rotating machinery compound fault diagnosis"](https://arxiv.org/abs/2508.20990)
*Hong-Yan Zhang,Haoting Liu,Rui-Jia Lin,Yu Zhou*

Main category: eess.SP

TL;DR: 本文指出了SGMD方法的局限性，并通过回拉定理修复了其缺陷，使其能够更准确地计算时间序列的分量。


<details>
  <summary>Details</summary>
Motivation: SGMD方法虽然强大，但其继承自SSA的对角平均原理（DAP）未随轨迹矩阵形式的扩展而更新，导致计算时间序列分量时存在缺陷。

Method: 通过回拉定理修正SGMD方法中的DAP问题，以准确计算时间序列分量。

Result: 修复了SGMD方法的局限性，使其能够更准确地分解时间序列。

Conclusion: 回拉定理的应用成功修正了SGMD方法的缺陷，提升了其在时间序列分解中的准确性。

Abstract: The symplectic geometry mode decomposition (SGMD) is a powerful method for
decomposing time series, which is based on the diagonal averaging principle
(DAP) inherited from the singular spectrum analysis (SSA). Although the authors
of SGMD method generalized the form of the trajectory matrix in SSA, the DAP is
not updated simultaneously. In this work, we pointed out the limitations of the
SGMD method and fixed the bugs with the pulling back theorem for computing the
given component of time series from the corresponding component of trajectory
matrix.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [8] [Learning Fast, Tool aware Collision Avoidance for Collaborative Robots](https://arxiv.org/abs/2508.20457)
*Joonho Lee,Yunho Kim,Seokjoon Kim,Quan Nguyen,Youngjin Heo*

Main category: cs.RO

TL;DR: 提出了一种工具感知的实时碰撞避免系统，用于动态环境中协作机器人的安全高效操作。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中机器人因工具变化和部分可见性导致的碰撞或保守行为问题。

Method: 结合学习感知模型和受限强化学习的控制策略，实时调整工具大小和交互模式。

Result: 在仿真和实际测试中优于传统方法（APF、MPPI），计算成本降低60%，保持亚毫米精度。

Conclusion: 系统模块化、高效且有效，适用于动态环境中的协作机器人应用。

Abstract: Ensuring safe and efficient operation of collaborative robots in human
environments is challenging, especially in dynamic settings where both obstacle
motion and tasks change over time. Current robot controllers typically assume
full visibility and fixed tools, which can lead to collisions or overly
conservative behavior. In our work, we introduce a tool-aware collision
avoidance system that adjusts in real time to different tool sizes and modes of
tool-environment interaction. Using a learned perception model, our system
filters out robot and tool components from the point cloud, reasons about
occluded area, and predicts collision under partial observability. We then use
a control policy trained via constrained reinforcement learning to produce
smooth avoidance maneuvers in under 10 milliseconds. In simulated and
real-world tests, our approach outperforms traditional approaches (APF, MPPI)
in dynamic environments, while maintaining sub-millimeter accuracy. Moreover,
our system operates with approximately 60% lower computational cost compared to
a state-of-the-art GPU-based planner. Our approach provides modular, efficient,
and effective collision avoidance for robots operating in dynamic environments.
We integrate our method into a collaborative robot application and demonstrate
its practical use for safe and responsive operation.

</details>


### [9] [SPGrasp: Spatiotemporal Prompt-driven Grasp Synthesis in Dynamic Scenes](https://arxiv.org/abs/2508.20547)
*Yunpeng Mei,Hongjie Cao,Yinqiu Xia,Wei Xiao,Zhaohan Feng,Gang Wang,Jie Chen*

Main category: cs.RO

TL;DR: SPGrasp 是一种基于 SAMv2 的实时交互式动态抓取合成框架，通过结合用户提示和时空上下文，实现了低延迟（59 ms）和高准确率（90.6%-93.8%）的动态抓取。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态物体抓取合成中难以同时实现低延迟和高交互性，因此需要一种能够兼顾这两者的新框架。

Method: SPGrasp 扩展了 SAMv2 模型，结合用户提示和时空上下文，实现了端到端的动态抓取合成，并显著降低了延迟。

Result: 在多个基准测试中，SPGrasp 的抓取准确率达到 90.6% 到 93.8%，并且在 GraspNet-1Billion 上实现了 92.0% 的准确率和 73.1 ms 的每帧延迟。

Conclusion: SPGrasp 成功解决了动态抓取合成中延迟与交互性的权衡问题，并在实际应用中表现出色。

Abstract: Real-time interactive grasp synthesis for dynamic objects remains challenging
as existing methods fail to achieve low-latency inference while maintaining
promptability. To bridge this gap, we propose SPGrasp (spatiotemporal
prompt-driven dynamic grasp synthesis), a novel framework extending segment
anything model v2 (SAMv2) for video stream grasp estimation. Our core
innovation integrates user prompts with spatiotemporal context, enabling
real-time interaction with end-to-end latency as low as 59 ms while ensuring
temporal consistency for dynamic objects. In benchmark evaluations, SPGrasp
achieves instance-level grasp accuracies of 90.6% on OCID and 93.8% on
Jacquard. On the challenging GraspNet-1Billion dataset under continuous
tracking, SPGrasp achieves 92.0% accuracy with 73.1 ms per-frame latency,
representing a 58.5% reduction compared to the prior state-of-the-art
promptable method RoG-SAM while maintaining competitive accuracy. Real-world
experiments involving 13 moving objects demonstrate a 94.8% success rate in
interactive grasping scenarios. These results confirm SPGrasp effectively
resolves the latency-interactivity trade-off in dynamic grasp synthesis. Code
is available at https://github.com/sejmoonwei/SPGrasp.

</details>


### [10] [SimShear: Sim-to-Real Shear-based Tactile Servoing](https://arxiv.org/abs/2508.20561)
*Kipp McAdam Freud,Yijiong Lin,Nathan F. Lepora*

Main category: cs.RO

TL;DR: SimShear 是一种利用剪切信息的触觉控制模拟到真实世界的管道，通过条件 GAN 生成包含剪切变形的触觉图像，无需显式模拟剪切动态，成功应用于机器人控制任务。


<details>
  <summary>Details</summary>
Motivation: 剪切力在动态物体交互中至关重要，但模拟剪切动态非常困难。本文旨在利用剪切信息实现高精度的触觉控制任务，无需复杂模拟。

Method: 提出 shPix2pix，一种剪切条件化的 U-Net GAN，将不含剪切的模拟触觉图像与剪切向量结合，生成包含剪切变形的真实触觉图像。

Result: 该方法在触觉图像模拟和姿态/剪切预测上优于基线 pix2pix 方法，并在实际机器人任务中保持接触误差在 1-2 毫米内。

Conclusion: SimShear 通过刚性模拟器实现剪切力的模拟到真实世界应用，为触觉机器人研究开辟了新方向。

Abstract: We present SimShear, a sim-to-real pipeline for tactile control that enables
the use of shear information without explicitly modeling shear dynamics in
simulation. Shear, arising from lateral movements across contact surfaces, is
critical for tasks involving dynamic object interactions but remains
challenging to simulate. To address this, we introduce shPix2pix, a
shear-conditioned U-Net GAN that transforms simulated tactile images absent of
shear, together with a vector encoding shear information, into realistic
equivalents with shear deformations. This method outperforms baseline pix2pix
approaches in simulating tactile images and in pose/shear prediction. We apply
SimShear to two control tasks using a pair of low-cost desktop robotic arms
equipped with a vision-based tactile sensor: (i) a tactile tracking task, where
a follower arm tracks a surface moved by a leader arm, and (ii) a collaborative
co-lifting task, where both arms jointly hold an object while the leader
follows a prescribed trajectory. Our method maintains contact errors within 1
to 2 mm across varied trajectories where shear sensing is essential, validating
the feasibility of sim-to-real shear modeling with rigid-body simulators and
opening new directions for simulation in tactile robotics.

</details>


### [11] [Traversing the Narrow Path: A Two-Stage Reinforcement Learning Framework for Humanoid Beam Walking](https://arxiv.org/abs/2508.20661)
*TianChen Huang,Wei Gao,Runchen Xu,Shiwu Zhang*

Main category: cs.RO

TL;DR: 提出了一种物理基础的两阶段框架，用于解决人形机器人在狭窄横梁上行走的挑战，通过耦合XCoM/LIPM步态模板与轻量级残差规划器及简单低层跟踪器，实现稳健的横梁穿越。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在狭窄横梁上行走时稀疏、安全关键性接触以及纯学习策略脆弱性的问题。

Method: 采用两阶段框架：第一阶段在平地上训练跟踪器以稳定跟踪步态目标；第二阶段在模拟中训练高层规划器，通过残差细化步态以优先安全精确的落脚点。

Result: 在Unitree G1上成功穿越0.2米宽、3米长的横梁，残差细化在成功率、中线跟踪和安全裕度上优于基准方法，并实现透明分析和低摩擦的仿真到现实迁移。

Conclusion: 提出的两阶段框架显著提升了人形机器人在狭窄横梁上的行走能力，结合了物理模型与学习策略的优势，为复杂环境下的稳健运动提供了解决方案。

Abstract: Traversing narrow beams is challenging for humanoids due to sparse,
safety-critical contacts and the fragility of purely learned policies. We
propose a physically grounded, two-stage framework that couples an XCoM/LIPM
footstep template with a lightweight residual planner and a simple low-level
tracker. Stage-1 is trained on flat ground: the tracker learns to robustly
follow footstep targets by adding small random perturbations to heuristic
footsteps, without any hand-crafted centerline locking, so it acquires stable
contact scheduling and strong target-tracking robustness. Stage-2 is trained in
simulation on a beam: a high-level planner predicts a body-frame residual
(Delta x, Delta y, Delta psi) for the swing foot only, refining the template
step to prioritize safe, precise placement under narrow support while
preserving interpretability. To ease deployment, sensing is kept minimal and
consistent between simulation and hardware: the planner consumes compact,
forward-facing elevation cues together with onboard IMU and joint signals. On a
Unitree G1, our system reliably traverses a 0.2 m-wide, 3 m-long beam. Across
simulation and real-world studies, residual refinement consistently outperforms
template-only and monolithic baselines in success rate, centerline adherence,
and safety margins, while the structured footstep interface enables transparent
analysis and low-friction sim-to-real transfer.

</details>


### [12] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种任务导向的边缘辅助跨系统框架，利用数字孪生技术实现实时人机交互，解决了工业元宇宙中的高计算负载、有限带宽和严格延迟问题。通过预测操作员动作并采用HITL-MAML算法，系统在轨迹绘制和3D场景重建任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 工业元宇宙中的人机交互面临高计算负载、带宽限制和严格延迟的挑战，需要一种高效且实时的解决方案。

Method: 提出了一种基于数字孪生的任务导向边缘辅助框架，将数字孪生分解为视觉显示和机器人控制两个虚拟功能，并引入HITL-MAML算法动态调整预测范围。

Result: 在轨迹绘制控制任务中，加权RMSE从0.0712米降至0.0101米；在核退役实时3D场景表示任务中，PSNR为22.11，SSIM为0.8729，LPIPS为0.1298。

Conclusion: 该框架能够确保高风险工业环境中实时交互的空间精度和视觉保真度，具有广泛应用潜力。

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


### [13] [Task Allocation for Autonomous Machines using Computational Intelligence and Deep Reinforcement Learning](https://arxiv.org/abs/2508.20688)
*Thanh Thi Nguyen,Quoc Viet Hung Nguyen,Jonathan Kua,Imran Razzak,Dung Nguyen,Saeid Nahavandi*

Main category: cs.RO

TL;DR: 本文综述了用于控制和协调自主机器的算法，重点关注计算智能（CI）和深度强化学习（RL）的任务分配方法，分析了其优缺点，并提出了未来研究方向，以提升算法在实际应用中的性能和可用性。


<details>
  <summary>Details</summary>
Motivation: 开发高效的协同控制算法以实现多自主机器的可靠运行。

Method: 综述现有的控制和协调自主机器的算法，尤其是基于CI和深度RL的任务分配方法。

Result: CI和深度RL为动态不确定环境中的复杂任务分配提供了可行方案，深度RL的发展推动了自主机器控制领域的研究。

Conclusion: 本文为研究人员提供了自主机器学习研究的全面概览，并指明了未来的研究方向。

Abstract: Enabling multiple autonomous machines to perform reliably requires the
development of efficient cooperative control algorithms. This paper presents a
survey of algorithms that have been developed for controlling and coordinating
autonomous machines in complex environments. We especially focus on task
allocation methods using computational intelligence (CI) and deep reinforcement
learning (RL). The advantages and disadvantages of the surveyed methods are
analysed thoroughly. We also propose and discuss in detail various future
research directions that shed light on how to improve existing algorithms or
create new methods to enhance the employability and performance of autonomous
machines in real-world applications. The findings indicate that CI and deep RL
methods provide viable approaches to addressing complex task allocation
problems in dynamic and uncertain environments. The recent development of deep
RL has greatly contributed to the literature on controlling and coordinating
autonomous machines, and it has become a growing trend in this area. It is
envisaged that this paper will provide researchers and engineers with a
comprehensive overview of progress in machine learning research related to
autonomous machines. It also highlights underexplored areas, identifies
emerging methodologies, and suggests new avenues for exploration in future
research within this domain.

</details>


### [14] [Non-expert to Expert Motion Translation Using Generative Adversarial Networks](https://arxiv.org/abs/2508.20740)
*Yuki Tanaka,Seiichiro Katsura*

Main category: cs.RO

TL;DR: 模仿学习用于机器人技能转移，利用生成对抗网络提出灵活任务调整方法。


<details>
  <summary>Details</summary>
Motivation: 随着熟练工人减少，通过模仿学习从专家向机器人转移技能的需求日益迫切。当前的模仿学习方法难以根据人类意图灵活调整任务，而现有有条件训练的方法标签有限。

Method: 提出基于生成对抗网络的灵活运动翻译方法，用户可通过输入数据和训练模型向机器人教授任务与技能。

Result: 使用3自由度书法机器人对系统进行了评估。

Conclusion: 该方法有效实现了机器人技能的灵活转移和任务调整。

Abstract: Decreasing skilled workers is a very serious problem in the world. To deal
with this problem, the skill transfer from experts to robots has been
researched. These methods which teach robots by human motion are called
imitation learning. Experts' skills generally appear in not only position data,
but also force data. Thus, position and force data need to be saved and
reproduced. To realize this, a lot of research has been conducted in the
framework of a motion-copying system. Recent research uses machine learning
methods to generate motion commands. However, most of them could not change
tasks by following human intention. Some of them can change tasks by
conditional training, but the labels are limited. Thus, we propose the flexible
motion translation method by using Generative Adversarial Networks. The
proposed method enables users to teach robots tasks by inputting data, and
skills by a trained model. We evaluated the proposed system with a 3-DOF
calligraphy robot.

</details>


### [15] [Uncertainty Aware-Predictive Control Barrier Functions: Safer Human Robot Interaction through Probabilistic Motion Forecasting](https://arxiv.org/abs/2508.20812)
*Lorenzo Busellato,Federico Cunico,Diego Dall'Alba,Marco Emporio,Andrea Giachetti,Riccardo Muradore,Marco Cristani*

Main category: cs.RO

TL;DR: 论文提出了不确定性感知预测控制屏障函数（UA-PCBFs），结合了概率性人手运动预测与控制屏障函数的安全保障，优化人机交互的流畅性和安全性。


<details>
  <summary>Details</summary>
Motivation: 在人与机器人共享工作空间的环境下，现有方法因过度保守的预测和规划限制了灵活性，无法满足高效与安全的需求。

Method: UA-PCBFs通过动态调整安全边界，结合预测模块的不确定性估计，实现更智能的运动规划。

Result: 实验表明，UA-PCBFs显著减少了机器人安全空间被侵犯的次数，提升了交互流畅性。

Conclusion: UA-PCBFs在保证安全的同时提高了人机交互的响应速度和效率，优于现有方法。

Abstract: To enable flexible, high-throughput automation in settings where people and
robots share workspaces, collaborative robotic cells must reconcile stringent
safety guarantees with the need for responsive and effective behavior. A
dynamic obstacle is the stochastic, task-dependent variability of human motion:
when robots fall back on purely reactive or worst-case envelopes, they brake
unnecessarily, stall task progress, and tamper with the fluidity that true
Human-Robot Interaction demands. In recent years, learning-based human-motion
prediction has rapidly advanced, although most approaches produce worst-case
scenario forecasts that often do not treat prediction uncertainty in a
well-structured way, resulting in over-conservative planning algorithms,
limiting their flexibility. We introduce Uncertainty-Aware Predictive Control
Barrier Functions (UA-PCBFs), a unified framework that fuses probabilistic
human hand motion forecasting with the formal safety guarantees of Control
Barrier Functions. In contrast to other variants, our framework allows for
dynamic adjustment of the safety margin thanks to the human motion uncertainty
estimation provided by a forecasting module. Thanks to uncertainty estimation,
UA-PCBFs empower collaborative robots with a deeper understanding of future
human states, facilitating more fluid and intelligent interactions through
informed motion planning. We validate UA-PCBFs through comprehensive real-world
experiments with an increasing level of realism, including automated setups (to
perform exactly repeatable motions) with a robotic hand and direct human-robot
interactions (to validate promptness, usability, and human confidence).
Relative to state-of-the-art HRI architectures, UA-PCBFs show better
performance in task-critical metrics, significantly reducing the number of
violations of the robot's safe space during interaction with respect to the
state-of-the-art.

</details>


### [16] [A Soft Fabric-Based Thermal Haptic Device for VR and Teleoperation](https://arxiv.org/abs/2508.20831)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 该论文提出了一种新型的基于织物的热触觉接口，用于虚拟现实和远程操作，具有超轻量化设计和快速热调节能力，显著提升了用户操作性能。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实和远程操作需要更自然和高效的触觉反馈，传统接口通常笨重且功能单一。本研究旨在开发一种轻量化、多功能的热触觉接口，以提升用户体验。

Method: 研究通过结合气动驱动和导电织物设计了一种超轻量化接口，每根手指单元仅重2克。接口内置加热元件，通过软性可穿戴设计实现压力和热刺激的调节。

Result: 实验显示，接口能快速调节温度（最高3°C/s），并提供高达8.93N的力。用户研究验证了高温度识别准确率（0.98）和显著提升的任务成功率（88.5%到96.4%）及力控制精度。

Conclusion: 集成的热触觉接口在虚拟现实和远程操作中表现优异，验证了其在高级人机交互应用中的有效性。

Abstract: This paper presents a novel fabric-based thermal-haptic interface for virtual
reality and teleoperation. It integrates pneumatic actuation and conductive
fabric with an innovative ultra-lightweight design, achieving only 2~g for each
finger unit. By embedding heating elements within textile pneumatic chambers,
the system delivers modulated pressure and thermal stimuli to fingerpads
through a fully soft, wearable interface.
  Comprehensive characterization demonstrates rapid thermal modulation with
heating rates up to 3$^{\circ}$C/s, enabling dynamic thermal feedback for
virtual or teleoperation interactions. The pneumatic subsystem generates forces
up to 8.93~N at 50~kPa, while optimization of fingerpad-actuator clearance
enhances cooling efficiency with minimal force reduction. Experimental
validation conducted with two different user studies shows high temperature
identification accuracy (0.98 overall) across three thermal levels, and
significant manipulation improvements in a virtual pick-and-place tasks.
Results show enhanced success rates (88.5\% to 96.4\%, p = 0.029) and improved
force control precision (p = 0.013) when haptic feedback is enabled, validating
the effectiveness of the integrated thermal-haptic approach for advanced
human-machine interaction applications.

</details>


### [17] [Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration](https://arxiv.org/abs/2508.20836)
*Ahmed A. Elgohary,Rohan Palanikumar,Sameh A. Eisa*

Main category: cs.RO

TL;DR: 提出了一种新颖的极值搜索控制方法，模拟了昆虫和蜂鸟的悬停与源搜寻行为，并在实验中验证了其在机器人上的应用。


<details>
  <summary>Details</summary>
Motivation: 探索一种无需模型的实时控制方法，模仿生物飞行行为，推动扑翼机器人的发展。

Method: 采用极值搜索控制(ESC)方法，首次在机器人上进行实验验证。

Result: 实验结果在一维空间中证实了ESC作为扑翼飞行自然控制方法的潜力。

Conclusion: ESC为扑翼飞行和机器人领域提供了一种新的仿生控制机制。

Abstract: In a recent effort, we successfully proposed a categorically novel approach
to mimic the phenomenoa of hovering and source seeking by flapping insects and
hummingbirds using a new extremum seeking control (ESC) approach. Said ESC
approach was shown capable of characterizing the physics of hovering and source
seeking by flapping systems, providing at the same time uniquely novel
opportunity for a model-free, real-time biomimicry control design. In this
paper, we experimentally test and verify, for the first time in the literature,
the potential of ESC in flapping robots to achieve model-free, real-time
controlled hovering and source seeking. The results of this paper, while being
restricted to 1D, confirm the premise of introducing ESC as a natural control
method and biomimicry mechanism to the field of flapping flight and robotics.

</details>


### [18] [Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing](https://arxiv.org/abs/2508.20959)
*Curtis C. Johnson,Daniel Webb,David Hill,Marc D. Killpack*

Main category: cs.RO

TL;DR: 该论文提出了一种新型触觉传感架构，通过硬件和拓扑优化解决了大规模触觉传感在布线复杂度、数据吞吐和系统可靠性方面的挑战，并在实时控制任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模触觉传感在机器人全身操作中的实现面临布线复杂度高、数据吞吐不足和系统可靠性差等挑战，亟需一种稳健的解决方案。

Method: 采用基于织物的开源传感器和定制读取电子设备，结合新型菊花链SPI总线拓扑，减少信号串扰并优化数据同步传输。

Result: 系统成功实现了每平方米8,000个触点的数据同步传输，更新速率超过50 FPS，并在实时抓取任务中表现出色。

Conclusion: 该架构为未来高级全身控制和物理人机交互研究提供了一个稳健的平台。

Abstract: Scaling tactile sensing for robust whole-body manipulation is a significant
challenge, often limited by wiring complexity, data throughput, and system
reliability. This paper presents a complete architecture designed to overcome
these barriers. Our approach pairs open-source, fabric-based sensors with
custom readout electronics that reduce signal crosstalk to less than 3.3%
through hardware-based mitigation. Critically, we introduce a novel,
daisy-chained SPI bus topology that avoids the practical limitations of common
wireless protocols and the prohibitive wiring complexity of USB hub-based
systems. This architecture streams synchronized data from over 8,000 taxels
across 1 square meter of sensing area at update rates exceeding 50 FPS,
confirming its suitability for real-time control. We validate the system's
efficacy in a whole-body grasping task where, without feedback, the robot's
open-loop trajectory results in an uncontrolled application of force that
slowly crushes a deformable cardboard box. With real-time tactile feedback, the
robot transforms this motion into a gentle, stable grasp, successfully
manipulating the object without causing structural damage. This work provides a
robust and well-characterized platform to enable future research in advanced
whole-body control and physical human-robot interaction.

</details>


### [19] [Learning Primitive Embodied World Models: Towards Scalable Robotic Learning](https://arxiv.org/abs/2508.20840)
*Qiao Sun,Liujia Yang,Wei Tang,Wei Huang,Kaixin Xu,Yongchao Chen,Mingyu Liu,Jiange Yang,Haoyi Zhu,Yating Wang,Tong He,Yilun Chen,Xili Dai,Nanyang Ye,Qinying Gu*

Main category: cs.RO

TL;DR: 论文提出了一种基于原始动作的嵌入世界模型（PEWM），通过限制视频生成的时间范围，解决了现有视频生成模型在数据和复杂性上的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频生成的嵌入世界模型依赖大规模交互数据，导致数据稀缺、收集困难和高维度问题，限制了语言与动作的细粒度对齐和长时视频生成的实现。

Method: 提出PEWM方法，限制视频生成的短时间范围，结合模块化视觉语言模型（VLM）规划和起始-目标热图引导（SGG）机制，实现闭环控制和复合任务的泛化。

Result: PEWM提高了数据效率、降低了推理延迟，并支持细粒度语言-视觉对齐和复合任务的灵活控制。

Conclusion: PEWM通过结合视频模型的时空先验和VLM的语义感知，弥合了物理交互与高层推理之间的鸿沟，为可扩展、可解释的通用嵌入智能奠定了基础。

Abstract: While video-generation-based embodied world models have gained increasing
attention, their reliance on large-scale embodied interaction data remains a
key bottleneck. The scarcity, difficulty of collection, and high dimensionality
of embodied data fundamentally limit the alignment granularity between language
and actions and exacerbate the challenge of long-horizon video
generation--hindering generative models from achieving a "GPT moment" in the
embodied domain. There is a naive observation: the diversity of embodied data
far exceeds the relatively small space of possible primitive motions. Based on
this insight, we propose a novel paradigm for world modeling--Primitive
Embodied World Models (PEWM). By restricting video generation to fixed short
horizons, our approach 1) enables fine-grained alignment between linguistic
concepts and visual representations of robotic actions, 2) reduces learning
complexity, 3) improves data efficiency in embodied data collection, and 4)
decreases inference latency. By equipping with a modular Vision-Language Model
(VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further
enables flexible closed-loop control and supports compositional generalization
of primitive-level policies over extended, complex tasks. Our framework
leverages the spatiotemporal vision priors in video models and the semantic
awareness of VLMs to bridge the gap between fine-grained physical interaction
and high-level reasoning, paving the way toward scalable, interpretable, and
general-purpose embodied intelligence.

</details>


### [20] [Genetic Informed Trees (GIT*): Path Planning via Reinforced Genetic Programming Heuristics](https://arxiv.org/abs/2508.20871)
*Liding Zhang,Kuanqi Cai,Zhenshan Bing,Chaoqun Wang,Alois Knoll*

Main category: cs.RO

TL;DR: GIT*通过整合更多环境数据和强化遗传编程来优化启发式函数，提高了路径规划的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法因信息关系复杂性而简化启发式函数，忽略了环境数据。GIT*旨在通过更多数据提升规划效果。

Method: 结合强化遗传编程（RGP），利用障碍排斥力和顶点动态重要性等数据优化启发式函数。

Result: GIT*在R^4到R^16问题中优于现有单查询采样规划器，并在实际任务中验证。

Conclusion: GIT*通过数据整合和RGP显著提升路径规划性能。

Abstract: Optimal path planning involves finding a feasible state sequence between a
start and a goal that optimizes an objective. This process relies on heuristic
functions to guide the search direction. While a robust function can improve
search efficiency and solution quality, current methods often overlook
available environmental data and simplify the function structure due to the
complexity of information relationships. This study introduces Genetic Informed
Trees (GIT*), which improves upon Effort Informed Trees (EIT*) by integrating a
wider array of environmental data, such as repulsive forces from obstacles and
the dynamic importance of vertices, to refine heuristic functions for better
guidance. Furthermore, we integrated reinforced genetic programming (RGP),
which combines genetic programming with reward system feedback to mutate
genotype-generative heuristic functions for GIT*. RGP leverages a multitude of
data types, thereby improving computational efficiency and solution quality
within a set timeframe. Comparative analyses demonstrate that GIT* surpasses
existing single-query, sampling-based planners in problems ranging from R^4 to
R^16 and was tested on a real-world mobile manipulation task. A video
showcasing our experimental results is available at
https://youtu.be/URjXbc_BiYg

</details>


### [21] [Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning](https://arxiv.org/abs/2508.20884)
*Liding Zhang,Qiyang Zong,Yu Zhang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: LIT*是一种基于采样和深度模糊学习的运动规划算法，通过动态调整批次大小和最近邻参数，提高规划效率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划算法缺乏环境适应性，需要优化批次大小和最近邻选择等参数。

Method: 提出LIT*，利用深度模糊神经网络动态调整参数，区分障碍物稀疏和密集区域。

Result: LIT*在高维空间展现更快收敛和更优路径质量，优于现有单查询采样规划器。

Conclusion: LIT*通过动态参数调整提升了运动规划的效率和适应性。

Abstract: Efficient motion planning algorithms are essential in robotics. Optimizing
essential parameters, such as batch size and nearest neighbor selection in
sampling-based methods, can enhance performance in the planning process.
However, existing approaches often lack environmental adaptability. Inspired by
the method of the deep fuzzy neural networks, this work introduces
Learning-based Informed Trees (LIT*), a sampling-based deep fuzzy
learning-based planner that dynamically adjusts batch size and nearest neighbor
parameters to obstacle distributions in the configuration spaces. By encoding
both global and local ratios via valid and invalid states, LIT* differentiates
between obstacle-sparse and obstacle-dense regions, leading to lower-cost paths
and reduced computation time. Experimental results in high-dimensional spaces
demonstrate that LIT* achieves faster convergence and improved solution
quality. It outperforms state-of-the-art single-query, sampling-based planners
in environments ranging from R^8 to R^14 and is successfully validated on a
dual-arm robot manipulation task. A video showcasing our experimental results
is available at: https://youtu.be/NrNs9zebWWk

</details>


### [22] [CoCoL: A Communication Efficient Decentralized Collaborative Method for Multi-Robot Systems](https://arxiv.org/abs/2508.20898)
*Jiaxi Huang,Yan Huang,Yixian Zhao,Wenchao Meng,Jinming Xu*

Main category: cs.RO

TL;DR: CoCoL是一种针对多机器人系统的通信高效去中心化协作学习方法，显著减少通信开销，同时在非独立同分布数据等挑战性场景中保持高精度。


<details>
  <summary>Details</summary>
Motivation: 多机器人协作学习在复杂任务中表现优异，但面临高通信开销和数据异构性的挑战。

Method: 采用镜像下降框架，通过近似牛顿型更新和梯度跟踪方案，减少通信轮数和计算成本。

Result: 实验表明，CoCoL在减少通信轮数和带宽消耗的同时保持了高精度，尤其适用于非独立同分布数据和动态网络拓扑场景。

Conclusion: CoCoL为多机器人系统提供了一种高效且鲁棒的协作学习解决方案。

Abstract: Collaborative learning enhances the performance and adaptability of
multi-robot systems in complex tasks but faces significant challenges due to
high communication overhead and data heterogeneity inherent in multi-robot
tasks. To this end, we propose CoCoL, a Communication efficient decentralized
Collaborative Learning method tailored for multi-robot systems with
heterogeneous local datasets. Leveraging a mirror descent framework, CoCoL
achieves remarkable communication efficiency with approximate Newton-type
updates by capturing the similarity between objective functions of robots, and
reduces computational costs through inexact sub-problem solutions. Furthermore,
the integration of a gradient tracking scheme ensures its robustness against
data heterogeneity. Experimental results on three representative multi robot
collaborative learning tasks show the superiority of the proposed CoCoL in
significantly reducing both the number of communication rounds and total
bandwidth consumption while maintaining state-of-the-art accuracy. These
benefits are particularly evident in challenging scenarios involving non-IID
(non-independent and identically distributed) data distribution, streaming
data, and time-varying network topologies.

</details>


### [23] [Language-Enhanced Mobile Manipulation for Efficient Object Search in Indoor Environments](https://arxiv.org/abs/2508.20899)
*Liding Zhang,Zeqi Li,Kuanqi Cai,Qian Huang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 该论文提出了一种语言增强的层次导航框架GODHS，通过结合大型语言模型和多层次决策来提升机器人在复杂环境中搜索物体的效率。


<details>
  <summary>Details</summary>
Motivation: 传统场景表示仅捕获静态语义且缺乏可解释的上下文推理，限制了在陌生环境中指导物体搜索的能力。

Method: 提出GODHS方法，利用大型语言模型推断场景语义，并通过多层次决策和启发式运动规划器优化搜索路径。

Result: 在Isaac Sim中的评估表明，GODHS比传统非语义搜索策略更高效地定位目标物体。

Conclusion: GODHS通过语言模型和层次化推理显著提升了复杂环境中的物体搜索能力。

Abstract: Enabling robots to efficiently search for and identify objects in complex,
unstructured environments is critical for diverse applications ranging from
household assistance to industrial automation. However, traditional scene
representations typically capture only static semantics and lack interpretable
contextual reasoning, limiting their ability to guide object search in
completely unfamiliar settings. To address this challenge, we propose a
language-enhanced hierarchical navigation framework that tightly integrates
semantic perception and spatial reasoning. Our method, Goal-Oriented
Dynamically Heuristic-Guided Hierarchical Search (GODHS), leverages large
language models (LLMs) to infer scene semantics and guide the search process
through a multi-level decision hierarchy. Reliability in reasoning is achieved
through the use of structured prompts and logical constraints applied at each
stage of the hierarchy. For the specific challenges of mobile manipulation, we
introduce a heuristic-based motion planner that combines polar angle sorting
with distance prioritization to efficiently generate exploration paths.
Comprehensive evaluations in Isaac Sim demonstrate the feasibility of our
framework, showing that GODHS can locate target objects with higher search
efficiency compared to conventional, non-semantic search strategies. Website
and Video are available at: https://drapandiger.github.io/GODHS

</details>


### [24] [PLUME: Procedural Layer Underground Modeling Engine](https://arxiv.org/abs/2508.20926)
*Gabriel Manuel Garcia,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: PLUME是一个开源的程序化生成框架，用于快速创建3D地下环境，支持AI训练、机器人算法评估等应用。


<details>
  <summary>Details</summary>
Motivation: 地下环境在太空探索中具有潜力，但现有地球环境难以准确模拟太阳系多样性。

Method: 开发了PLUME框架，采用灵活结构生成地下环境，并结合机器人模拟器进行验证。

Result: PLUME成功生成多样地下环境，可用于多种技术开发和测试。

Conclusion: PLUME为太空探索技术开发提供了高效、灵活的工具，代码已开源。

Abstract: As space exploration advances, underground environments are becoming
increasingly attractive due to their potential to provide shelter, easier
access to resources, and enhanced scientific opportunities. Although such
environments exist on Earth, they are often not easily accessible and do not
accurately represent the diversity of underground environments found throughout
the solar system. This paper presents PLUME, a procedural generation framework
aimed at easily creating 3D underground environments. Its flexible structure
allows for the continuous enhancement of various underground features, aligning
with our expanding understanding of the solar system. The environments
generated using PLUME can be used for AI training, evaluating robotics
algorithms, 3D rendering, and facilitating rapid iteration on developed
exploration algorithms. In this paper, it is demonstrated that PLUME has been
used along with a robotic simulator. PLUME is open source and has been released
on Github. https://github.com/Gabryss/P.L.U.M.E

</details>


### [25] [ActLoc: Learning to Localize on the Move via Active Viewpoint Selection](https://arxiv.org/abs/2508.20981)
*Jiajie Li,Boyang Sun,Luca Di Giammarino,Hermann Blum,Marc Pollefeys*

Main category: cs.RO

TL;DR: 提出了一种名为ActLoc的主动视角感知规划框架，通过注意力模型选择视角，提升机器人导航的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有定位系统假设所有视角同等信息丰富，但在实践中，观察未映射或模糊区域时定位不可靠。

Method: ActLoc采用大规模训练的注意力模型预测3D位置上的定位精度分布，并将其整合到路径规划器中，选择最优视角。

Result: ActLoc在单视角选择和全轨迹规划中均达到最优效果。

Conclusion: ActLoc的模块化设计使其适用于多种机器人导航和检查任务。

Abstract: Reliable localization is critical for robot navigation, yet most existing
systems implicitly assume that all viewing directions at a location are equally
informative. In practice, localization becomes unreliable when the robot
observes unmapped, ambiguous, or uninformative regions. To address this, we
present ActLoc, an active viewpoint-aware planning framework for enhancing
localization accuracy for general robot navigation tasks. At its core, ActLoc
employs a largescale trained attention-based model for viewpoint selection. The
model encodes a metric map and the camera poses used during map construction,
and predicts localization accuracy across yaw and pitch directions at arbitrary
3D locations. These per-point accuracy distributions are incorporated into a
path planner, enabling the robot to actively select camera orientations that
maximize localization robustness while respecting task and motion constraints.
ActLoc achieves stateof-the-art results on single-viewpoint selection and
generalizes effectively to fulltrajectory planning. Its modular design makes it
readily applicable to diverse robot navigation and inspection tasks.

</details>


### [26] [UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception](https://arxiv.org/abs/2508.20982)
*Junhao Gong,Kit-Wa Sou,Shoujie Li,Changqing Guo,Yan Huang,Chuqiao Lyu,Ziwu Song,Wenbo Ding*

Main category: cs.RO

TL;DR: UltraTac是一种结合视觉触觉成像与超声传感的集成传感器，通过同轴光声架构实现高分辨触觉信息与材料特征感知。


<details>
  <summary>Details</summary>
Motivation: 传统视觉触觉传感器无法感知物体的材料特征，限制了其在复杂操作中的应用。

Method: 采用同轴光声架构，共享结构组件和传感区域，并加入声学匹配技术，实现视觉触觉与超声传感的无损集成。

Result: 实验显示传感器具备近距离传感（3-8厘米，R²=0.90）、材料分类（平均准确率99.20%）和纹理-材料双模式识别（15类任务准确率92.11%）。

Conclusion: UltraTac在机器人操作系统中验证了其在人机交互和精确操作中的潜力。

Abstract: Visuotactile sensors provide high-resolution tactile information but are
incapable of perceiving the material features of objects. We present UltraTac,
an integrated sensor that combines visuotactile imaging with ultrasound sensing
through a coaxial optoacoustic architecture. The design shares structural
components and achieves consistent sensing regions for both modalities.
Additionally, we incorporate acoustic matching into the traditional
visuotactile sensor structure, enabling integration of the ultrasound sensing
modality without compromising visuotactile performance. Through tactile
feedback, we dynamically adjust the operating state of the ultrasound module to
achieve flexible functional coordination. Systematic experiments demonstrate
three key capabilities: proximity sensing in the 3-8 cm range ($R^2=0.90$),
material classification (average accuracy: 99.20%), and texture-material
dual-mode object recognition achieving 92.11% accuracy on a 15-class task.
Finally, we integrate the sensor into a robotic manipulation system to
concurrently detect container surface patterns and internal content, which
verifies its potential for advanced human-machine interaction and precise
robotic manipulation.

</details>


### [27] [Rapid Mismatch Estimation via Neural Network Informed Variational Inference](https://arxiv.org/abs/2508.21007)
*Mateusz Jaszczuk,Nadia Figueroa*

Main category: cs.RO

TL;DR: 论文介绍了Rapid Mismatch Estimation (RME)，一种自适应、不依赖外部力传感器的框架，用于在线估计机器人末端执行器的动态模型不匹配，以提升安全和交互性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人日益与人类交互的环境中，确保软性和安全的物理交互至关重要，而现有方法依赖于精确的动力学模型，模型不匹配会导致任务失败和不安全行为。

Method: RME结合神经网络模型不匹配估计器和变分推断求解器，通过机器人本体反馈在线估计未知参数及其不确定性，适应动态变化。

Result: 在真实7自由度机械臂上，RME在约400毫秒内适应末端执行器的质量和重心变化，展示了快速且安全的动态适应能力。

Conclusion: RME在协作场景中表现出色，能够快速适应物理交互中的动态变化，无需依赖外部传感系统。

Abstract: With robots increasingly operating in human-centric environments, ensuring
soft and safe physical interactions, whether with humans, surroundings, or
other machines, is essential. While compliant hardware can facilitate such
interactions, this work focuses on impedance controllers that allow
torque-controlled robots to safely and passively respond to contact while
accurately executing tasks. From inverse dynamics to quadratic
programming-based controllers, the effectiveness of these methods relies on
accurate dynamics models of the robot and the object it manipulates. Any model
mismatch results in task failures and unsafe behaviors. Thus, we introduce
Rapid Mismatch Estimation (RME), an adaptive, controller-agnostic,
probabilistic framework that estimates end-effector dynamics mismatches online,
without relying on external force-torque sensors. From the robot's
proprioceptive feedback, a Neural Network Model Mismatch Estimator generates a
prior for a Variational Inference solver, which rapidly converges to the
unknown parameters while quantifying uncertainty. With a real 7-DoF manipulator
driven by a state-of-the-art passive impedance controller, RME adapts to sudden
changes in mass and center of mass at the end-effector in $\sim400$ ms, in
static and dynamic settings. We demonstrate RME in a collaborative scenario
where a human attaches an unknown basket to the robot's end-effector and
dynamically adds/removes heavy items, showcasing fast and safe adaptation to
changing dynamics during physical interaction without any external sensory
system.

</details>


### [28] [HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning](https://arxiv.org/abs/2508.21043)
*Zhi Su,Bike Zhang,Nima Rahmanian,Yuman Gao,Qiayuan Liao,Caitlin Regan,Koushil Sreenath,S. Shankar Sastry*

Main category: cs.RO

TL;DR: 本文提出了一种层次化框架，用于解决人形机器人在动态环境中的快速交互挑战，通过结合基于模型的轨迹预测和强化学习的全身控制，实现了高敏捷性和精确度的乒乓球任务。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在动态环境中（如乒乓球）需要快速感知、预测和反应，但目前技术仍受限于子秒级的反应时间。文章旨在通过综合方法提升机器人的敏捷性和精确度。

Method: 采用层次化框架，结合基于模型的球轨迹预测和强化学习的全身控制器，并引入人体运动参考以生成自然的动作。

Result: 在通用人形机器人上实现最多106次连续击球，并成功与人类和机器人对手进行持续交互。

Conclusion: 该方法实现了人形机器人在乒乓球任务中的子秒级反应控制，为敏捷和交互式的人形行为提供了一步进展。

Abstract: Humanoid robots have recently achieved impressive progress in locomotion and
whole-body control, yet they remain constrained in tasks that demand rapid
interaction with dynamic environments through manipulation. Table tennis
exemplifies such a challenge: with ball speeds exceeding 5 m/s, players must
perceive, predict, and act within sub-second reaction times, requiring both
agility and precision. To address this, we present a hierarchical framework for
humanoid table tennis that integrates a model-based planner for ball trajectory
prediction and racket target planning with a reinforcement learning-based
whole-body controller. The planner determines striking position, velocity and
timing, while the controller generates coordinated arm and leg motions that
mimic human strikes and maintain stability and agility across consecutive
rallies. Moreover, to encourage natural movements, human motion references are
incorporated during training. We validate our system on a general-purpose
humanoid robot, achieving up to 106 consecutive shots with a human opponent and
sustained exchanges against another humanoid. These results demonstrate
real-world humanoid table tennis with sub-second reactive control, marking a
step toward agile and interactive humanoid behaviors.

</details>


### [29] [Prompt-to-Product: Generative Assembly via Bimanual Manipulation](https://arxiv.org/abs/2508.21063)
*Ruixuan Liu,Philip Huang,Ava Pun,Kangle Deng,Shobhit Aggarwal,Kevin Tang,Michelle Liu,Deva Ramanan,Jun-Yan Zhu,Jiaoyang Li,Changliu Liu*

Main category: cs.RO

TL;DR: 通过Prompt-to-Product自动化流程，从自然语言提示生成可实际组装的乐高积木产品。


<details>
  <summary>Details</summary>
Motivation: 降低设计组装的复杂性和手工工作量，将用户创意快速转化为实际产品。

Method: 利用自然语言提示生成可组装的积木设计，并通过双手机器人系统完成构造。

Result: 用户研究表明，该方法显著降低了组装产品的门槛和工作量。

Conclusion: Prompt-to-Product为创意到产品的转化提供了高效的自动化解决方案。

Abstract: Creating assembly products demands significant manual effort and expert
knowledge in 1) designing the assembly and 2) constructing the product. This
paper introduces Prompt-to-Product, an automated pipeline that generates
real-world assembly products from natural language prompts. Specifically, we
leverage LEGO bricks as the assembly platform and automate the process of
creating brick assembly structures. Given the user design requirements,
Prompt-to-Product generates physically buildable brick designs, and then
leverages a bimanual robotic system to construct the real assembly products,
bringing user imaginations into the real world. We conduct a comprehensive user
study, and the results demonstrate that Prompt-to-Product significantly lowers
the barrier and reduces manual effort in creating assembly products from
imaginative ideas.

</details>


### [30] [Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation](https://arxiv.org/abs/2508.21065)
*Jiahe Pan,Jiaxu Xing,Rudolf Reiter,Yifan Zhai,Elie Aljalbout,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 论文提出了一种在线自适应学习框架，通过实时调整策略应对现实世界的未建模动态和扰动，提升了仿真到现实的策略迁移效果。


<details>
  <summary>Details</summary>
Motivation: 解决仿真到现实的策略迁移问题，避免传统方法在非分布条件或离线重训练时的局限性。

Method: 结合残差动力学学习和实时策略调整，在可微分仿真中连续优化模型以适应未建模效应。

Result: 在5秒内实现策略调整，无人机悬停误差降低81%（相比L1-MPC）和55%（相比DATT）。

Conclusion: 框架有效提升了策略的快速适应性和鲁棒性，适用于实时控制任务。

Abstract: Learning control policies in simulation enables rapid, safe, and
cost-effective development of advanced robotic capabilities. However,
transferring these policies to the real world remains difficult due to the
sim-to-real gap, where unmodeled dynamics and environmental disturbances can
degrade policy performance. Existing approaches, such as domain randomization
and Real2Sim2Real pipelines, can improve policy robustness, but either struggle
under out-of-distribution conditions or require costly offline retraining. In
this work, we approach these problems from a different perspective. Instead of
relying on diverse training conditions before deployment, we focus on rapidly
adapting the learned policy in the real world in an online fashion. To achieve
this, we propose a novel online adaptive learning framework that unifies
residual dynamics learning with real-time policy adaptation inside a
differentiable simulation. Starting from a simple dynamics model, our framework
refines the model continuously with real-world data to capture unmodeled
effects and disturbances such as payload changes and wind. The refined dynamics
model is embedded in a differentiable simulation framework, enabling gradient
backpropagation through the dynamics and thus rapid, sample-efficient policy
updates beyond the reach of classical RL methods like PPO. All components of
our system are designed for rapid adaptation, enabling the policy to adjust to
unseen disturbances within 5 seconds of training. We validate the approach on
agile quadrotor control under various disturbances in both simulation and the
real world. Our framework reduces hovering error by up to 81% compared to
L1-MPC and 55% compared to DATT, while also demonstrating robustness in
vision-based control without explicit state estimation.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [31] [Electrical Impedance Tomography with an Integrated Picoliter-Volume Subtractive Microfluidic Chamber in 65 nm CMOS](https://arxiv.org/abs/2508.20431)
*Antonio Victor Machado de Oliveira,Debjit Sarkar,Ali Hajimiri*

Main category: physics.ins-det

TL;DR: 首次在CMOS芯片中实现了完全集成的微流控与电子学的电阻抗断层成像系统，通过后处理在65纳米CMOS芯片的互连层中制造腔室和电极，实现了皮升级体积的样本处理与成像。


<details>
  <summary>Details</summary>
Motivation: 探索CMOS技术作为微流控和电子学共集成平台的潜力，实现高精度的微流控样本成像和分析。

Method: 在65纳米CMOS芯片的互连层中制造微流控腔室和16电极阵列，通过外部数据处理重建断层图像。

Result: 成功实现了皮升级样本的电阻抗断层成像，并分析了系统重建过程中的误差来源。

Conclusion: 本工作为CMOS作为微流控与电子学共集成平台提供了概念验证，展示了其在微流控成像领域的应用潜力。

Abstract: Electrical impedance tomography with fully integrated microfluidics and
electronics is presented for the first time in a CMOS chip. Chambers and
electrodes are fabricated in the interconnect layers of a 65 nm CMOS chip
through post-processing, enabling picoliter-volumes to be processed and imaged.
Tomography maps are reconstructed by reading out voltages from a 16-element
electrode array and processing the data off-chip, and sources of variation in
reconstruction are discussed. The EIT system presented in this work serves as a
proof-of-concept towards using CMOS as a platform for co-integrated
microfluidics and electronics.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [32] [Regulation-Aware Game-Theoretic Motion Planning for Autonomous Racing](https://arxiv.org/abs/2508.20203)
*Francesco Prignoli,Francesco Borrelli,Paolo Falcone,Mark Pustilnik*

Main category: eess.SY

TL;DR: 该论文提出了一种用于自动驾驶赛车场景的规则感知运动规划框架，通过结合博弈论和模型预测控制，生成既安全又高效的超车策略。


<details>
  <summary>Details</summary>
Motivation: 赛车场景中，自动驾驶车辆需要遵守规则并与其他车辆互动，现有方法往往忽略规则或对手行为，导致保守或不安全的策略。

Method: 使用混合逻辑动态约束编码规则，将车辆交互建模为广义纳什均衡问题，并引入迭代最佳响应和博弈论规划器RA-GTP。

Result: 仿真结果表明，RA-GTP优于忽略对手或规则的方法，能生成更有效且合规的策略。

Conclusion: 该框架成功将规则约束与博弈论结合，提升了自动驾驶赛车场景的运动规划性能。

Abstract: This paper presents a regulation-aware motion planning framework for
autonomous racing scenarios. Each agent solves a Regulation-Compliant Model
Predictive Control problem, where racing rules - such as right-of-way and
collision avoidance responsibilities - are encoded using Mixed Logical
Dynamical constraints. We formalize the interaction between vehicles as a
Generalized Nash Equilibrium Problem (GNEP) and approximate its solution using
an Iterative Best Response scheme. Building on this, we introduce the
Regulation-Aware Game-Theoretic Planner (RA-GTP), in which the attacker reasons
over the defender's regulation-constrained behavior. This game-theoretic layer
enables the generation of overtaking strategies that are both safe and
non-conservative. Simulation results demonstrate that the RA-GTP outperforms
baseline methods that assume non-interacting or rule-agnostic opponent models,
leading to more effective maneuvers while consistently maintaining compliance
with racing regulations.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [33] [Encoding Tactile Stimuli for Organoid Intelligence in Braille Recognition](https://arxiv.org/abs/2508.20850)
*Tianyi Liu,Hemma Philamore,Benjamin Ward-Cherrier*

Main category: cs.NE

TL;DR: 该研究提出了一种通用的编码策略，将触觉传感器数据映射到电刺激模式，使神经类器官能够执行开环人工触觉盲文分类任务。通过多器官配置提升分类准确性和抗噪性。


<details>
  <summary>Details</summary>
Motivation: 探索神经类器官作为低功耗、自适应生物混合计算元件的潜力，并为未来可扩展的生物混合计算架构提供基础编码框架。

Method: 使用低密度微电极阵列培养的人前脑类器官，通过电刺激参数（脉冲数、相位幅度、相位持续时间和触发延迟）和类器官响应（峰活动与活动中心的空间位移）的关系进行系统表征。基于Evetac传感器的事件触觉输入实现。

Result: 单个类器官的盲文字母分类平均准确率为61％，三器官组合提升至83％。多器官配置增强了抗噪性。

Conclusion: 研究展示了类器官作为生物混合计算元件的潜力，为未来架构提供了基础框架。

Abstract: This study proposes a generalizable encoding strategy that maps tactile
sensor data to electrical stimulation patterns, enabling neural organoids to
perform an open-loop artificial tactile Braille classification task. Human
forebrain organoids cultured on a low-density microelectrode array (MEA) are
systematically stimulated to characterize the relationship between electrical
stimulation parameters (number of pulse, phase amplitude, phase duration, and
trigger delay) and organoid responses, measured as spike activity and spatial
displacement of the center of activity. Implemented on event-based tactile
inputs recorded from the Evetac sensor, our system achieved an average Braille
letter classification accuracy of 61 percent with a single organoid, which
increased significantly to 83 percent when responses from a three-organoid
ensemble were combined. Additionally, the multi-organoid configuration
demonstrated enhanced robustness against various types of artificially
introduced noise. This research demonstrates the potential of organoids as
low-power, adaptive bio-hybrid computational elements and provides a
foundational encoding framework for future scalable bio-hybrid computing
architectures.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [34] [Achieving Optimal Performance-Cost Trade-Off in Hierarchical Cell-Free Massive MIMO](https://arxiv.org/abs/2508.20704)
*Wei Jiang,Hans D Schotten*

Main category: cs.IT

TL;DR: 本文提出了一种分层无蜂窝（HCF）大规模MIMO设计，通过用中央基站替换部分接入点（AP），降低成本的同时保持性能。通过分析，发现HCF采用集中式零迫组合在性能和成本效率之间达到了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 解决无蜂窝（CF）大规模MIMO因分布式接入点（AP）部署成本高的问题，提出分层无蜂窝（HCF）设计，以降低前传网络成本并保持性能。

Method: 开发统一的分析框架支持任意组合方案，并提出针对HCF两层级架构的层级组合方法，通过分析用户公平性、系统容量、前传需求和计算复杂度进行优化。

Result: HCF采用集中式零迫组合能够在性能和成本效率之间达到最佳平衡。

Conclusion: HCF设计在降低成本的同时保持了性能，集中式零迫组合是实现这一目标的关键。

Abstract: Cell-free (CF) massive MIMO offers uniform service via distributed access
points (APs), which impose high deployment costs. A novel design called
hierarchical cell-free (HCF) addresses this problem by replacing some APs with
a central base station, thereby lowering the costs of fronthaul network
(wireless sites and fiber cables) while preserving performance. To identify the
optimal uplink configuration in HCF massive MIMO, this paper provides the first
comprehensive analysis, benchmarking it against cellular and CF systems. We
develop a unified analytical framework for spectral efficiency that supports
arbitrary combining schemes and introduce a novel hierarchical combining
approach tailored to HCF two-tier architecture. Through analysis and evaluation
of user fairness, system capacity, fronthaul requirements, and computational
complexity, this paper identifies that HCF using centralized zero-forcing
combining achieves the optimal balance between performance and cost-efficiency.

</details>


### [35] [What is the Most Efficient Technique for Uplink Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.20708)
*Wei Jiang,Hans D. Schotten*

Main category: cs.IT

TL;DR: 本文提出了一种统一的分析框架，确定了无蜂窝大规模MIMO系统中最优化的上行链路技术，并评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究方法论分散且假设不一致，限制了无蜂窝大规模MIMO系统的性能评估和优化。

Method: 建立了兼容集中式/分布式处理的分析框架，开发了通用的最大最小功率控制优化策略，并进行了全面的性能指标研究。

Result: 通过分析和评估，确定了适用于实际无蜂窝部署的最优上行链路技术。

Conclusion: 本论文为无蜂窝大规模MIMO系统的上行链路技术提供了统一的解决方案和性能评估。

Abstract: This paper seeks to determine the most efficient uplink technique for
cell-free massive MIMO systems. Despite offering great advances, existing works
suffer from fragmented methodologies and inconsistent assumptions (e.g.,
single- vs. multi-antenna access points, ideal vs. spatially correlated
channels). To address these limitations, we: (1) establish a unified analytical
framework compatible with centralized/distributed processing and diverse
combining schemes; (2) develop a universal optimization strategy for max-min
power control; and (3) conduct a holistic study among four critical metrics:
worst-case user spectral efficiency (fairness), system capacity, fronthaul
signaling, and computational complexity. Through analyses and evaluation, this
work ultimately identifies the optimal uplink technique for practical cell-free
deployments.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [36] [Enhancing Automatic Modulation Recognition With a Reconstruction-Driven Vision Transformer Under Limited Labels](https://arxiv.org/abs/2508.20193)
*Hossein Ahmadi,Banafsheh Saffari*

Main category: cs.CV

TL;DR: 提出了一种基于Vision Transformer的统一框架，通过整合监督、自监督和重建目标，解决自动调制识别中的标签效率问题，并在低标签率下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有自动调制识别方法依赖大量标注数据或多阶段训练，限制了可扩展性和泛化能力。

Method: 结合ViT编码器、轻量卷积解码器和线性分类器，通过重建目标增强特征学习，并在微调阶段利用部分标签监督。

Result: 在RML2018.01A数据集上，低标签率下优于CNN和ViT基线，仅需15-20%标注数据即可接近ResNet精度。

Conclusion: 该框架为AMR提供了一种简单、泛化性强且标签高效的新方法。

Abstract: Automatic modulation recognition (AMR) is critical for cognitive radio,
spectrum monitoring, and secure wireless communication. However, existing
solutions often rely on large labeled datasets or multi-stage training
pipelines, which limit scalability and generalization in practice. We propose a
unified Vision Transformer (ViT) framework that integrates supervised,
self-supervised, and reconstruction objectives. The model combines a ViT
encoder, a lightweight convolutional decoder, and a linear classifier; the
reconstruction branch maps augmented signals back to their originals, anchoring
the encoder to fine-grained I/Q structure. This strategy promotes robust,
discriminative feature learning during pretraining, while partial label
supervision in fine-tuning enables effective classification with limited
labels. On the RML2018.01A dataset, our approach outperforms supervised CNN and
ViT baselines in low-label regimes, approaches ResNet-level accuracy with only
15-20% labeled data, and maintains strong performance across varying SNR
levels. Overall, the framework provides a simple, generalizable, and
label-efficient solution for AMR.

</details>


### [37] [SKGE-SWIN: End-To-End Autonomous Vehicle Waypoint Prediction and Navigation Using Skip Stage Swin Transformer](https://arxiv.org/abs/2508.20762)
*Fachri Najm Noer Kartiman,Rasim,Yaya Wihardi,Nurul Hasanah,Oskar Natan,Bambang Wahono,Taufik Ibnu Salim*

Main category: cs.CV

TL;DR: 该研究提出了一种端到端的自动驾驶模型SKGE-Swin，利用Swin Transformer和跳跃级机制增强全局和局部特征的表示能力，并在CARLA平台上通过对抗场景验证了其优越的驾驶评分。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够从像素层面理解复杂环境信息的自动驾驶模型，以提升车辆对周围环境的感知能力。

Method: 采用Swin Transformer结合跳跃级机制，利用SW-MSA机制提取远距离像素信息，并保留关键特征。

Result: 在CARLA平台上，SKGE-Swin架构的表现优于现有方法，驾驶评分更高。

Conclusion: SKGE-Swin架构通过结合Swin Transformer和跳跃级机制，显著提升了自动驾驶模型的环境理解能力。

Abstract: Focusing on the development of an end-to-end autonomous vehicle model with
pixel-to-pixel context awareness, this research proposes the SKGE-Swin
architecture. This architecture utilizes the Swin Transformer with a skip-stage
mechanism to broaden feature representation globally and at various network
levels. This approach enables the model to extract information from distant
pixels by leveraging the Swin Transformer's Shifted Window-based Multi-head
Self-Attention (SW-MSA) mechanism and to retain critical information from the
initial to the final stages of feature extraction, thereby enhancing its
capability to comprehend complex patterns in the vehicle's surroundings. The
model is evaluated on the CARLA platform using adversarial scenarios to
simulate real-world conditions. Experimental results demonstrate that the
SKGE-Swin architecture achieves a superior Driving Score compared to previous
methods. Furthermore, an ablation study will be conducted to evaluate the
contribution of each architectural component, including the influence of skip
connections and the use of the Swin Transformer, in improving model
performance.

</details>


### [38] [To New Beginnings: A Survey of Unified Perception in Autonomous Vehicle Software](https://arxiv.org/abs/2508.20892)
*Loïc Stratil,Felix Fent,Esteban Rivera,Markus Lienkamp*

Main category: cs.CV

TL;DR: 摘要介绍了自动驾驶感知的统一感知范式的综合调查，提出了分类方法并定义了三种范示，总结了现有方法并指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 解决传统模块化感知管道的错误积累和子任务协同不足的问题。

Method: 提出任务整合、跟踪公式化和表示流的分类法，定义早期、晚期和完全统一感知三种范示。

Result: 建立了首个综合框架，整理了现有方法并强调了开源可用性。

Conclusion: 统一感知范式有望提高鲁棒性和可解释性，并指导未来研究。

Abstract: Autonomous vehicle perception typically relies on modular pipelines that
decompose the task into detection, tracking, and prediction. While
interpretable, these pipelines suffer from error accumulation and limited
inter-task synergy. Unified perception has emerged as a promising paradigm that
integrates these sub-tasks within a shared architecture, potentially improving
robustness, contextual reasoning, and efficiency while retaining interpretable
outputs. In this survey, we provide a comprehensive overview of unified
perception, introducing a holistic and systemic taxonomy that categorizes
methods along task integration, tracking formulation, and representation flow.
We define three paradigms -Early, Late, and Full Unified Perception- and
systematically review existing methods, their architectures, training
strategies, datasets used, and open-source availability, while highlighting
future research directions. This work establishes the first comprehensive
framework for understanding and advancing unified perception, consolidates
fragmented efforts, and guides future research toward more robust,
generalizable, and interpretable perception.

</details>


### [39] [COMETH: Convex Optimization for Multiview Estimation and Tracking of Humans](https://arxiv.org/abs/2508.20920)
*Enrico Martini,Ho Jin Choi,Nadia Figueroa,Nicola Bombieri*

Main category: cs.CV

TL;DR: COMETH是一种轻量级算法，通过凸优化和多视角融合技术，解决边缘设备资源受限和计算不一致性问题，显著提升了人体姿态估计的准确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 在工业5.0时代，多摄像头集中式设置虽然提高了姿态估计准确性，但存在高计算成本和带宽需求的问题。分布式边缘设备虽能缓解这一问题，却因资源受限导致准确性下降和时空不一致性。

Method: 提出COMETH算法，结合运动学和生物力学约束、基于凸优化的逆运动学空间融合技术以及状态观测器，以提升姿态估计的时空一致性和准确性。

Result: 在公开和工业数据集上，COMETH在定位、检测和跟踪准确性上优于现有方法，实现了高精度和可扩展的人体运动跟踪。

Conclusion: COMETH为工业和安全性关键应用提供了准确且可扩展的实时人体姿态跟踪解决方案，代码已开源。

Abstract: In the era of Industry 5.0, monitoring human activity is essential for
ensuring both ergonomic safety and overall well-being. While multi-camera
centralized setups improve pose estimation accuracy, they often suffer from
high computational costs and bandwidth requirements, limiting scalability and
real-time applicability. Distributing processing across edge devices can reduce
network bandwidth and computational load. On the other hand, the constrained
resources of edge devices lead to accuracy degradation, and the distribution of
computation leads to temporal and spatial inconsistencies. We address this
challenge by proposing COMETH (Convex Optimization for Multiview Estimation and
Tracking of Humans), a lightweight algorithm for real-time multi-view human
pose fusion that relies on three concepts: it integrates kinematic and
biomechanical constraints to increase the joint positioning accuracy; it
employs convex optimization-based inverse kinematics for spatial fusion; and it
implements a state observer to improve temporal consistency. We evaluate COMETH
on both public and industrial datasets, where it outperforms state-of-the-art
methods in localization, detection, and tracking accuracy. The proposed fusion
pipeline enables accurate and scalable human motion tracking, making it
well-suited for industrial and safety-critical applications. The code is
publicly available at https://github.com/PARCO-LAB/COMETH.

</details>


### [40] [CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification](https://arxiv.org/abs/2508.21046)
*Wei Li,Renshan Zhang,Rui Shao,Jie He,Liqiang Nie*

Main category: cs.CV

TL;DR: CogVLA是一个基于认知对齐的视觉-语言-动作框架，通过指令驱动的路由和稀疏化方法提升效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作模型因后训练需求高而导致的计算开销过大问题。

Method: 采用三阶段渐进式架构：EFA-Routing选择性压缩视觉标记，LFP-Routing剪枝无关标记，以及CAtten结合注意机制支持动作生成。

Result: 在LIBERO基准和实际机器人任务中，分别达到97.4%和70.0%的成功率，同时降低2.5倍训练成本和2.8倍推理延迟。

Conclusion: CogVLA在效率和性能上均优于现有方法，并已开源。

Abstract: Recent Vision-Language-Action (VLA) models built on pre-trained
Vision-Language Models (VLMs) require extensive post-training, resulting in
high computational overhead that limits scalability and deployment.We propose
CogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages
instruction-driven routing and sparsification to improve both efficiency and
performance. CogVLA draws inspiration from human multimodal coordination and
introduces a 3-stage progressive architecture. 1) Encoder-FiLM based
Aggregation Routing (EFA-Routing) injects instruction information into the
vision encoder to selectively aggregate and compress dual-stream visual tokens,
forming a instruction-aware latent representation. 2) Building upon this
compact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)
introduces action intent into the language model by pruning
instruction-irrelevant visually grounded tokens, thereby achieving token-level
sparsity. 3) To ensure that compressed perception inputs can still support
accurate and coherent action generation, we introduce V-L-A Coupled Attention
(CAtten), which combines causal vision-language attention with bidirectional
action parallel decoding. Extensive experiments on the LIBERO benchmark and
real-world robotic tasks demonstrate that CogVLA achieves state-of-the-art
performance with success rates of 97.4% and 70.0%, respectively, while reducing
training costs by 2.5-fold and decreasing inference latency by 2.8-fold
compared to OpenVLA. CogVLA is open-sourced and publicly available at
https://github.com/JiuTian-VL/CogVLA.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [41] [Live Vocal Extraction from K-pop Performances](https://arxiv.org/abs/2508.20273)
*Yujin Kim,Richa Namballa,Magdalena Fuentes*

Main category: eess.AS

TL;DR: 提出了从K-pop现场表演中自动提取现场人声的方法，结合源分离、互相关和振幅缩放技术。


<details>
  <summary>Details</summary>
Motivation: 受K-pop粉丝文化的启发，旨在解决现场表演中预录人声与音乐的分离问题。

Method: 结合源分离、互相关和振幅缩放技术，自动去除预录人声和伴奏。

Result: 初步工作为现场人声分离任务奠定了基础。

Conclusion: 为未来相关研究提供了方向和技术支持。

Abstract: K-pop's global success is fueled by its dynamic performances and vibrant fan
engagement. Inspired by K-pop fan culture, we propose a methodology for
automatically extracting live vocals from performances. We use a combination of
source separation, cross-correlation, and amplitude scaling to automatically
remove pre-recorded vocals and instrumentals from a live performance. Our
preliminary work introduces the task of live vocal separation and provides a
foundation for future research in this topic.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [42] [Adaptive Segmentation of EEG for Machine Learning Applications](https://arxiv.org/abs/2508.20336)
*Johnson Zhou,Joseph West,Krista A. Ehinger,Zhenming Ren,Sam E. John,David B. Grayden*

Main category: cs.LG

TL;DR: 论文提出了一种自适应分割方法CTXSEG，用于改进EEG信号的分割，提升了癫痫检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定时间分割EEG信号的方法缺乏生物学依据，作者研究自适应分割是否对机器学习分析更有利。

Method: 提出CTXSEG方法，基于EEG数据的统计差异生成可变长度分段，并结合现代机器学习方法。

Result: CTXSEG在癫痫检测中表现优于固定长度分割，且所需分段更少。

Conclusion: 自适应分割CTXSEG是EEG机器学习预处理的有前景的替代方法。

Abstract: Objective. Electroencephalography (EEG) data is derived by sampling
continuous neurological time series signals. In order to prepare EEG signals
for machine learning, the signal must be divided into manageable segments. The
current naive approach uses arbitrary fixed time slices, which may have limited
biological relevance because brain states are not confined to fixed intervals.
We investigate whether adaptive segmentation methods are beneficial for machine
learning EEG analysis.
  Approach. We introduce a novel adaptive segmentation method, CTXSEG, that
creates variable-length segments based on statistical differences in the EEG
data and propose ways to use them with modern machine learning approaches that
typically require fixed-length input. We assess CTXSEG using controllable
synthetic data generated by our novel signal generator CTXGEN. While our CTXSEG
method has general utility, we validate it on a real-world use case by applying
it to an EEG seizure detection problem. We compare the performance of CTXSEG
with fixed-length segmentation in the preprocessing step of a typical EEG
machine learning pipeline for seizure detection.
  Main results. We found that using CTXSEG to prepare EEG data improves seizure
detection performance compared to fixed-length approaches when evaluated using
a standardized framework, without modifying the machine learning method, and
requires fewer segments.
  Significance. This work demonstrates that adaptive segmentation with CTXSEG
can be readily applied to modern machine learning approaches, with potential to
improve performance. It is a promising alternative to fixed-length segmentation
for signal preprocessing and should be considered as part of the standard
preprocessing repertoire in EEG machine learning applications.

</details>


### [43] [Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees](https://arxiv.org/abs/2508.21001)
*Yaniv Hassidof,Tom Jurgenson,Kiril Solovey*

Main category: cs.LG

TL;DR: DiTree框架结合扩散策略（DP）与基于采样的运动规划器（SBPs），显著提升动力学运动规划的性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有SBPs（基于采样的运动规划器）因无目标动作采样导致探索速度慢，以及学习型方法在分布外（OOD）场景中泛化性差的问题。

Method: 提出DiTree框架，利用扩散策略作为智能采样器，结合SBPs的完备性生成安全轨迹。

Result: DiTree在OOD场景中比传统SBPs快3倍，成功率提高30%。

Conclusion: DiTree通过结合DP和SBPs的优势，提供了高效的动力学运动规划解决方案。

Abstract: Kinodynamic motion planning is concerned with computing collision-free
trajectories while abiding by the robot's dynamic constraints. This critical
problem is often tackled using sampling-based planners (SBPs) that explore the
robot's high-dimensional state space by constructing a search tree via action
propagations. Although SBPs can offer global guarantees on completeness and
solution quality, their performance is often hindered by slow exploration due
to uninformed action sampling. Learning-based approaches can yield
significantly faster runtimes, yet they fail to generalize to
out-of-distribution (OOD) scenarios and lack critical guarantees, e.g., safety,
thus limiting their deployment on physical robots. We present Diffusion Tree
(DiTree): a \emph{provably-generalizable} framework leveraging diffusion
policies (DPs) as informed samplers to efficiently guide state-space search
within SBPs. DiTree combines DP's ability to model complex distributions of
expert trajectories, conditioned on local observations, with the completeness
of SBPs to yield \emph{provably-safe} solutions within a few action propagation
iterations for complex dynamical systems. We demonstrate DiTree's power with an
implementation combining the popular RRT planner with a DP action sampler
trained on a \emph{single environment}. In comprehensive evaluations on OOD
scenarios, % DiTree has comparable runtimes to a standalone DP (3x faster than
classical SBPs), while improving the average success rate over DP and SBPs.
DiTree is on average 3x faster than classical SBPs, and outperforms all other
approaches by achieving roughly 30\% higher success rate. Project webpage:
https://sites.google.com/view/ditree.

</details>
