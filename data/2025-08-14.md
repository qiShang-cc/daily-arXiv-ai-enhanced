<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.LG](#cs.LG) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet](https://arxiv.org/abs/2508.09140)
*Honggang Jia,Nan Cheng,Xiucheng Wang,Conghao Zhou,Ruijin Sun,Xuemin,Shen*

Main category: eess.SP

TL;DR: RadioMamba是一种结合Mamba-UNet架构的混合方法，用于构建6G服务中的无线地图（RM），解决了现有深度学习方法的精度-效率权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的RM构建方法在精度和效率之间存在权衡问题，无法同时满足实时性和高精度需求。

Method: 提出了一种混合Mamba-UNet架构，通过Mamba分支（线性复杂度）捕获长距离空间依赖，同时卷积分支提取局部特征。

Result: 实验表明，RadioMamba精度优于现有方法（包括扩散模型），速度提升近20倍，模型参数仅需2.9%。

Conclusion: RadioMamba通过同时提升精度和效率，为下一代无线系统的实时智能优化提供了可行方案。

Abstract: Radio map (RM) has recently attracted much attention since it can provide
real-time and accurate spatial channel information for 6G services and
applications. However, current deep learning-based methods for RM construction
exhibit well known accuracy-efficiency trade-off. In this paper, we introduce
RadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the
trade-off. Generally, accurate RM construction requires modeling long-range
spatial dependencies, reflecting the global nature of wave propagation physics.
RadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures
these global dependencies with linear complexity, while a parallel
convolutional branch extracts local features. This hybrid design generates
feature representations that capture both global context and local detail.
Experiments show that RadioMamba achieves higher accuracy than existing
methods, including diffusion models, while operating nearly 20 times faster and
using only 2.9\% of the model parameters. By improving both accuracy and
efficiency, RadioMamba presents a viable approach for real-time intelligent
optimization in next generation wireless systems.

</details>


### [2] [Bayesian-Driven Graph Reasoning for Active Radio Map Construction](https://arxiv.org/abs/2508.09142)
*Wenlihan Lu,Shijian Gao,Miaowen Wen,Yuxuan Liang,Chan-Byoung Chae,H. Vincent Poor*

Main category: eess.SP

TL;DR: 提出了一种不确定性感知的无线电地图重建框架（URAM），通过图推理和深度学习提高低空经济中无人机的效率和覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 低空经济的发展对无人机无线连接可靠性提出了更高要求，传统导航方式受电池容量限制，覆盖和效率不足。

Method: 结合贝叶斯神经网络实时估计空间不确定性，以及基于注意力的强化学习策略，规划信息丰富且节能的轨迹。

Result: 实验显示URAM将重建精度提升高达34%。

Conclusion: URAM通过智能非短视的轨迹规划，显著提升了无人机在无线电地图重建中的性能。

Abstract: With the emergence of the low-altitude economy, radio maps have become
essential for ensuring reliable wireless connectivity to aerial platforms.
Autonomous aerial agents are commonly deployed for data collection using
waypoint-based navigation; however, their limited battery capacity
significantly constrains coverage and efficiency. To address this, we propose
an uncertainty-aware radio map (URAM) reconstruction framework that explicitly
leverages graph-based reasoning tailored for waypoint navigation. Our approach
integrates two key deep learning components: (1) a Bayesian neural network that
estimates spatial uncertainty in real time, and (2) an attention-based
reinforcement learning policy that performs global reasoning over a
probabilistic roadmap, using uncertainty estimates to plan informative and
energy-efficient trajectories. This graph-based reasoning enables intelligent,
non-myopic trajectory planning, guiding agents toward the most informative
regions while satisfying safety constraints. Experimental results show that
URAM improves reconstruction accuracy by up to 34% over existing baselines.

</details>


### [3] [Generative AI-Enabled Robust 6G Uplink: Principles, Challenges, and Directions](https://arxiv.org/abs/2508.09348)
*Chunmei Xu,Yi Ma,Rahim Tafazolli,Peiying Zhu*

Main category: eess.SP

TL;DR: GenCom 是一种利用生成式 AI 解决 6G 上行链路瓶颈的新系统级范式，通过简化发射端设计并依赖接收端的强大 AI 模型重建高保真内容。


<details>
  <summary>Details</summary>
Motivation: 6G 网络因设备资源限制和信道条件严峻面临上行链路瓶颈，需要创新方案以提升性能。

Method: GenCom 利用生成式 AI，简化发射端设计（如语义保留压缩和弱纠错码），依赖接收端 AI 模型进行信号重建。

Result: GenCom 在低 SNR/SINR 条件下表现优异，优于传统系统。

Conclusion: GenCom 为未来以人为中心、智能和可持续的无线网络提供了潜在解决方案，但仍需解决实用化挑战。

Abstract: Next-generation wireless networks (6G) face a critical uplink bottleneck due
to stringent device-side resource constraints and challenging channel
conditions. This article introduces GenCom, a novel system-level paradigm for
robust 6G uplink that leverages Generative AI and exploits the inherent
resource imbalance between transmitters and receivers. In GenCom, resource-rich
receivers deploy powerful offline-trained GenAI models to reconstruct high
semantic-fidelity content from degraded signals, while resource-constrained
transmitters are simplified in both source and channel coding design. We
present the core mechanisms and key design principles behind GenCom, which
shifts from conventional approaches toward simple semantic-preserving
compression, weak error-distribution codes, and semantic-aware retransmissions.
Through a case study, GenCom is shown to deliver robust performance across a
wide range of low and uncertain SNR/SINR conditions where conventional systems
fail. Finally, we outline critical challenges and research directions toward
making GenCom a practical enabler of future human-centric, intelligent, and
sustainable wireless networks.

</details>


### [4] [Satellites are closer than you think: A near field MIMO approach for Ground stations](https://arxiv.org/abs/2508.09374)
*Rohith Reddy Vennam,Luke Wilson,Ish Kumar Jain,Dinesh Bharadia*

Main category: eess.SP

TL;DR: ArrayLink是一种分布式相控阵架构，通过结合多个小型商用面板实现高增益波束成形，提升低地球轨道卫星与地面站的回传容量。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星星座的快速增长，地面站基础设施的扩展滞后，导致回传容量瓶颈。传统抛物面天线不适合快速移动的LEO网络，而现有的相控阵天线成本高且复杂。

Method: 提出ArrayLink架构，利用16个商用面板分布在千米级孔径上，实现高增益波束成形和空间多路复用。

Result: 实验表明，ArrayLink在增益上接近1.47米反射器（差距1-2 dB），支持最多4个并行数据流，且在数百公里范围内性能稳定。

Conclusion: ArrayLink为提升LEO卫星回传容量提供了一种实用且可扩展的解决方案。

Abstract: The rapid growth of low Earth orbit (LEO) satellite constellations has
revolutionized broadband access, earth observation, and direct-to-device
connectivity. However, the expansion of ground station infrastructure has not
kept pace, creating a critical bottleneck in satellite-to-ground backhaul
capacity. Traditional parabolic dish antennas, though effective for
geostationary (GEO) satellites, are ill-suited for dense, fastmoving LEO
networks due to mechanical steering delays and their inability to track
multiple satellites simultaneously. Phased array antennas offer electronically
steerable beams and multisatellite support, but their integration into ground
stations is limited by the high cost, hardware issues, and complexity of
achieving sufficient antenna gain. We introduce ArrayLink, a distributed phased
array architecture that coherently combines multiple small commercially
available panels to achieve high-gain beamforming and unlock line-of-sight MIMO
spatial multiplexing with minimal additional capital expenditure. By spacing 16
(32x32) panels across a kilometer-scale aperture, ArrayLink enters the
radiative near-field, focusing energy in both angle and range while supporting
up to four simultaneous spatial streams on a single feeder link. Through
rigorous theoretical analysis, detailed 2D beam pattern simulations and
real-world hardware experiments, we show that ArrayLink (i) achieves dish-class
gain with in range 1-2 dB of 1.47 m reflector, (ii) maintains four parallel
streams at ranges of hundreds of kilometers (falling to two beyond 2000 km),
and (iii) exhibits tight agreement across theory, simulation, and experiment
with minimal variance. These findings open a practical and scalable path to
boosting LEO backhaul capacity.

</details>


### [5] [Sub-THz Power Amplifiers: Measurements, Behavioral Modeling and Predistortion Algorithms](https://arxiv.org/abs/2508.09545)
*Lutfi Samara,Simon Haussmann,Erind Tufa,Antonio Alberto D'Amico,Tommaso Zugno,Ingmar Kallfass,Thomas Kürner*

Main category: eess.SP

TL;DR: 论文研究了太赫兹频谱中的功率放大器非线性问题，提出了建模和预失真算法，并展示了通过参数选择优化性能的方法。


<details>
  <summary>Details</summary>
Motivation: 随着全球IMT流量预计增长10-100倍，太赫兹频谱成为解决方案，但其宽带射频组件的非线性问题影响了系统性能。

Method: 使用小信号和大信号连续波测量，开发并验证了AM-AM和AM-PM行为模型，设计了预失真算法。

Result: 模型揭示了低输入功率下的不准确性，预失真算法在多载波波形切换时性能下降，但参数优化可显著改善性能。

Conclusion: 适当选择预失真器参数能显著提升太赫兹频谱中的系统性能。

Abstract: With global IMT traffic expected to grow 10-100 times from 2020 to 20301, the
Terahertz (THz) spectrum offers a promising solution to satisfy such forecasts.
However, occupying the THz spectrum comes with its own challenges, an important
one being impairments caused by broadband RF components in THz transceivers.
Nonlinearities in power amplifiers (PAs) complicate meeting link budget
requirements, with amplitude and phase distortions degrading the system's
performance, especially when adopting waveforms with high peak-to-average power
ratios (PAPRs), such as Orthogonal Frequency Division Multiplexing (OFDM). In
this paper, we present characterization results of a 300 GHz PA using
small-signal and large-signal continuous-wave measurements. Models capturing
Amplitude-to- Amplitude Modulation (AM-AM) and Amplitude-to-Phase Modulation
(AMPM) behavior across 270-330 GHz are developed and verified with wideband
measurements, confirming the compression behavior, while nonetheless showing
inaccuracies for low input powers due to unaccounted frequency dependencies.
Based on the derived models, a predistortion algorithm is designed and
analyzed, revealing significant error performance degradation when switching
between single- and multi-carrier waveforms. We finally show that an
appropriate selection of pre-distorter parameters can significantly improve the
performance.

</details>


### [6] [Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm](https://arxiv.org/abs/2508.09546)
*Dumitra Iancu,Liang Liu,Ove Edfors,Erik Leitinger,Xuhong Li*

Main category: eess.SP

TL;DR: 提出了一种针对分布式MIMO系统的低延迟定位方法，联合检测视距路径并优化硬件处理延迟。


<details>
  <summary>Details</summary>
Motivation: 未来无线系统需要分布式架构和低延迟定位技术，以支持可靠通信和精准定位需求。

Method: 设计了一种基于消息传递的分布式定位方法，结合FPGA操作构建了系统延迟模型。

Result: 该方法在多路径场景下实现低延迟定位，并在硬件利用率和延迟性能上取得平衡。

Conclusion: 相比传统方法，新方法在定位精度相近的同时，显著降低了延迟和计算复杂度。

Abstract: Distributed MIMO and integrated sensing and communication are expected to be
key technologies in future wireless systems, enabling reliable, low-latency
communication and accurate localization. Dedicated localization solutions must
support distributed architecture, provide scalability across different system
configurations and meet strict latency requirements. We present a scalable
message-passing localization method and architecture co-designed for a
panel-based distributed MIMO system and network topology, in which
interconnected units operate without centralized processing. This method
jointly detects line-of-sight paths to distributed units from multipath
measurements in dynamic scenarios, localizes the agent, and achieves very low
latency. Additionally, we introduce a cycle-accurate system latency model based
on implemented FPGA operations, and show important insights into processing
latency and hardware utilization and system-level trade-offs. We compare our
method to a multipath-based localization method and show that it can achieve
similar localization performance, with wide enough distribution of array
elements, while offering lower latency and computational complexity.

</details>


### [7] [Profiling Multi-Level Operator Costs for Bottleneck Diagnosis in High-Speed Data Planes](https://arxiv.org/abs/2508.09574)
*Zhiyuan Ren,Yutao Liu,Wenchi Cheng,Kun Yang*

Main category: eess.SP

TL;DR: 提出了一种基于饱和吞吐量增量的方法，用于精确测量高速数据平面中运算符的成本，无需侵入式工具。该方法揭示了计算密集型运算符的非线性缩放特性，并引入OPQ框架对运算符进行分类。


<details>
  <summary>Details</summary>
Motivation: 在高速数据平面中，精确测量运算符成本是一个挑战，尤其是在不同架构上（如Arm和x86）。传统方法可能无法捕捉非线性缩放行为。

Method: 采用饱和吞吐量增量法，无需侵入式工具，引入OPQ框架将运算符按基础和缩放成本分类。

Result: 发现计算密集型运算符（如CRC）表现出超线性行为，而大多数其他运算符为次线性。OPQ框架揭示了Arm和x86之间的象限转换。

Conclusion: 该方法提供了精确的、架构感知的瓶颈诊断，并为性能建模和优化提供了现实基础。

Abstract: This paper proposes a saturation throughput delta-based methodology to
precisely measure operator costs in high-speed data planes without intrusive
instrumentation. The approach captures non-linear scaling, revealing that
compute-intensive operators like CRC exhibit super-linear behavior, while most
others are sub-linear. We introduce the Operator Performance Quadrant (OPQ)
framework to classify operators by base and scaling costs, exposing a
cross-architecture Quadrant Shift between Arm and x86. This method provides
accurate, architecture-aware bottleneck diagnosis and a realistic basis for
performance modeling and optimization.

</details>


### [8] [3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator](https://arxiv.org/abs/2508.09708)
*Thomas Fehrenbach,Luis Omar Ortiz Abrego,Cornelius Hellge,Thomas Schierl,Jörg Ott*

Main category: eess.SP

TL;DR: 本文研究了用于车辆编队行驶（V2X通信）的组调度模式（Mode 2d），通过分布式资源分配方案满足高可靠性和低延迟需求，模拟结果显示其有效性。


<details>
  <summary>Details</summary>
Motivation: 车辆编队行驶是智能交通系统的关键应用，但现有的无线通信方案难以满足其高可靠性和低延迟需求，因此需要探索新的资源分配方法。

Method: 采用分布式和预定的资源分配方案（Mode 2d），车辆组从配置的资源池中自主选择资源，无需网络辅助支持。

Result: 模拟结果表明，该方案能够满足编队行驶对高可靠性、低延迟和数据速率的要求。

Conclusion: 组调度模式（Mode 2d）是一种有效的资源分配方案，适用于车辆编队行驶的无线通信需求。

Abstract: Vehicle-to-everything (V2X) communication is a key technology for enabling
intelligent transportation systems (ITS) that can improve road safety, traffic
efficiency, and environmental sustainability. Among the various V2X
applications, platooning is one of the most promising ones, as it allows a
group of vehicles to travel closely together at high speeds, reducing fuel
consumption and emissions. However, it poses significant challenges for
wireless communication, such as high reliability and low latency. In this
paper, we evaluate the benefits of group scheduling, also referred to as Mode
2d, which is based on a distributed and scheduled resource allocation scheme
that allows the group of cars to select resources from a configured pool
without network assistance. We evaluated the scheme through simulations, and
the results show that this approach can meet the reliability, low latency, and
data rate requirements for platooning.

</details>


### [9] [CKFNet: Neural Network Aided Cubature Kalman filtering](https://arxiv.org/abs/2508.09727)
*Jinhui Hu,Haiquan Zhao,Yi Peng*

Main category: eess.SP

TL;DR: CKFNet是一种将循环神经网络（RNN）与容积卡尔曼滤波器（CKF）结合的混合架构，通过动态适应未建模的不确定性，提高了非线性估计的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决容积卡尔曼滤波器（CKF）在模型与环境不匹配时性能下降的问题。

Method: 在CKF的预测阶段嵌入RNN模块，动态适应未建模的不确定性，并通过约束优化保持CKF的可解释性。

Result: 实验表明CKFNet在准确性和鲁棒性上优于传统模型驱动方法和现有KalmanNet算法。

Conclusion: CKFNet通过融合RNN与CKF，有效提升了非线性估计性能，同时保留了CKF的理论优势。

Abstract: The cubature Kalman filter (CKF), while theoretically rigorous for nonlinear
estimation, often suffers performance degradation due to model-environment
mismatches in practice. To address this limitation, we propose CKFNet-a hybrid
architecture that synergistically integrates recurrent neural networks (RNN)
with the CKF framework while preserving its cubature principles. Unlike
conventional model-driven approaches, CKFNet embeds RNN modules in the
prediction phase to dynamically adapt to unmodeled uncertainties, effectively
reducing cumulative error propagation through temporal noise correlation
learning. Crucially, the architecture maintains CKF's analytical
interpretability via constrained optimization of cubature point distributions.
Numerical simulation experiments have confirmed that our proposed CKFNet
exhibits superior accuracy and robustness compared to conventional model-based
methods and existing KalmanNet algorithms.

</details>


### [10] [Online Data Generation for MIMO-OFDM Channel Denoising: Transfer Learning vs. Meta Learning](https://arxiv.org/abs/2508.09751)
*Sungyoung Ha,Ikbeom Lee,Seunghyeon Jeon,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 提出了一种标准兼容的策略，用于生成在线训练数据，从而实现在线自适应信道去噪，有效适应动态信道条件并显著减少信道估计误差。


<details>
  <summary>Details</summary>
Motivation: 现有信道去噪技术在适应变化的信道条件时，通常需要先验知识或大量训练开销，面临挑战。

Method: 利用数据辅助的信道估计获取高质量信道估计作为真实信道的替代，并基于此提出两种去噪方法：基于迁移学习的微调方法和基于元学习的快速适应方法。

Result: 仿真结果表明，所提方法能有效适应动态信道条件，显著减少信道估计误差。

Conclusion: 该方法为标准兼容的在线自适应信道去噪提供了有效解决方案。

Abstract: Channel denoising is a practical and effective technique for mitigating
channel estimation errors in multiple-input multiple-output orthogonal
frequency-division multiplexing (MIMO-OFDM) systems. However, adapting
denoising techniques to varying channel conditions typically requires prior
knowledge or incurs significant training overhead. To address these challenges,
we propose a standard-compatible strategy for generating online training data
that enables online adaptive channel denoising. The key idea is to leverage
high-quality channel estimates obtained via data-aided channel estimation as
practical substitutes for unavailable ground-truth channels. Our data-aided
method exploits adjacent detected data symbols within a specific time-frequency
neighborhood as virtual reference signals, and we analytically derive the
optimal size of this neighborhood to minimize the mean squared error of the
resulting estimates. By leveraging the proposed strategy, we devise two channel
denoising approaches, one based on transfer learning, which fine-tunes a
pre-trained denoising neural network, and the other based on meta learning,
which rapidly adapts to new channel environments with minimal updates.
Simulation results demonstrate that the proposed methods effectively adapt to
dynamic channel conditions and significantly reduce channel estimation errors
compared to conventional techniques.

</details>


### [11] [Location Privacy-Enabled Beamforming in ISAC Scenarios](https://arxiv.org/abs/2508.09882)
*Umair Ali Khan,Lester Ho,Holger Claussen,Chinmoy Kundu*

Main category: eess.SP

TL;DR: 提出了一种基于方向到达混淆比（DAOR）的波束成形框架，以保护ISAC场景中的发射机位置隐私，同时优化通信速率。


<details>
  <summary>Details</summary>
Motivation: ISAC技术在实现环境感知和数据传输的同时暴露了用户位置，需要一种新的隐私保护方法。

Method: 通过广义特征值分析推导DAOR的闭式界，并使用半定松弛、特征模选择和最优功率分配解决非凸问题。

Result: DAOR波束成形在隐私和通信速率之间取得平衡，子优化设计在降低85%计算时间下仍接近最优速率。

Conclusion: 该方法有效保护位置隐私并维持通信性能，子优化设计显著降低了计算复杂度。

Abstract: Integrated sensing and communication (ISAC) technology enables simultaneous
environmental perception and data transmission in wireless networks; however,
it also exposes user location to receivers. In this paper, we introduce a novel
beamforming framework guided by the proposed privacy metric direction of
arrival obfuscation ratio (DAOR) to protect transmitter location privacy in
ISAC scenarios. Unlike previous approaches, we do not suppress the
line-of-sight (LOS) component while reshaping the angular power distribution so
that a false direction appears dominant at the receiver. We derive closed-form
bounds on the feasible DAOR via generalized eigenvalue analysis and formulate
an achievable rate-maximization problem under the DAOR constraint. The
resulting problem is non-convex, which is efficiently solved using semidefinite
relaxation, eigenmode selection, and optimal power allocation. A suboptimal
design strategy is also proposed with reduced complexity. Numerical results
demonstrate that the proposed DAOR-based beamformer achieves a trade-off
between location privacy and communication rate without nullifying the LOS
path. Results also show that a suboptimal design achieves a near-optimal
communication rate with nearly an 85% reduction in computation time at a
signal-to-noise ratio (SNR) of 10 dB.

</details>


### [12] [Beam Cross Sections Create Mixtures: Improving Feature Localization in Secondary Electron Imaging](https://arxiv.org/abs/2508.09942)
*Vaibhav Choudhary,Akshay Agarwal,Vivek K Goyal*

Main category: eess.SP

TL;DR: 该论文提出了一种基于混合模型的二次电子成像技术改进方法，通过更精细的建模和最大似然估计，显著提高了边缘定位的精度。


<details>
  <summary>Details</summary>
Motivation: 传统卷积模型仅描述二次电子计数的平均值，无法充分捕捉其分布的复杂性。研究旨在通过更详细的建模提高分辨率。

Method: 论文提出了一种混合模型来描述二次电子计数的分布，并利用时间分辨测量（TRM）和最大似然估计（MLE）进行边缘定位。

Result: 蒙特卡罗模拟显示，与传统插值方法相比，MLE将边缘定位的均方根误差（RMSE）降低了5倍。实际HIM数据集的RMSE平均降低了5.4倍。

Conclusion: 通过更精确的建模和优化，该方法在半导体检测中实现了显著的精度提升，为高分辨率成像提供了新思路。

Abstract: Secondary electron (SE) imaging techniques, such as scanning electron
microscopy and helium ion microscopy (HIM), use electrons emitted by a sample
in response to a focused beam of charged particles incident at a grid of raster
scan positions. Spot size -- the diameter of the incident beam's spatial
profile -- is one of the limiting factors for resolution, along with various
sources of noise in the SE signal. The effect of the beam spatial profile is
commonly understood as convolutional. We show that under a simple and plausible
physical abstraction for the beam, though convolution describes the mean of the
SE counts, the full distribution of SE counts is a mixture. We demonstrate that
this more detailed modeling can enable resolution improvements over
conventional estimators through a stylized application in semiconductor
inspection of localizing the edge in a two-valued sample. We derive Fisher
information about edge location in conventional and time-resolved measurements
(TRM) and also derive the maximum likelihood estimate (MLE) from the latter.
Empirically, the MLE computed from TRM is approximately efficient except at
very low beam diameter, so Fisher information comparisons are predictive of
performance and can be used to optimize the beam diameter relative to the
raster scan spacing. Monte Carlo simulations show that the MLE gives a 5-fold
reduction in root mean-squared error (RMSE) of edge localization as compared to
conventional interpolation-based estimation. Applied to three real HIM
datasets, the average RMSE reduction factor is 5.4.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Bayesian autoregression to optimize temporal Matérn kernel Gaussian process hyperparameters](https://arxiv.org/abs/2508.09792)
*Wouter M. Kouw*

Main category: cs.LG

TL;DR: 论文提出了一种优化Matérn核时态高斯过程超参数的方法，基于递归贝叶斯估计，在运行时和均方根误差上优于边际似然最大化和哈密顿蒙特卡洛采样。


<details>
  <summary>Details</summary>
Motivation: 高斯过程在概率数值计算中具有重要意义，但优化其核超参数是一个挑战。论文旨在提出一种高效且准确的优化方法。

Method: 将优化问题转化为自回归模型参数的递归贝叶斯估计过程。

Result: 所提方法在运行时和均方根误差上优于边际似然最大化和哈密顿蒙特卡洛采样。

Conclusion: 该方法为优化高斯过程超参数提供了一种高效且准确的解决方案。

Abstract: Gaussian processes are important models in the field of probabilistic
numerics. We present a procedure for optimizing Mat\'ern kernel temporal
Gaussian processes with respect to the kernel covariance function's
hyperparameters. It is based on casting the optimization problem as a recursive
Bayesian estimation procedure for the parameters of an autoregressive model. We
demonstrate that the proposed procedure outperforms maximizing the marginal
likelihood as well as Hamiltonian Monte Carlo sampling, both in terms of
runtime and ultimate root mean square error in Gaussian process regression.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [14] [Per-antenna power constraints: constructing Pareto-optimal precoders with cubic complexity under non-negligible noise conditions](https://arxiv.org/abs/2508.09646)
*Sergey Petrov,Samson Lasaulce,Merouane Debbah*

Main category: math.NA

TL;DR: 本文提出了一种计算算法，用于构建在每天线功率约束下SINR多目标Pareto最优的预编码器，其复杂度与零强迫算法相近但性能更优。


<details>
  <summary>Details</summary>
Motivation: 现有零强迫算法在每天线功率约束下适应性差且忽略背景噪声系数，导致性能不佳。

Method: 提出一种计算复杂度与零强迫算法相近的算法，通过输入参数调整用户吞吐量重要性，实现Pareto边界的高效参数化。

Result: 算法在每天线功率约束下实现SINR多目标Pareto最优，且复杂度可控。

Conclusion: 该算法优于零强迫基线，适用于实际应用中需要考虑背景噪声和多目标优化的场景。

Abstract: Precoding matrix construction is a key element of the wireless signal
processing using the multiple-input and multiple-output model. It is
established that the problem of global throughput optimization under
per-antenna power constraints belongs, in general, to the class of monotonic
optimization problems, and is unsolvable in real-time. The most widely used
real-time baseline is the suboptimal solution of Zero-Forcing, which achieves a
cubic complexity by discarding the background noise coefficients. This
baseline, however, is not readily adapted to per-antenna power constraints, and
performs poorly if background noise coefficients are not negligible. In this
paper, we are going to present a computational algorithm which constructs a
precoder that is SINR multiobjective Pareto-optimal under per-antenna power
constraints - with a complexity that differs from that of Zero-Forcing only by
a constant factor. The algorithm has a set of input parameters, changing which
skews the importance of particular user throughputs: these parameters make up
an efficient parameterization of the entire Pareto boundary.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [15] [ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding](https://arxiv.org/abs/2508.09744)
*Andreas Zunker,Marvin Rübenacke,Stephan ten Brink*

Main category: cs.IT

TL;DR: 论文提出了一种基于递归Plotkin级联的ORCAS编码，该编码通过结合低复杂度ML解码和SC解码，性能优于极化码，且具有更灵活的码字长度。


<details>
  <summary>Details</summary>
Motivation: 需要低复杂度的软判决解码算法，以提升信道编码的性能和灵活性。

Method: 采用递归Plotkin级联，结合单纯形码及其对偶码的低复杂度ML解码和SC解码。

Result: ORCAS编码性能优于极化码，误块率降低0.5dB，且复杂度相近。

Conclusion: ORCAS编码在性能和灵活性上优于极化码，适用于实际参数场景。

Abstract: Motivated by the need for channel codes with low-complexity soft-decision
decoding algorithms, we consider the recursive Plotkin concatenation of optimal
low-rate and high-rate codes based on simplex codes and their duals. These
component codes come with low-complexity maximum likelihood (ML) decoding
which, in turn, enables efficient successive cancellation (SC)-based decoding.
As a result, the proposed optimally recursively concatenated simplex (ORCAS)
codes achieve a performance that is at least as good as that of polar codes.
For practical parameters, the proposed construction significantly outperforms
polar codes in terms of block error rate by up to 0.5 dB while maintaining
similar decoding complexity. Furthermore, the codes offer greater flexibility
in codeword length than conventional polar codes.

</details>
