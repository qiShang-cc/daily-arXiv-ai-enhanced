<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [cs.IT](#cs.IT) [Total: 3]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.AR](#cs.AR) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration](https://arxiv.org/abs/2506.15843)
*Ninghe Liu,Yu Xi Huang,Simon Mahler,Changhuei Yang*

Main category: eess.SP

TL;DR: 本文提出了一种基于优化的噪声校准方法，用于提高SCOS技术中CBF测量的准确性，尤其是在低信号水平下。该方法通过减少CBF-CBV波形相关性，显著降低了可靠信号阈值。


<details>
  <summary>Details</summary>
Motivation: SCOS技术用于无创监测CBF，但噪声校准不准确会降低测量可靠性，尤其是在低信号水平下。为了解决这一问题，作者提出了一种优化框架。

Method: 采用基于优化的自适应噪声校准方法，减少CBV波形模仿的伪影，从而降低CBF-CBV波形的相关性。

Result: 在10名受试者中验证，该方法将可靠CBF信号的阈值从97电子/像素降至26电子/像素，提高了测量的准确性。

Conclusion: 该方法显著提升了SCOS技术在低信号和大SD距离下的CBF测量性能，为深层组织研究提供了更可靠的工具。

Abstract: Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and
cost-effective method for monitoring cerebral blood flow (CBF). However,
extracting accurate CBF from SCOS necessitates precise noise pre-calibration.
Errors from this can degrade CBF measurement fidelity, particularly when the
overall signal level is low. Such errors primarily stem from residual speckle
contrast associated with camera and shot noise, whose fluctuations exhibit a
temporal structure that mimics cerebral blood volume (CBV) waveforms. We
propose an optimization-based framework that performs an adaptive refinement of
noise calibration, mitigating the CBV-mimicking artifacts by reducing the
CBF-CBV waveform correlation. Validated on 10 human subjects, our approach
effectively lowered the signal threshold for reliable CBF signal from 97 to 26
electrons per pixel for a 1920x1200 pixels SCOS system. This improvement
enables more accurate and robust CBF measurements in SCOS, especially at large
source-detector (SD) distances for deeper tissue interrogation.

</details>


### [2] [On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design](https://arxiv.org/abs/2506.15950)
*Saeed Razavikia,Carlo Fischione*

Main category: eess.SP

TL;DR: 该论文提出了一种基于噪声感知的数字调制方法（ChannelComp框架），通过优化星座设计和编码器，显著提高了在噪声多接入信道中的计算精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的模拟OAC方法对噪声敏感且硬件受限，数字方法则在设计复杂度上受限，影响了可扩展性和频谱效率。

Method: 论文分为两部分：第一部分提出了一种噪声感知的星座设计方法，通过max-min优化问题解决编码器设计；第二部分引入量化采样方案以提升大规模数字OAC的调制可扩展性和计算精度。

Result: 数值实验表明，噪声感知设计在噪声多接入信道中的均方误差显著低于领先的数字OAC方法。

Conclusion: ChannelComp框架通过噪声感知设计和量化采样方案，有效解决了数字OAC的可扩展性和噪声敏感性问题。

Abstract: Over-the-air computation (OAC) leverages the physical superposition property
of wireless multiple access channels (MACs) to compute functions while
communication occurs, enabling scalable and low-latency processing in
distributed networks. While analog OAC methods suffer from noise sensitivity
and hardware constraints, existing digital approaches are often limited in
design complexity, which may hinder scalability and fail to exploit spectral
efficiency fully. This two-part paper revisits and extends the ChannelComp
framework, a general methodology for computing arbitrary finite-valued
functions using digital modulation. In Part I, we develop a novel constellation
design approach that is aware of the noise distribution and formulates the
encoder design as a max-min optimization problem using noise-tailored distance
metrics. Our design supports noise models, including Gaussian, Laplace, and
heavy-tailed distributions. We further demonstrate that, for heavy-tailed
noise, the optimal ChannelComp setup coincides with the solution to the
corresponding max-min criterion for the channel noise with heavy-tailed
distributions. Numerical experiments confirm that our noise-aware design
achieves a substantially lower mean-square error than leading digital OAC
methods over noisy MACs. In Part II, we consider a constellation design with a
quantization-based sampling scheme to enhance modulation scalability and
computational accuracy for large-scale digital OAC.

</details>


### [3] [Theoretical Analysis of Near-Field MIMO Channel Capacity and Mid-Band Experimental Validation](https://arxiv.org/abs/2506.15972)
*Haiyang Miao,Jianhua Zhang,Pan Tang,Heng Wang,Lei Tian,Guangyi Liu*

Main category: eess.SP

TL;DR: 本文研究了6G无线网络中近场MIMO通信的容量问题，从电磁信息角度建模，并通过理论和实验分析指出大规模MIMO在近场容量增益中的潜力与实际限制。


<details>
  <summary>Details</summary>
Motivation: 随着MIMO阵列规模和载频的增加，近场MIMO通信在6G网络中变得至关重要，研究其容量特性具有广泛意义。

Method: 从电磁信息角度建立近场信道模型，并基于UPA和EDoF理论分析信道容量，推导闭合表达式，通过13 GHz频段的实验验证结论。

Result: 研究发现UPA型MIMO系统的信道容量随距离增加持续下降，大规模MIMO在近场容量增益显著，但接收端天线规模较小时增益受限。

Conclusion: 本文为近场通信系统提供了理论参考，指出大规模MIMO在近场容量中的优势及实际应用中的限制。

Abstract: With the increase of multiple-input-multiple-output (MIMO) array size and
carrier frequency, near-field MIMO communications will become crucial in 6G
wireless networks. Due to the increase of MIMO near-field range, the research
of near-field MIMO capacity has aroused wide interest. In this paper, we focus
on the theoretical analysis and empirical study of near-field MIMO capacity.
First, the near-field channel model is characterized from the electromagnetic
information perspective. Second, with the uniform planar array (UPA), the
channel capacity based on effective degree of freedom (EDoF) is analyzed
theoretically, and the closed-form analytical expressions are derived in
detail. Finally, based on the numerical verification of near-field channel
measurement experiment at 13 GHz band, we reveal that the channel capacity of
UPA-type MIMO systems decreases continuously with the communication distance
increasing. It can be observed that the near-field channel capacity gain is
relatively obvious when large-scale MIMO is adopted at both receiving and
transmitter ends, but the near-field channel capacity gain may be limited in
the actual communication system with the small antenna array at receiving end.
This work will give some reference to the near-field communication systems.

</details>


### [4] [Exploiting Both Pilots and Data Payloads for Integrated Sensing and Communications](https://arxiv.org/abs/2506.15998)
*Chen Xu,Xianghao Yu,Fan Liu,Shi Jin*

Main category: eess.SP

TL;DR: ISAC系统中利用随机数据信号进行感知任务，提升系统效用，通过RMT理论优化感知性能。


<details>
  <summary>Details</summary>
Motivation: 未来6G网络中，ISAC是关键技术，但目前感知任务主要依赖占用少量资源的确定性信号，需提升系统效用。

Method: 利用随机矩阵理论（RMT）推导ELMMSE表达式，提出ISAC预编码优化问题并通过SAC算法求解。

Result: 在高SNR下，感知性能退化由发射天线数与数据符号长度的比值决定，仿真验证性能显著提升5.6 dB。

Conclusion: 利用随机数据信号可显著提升ISAC系统感知性能，优化问题在高SNR下转化为凸优化问题。

Abstract: Integrated sensing and communications (ISAC) is one of the key enabling
technologies in future sixth-generation (6G) networks. Current ISAC systems
predominantly rely on deterministic pilot signals within the signal frame to
accomplish sensing tasks. However, these pilot signals typically occupy only a
small portion, e.g., 0.15% to 25%, of the time-frequency resources. To enhance
the system utility, a promising solution is to repurpose the extensive random
data payload signals for sensing tasks. In this paper, we analyze the ISAC
performance of a multi-antenna system where both deterministic pilot and random
data symbols are employed for sensing tasks. By capitalizing on random matrix
theory (RMT), we first derive a semi-closed-form asymptotic expression of the
ergodic linear minimum mean square error (ELMMSE). Then, we formulate an ISAC
precoding optimization problem to minimize the ELMMSE, which is solved via a
specifically tailored successive convex approximation (SAC) algorithm. To
provide system insights, we further derive a closed-form expression for the
asymptotic ELMMSE at high signal-to-noise ratios (SNRs). Our analysis reveals
that, compared with conventional sensing implemented by deterministic signals,
the sensing performance degradation induced by random signals is critically
determined by the ratio of the transmit antenna size to the data symbol length.
Based on this result, the ISAC precoding optimization problem at high SNRs is
transformed into a convex optimization problem that can be efficiently solved.
Simulation results validate the accuracy of the derived asymptotic expressions
of ELMMSE and the performance of the proposed precoding schemes. Particularly,
by leveraging data payload signals for sensing tasks, the sensing error is
reduced by up to 5.6 dB compared to conventional pilot-based sensing.

</details>


### [5] [Multi-Domain Optimization Framework for ISAC: From Electromagnetic Shaping to Network Cooperation](https://arxiv.org/abs/2506.16011)
*Rang Liu,Ming Li,Mehdi Zafari,Bjorn Ottersten,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 该论文探讨了6G网络中集成传感与通信（ISAC）的多域优化，重点关注电磁成形、基带处理和网络协作的联合策略，以提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究主要关注单一基带优化，而忽视了电磁成形和网络级协调的潜力，论文旨在填补这一空白。

Method: 论文提出一种多域优化方法，整合电磁成形、基带处理和网络协作策略，分析其权衡关系。

Result: 案例研究表明，联合多域优化能显著提升ISAC性能，为6G网络提供高效、智能架构。

Conclusion: 论文为ISAC的理论与实践结合指明了方向，提出未来挑战和研究路径。

Abstract: Integrated sensing and communication (ISAC) has emerged as a key feature for
sixth-generation (6G) networks, providing an opportunity to meet the dual
demands of communication and sensing. Existing ISAC research primarily focuses
on baseband optimization at individual access points, with limited attention to
the roles of electromagnetic (EM) shaping and network-wide coordination. The
intricate interdependencies between these domains remain insufficiently
explored, leaving their full potential for enhancing ISAC performance largely
untapped. To bridge this gap, we consider multi-domain ISAC optimization
integrating EM shaping, baseband processing, and network cooperation strategies
that facilitate efficient resource management and system-level design. We
analyze the fundamental trade-offs between these domains and offer insights
into domain-specific and cross-domain strategies contributing to ISAC
performance and efficiency. We then conduct a case study demonstrating the
effectiveness of joint multi-domain optimization. Finally, we discuss key
challenges and future research directions to connect theoretical advancements
and practical ISAC deployments. This work paves the way for intelligent and
scalable ISAC architectures, providing critical insights for their seamless
integration into next-generation wireless networks.

</details>


### [6] [Towards AI-Driven RANs for 6G and Beyond: Architectural Advancements and Future Horizons](https://arxiv.org/abs/2506.16070)
*Mathushaharan Rathakrishnan,Samiru Gayan,Rohit Singh,Amandeep Kaur,Hazer Inaltekin,Sampath Edirisinghe,H. Vincent Poor*

Main category: eess.SP

TL;DR: 本文探讨了6G网络向AI驱动的RAN（AI-RAN）转型，提出了一种新框架，并通过智能编排和资源优化进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有RAN架构难以满足灵活性、自动化和适应性的需求，需通过AI技术实现自演进和自主无线网络。

Method: 开发了一种新的AI-RAN框架，并利用数字孪生、智能反射面、生成式AI和区块链等关键技术。

Result: 论文提出了AI-RAN框架，并展示了其在智能编排和资源优化中的实际效果。

Conclusion: AI-RAN是6G网络的关键发展方向，但仍面临技术和监管挑战，未来需结合ISAC和代理AI等技术进一步研究。

Abstract: It is envisioned that 6G networks will be supported by key architectural
principles, including intelligence, decentralization, interoperability, and
digitalization. With the advances in artificial intelligence (AI) and machine
learning (ML), embedding intelligence into the foundation of wireless
communication systems is recognized as essential for 6G and beyond. Existing
radio access network (RAN) architectures struggle to meet the ever growing
demands for flexibility, automation, and adaptability required to build
self-evolving and autonomous wireless networks. In this context, this paper
explores the transition towards AI-driven RAN (AI-RAN) by developing a novel
AI-RAN framework whose performance is evaluated through a practical scenario
focused on intelligent orchestration and resource optimization. Besides, the
paper reviews the evolution of RAN architectures and sheds light on key
enablers of AI-RAN including digital twins (DTs), intelligent reflecting
surfaces (IRSs), large generative AI (GenAI) models, and blockchain (BC).
Furthermore, it discusses the deployment challenges of AI-RAN, including
technical and regulatory perspectives, and outlines future research directions
incorporating technologies such as integrated sensing and communication (ISAC)
and agentic AI.

</details>


### [7] [Multigroup Multicast Design for Pinching-Antenna Systems: Waveguide-Division or Waveguide-Multiplexing?](https://arxiv.org/abs/2506.16184)
*Shan Shan,Chongjun Ouyang,Yong Li,Yuanwei Liu*

Main category: eess.SP

TL;DR: 文章提出了PASS系统中多组多播通信的设计方法，通过WD和WM架构优化了多播速率，并证明了其在MIMO技术上的优势。


<details>
  <summary>Details</summary>
Motivation: 研究PASS（pinching-antenna系统）中多组多播通信的设计，以最大化多播速率。

Method: 1) 对WD架构提出元素级顺序优化策略和功率分配算法；2) 对WM架构提出基于MM的框架和低复杂度优化方法。

Result: WD和WM架构在PASS中显著优于传统MIMO技术，WM在密集部署中更稳健，WD在用户组空间分离时表现更优。

Conclusion: PASS系统的设计为多组多播通信提供了高效解决方案，在不同场景下WD和WM架构各有优势。

Abstract: This article addresses the design of multigroup multicast communications in
the pinching-antenna system (PASS). A PASS-enabled multigroup transmission
framework is proposed to maximize multicast rates under a couple of
transmission architectures: waveguide-division (WD) and waveguide-multiplexing
(WM). 1) For WD, an element-wise sequential optimization strategy is proposed
for pinching beamforming, i.e., optimizing the activated positions of pinching
antennas along dielectric waveguides. Meanwhile, a log-sum-exp projected
gradient descent algorithm is proposed for transmit power allocation across
waveguides. 2) For WM, a majorization-minimization (MM)-based framework is
proposed to tackle the problem's non-smoothness and non-convexity. On this
basis, a low-complexity element-wise sequential optimization method is
developed for pinching beamforming using the MM surrogate objective.
Furthermore, the optimal transmit beamformer structure is derived from the MM
surrogate objective using the Lagrange duality, with an efficient transmit
beamforming algorithm proposed using projected adaptive gradient descent.
Numerical results demonstrate that: i) both WD and WM architectures in PASS
achieve significant multicast rate improvements over conventional MIMO
techniques, especially for systems with large service areas; ii) WM is more
robust than WD in dense deployments, while WD excels when user groups are
spatially separated.

</details>


### [8] [DCFNet: Doppler Correction Filter Network for Integrated Sensing and Communication in Multi-User MIMO-OFDM Systems](https://arxiv.org/abs/2506.16191)
*Hyeonho Noh,Hyeonsu Lyu,Moe Z. Win,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 论文提出了一种名为DCFNet的AI原生集成感知与通信（ISAC）模型，通过多用户MIMO-OFDM系统解决了多普勒引起的干扰问题，显著提升了感知精度和速度。


<details>
  <summary>Details</summary>
Motivation: IMT-2030和6G即将发布，但目前尚无适合OFDM家族的具体ISAC解决方案。多普勒引起的干扰会破坏OFDM信号的子载波正交性，降低感知精度。

Method: 提出DCFNet模型，通过一组多普勒校正滤波器（DCF）和紧凑的深度学习网络来抑制干扰。进一步提出DCFNet-LR，利用广义似然比测试（GLRT）提升范围和速度分辨率。

Result: DCFNet-LR比最大似然搜索快143倍，范围和速度RMSE分别降低至2.7×10−4和6.7×10−4倍。

Conclusion: DCFNet系列模型在不改变传统帧结构的情况下，以极低复杂度实现了高精度的感知性能，适用于未来6G通信。

Abstract: Integrated sensing and communication (ISAC) is a headline feature for the
forthcoming IMT-2030 and 6G releases, yet a concrete solution that fits within
the established orthogonal frequency division multiplexing (OFDM) family
remains open. Specifically, Doppler-induced inter-carrier interference (ICI)
destroys sub-carrier orthogonality of OFDM sensing signals, blurring
range-velocity maps and severely degrading sensing accuracy. Building on
multi-user multi-input-multi-output (MIMO) OFDM systems, this paper proposes
Doppler-Correction Filter Network (DCFNet), an AI-native ISAC model that
delivers fine range-velocity resolution at minimal complexity without altering
the legacy frame structure. A bank of DCFs first shifts dominant ICI energy
away from critical Doppler bins; a compact deep learning network then
suppresses the ICI. To further enhance the range and velocity resolutions, we
propose DCFNet with local refinement (DCFNet-LR), which applies a generalized
likelihood ratio test (GLRT) to refine target estimates of DCFNet to sub-cell
accuracy. Simulation results show that DCFNet-LR runs $143\times$ faster than
maximum likelihood search and achieves significantly superior performance,
reducing the range RMSE by up to $2.7 \times 10^{-4}$ times and the velocity
RMSE by $6.7 \times 10^{-4}$ times compared to conventional detection methods.

</details>


### [9] [MASC: Integrated Sensing and Communications for the Martian Internet of Space](https://arxiv.org/abs/2506.16198)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 论文介绍了针对火星环境的MASC系统，通过自适应感知和通信技术提升了在极端环境下的通信可靠性和覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 火星探索任务需要可靠的通信系统，但频繁的沙尘暴、极端多普勒效应和资源限制对传统通信方法提出了挑战。

Method: MASC系统基于可解释信道模型，开发了环境感知混合预编码、自适应参数映射和鲁棒通信预编码三项关键技术。

Result: MASC在严重沙尘条件下保持45%的感知覆盖率（传统方法仅5%），提高SINR 2.5 dB，并在中等沙尘暴中提升80%容量。

Conclusion: MASC为火星环境提供了可靠的通信框架，平衡了感知和数据传输，为非地面网络的ISAC技术提供了范例。

Abstract: Mars exploration missions increasingly demand reliable communication systems,
yet harsh environmental conditions -- particularly frequent dust storms,
extreme Doppler effects, and stringent resource constraints -- pose
unprecedented challenges to conventional communication approaches. This paper
presents the Martian Adaptive Sensing and Communication (MASC) system
specifically designed for the Martian environment. MASC establishes a
physically interpretable channel model and develops three key components:
environment-aware hybrid precoding, adaptive parameter mapping, and robust
communication precoding. Simulation results demonstrate that MASC maintains 45
percent sensing coverage under severe dust conditions compared to only 5
percent with conventional methods, provides up to 2.5 dB
signal-to-interference-plus-noise ratio (SINR) improvement at 50 percent
channel state information (CSI) uncertainty, and yields 80 percent higher
capacity in moderate dust storms. Using an epsilon-constraint multi-objective
optimization approach, we enable mission planners to select operational modes
ranging from communication-priority (0.33 bps/Hz capacity, 28 percent sensing
coverage) to sensing-priority (90 percent coverage with minimal capacity),
offering a versatile framework that balances environmental awareness with
hyper-reliable data transmission. This work provides a validated blueprint for
integrated sensing and communication (ISAC) in non-terrestrial networks (NTN),
a key enabler for achieving ubiquitous connectivity in the 6G era.

</details>


### [10] [On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling](https://arxiv.org/abs/2506.16208)
*Saeed Razavikia,Carlo Fischione*

Main category: eess.SP

TL;DR: 本文提出了金字塔采样策略，通过选择一个叠加星座点子集，将数字OAC编码设计的复杂度从 $\mathcal{O}(q^K)$ 降低到 $\mathcal{O}(q^{K-p+1})$ ，以在计算复杂度和函数计算精度之间实现可控平衡。


<details>
  <summary>Details</summary>
Motivation: 解决大规模边缘网络中数字OAC星座设计的高复杂性和量化挑战。

Method: 引入金字塔采样策略，通过对称聚合假设，选择叠加星座点子集，减少设计复杂度。

Result: 模拟显示，中等采样顺序可以在显著减少约束的条件下达到可接受的性能。

Conclusion: 提出的方法在降低复杂度的同时保持了计算精度，支持标准数字调制方案的直接应用。

Abstract: Over-the-air computation (OAC) harnesses the natural superposition of
wireless signals to compute aggregate functions during transmission, thereby
collapsing communication and computation into a single step and significantly
reducing latency and resource usage. In Part I, digital OAC was formulated as a
noise-aware constellation design problem by casting encoder design as a max-min
optimization that aligns minimum Euclidean distances between superimposed
constellation points with squared differences of their corresponding function
outputs.
  In this paper, Part II, we address the prohibitive complexity and
quantization challenges inherent in digital OAC constellation design for
large-scale edge networks. More precisely, we introduce a pyramid sampling
strategy that judiciously selects a subset of superimposed constellation points
to reduce the encoder design complexity from $\mathcal{O}(q^K)$ to
$\mathcal{O}(q^{K-p+1})$, where $p\in\{1,\dots, K\}$ denotes the sampling
order, $q$ levels of modulation, and $K$ denotes the number nodes in the
network. Under the assumption of symmetric aggregation, this approach enables a
controlled trade-off between computational complexity and function computation
accuracy. As a special case, we propose majority-based sampling ($p=K$), which
confines aggregation to only $q$ consensus points, inherently avoiding
destructive overlaps and permitting the use of standard digital modulations
(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via
several simulations, across various aggregation functions, modulation levels,
and noise levels, that moderate sampling orders attain acceptable performance
with orders-of-magnitude fewer constraints than exhaustive designs.

</details>


### [11] [Refining Ray-Tracing Accuracy and Efficiency in the Context of FRMCS Urban Railway Channel Predictions](https://arxiv.org/abs/2506.16236)
*Romain Charbonnier,Thierry Tenoux,Yoann Corre*

Main category: eess.SP

TL;DR: 本文介绍了一种用于FRMCS无线通信标准的动态射线追踪工具，结合物理光学方法模拟列车与固定基础设施间的无线链路，重点关注计算时间与精度的平衡以及金属支柱对信号散射的影响。


<details>
  <summary>Details</summary>
Motivation: 研究FRMCS无线通信系统在真实环境中的性能，以优化基础设施部署成本和长期有效性。

Method: 开发动态射线追踪（RT）工具，结合物理光学（PO）方法，模拟列车移动场景中的无线链路，并分析金属支柱等物体对信号的散射作用。

Result: 通过案例研究表明，金属支柱的散射对信号传播有显著影响。

Conclusion: 动态RT工具结合PO方法能有效模拟FRMCS系统中的无线链路，为基础设施规划提供可靠依据。

Abstract: The upcoming roll-out of the new wireless communication standard for wireless
railway services, FRMCS, requires a thorough understanding of the system
performance in real-world conditions, since this will strongly influence the
deployment costs and the effectiveness of an infrastructure planned for
decades. The virtual testing of the equipment and network performance in
realistic simulated scenarios is key; its accuracy depends on the reliability
of the predicted radio channel properties. In this article, the authors explain
how they are evolving a ray-tracing (RT) tool to apply it to the specific case
of simulating the radio link between the FRMCS fixed infrastructure and an
antenna placed on the roof of a train moving in an urban environment. First, a
dynamic version of the RT tool is used to capture the rapid variations of all
channel metrics; a compromise is sought between computation time and accuracy.
Besides, a hybridization of RT and physical optics (PO) allows the integration
of objects near the track, such as catenary pylons, into the simulation. A case
study shows that the scattering by metallic pylons brings a significant
contribution.

</details>


### [12] [A Tractable Approach to Massive Communication and Ubiquitous Connectivity in 6G Standardization](https://arxiv.org/abs/2506.16304)
*Junyi Jiang,Wei Chen,Xin Guo,Shenghui Song,Ying Jun,Zhang,Zhu Han,Merouane Debbah,Khaled B. Letaief*

Main category: eess.SP

TL;DR: 该论文探讨了6G标准化中的频谱、能量和覆盖效率理论极限，重点研究了大规模通信和泛在连接两种场景，提出了低信令开销的频谱重用架构。


<details>
  <summary>Details</summary>
Motivation: 为理解6G的实用性和基础价值，并推动其标准化，研究在硬件和信令限制下的理论极限至关重要。

Method: 采用均值场近似方法，分析IMT-2030定义的两种场景，提出低信令开销的频谱重用架构。

Result: 研究发现，蜂窝和D2D网络可通过信道正交化受益，而无需共享干扰链路的CSI；部署中继或可移动基站（如无人机）能显著提升能量和频谱效率。

Conclusion: 基于均值场优化的评估有望对3GPP等标准组织的6G和NextG标准化产生积极影响。

Abstract: The full-scale 6G standardization has attracted considerable recent
attention, especially since the first 3GPP-wide 6G workshop held in March 2025.
To understand the practical and fundamental values of 6G and facilitate its
standardization, it is crucial to explore the theoretical limits of spectrum,
energy, and coverage efficiency considering practical hardware and signaling
constraints. In this paper, we present a mean-field-approximation-based
investigation on two out of six use case scenarios defined by IMT-2030, namely,
massive communication and ubiquitous connectivity. Being aware of the
limitation in interference cancellation owing to constrained cost and hardware
complexity, we investigate the spectrum reuse architecture in both usage
scenarios. We propose a tractable spectrum reuse with low signaling overhead
consumed for channel estimation and channel state information (CSI) feedback.
Our analysis indicates that the massive communication over cellular and
device-to-device (D2D) networks can benefit from channel orthogonalization,
while it is unnecessary to share the CSI of interfering links. Moreover,
deploying relays or movable base stations, e.g. unmanned aerial vehicle, yields
substantial energy and spectrum gain for ubiquitous connectivity, despite
introducing interference. As such, the mean-field-optimization-based evaluation
is expected to positively impact 6G and NextG standardization in 3GPP and other
standardization bodies.

</details>


### [13] [Beamforming design for minimizing the signal power estimation error](https://arxiv.org/abs/2506.16767)
*Esa Ollila,Xavier Mestre,Elias Raninen*

Main category: eess.SP

TL;DR: 研究Capon和MMSE波束形成器在信号功率估计中的偏差问题，提出一种改进的Capon⁺波束形成器以最小化均方误差。


<details>
  <summary>Details</summary>
Motivation: Capon和MMSE波束形成器在信号功率估计中存在偏差问题，无法在大样本下实现无偏估计，需要改进。

Method: 通过缩放因子调整Capon波束形成器，最小化信号功率估计的均方误差，提出Capon⁺波束形成器。

Result: Capon⁺在信号功率和波形估计中表现更优，偏差接近零，优于传统方法。

Conclusion: Capon⁺波束形成器在信号功率估计中表现出更好的平衡性和无偏性，适用于大样本场景。

Abstract: We study the properties of beamformers in their ability to either maintain or
estimate the true signal power of the signal of interest (SOI). Our focus is
particularly on the Capon beamformer and the minimum mean squared error (MMSE)
beamformer. The Capon beamformer, also known as the minimum power
distortionless response (MPDR) or the minimum variance distortionless response
(MVDR) beamformer, is a widely used method in array signal processing. A
curious feature of both the Capon and the MMSE beamformers is their tendency to
either overestimate or underestimate the signal power. That is, they are not
asymptotically unbiased (as the sample size approaches infinity). To address
this issue, we propose to shrink the Capon beamformer by finding a scaling
factor that minimizes the mean squared error (MSE) of the signal power
estimate. The new beamformer, referred to as the Capon$^+$ beamformer, is
evaluated against the Capon and MMSE beamformers in terms of bias, signal power
MSE, and signal waveform MSE. The Capon$^+$ beamformer strikes a better balance
between signal power and waveform estimation while also exhibiting minimal
bias, which approaches zero as the sample size increases.

</details>


### [14] [Wi-Fi Sensing Tool Release: Gathering 802.11ax Channel State Information from a Commercial Wi-Fi Access Point](https://arxiv.org/abs/2506.16957)
*Zisheng Wang,Feng Li,Hangbin Zhao,Zihuan Mao,Yaodong Zhang,Qisheng Huang,Bo Cao,Mingming Cao,Baolin He,Qilin Hou*

Main category: eess.SP

TL;DR: 论文介绍了ZTECSITool，一个用于从Wi-Fi 6设备捕获高分辨率CSI的工具包，填补了Wi-Fi传感研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的商业Wi-Fi接入点缺乏并过时的CSI提取技术限制了Wi-Fi传感的发展。

Method: 开发了ZTECSITool，包含定制固件和开源软件工具，支持160 MHz带宽和512个子载波配置。

Result: 提供了高分辨率CSI测量和实时分析工具，支持高级传感应用的开发。

Conclusion: ZTECSITool为Wi-Fi传感研究提供了关键工具，推动了下一代传感系统的进步。

Abstract: Wi-Fi sensing has emerged as a powerful technology, leveraging channel state
information (CSI) extracted from wireless data packets to enable diverse
applications, ranging from human presence detection to gesture recognition and
health monitoring. However, CSI extraction from commercial Wi-Fi access point
lacks and out of date. This paper introduces ZTECSITool,a toolkit designed to
capture high-resolution CSI measurements from commercial Wi-Fi 6 (802.11ax)
access points, supporting bandwidths up to 160 MHz and 512 subcarriers.
ZTECSITool bridges a critical gap in Wi-Fi sensing research, facilitating the
development of next-generation sensing systems. The toolkit includes customized
firmware and open-source software tools for configuring, collecting, and
parsing CSI data, offering researchers a robust platform for advanced sensing
applications. We detail the command protocols for CSI extraction, including
band selection,STA filtering, and report configuration, and provide insights
into the data structure of the reported CSI. Additionally, we present a
Python-based graphical interface for real-time CSI visualization and analysis

</details>


### [15] [Low-Complexity Receiver Design for Affine Filter Bank Modulation](https://arxiv.org/abs/2506.17010)
*Kuranage Roche Rayan Ranasinghe,Bruno S. Chang,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 提出一种低复杂度接收器结构，用于新型AFBM波形，利用GaBP框架实现高效的符号检测。


<details>
  <summary>Details</summary>
Motivation: 为双分散信道中的ISAC系统设计高效接收方案。

Method: 基于GaBP框架，采用标量运算实现符号检测。

Result: AFBM结合GaBP在BER和OOBE性能上优于AFDM。

Conclusion: 低复杂度接收器在双分散信道中表现优异。

Abstract: We propose a low-complexity receiver structure for the recently introduced
Affine Filter Bank Modulation (AFBM) scheme, which is a novel waveform designed
for integrated sensing and communications (ISAC) systems operating in
doubly-dispersive (DD) channels. The proposed receiver structure is based on
the Gaussian Belief Propagation (GaBP) framework, making use of only
element-wise scalar operations to perform detection of the transmitted symbols.
Simulation results demonstrate that AFBM in conjunction with GaBP outperforms
affine frequency division multiplexing (AFDM) in terms of bit error rates
(BERs) in DD channels, while achieving very low out-of-band emissions (OOBE) in
high-mobility scenarios.

</details>


### [16] [Searching for a Hidden Markov Anomaly over Multiple Processes](https://arxiv.org/abs/2506.17108)
*Levli Citron,Kobi Cohen,Qing Zhao*

Main category: eess.SP

TL;DR: 提出一种名为ADHM的新算法，用于在隐藏马尔可夫模型下动态探测异常过程，最小化检测时间并满足错误概率约束，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决在大规模过程中检测异常过程的难题，尤其是异常状态随时间动态变化（隐藏马尔可夫模型）的情况。

Method: 设计ADHM算法，通过动态调整探测策略、利用统计证据和隐藏状态的预测更新，集中资源检测最可能异常的过程。

Result: ADHM算法在理论和实验中均表现优异，显著降低检测时间并优于传统独立同分布假设方法。

Conclusion: ADHM算法有效应对动态异常检测问题，理论分析和实验验证了其优越性。

Abstract: We address the problem of detecting an anomalous process among a large number
of processes. At each time t, normal processes are in state zero (normal
state), while the abnormal process may be in either state zero (normal state)
or state one (abnormal state), with the states being hidden. The transition
between states for the abnormal process is governed by a Markov chain over
time. At each time step, observations can be drawn from a selected subset of
processes. Each probed process generates an observation depending on its hidden
state, either a typical distribution under state zero or an abnormal
distribution under state one. The objective is to design a sequential search
strategy that minimizes the expected detection time, subject to an error
probability constraint. In contrast to prior works that assume i.i.d.
observations, we address a new setting where anomalies evolve according to a
hidden Markov model. To this end, we propose a novel algorithm, dubbed Anomaly
Detection under Hidden Markov model (ADHM), which dynamically adapts the
probing strategy based on accumulated statistical evidence and predictive
belief updates over hidden states. ADHM effectively leverages temporal
correlations to focus sensing resources on the most informative processes. The
algorithm is supported by an asymptotic theoretical foundation, grounded in an
oracle analysis that characterizes the fundamental limits of detection under
the assumption of a known distribution of the hidden states. In addition, the
algorithm demonstrates strong empirical performance, consistently outperforming
existing methods in extensive simulations.

</details>


### [17] [On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA Networks](https://arxiv.org/abs/2506.17189)
*Muhammad Umer,Muhammad Ahmed Mohsin,Aamir Mahmood,Haejoon Jung,Haris Pervaiz,Mikael Gidlund,Syed Ali Hassan*

Main category: eess.SP

TL;DR: 这篇论文研究了可重构智能表面（RIS）与非正交多址接入（NOMA）的协同潜力，以提升下一代无线网络的能效和性能。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过RIS辅助的协作多点（CoMP）-NOMA网络设计高效无源波束成形（PBF）策略。

Method: 提出了两种RIS配置（纯增强型PBF和增强与取消型PBF）并分析其效果，优化RIS相位以最大化能效。

Result: RIS辅助的CoMP-NOMA网络比传统系统显著提升了能效，且最优PBF设计受基站数量、RIS元素和配置影响。

Conclusion: RIS辅助的CoMP-NOMA网络是实现未来无线网络高能效和性能的有前途的解决方案。

Abstract: This paper investigates the synergistic potential of reconfigurable
intelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance
the energy efficiency and performance of next-generation wireless networks. We
delve into the design of energy-efficient passive beamforming (PBF) strategies
within RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct
RIS configurations, namely, enhancement-only PBF (EO) and enhancement &
cancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that
RIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to
traditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem
to optimize the RIS phase shifts for maximizing energy efficiency. Our results
reveal that the optimal PBF design is contingent upon several factors,
including the number of cooperating base stations (BSs), the number of RIS
elements deployed, and the RIS configuration. This study underscores the
potential of RIS-assisted CoMP-NOMA networks as a promising solution for
achieving superior energy efficiency and overall performance in future wireless
networks.

</details>


### [18] [Intelligent Reflecting Surfaces for THz Communications: Fundamentals, Key Solutions, and System Prototyping](https://arxiv.org/abs/2506.17200)
*Qingqing Wu,Yanze Zhu,Qiaoyan Peng,Wanming Hao,Yanzhao Hou,Fengyuan Yang,Wencai Yan,Guoning Wang,Wen Chen,Chi Qiu*

Main category: eess.SP

TL;DR: IRSs是一种经济高效的太赫兹通信技术，本文全面综述了IRSs在太赫兹通信中的应用，涵盖硬件设计、信号处理技术和部署策略。


<details>
  <summary>Details</summary>
Motivation: 研究IRSs在太赫兹通信中的潜在优势和应用挑战，以提升信号强度和通信可靠性。

Method: 分析了多种THz可重构超表面架构，研究了近场和波束斜视效应，提出了信道估计和波束管理策略，并通过220GHz实验验证。

Result: 实验证明IRSs能显著提升单用户和多用户场景下的信号强度和通信可靠性。

Conclusion: IRSs是实现高效太赫兹通信的有前景技术，未来需解决硬件和部署中的挑战。

Abstract: Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective
technology for terahertz (THz) communications by enabling programmable control
of the wireless environment. This paper provides a comprehensive overview of
IRSs-aided THz communications, covering hardware designs, advanced signal
processing techniques, and practical deployment strategies. It first examines
key THz reconfigurable metasurface architectures, including electronic,
optical, phase-change material, and micro-electromechanical systems
(MEMS)-based implementations, highlighting their reconfiguration mechanisms and
challenges. Then, fundamental effects including near field and beam squint in
wideband THz systems are analyzed, along with their impacts on system
performance. The paper further explores conventional and beam-squint-assisted
channel estimation methods, innovative beam management strategies, and
deployment considerations across large- and small-scale scenarios. Practical
experiments at 220 gigahertz (GHz) validate the effectiveness of IRS in
improving signal strength and communication reliability for both single-user
and multi-user setups.

</details>


### [19] [Efficient Implementation of Multi-sensor Adaptive Birth Samplers for Labeled Random Finite Set Tracking](https://arxiv.org/abs/2506.17205)
*Jennifer Bondarchuk,Anthony Trezza,Donald J. Bucci Jr*

Main category: eess.SP

TL;DR: 本文提出了五种效率提升方法，用于改进多传感器自适应目标跟踪中的初始化过程，显著降低了计算复杂度，同时保持跟踪性能不变。


<details>
  <summary>Details</summary>
Motivation: 自适应目标跟踪在多目标跟踪系统中至关重要，但现有的多传感器自适应初始化方法计算复杂度高，需要进一步优化以提高实际应用效率。

Method: 作者提出了五种效率增强技术，通过改进标号随机有限集多传感器自适应出生密度构建过程，显著减少计算负担。

Result: 模拟结果显示，这些方法将计算复杂度从指数级降低到线性级，且对多目标跟踪性能影响可以忽略不计。

Conclusion: 这些高效的改进技术为实际多目标跟踪系统提供了显著的性能提升，同时保持了跟踪精度。

Abstract: Adaptive track initiation remains a crucial component of many modern
multi-target tracking systems. For labeled random finite sets multi-object
filters, prior work has been established to construct a labeled multi-object
birth density using measurements from multiple sensors. A naive construction of
this adaptive birth set density results in an exponential number of newborn
components in the number of sensors. A truncation procedure was provided that
leverages a Gibbs sampler to truncate the birth density, reducing the
complexity to quadratic in the number of sensors. However, only a limited
discussion has been provided on additional algorithmic techniques that can be
employed to substantially reduce the complexity in practical tracking
applications. In this paper, we propose five efficiency enhancements for the
labeled random finite sets multi-sensor adaptive birth procedure. Simulation
results are provided to demonstrate their computational benefits and show that
they result in a negligible change to the multi-target tracking performance.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [20] [Hybrid Near-Far Field 6D Movable Antenna Design Exploiting Directional Sparsity and Deep Learning](https://arxiv.org/abs/2506.15808)
*Xiaodan Shao,Limei Hu,Yulong Sun,Xing Li,Yixiao Zhang,Jingze Ding,Xiaoming Shi,Feng Chen,Derrick Wing Kwan Ng,Robert Schober*

Main category: cs.IT

TL;DR: 本文提出了一种高效混合场6DMA信道模型和低开销信道估计算法，解决了传统远场模型的不足和高计算复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 传统6DMA信道模型在混合场环境下存在不准确性，且高维信道和位置-旋转约束导致信道估计和联合设计复杂度极高。

Method: 提出混合场通用6DMA信道模型，结合平面波和球面波传播，并利用方向稀疏性设计低开销信道估计算法，同时使用深度强化学习联合设计位置、旋转和波束成形。

Result: 数值结果表明，提出的混合场模型和估计算法优于现有方法，DRL增强的6DMA系统性能显著优于灵活天线系统。

Conclusion: 本文提出的方法有效解决了6DMA系统的信道建模和计算复杂度问题，显著提升了系统性能。

Abstract: Six-dimensional movable antenna (6DMA) has been identified as a new
disruptive technology for future wireless systems to support a large number of
users with only a few antennas. However, the intricate relationships between
the signal carrier wavelength and the transceiver region size lead to
inaccuracies in traditional far-field 6DMA channel model, causing discrepancies
between the model predictions and the hybrid-field channel characteristics in
practical 6DMA systems, where users might be in the far-field region relative
to the antennas on the same 6DMA surface, while simultaneously being in the
near-field region relative to different 6DMA surfaces. Moreover, due to the
high-dimensional channel and the coupled position and rotation constraints, the
estimation of the 6DMA channel and the joint design of the 6DMA positions and
rotations and the transmit beamforming at the base station (BS) incur extremely
high computational complexity. To address these issues, we propose an efficient
hybrid-field generalized 6DMA channel model, which accounts for planar-wave
propagation within individual 6DMA surfaces and spherical-wave propagation
among different 6DMA surfaces. Furthermore, by leveraging directional sparsity,
we propose a low-overhead channel estimation algorithm that efficiently
constructs a complete channel map for all potential antenna position-rotation
pairs while limiting the training overhead incurred by antenna movement. In
addition, we propose a low-complexity design leveraging deep reinforcement
learning (DRL), which facilitates the joint design of the 6DMA positions,
rotations, and beamforming in a unified manner. Numerical results demonstrate
that the proposed hybrid-field channel model and channel estimation algorithm
outperform existing approaches and that the DRL-enhanced 6DMA system
significantly surpasses flexible antenna systems.

</details>


### [21] [End-to-End Learning of Probabilistic Constellation Shaping through Importance Sampling](https://arxiv.org/abs/2506.16098)
*Shrinivas Chimmalgi,Laurent Schmalen,Vahid Aref*

Main category: cs.IT

TL;DR: 论文提出了基于自动微分和重要性采样的新型损失函数，用于自动编码器学习概率星座成形，解决了传统优化方法中梯度计算复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统概率星座成形优化方法中梯度计算复杂且易出错的问题。

Method: 提出新型损失函数，利用自动微分和重要性采样，实现精确的星座点概率梯度优化。

Result: 仿真结果表明，该方法在高斯白噪声和简化光信道模型中的性能与现有方法相当。

Conclusion: 新方法显著简化了概率星座成形的梯度计算，为编码调制系统提供了更高效的技术支持。

Abstract: Probabilistic constellation shaping enables easy rate adaption and has been
proven to reduce the gap to Shannon capacity. Constellation point probabilities
are optimized to maximize either the mutual information or the bit-wise mutual
information. The optimization problem is however challenging even for simple
channel models. While autoencoder-based machine learning has been applied
successfully to solve this problem [1], it requires manual computation of
additional terms for the gradient which is an error-prone task. In this work,
we present novel loss functions for autoencoder-based learning of probabilistic
constellation shaping for coded modulation systems using automatic
differentiation and importance sampling. We show analytically that our proposed
approach also uses exact gradients of the constellation point probabilities for
the optimization. In simulations, our results closely match the results from
[1] for the additive white Gaussian noise channel and a simplified model of the
intensity-modulation direct-detection channel.

</details>


### [22] [Codeword-Segmentation Rate-Splitting Multiple Access and Evaluation under Suboptimal Decoding](https://arxiv.org/abs/2506.17164)
*Sibo Zhang,Bruno Clerckx,David Vargas*

Main category: cs.IT

TL;DR: 提出一种新型的RSMA架构CS-RSMA，通过直接编码用户消息并分割码字，优化了性能和实现复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统RSMA在编码前分割消息可能效率不足，CS-RSMA旨在改进性能和简化实现。

Method: CS-RSMA直接编码消息并分割码字，提出性能分析框架及预编码优化。

Result: CS-RSMA在总速率上优于传统RSMA，公平性相近，实现复杂度更低。

Conclusion: CS-RSMA在性能和实现上均有显著优势，是RSMA的有力替代方案。

Abstract: Rate-Splitting Multiple Access (RSMA) has been recognized as a promising
multiple access technique. We propose a novel architecture for downlink RSMA,
namely Codeword-Segmentation RSMA (CS-RSMA). Different from conventional RSMA
which splits users' messages into common and private parts before encoding,
CS-RSMA encodes the users' messages directly, segments the codewords into
common and private parts, and transmits the codeword segments using common and
private streams. In addition to the principle of CS-RSMA, a novel performance
analysis framework is proposed. This framework utilizes a recent discovery in
mismatched decoding under finite-alphabet input and interference, and can
better capture the receiver's complexity limits. Precoder optimization under
finite alphabets and suboptimal decoders for conventional RSMA and CS-RSMA to
maximize the Sum-Rate (SR) and the Max-Min Fairness (MMF) is also addressed.
The numerical results reveal the theoretical performance of conventional RSMA
and CS-RSMA. We observe that CS-RSMA leads to better performance than
conventional RSMA in SR, and similar performance in MMF. Furthermore, a
physical-layer implementation of CS-RSMA is proposed and evaluated through
link-level simulations. Aside performance benefits, we also demonstrate that
CS-RSMA brings significant benefits on the encoding/decoding, control
signaling, and retransmission process compared to conventional RSMA.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [23] [Efficient Transformations in Deep Learning Convolutional Neural Networks](https://arxiv.org/abs/2506.16418)
*Berk Yilmaz,Daniel Fidel Harvey,Prajit Dhuri*

Main category: cs.CV

TL;DR: 研究了在ResNet50中集成FFT、WHT和DCT信号处理变换对图像分类的影响，发现WHT显著降低能耗并提升准确率。


<details>
  <summary>Details</summary>
Motivation: 探讨信号处理变换在CNN中的计算效率、能耗与分类准确率的权衡。

Method: 在ResNet50的卷积层中集成FFT、WHT和DCT，使用CIFAR-100数据集进行实验。

Result: WHT在早期或全部卷积层中的应用使准确率提升至74%和79%，能耗降至39 kJ。

Conclusion: WHT是一种高效节能的CNN优化方法，适用于能源受限场景。

Abstract: This study investigates the integration of signal processing transformations
-- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete
Cosine Transform (DCT) -- within the ResNet50 convolutional neural network
(CNN) model for image classification. The primary objective is to assess the
trade-offs between computational efficiency, energy consumption, and
classification accuracy during training and inference. Using the CIFAR-100
dataset (100 classes, 60,000 images), experiments demonstrated that
incorporating WHT significantly reduced energy consumption while improving
accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy
of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified
ResNet50 incorporating WHT in the early convolutional layers achieved 74%
accuracy, and an enhanced version with WHT applied to both early and late
layers achieved 79% accuracy, with an average energy consumption of only 39 kJ
per model. These results demonstrate the potential of WHT as a highly efficient
and effective approach for energy-constrained CNN applications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [A Low-Cost Portable Lidar-based Mobile Mapping System on an Android Smartphone](https://arxiv.org/abs/2506.15983)
*Jianzhu Huai,Yuxin Shao,Yujia Zhang,Alper Yilmaz*

Main category: cs.RO

TL;DR: 该论文提出了一种低成本、便携式移动测绘系统，结合了激光雷达、Android智能手机和RTK-GNSS模块，旨在解决现有高成本或精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着元宇宙、数字孪生和机器人技术的快速发展，对低成本便携式测绘系统的需求日益增加。现有方案如Leica BLK2Go或配备激光雷达的智能手机成本高或性能有限。

Method: 系统集成了激光雷达、Android智能手机和RTK-GNSS模块，使用Android平台运行激光雷达-惯性里程计，并记录多传感器数据。总成本低于2000美元，重量约1千克。

Result: 系统在成本和便携性之间取得了良好平衡，性能在追踪和测绘方面表现出色。设计与软件已开源。

Conclusion: 该低成本便携式系统为现实捕捉提供了实用解决方案，开源设计有助于社区进一步发展。

Abstract: The rapid advancement of the metaverse, digital twins, and robotics
underscores the demand for low-cost, portable mapping systems for reality
capture. Current mobile solutions, such as the Leica BLK2Go and lidar-equipped
smartphones, either come at a high cost or are limited in range and accuracy.
Leveraging the proliferation and technological evolution of mobile devices
alongside recent advancements in lidar technology, we introduce a novel,
low-cost, portable mobile mapping system. Our system integrates a lidar unit,
an Android smartphone, and an RTK-GNSS stick. Running on the Android platform,
it features lidar-inertial odometry built with the NDK, and logs data from the
lidar, wide-angle camera, IMU, and GNSS. With a total bill of materials (BOM)
cost under 2,000 USD and a weight of about 1 kilogram, the system achieves a
good balance between affordability and portability. We detail the system
design, multisensor calibration, synchronization, and evaluate its performance
for tracking and mapping. To further contribute to the community, the system's
design and software are made open source at:
https://github.com/OSUPCVLab/marslogger_android/releases/tag/v2.1

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [25] [HybridRAG-based LLM Agents for Low-Carbon Optimization in Low-Altitude Economy Networks](https://arxiv.org/abs/2506.15947)
*Jinbo Wen,Cheng Su,Jiawen Kang,Jiangtian Nie,Yang Zhang,Jianhang Tang,Dusit Niyato,Chau Yuen*

Main category: cs.NI

TL;DR: 论文提出了一种基于检索增强生成（RAG）的大型语言模型（LLM）代理框架HybridRAG，用于解决低空经济网络中多无人机辅助MEC网络的低碳优化问题，并开发了R2DSAC算法实现多目标优化。


<details>
  <summary>Details</summary>
Motivation: 低空经济网络（LAENets）因其低延迟和高计算需求，需要无人机与移动边缘计算（MEC）系统的结合。然而，现有方法在多维无人机建模和多目标耦合优化上存在挑战。

Method: 提出了HybridRAG框架，结合KeywordRAG、VectorRAG和GraphRAG，以更高效地从专家数据库中检索信息并生成优化问题。此外，开发了R2DSAC算法，通过扩散熵正则化和动态掩码技术降低碳排放。

Result: 仿真结果表明，HybridRAG和R2DSAC在优化效果和可靠性上表现优异。

Conclusion: 该研究为低空经济网络的低碳优化提供了一种有效解决方案，展示了LLM代理和强化学习算法的潜力。

Abstract: Low-Altitude Economy Networks (LAENets) are emerging as a promising paradigm
to support various low-altitude services through integrated air-ground
infrastructure. To satisfy low-latency and high-computation demands, the
integration of Unmanned Aerial Vehicles (UAVs) with Mobile Edge Computing (MEC)
systems plays a vital role, which offloads computing tasks from terminal
devices to nearby UAVs, enabling flexible and resilient service provisions for
ground users. To promote the development of LAENets, it is significant to
achieve low-carbon multi-UAV-assisted MEC networks. However, several challenges
hinder this implementation, including the complexity of multi-dimensional UAV
modeling and the difficulty of multi-objective coupled optimization. To this
end, this paper proposes a novel Retrieval Augmented Generation (RAG)-based
Large Language Model (LLM) agent framework for model formulation. Specifically,
we develop HybridRAG by combining KeywordRAG, VectorRAG, and GraphRAG,
empowering LLM agents to efficiently retrieve structural information from
expert databases and generate more accurate optimization problems compared with
traditional RAG-based LLM agents. After customizing carbon emission
optimization problems for multi-UAV-assisted MEC networks, we propose a Double
Regularization Diffusion-enhanced Soft Actor-Critic (R\textsuperscript{2}DSAC)
algorithm to solve the formulated multi-objective optimization problem. The
R\textsuperscript{2}DSAC algorithm incorporates diffusion entropy
regularization and action entropy regularization to improve the performance of
the diffusion policy. Furthermore, we dynamically mask unimportant neurons in
the actor network to reduce the carbon emissions associated with model
training. Simulation results demonstrate the effectiveness and reliability of
the proposed HybridRAG-based LLM agent framework and the
R\textsuperscript{2}DSAC algorithm.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [26] [Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute](https://arxiv.org/abs/2506.15882)
*Sheng Liu,Tianlang Chen,Pan Lu,Haotian Ye,Yizheng Chen,Lei Xing,James Zou*

Main category: cs.LG

TL;DR: 提出了一种名为Fractional Reasoning的训练无关、模型无关框架，通过动态调整推理深度来提升大语言模型在测试时的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Best-of-N、多数投票、自我反思）在推理时对所有输入采用统一方式，忽略了不同问题可能需要不同推理深度。

Method: 提取与深度推理相关的潜在导向向量，并通过可调缩放因子重新应用，实现推理强度的连续控制。

Result: 在GSM8K、MATH500和GPQA等任务上的实验表明，该方法能显著提升性能和模型表现。

Conclusion: Fractional Reasoning通过动态调整推理深度，有效提升了测试时计算的效果，且适用于多种推理任务和模型。

Abstract: Test-time compute has emerged as a powerful paradigm for improving the
performance of large language models (LLMs), where generating multiple outputs
or refining individual chains can significantly boost answer accuracy. However,
existing methods like Best-of-N, majority voting, and self-reflection typically
apply reasoning in a uniform way across inputs, overlooking the fact that
different problems may require different levels of reasoning depth. In this
work, we propose Fractional Reasoning, a training-free and model-agnostic
framework that enables continuous control over reasoning intensity at inference
time, going beyond the limitations of fixed instructional prompts. Our method
operates by extracting the latent steering vector associated with deeper
reasoning and reapplying it with a tunable scaling factor, allowing the model
to tailor its reasoning process to the complexity of each input. This supports
two key modes of test-time scaling: (1) improving output quality in
breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing
the correctness of individual reasoning chains in depth-based strategies (e.g.,
self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that
Fractional Reasoning consistently improves performance across diverse reasoning
tasks and models.

</details>


### [27] [A Scalable Factorization Approach for High-Order Structured Tensor Recovery](https://arxiv.org/abs/2506.16032)
*Zhen Qin,Michael B. Wakin,Zhihui Zhu*

Main category: cs.LG

TL;DR: 提出了一种统一的框架，通过Riemannian梯度下降优化张量分解问题，证明在适当初始化下可线性收敛。


<details>
  <summary>Details</summary>
Motivation: 张量分解通过减少参数数量在高阶张量中具有优势，但非凸优化问题带来挑战，需改进收敛分析。

Method: 利用正交约束的规范形式，使用Riemannian梯度下降优化Stiefel流形上的正交因子。

Result: 在损失函数的温和条件下，证明RGD线性收敛于真实张量，且初始化需求和收敛速度随阶数多项式增长。

Conclusion: 此方法在理论和实际中优于现有结果，适用于Tucker和张量链格式。

Abstract: Tensor decompositions, which represent an $N$-order tensor using
approximately $N$ factors of much smaller dimensions, can significantly reduce
the number of parameters. This is particularly beneficial for high-order
tensors, as the number of entries in a tensor grows exponentially with the
order. Consequently, they are widely used in signal recovery and data analysis
across domains such as signal processing, machine learning, and quantum
physics. A computationally and memory-efficient approach to these problems is
to optimize directly over the factors using local search algorithms such as
gradient descent, a strategy known as the factorization approach in matrix and
tensor optimization. However, the resulting optimization problems are highly
nonconvex due to the multiplicative interactions between factors, posing
significant challenges for convergence analysis and recovery guarantees.
  In this paper, we present a unified framework for the factorization approach
to solving various tensor decomposition problems. Specifically, by leveraging
the canonical form of tensor decompositions--where most factors are constrained
to be orthonormal to mitigate scaling ambiguity--we apply Riemannian gradient
descent (RGD) to optimize these orthonormal factors on the Stiefel manifold.
Under a mild condition on the loss function, we establish a Riemannian
regularity condition for the factorized objective and prove that RGD converges
to the ground-truth tensor at a linear rate when properly initialized. Notably,
both the initialization requirement and the convergence rate scale polynomially
rather than exponentially with $N$, improving upon existing results for Tucker
and tensor-train format tensors.

</details>


### [28] [Manifold Learning for Personalized and Label-Free Detection of Cardiac Arrhythmias](https://arxiv.org/abs/2506.16494)
*Amir Reza Vazifeh,Jason W. Fleischer*

Main category: cs.LG

TL;DR: 非线性降维技术（NLDR）在ECG信号分析中表现优异，无需训练即可识别医学相关特征，准确区分心律失常。


<details>
  <summary>Details</summary>
Motivation: 传统ECG分析方法耗时且易错，机器学习模型因信号差异和标签标准不一难以泛化，需要新的无监督方法。

Method: 采用t-SNE和UMAP等非线性降维技术，分析MIT-BIH数据集中的MLII和V1导联信号。

Result: NLDR区分个体记录的准确率≥90%，识别心律失常的中位准确率和F1分数分别为98.96%和91.02%。

Conclusion: NLDR在心脏监测和个性化医疗中潜力巨大，适用于单导联和12导联ECG。

Abstract: Electrocardiograms (ECGs) provide direct, non-invasive measurements of heart
activity and are well-established tools for detecting and monitoring
cardiovascular disease. However, manual ECG analysis can be time-consuming and
prone to errors. Machine learning has emerged as a promising approach for
automated heartbeat recognition and classification, but substantial variations
in ECG signals make it challenging to develop generalizable models. ECG signals
can vary widely across individuals and leads, while datasets often follow
different labeling standards and may be biased, all of which greatly hinder
supervised methods. Conventional unsupervised methods, e.g. principal component
analysis, prioritize large (and often obvious) variances in the data and
typically overlook subtle yet clinically relevant patterns. If labels are
missing and/or variations are significant but small, both approaches fail.
Here, we show that nonlinear dimensionality reduction (NLDR) can accommodate
these issues and identify medically relevant features in ECG signals, with no
need for training or prior information. Using the MLII and V1 leads of the
MIT-BIH dataset, we demonstrate that t-distributed stochastic neighbor
embedding and uniform manifold approximation and projection can discriminate
individual recordings in mixed populations with >= 90% accuracy and distinguish
different arrhythmias in individual patients with a median accuracy of 98.96%
and a median F1-score of 91.02%. The results show that NLDR holds much promise
for cardiac monitoring, including the limiting cases of single-lead ECG and the
current 12-lead standard of care, and for personalized health care beyond
cardiology.

</details>


### [29] [IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification](https://arxiv.org/abs/2506.16744)
*Eion Tyacke,Kunal Gupta,Jay Patel,Rui Li*

Main category: cs.LG

TL;DR: 论文研究了多模态融合策略在解码手势神经肌肉信号中的效果，提出了一种层次化Transformer架构，在多模态输入下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统的人机接口依赖单一生物信号模态，而多模态融合可以利用传感器间的互补信息，提升基本神经科学和辅助技术（如假肢）的性能。

Method: 系统比较了线性和注意力融合策略，使用了三种架构（多模态MLP、多模态Transformer和层次化Transformer），并通过两个公开数据集进行实验。

Result: 层次化Transformer在注意力融合下表现最佳，在两个数据集上分别比基线提升了10%和3.7%。交叉模态交互贡献了近30%的决策信号。

Conclusion: 多模态融合能显著提升生物信号分类性能，尤其是在交叉模态交互中。研究对神经机器系统的传感器阵列设计具有指导意义。

Abstract: Hand gestures are a primary output of the human motor system, yet the
decoding of their neuromuscular signatures remains a bottleneck for basic
neuroscience and assistive technologies such as prosthetics. Traditional
human-machine interface pipelines rely on a single biosignal modality, but
multimodal fusion can exploit complementary information from sensors. We
systematically compare linear and attention-based fusion strategies across
three architectures: a Multimodal MLP, a Multimodal Transformer, and a
Hierarchical Transformer, evaluating performance on scenarios with unimodal and
multimodal inputs. Experiments use two publicly available datasets: NinaPro DB2
(sEMG and accelerometer) and HD-sEMG 65-Gesture (high-density sEMG and force).
Across both datasets, the Hierarchical Transformer with attention-based fusion
consistently achieved the highest accuracy, surpassing the multimodal and best
single-modality linear-fusion MLP baseline by over 10% on NinaPro DB2 and 3.7%
on HD-sEMG. To investigate how modalities interact, we introduce an Isolation
Network that selectively silences unimodal or cross-modal attention pathways,
quantifying each group of token interactions' contribution to downstream
decisions. Ablations reveal that cross-modal interactions contribute
approximately 30% of the decision signal across transformer layers,
highlighting the importance of attention-driven fusion in harnessing
complementary modality information. Together, these findings reveal when and
how multimodal fusion would enhance biosignal classification and also provides
mechanistic insights of human muscle activities. The study would be beneficial
in the design of sensor arrays for neurorobotic systems.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [30] [SparseDPD: A Sparse Neural Network-based Digital Predistortion FPGA Accelerator for RF Power Amplifier Linearization](https://arxiv.org/abs/2506.16591)
*Manno Versluis,Yizhuo Wu,Chang Gao*

Main category: cs.AR

TL;DR: SparseDPD是一种基于FPGA的稀疏神经网络加速器，用于数字预失真（DPD），通过优化计算负载实现高效线性化。


<details>
  <summary>Details</summary>
Motivation: 传统多项式DPD方法性能有限，神经网络方法虽优但计算复杂，难以实际部署。

Method: 采用空间稀疏相位归一化时延神经网络（PNTDNN），通过非结构化剪枝减少计算量。

Result: 在FPGA上实现170 MHz运行，性能优异（ACPR: -59.4 dBc, EVM: -54.0 dB, NMSE: -48.2 dB），功耗仅241 mW。

Conclusion: SparseDPD展示了FPGA加速的可行性，为实时无线通信提供了高效DPD解决方案。

Abstract: Digital predistortion (DPD) is crucial for linearizing radio frequency (RF)
power amplifiers (PAs), improving signal integrity and efficiency in wireless
systems. Neural network (NN)-based DPD methods surpass traditional polynomial
models but face computational challenges limiting their practical deployment.
This paper introduces SparseDPD, an FPGA accelerator employing a spatially
sparse phase-normalized time-delay neural network (PNTDNN), optimized through
unstructured pruning to reduce computational load without accuracy loss.
Implemented on a Xilinx Zynq-7Z010 FPGA, SparseDPD operates at 170 MHz,
achieving exceptional linearization performance (ACPR: -59.4 dBc, EVM: -54.0
dBc, NMSE: -48.2 dB) with only 241 mW dynamic power, using 64 parameters with
74% sparsity. This work demonstrates FPGA-based acceleration, making NN-based
DPD practical and efficient for real-time wireless communication applications.
Code is publicly available at https://github.com/MannoVersluis/SparseDPD.

</details>
