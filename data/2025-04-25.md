<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 10]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.HC](#cs.HC) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Automotive Radar Multi-Frame Track-Before-Detect Algorithm Considering Self-Positioning Errors](https://arxiv.org/abs/2504.17155)
*Wujun Li,Qing Miao,Ye Yuan,Yunlian Tian,Wei Yi,Kah Chan Teh*

Main category: eess.SP

TL;DR: 本文提出了一种用于汽车雷达中弱目标联合检测与跟踪的多帧检测前跟踪（MF-TBD）方法，解决了由于雷达视场错位、非线性坐标转换和自车运动定位误差导致的挑战，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 汽车雷达中的目标跟踪因FOV错位、坐标转换非线性和自车定位误差而困难，传统MF-TBD方法难以直接应用。本文旨在解决这些问题，提升弱目标检测与跟踪性能。

Method: 提出自适应调整检测阈值的新MF-TBD架构，并针对移动平台雷达设计多帧能量整合策略，精确推导目标能量整合路径函数，解决自车定位误差问题。

Result: 数值模拟和真实雷达数据实验表明，该方法在弱目标环境下显著优于标准汽车雷达处理方案。

Conclusion: 本文方法有效解决了汽车雷达中的弱目标检测与跟踪问题，尤其在处理自车运动误差方面表现优异，为实际应用提供了可靠方案。

Abstract: This paper presents a method for the joint detection and tracking of weak
targets in automotive radars using the multi-frame track-before-detect (MF-TBD)
procedure. Generally, target tracking in automotive radars is challenging due
to radar field of view (FOV) misalignment, nonlinear coordinate conversion, and
self-positioning errors of the ego-vehicle, which are caused by platform
motion. These issues significantly hinder the implementation of MF-TBD in
automotive radars. To address these challenges, a new MF-TBD detection
architecture is first proposed. It can adaptively adjust the detection
threshold value based on the existence of moving targets within the radar FOV.
Since the implementation of MF-TBD necessitates the inclusion of position,
velocity, and yaw angle information of the ego-vehicle, each with varying
degrees of measurement error, we further propose a multi-frame energy
integration strategy for moving-platform radar and accurately derive the target
energy integration path functions. The self-positioning errors of the
ego-vehicle, which are usually not considered in some previous target tracking
approaches, are well addressed. Numerical simulations and experimental results
with real radar data demonstrate large detection and tracking gains over
standard automotive radar processing in weak target environments.

</details>


### [2] [DualAttWaveNet: Multiscale Attention Networks for Satellite Interference Detection](https://arxiv.org/abs/2504.17187)
*Chunyu Yang,Boyu Yang,Kun Qiu,Zhe Chen,Yue Gao*

Main category: eess.SP

TL;DR: 论文提出DualAttWaveNet，通过双向注意力融合层和小波正则化损失，解决NGSO与GSO卫星频谱干扰检测中计算效率低和跨域依赖忽视的问题，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法如TrID虽性能优异，但计算耗时且忽略时频跨域依赖，亟需高效且鲁棒的干扰检测方案。

Method: 采用双向注意力融合层动态关联时域样本，并结合小波正则化损失保证多尺度一致性。

Result: AUC提升12%，推理时间减少50%至540ms/批次，F1分数保持。

Conclusion: DualAttWaveNet在计算效率和性能上均显著优于现有方法，适合实时干扰检测。

Abstract: The escalating overlap between non-geostationary orbit (NGSO) and
geostationary orbit (GSO) satellite frequency allocations necessitates accurate
interference detection methods that address two pivotal technical gaps:
computationally efficient signal analysis for real-time operation, and robust
anomaly discrimination under varying interference patterns. Existing deep
learning approaches employ encoder-decoder anomaly detectors that threshold
input-output discrepancies for robustness. While the transformer-based TrID
model achieves state-of-the-art performance (AUC: 0.8318, F1: 0.8321), its
multi-head attention incurs prohibitive computation time, and its decoupled
training of time-frequency models overlooks cross-domain dependencies. To
overcome these problems, we propose DualAttWaveNet. A bidirectional attention
fusion layer dynamically correlates time-domain samples using
parameter-efficient cross-attention routing. A wavelet-regularized
reconstruction loss enforces multi-scale consistency. We train the model on
public dataset which consists of 48 hours of satellite signals. Experiments
show that compared to TrID, DualAttWaveNet improves AUC by 12% and reduces
inference time by 50% to 540ms per batch while maintaining F1-score.

</details>


### [3] [CKMDiff: A Generative Diffusion Model for CKM Construction via Inverse Problems with Learned Priors](https://arxiv.org/abs/2504.17323)
*Shen Fu,Yong Zeng,Zijian Wu,Di Wu,Shi Jin,Cheng-Xiang Wang,Xiqi Gao*

Main category: eess.SP

TL;DR: 该论文提出了一种基于生成式AI的条件扩散模型CKMDiff，用于构建高质量的无线通信信道知识地图（CKM），在不依赖物理环境地图或收发器位置的情况下，支持去噪、补全和超分辨率等任务。通过环境感知数据增强机制，模型能学习电磁传播模式与空间几何特征的隐含关系，实验表明其性能优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统的性能依赖于高质量的信道知识地图（CKM），但现有方法难以仅基于有限且嘈杂的现场数据构建完整CKM。这一问题类似于经典的病态逆问题，需从有限观测中推断潜在因素。

Method: 采用条件扩散模型CKMDiff，结合生成式AI解决CKM构建中的去噪、补全和超分辨率任务。通过环境感知数据增强机制，强化模型对电磁传播与空间几何特征关系的建模能力。

Result: 在CKMImageNet和RadioMapSeer数据集上的实验表明，CKMDiff在性能上优于多种基准方法，实现了最先进的CKM构建效果。

Conclusion: CKMDiff为CKM构建提供了一种高效且环境感知的解决方案，无需依赖物理地图或收发器位置信息，展现了生成式AI在无线通信中的潜力。

Abstract: Channel knowledge map (CKM) is a promising technology to enable
environment-aware wireless communications and sensing with greatly enhanced
performance, by offering location-specific channel prior information for future
wireless networks. One fundamental problem for CKM-enabled wireless systems
lies in how to construct high-quality and complete CKM for all locations of
interest, based on only limited and noisy on-site channel knowledge data. This
problem resembles the long-standing ill-posed inverse problem, which tries to
infer from a set of limited and noisy observations the cause factors that
produced them. By utilizing the recent advances of solving inverse problems
with learned priors using generative artificial intelligence (AI), we propose
CKMDiff, a conditional diffusion model that can be applied to perform various
tasks for CKM constructions such as denoising, inpainting, and
super-resolution, without having to know the physical environment maps or
transceiver locations. Furthermore, we propose an environment-aware data
augmentation mechanism to enhance the model's ability to learn implicit
relations between electromagnetic propagation patterns and spatial-geometric
features. Extensive numerical results are provided based on the CKMImageNet and
RadioMapSeer datasets, which demonstrate that the proposed CKMDiff achieves
state-of-the-art performance, outperforming various benchmark methods.

</details>


### [4] [Introducing Combined Effects of Filtering and ASE Noise in Optical Links Supposing Different Equalization Algorithms](https://arxiv.org/abs/2504.17408)
*Enrico Miotto,Andrea Rosso,Emanuele Virgillito,Stefano Straullu,Andrea Castoldi,Andrea Bovio,Francisco Martinez Rodriguez,Vittorio Curri*

Main category: eess.SP

TL;DR: 该论文提出了一个用于评估ASE噪声受限相干光链路中滤波惩罚的全面分析框架，考虑了级联光滤波器、放大器引入的ASE噪声、收发器噪声以及接收端数字均衡的影响，并通过实验验证了模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决相干光链路中滤波惩罚的评估难题，尤其是级联滤波器和噪声累积对信号质量的复杂影响，为实际系统设计提供理论支持。

Method: 通过建立广义信道表示，推导了在多种均衡策略（如迫零均衡、最小均方误差均衡和分数间隔均衡）下的信噪比退化闭式表达式，结合时域和频域分析。

Result: 实验验证表明理论与实际结果高度一致，模型能够准确预测滤波和噪声对系统性能的影响，适用于城域接入网络的性能评估。

Conclusion: 该分析框架为相干光链路的系统级性能评估提供了可靠的理论基础，尤其在处理滤波和噪声问题上表现出色。

Abstract: This paper presents a comprehensive analytical framework for evaluating
filtering penalties in ASE-noise-limited coherent optical links. The model
accounts for the cumulative effects of cascaded optical filters,
amplifier-induced ASE noise, and transceiver noise, alongside digital
equalization at the receiver. By developing a generalized channel
representation, we derive closed-form expressions for signal-to-noise ratio
degradation under various equalization strategies, including Zero-Forcing
Equalizer, Minimum Mean Square Error Equalizer, and Fractionally Spaced
Equalizer. These models capture the impact of colored noise resulting from
linear filtering and provide both time and frequency-domain insights. The
proposed framework is validated through experimental comparisons using
accurately modeled optical filters, demonstrating close agreement between
theory and practice and offering a robust foundation for system-level
performance evaluation in metro-access networks.

</details>


### [5] [RIS-Assisted Noncoherent Wireless System: Error Analysis with Optimal Receiver and Multi-level ASK](https://arxiv.org/abs/2504.17423)
*Sambit Mishra,Soumya P. Dash*

Main category: eess.SP

TL;DR: 论文研究了RIS辅助的非相干无线通信系统，提出了一种新的统计分析方法以近似加权和中心与非中心卡方随机变量，并推导了符号错误概率（SEP）的闭式表达式。进一步提出了在传输能量约束下最小化SEP的优化问题，并通过新算法得到最优ASK星座。数值结果表明，与传统等间距ASK星座相比，非相干系统在最优ASK星座下具有更优的误码性能和更高分集阶数。


<details>
  <summary>Details</summary>
Motivation: 现有非相干通信系统在RIS辅助场景下的性能尚未充分探索，尤其是在ASK调制下如何通过优化星座设计提升系统误码性能的研究较少，因此论文旨在填补这一空白。

Method: 论文提出了加权和中心与非中心卡方随机变量的统计近似方法，推导了非相干系统的SEP闭式表达式，并设计了优化算法求解最优ASK星座。

Result: 数值结果显示，最优ASK星座显著提升了系统误码性能和分集阶数，尤其是在高信噪比和RIS反射单元较少时效果更明显。

Conclusion: 论文证明了在RIS辅助的非相干系统中，通过优化ASK星座设计可显著提升性能，为未来无线通信系统的实际部署提供了理论支持。

Abstract: This paper considers a reconfigurable intelligent surface (RIS) aided
wireless communication system where the transmitter employs one-sided
amplitude-shift keying (ASK) for data modulation and the receiver employs an
optimal noncoherent maximum-likelihood rule for symbol detection. A novel
statistical analysis is presented to approximate the weighted sum of a central
and a non-central chi-squared random variable, which is used to derive a novel
closed-form expression for the symbol error probability (SEP) of the
noncoherent system. Furthermore, an optimization problem to minimize the
system's SEP under transmission energy constraint is proposed, and novel
algorithms are presented to obtain the optimal ASK constellation minimizing the
SEP. Numerical results indicate that the noncoherent system achieves superior
error performance and higher diversity order with the optimal ASK constellation
compared to the traditional equispaced ASK constellation. Further, the optimal
ASK significantly differs from the traditional one, with the difference
becoming significant with an increase in the average signal-to-noise ratio and
at a lower number of RIS's reflecting elements.

</details>


### [6] [On Geometric Shaping for 400 Gbps IM-DD Links with Laser Intensity Noise](https://arxiv.org/abs/2504.17433)
*Felipe Villenas,Kaiquan Wu,Yunus Can Gültekin,Jamal Riani,Alex Alvarado*

Main category: eess.SP

TL;DR: 提出针对受相对强度噪声（RIN）主导的IM-DD链路的几何整形方法，使400 Gbps链路的误码率降低，激光器RIN设计放宽3 dB。


<details>
  <summary>Details</summary>
Motivation: IM-DD链路中相对强度噪声（RIN）是主要性能限制因素，需优化传输性能。

Method: 采用几何整形设计星座图，优化信号分布以对抗RIN影响。

Result: 在400 Gbps链路中实现误码率显著改善，RIN激光器设计需求放宽3 dB。

Conclusion: 几何整形可有效提升IM-DD链路性能，降低对激光器RIN的严格要求。

Abstract: We propose geometric shaping for IM-DD links dominated by relative intensity
noise (RIN). For 400 Gbps links, our geometrically-shaped constellations result
in error probability improvements that relaxes the RIN laser design by 3 dB.

</details>


### [7] [Comparative Analysis of Hybrid Precoding Optimization Approaches for Millimeter Wave Massive MIMO System](https://arxiv.org/abs/2504.17521)
*Om Nath Acharya,Ram Kaji Budhathoki,Santosh Shaha*

Main category: eess.SP

TL;DR: 论文比较了混合波束成形与传统数字波束成形在毫米波大规模MIMO系统中的性能，提出基于深度神经网络的混合预编码优化方法，解决了非凸优化问题，并在频谱效率、误码率和复杂度上优于传统技术。


<details>
  <summary>Details</summary>
Motivation: 传统数字波束成形在实现大规模MIMO系统时存在高功耗、高成本和复杂信号处理的问题，混合波束成形结合了模拟和数字波束成形的优势，但需解决其非凸优化问题。

Method: 采用深度神经网络优化混合波束成形的发射和接收端，通过训练和测试评估模型性能。

Result: 深度神经网络方法在频谱效率、误码率和复杂度上均优于传统技术，且模型训练和测试精度表现良好。

Conclusion: 基于深度神经网络的混合预编码优化是解决大规模MIMO系统中非凸优化问题的有效方法，具有实际应用潜力。

Abstract: The conventional digital beamforming technique needs one radio frequency (RF)
chain per antenna element. High power consumption, significantly high cost of
RF chain components per antenna and complex signal processing task at base band
makes digital beamforming unsuitable for implementation in massive MIMO system.
Hybrid beamforming takes the benefits of both analog and digital beamforming
schemes. Near optimal performance can be achieved using very few RF chains in
hybrid beamforming method. By optimizing the hybrid transmit and receive
beamformers, the spectral efficiency of a system can be maximized. The hybrid
beamforming optimization problem is non-convex optimization problem due to the
non-convexity of the constraints. In this research work, the millimeter wave
massive MIMO system performance implementing the hybrid precoding based on the
conventional methods and deep neural network is studied considering the
spectral efficiency, bit error rate and complexity. It is shown that the deep
neural network based approach for hybrid precoding optimization outperforms
conventional techniques by solving the non-convex optimization problem.
Moreover, the DNN model accuracy is also analyzed by observing the training
accuracy and test accuracy.

</details>


### [8] [Semi-Blind Strategies for MMSE Channel Estimation Utilizing Generative Priors](https://arxiv.org/abs/2504.17573)
*Franz Weißer,Nurettin Turan,Dominik Semmler,Fares Ben Jazia,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 该论文研究大规模MIMO系统中的半盲信道估计，提出通过子空间估计和两种线性MMSE估计器变体提升性能，并结合高斯混合模型和变分自编码器作为生成先验，实验结果表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统的信道估计需要高效且准确的方法。传统方法依赖导频信号，但半盲方法利用所有接收符号（导频和载荷）提供额外信息以提高估计精度。

Method: 首先基于所有接收符号估计子空间，随后提出两种线性MMSE估计器变体：一种在子空间内求解，另一种使用子空间投影作为预处理。进一步引入基于高斯混合模型和变分自编码器的生成先验。

Result: 理论推导和实验证明，后一种估计器在非相关瑞利衰落信道下具有更优的均方误差性能，且在真实测量数据和空间信道模型中表现优于现有半盲估计器。

Conclusion: 通过子空间信息和生成先验的结合，提出的半盲LMMSE估计器显著提升了大规模MIMO系统的信道估计性能。

Abstract: This paper investigates semi-blind channel estimation for massive
multiple-input multiple-output (MIMO) systems. To this end, we first estimate a
subspace based on all received symbols (pilot and payload) to provide
additional information for subsequent channel estimation. We show how this
additional information enhances minimum mean square error (MMSE) channel
estimation. Two variants of the linear MMSE (LMMSE) estimator are formulated,
where the first one solves the estimation within the subspace, and the second
one uses a subspace projection as a preprocessing step. Theoretical derivations
show the superior estimation performance of the latter method in terms of mean
square error for uncorrelated Rayleigh fading. Subsequently, we introduce
parameterizations of this semi-blind LMMSE estimator based on two different
conditional Gaussian latent models, i.e., the Gaussian mixture model and the
variational autoencoder. Both models learn the underlying channel distribution
of the propagation environment based on training data and serve as generative
priors for semi-blind channel estimation. Extensive simulations for real-world
measurement data and spatial channel models show the superior performance of
the proposed methods compared to state-of-the-art semi-blind channel estimators
with respect to the MSE.

</details>


### [9] [UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning](https://arxiv.org/abs/2504.17676)
*Yuhao Zhang,Guangjin Pan,Musa Furkan Keskin,Ossi Kaltiokallio,Mikko Valkama,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出一种结合模型与机器学习（ML）的定位方法，自动生成标签并显著提升定位精度


<details>
  <summary>Details</summary>
Motivation: 5G/6G应用（如自动驾驶和AR）需高精度设备定位

Method: 结合模型与ML方法，利用地图信息并通过最优传输（OT）自动生成标签

Result: 定位精度显著提升（LoS用户优于ML方法，NLoS用户优于模型方法）

Conclusion: 无需人工标注数据即可达到与全监督指纹法相当的竞争力

Abstract: Accurate mobile device localization is critical for emerging 5G/6G
applications such as autonomous vehicles and augmented reality. In this paper,
we propose a unified localization method that integrates model-based and
machine learning (ML)-based methods to reap their respective advantages by
exploiting available map information. In order to avoid supervised learning, we
generate training labels automatically via optimal transport (OT) by fusing
geometric estimates with building layouts. Ray-tracing based simulations are
carried out to demonstrate that the proposed method significantly improves
positioning accuracy for both line-of-sight (LoS) users (compared to ML-based
methods) and non-line-of-sight (NLoS) users (compared to model-based methods).
Remarkably, the unified method is able to achieve competitive overall
performance with the fully-supervised fingerprinting, while eliminating the
need for cumbersome labeled data measurement and collection.

</details>


### [10] [Unsupervised EEG-based decoding of absolute auditory attention with canonical correlation analysis](https://arxiv.org/abs/2504.17724)
*Nicolas Heintz,Tom Francart,Alexander Bertrand*

Main category: eess.SP

TL;DR: 该论文提出了一种无监督算法，用于从脑电图（EEG）记录中检测受试者是主动聆听声音还是忽略声音，性能显著优于现有监督模型。


<details>
  <summary>Details</summary>
Motivation: 解决绝对听觉注意力解码（aAAD）问题，无需监督训练即可适应非稳态测试数据。

Method: 结合无监督判别性CCA特征提取与MILDA分类器进行aAAD分类。

Result: 无监督算法性能显著优于现有监督模型，且计算成本低。

Conclusion: 该方法为通过EEG信号分析听觉注意力提供了无需监督训练的自动适配方案。

Abstract: We propose a fully unsupervised algorithm that detects from encephalography
(EEG) recordings when a subject actively listens to sound, versus when the
sound is ignored. This problem is known as absolute auditory attention decoding
(aAAD). We propose an unsupervised discriminative CCA model for feature
extraction and combine it with an unsupervised classifier called minimally
informed linear discriminant analysis (MILDA) for aAAD classification.
Remarkably, the proposed unsupervised algorithm performs significantly better
than a state-of-the-art supervised model. A key reason is that the unsupervised
algorithm can successfully adapt to the non-stationary test data at a low
computational cost. This opens the door to the analysis of the auditory
attention of a subject using EEG signals with a model that automatically tunes
itself to the subject without requiring an arduous supervised training session
beforehand.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [11] [On the feasibility of laser satellite communications from the Martian surface](https://arxiv.org/abs/2504.16955)
*Eva Fernandez Rodriguez,Zachary C. Rowland,Roderik A. Overzier*

Main category: astro-ph.IM

TL;DR: 该论文研究了火星大气层（尤其是尘埃）对自由空间光通信（FSO）链路的影响，基于火星气候数据库生成尘埃光学深度图，并模拟表面与卫星间的通信链路预算，结果对未来火星任务的激光通信系统设计有指导意义。


<details>
  <summary>Details</summary>
Motivation: 自由空间光通信（FSO）在数据传输速率、功耗和安全性方面优于传统射频技术，火星表面的FSO链路是这一技术的自然延伸。研究旨在评估火星大气尘埃对光通信的影响，为未来任务提供设计依据。

Method: 利用火星气候数据库生成标准气候和暖（多尘）气候下的尘埃光学深度图，将其外推至1.55微米波长，转换为斜路径光学深度以计算链路预算和可用性统计。

Result: 研究量化了火星尘埃对通信链路的影响，生成了不同气候条件下的链路预算和可用性数据，为地面站选址和终端设计提供了参考。

Conclusion: 火星大气尘埃显著影响FSO链路性能，研究结果为未来火星任务中激光通信系统的设计与性能评估提供了重要依据。

Abstract: Free space optical (FSO) communication using lasers is a rapidly developing
field in telecommunications that can offer advantages over traditional radio
frequency technology. For example, optical laser links may allow transmissions
at far higher data rates, require less operating power and smaller systems and
have a smaller risk of interception. In recent years, FSO laser links have been
demonstrated, tested or integrated in a range of environments and scenarios.
These include FSO links for terrestrial communication, between ground stations
and cube-sats in low Earth orbit, between ground and satellite in lunar orbit,
as part of scientific or commercial space relay networks, and deep space
communications beyond the moon. The possibility of FSO links from and to the
surface of Mars could be a natural extension of these developments. In this
paper we evaluate some effects of the Martian atmosphere on the propagation of
optical communication links, with an emphasis on the impact of dust on the
total link budget. We use the output of the Mars Climate Database to generate
maps of the dust optical depth for a standard Mars climatology, as well as for
a warm (dusty) atmosphere. These dust optical depths are then extrapolated to a
wavelength of 1.55 um, and translated into total slant path optical depths to
calculate link budgets and availability statistics for a link between the
surface and a satellite in a sun-synchronous orbit. The outcomes of this study
are relevant to potential future missions to Mars that may require laser
communications to or from its surface. For example, the results could be used
to constrain the design of communication terminals suitable to the Mars
environment, or to assess the link performance as a function of ground station
location.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications](https://arxiv.org/abs/2504.16972)
*Hossein Ahmadi,Sajjad Emdadi Mahdimahalleh,Arman Farahat,Banafsheh Saffari*

Main category: cs.LG

TL;DR: 本文综述了自动编码器和视觉Transformer在无监督信号分析中的应用，探讨其架构、应用及趋势，并指出混合架构和自监督学习的优势与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信、雷达、生物医学工程和物联网等领域未标记时间序列数据的快速增长，无监督学习技术需求激增，本文旨在总结此类应用的最新进展。

Method: 综述了基于自动编码器和视觉Transformer的模型架构及其在特征提取、异常检测和分类任务中的应用，重点关注混合架构和自监督学习策略。

Result: 研究表明，这些模型在多样化信号（如心电图、雷达波形和IoT数据）处理中表现优异，但仍面临可解释性、可扩展性和领域泛化的挑战。

Conclusion: 本文为开发鲁棒、自适应的信号智能模型提供了技术路线，并强调未来需解决的关键问题。

Abstract: The rapid growth of unlabeled time-series data in domains such as wireless
communications, radar, biomedical engineering, and the Internet of Things (IoT)
has driven advancements in unsupervised learning. This review synthesizes
recent progress in applying autoencoders and vision transformers for
unsupervised signal analysis, focusing on their architectures, applications,
and emerging trends. We explore how these models enable feature extraction,
anomaly detection, and classification across diverse signal types, including
electrocardiograms, radar waveforms, and IoT sensor data. The review highlights
the strengths of hybrid architectures and self-supervised learning, while
identifying challenges in interpretability, scalability, and domain
generalization. By bridging methodological innovations and practical
applications, this work offers a roadmap for developing robust, adaptive models
for signal intelligence.

</details>


### [13] [Coding for Computation: Efficient Compression of Neural Networks for Reconfigurable Hardware](https://arxiv.org/abs/2504.17403)
*Hans Rosenberger,Rodrigo Fischer,Johanna S. Fröhlich,Ali Bereyhi,Ralf R. Müller*

Main category: cs.LG

TL;DR: 提出一种针对FPGA等可重构硬件的神经网络压缩方案，通过剪枝、权重共享和线性计算编码（LCC）减少推理时的加法运算，而非常见的权重存储优化。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络规模增大，资源高效实现变得尤为重要。现有压缩技术多关注权重存储优化，而本文针对硬件推理时的计算效率提升。

Method: 结合正则化训练的剪枝、权重共享和线性计算编码（LCC），以减少推理所需的加法运算为核心目标。

Result: 在简单多层感知器和ResNet-34等大型深度网络上均取得竞争力性能。

Conclusion: 该方案为硬件友好的高效推理提供了新思路，尤其适用于可重构硬件场景。

Abstract: As state of the art neural networks (NNs) continue to grow in size, their
resource-efficient implementation becomes ever more important. In this paper,
we introduce a compression scheme that reduces the number of computations
required for NN inference on reconfigurable hardware such as FPGAs. This is
achieved by combining pruning via regularized training, weight sharing and
linear computation coding (LCC). Contrary to common NN compression techniques,
where the objective is to reduce the memory used for storing the weights of the
NNs, our approach is optimized to reduce the number of additions required for
inference in a hardware-friendly manner. The proposed scheme achieves
competitive performance for simple multilayer perceptrons, as well as for large
scale deep NNs such as ResNet-34.

</details>


### [14] [Disaggregated Deep Learning via In-Physics Computing at Radio Frequency](https://arxiv.org/abs/2504.17752)
*Zhihui Gao,Sri Krishna Vadlamani,Kfir Sulimany,Dirk Englund,Tingjun Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为WISE的新型无线边缘网络计算架构，通过无线广播和射频物理计算实现了低功耗的深度学习推理。


<details>
  <summary>Details</summary>
Motivation: 边缘设备资源有限，难以支持传统数字计算架构下的深度学习实时推理，因此需要一种更高效的解决方案。

Method: WISE采用无线广播分解模型访问和射频直接进行复数矩阵向量乘法计算，通过软件定义无线电平台验证。

Result: 实验证明WISE实现95.7%的图像分类准确率，每客户6.0 fJ/MAC的超低功耗，计算效率达165.8 TOPS/W。

Conclusion: WISE在无线连接边缘设备上实现了能效比传统数字计算高两个数量级的深度学习推理。

Abstract: Modern edge devices, such as cameras, drones, and Internet-of-Things nodes,
rely on deep learning to enable a wide range of intelligent applications,
including object recognition, environment perception, and autonomous
navigation. However, deploying deep learning models directly on the often
resource-constrained edge devices demands significant memory footprints and
computational power for real-time inference using traditional digital computing
architectures. In this paper, we present WISE, a novel computing architecture
for wireless edge networks designed to overcome energy constraints in deep
learning inference. WISE achieves this goal through two key innovations:
disaggregated model access via wireless broadcasting and in-physics computation
of general complex-valued matrix-vector multiplications directly at radio
frequency. Using a software-defined radio platform with wirelessly broadcast
model weights over the air, we demonstrate that WISE achieves 95.7% image
classification accuracy with ultra-low operation power of 6.0 fJ/MAC per
client, corresponding to a computation efficiency of 165.8 TOPS/W. This
approach enables energy-efficient deep learning inference on wirelessly
connected edge devices, achieving more than two orders of magnitude improvement
in efficiency compared to traditional digital computing.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [15] [The Riemannian Means Field Classifier for EEG-Based BCI Data](https://arxiv.org/abs/2504.17352)
*Anton Andreev,Grégoire Cattan,Marco Congedo*

Main category: cs.HC

TL;DR: 该论文提出了一种改进的Riemannian最小距离均值（MDM）分类器，通过使用多个SPD矩阵的幂均值而非单一的几何均值，显著提升了分类性能，接近最先进水平，同时保持了简单性和确定性。


<details>
  <summary>Details</summary>
Motivation: 传统的MDM分类器在EEG-based BCIs中表现出鲁棒性和准确性，但仍存在性能提升空间。作者希望通过改进方法进一步提升分类效果，同时保持其简单高效的特点。

Method: 作者提出了改进的MDM分类器，采用多个SPD矩阵的幂均值代替原来的单一几何均值。该方法在大规模公开数据集上进行了验证，涵盖运动想象和P300两种BCI范式。

Result: 通过分析20个公开数据集（包含587名受试者），改进后的分类器性能明显优于传统MDM，接近最先进水平，同时保持了简单和确定性等优势。

Conclusion: 改进的MDM分类器在性能上显著提升，适用于多种BCI范式，且代码开源以促进可重复研究。

Abstract: A substantial amount of research has demonstrated the robustness and accuracy
of the Riemannian minimum distance to mean (MDM) classifier for all kinds of
EEG-based brain--computer interfaces (BCIs). This classifier is simple, fully
deterministic, robust to noise, computationally efficient, and prone to
transfer learning. Its training is very simple, requiring just the computation
of a geometric mean of a symmetric positive-definite (SPD) matrix per class. We
propose an improvement of the MDM involving a number of power means of SPD
matrices instead of the sole geometric mean. By the analysis of 20 public
databases, 10 for the motor-imagery BCI paradigm and 10 for the P300 BCI
paradigm, comprising 587 individuals in total, we show that the proposed
classifier clearly outperforms the MDM, approaching the state-of-the art in
terms of performance while retaining the simplicity and the deterministic
behavior. In order to promote reproducible research, our code will be released
as open source.

</details>
