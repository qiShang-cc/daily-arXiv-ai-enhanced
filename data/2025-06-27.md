<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.NE](#cs.NE) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
*Zijun Wang,Shawn Tsai,Rama Kiran,Rui Zhang*

Main category: eess.SP

TL;DR: 本文提出了一种低复杂度的近场波束训练方案，利用远场用户的DFT码本，通过分析近场波束模式，推导出闭式表达式，并提出一种O(1)复杂度的用户距离估计方法，仿真结果显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着超大规模天线阵列和高频段通信的发展，近场通信的需求日益增长，亟需高效的波束训练和信号处理方案。

Method: 通过分析近场波束模式，推导闭式表达式定义角度依赖的修正Rayleigh距离，提出低复杂度的距离估计方法，并进一步通过MLE方法提升精度。

Result: 仿真结果显示，相比穷举搜索，信噪比提升达2.38 dB，且单用户和多用户性能接近理想信道状态信息下的结果。

Conclusion: 本方案高效且性能优越，适用于近场通信场景，为未来大规模天线系统提供了实用解决方案。

Abstract: Extremely large antenna arrays (ELAAs) operating in high-frequency bands have
spurred the development of near-field communication, driving advancements in
beam training and signal processing design. In this work, we present a
low-complexity near-field beam training scheme that fully utilizes the
conventional discrete Fourier transform (DFT) codebook designed for far-field
users. We begin by analyzing the received beam pattern in the near field and
derive closed-form expressions for the beam width and central gain. These
analytical results enable the definition of an angle-dependent, modified
Rayleigh distance, which effectively distinguishes near-field and far-field
user regimes. Building on the analysis, we develop a direct and computationally
efficient method to estimate user distance, with a complexity of O(1), and
further improve its accuracy through a simple refinement. Simulation results
demonstrate significant gains in both single- and multi-user settings, with up
to 2.38 dB SNR improvement over exhaustive search. To further enhance
estimation accuracy, we additionally propose a maximum likelihood estimation
(MLE) based refinement method, leveraging the Rician distribution of signal
amplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).
Simulation shows the single-user and multi-user achievable rates can both
approach those obtained with ideal channel state information.

</details>


### [2] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
*Mohammad Taghi Dabiri,Mazen Hasna,Saif Al-Kuwari,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 本文分析了基于纠缠的卫星间量子密钥分发（QKD）性能，重点研究了光子级建模和实际损伤的影响，提出了优化系统设计的可操作建议。


<details>
  <summary>Details</summary>
Motivation: 现有的文献未解决长距离卫星间自由空间光学信道中的关键物理层挑战，如光子损耗和背景噪声对密钥生成率和量子比特错误率的影响。

Method: 通过光子级建模，开发了信号检测概率、背景光子影响、多对发射和量子比特错误率的解析表达式，并结合仿真分析了跟踪误差和视场限制对系统性能的非线性敏感性。

Result: 仿真结果显示系统性能对跟踪误差和视场限制非常敏感，并提出了在量子比特错误率可接受范围内联合最大化密钥率的优化参数范围。

Conclusion: 该模型为可靠高效部署基于纠缠的卫星量子密钥分发系统提供了实用的设计指导。

Abstract: Entanglement-based quantum key distribution (QKD) protocols, such as E91 and
BBM92, offer strong information-theoretic security and are naturally suited for
satellite-to-satellite QKD (SatQKD) links. However, implementing these
protocols over long-distance inter-satellite free-space optical (FSO) channels
poses critical physical-layer challenges that are not addressed in the existing
literature. In particular, photon losses due to beam divergence, pointing
errors, and background noise can severely degrade the key generation rate and
quantum bit error rate (QBER), especially under narrow receiver field-of-view
(FoV) constraints. This paper presents a comprehensive performance analysis of
entanglement-based inter-satellite QKD, focusing on photon-level modeling and
the impact of practical impairments. We develop analytical expressions for
signal detection probabilities, background photon influence, multi-pair
emissions, and QBER, incorporating key parameters such as link distance,
transmitter tracking jitter, receiver misalignment, and photon pair generation
rate. Simulation results reveal the nonlinear sensitivity of system performance
to tracking error and FoV limitations, and highlight optimal parameter regimes
that jointly maximize secret key rate while maintaining QBER below acceptable
thresholds. The proposed model provides actionable design insights for reliable
and efficient deployment of entanglement-based SatQKD systems.

</details>


### [3] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
*Mohammad Taghi Dabiri,Mazen Hasna*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents an efficient analytical framework for evaluating the
performance of inter-satellite communication systems utilizing orbital angular
momentum (OAM) beams under pointing errors. An accurate analytical model is
first developed to characterize intermodal crosstalk caused by beam
misalignment in OAM-based inter-satellite links. Building upon this model, we
derive efficient expressions to analyze and optimize system performance in
terms of bit error rate (BER). Unlike traditional Monte Carlo-based methods
that are computationally intensive, the proposed approach offers accurate
performance predictions. This enables a substantial decrease in computation
time while maintaining high accuracy, thanks to the use of analytical
expressions for both crosstalk and BER. This fast and accurate evaluation
capability is particularly critical for dynamic low Earth orbit (LEO) satellite
constellations, where network topology and channel conditions change rapidly,
requiring real-time link adaptation. Furthermore, we systematically design and
evaluate asymmetric OAM mode sets, which significantly outperform symmetric
configurations in the presence of pointing errors. Our results also reveal key
insights into the interaction between beam divergence, tracking accuracy, and
link distance, demonstrating that the proposed framework enables real-time
optimization of system parameters with high fidelity. The analytical findings
are rigorously validated against extensive Monte Carlo simulations, confirming
their practical applicability for high-mobility optical wireless systems such
as LEO satellite networks.

</details>


### [4] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
*Jamil Farhat,Gianni Pasolini,Enrico Paolini,Muhammad Asad Ullah,Richard Demo Souza*

Main category: eess.SP

TL;DR: 该论文探讨了LoRa调制在LPWAN框架中的应用，特别是在远程地区通过卫星实现物联网（IoT）连接时面临的Doppler效应问题，提出了四种补偿框架，并分析了性能表现。


<details>
  <summary>Details</summary>
Motivation: 由于LEO卫星的移动性导致的Doppler效应对LoRa直接到卫星（DtS）连接的性能有显著负面影响，需要研究补偿方法以提高连接质量。

Method: 提出了四种Doppler估计和补偿框架，并通过数值模拟与理想无Doppler效应的场景进行性能比较，同时分析扩频因子等关键参数的权衡。

Result: 研究结果为LoRa在DtS连接中的鲁棒配置提供了指导，并展示了不同补偿框架的性能差异。

Conclusion: 通过补偿框架可以有效减轻Doppler效应对LoRa DtS连接的影响，但需要根据具体应用场景选择合适的参数配置。

Abstract: Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology
has garnered significant interest as a connectivity solution for IoT
applications due to its ability to offer low-cost, low-power, and long-range
communications. One emerging use case of LoRa is DtS connectivity, which
extends coverage to remote areas for supporting IoT operations. The satellite
IoT industry mainly prefers LEO because it has lower launch costs and less path
loss compared to Geostationary orbit. However, a major drawback of LEO
satellites is the impact of the Doppler effect caused by their mobility.
Earlier studies have confirmed that the Doppler effect significantly degrades
the LoRa DtS performance. In this paper, we propose four frameworks for Doppler
estimation and compensation in LoRa DtS connectivity and numerically compare
the performance against the ideal scenario without the Doppler effect.
Furthermore, we investigate the trade-offs among these frameworks by analyzing
the interplay between spreading factor, and other key parameters related to the
Doppler effect. The results provide insights into how to achieve robust LoRa
configurations for DtS connectivity.

</details>


### [5] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
*Naoki Ishikawa,Giuseppe Thadeu Freitas de Abreu,Petar Popovski,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: 量子计算有望改变通信系统的算法基础，本文探讨了量子计算在通信中的应用潜力及与无线系统的数学和谐性。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在通信系统中的实际应用，并激发量子信息处理与未来通信系统的跨学科研究。

Method: 系统回顾了量子加速通信系统的先驱和最新研究，总结了设计趋势和经典启发式方法对量子参数的优化作用。

Result: 揭示了量子计算与无线系统之间的数学和谐性，并展示了经典与量子计算的互补优势。

Conclusion: 本文旨在推动量子信息处理与未来通信系统跨学科研究的发展。

Abstract: Quantum computing is poised to redefine the algorithmic foundations of
communication systems. While quantum superposition and entanglement enable
quadratic or exponential speedups for specific problems, identifying use cases
where these advantages yield engineering benefits is, however, still
nontrivial. This article presents the fundamentals of quantum computing in a
style familiar to the communications society, outlining the current limits of
fault-tolerant quantum computing and uncovering a mathematical harmony between
quantum and wireless systems, which makes the topic more enticing to wireless
researchers. Based on a systematic review of pioneering and state-of-the-art
studies, we distill common design trends for the research and development of
quantum-accelerated communication systems and highlight lessons learned. The
key insight is that classical heuristics can sharpen certain quantum
parameters, underscoring the complementary strengths of classical and quantum
computing. This article aims to catalyze interdisciplinary research at the
frontier of quantum information processing and future communication systems.

</details>


### [6] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
*Haijia Jin,Jun Wu,Weijie Yuan,Fan Liu,Yuanhao Cui*

Main category: eess.SP

TL;DR: 论文研究了多无人机协同系统中集成传感、通信和控制的联合设计，提出了资源分配、部署和调度的优化方法，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网服务和6G的发展，无人机在低空无线网络中的作用日益重要，如何优化其集成传感、通信与控制成为关键问题。

Method: 通过加权优化问题，结合交替优化和DC编程等方法，解决了非凸问题的挑战。

Result: 仿真结果表明，所提方法优于基准方案，揭示了控制与传感性能之间的权衡。

Conclusion: 该研究为无人机协同系统的优化设计提供了有效解决方案，具有实际应用潜力。

Abstract: The rapid advancement of Internet of Things (IoT) services and the evolution
toward the sixth generation (6G) have positioned unmanned aerial vehicles
(UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This
work investigates the co-design of integrated sensing, communication, and
control ($\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite
blocklength (FBL) transmission. In particular, the UAVs continuously monitor
the state of the field robots and transmit their observations to the robot
controller to ensure stable control while cooperating to localize an unknown
sensing target (ST). To this end, a weighted optimization problem is first
formulated by jointly considering the control and localization performance in
terms of the linear quadratic regulator (LQR) cost and the determinant of the
Fisher information matrix (FIM), respectively. The resultant problem,
optimizing resource allocations, the UAVs' deployment positions, and multi-user
scheduling, is non-convex. To circumvent this challenge, we first derive a
closed-form expression of the LQR cost with respect to other variables.
Subsequently, the non-convex optimization problem is decomposed into a series
of sub-problems by leveraging the alternating optimization (AO) approach, in
which the difference of convex functions (DC) programming and projected
gradient descent (PGD) method are employed to obtain an efficient near-optimal
solution. Furthermore, the convergence and computational complexity of the
proposed algorithm are thoroughly analyzed. Extensive simulation results are
presented to validate the effectiveness of our proposed approach compared to
the benchmark schemes and reveal the trade-off between control and sensing
performance.

</details>


### [7] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 该论文提出了评估差分麦克风阵列（DMA）波束功率模式中零点效用的新度量，包括零点深度和零点宽度，并通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏直接评估DMA中零点效用的度量，该研究填补了这一空白，旨在更好地理解DMA在干扰源抑制中的潜力。

Method: 提出了零点深度（ND）和零点宽度（NW）作为新度量，研究了信号量化对DMA性能的影响，并通过仿真和实验室实验验证了理论分析。

Result: 仿真和实验结果显示了量化位数对ND的影响以及NW随深度变化的关系，验证了理论与实验的一致性。

Conclusion: 该研究为评估DMA零点性能提供了新工具，实验证明了其有效性，为DMA在干扰抑制中的应用提供了支持。

Abstract: A differential microphone array (DMA) offers enhanced capabilities to obtain
sharp nulls at the cost of relatively broad peaks in the beam power pattern.
This can be used for applications that require nullification or attenuation of
interfering sources. To the best of our knowledge, the existing literature
lacks measures that directly assess the efficacy of nulls, and null-related
measures have not been investigated in the context of differential microphone
arrays (DMAs). This paper offers new insights about the utility of DMAs by
proposing measures that characterize the nulls in their beam power patterns. We
investigate the performance of differential beamformers by presenting and
evaluating null-related measures namely null depth (ND) and Null Width (NW) as
a function of depth level relative to the beam power pattern maxima. A study of
signal quantization effects due to data acquisition for 1st, 2nd and 3rd order
linear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid
and supercardioid is presented. An analytical expression for the quantized
beamformed output for any general $ N^{th} $ order DMA is formulated.
Simulation results of the variation of ND with number of quantization bits and
the variation of NW as a function of depth are also presented and inferences
are drawn. Lab experiments are conducted in a fully anechoic room to support
the simulation results. The measured beampattern exhibits a pronounced null
depth, confirming the effectiveness of the experimental setup.

</details>


### [8] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
*Yancheng Wang,Wei Guo,Guanying Chen,Ye Zhang,Shuguang Cui*

Main category: eess.SP

TL;DR: 该论文提出了一种结合模型和数据驱动的方法，利用点云环境数据和少量位置标记的通道信息构建通道知识地图（CKM），显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方案过于简化环境信息，导致准确性不足，需要一种更精确的方法。

Method: 通过点选择器识别与多路径通道增益相关的环境点云子集，并训练神经网络学习其映射关系。

Result: 在功率延迟分布（PDP）和接收功率值的CKM构建中，新方法的均方根误差（RMSE）显著低于传统方法。

Conclusion: 所提方法在CKM构建中表现出更高的准确性，为环境感知通信提供了可靠支持。

Abstract: Channel knowledge map (CKM) provides certain levels of channel state
information (CSI) for an area of interest, serving as a critical enabler for
environment-aware communications by reducing the overhead of frequent CSI
acquisition. However, existing CKM construction schemes adopt over-simplified
environment information, which significantly compromises their accuracy. To
address this issue, this work proposes a joint model- and data-driven approach
to construct CKM by leveraging point cloud environmental data along with a few
samples of location-tagged channel information. First, we propose a novel point
selector to identify subsets of point cloud that contain environmental
information relevant to multipath channel gains, by constructing a set of
co-focal ellipsoids based on different time of arrival (ToAs). Then, we trained
a neural channel gain estimator to learn the mapping between each selected
subset and its corresponding channel gain, using a real-world dataset we
collected through field measurements, comprising environmental point clouds and
corresponding channel data. Finally, experimental results demonstrate that: For
CKM construction of power delay profile (PDP), the proposed method achieves a
root mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB
achieved by the conventional ray-tracing method; for CKM construction of
received power values, i.e., radio map, it achieves an RMSE of 1.04 dB,
surpassing the Kriging interpolation method with an RMSE of 1.68 dB.

</details>


### [9] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
*Hao Wu,Chongwu Xie,Xinyuan Yao,Kang-Da Wu,Shanchi Wu,Rui Ni,Guo-Yong Xiang,Chen Gong*

Main category: eess.SP

TL;DR: 分析了基于里德堡原子传感器的多用户通信中的互干扰特性，提出了联合响应系数，并验证了误码率和符号错误率。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子传感器在多频率信号测量中具有潜力，但多用户干扰问题限制了其性能。本文旨在分析这种干扰特性。

Method: 通过引入联合响应系数，分析了两种载频信号对不同能级的耦合干扰，并进行了实验验证。

Result: 研究了多用户干扰对误码率和符号错误率的影响，实验结果与理论分析一致。

Conclusion: 研究为里德堡原子传感器在多用户通信中的应用提供了理论基础和实验支持。

Abstract: Rydberg atomic sensors have been adopted for novel radio frequency (RF)
measurement technique and the sensing capability for signals in multiple
frequencies makes it attractive for multi-user communication. However, unlike
traditional antennas where the signals in multiple frequencies are orthogonal,
the received signals of atomic sensors corresponding to different energy levels
will be downconverted to the baseband simultaneously, resulting in multi-user
interference. Thus, in this paper, we analyze the mutual interference
characteristics of two RF signals with different carrier frequencies coupling
different energy levels. We introduce the joint response coefficient based on
the receiver characteristics and analyze the interference of one user to
another. We analyze the bit-error rate (BER) and symbol-error rate (SER) for
two signals coupling two different energy levels. We also conduct experiments
to validate the BER and SER results.

</details>


### [10] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
*Shengjie Liu,Chenyang Yang*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep neural networks (DNNs) have widespread applications for optimizing
resource allocation. Yet, their performance is vulnerable to distribution
shifts between training and test data, say channels. In this letter, we resort
to adversarial training (AT) for enhancing out-of-distribution (OOD)
generalizability of DNNs trained in unsupervised manner. We reformulate AT to
capture the OOD degradation, and propose a one-step gradient ascent method for
AT. The proposed method is validated by optimizing hybrid precoding. Simulation
results showcase the enhanced OOD performance of multiple kinds of DNNs across
various channel distributions, when only Rayleigh fading channels are used for
training.

</details>


### [11] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
*Nima Mozaffarikhosravi,Prathapasinghe Dharmawansa,Italo Atzeni*

Main category: eess.SP

TL;DR: 本文提出了一种基于定位的波束聚焦策略，适用于6G及以上无线通信系统，分析了2D-MUSIC算法的距离估计能力，并通过数值结果验证了该方法在LoS主导传播中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着6G及以上无线通信系统向更高频段发展，以及大规模MIMO阵列的应用，近场区域扩展影响了波束成形和用户定位方案，需要新的解决方案。

Method: 利用mmWave和sub-THz频率下的LoS传播优势，提出基于定位的波束聚焦策略，并通过2D-MUSIC算法分析距离估计能力。

Result: 数值结果表明，该方法在LoS主导传播、短相干块和高噪声功率情况下更为有效。

Conclusion: 提出的基于定位的波束聚焦策略在6G高频段和大带宽场景下具有显著优势。

Abstract: Shifting 6G-and-beyond wireless communication systems to higher frequency
bands and the utilization of massive multiple-input multiple-output arrays will
extend the near-field region, affecting beamforming and user localization
schemes. In this paper, we propose a localization-based beam-focusing strategy
that leverages the dominant line-of-sight (LoS) propagation arising at mmWave
and sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC
algorithm for distance estimation by examining its spectrum in simplified,
tractable setups with minimal numbers of antennas and users. Lastly, we compare
the proposed localization-based beam focusing, with locations estimated via
2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of
uplink sum spectral efficiency. Our numerical results show that the proposed
method becomes more effective under LoS-dominated propagation, short coherence
blocks, and strong noise power arising at high carrier frequencies and with
large bandwidths.

</details>


### [12] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
*Ying Gao,Qingqing Wu,Weidong Mei,Guangji Chen,Wen Chen,Ziyuan Zheng*

Main category: eess.SP

TL;DR: 该论文研究了智能反射面（IRS）辅助的可移动天线（MA）系统，通过联合优化MA位置、IRS反射系数和发射波束成形，最大化多个目标区域的信号噪声比（SNR）。提出了三种覆盖增强方案，并通过仿真验证了其性能优于固定天线（FPA）方案。


<details>
  <summary>Details</summary>
Motivation: 为了扩展无线覆盖范围并提升多目标区域的通信质量，研究如何通过IRS和MA的协同优化来实现最坏情况下SNR的最大化。

Method: 提出了三种覆盖增强方案（area-adaptive MA-IRS、area-adaptive MA-staIRS和shared MA-staIRS），并设计了一个通用算法框架来解决相关非凸优化问题。

Result: 仿真表明，MA方案在性能上优于FPA方案，其中area-adaptive MA-IRS表现最佳；天线数量的小幅增加可逆转area-adaptive MA-staIRS的劣势；MA与IRS元件的最优比例与其单位成本成反比。

Conclusion: IRS辅助的MA系统在覆盖扩展和性能提升方面具有潜力，尤其是通过动态优化MA位置和IRS配置，可以为无线通信提供灵活且高效的解决方案。

Abstract: This paper investigates an intelligent reflecting surface (IRS)-aided movable
antenna (MA) system, where multiple IRSs cooperate with a multi-MA base station
to extend wireless coverage to multiple designated target areas. The objective
is to maximize the worst-case signal-to-noise ratio (SNR) across all locations
within these areas through joint optimization of MA positions, IRS reflection
coefficients, and transmit beamforming. To achieve this while balancing the
performance-cost trade-off, we propose three coverage-enhancement schemes: the
area-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared
MA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients
configured only once during installation. These schemes lead to challenging
non-convex optimization problems with implicit objective functions, which are
difficult to solve optimally. To address these problems, we propose a general
algorithmic framework that can be applied to solve each problem efficiently
albeit suboptimally. Simulation results demonstrate that: 1) the proposed
MA-based schemes consistently outperform their fixed-position antenna
(FPA)-based counterparts under both area-adaptive and static IRS
configurations, with the area-adaptive MA-IRS scheme achieving the best
worst-case SNR performance; 2) as transmit antennas are typically far fewer
than IRS elements, the area-adaptive MA-staIRS scheme may underperform the
baseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but
a modest increase in antenna number can reverse this trend; 3) under a fixed
total cost, the optimal MA-to-IRS-element ratio for the worst-case SNR
maximization is empirically found to be proportional to the reciprocal of their
unit cost ratio.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [14] [Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks](https://arxiv.org/abs/2506.20762)
*Shisheng Hu,Jie Gao,Xue Qin,Conghao Zhou,Xinyu Huang,Mushu Li,Mingcheng He,Xuemin Shen*

Main category: cs.NI

TL;DR: 该论文提出了一种新型的漂移自适应切片资源管理方案，用于协作式集成感测与通信（ISAC）网络，提升了服务满意度和资源利用效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决移动设备和感测目标的非静态空间分布导致的规划决策失效问题，研究设计了漂移自适应方案。

Method: 通过建立两个网络切片分别提供感测和通信服务，并在数字孪生（DT）中开发漂移自适应统计模型和仿真功能。

Result: 数值结果显示，与基准方案相比，服务满意度提升18%，资源消耗减少13.1%。

Conclusion: 该方案在动态环境下显著提升了资源管理效率和性能。

Abstract: In this paper, we propose a novel drift-adaptive slicing-based resource
management scheme for cooperative integrated sensing and communication (ISAC)
networks. Particularly, we establish two network slices to provide sensing and
communication services, respectively. In the large-timescale planning for the
slices, we partition the sensing region of interest (RoI) of each mobile device
and reserve network resources accordingly, facilitating low-complexity
distance-based sensing target assignment in small timescales. To cope with the
non-stationary spatial distributions of mobile devices and sensing targets,
which can result in the drift in modeling the distributions and ineffective
planning decisions, we construct digital twins (DTs) of the slices. In each DT,
a drift-adaptive statistical model and an emulation function are developed for
the spatial distributions in the corresponding slice, which facilitates
closed-form decision-making and efficient validation of a planning decision,
respectively. Numerical results show that the proposed drift-adaptive
slicing-based resource management scheme can increase the service satisfaction
ratio by up to 18% and reduce resource consumption by up to 13.1% when compared
with benchmark schemes.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [15] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
*Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert*

Main category: eess.IV

TL;DR: PTACL是一种多模态对比学习框架，通过整合CMR的时空信息增强ECG表征，在临床相关任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 心电图(ECG)无法直接测量心室功能参数，而心脏磁共振(CMR)虽为金标准却昂贵且不易获取。PTACL旨在填补这一差距。

Method: PTACL结合了全局患者级和局部时间级的对比损失，通过对比学习对齐ECG和CMR的表征。

Result: 在UK Biobank的27,951个受试者数据上，PTACL在患者检索和CMR功能参数预测任务中表现更优。

Conclusion: PTACL展示了通过ECG增强无创心脏诊断的潜力。

Abstract: An electrocardiogram (ECG) is a widely used, cost-effective tool for
detecting electrical abnormalities in the heart. However, it cannot directly
measure functional parameters, such as ventricular volumes and ejection
fraction, which are crucial for assessing cardiac function. Cardiac magnetic
resonance (CMR) is the gold standard for these measurements, providing detailed
structural and functional insights, but is expensive and less accessible. To
bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive
Learning), a multimodal contrastive learning framework that enhances ECG
representations by integrating spatio-temporal information from CMR. PTACL uses
global patient-level contrastive loss and local temporal-level contrastive
loss. The global loss aligns patient-level representations by pulling ECG and
CMR embeddings from the same patient closer together, while pushing apart
embeddings from different patients. Local loss enforces fine-grained temporal
alignment within each patient by contrasting encoded ECG segments with
corresponding encoded CMR frames. This approach enriches ECG representations
with diagnostic information beyond electrical activity and transfers more
insights between modalities than global alignment alone, all without
introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data
from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL
achieves better performance in two clinically relevant tasks: (1) retrieving
patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac
function parameters, such as ventricular volumes and ejection fraction. Our
results highlight the potential of PTACL to enhance non-invasive cardiac
diagnostics using ECG. The code is available at:
https://github.com/alsalivan/ecgcmr

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [16] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
*Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Current medical image analysis systems are typically task-specific, requiring
separate models for classification and segmentation, and lack the flexibility
to support user-defined workflows. To address these challenges, we introduce
MedPrompt, a unified framework that combines a few-shot prompted Large Language
Model (Llama-4-17B) for high-level task planning with a modular Convolutional
Neural Network (DeepFusionLab) for low-level image processing. The LLM
interprets user instructions and generates structured output to dynamically
route task-specific pretrained weights. This weight routing approach avoids
retraining the entire framework when adding new tasks-only task-specific
weights are required, enhancing scalability and deployment. We evaluated
MedPrompt across 19 public datasets, covering 12 tasks spanning 5 imaging
modalities. The system achieves a 97% end-to-end correctness in interpreting
and executing prompt-driven instructions, with an average inference latency of
2.5 seconds, making it suitable for near real-time applications. DeepFusionLab
achieves competitive segmentation accuracy (e.g., Dice 0.9856 on lungs) and
strong classification performance (F1 0.9744 on tuberculosis). Overall,
MedPrompt enables scalable, prompt-driven medical imaging by combining the
interpretability of LLMs with the efficiency of modular CNNs.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [17] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
*Maxime Leiber,Yosra Marnissi,Axel Barrau,Sylvain Meignen,Laurent Massoulié*

Main category: cs.SD

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The short-time Fourier transform (STFT) is widely used for analyzing
non-stationary signals. However, its performance is highly sensitive to its
parameters, and manual or heuristic tuning often yields suboptimal results. To
overcome this limitation, we propose a unified differentiable formulation of
the STFT that enables gradient-based optimization of its parameters. This
approach addresses the limitations of traditional STFT parameter tuning
methods, which often rely on computationally intensive discrete searches. It
enables fine-tuning of the time-frequency representation (TFR) based on any
desired criterion. Moreover, our approach integrates seamlessly with neural
networks, allowing joint optimization of the STFT parameters and network
weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and
improving performance in downstream tasks is demonstrated through experiments
on both simulated and real-world data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [18] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
*Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker*

Main category: cs.LG

TL;DR: FINN框架用于LSTMs在FPGA上的高效部署，通过ONNX的Scan操作符支持混合量化，并在资源受限环境中实现性能与精度的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有FPGA工具主要针对前馈网络，LSTM加速通常需要完全自定义实现，限制了效率。

Method: 利用FINN框架和ONNX的Scan操作符，实现LSTM的量化与硬件映射。

Result: 生成的量化ConvLSTM加速器在性能和资源消耗间取得平衡，匹配或优于现有模型的推理精度。

Conclusion: 该流程为FPGA上资源高效RNN加速器设计铺平了道路。

Abstract: Recurrent neural networks (RNNs), particularly LSTMs, are effective for
time-series tasks like sentiment analysis and short-term stock prediction.
However, their computational complexity poses challenges for real-time
deployment in resource constrained environments. While FPGAs offer a promising
platform for energy-efficient AI acceleration, existing tools mainly target
feed-forward networks, and LSTM acceleration typically requires full custom
implementation. In this paper, we address this gap by leveraging the
open-source and extensible FINN framework to enable the generalized deployment
of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open
Neural Network Exchange (ONNX) specification to model the recurrent nature of
LSTM computations, enabling support for mixed quantisation within them and
functional verification of LSTM-based models. Furthermore, we introduce custom
transformations within the FINN compiler to map the quantised ONNX computation
graph to hardware blocks from the HLS kernel library of the FINN compiler and
Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM
model for a mid-price stock prediction task using the widely used dataset and
generating a corresponding hardware IP of the model using our flow, targeting
the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator
through our flow achieves a balance between performance (latency) and resource
consumption, while matching (or bettering) inference accuracy of
state-of-the-art models with reduced precision. We believe that the
generalisable nature of the proposed flow will pave the way for
resource-efficient RNN accelerator designs on FPGAs.

</details>


### [19] [Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management](https://arxiv.org/abs/2506.20853)
*Ziyang Lu,Subodh Kalia,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney*

Main category: cs.LG

TL;DR: 该论文研究了多功能认知雷达系统中的时间分配问题，通过深度强化学习和多目标优化方法（如DDPG和SAC）找到帕累托最优解，并比较了两种算法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决雷达系统中新目标扫描和已知目标跟踪之间的权衡问题，提高系统在动态环境中的效率和适应性。

Method: 采用深度强化学习（DDPG和SAC）和多目标优化算法（NSGA-II）来寻找帕累托最优解，并比较算法性能。

Result: SAC算法在稳定性和样本效率上优于DDPG，NSGA-II提供了帕累托前沿的上界估计，验证了方法的有效性。

Conclusion: 本研究为认知雷达系统在多目标动态环境中的时间分配问题提供了高效且自适应的解决方案。

Abstract: The time allocation problem in multi-function cognitive radar systems focuses
on the trade-off between scanning for newly emerging targets and tracking the
previously detected targets. We formulate this as a multi-objective
optimization problem and employ deep reinforcement learning to find
Pareto-optimal solutions and compare deep deterministic policy gradient (DDPG)
and soft actor-critic (SAC) algorithms. Our results demonstrate the
effectiveness of both algorithms in adapting to various scenarios, with SAC
showing improved stability and sample efficiency compared to DDPG. We further
employ the NSGA-II algorithm to estimate an upper bound on the Pareto front of
the considered problem. This work contributes to the development of more
efficient and adaptive cognitive radar systems capable of balancing multiple
competing objectives in dynamic environments.

</details>


### [20] [Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection](https://arxiv.org/abs/2506.21093)
*Li Fan,Peng Wang,Jing Yang,Cong Shen*

Main category: cs.LG

TL;DR: CHOOSE是一种通过增强浅层Transformer推理能力的框架，用于无线符号检测，无需增加模型深度即可媲美深层模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于ICL的Transformer模型依赖深层架构，导致存储和计算成本高，不适合资源受限的设备。

Method: 提出CHOOSE框架，在隐藏空间中引入自回归潜在推理步骤，提升浅层模型的推理能力。

Result: 实验表明CHOOSE性能优于传统浅层Transformer，媲美深层模型，且保持高效存储和计算。

Conclusion: CHOOSE为资源受限的无线接收器部署Transformer算法提供了可行方案。

Abstract: Transformers have shown potential in solving wireless communication problems,
particularly via in-context learning (ICL), where models adapt to new tasks
through prompts without requiring model updates. However, prior ICL-based
Transformer models rely on deep architectures with many layers to achieve
satisfactory performance, resulting in substantial storage and computational
costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a
CoT-enhanced shallow Transformer framework for wireless symbol detection. By
introducing autoregressive latent reasoning steps within the hidden space,
CHOOSE significantly improves the reasoning capacity of shallow models (1-2
layers) without increasing model depth. This design enables lightweight
Transformers to achieve detection performance comparable to much deeper models,
making them well-suited for deployment on resource-constrained mobile devices.
Experimental results demonstrate that our approach outperforms conventional
shallow Transformers and achieves performance comparable to that of deep
Transformers, while maintaining storage and computational efficiency. This
represents a promising direction for implementing Transformer-based algorithms
in wireless receivers with limited computational resources.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [21] [Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications](https://arxiv.org/abs/2506.21078)
*Tian Han,Shalanika Dayarathna,Rajitha Senanayake,Peter Smith,Aryan Kaushik,Alain Mourad,Richard A. Stirling-Gallacher,Jamie Evans*

Main category: cs.IT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Integrated sensing and communications (ISAC) is considered a key enabler to
support application scenarios such as the Internet-of-Things (IoT) in which
both communications and sensing play significant roles. Multi-carrier
waveforms, such as orthogonal frequency division multiplexing (OFDM), have been
considered as good candidates for ISAC due to their high communications data
rate and good time bandwidth property for sensing. Nevertheless, their high
peak-to-average-power-ratio (PAPR) values lead to either performance
degradation or an increase in system complexity. This can make OFDM unsuitable
for IoT applications with insufficient resources in terms of power, system
complexity, hardware size or cost. This article provides IoT-centric constant
modulus waveform designs that leverage the advantage of unit PAPR and thus are
more suitable in resource-limited scenarios. More specifically, several
single-carrier frequency and/or phase-modulated waveforms are considered. A
comprehensive discussion on their radar sensing and communications performance
is conducted based on performance metrics, including the radar ambiguity
function, the bandwidth property, the data rate, and the communications
receiver complexity.

</details>


### [22] [Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications](https://arxiv.org/abs/2506.21370)
*Jiuyu Liu,Yi Ma,Qihao Peng,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出了一种针对直连卫星通信的集群感知两阶段MIMO检测方法，利用用户地理集群的高相关性特性，显著提高了计算效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 卫星MIMO通信中，同一地理集群内用户的信道特性高度相关，导致传统迭代MIMO检测器的收敛速度受限，亟需一种高效方法解决这一问题。

Method: 采用两阶段策略：先用小矩阵逆运算消除集群内干扰，再利用预计算矩阵加速标准迭代MIMO检测器（如GS和SSOR）以消除集群间干扰。

Result: 在完美信道状态下实现了12倍以上的收敛速度提升；即使存在信道估计误差，仍保持9倍的加速效果。

Conclusion: 该方法显著提升了卫星MIMO通信的检测效率，适用于下一代通信系统。

Abstract: In this paper, a cluster-aware two-stage multiple-input multiple-output
(MIMO) detection method is proposed for direct-to-cell satellite
communications. The method achieves computational efficiency by exploiting a
distinctive property of satellite MIMO channels: users within the same
geographical cluster exhibit highly correlated channel characteristics due to
their physical proximity, which typically impedes convergence in conventional
iterative MIMO detectors. The proposed method implements a two-stage strategy
that first eliminates intra-cluster interference using computationally
efficient small matrix inversions, then utilizes these pre-computed matrices to
accelerate standard iterative MIMO detectors such as Gauss-Seidel (GS) and
symmetric successive over-relaxation (SSOR) for effective inter-cluster
interference cancellation. Computer simulations demonstrate that the proposed
method achieves more than 12 times faster convergence under perfect channel
state information. Even when accounting for channel estimation errors, the
method maintains 9 times faster convergence, demonstrating its robustness and
effectiveness for next-generation satellite MIMO communications.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [23] [Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing](https://arxiv.org/abs/2506.20782)
*Marc Bara*

Main category: cs.NE

TL;DR: 提出了第一个将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）相位解缠的理论框架，填补了现有方法的空白。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据量快速增长，需要高效节能的处理方法；SNNs的事件驱动计算模型有望大幅节省能耗。

Method: 开发了针对相位数据的脉冲编码方案，设计了适合相位解缠的SNN架构，并分析了计算复杂性和收敛性。

Result: SNNs在保持精度的同时，能耗可能比传统方法低30-100倍，为大规模InSAR处理提供了可持续的解决方案。

Conclusion: 该研究开启了神经形态计算与SAR干涉测量的新方向，为相位解缠提供了互补性方法。

Abstract: We present the first theoretical framework for applying spiking neural
networks (SNNs) to synthetic aperture radar (SAR) interferometric phase
unwrapping. Despite extensive research in both domains, our comprehensive
literature review confirms that SNNs have never been applied to phase
unwrapping, representing a significant gap in current methodologies. As Earth
observation data volumes continue to grow exponentially (with missions like
NISAR expected to generate 100PB in two years) energy-efficient processing
becomes critical for sustainable data center operations. SNNs, with their
event-driven computation model, offer potential energy savings of 30-100x
compared to conventional approaches while maintaining comparable accuracy. We
develop spike encoding schemes specifically designed for wrapped phase data,
propose SNN architectures that leverage the spatial propagation nature of phase
unwrapping, and provide theoretical analysis of computational complexity and
convergence properties. Our framework demonstrates how the temporal dynamics
inherent in SNNs can naturally model the spatial continuity constraints
fundamental to phase unwrapping. This work opens a new research direction at
the intersection of neuromorphic computing and SAR interferometry, offering a
complementary approach to existing algorithms that could enable more
sustainable large-scale InSAR processing.

</details>
