<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [math.OC](#math.OC) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Communication-Efficient Collaborative LLM Inference via Distributed Speculative Decoding](https://arxiv.org/abs/2509.04576)
*Ce Zheng,Tingting Yang*

Main category: eess.SP

TL;DR: 提出了一种名为Top-K稀疏对数传输（TK-SLT）的方案，通过仅传输前K个token的概率和索引，减少分布式推测解码中的通信开销，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 在AI-RAN中，现有的分布式推测解码方法需要传输完整的词汇概率分布，导致上行通信开销过大。为了解决这一问题，提出了TK-SLT方案。

Method: 通过仅传输前K个token的原始概率和对应的索引，替代完整的概率分布传输，从而显著减少带宽消耗。进一步推导了最大化推理吞吐量的最优草案长度，并理论分析了TK-SLT的可实现加速比。

Result: 实验结果表明，该方法在降低通信开销的同时，保持了推理性能。

Conclusion: TK-SLT方案有效解决了分布式推测解码中的通信开销问题，并在理论和实验上验证了其高效性和有效性。

Abstract: Speculative decoding is an emerging technique that accelerates large language
model (LLM) inference by allowing a smaller draft model to predict multiple
tokens in advance, which are then verified or corrected by a larger target
model. In AI-native radio access networks (AI-RAN), this paradigm is
well-suited for collaborative inference between resource-constrained end
devices and more capable edge servers or base stations (BSs). However, existing
distributed speculative decoding requires transmitting the full vocabulary
probability distribution from the draft model on the device to the target model
at the BS, which leads to prohibitive uplink communication overhead. To address
this issue, we propose a ``Top-K Sparse Logits Transmission (TK-SLT)`` scheme,
where the draft model transmits only the top-K token raw probabilities and the
corresponding token indices instead of the entire distribution. This approach
significantly reduces bandwidth consumption while maintaining inference
performance. We further derive an analytical expression for the optimal draft
length that maximizes inference throughput, and provide a theoretical analysis
of the achievable speedup ratio under TK-SLT. Experimental results validate
both the efficiency and effectiveness of the proposed method.

</details>


### [2] [Tangential Velocity Estimation Using Near-Field Automotive Radar Model](https://arxiv.org/abs/2509.04692)
*Michael Shifrin,Joseph Tabrikian,Igal Bilik*

Main category: eess.SP

TL;DR: 提出了基于近场雷达模型的方法，用于汽车雷达系统中切向速度的估计，解决了传统远场模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统汽车雷达无法估计目标的切向速度，而这一参数对动态环境的可靠感知至关重要。

Method: 引入近场雷达模型，分析可识别性，开发高效的最大似然算法，利用目标迁移效应估计切向速度。

Result: 仿真验证了理论可行性，算法在单目标和多目标场景下均表现优异。

Conclusion: 该方法提升了汽车雷达的精度和可靠性，增强了先进驾驶辅助系统和自动驾驶车辆的情境感知能力。

Abstract: This work investigates the problem of tangential velocity estimation in
automotive radar systems, addressing the limitations of conventionally
considered models. Conventional automotive radars are usually based on
far-field models and estimate the target's range, radial velocity, and
direction-of-arrival (DOA) but are not able to estimate the tangential
component of the target 2-D velocity, which is a critical parameter for
reliable perception of dynamic environments. To address this challenge, we
introduce the near-field radar model, which considers various migration
elements in range, radial velocity, and Doppler along time and space.
Conventionally, these migration effects result in smearing of the likelihood
function for estimating the target parameters. However, if the model is
correctly specified, these migration effects are informative for tangential
velocity estimation. We conduct an identifiability analysis for tangential
velocity estimation using the Cram\'er-Rao bound and ambiguity function. The
insights from this study motivate the use of a separated array configuration
and the development of a computationally efficient maximum likelihood based
algorithm designed to utilize target migrations for tangential velocity
estimation, while maintaining practical computational complexity. In addition
to tangential velocity estimation, the proposed algorithm mitigates likelihood
smearing in range, radial velocity, and Doppler. Simulations validate the
theoretical feasibility study, and evaluate the algorithms' performance in both
single- and multi-target scenarios. The proposed approach improves the accuracy
and reliability of automotive radars, enhancing situational awareness for
advanced driver assistance systems and autonomous vehicles.

</details>


### [3] [Environment-Aware IRS Deployment via Channel Knowledge Map: Joint Sensing-Communications Coverage Optimization](https://arxiv.org/abs/2509.04768)
*Yilong Chen,Zixiang Ren,Jie Xu,Rui Zhang*

Main category: eess.SP

TL;DR: 本文研究了智能反射面（IRS）在集成传感与通信（ISAC）系统中的部署优化问题，通过利用通道知识图（CKM）优化IRS部署、基站波束成形和IRS反射波束成形，以最小化系统成本并满足传感与通信需求。


<details>
  <summary>Details</summary>
Motivation: 在IRS支持的ISAC系统中，通过优化IRS部署来增强基站的双重覆盖（传感与通信）是当前研究的重点。

Method: 基于CKM获取通道状态信息，提出混合整数非凸优化问题，并采用基于SCA的松弛-边界方法求解。

Result: 数值结果表明所提算法能有效降低系统成本，同时满足传感与通信的最小功率和信噪比要求。

Conclusion: 提出的IRS部署和波束成形联合优化方法在实时和准静态情况下均能显著提升系统性能。

Abstract: This paper studies the intelligent reflecting surface (IRS) deployment
optimization problem for IRS-enabled integrated sensing and communications
(ISAC) systems, in which multiple IRSs are strategically deployed at candidate
locations to assist a base station (BS) to enhance the coverage of both sensing
and communications. We present an environment-aware IRS deployment design via
exploiting the channel knowledge map (CKM), which provides the channel state
information (CSI) between each candidate IRS location and BS or targeted
sensing/communication points. Based on the obtained CSI from CKM, we optimize
the deployment of IRSs, jointly with the BS's transmit beamforming and IRSs'
reflective beamforming during operation, with the objective of minimizing the
system cost, while guaranteeing the minimum illumination power requirements at
sensing areas and the minimum signal-to-noise ratio (SNR) requirements at
communication areas. In particular, we consider two cases when the IRSs'
reflective beamforming optimization can be implemented dynamically in real time
and quasi-stationarily over the whole operation period, respectively. For both
cases, the joint IRS deployment and transmit/reflective beamforming designs are
formulated as mixed-integer non-convex optimization problems, which are solved
via the successive convex approximation (SCA)-based relax-and-bound method.
Specifically, we first relax the binary IRS deployment indicators into
continuous variables, then find converged solutions via SCA, and finally round
relaxed indicators back to binary values. Numerical results demonstrate the
effectiveness of our proposed algorithms in reducing the system cost while
meeting the sensing and communication requirements.

</details>


### [4] [SREC: Encrypted Semantic Super-Resolution Enhanced Communication](https://arxiv.org/abs/2509.04787)
*Zhidi Zhang,Rui Meng,Song Gao,Haixiao Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: 论文提出了一种加密的语义超分辨率增强通信（SREC）方法，以解决语义通信中的安全问题，通过模256加密和超分辨率重建技术提升通信安全性和图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 随着语义通信（SemCom）的广泛应用，其安全问题日益突出，例如通过物理信道明传输的语义特征容易被窃听者拦截，因此需要一种新的安全通信方法。

Method: 提出的SREC方法结合了模256加密技术和超分辨率重建技术，通过加密语义特征和提升图像重建质量来增强通信安全性。

Result: 在加性高斯白噪声（AWGN）信道中，SREC在不同调制方法下不仅能稳定保证安全性，还能在低信噪比（SNR）条件下实现更好的传输性能。

Conclusion: SREC是一种有效的安全语义通信解决方案，能够在保证安全的同时提升通信性能。

Abstract: Semantic communication (SemCom), as a typical paradigm of deep integration
between artificial intelligence (AI) and communication technology,
significantly improves communication efficiency and resource utilization
efficiency. However, the security issues of SemCom are becoming increasingly
prominent. Semantic features transmitted in plaintext over physical channels
are easily intercepted by eavesdroppers. To address this issue, this paper
proposes Encrypted Semantic Super-Resolution Enhanced Communication (SREC) to
secure SemCom. SREC uses the modulo-256 encryption method to encrypt semantic
features, and employs super-resolution reconstruction method to improve the
reconstruction quality of images. The simulation results show that in the
additive Gaussian white noise (AWGN) channel, when different modulation methods
are used, SREC can not only stably guarantee security, but also achieve better
transmission performance under low signal-to-noise ratio (SNR) conditions.

</details>


### [5] [KGRAG-SC: Knowledge Graph RAG-Assisted Semantic Communication](https://arxiv.org/abs/2509.04801)
*Dayu Fan,Rui Meng,Song Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: KGRAG-SC是一种知识图谱辅助的语义通信框架，通过检索增强生成技术解决了现有端到端深度学习框架在噪声环境下的语义提取和重建问题。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方案依赖端到端深度学习，缺乏可解释性且在噪声环境下表现不佳。

Method: 利用多维知识图谱实现语义提取，采用社区引导的实体链接和GraphRAG辅助处理，传输最小连接子图和紧凑实体索引，并结合重要性感知的自适应传输策略。

Result: 在低信噪比条件下表现优异，传输开销显著降低。

Conclusion: 结合知识图谱和生成语言模型可有效提升语义通信系统的性能。

Abstract: The state-of-the-art semantic communication (SC) schemes typically rely on
end-to-end deep learning frameworks that lack interpretability and struggle
with robust semantic selection and reconstruction under noisy conditions. To
address this issue, this paper presents KGRAG-SC, a knowledge graph-assisted SC
framework that leverages retrieval-augmented generation principles. KGRAG-SC
employs a multi-dimensional knowledge graph, enabling efficient semantic
extraction through community-guided entity linking and GraphRAG-assisted
processing. The transmitter constructs minimal connected subgraphs that capture
essential semantic relationships and transmits only compact entity indices
rather than full text or semantic triples. An importance-aware adaptive
transmission strategy provides unequal error protection based on structural
centrality metrics, prioritizing critical semantic elements under adverse
channel conditions. At the receiver, large language models perform
knowledge-driven text reconstruction using the shared knowledge graph as
structured context, ensuring robust semantic recovery even with partial
information loss. Experimental results demonstrate that KGRAG-SC achieves
superior semantic fidelity in low Signal-to-Noise Ratio (SNR) conditions while
significantly reducing transmission overhead compared to traditional
communication methods, highlighting the effectiveness of integrating structured
knowledge representation with generative language models for SC systems.

</details>


### [6] [SemSteDiff: Generative Diffusion Model-based Coverless Semantic Steganography Communication](https://arxiv.org/abs/2509.04803)
*Song Gao,Rui Meng,Xiaodong Xu,Haixiao Gao,Yiming Liu,Chenyuan Feng,Ping Zhang,Tony Q. S. Quek,Dusit Niyato*

Main category: eess.SP

TL;DR: 论文提出了一种基于生成扩散模型的SemSteDiff方案，用于解决现有语义隐写通信对预选封面图像的依赖问题，提高了通用性。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽高效但易受窃听威胁，现有语义隐写通信方案依赖预选图像，限制了通用性。

Method: 提出SemSteDiff方案，通过生成扩散模型将秘密图像嵌入生成的隐写图像中，利用语义相关的公私钥对确保合法接收者正确解码。

Result: 实验表明，SNR为0 dB时，合法接收者的PSNR比窃听者高4.14 dB。

Conclusion: SemSteDiff方案有效解决了现有方法的局限性，在多种JSCC框架中表现良好。

Abstract: Semantic communication (SemCom), as a novel paradigm for future communication
systems, has recently attracted much attention due to its superiority in
communication efficiency. However, similar to traditional communication, it
also suffers from eavesdropping threats. Intelligent eavesdroppers could launch
advanced semantic analysis techniques to infer secret semantic information.
Therefore, some researchers have designed Semantic Steganography Communication
(SemSteCom) scheme to confuse semantic eavesdroppers. However, the
state-of-the-art SemSteCom schemes for image transmission rely on the
pre-selected cover image, which limits the universality. To address this issue,
we propose a Generative Diffusion Model-based Coverless Semantic Steganography
Communication (SemSteDiff) scheme to hide secret images into generated stego
images. The semantic related private and public keys enable legitimate receiver
to decode secret images correctly while the eavesdropper without completely
true key-pairs fail to obtain them. Simulation results demonstrate the
effectiveness of the plug-and-play design in different Joint Source-Channel
Coding (JSCC) frameworks. The comparison results under different eavesdroppers'
threats show that, when Signal-to-Noise Ratio (SNR) = 0 dB, the peak
signal-to-noise ratio (PSNR) of the legitimate receiver is 4.14 dB higher than
that of the eavesdropper.

</details>


### [7] [AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design](https://arxiv.org/abs/2509.04805)
*Keqin Zhang*

Main category: eess.SP

TL;DR: 概述了AI驱动的压缩技术在现代无线前端链路中的应用，重点分析了两种高压缩率方法，并提出了一种适用于无蜂窝架构的压缩策略。


<details>
  <summary>Details</summary>
Motivation: 现代无线系统中的前端链路需要在高带宽和低延迟约束下传输高维信号，传统压缩方法效果有限，因此需要更高效的AI驱动解决方案。

Method: 论文首先综述了AI驱动的压缩技术，然后分析了两种代表性的高压缩率方法：端到端学习的CSI反馈和RB粒度预编码优化结合压缩，并提出了一种适用于无蜂窝架构的压缩策略。

Result: 提出的压缩策略能够实现高压缩率且性能损失可控，支持RB级速率适应，并适合下一代网络的集中式协作传输。

Conclusion: AI驱动的压缩技术为无线前端链路提供了高效的解决方案，特别是在高压缩率和低延迟需求场景下。

Abstract: Modern fronthaul links in wireless systems must transport high-dimensional
signals under stringent bandwidth and latency constraints, which makes
compression indispensable. Traditional strategies such as compressed sensing,
scalar quantization, and fixed-codec pipelines often rely on restrictive
priors, degrade sharply at high compression ratios, and are hard to tune across
channels and deployments. Recent progress in Artificial Intelligence (AI) has
brought end-to-end learned transforms, vector and hierarchical quantization,
and learned entropy models that better exploit the structure of Channel State
Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first
surveys AI-driven compression techniques and then provides a focused analysis
of two representative high-compression routes: CSI feedback with end-to-end
learning and Resource Block (RB) granularity precoding optimization combined
with compression. Building on these insights, we propose a fronthaul
compression strategy tailored to cell-free architectures. The design targets
high compression with controlled performance loss, supports RB-level rate
adaptation, and enables low-latency inference suitable for centralized
cooperative transmission in next-generation networks.

</details>


### [8] [Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering with Application to Brain Imaging](https://arxiv.org/abs/2509.04860)
*Rui Guo,Yi Zhang,Yhonatan Kvich,Tianyao Huang,Maokun Li,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 该论文提出了一种基于潜在扩散的后验采样方法，用于定量电磁脑成像，结合先验知识和物理模型，无需配对数据，实现高精度重建。


<details>
  <summary>Details</summary>
Motivation: 电磁成像在非侵入式传感中有广泛应用，但现有方法难以平衡可解释性、失真误差和可靠性，作者旨在解决这一问题。

Method: 通过训练潜在扩散模型学习目标先验分布，并利用交替采样器结合似然和先验分布，最终通过最小均方误差估计获得可靠重建。

Result: 实验证明，该方法在重建精度和结构相似性上达到最先进水平，同时保持高测量保真度。

Conclusion: 该方法为电磁脑成像提供了一种灵活且可靠的重建方案，结合了先验知识与物理模型。

Abstract: Electromagnetic (EM) imaging is an important tool for non-invasive sensing
with low-cost and portable devices. One emerging application is EM stroke
imaging, which enables early diagnosis and continuous monitoring of brain
strokes. Quantitative imaging is achieved by solving an inverse scattering
problem (ISP) that reconstructs permittivity and conductivity maps from
measurements. In general, the reconstruction accuracy is limited by its
inherent nonlinearity and ill-posedness. Existing methods, including
learning-free and learning-based approaches, fail to either incorporate
complicated prior distributions or provide theoretical guarantees, posing
difficulties in balancing interpretability, distortion error, and reliability.
To overcome these limitations, we propose a posterior sampling method based on
latent diffusion for quantitative EM brain imaging, adapted from a generative
plug-and-play (PnP) posterior sampling framework. Our approach allows to
flexibly integrate prior knowledge into physics-based inversion without
requiring paired measurement-label datasets. We first learn the prior
distribution of targets from an unlabeled dataset, and then incorporate the
learned prior into posterior sampling. In particular, we train a latent
diffusion model on permittivity and conductivity maps to capture their prior
distribution. Then, given measurements and the forward model describing EM wave
physics, we perform posterior sampling by alternating between two samplers that
respectively enforce the likelihood and prior distributions. Finally, reliable
reconstruction is obtained through minimum mean squared error (MMSE) estimation
based on the samples. Experimental results on brain imaging demonstrate that
our approach achieves state-of-the-art performance in reconstruction accuracy
and structural similarity while maintaining high measurement fidelity.

</details>


### [9] [Rotatable Antenna Aided Mixed Near-Field and Far-Field Communications in the Upper Mid-Band: Interference Analysis and Joint Optimization](https://arxiv.org/abs/2509.04865)
*Yunpu Zhang,Changsheng You,Hing Cheung So,Dusit Niyato*

Main category: eess.SP

TL;DR: 该论文提出了利用可旋转天线（RAs）提升混合近场和远场通信系统性能的方法，通过天线旋转提供的自由度抑制干扰，并设计了高效的优化算法。


<details>
  <summary>Details</summary>
Motivation: 混合近场和远场通信系统中存在复杂的干扰问题，传统固定天线难以有效解决。本文旨在通过可旋转天线提供的新自由度来改善通信性能。

Method: 研究了基于模块化RA的混合场下行通信系统，联合优化功率分配和旋转角度。分析了特殊和一般情况，并提出双层优化算法（SCA和PSO）。

Result: 理论分析表明天线旋转可有效抑制干扰。数值结果验证了RA相比传统系统的显著性能提升。

Conclusion: 可旋转天线显著提升了混合场通信性能，所提出的联合设计优于基准方案。

Abstract: In this paper, we propose to leverage rotatable antennas (RAs) for improving
the communication performance in mixed near-field and far-field communication
systems by exploiting a new spatial degree-of-freedom (DoF) offered by antenna
rotation to mitigate complex near-field interference and mixed-field
interference. Specifically, we investigate a modular RA-enabled mixed-field
downlink communication system, where a base station (BS) consisting of multiple
RA subarrays communicates with multiple near-field users in the presence of
several legacy far-field users. We formulate an optimization problem to
maximize the sum-rate of the near-field users by jointly optimizing the power
allocation and rotation angles of all subarrays at the BS. To gain useful
insights into the effect of RAs on mixed-field communications, we first analyze
a special case where all subarrays share the same rotation angle and obtain
closed-form expressions for the rotation-aware normalized near-field
interference and the rotation-aware normalized mixed-field interference using
the Fresnel integrals. We then analytically reveal that array rotation
effectively suppresses both interference types, thereby significantly enhancing
mixed-field communication performance. For the general case involving
subarray-wise rotation, we propose an efficient double-layer algorithm to
obtain a high-quality solution, where the inner layer optimizes power
allocation using the successive convex approximation (SCA) technique, while the
outer layer determines the rotation angles of all subarrays via particle swarm
optimization (PSO). Finally, numerical results highlight the significant
performance gains achieved by RAs over conventional fixed-antenna systems and
demonstrate the effectiveness of our developed joint design compared to
benchmark schemes.

</details>


### [10] [Movable IRS-Aided ISAC Systems: Joint Beamforming and Position Optimization](https://arxiv.org/abs/2509.04873)
*Yue Geng,Tee Hiang Cheng,Kai Zhong,Kah Chan Teh,Qingqing Wu*

Main category: eess.SP

TL;DR: 论文提出了一种基于可移动智能反射表面（MIRS）的集成感知与通信系统优化方法，通过联合优化反射元件位置和反射系数等，实现了功率最小化目标。


<details>
  <summary>Details</summary>
Motivation: 传统智能反射表面（IRS）性能受限，MIRS通过可移动反射元件提高系统适应性和性能。

Method: 提出两种MIRS控制方案（元件级和阵列级）及PRMO优化方法，利用RBFGS算法并行更新变量。

Result: 仿真显示MIRS在功率最小化上优于传统IRS，元件级控制方案效果最佳，阵列级方案计算效率更高。

Conclusion: MIRS显著提升ISAC系统性能，尤其在功率效率方面具有优势。

Abstract: Driven by intelligent reflecting surface (IRS) and movable antenna (MA)
technologies, movable IRS (MIRS) has been proposed to improve the adaptability
and performance of conventional IRS, enabling flexible adjustment of the IRS
reflecting element positions. This paper investigates MIRS-aided integrated
sensing and communication (ISAC) systems. The objective is to minimize the
power required for satisfying the quality-of-service (QoS) of sensing and
communication by jointly optimizing the MIRS element positions, IRS reflection
coefficients, transmit beamforming, and receive filters. To balance the
performance-cost trade-off, we proposed two MIRS schemes: element-wise control
and array-wise control, where the positions of individual reflecting elements
and arrays consisting of multiple elements are controllable, respectively. To
address the joint beamforming and position optimization, a product Riemannian
manifold optimization (PRMO) method is proposed, where the variables are
updated over a constructed product Riemannian manifold space (PRMS) in parallel
via penalty-based transformation and Riemannian
Broyden-Fletcher-Goldfarb-Shanno (RBFGS) algorithm. Simulation results
demonstrate that the proposed MIRS outperforms conventional IRS in power
minimization with both element-wise control and array-wise control.
Specifically, with different system parameters, the minimum power is achieved
by the MIRS with the element-wise control scheme, while suboptimal solution and
higher computational efficiency are achieved by the MIRS with array-wise
control scheme.

</details>


### [11] [Coupled tensor models for probability mass function estimation: Part I, Principles and algorithms](https://arxiv.org/abs/2509.04930)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 提出了一种称为PCTF3D的方法，通过部分耦合三维边际来估计概率质量函数，解决了维度诅咒问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在高维情况下难以处理概率质量函数的估计问题，PCTF3D旨在通过部分耦合和超图选择合适的边际来解决这一问题。

Method: PCTF3D方法通过部分耦合三维数据投影（视为三阶张量），并使用超图选择边际，从而实现张量分解。

Result: 提供了数值实验和应用示例，展示了该方法的有效性。

Conclusion: PCTF3D为概率质量函数估计提供了新框架，第二部分将研究其唯一性特性。

Abstract: In this article, a Probability Mass Function (PMF) estimation method which
tames the curse of dimensionality is proposed. This method, called Partial
Coupled Tensor Factorization of 3D marginals or PCTF3D, has for principle to
partially couple order-3 data projections -- seen as order-3 tensors -- to
obtain a tensor decomposition of the probability mass tensor. The novelty of
PCTF3D relies on partial coupling which consists in choosing a subset of 3D
marginals. The choice of marginals is then formulated with hypergraphs. After
presenting possible coupling strategies, some numerical experiments and an
application of the method are proposed. This article is the first of a two-part
article. While this first article focuses on a new algorithmic framework for
PMF estimation, the second studies uniqueness properties of the model
introduced in this article.

</details>


### [12] [Coupled tensor models for probability mass function estimation: Part II, Uniqueness of the model](https://arxiv.org/abs/2509.04931)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 研究了PCTF3D方法中耦合张量模型的唯一性，表明其依赖于耦合策略，并通过Jacobian算法提出了最大可恢复秩。


<details>
  <summary>Details</summary>
Motivation: 探究PCTF3D方法中张量耦合模型的唯一性，以指导实际应用中的策略选择。

Method: 提出Jacobian算法分析最大可恢复秩，并评估不同耦合策略的唯一性。

Result: 唯一性高度依赖耦合策略，提出Cartesian耦合的识别性界限。

Conclusion: PCTF3D方法的唯一性分析为张量耦合模型的优化提供了理论支持。

Abstract: In this paper, uniqueness properties of a coupled tensor model are studied.
This new coupled tensor model is used in a new method called Partial Coupled
Tensor Factorization of 3D marginals or PCTF3D. This method performs estimation
of probability mass functions by coupling 3D marginals, seen as order-3
tensors. The core novelty of PCTF3D's approach (detailed in the part I article)
relies on the partial coupling which consists on the choice of 3D marginals to
be coupled. Tensor methods are ubiquitous in many applications of statistical
learning, with their biggest advantage of having strong uniqueness properties.
In this paper, the uniqueness properties of PCTF3D's constrained coupled
low-rank model is assessed. While probabilistic constraints of the coupled
model are handled properly, it is shown that uniqueness highly depends on the
coupling used in PCTF3D. After proposing a Jacobian algorithm providing maximum
recoverable rank, different coupling strategies presented in the Part I article
are examined with respect to their uniqueness properties. Finally, an
identifiability bound is given for a so-called Cartesian coupling which permits
enhancing sufficient bounds of the literature.

</details>


### [13] [ROPE: A Novel Method for Real-Time Phase Estimation of Complex Biological Rhythms](https://arxiv.org/abs/2509.04962)
*Antonio Spallone,Marco Coraggio,Francesco De Lellis,Mario di Bernardo*

Main category: eess.SP

TL;DR: ROPE是一种新型相位估计算法，能处理任意维度的信号并实时运行，在各种信号类型中表现出卓越性能，适用于生物节律分析等领域。


<details>
  <summary>Details</summary>
Motivation: 相位估计在神经科学、机器人学等领域至关重要，但现有方法局限于离线处理和一维信号，需要更先进的算法。

Method: ROPE通过识别信号中的重复部分并将其分段，通过高效搜索先前信号段来分配相位值。

Result: ROPE在噪声和信号漂移下表现稳健，性能显著优于现有方法。

Conclusion: ROPE为复杂生物节律的实时分析提供了新途径，有助于早期病理诊断和节律治疗。

Abstract: Accurate phase estimation -- the process of assigning phase values between
$0$ and $2\pi$ to repetitive or periodic signals -- is a cornerstone in the
analysis of oscillatory signals across diverse fields, from neuroscience to
robotics, where it is fundamental, e.g., to understanding coordination in
neural networks, cardiorespiratory coupling, and human-robot interaction.
However, existing methods are often limited to offline processing and/or
constrained to one-dimensional signals. In this paper, we introduce ROPE,
which, to the best of our knowledge, is the first phase-estimation algorithm
capable of (i) handling signals of arbitrary dimension and (ii) operating in
real-time, with minimal error. ROPE identifies repetitions within the signal to
segment it into (pseudo-)periods and assigns phase values by performing
efficient, tractable searches over previous signal segments. We extensively
validate the algorithm on a variety of signal types, including trajectories
from chaotic dynamical systems, human motion-capture data, and
electrocardiographic recordings. Our results demonstrate that ROPE is robust
against noise and signal drift, and achieves significantly superior performance
compared to state-of-the-art phase estimation methods. This advancement enables
real-time analysis of complex biological rhythms, opening new pathways, for
example, for early diagnosis of pathological rhythm disruptions and developing
rhythm-based therapeutic interventions in neurological and cardiovascular
disorders.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [In-Context Policy Adaptation via Cross-Domain Skill Diffusion](https://arxiv.org/abs/2509.04535)
*Minjong Yoo,Woo Kyung Kim,Honguk Woo*

Main category: cs.RO

TL;DR: 提出了一种基于扩散技能的上下文策略适应框架（ICPAD），适用于多任务长时程环境，支持在有限目标域数据和无模型更新的条件下快速适应。


<details>
  <summary>Details</summary>
Motivation: 研究在跨域设置中，如何利用扩散技能学习技术实现强化学习策略的快速适应，尤其是在模型不可更新和目标域数据有限的严格约束下。

Method: 采用跨域技能扩散方案，学习域无关的原型技能和域基础的技能适配器，并通过动态域提示方案优化适配性能。

Result: 在Metaworld的机器人操作和CARLA的自动驾驶实验中，ICPAD在多种跨域配置下表现出优越的策略适应性能。

Conclusion: ICPAD框架为长时程多任务环境下的策略适应提供了一种高效解决方案，尤其在资源受限的情况下表现突出。

Abstract: In this work, we present an in-context policy adaptation (ICPAD) framework
designed for long-horizon multi-task environments, exploring diffusion-based
skill learning techniques in cross-domain settings. The framework enables rapid
adaptation of skill-based reinforcement learning policies to diverse target
domains, especially under stringent constraints on no model updates and only
limited target domain data. Specifically, the framework employs a cross-domain
skill diffusion scheme, where domain-agnostic prototype skills and a
domain-grounded skill adapter are learned jointly and effectively from an
offline dataset through cross-domain consistent diffusion processes. The
prototype skills act as primitives for common behavior representations of
long-horizon policies, serving as a lingua franca to bridge different domains.
Furthermore, to enhance the in-context adaptation performance, we develop a
dynamic domain prompting scheme that guides the diffusion-based skill adapter
toward better alignment with the target domain. Through experiments with
robotic manipulation in Metaworld and autonomous driving in CARLA, we show that
our $\oursol$ framework achieves superior policy adaptation performance under
limited target domain data conditions for various cross-domain configurations
including differences in environment dynamics, agent embodiment, and task
horizon.

</details>


### [15] [Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control](https://arxiv.org/abs/2509.04628)
*Alejandro Posadas-Nava,Andrea Scorsoglio,Luca Ghilardi,Roberto Furfaro,Richard Linares*

Main category: cs.RO

TL;DR: 本文提出了一种基于模仿学习的航天器导航控制方法，通过仅需100次专家演示（相当于6300次环境交互），实现了高性能控制策略。


<details>
  <summary>Details</summary>
Motivation: 传统的元强化学习方法需要大量数据，而本文旨在通过模仿学习从有限数据中实现高性能的航天器导航控制。

Method: 采用Action Chunking with Transformers (ACT)方法，通过视觉和状态观测映射推力与扭矩指令。

Result: ACT在ISS对接任务中表现优于元强化学习基线，轨迹更平滑、更准确且数据效率更高。

Conclusion: ACT方法在航天器导航控制任务中具有显著优势，适用于数据有限的高性能控制场景。

Abstract: We present an imitation learning approach for spacecraft guidance,
navigation, and control(GNC) that achieves high performance from limited data.
Using only 100 expert demonstrations, equivalent to 6,300 environment
interactions, our method, which implements Action Chunking with Transformers
(ACT), learns a control policy that maps visual and state observations to
thrust and torque commands. ACT generates smoother, more consistent
trajectories than a meta-reinforcement learning (meta-RL) baseline trained with
40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking
with the International Space Station (ISS). We show that our approach achieves
greater accuracy, smoother control, and greater sample efficiency.

</details>


### [16] [Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement](https://arxiv.org/abs/2509.04645)
*Kallol Saha,Amber Li,Angela Rodriguez-Izquierdo,Lifan Yu,Ben Eisner,Maxim Likhachev,David Held*

Main category: cs.RO

TL;DR: SPOT提出了一种结合学习和规划的混合方法，通过搜索点云变换序列来规划机器人操作任务，避免了传统方法对连续空间的离散化需求。


<details>
  <summary>Details</summary>
Motivation: 研究中发现传统任务规划方法需要对连续状态和动作空间进行符号化描述，限制了其在高维连续空间中的应用。

Method: SPOT利用学习模型作为领域先验，指导在高维连续动作空间中进行搜索，通过操作部分观测的点云生成候选动作。

Result: 在仿真和真实环境中进行多物体重排任务测试，SPOT生成的计划成功率高，且优于策略学习方法。

Conclusion: 实验表明，基于搜索的规划方法对提高任务成功率和性能至关重要。

Abstract: Long-horizon planning for robot manipulation is a challenging problem that
requires reasoning about the effects of a sequence of actions on a physical 3D
scene. While traditional task planning methods are shown to be effective for
long-horizon manipulation, they require discretizing the continuous state and
action space into symbolic descriptions of objects, object relationships, and
actions. Instead, we propose a hybrid learning-and-planning approach that
leverages learned models as domain-specific priors to guide search in
high-dimensional continuous action spaces. We introduce SPOT: Search over Point
cloud Object Transformations, which plans by searching for a sequence of
transformations from an initial scene point cloud to a goal-satisfying point
cloud. SPOT samples candidate actions from learned suggesters that operate on
partially observed point clouds, eliminating the need to discretize actions or
object relationships. We evaluate SPOT on multi-object rearrangement tasks,
reporting task planning success and task execution success in both simulation
and real-world environments. Our experiments show that SPOT generates
successful plans and outperforms a policy-learning approach. We also perform
ablations that highlight the importance of search-based planning.

</details>


### [17] [Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision](https://arxiv.org/abs/2509.04658)
*Manish Kansana,Sindhuja Penchala,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.RO

TL;DR: Surformer v2是一个改进的多模态分类架构，通过决策级融合机制整合视觉和触觉感官流，提升了机器人触觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 提升机器人操作和交互中的触觉感知能力。

Method: 采用CNN和Transformer分别处理视觉和触觉数据，通过决策级融合结合输出logits。

Result: 在Touch and Go数据集上表现良好，适合实时机器人应用。

Conclusion: 决策级融合和基于Transformer的触觉建模有效增强了多模态机器人感知的表面理解能力。

Abstract: Multimodal surface material classification plays a critical role in advancing
tactile perception for robotic manipulation and interaction. In this paper, we
present Surformer v2, an enhanced multi-modal classification architecture
designed to integrate visual and tactile sensory streams through a
late(decision level) fusion mechanism. Building on our earlier Surformer v1
framework [1], which employed handcrafted feature extraction followed by
mid-level fusion architecture with multi-head cross-attention layers, Surformer
v2 integrates the feature extraction process within the model itself and shifts
to late fusion. The vision branch leverages a CNN-based classifier(Efficient
V-Net), while the tactile branch employs an encoder-only transformer model,
allowing each modality to extract modality-specific features optimized for
classification. Rather than merging feature maps, the model performs
decision-level fusion by combining the output logits using a learnable weighted
sum, enabling adaptive emphasis on each modality depending on data context and
training dynamics. We evaluate Surformer v2 on the Touch and Go dataset [2], a
multi-modal benchmark comprising surface images and corresponding tactile
sensor readings. Our results demonstrate that Surformer v2 performs well,
maintaining competitive inference speed, suitable for real-time robotic
applications. These findings underscore the effectiveness of decision-level
fusion and transformer-based tactile modeling for enhancing surface
understanding in multi-modal robotic perception.

</details>


### [18] [Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving](https://arxiv.org/abs/2509.04712)
*Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 使用强化学习的自动驾驶控制因能通过环境交互学习驾驶策略而受关注，但面临样本效率和探索有效性的挑战。为解决这些问题，作者提出了结合基于规则的车道变换控制器与SAC算法的方法。


<details>
  <summary>Details</summary>
Motivation: 解决RL在自动驾驶中样本效率低和探索难的问题，通过非专家级演示策略引导RL智能体。

Method: 集成基于规则的车道变换控制器与Soft Actor Critic（SAC）算法，提升探索和学习效率。

Result: 驾驶性能得到改善，该方法可扩展至其他适用演示引导的驾驶场景。

Conclusion: 通过非专家级演示策略结合SAC算法，有效提升了RL在自动驾驶中的性能与泛化能力。

Abstract: Automated vehicle control using reinforcement learning (RL) has attracted
significant attention due to its potential to learn driving policies through
environment interaction. However, RL agents often face training challenges in
sample efficiency and effective exploration, making it difficult to discover an
optimal driving strategy. To address these issues, we propose guiding the RL
driving agent with a demonstration policy that need not be a highly optimized
or expert-level controller. Specifically, we integrate a rule-based lane change
controller with the Soft Actor Critic (SAC) algorithm to enhance exploration
and learning efficiency. Our approach demonstrates improved driving performance
and can be extended to other driving scenarios that can similarly benefit from
demonstration-based guidance.

</details>


### [19] [Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots](https://arxiv.org/abs/2509.04722)
*Adrian B. Ghansah,Sergio A. Esteban,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种基于降阶模型的计算高效分层控制框架，用于人形机器人步态控制，结合臂和躯干动力学增强稳定性。


<details>
  <summary>Details</summary>
Motivation: 为确保人形机器人在多样化环境中实现鲁棒运动，需设计高效且适应性强的控制框架。

Method: 采用分层控制：高层使用ALIP模型通过非线性MPC优化步幅参数；中层基于线性MPC结合简化臂和躯干动力学。

Result: 实验显示，自适应步幅时间提升抗推成功率36%，上身控制改善偏航扰动抑制，且在多类地形中验证了鲁棒性。

Conclusion: 所提出的分层框架有效提升了人形机器人在复杂环境下的运动稳定性和适应性。

Abstract: As humanoid robots enter real-world environments, ensuring robust locomotion
across diverse environments is crucial. This paper presents a computationally
efficient hierarchical control framework for humanoid robot locomotion based on
reduced-order models -- enabling versatile step planning and incorporating arm
and torso dynamics to better stabilize the walking. At the high level, we use
the step-to-step dynamics of the ALIP model to simultaneously optimize over
step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP
trajectories are used as references to a linear MPC framework that extends the
standard SRB-MPC to also include simplified arm and torso dynamics. We validate
the performance of our approach through simulation and hardware experiments on
the Unitree G1 humanoid robot. In the proposed framework the high-level step
planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard
mini-PC. Adaptive step timing increased the push recovery success rate by 36%,
and the upper body control improved the yaw disturbance rejection. We also
demonstrate robust locomotion across diverse indoor and outdoor terrains,
including grass, stone pavement, and uneven gym mats.

</details>


### [20] [Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics](https://arxiv.org/abs/2509.04737)
*Ryoga Oishi,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 该论文提出了一种运动生成模型，通过语言指令调整机器人动作，解决了传统批处理方法无法在线调整的局限性。


<details>
  <summary>Details</summary>
Motivation: 在机器人学习中，通过语言指令协调机器人动作越来越可行，但适应人类指令仍具挑战性，因为这些指令通常是定性的，需要探索满足不同条件的行为。

Method: 方法通过将演示分割成短序列并分配弱监督标签，学习从修饰指令到动作的映射。

Result: 在擦拭和抓取放置任务中评估，结果显示该方法能在线响应修饰指令调整动作，优于传统批处理方法。

Conclusion: 提出的模型能够在线适应人类指令，为机器人动作生成提供了一种灵活高效的方法。

Abstract: In the field of robot learning, coordinating robot actions through language
instructions is becoming increasingly feasible. However, adapting actions to
human instructions remains challenging, as such instructions are often
qualitative and require exploring behaviors that satisfy varying conditions.
This paper proposes a motion generation model that adapts robot actions in
response to modifier directives human instructions imposing behavioral
conditions during task execution. The proposed method learns a mapping from
modifier directives to actions by segmenting demonstrations into short
sequences, assigning weakly supervised labels corresponding to specific
modifier types. We evaluated our method in wiping and pick and place tasks.
Results show that it can adjust motions online in response to modifier
directives, unlike conventional batch-based methods that cannot adapt during
execution.

</details>


### [21] [COMMET: A System for Human-Induced Conflicts in Mobile Manipulation of Everyday Tasks](https://arxiv.org/abs/2509.04836)
*Dongping Li,Shaoting Peng,John Pohovey,Katherine Rose Driggs-Campbell*

Main category: cs.RO

TL;DR: COMMET系统通过混合检测方法解决了日常任务中机器人移动操作的人类引发冲突，结合多模态检索和精细模型推断，并利用GPT-4总结用户偏好。初步研究表明其检测模块优于GPT模型。


<details>
  <summary>Details</summary>
Motivation: 动态且不可预测的人类活动会与机器人行为产生冲突，且这类冲突的解决方案依赖用户偏好，因此需要开发适应性强且个性化的机器人系统。

Method: 采用混合检测方法（多模态检索和精细模型推断），并利用GPT-4总结用户偏好，设计了用户友好的数据收集界面。

Result: 检测模块在准确性和延迟上优于GPT模型，并展示了实际部署的有效工作流程。

Conclusion: COMMET为解决人类引发冲突提供了有效方案，支持未来家用机器人的开发。

Abstract: Continuous advancements in robotics and AI are driving the integration of
robots from industry into everyday environments. However, dynamic and
unpredictable human activities in daily lives would directly or indirectly
conflict with robot actions. Besides, due to the social attributes of such
human-induced conflicts, solutions are not always unique and depend highly on
the user's personal preferences. To address these challenges and facilitate the
development of household robots, we propose COMMET, a system for human-induced
COnflicts in Mobile Manipulation of Everyday Tasks. COMMET employs a hybrid
detection approach, which begins with multi-modal retrieval and escalates to
fine-tuned model inference for low-confidence cases. Based on collected user
preferred options and settings, GPT-4o will be used to summarize user
preferences from relevant cases. In preliminary studies, our detection module
shows better accuracy and latency compared with GPT models. To facilitate
future research, we also design a user-friendly interface for user data
collection and demonstrate an effective workflow for real-world deployments.

</details>


### [22] [A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing](https://arxiv.org/abs/2509.04853)
*Chengkai Xu,Jiaqi Liu,Yicheng Guo,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: 本文提出了一种基于知识驱动的扩散策略（KDP），通过结合生成扩散模型和稀疏专家混合路由机制，解决了自动驾驶中多模态动作生成、时间稳定性和场景泛化的问题，实验证明了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在端到端实现中面临多模态动作生成、时间一致性和场景多样性等挑战，现有方法常无法兼顾这些需求。

Method: KDP结合了生成扩散模型和稀疏专家混合路由机制，扩散模型生成时间一致的多模态动作序列，路由机制激活上下文相关的专家模块。

Result: 实验表明，KDP在多种驾驶场景中表现出更高的成功率、更低的碰撞风险和更平滑的控制效果。

Conclusion: KDP为知识驱动的自动驾驶提供了可扩展且可解释的解决方案，展示了扩散模型与专家路由机制的有效结合。

Abstract: End-to-end autonomous driving remains constrained by the need to generate
multi-modal actions, maintain temporal stability, and generalize across diverse
scenarios. Existing methods often collapse multi-modality, struggle with
long-horizon consistency, or lack modular adaptability. This paper presents
KDP, a knowledge-driven diffusion policy that integrates generative diffusion
modeling with a sparse mixture-of-experts routing mechanism. The diffusion
component generates temporally coherent and multi-modal action sequences, while
the expert routing mechanism activates specialized and reusable experts
according to context, enabling modular knowledge composition. Extensive
experiments across representative driving scenarios demonstrate that KDP
achieves consistently higher success rates, reduced collision risk, and
smoother control compared to prevailing paradigms. Ablation studies highlight
the effectiveness of sparse expert activation and the Transformer backbone, and
activation analyses reveal structured specialization and cross-scenario reuse
of experts. These results establish diffusion with expert routing as a scalable
and interpretable paradigm for knowledge-driven end-to-end autonomous driving.

</details>


### [23] [Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)](https://arxiv.org/abs/2509.04948)
*Emanuela Boros*

Main category: cs.RO

TL;DR: 该论文研究了在办公环境中使用单一彩色相机进行拓扑定位的问题，评估了多种视觉描述符的性能，并提出了优化配置。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在复杂环境中因感知模糊、传感器噪声和光照变化导致的视觉定位和位置识别挑战。

Method: 评估了颜色直方图、SIFT、ASIFT、RGB-SIFT和词袋模型等多种视觉描述符，结合距离度量和分类器进行系统性比较。

Result: 通过标准评估指标验证了描述符配置的优势，并在ImageCLEF评测任务中验证了系统的定位能力。

Conclusion: 未来研究方向包括分层模型、排名方法和特征组合，以实现更鲁棒、高效的实时定位系统。

Abstract: Topological localization is a fundamental problem in mobile robotics, since
robots must be able to determine their position in order to accomplish tasks.
Visual localization and place recognition are challenging due to perceptual
ambiguity, sensor noise, and illumination variations. This work addresses
topological localization in an office environment using only images acquired
with a perspective color camera mounted on a robot platform, without relying on
temporal continuity of image sequences. We evaluate state-of-the-art visual
descriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and
Bag-of-Visual-Words approaches inspired by text retrieval. Our contributions
include a systematic, quantitative comparison of these features, distance
measures, and classifiers. Performance was analyzed using standard evaluation
metrics and visualizations, extending previous experiments. Results demonstrate
the advantages of proper configurations of appearance descriptors, similarity
measures, and classifiers. The quality of these configurations was further
validated in the Robot Vision task of the ImageCLEF evaluation campaign, where
the system identified the most likely location of novel image sequences. Future
work will explore hierarchical models, ranking methods, and feature
combinations to build more robust localization systems, reducing training and
runtime while avoiding the curse of dimensionality. Ultimately, this aims
toward integrated, real-time localization across varied illumination and longer
routes.

</details>


### [24] [Ground-Aware Octree-A* Hybrid Path Planning for Memory-Efficient 3D Navigation of Ground Vehicles](https://arxiv.org/abs/2509.04950)
*Byeong-Il Ham,Hyun-Bin Kim,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出了一种结合A*算法与八叉树结构的3D路径规划方法，优化了UGV和腿式机器人的路径生成效率和实际应用性。


<details>
  <summary>Details</summary>
Motivation: 提升UGV和腿式机器人在复杂地形中的路径规划效率和实用性，利用障碍物作为导航辅助，而非完全规避。

Method: 结合改进的3D A*算法和八叉树结构，引入高度惩罚的代价函数，利用可穿越障碍物优化路径，并通过节点合并减少计算量。

Result: 基准测试显示，该方法在保证路径最优的同时，显著降低了内存占用和计算时间。

Conclusion: 提出的方法高效、实用，适用于实时路径规划，尤其在地形复杂的环境中。

Abstract: In this paper, we propose a 3D path planning method that integrates the A*
algorithm with the octree structure. Unmanned Ground Vehicles (UGVs) and legged
robots have been extensively studied, enabling locomotion across a variety of
terrains. Advances in mobility have enabled obstacles to be regarded not only
as hindrances to be avoided, but also as navigational aids when beneficial. A
modified 3D A* algorithm generates an optimal path by leveraging obstacles
during the planning process. By incorporating a height-based penalty into the
cost function, the algorithm enables the use of traversable obstacles to aid
locomotion while avoiding those that are impassable, resulting in more
efficient and realistic path generation. The octree-based 3D grid map achieves
compression by merging high-resolution nodes into larger blocks, especially in
obstacle-free or sparsely populated areas. This reduces the number of nodes
explored by the A* algorithm, thereby improving computational efficiency and
memory usage, and supporting real-time path planning in practical environments.
Benchmark results demonstrate that the use of octree structure ensures an
optimal path while significantly reducing memory usage and computation time.

</details>


### [25] [DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation](https://arxiv.org/abs/2509.04970)
*Tien Pham,Xinyun Chi,Khang Nguyen,Manfred Huber,Angelo Cangelosi*

Main category: cs.RO

TL;DR: 论文提出了一种名为DeGuV的强化学习框架，旨在提高泛化能力和样本效率，通过在深度输入上使用可学习的掩码网络来保留关键视觉信息，并结合对比学习稳定Q值估计。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习代理在视觉输入任务中泛化能力有限，而数据增强虽能改善泛化但会牺牲样本效率和训练稳定性，因此需要一种兼顾两者的方法。

Method: DeGuV框架利用掩码网络从深度输入中提取关键视觉信息，结合对比学习和稳定的Q值估计来提升泛化与样本效率。

Result: 在RL-ViGen基准测试中，DeGuV在零样本模拟到现实转移任务中表现优于现有方法，同时在泛化和样本效率上均有提升。

Conclusion: DeGuV通过专注于关键视觉特征和稳定的训练方法，成功解决了强化学习中的泛化和效率问题，并提高了模型的可解释性。

Abstract: Reinforcement learning (RL) agents can learn to solve complex tasks from
visual inputs, but generalizing these learned skills to new environments
remains a major challenge in RL application, especially robotics. While data
augmentation can improve generalization, it often compromises sample efficiency
and training stability. This paper introduces DeGuV, an RL framework that
enhances both generalization and sample efficiency. In specific, we leverage a
learnable masker network that produces a mask from the depth input, preserving
only critical visual information while discarding irrelevant pixels. Through
this, we ensure that our RL agents focus on essential features, improving
robustness under data augmentation. In addition, we incorporate contrastive
learning and stabilize Q-value estimation under augmentation to further enhance
sample efficiency and training stability. We evaluate our proposed method on
the RL-ViGen benchmark using the Franka Emika robot and demonstrate its
effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV
outperforms state-of-the-art methods in both generalization and sample
efficiency while also improving interpretability by highlighting the most
relevant regions in the visual input

</details>


### [26] [Lyapunov-Based Deep Learning Control for Robots with Unknown Jacobian](https://arxiv.org/abs/2509.04984)
*Koji Matsuno,Chien Chern Cheah*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人控制的深度学习框架，通过模块化学习和李雅普诺夫分析解决深度学习的黑盒问题，确保系统稳定性和实时性。


<details>
  <summary>Details</summary>
Motivation: 深度学习的黑盒特性在机器人控制中带来了信任和鲁棒性挑战，现有理论框架尚无法满足需求。

Method: 采用模块化学习方法实时更新各层权重，基于李雅普诺夫分析确保系统稳定性。

Result: 实验证明方法有效，为实时深度学习机器人控制提供了稳定解决方案。

Conclusion: 该方法为解决深度学习黑盒问题提供了重要基础，推动了实时机器人控制的发展。

Abstract: Deep learning, with its exceptional learning capabilities and flexibility,
has been widely applied in various applications. However, its black-box nature
poses a significant challenge in real-time robotic applications, particularly
in robot control, where trustworthiness and robustness are critical in ensuring
safety. In robot motion control, it is essential to analyze and ensure system
stability, necessitating the establishment of methodologies that address this
need. This paper aims to develop a theoretical framework for end-to-end deep
learning control that can be integrated into existing robot control theories.
The proposed control algorithm leverages a modular learning approach to update
the weights of all layers in real time, ensuring system stability based on
Lyapunov-like analysis. Experimental results on industrial robots are presented
to illustrate the performance of the proposed deep learning controller. The
proposed method offers an effective solution to the black-box problem in deep
learning, demonstrating the possibility of deploying real-time deep learning
strategies for robot kinematic control in a stable manner. This achievement
provides a critical foundation for future advancements in deep learning based
real-time robotic applications.

</details>


### [27] [FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies](https://arxiv.org/abs/2509.04996)
*Moritz Reuss,Hongyi Zhou,Marcel Rühle,Ömer Erdinç Yağmurlu,Fabian Otto,Rudolf Lioutikov*

Main category: cs.RO

TL;DR: 论文提出了一种名为FLOWER的高效视觉-语言-动作（VLA）策略，通过中间模态融合和动作特定的全局自适应层归一化（Global-AdaLN）技术，显著降低了计算资源和参数需求，同时在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的VLA策略需要巨大的计算资源和参数规模，限制了其在机器人领域的实际应用。论文旨在通过技术创新解决这一效率挑战。

Method: 采用中间模态融合技术，通过裁剪LLM层减少50%容量；提出动作特定的Global-AdaLN条件化方法，进一步削减20%参数。

Result: FLOWER仅需950M参数和200小时H100 GPU训练时间，在190个任务中表现优异，并在CALVIN ABC基准测试中达到新SoTA（4.53）。

Conclusion: FLOWER展现了高效VLA策略的可行性，为机器人部署提供了更实用的解决方案。

Abstract: Developing efficient Vision-Language-Action (VLA) policies is crucial for
practical robotics deployment, yet current approaches face prohibitive
computational costs and resource requirements. Existing diffusion-based VLA
policies require multi-billion-parameter models and massive datasets to achieve
strong performance. We tackle this efficiency challenge with two contributions:
intermediate-modality fusion, which reallocates capacity to the diffusion head
by pruning up to $50\%$ of LLM layers, and action-specific Global-AdaLN
conditioning, which cuts parameters by $20\%$ through modular adaptation. We
integrate these advances into a novel 950 M-parameter VLA called FLOWER.
Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance
with bigger VLAs across $190$ tasks spanning ten simulation and real-world
benchmarks and demonstrates robustness across diverse robotic embodiments. In
addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark.
Demos, code and pretrained weights are available at
https://intuitive-robots.github.io/flower_vla/.

</details>


### [28] [Pointing-Guided Target Estimation via Transformer-Based Attention](https://arxiv.org/abs/2509.05031)
*Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter*

Main category: cs.RO

TL;DR: 提出一种模块化架构MM-ITF，通过多模态交互注意力机制，将2D指向手势映射到物体位置，预测人类意图，提高人机交互的直觉性和可达性。


<details>
  <summary>Details</summary>
Motivation: 在HRI中，机器人需要预测人类意图并做出适当响应。指向手势作为非语言交流的基本形式，是这一目标的关键。

Method: 采用Multi-Modality Inter-TransFormer (MM-ITF)架构，利用交互模态注意力机制，处理单目RGB数据，预测指向手势的目标物体。

Result: 该方法能准确预测目标物体，并通过引入patch confusion matrix评估模型性能。

Conclusion: MM-ITF为直觉性人机协作提供了有效解决方案，代码已开源。

Abstract: Deictic gestures, like pointing, are a fundamental form of non-verbal
communication, enabling humans to direct attention to specific objects or
locations. This capability is essential in Human-Robot Interaction (HRI), where
robots should be able to predict human intent and anticipate appropriate
responses. In this work, we propose the Multi-Modality Inter-TransFormer
(MM-ITF), a modular architecture to predict objects in a controlled tabletop
scenario with the NICOL robot, where humans indicate targets through natural
pointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing
gestures to object locations, assigns a likelihood score to each, and
identifies the most likely target. Our results demonstrate that the method can
accurately predict the intended object using monocular RGB data, thus enabling
intuitive and accessible human-robot collaboration. To evaluate the
performance, we introduce a patch confusion matrix, providing insights into the
model's predictions across candidate object locations. Code available at:
https://github.com/lucamuellercode/MMITF.

</details>


### [29] [Shared Autonomy through LLMs and Reinforcement Learning for Applications to Ship Hull Inspections](https://arxiv.org/abs/2509.05042)
*Cristiano Caissutti,Estelle Gerbier,Ehsan Khorrambakht,Paolo Marinelli,Andrea Munafo',Andrea Caiti*

Main category: cs.RO

TL;DR: 论文探讨了共享自治在海洋机器人系统中的三种互补方法：LLMs集成、人机交互框架和模块化任务管理器，旨在减少操作认知负担并增强透明度。


<details>
  <summary>Details</summary>
Motivation: 海洋环境的复杂性和高风险性需要高效的人机协作，因此研究共享自治以提升机器人在不确定环境中的适应性。

Method: 结合大型语言模型（LLMs）实现任务描述、人机交互框架支持多智能体协调，以及基于行为树的模块化任务管理器。

Result: 模拟和实际湖面测试表明，该系统能降低认知负荷、提高透明度并增强行为与人类意图的匹配度。

Conclusion: 研究为安全关键的海事机器人应用提供了模块化、可扩展的共享自治基础，未来将进一步优化和验证。

Abstract: Shared autonomy is a promising paradigm in robotic systems, particularly
within the maritime domain, where complex, high-risk, and uncertain
environments necessitate effective human-robot collaboration. This paper
investigates the interaction of three complementary approaches to advance
shared autonomy in heterogeneous marine robotic fleets: (i) the integration of
Large Language Models (LLMs) to facilitate intuitive high-level task
specification and support hull inspection missions, (ii) the implementation of
human-in-the-loop interaction frameworks in multi-agent settings to enable
adaptive and intent-aware coordination, and (iii) the development of a modular
Mission Manager based on Behavior Trees to provide interpretable and flexible
mission control. Preliminary results from simulation and real-world lake-like
environments demonstrate the potential of this multi-layered architecture to
reduce operator cognitive load, enhance transparency, and improve adaptive
behaviour alignment with human intent. Ongoing work focuses on fully
integrating these components, refining coordination mechanisms, and validating
the system in operational port scenarios. This study contributes to
establishing a modular and scalable foundation for trustworthy,
human-collaborative autonomy in safety-critical maritime robotics applications.

</details>


### [30] [Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers](https://arxiv.org/abs/2509.05201)
*Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的模型预测控制（MPC）框架，用于处理深度学习感知模块中的非高斯噪声，通过集合状态估计和线性规划实现高效稳定的控制。


<details>
  <summary>Details</summary>
Motivation: 传统MPC假设感知误差为零均值噪声，但在实际中噪声可能具有偏态或厚尾分布，这对安全反馈控制构成挑战。

Method: 使用约束zonotopes进行集合状态估计，将鲁棒MPC重构为线性规划，采用Minkowski-Lyapunov成本函数确保稳定性。

Result: 仿真和硬件实验表明，该方法在厚尾噪声条件下表现稳定且准确，显著优于传统高斯噪声设计。

Conclusion: 该框架为处理非高斯噪声提供了一种高效且稳定的解决方案，适用于真实世界的控制问题。

Abstract: This paper presents a robust model predictive control (MPC) framework that
explicitly addresses the non-Gaussian noise inherent in deep learning-based
perception modules used for state estimation. Recognizing that accurate
uncertainty quantification of the perception module is essential for safe
feedback control, our approach departs from the conventional assumption of
zero-mean noise quantification of the perception error. Instead, it employs
set-based state estimation with constrained zonotopes to capture biased,
heavy-tailed uncertainties while maintaining bounded estimation errors. To
improve computational efficiency, the robust MPC is reformulated as a linear
program (LP), using a Minkowski-Lyapunov-based cost function with an added
slack variable to prevent degenerate solutions. Closed-loop stability is
ensured through Minkowski-Lyapunov inequalities and contractive zonotopic
invariant sets. The largest stabilizing terminal set and its corresponding
feedback gain are then derived via an ellipsoidal approximation of the
zonotopes. The proposed framework is validated through both simulations and
hardware experiments on an omnidirectional mobile robot along with a camera and
a convolutional neural network-based perception module implemented within a
ROS2 framework. The results demonstrate that the perception-aware MPC provides
stable and accurate control performance under heavy-tailed noise conditions,
significantly outperforming traditional Gaussian-noise-based designs in terms
of both state estimation error bounding and overall control performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [31] [CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals](https://arxiv.org/abs/2509.04699)
*Wenhui Cui,Christopher Sandino,Hadi Pouransari,Ran Liu,Juri Minxha,Ellen L. Zippi,Aman Verma,Anna Sedlackova,Behrooz Mahasseni,Erdrin Azemi*

Main category: cs.LG

TL;DR: 本文提出了一种名为CPEP的框架，通过对比学习对齐EMG和姿态表示，提升了弱模态数据的表征质量，并在零样本分类中表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用低成本、低功耗的生物信号（如sEMG）实现手势分类，但弱模态数据的表征质量较低。通过与高质量结构化数据的对齐学习，可以提升表征质量并支持零样本分类。

Method: 提出CPEP框架，通过对比学习对齐EMG和姿态表示，训练一个能生成高质量且包含姿态信息的EMG编码器。

Result: 模型在线性探测和零样本分类中表现优异，优于基准模型21%（同分布手势分类）和72%（分布外手势分类）。

Conclusion: CPEP框架通过对齐学习提升了EMG数据的表征能力，为基于生物信号的手势分类提供了高效解决方案。

Abstract: Hand gesture classification using high-quality structured data such as
videos, images, and hand skeletons is a well-explored problem in computer
vision. Leveraging low-power, cost-effective biosignals, e.g. surface
electromyography (sEMG), allows for continuous gesture prediction on wearables.
In this paper, we demonstrate that learning representations from weak-modality
data that are aligned with those from structured, high-quality data can improve
representation quality and enables zero-shot classification. Specifically, we
propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and
pose representations, where we learn an EMG encoder that produces high-quality
and pose-informative representations. We assess the gesture classification
performance of our model through linear probing and zero-shot setups. Our model
outperforms emg2pose benchmark models by up to 21% on in-distribution gesture
classification and 72% on unseen (out-of-distribution) gesture classification.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [32] [UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis](https://arxiv.org/abs/2509.04624)
*Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel*

Main category: cs.CV

TL;DR: 论文介绍了一种基于无人机的交通监控系统，通过多尺度和多角度模板匹配、卡尔曼滤波等技术，实现了高精度的车辆检测、分类、跟踪和交通违法行为识别。


<details>
  <summary>Details</summary>
Motivation: 传统交通监控系统因覆盖范围有限、适应性差和可扩展性低等问题，无法有效应对交通拥堵和违规行为。无人机监控系统旨在解决这些局限性。

Method: 系统利用多尺度和多角度模板匹配、卡尔曼滤波和基于单应性的校准技术处理无人机采集的视频数据，同时结合地理围栏、运动过滤和轨迹偏差分析识别交通违法行为。

Result: 实验表明，系统的检测精度达91.8%，F1分数为90.5%，跟踪指标MOTA/MOTP分别为92.1%和93.7%，并能识别五种车辆类型和多种交通违规行为。

Conclusion: 系统具有高精度、可扩展性和实用性，可作为新一代智慧城市的基础设施独立交通监控解决方案。

Abstract: Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.

</details>


### [33] [Domain Adaptation for Different Sensor Configurations in 3D Object Detection](https://arxiv.org/abs/2509.04711)
*Satoshi Tanaka,Kok Seang Tan,Isamu Yamashita*

Main category: cs.CV

TL;DR: 提出两种自适应技术，用于解决不同传感器配置间的3D物体检测领域适应问题。


<details>
  <summary>Details</summary>
Motivation: 解决不同传感器配置导致的性能下降问题，填补该领域的空白。

Method: 采用下游微调和部分层微调技术，提升跨配置泛化能力。

Result: 实验表明，结合两种技术的方法优于简单的联合训练。

Conclusion: 提供了适应多样化车辆平台的实用且可扩展的解决方案。

Abstract: Recent advances in autonomous driving have underscored the importance of
accurate 3D object detection, with LiDAR playing a central role due to its
robustness under diverse visibility conditions. However, different vehicle
platforms often deploy distinct sensor configurations, causing performance
degradation when models trained on one configuration are applied to another
because of shifts in the point cloud distribution. Prior work on multi-dataset
training and domain adaptation for 3D object detection has largely addressed
environmental domain gaps and density variation within a single LiDAR; in
contrast, the domain gap for different sensor configurations remains largely
unexplored. In this work, we address domain adaptation across different sensor
configurations in 3D object detection. We propose two techniques: Downstream
Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and
Partial Layer Fine-tuning (updating only a subset of layers to improve
cross-configuration generalization). Using paired datasets collected in the
same geographic region with multiple sensor configurations, we show that joint
training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently
outperforms naive joint training for each configuration. Our findings provide a
practical and scalable solution for adapting 3D object detection models to the
diverse vehicle platforms.

</details>


### [34] [Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet](https://arxiv.org/abs/2509.05198)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari*

Main category: cs.CV

TL;DR: 本文分析了3D点云分类的重要性及现有数据集ModelNet40的局限性，提出了改进数据集ModelNet-R和轻量级神经网络Point-SkipNet，显著提升了分类性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 由于ModelNet40数据集存在标注不一致、2D数据、尺寸不匹配和类别区分不足等问题，影响了模型的性能，因此需要更高质量的数据集和高效网络来解决这些问题。

Method: 提出ModelNet-R数据集以解决ModelNet40的缺陷，并设计Point-SkipNet网络，通过高效采样、邻域分组和跳连实现高分类精度和低计算开销。

Result: 实验显示，在ModelNet-R上训练的模型性能显著提升，Point-SkipNet在低参数量的情况下达到了最先进的分类精度。

Conclusion: 研究强调了高质量数据集对优化3D点云分类模型效率的关键作用，且Point-SkipNet为轻量级高性能网络提供了新方向。

Abstract: The classification of 3D point clouds is crucial for applications such as
autonomous driving, robotics, and augmented reality. However, the commonly used
ModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D
data, size mismatches, and inadequate class differentiation, which hinder model
performance. This paper introduces ModelNet-R, a meticulously refined version
of ModelNet40 designed to address these issues and serve as a more reliable
benchmark. Additionally, this paper proposes Point-SkipNet, a lightweight
graph-based neural network that leverages efficient sampling, neighborhood
grouping, and skip connections to achieve high classification accuracy with
reduced computational overhead. Extensive experiments demonstrate that models
trained in ModelNet-R exhibit significant performance improvements. Notably,
Point-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a
substantially lower parameter count compared to contemporary models. This
research highlights the crucial role of dataset quality in optimizing model
efficiency for 3D point cloud classification. For more details, see the code
at: https://github.com/m-saeid/ModeNetR_PointSkipNet.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [35] [Analyzing Gait Adaptation with Hemiplegia Simulation Suits and Digital Twins](https://arxiv.org/abs/2509.05116)
*Jialin Chen,Jeremie Clos,Dominic Price,Praminda Caleb-Solly*

Main category: cs.ET

TL;DR: 研究使用模拟服装和数字孪生技术分析步态变化，发现模拟服装显著改变运动和肌肉激活模式。


<details>
  <summary>Details</summary>
Motivation: 为了在辅助和康复机器人设计早期测试中避免安全隐患，研究探索了使用健康参与者佩戴模拟服装在受控环境中进行步态分析。

Method: 通过Vicon运动捕捉系统和EMG/IMU传感器收集四种步行条件下的生物力学数据，并结合数字孪生模型进行机器学习分析。

Result: 模拟服装显著改变了使用者的步态和肌肉激活模式，使用者需要更突然的动作来补偿。同时确定了关键特征和传感器模态。

Conclusion: 模拟服装可用于早期设计阶段的步态研究，数字孪生框架为人类-助行器交互建模提供了有效工具。

Abstract: To advance the development of assistive and rehabilitation robots, it is
essential to conduct experiments early in the design cycle. However, testing
early prototypes directly with users can pose safety risks. To address this, we
explore the use of condition-specific simulation suits worn by healthy
participants in controlled environments as a means to study gait changes
associated with various impairments and support rapid prototyping. This paper
presents a study analyzing the impact of a hemiplegia simulation suit on gait.
We collected biomechanical data using a Vicon motion capture system and Delsys
Trigno EMG and IMU sensors under four walking conditions: with and without a
rollator, and with and without the simulation suit. The gait data was
integrated into a digital twin model, enabling machine learning analyses to
detect the use of the simulation suit and rollator, identify turning behavior,
and evaluate how the suit affects gait over time. Our findings show that the
simulation suit significantly alters movement and muscle activation patterns,
prompting users to compensate with more abrupt motions. We also identify key
features and sensor modalities that are most informative for accurately
capturing gait dynamics and modeling human-rollator interaction within the
digital twin framework.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [36] [Lightweight DNN for Full-Band Speech Denoising on Mobile Devices: Exploiting Long and Short Temporal Patterns](https://arxiv.org/abs/2509.05079)
*Konstantinos Drossos,Mikko Heikkinen,Paschalis Tsiaflakis*

Main category: eess.AS

TL;DR: 本文提出了一种适用于移动设备的轻量级、低延迟且因果的DNN方法，用于全频带语音降噪。该方法结合了短期和长期时间模式，并在移动设备上实现了实时处理。


<details>
  <summary>Details</summary>
Motivation: 当前大多数基于DNN的语音降噪方法未针对资源受限平台（如移动设备）优化，且缺乏对全频带信号和低延迟场景的关注。

Method: 采用改进的UNet架构，利用回溯帧、卷积核的时间跨度以及循环神经网络，通过STFT幅度输入和倒置瓶颈结构（受MobileNet启发），实现因果帧处理。

Result: 在移动设备上实现了低于0.02的实时因子，并在公开数据集上表现出优于现有全频带和低延迟方法的SI-SDR值。

Conclusion: 该方法在移动设备上高效实现了全频带语音降噪，且具有低延迟特性，适用于实际应用场景。

Abstract: Speech denoising (SD) is an important task of many, if not all, modern signal
processing chains used in devices and for everyday-life applications. While
there are many published and powerful deep neural network (DNN)-based methods
for SD, few are optimized for resource-constrained platforms such as mobile
devices. Additionally, most DNN-based methods for SD are not focusing on
full-band (FB) signals, i.e. having 48 kHz sampling rate, and/or low latency
cases. In this paper we present a causal, low latency, and lightweight
DNN-based method for full-band SD, leveraging both short and long temporal
patterns. The method is based on a modified UNet architecture employing
look-back frames, temporal spanning of convolutional kernels, and recurrent
neural networks for exploiting short and long temporal patterns in the signal
and estimated denoising mask. The DNN operates on a causal frame-by-frame basis
taking as an input the STFT magnitude, utilizes inverted bottlenecks inspired
by MobileNet, employs causal instance normalization for channel-wise
normalization, and achieves a real-time factor below 0.02 when deployed on a
modern mobile phone. The proposed method is evaluated using established speech
denoising metrics and publicly available datasets, demonstrating its
effectiveness in achieving an (SI-)SDR value that outperforms existing FB and
low latency SD methods.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [37] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 论文探讨了结合语言模型、代理模型和世界模型的必要性，提出通过分层脚手架和语言驱动的方法构建显式世界模型，以提高多智能体任务的效率和策略性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂、长期多智能体任务中世界模型发展的瓶颈问题，特别是探索空间和稀疏奖励带来的挑战。

Method: 提出分层脚手架方法，分解复杂目标为可管理的子目标，并结合大语言模型动态生成分层结构。

Result: 研究表明，将符号化、分层方法与多智能体强化学习结合的趋势显著，且语言驱动的世界模型能提供密集学习信号和高效训练框架。

Conclusion: 通过构建语言可配置的任务层环境，可以连接低级反应行为和高级策略团队协作，推动新一代智能代理的发展。

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [38] [Inferring the Graph Structure of Images for Graph Neural Networks](https://arxiv.org/abs/2509.04677)
*Mayur S Gowda,John Shi,Augusto Santos,José M. F. Moura*

Main category: eess.IV

TL;DR: 通过改进MNIST和Fashion-MNIST数据集的图表示方法，提高了图神经网络（GNN）任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用网格图和超像素方法表示图像数据集（如MNIST），但希望找到更优的图表示方法以提升GNN的分类性能。

Method: 通过计算像素之间的行相关性、列相关性和乘积图，生成新的图表示替代传统方法。

Result: 实验表明，使用新的图表示和特征作为GNN输入，比传统方法显著提高了准确性。

Conclusion: 改进图表示方法是提升GNN任务性能的有效途径。

Abstract: Image datasets such as MNIST are a key benchmark for testing Graph Neural
Network (GNN) architectures. The images are traditionally represented as a grid
graph with each node representing a pixel and edges connecting neighboring
pixels (vertically and horizontally). The graph signal is the values
(intensities) of each pixel in the image. The graphs are commonly used as input
to graph neural networks (e.g., Graph Convolutional Neural Networks (Graph
CNNs) [1, 2], Graph Attention Networks (GAT) [3], GatedGCN [4]) to classify the
images. In this work, we improve the accuracy of downstream graph neural
network tasks by finding alternative graphs to the grid graph and superpixel
methods to represent the dataset images, following the approach in [5, 6]. We
find row correlation, column correlation, and product graphs for each image in
MNIST and Fashion-MNIST using correlations between the pixel values building on
the method in [5, 6]. Experiments show that using these different graph
representations and features as input into downstream GNN models improves the
accuracy over using the traditional grid graph and superpixel methods in the
literature.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [39] [PRREACH: Probabilistic Risk Assessment Using Reachability for UAV Control](https://arxiv.org/abs/2509.04451)
*Nicole Fronda,Hariharan Narayanan,Sadia Afrin Ananna,Steven Weber,Houssam Abbas*

Main category: eess.SY

TL;DR: 提出了一种基于可达性分析的无人机风险有界控制器设计方法PRReach，通过优化控制律降低风险，离线可减少24%风险，在线可减少53%。


<details>
  <summary>Details</summary>
Motivation: 现有无人机风险评估框架依赖已知条件概率且缺乏风险缓解控制方法，数据不足导致实施困难。

Method: 结合无人机动力学和可达性分析，评估所有可行轨迹的风险，优化控制律以风险阈值为界。

Result: 仿真实验显示，PRReach在离线和在线场景中分别降低风险24%和53%。

Conclusion: PRReach利用开源数据和动力学模型，实际可行，能显著降低无人机操作风险。

Abstract: We present a new approach for designing risk-bounded controllers for Uncrewed
Aerial Vehicles (UAVs). Existing frameworks for assessing risk of UAV
operations rely on knowing the conditional probability of an incident occurring
given different causes. Limited data for computing these probabilities makes
real-world implementation of these frameworks difficult. Furthermore, existing
frameworks do not include control methods for risk mitigation. Our approach
relies on UAV dynamics, and employs reachability analysis for a probabilistic
risk assessment over all feasible UAV trajectories. We use this holistic risk
assessment to formulate a control optimization problem that minimally changes a
UAV's existing control law to be bounded by an accepted risk threshold. We call
our approach PRReach. Public and readily available UAV dynamics models and open
source spatial data for mapping hazard outcomes enables practical
implementation of PRReach for both offline pre-flight and online in-flight risk
assessment and mitigation. We evaluate PRReach through simulation experiments
on real-world data. Results show that PRReach controllers reduce risk by up to
24% offline, and up to 53% online from classical controllers.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [40] [The best approximation pair problem relative to two subsets in a normed space](https://arxiv.org/abs/2403.18767)
*Daniel Reem,Yair Censor*

Main category: math.OC

TL;DR: 论文讨论了广义赋范空间中最佳逼近对（BAP）问题的唯一性和存在性，提出了若干几何条件，并将结果扩展到非凸集合。


<details>
  <summary>Details</summary>
Motivation: 研究BAP问题在更一般的空间和非凸集合中的唯一性和存在性，填补这一领域的研究空白。

Method: 通过分析集合边界结构和相对方向以及范数性质，提出若干几何条件来保证唯一性和存在性。

Result: 提出了多种充分条件，显著扩展了现有算法的适用范围，并展示了BAP问题的广泛应用。

Conclusion: BAP问题在科学界和应用中的广泛性首次被揭示，提出的条件为其解决提供了新思路。

Abstract: In the classical best approximation pair (BAP) problem, one is given two
nonempty, closed, convex and disjoint subsets in a finite- or an
infinite-dimensional Hilbert space, and the goal is to find a pair of points,
each from each subset, which realizes the distance between the subsets. We
discuss the problem in more general normed spaces and with possibly non-convex
subsets, and focus our attention on the issues of uniqueness and existence of
the solution to the problem. As far as we know, these fundamental issues have
not received much attention. We present several sufficient geometric conditions
for the (at most) uniqueness of a BAP. These conditions are related to the
structure and the relative orientation of the boundaries of the subsets and to
the norm. We also present many sufficient conditions for the existence of a
BAP. Our results significantly extend the horizon of a recent algorithm for
solving the BAP problem [Censor, Mansour, Reem, J. Approx. Theory (2024)]. The
paper also shows, perhaps for the first time, how wide is the scope of the BAP
problem in terms of the scientific communities which are involved in it
(frequently independently) and in terms of its applications.

</details>
