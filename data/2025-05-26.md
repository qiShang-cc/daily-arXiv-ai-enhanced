<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 5]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Interference Modulation: A Novel Technique for Low-Rate and Power Efficient Multiple Access](https://arxiv.org/abs/2505.17526)
*M. Yaser Yagan,Ali E. Pusane,Ali Gorcin,Ibrahim Hokelek*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的干扰调制方法，利用无线信道相关性，以最小功率分配为额外用户提供低数据速率传输。


<details>
  <summary>Details</summary>
Motivation: 现有技术主要关注提高系统容量和数据速率，而本文旨在实现低功耗下为额外用户提供低速率通信。

Method: 通过调整发射机前端组件的辐射模式（如模拟波束成形权重或超表面配置），改变特定信道的干扰功率，实现低速率开关键控信号调制。

Result: 理论研究与仿真结果（如误码率）一致，表明该方法在6G网络中能以最小功耗实现低能力通信。

Conclusion: 该技术为6G网络中低功耗通信提供了可行方案。

Abstract: The majority of spatial signal processing techniques focus on increasing the
total system capacity and providing high data rates for intended user(s).
Unlike the existing studies, this paper introduces a novel interference
modulation method that exploits the correlation between wireless channels to
enable low-data-rate transmission towards additional users with a minimal power
allocation. The proposed method changes the interference power at specific
channels to modulate a low-rate on-off keying signal. This is achieved by
appropriately setting the radiation pattern of front-end components of a
transmitter, i.e., analog beamforming weights or metasurface configuration. The
paper investigates theoretical performance limits and analyzes the efficiency
in terms of sum rate. Bit error rate simulation results are closely matched
with theoretical findings. The initial findings indicate that the proposed
technique can be instrumental in providing reduced capability communication
using minimal power consumption in 6G networks.

</details>


### [2] [GPS-Aided Deep Learning for Beam Prediction and Tracking in UAV mmWave Communication](https://arxiv.org/abs/2505.17530)
*Vendi Ardianto Nugroho,Byung Moo Lee*

Main category: eess.SP

TL;DR: 论文提出了一种基于GPS辅助的深度学习模型，用于预测无人机毫米波通信中的当前和未来最优波束，显著降低开销并保持高精度和低功率损耗。


<details>
  <summary>Details</summary>
Motivation: 无人机毫米波通信中，波束管理面临高路径损耗和动态移动的挑战，需要一种高效且准确的方法来维持稳定连接。

Method: 通过GPS预处理提取关键位置特征，使用深度学习架构将顺序位置数据映射到波束索引预测，并提出数据集拆分方法以确保标签分布均衡。

Result: 模型在Top-1预测准确率超过70%，平均功率损耗低于0.6 dB，开销减少约93%，且95%的波束预测准确率保证了高可靠性。

Conclusion: 该模型能够高效且可靠地预测最优波束，显著提升无人机毫米波通信的稳定性与性能。

Abstract: Millimeter-wave (mmWave) communication enables high data rates for
cellular-connected Unmanned Aerial Vehicles (UAVs). However, a robust beam
management remains challenging due to significant path loss and the dynamic
mobility of UAVs, which can destabilize the UAV-base station (BS) link. This
research presents a GPS-aided deep learning (DL) model that simultaneously
predicts current and future optimal beams for UAV mmWave communications,
maintaining a Top-1 prediction accuracy exceeding 70% and an average power loss
below 0.6 dB across all prediction steps. These outcomes stem from a proposed
data set splitting method ensuring balanced label distribution, paired with a
GPS preprocessing technique that extracts key positional features, and a DL
architecture that maps sequential position data to beam index predictions. The
model reduces overhead by approximately 93% (requiring the training of 2 ~ 3
beams instead of 32 beams) with 95% beam prediction accuracy guarantees, and
ensures 94% to 96% of predictions exhibit mean power loss not exceeding 1 dB.

</details>


### [3] [LLM4SP: Large Language Models for Scatterer Prediction via Synesthesia of Machines](https://arxiv.org/abs/2505.17879)
*Zengrui Han,Lu Bai,Ziwei Huang,Xiang Cheng*

Main category: eess.SP

TL;DR: 这篇论文提出了一种基于大型语言模型（LLM）的散射体预测方法（LLM4SP），通过多模态数据集成和跨模态表示对齐，显著提升了智能交通系统中车对车通信的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索物理环境与电磁空间之间的通用映射关系，以提升车对车（V2V）多模态智能通道建模（MMICM）的性能。通过机器联觉（SoM）引导，实现传感与通信信息的非线性映射。

Method: 方法包括构建V2V-M3数据集，开发基于LLM的散射体预测方法（LLM4SP），并通过四模块架构（预处理、嵌入、骨干和输出模块）协同优化跨模态数据差异。

Result: 仿真结果表明，LLM4SP在全样本和泛化测试中表现优异，在不同频段、场景和车辆交通密度（VTD）下均显著优于小模型。

Conclusion: 论文结论指出，LLM4SP通过跨模态表示对齐和位置编码，成功捕捉了激光雷达点云与散射体之间的通用映射关系，为智能交通系统的通信建模提供了有效工具。

Abstract: Guided by Synesthesia of Machines (SoM), the nonlinear mapping relationship
between sensory and communication information serves as a powerful tool to
enhance both the accuracy and generalization of vehicle-to-vehicle (V2V)
multi-modal intelligent channel modeling (MMICM) in intelligent transportation
systems (ITSs). To explore the general mapping relationship between physical
environment and electromagnetic space, a new intelligent sensing-communication
integration dataset, named V2V-M3, is constructed for multiple scenarios in V2V
communications with multiple frequency bands and multiple vehicular traffic
densities (VTDs). Leveraging the strong representation and cross-modal
inference capabilities of large language models (LLMs), a novel LLM-based
method for Scatterer Prediction (LLM4SP) from light detection and ranging
(LiDAR) point clouds is developed. To address the inherent and significant
differences across multi-modal data, synergistically optimized four-module
architecture, i.e., preprocessor, embedding, backbone, and output modules, are
designed by considering the sensing/channel characteristics and electromagnetic
propagation mechanism. On the basis of cross-modal representation alignment and
positional encoding, the network of LLM4SP is fine-tuned to capture the general
mapping relationship between LiDAR point clouds and scatterers. Simulation
results demonstrate that the proposed LLM4SP achieves superior performance in
full-sample and generalization testing, significantly outperforming small
models across different frequency bands, scenarios, and VTDs.

</details>


### [4] [Faulty RIS-aided Integrated Sensing and Communication: Modeling and Optimization](https://arxiv.org/abs/2505.17970)
*Lu Wang,Gui Zhou,Changheng Li,Luis F. Abanto-Leon,Nairy Moghadas Gholian,Matthias Hollick,Arash Asadi*

Main category: eess.SP

TL;DR: 该论文研究了在可重构智能表面（RIS）辅助的集成感知与通信（ISAC）系统中，部分RIS元素失效时的性能下降问题。通过推导感知参数估计的MCRB和通信质量的SINR，设计了联合优化功能性RIS相移和发射波束成形的算法，以减少性能损失。仿真结果表明，该方法平均减少24.36%的MCRB性能损失。


<details>
  <summary>Details</summary>
Motivation: 当前研究尚未解决RIS元素故障对ISAC系统性能的影响问题。本文旨在填补这一空白，通过量化故障元素的影响并提出优化方案以提升系统性能。

Method: 论文首先推导了MCRB和SINR以评估故障元素的影响；随后，设计了一个联合优化功能性RIS相移和发射波束成形的非凸问题；为解决该问题，采用了BCD算法结合MM、SCA和惩罚技术进行优化。

Result: 仿真结果显示，所提方法平均减少24.36%的MCRB性能损失，尤其在故障元素数量增加时，性能提升更为显著。

Conclusion: 本文不仅填补了RIS元素故障对ISAC系统影响的研究空白，还提出了一种有效的优化方案，显著提升了系统性能。

Abstract: This work investigates a practical reconfigurable intelligent surface
(RIS)-aided integrated sensing and communication (ISAC) system, where a subset
of RIS elements fail to function properly and reflect incident signals randomly
towards unintended directions, thereby degrading system performance. To date,
no study has addressed such impairments caused by faulty RIS elements in ISAC
systems. This work aims to fill the gap. First, to quantify the impact of
faulty elements on ISAC performance, we derive the misspecified Cram\'er-Rao
bound (MCRB) for sensing parameter estimation and
signal-to-interference-and-noise ratio (SINR) for communication quality. Then,
to mitigate the performance loss caused by faulty elements, we jointly design
the remaining functional RIS phase shifts and transmit beamforming to minimize
the MCRB, subject to the communication SINR and transmit power constraints. The
resulting optimization problem is highly non-convex due to the intricate
structure of the MCRB expression and constant-modulus constraint imposed on
RIS. To address this, we reformulate it into a more tractable form and propose
a block coordinate descent (BCD) algorithm that incorporates
majorization-minimization (MM), successive convex approximation (SCA), and
penalization techniques. Simulation results demonstrate that our proposed
approach reduces the MCRB performance loss by 24.36% on average compared to the
case where the presence of faulty elements is ignored. Furthermore, the
performance gain becomes more evident as the number of faulty elements
increases.

</details>


### [5] [Analysis on Energy Efficiency of RIS-Assisted Multiuser Downlink Near-Field Communications](https://arxiv.org/abs/2505.18076)
*Wei Wang,Xiaoyu Ou,Zhihan Ren,Waqas Bin Abbas,Shuping Dang,Angela Doufexi,Mark A. Beach*

Main category: eess.SP

TL;DR: 本文研究了近场通信中可重构智能表面（RIS）辅助多用户下行链路的能效优化问题，分析了多种因素对能效的影响，并提出了一种嵌套交替优化框架来最大化能效。


<details>
  <summary>Details</summary>
Motivation: 提升可重构智能表面（RIS）辅助通信系统的能效，同时考虑实际硬件限制（如离散相位调整）和不同的可重构元件类型。

Method: 采用嵌套交替优化框架：外层为基于整数的离散相位重构优化，内层为连续发射功率分配的非凸优化。

Result: 所提出的优化框架在多组基准方案中表现出更高的有效性和效率，并且能识别出具有最高能效的最优RIS架构。

Conclusion: 研究为RIS系统的能效优化提供了实用框架，并揭示了不同关键因素对能效的影响，为实际部署提供了指导。

Abstract: In this paper, we focus on the energy efficiency (EE) optimization and
analysis of reconfigurable intelligent surface (RIS)-assisted multiuser
downlink near-field communications. Specifically, we conduct a comprehensive
study on several key factors affecting EE performance, including the number of
RIS elements, the types of reconfigurable elements, reconfiguration
resolutions, and the maximum transmit power. To accurately capture the power
characteristics of RISs, we adopt more practical power consumption models for
three commonly used reconfigurable elements in RISs: PIN diodes, varactor
diodes, and radio frequency (RF) switches. These different elements may result
in RIS systems exhibiting significantly different energy efficiencies (EEs),
even when their spectral efficiencies (SEs) are similar. Considering discrete
phases implemented at most RISs in practice, which makes their optimization
NP-hard, we develop a nested alternating optimization framework to maximize EE,
consisting of an outer integer-based optimization for discrete RIS phase
reconfigurations and a nested non-convex optimization for continuous transmit
power allocation within each iteration. Extensive comparisons with multiple
benchmark schemes validate the effectiveness and efficiency of the proposed
framework. Furthermore, based on the proposed optimization method, we analyze
the EE performance of RISs across different key factors and identify the
optimal RIS architecture yielding the highest EE.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [6] [Adaptive Implicit-Based Deep Learning Channel Estimation for 6G Communications](https://arxiv.org/abs/2505.17421)
*Zhen Qiao,Jiang Xue,Junkai Zhang,Guanzhang Liu,Xiaoqin Ma,Runhua Li,Faheem A. Khan,John S. Thompson,Zongben Xu*

Main category: cs.IT

TL;DR: 本文提出了一种轻量级的自适应隐式层深度学习网络（ICENet），用于车联网通信中的信道估计，动态平衡计算复杂度和准确性。


<details>
  <summary>Details</summary>
Motivation: 5G广泛部署后，6G研究中AI的作用日益重要，但现有深度学习模型因结构固定难以适应资源受限的实际场景。

Method: 提出ICENet框架，通过动态调整迭代层数，适配不同输入条件（如信道质量），实现资源与性能的平衡。

Result: ICENet在保持高性能的同时减少了内存占用，优于传统显式多层堆叠模型。

Conclusion: 未来需进一步解决开放研究挑战，如算法通用性和实时性优化。

Abstract: With the widespread deployment of fifth-generation (5G) wireless networks,
research on sixth-generation (6G) technology is gaining momentum. Artificial
Intelligence (AI) is anticipated to play a significant role in 6G, particularly
through integration with the physical layer for tasks such as channel
estimation. Considering resource limitations in real systems, the AI algorithm
should be designed to have the ability to balance the accuracy and resource
consumption according to the scenarios dynamically. However, conventional
explicit multilayer-stacked Deep Learning (DL) models struggle to adapt due to
their heavy reliance on the structure of deep neural networks. This article
proposes an adaptive Implicit-layer DL Channel Estimation Network (ICENet) with
a lightweight framework for vehicle-to-everything communications. This novel
approach balances computational complexity and channel estimation accuracy by
dynamically adjusting computational resources based on input data conditions,
such as channel quality. Unlike explicit multilayer-stacked DL-based channel
estimation models, ICENet offers a flexible framework, where specific
requirements can be achieved by adaptively changing the number of iterations of
the iterative layer. Meanwhile, ICENet requires less memory while maintaining
high performance. The article concludes by highlighting open research
challenges and promising future research directions.

</details>


### [7] [Characterization of IRS-aided Indoor Wireless Virtual-Reality with Hybrid Beamforming](https://arxiv.org/abs/2505.17737)
*Nasim Alikhani,Abbas Mohammadi*

Main category: cs.IT

TL;DR: 该论文提出了一种用于提高无线VR系统频谱效率的优化解决方案，结合MU-MIMO OFDM和混合波束成形技术，在室内IRS场景下实现最优速率和低延迟。


<details>
  <summary>Details</summary>
Motivation: 由于VR流量传输对低延迟和高带宽的需求，特别是在mmWave频段下，亟需一种能够最大化传输速率的解决方案。

Method: 采用MU-MIMO OFDM和混合波束成形技术，通过优化IRS相移和有效信道增益，综合考虑处理、传输和排队延迟，分析不同SNR下的性能。

Result: 仿真结果显示与NS3高度一致（81.57%准确率），且在复杂度上优于现有设计。

Conclusion: 所提方法在提高频谱效率和满足低延迟需求方面表现优异，为无线VR系统提供了可行的技术方案。

Abstract: This paper introduces an optimum solution for a utility function that
increases spectral efficiency in wireless Virtual Reality (VR) systems. This
system uses Multi-user Multiple Input Multiple Output Orthogonal Frequency
Division Multiplexing (MU-MIMO OFDM) with hybrid beamforming in indoor
Intelligent Reflecting Surface (IRS) based Downlink (DL) scenario. Given the
critical need to maximize the rate for transmitting VR traffic to meet the
low-latency requirements, a substantial bandwidth allocation is essential. This
bandwidth is assumed to be in the mmWave band, according to the IEEE
802.11ad/ay standard. The proposed utility function takes into account various
delays, including processing, transmission and queuing delays, on both DL and
Uplink (UL). Moreover, the relation between transmission delay and the utility
function is examined in different Signal-to-Noise Ratio (SNR) levels, using
both mean and minimum channel gain metrics. An optimization approach is applied
to iteratively determine the IRS phase shifts and effective channel gain. The
simulation results are benchmarked against NS3 simulations, showing a high
degree of consistency. With an average accuracy of 81.57% the calculated DL and
UL rates match the NS3 results when considering the IRS. Also, our proposed
method achieves superior performance in the case of complexity over the
existing designs.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [Enhancing Fourier-based Doppler Resolution with Diffusion Models](https://arxiv.org/abs/2505.17567)
*Denisa Qosja,Kilian Barth,Simon Wagner*

Main category: cs.CV

TL;DR: 该论文利用生成神经网络扩散模型增强雷达多普勒分辨率，克服了传统FFT的局限，有效分离近距离目标。


<details>
  <summary>Details</summary>
Motivation: 在雷达系统中，高多普勒分辨率对于检测慢速目标至关重要，但硬件和物理因素限制了分辨率的提升，因此需要开发后处理技术来增强分辨率。

Method: 基于零填充FFT，利用生成神经网络扩散模型进行细化处理。

Result: 该方法成功克服了传统FFT的局限性，能够有效分离近距离目标。

Conclusion: 通过AI技术提升多普勒分辨率是可行的，为雷达信号处理提供了新的解决方案。

Abstract: In radar systems, high resolution in the Doppler dimension is important for
detecting slow-moving targets as it allows for more distinct separation between
these targets and clutter, or stationary objects. However, achieving sufficient
resolution is constrained by hardware capabilities and physical factors,
leading to the development of processing techniques to enhance the resolution
after acquisition. In this work, we leverage artificial intelligence to
increase the Doppler resolution in range-Doppler maps. Based on a zero-padded
FFT, a refinement via the generative neural networks of diffusion models is
achieved. We demonstrate that our method overcomes the limitations of
traditional FFT, generating data where closely spaced targets are effectively
separated.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [Interpreting Deep Neural Network-Based Receiver Under Varying Signal-To-Noise Ratios](https://arxiv.org/abs/2409.16768)
*Marko Tuononen,Dani Korpi,Ville Hautamäki*

Main category: cs.LG

TL;DR: 提出了一种新方法，用于解释卷积神经网络接收器模型，识别对信道参数信息贡献最大或最小的单元，全局和局部解释结合，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于更好地理解神经网络（尤其是卷积神经网络接收器模型）中哪些单元对特定信道参数信息的处理最为关键，从而提供可解释性。

Method: 方法通过识别模型中包含最多或最少信道参数信息的单元来实现，支持全局和局部层面的解释，全局解释由局部解释聚合而成。

Result: 实验结果表明，该方法能有效识别对信噪比处理贡献最大和最小的单元，且在高维环境中表现稳健。

Conclusion: 尽管针对无线电接收器模型设计，但该方法可扩展至其他神经网络架构和应用，具有普适性。

Abstract: We propose a novel method for interpreting neural networks, focusing on
convolutional neural network-based receiver model. The method identifies which
unit or units of the model contain most (or least) information about the
channel parameter(s) of the interest, providing insights at both global and
local levels -- with global explanations aggregating local ones. Experiments on
link-level simulations demonstrate the method's effectiveness in identifying
units that contribute most (and least) to signal-to-noise ratio processing.
Although we focus on a radio receiver model, the method generalizes to other
neural network architectures and applications, offering robust estimation even
in high-dimensional settings.

</details>


### [10] [Unsupervised Clustering for Fault Analysis in High-Voltage Power Systems Using Voltage and Current Signals](https://arxiv.org/abs/2505.17763)
*Julian Oelhaf,Georg Kordowich,Andreas Maier,Johann Jager,Siming Bayer*

Main category: cs.LG

TL;DR: 论文探讨了利用无监督聚类技术对高压电力系统进行故障诊断，通过FFT提取频域特征并应用K-Means算法，无需标注数据即可实现故障分类，结果展示了无监督学习的潜力。


<details>
  <summary>Details</summary>
Motivation: 现代电网中传感器产生大量故障波形数据，但缺乏标注数据导致故障分类和分析困难，因此研究无监督方法的适用性。

Method: 使用FFT提取频域特征，并应用K-Means算法进行无监督聚类，实现故障自动分类。

Result: 聚类结果与电力专家评估一致，证明无监督学习在故障分析中的有效性。

Conclusion: 无监督学习为电力系统故障提供了一种无需先验假设、可扩展的数据驱动分析方法。

Abstract: The widespread use of sensors in modern power grids has led to the
accumulation of large amounts of voltage and current waveform data, especially
during fault events. However, the lack of labeled datasets poses a significant
challenge for fault classification and analysis. This paper explores the
application of unsupervised clustering techniques for fault diagnosis in
high-voltage power systems. A dataset provided by the Reseau de Transport
d'Electricite (RTE) is analyzed, with frequency domain features extracted using
the Fast Fourier Transform (FFT). The K-Means algorithm is then applied to
identify underlying patterns in the data, enabling automated fault
categorization without the need for labeled training samples. The resulting
clusters are evaluated in collaboration with power system experts to assess
their alignment with real-world fault characteristics. The results demonstrate
the potential of unsupervised learning for scalable and data-driven fault
analysis, providing a robust approach to detecting and classifying power system
faults with minimal prior assumptions.

</details>


### [11] [Emergence of Hebbian Dynamics in Regularized Non-Local Learners](https://arxiv.org/abs/2505.18069)
*David Koplow,Tomaso Poggio,Liu Ziyin*

Main category: cs.LG

TL;DR: 论文揭示了SGD与Hebbian学习之间的联系，表明SGD与正则化或噪声可以表现出类似Hebbian或反Hebbian的学习特性。


<details>
  <summary>Details</summary>
Motivation: 探讨SGD与生物学习机制（如Hebbian学习）之间的联系，弥合人工与生物学习之间的差距。

Method: 通过理论和实证分析，比较SGD与Hebbian学习的学习信号，并验证权重衰减和噪声的作用。

Result: SGD在权重衰减下表现出类似Hebbian的特性，而在噪声下表现出反Hebbian特性。

Conclusion: Hebbian特性可能是更深层优化原则的副产品，其存在不能排除更复杂的异突触机制。

Abstract: Stochastic Gradient Descent (SGD) has emerged as a remarkably effective
learning algorithm, underpinning nearly all state-of-the-art machine learning
models, from large language models to autonomous vehicles. Despite its
practical success, SGD appears fundamentally distinct from biological learning
mechanisms. It is widely believed that the biological brain can not implement
gradient descent because it is nonlocal, and we have found little (if any)
experimental evidence for it. In contrast, the brain is widely thought to learn
via local Hebbian learning principles, which have been seen as incompatible
with gradient descent. In this paper, we establish a theoretical and empirical
connection between the learning signals of neural networks trained using SGD
with weight decay and those trained with Hebbian learning near convergence. We
show that SGD with regularization can appear to learn according to a Hebbian
rule, and SGD with injected noise according to an anti-Hebbian rule. We also
provide empirical evidence that Hebbian learning properties can emerge in a
network with weight decay from virtually any learning rule--even random ones.
These results may bridge a long-standing gap between artificial and biological
learning, revealing Hebbian properties as an epiphenomenon of deeper
optimization principles and cautioning against interpreting their presence in
neural data as evidence against more complex hetero-synaptic mechanisms.

</details>
