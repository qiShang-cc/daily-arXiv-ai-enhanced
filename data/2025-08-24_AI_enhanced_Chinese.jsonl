{"id": "2508.15257", "pdf": "https://arxiv.org/pdf/2508.15257", "abs": "https://arxiv.org/abs/2508.15257", "authors": ["Eduard E. Bahingayi", "Shuying Lin", "Murat Uysal", "Marco Di Renzo", "Le-Nam Tran"], "title": "A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems", "categories": ["eess.SP"], "comment": null, "summary": "Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive\ntechnology for future wireless networks. To investigate their capabilities, we\nstudy the sum rate maximization problem in an SIM-based multiuser (MU)\nmultiple-input single-output (MISO) downlink system. A vast majority of pioneer\nstudies, if not all, address this fundamental problem using the prevailing\nalternating optimization (AO) framework, where the digital beamforming (DB) and\nSIM phase shifts are optimized alternately. However, many of these approaches\nsuffer from suboptimal performance, quickly leading to performance saturation,\nwhen the number of SIM layers increases assuming the \\emph{fixed SIM\nthickness}. In this letter, we demonstrate that significant performance gains\ncan still be achieved, and such saturation does not occur with the proposed\nmethod in the considered setting. To this end, we provide practical design\nguidelines to improve AO-based optimization of digital precoders and SIM phase\nshifts. Specifically, we show that (i) optimizing the SIM phase shifts first\nyields significant performance improvements, compared to optimizing the DB\nfirst; and (ii) when applying projected gradient (PG) methods, which are\ngradually becoming more popular to optimize the phase shifts thanks to their\nscalability, we find that using an iterative PG method achieves better\nperformance than the single PG step, which is commonly used in existing\nsolutions. Based on these customizations, the proposed method achieves a higher\nachievable sum rate (ASR) of up to $\\ensuremath{115.53\\%}$, compared to\nbenchmark schemes for the scenarios under consideration.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5806\u53e0\u667a\u80fd\u8d85\u8868\u9762\uff08SIM\uff09\u7684\u591a\u7528\u6237\u591a\u8f93\u5165\u5355\u8f93\u51fa\uff08MISO\uff09\u4e0b\u884c\u7cfb\u7edf\u7684\u548c\u901f\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u4e0b\u4f18\u5316\u6570\u5b57\u6ce2\u675f\u6210\u5f62\uff08DB\uff09\u548cSIM\u76f8\u79fb\u65f6\uff0c\u6027\u80fd\u5bb9\u6613\u8fbe\u5230\u9971\u548c\uff0c\u5c24\u5176\u662f\u5728SIM\u5c42\u6570\u589e\u52a0\u4e14\u539a\u5ea6\u56fa\u5b9a\u65f6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6539\u8fdbAO\u6846\u67b6\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4ee5\u4e0b\u6539\u8fdb\u65b9\u6cd5\uff1a1\uff09\u5148\u4f18\u5316SIM\u76f8\u79fb\u518d\u4f18\u5316DB\uff1b2\uff09\u5728\u6295\u5f71\u68af\u5ea6\uff08PG\uff09\u65b9\u6cd5\u4e2d\u91c7\u7528\u8fed\u4ee3PG\u800c\u975e\u5e38\u89c1\u7684\u5355\u6b65PG\u3002\u8fd9\u4e9b\u6539\u8fdb\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u9a8c\u573a\u666f\u4e2d\u5c06\u53ef\u8fbe\u5230\u548c\u901f\u7387\uff08ASR\uff09\u63d0\u5347\u81f3\u591a\u8fbe115.53%\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdbAO\u6846\u67b6\u7684\u8bbe\u8ba1\uff0c\u672c\u6587\u8bc1\u660e\u5728SIM\u5c42\u6570\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\u4ecd\u53ef\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684SIM\u6280\u672f\u63d0\u4f9b\u4e86\u5b9e\u7528\u8bbe\u8ba1\u6307\u5bfc\u3002"}}
{"id": "2508.15375", "pdf": "https://arxiv.org/pdf/2508.15375", "abs": "https://arxiv.org/abs/2508.15375", "authors": ["Hanwen Hu", "Jiancheng An", "Lu Gan", "Chau Yuen"], "title": "Performance Analysis of RIS-Aided High-Mobility Wireless Systems", "categories": ["eess.SP"], "comment": "This paper has been accepted for publication in 2025 IEEE 102nd\n  Vehicular Technology Conference", "summary": "Reconfigurable intelligent surface (RIS) technology holds immense potential\nfor increasing the performance of wireless networks. Therefore, RIS is also\nregarded as one of the solutions to address communication challenges in\nhigh-mobility scenarios, such as Doppler shift and fast fading. This paper\ninvestigates a high-speed train (HST) multiple-input single-output (MISO)\ncommunication system aided by a RIS. We propose a block coordinate descent\n(BCD) algorithm to jointly optimize the RIS phase shifts and the transmit\nbeamforming vectors to maximize the channel gain. Numerical results are\nprovided to demonstrate that the proposed algorithm significantly enhances the\nsystem performance, achieving an average channel gain improvement of 15 dB\ncompared to traditional schemes. Additionally, the introduction of RIS\neliminates outage probability and improves key performance metrics such as\nachievable rate, channel capacity, and bit error rate (BER). These findings\nhighlight the critical role of RIS in enhancing HST communication systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\uff08\u5982\u9ad8\u901f\u5217\u8f66\u901a\u4fe1\uff09\u4e2d\u5229\u7528\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u6280\u672f\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316RIS\u76f8\u4f4d\u548c\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u9ad8\u901f\u5217\u8f66\u901a\u4fe1\u9762\u4e34\u591a\u666e\u52d2\u9891\u79fb\u548c\u5feb\u901f\u8870\u843d\u7b49\u6311\u6218\uff0cRIS\u6280\u672f\u88ab\u63d0\u51fa\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u4e4b\u4e00\uff0c\u4ee5\u63d0\u5347\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\u3002", "method": "\u91c7\u7528\u5757\u5750\u6807\u4e0b\u964d\uff08BCD\uff09\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316RIS\u76f8\u4f4d\u504f\u79fb\u548c\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u5411\u91cf\uff0c\u4ee5\u6700\u5927\u5316\u4fe1\u9053\u589e\u76ca\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u5e73\u5747\u4fe1\u9053\u589e\u76ca\u63d0\u9ad8\u4e8615 dB\uff0c\u5e76\u6d88\u9664\u4e86\u4e2d\u65ad\u6982\u7387\uff0c\u6539\u5584\u4e86\u53ef\u8fbe\u901f\u7387\u3001\u4fe1\u9053\u5bb9\u91cf\u548c\u8bef\u7801\u7387\u7b49\u5173\u952e\u6027\u80fd\u6307\u6807\u3002", "conclusion": "RIS\u5728\u9ad8\u901f\u5217\u8f66\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2508.15544", "pdf": "https://arxiv.org/pdf/2508.15544", "abs": "https://arxiv.org/abs/2508.15544", "authors": ["Pedro H. C. de Souza", "Luiz A. M. Pereira", "Faustino R. G\u00f3mez", "Elsa M. Mater\u00f3n", "Jorge Ricardo Mej\u00eda-Salazar"], "title": "Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems", "categories": ["eess.SP"], "comment": null, "summary": "Ongoing discussions about the future of wireless communications are reaching\na turning point as standardization activities for the sixth generation of\nmobile networks (6G) become more mature. New technologies must now face renewed\nscrutiny by the industry and academia in order to be ready for deployment in\nthe near future. Recently, reconfigurable intelligent surfaces (RISs) gained\nattention as a promising solution for improving the propagation conditions of\nsignal transmission in general. The RIS is a planar array of tunable resonant\nelements designed to dynamically and precisely manipulate the reflection of\nincident electromagnetic waves. However, the physical structure of the RIS and\nits components may be subject to practical limitations and imperfections. It is\nimperative that the hardware imperfections (HWIs) associated with the RIS be\nanalyzed, so that it remains a feasible technology from a practical standpoint.\nMoreover, solutions for mitigating the HWIs must be considered, as is discussed\nin this work. More specifically, we introduce a gradient descent optimization\nfor mitigating HWIs in RIS-aided wideband communication systems. Numerical\nresults show that the proposed optimization is able to compensate for HWIs such\nas the phase-shift noise (PSN) and RIS surface deformations.", "AI": {"tldr": "\u6458\u8981\u8ba8\u8bba\u4e866G\u79fb\u52a8\u7f51\u7edc\u4e2d\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u7684\u5e94\u7528\u53ca\u5176\u786c\u4ef6\u7f3a\u9677\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5\u6765\u7f13\u89e3\u8fd9\u4e9b\u7f3a\u9677\u3002", "motivation": "\u968f\u77406G\u6807\u51c6\u5316\u6d3b\u52a8\u7684\u6210\u719f\uff0c\u65b0\u6280\u672f\u9700\u8981\u7ecf\u53d7\u66f4\u4e25\u683c\u7684\u5ba1\u67e5\u3002RIS\u4f5c\u4e3a\u4e00\u79cd\u6539\u5584\u4fe1\u53f7\u4f20\u8f93\u6761\u4ef6\u7684\u89e3\u51b3\u65b9\u6848\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u786c\u4ef6\u7f3a\u9677\u53ef\u80fd\u5f71\u54cd\u5176\u5b9e\u7528\u6027\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u8f7bRIS\u8f85\u52a9\u7684\u5bbd\u5e26\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u786c\u4ef6\u7f3a\u9677\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8865\u507f\u76f8\u4f4d\u504f\u79fb\u566a\u58f0\u548cRIS\u8868\u9762\u53d8\u5f62\u7b49\u786c\u4ef6\u7f3a\u9677\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u65b9\u6cd5\uff0cRIS\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u5177\u53ef\u884c\u6027\uff0c\u4e3a6G\u901a\u4fe1\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2508.15581", "pdf": "https://arxiv.org/pdf/2508.15581", "abs": "https://arxiv.org/abs/2508.15581", "authors": ["Pedro H. C. de Souza", "Luciano Mendes"], "title": "Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces", "categories": ["eess.SP"], "comment": null, "summary": "Recently, the reconfigurable intelligent surface (RIS) technology has ushered\nin the prospect of control over the wireless propagation environment. By\nestablishing alternative propagation paths for the transmitted signals, and by\nreflecting them in a controllable manner, the RIS is able to improve the signal\nreception. However, an aspect often overlooked is the potential bandwidth\nrestrictions on the wideband signal reflected by the RIS. If not carefully\nconsidered, this can become an impediment for the adoption of the RIS in the\nnext generation of communications systems. Therefore, in this work we propose a\nRIS configuration method that provides frequency selective signal reflection\nfor wideband signals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdRIS\u914d\u7f6e\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5bbd\u9891\u4fe1\u53f7\u53cd\u5c04\u4e2d\u7684\u5e26\u5bbd\u9650\u5236\u95ee\u9898\u3002", "motivation": "RIS\u6280\u672f\u867d\u7136\u80fd\u6539\u5584\u4fe1\u53f7\u63a5\u6536\uff0c\u4f46\u5176\u5bbd\u9891\u4fe1\u53f7\u53cd\u5c04\u7684\u5e26\u5bbd\u9650\u5236\u53ef\u80fd\u963b\u788d\u5176\u5728\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u91c7\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u63d0\u4f9b\u9891\u7387\u9009\u62e9\u6027\u4fe1\u53f7\u53cd\u5c04\u7684RIS\u914d\u7f6e\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u671b\u4f18\u5316RIS\u5bf9\u5bbd\u9891\u4fe1\u53f7\u7684\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u9891\u7387\u9009\u62e9\u6027\u53cd\u5c04\uff0cRIS\u5728\u5bbd\u9891\u4fe1\u53f7\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u5f97\u5230\u63d0\u5347\u3002"}}
{"id": "2508.14994", "pdf": "https://arxiv.org/pdf/2508.14994", "abs": "https://arxiv.org/abs/2508.14994", "authors": ["Murilo Vinicius da Silva", "Matheus Hipolito Carvalho", "Juliano Negri", "Thiago Segreto", "Gustavo J. G. Lahr", "Ricardo V. Godoy", "Marcelo Becker"], "title": "A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In hazardous and remote environments, robotic systems perform critical tasks\ndemanding improved safety and efficiency. Among these, quadruped robots with\nmanipulator arms offer mobility and versatility for complex operations.\nHowever, teleoperating quadruped robots is challenging due to the lack of\nintegrated obstacle detection and intuitive control methods for the robotic\narm, increasing collision risks in confined or dynamically changing workspaces.\nTeleoperation via joysticks or pads can be non-intuitive and demands a high\nlevel of expertise due to its complexity, culminating in a high cognitive load\non the operator. To address this challenge, a teleoperation approach that\ndirectly maps human arm movements to the robotic manipulator offers a simpler\nand more accessible solution. This work proposes an intuitive remote control by\nleveraging a vision-based pose estimation pipeline that utilizes an external\ncamera with a machine learning-based model to detect the operator's wrist\nposition. The system maps these wrist movements into robotic arm commands to\ncontrol the robot's arm in real-time. A trajectory planner ensures safe\nteleoperation by detecting and preventing collisions with both obstacles and\nthe robotic arm itself. The system was validated on the real robot,\ndemonstrating robust performance in real-time control. This teleoperation\napproach provides a cost-effective solution for industrial applications where\nsafety, precision, and ease of use are paramount, ensuring reliable and\nintuitive robotic control in high-risk environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u59ff\u6001\u4f30\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u76f4\u63a5\u6620\u5c04\u4eba\u7c7b\u624b\u81c2\u52a8\u4f5c\u6765\u8fdc\u7a0b\u63a7\u5236\u56db\u8db3\u673a\u5668\u4eba\u7684\u673a\u68b0\u81c2\uff0c\u63d0\u9ad8\u4e86\u64cd\u4f5c\u7684\u76f4\u89c2\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u5371\u9669\u548c\u8fdc\u7a0b\u73af\u5883\u4e2d\u64cd\u4f5c\u56db\u8db3\u673a\u5668\u4eba\u5b58\u5728\u969c\u788d\u7269\u68c0\u6d4b\u548c\u63a7\u5236\u590d\u6742\u6027\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u76f4\u89c2\u4e14\u5b89\u5168\u7684\u9065\u63a7\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u89c6\u89c9\u59ff\u6001\u4f30\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5916\u7f6e\u6444\u50cf\u5934\u6355\u6349\u64cd\u4f5c\u8005\u624b\u8155\u52a8\u4f5c\uff0c\u5e76\u5b9e\u65f6\u6620\u5c04\u4e3a\u673a\u68b0\u81c2\u6307\u4ee4\uff0c\u7ed3\u5408\u8f68\u8ff9\u89c4\u5212\u5668\u9632\u6b62\u78b0\u649e\u3002", "result": "\u7cfb\u7edf\u5728\u5b9e\u9645\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u6210\u529f\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u3001\u5b89\u5168\u7684\u673a\u68b0\u81c2\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u98ce\u9669\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u76f4\u89c2\u4e14\u5b89\u5168\u7684\u9065\u63a7\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15599", "pdf": "https://arxiv.org/pdf/2508.15599", "abs": "https://arxiv.org/abs/2508.15599", "authors": ["P. H. C. de Souza", "M. Khazaee", "L. L. Mendes"], "title": "On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems", "categories": ["eess.SP"], "comment": "To be published in the PIERS2025 Abu Dhabi proceedings", "summary": "The reconfigurable intelligent surface (RIS) technology for metasurfaces is\nushering in a new paradigm for wireless communication systems. It provides an\naccessible way for controlling the interaction between electromagnetic waves\nwith the propagation medium. One particularly important aspect is the\nconfiguration of the RIS elements or reflectors. Simply stated, the objective\nof the RIS configuration is to choose the optimum phase-shift combination that\nmaximizes the channel capacity. Recently, neural networks (NNs) were proposed\nfor tackling this task and results have shown that the proposed NN promotes far\nless reconfigurations of the RIS, consequently reducing the configuration\noverhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift\nin high-mobility communication systems. Despite not being its usual primary\ngoal, results have also demonstrated that the RIS can compensate for the\nDoppler shift at a small cost in performance. However, the typical\nreflection-only constraint for RIS systems limits the spatial coverage and\nsignal amplification potential achieved by such systems. Therefore, the\nsimultaneously transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) can be employed to address these limitations by its dual\nfunctionality of transmitting and reflecting signals concurrently. It can be\nshown that the STAR-RIS can augment coverage, energy efficiency, and latency\nreduction, while enhancing sum-rate and physical-layer security across several\nwireless contexts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u6280\u672f\u5728\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u5176\u53cd\u5c04\u5143\u4ef6\u914d\u7f6e\u4f18\u5316\u3001\u795e\u7ecf\u7f51\u7edc\u8f85\u52a9\u914d\u7f6e\u3001\u5e94\u5bf9\u591a\u666e\u52d2\u9891\u79fb\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u5f15\u5165\u540c\u65f6\u900f\u5c04\u4e0e\u53cd\u5c04\u7684STAR-RIS\u6280\u672f\u4ee5\u89e3\u51b3\u4f20\u7edfRIS\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u901a\u8fc7RIS\u6280\u672f\u4f18\u5316\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4f20\u7edfRIS\u5728\u8986\u76d6\u8303\u56f4\u548c\u4fe1\u53f7\u653e\u5927\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51faSTAR-RIS\u6280\u672f\u4ee5\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6548\u80fd\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u4f18\u5316RIS\u7684\u76f8\u4f4d\u504f\u79fb\u914d\u7f6e\uff0c\u5e76\u5f15\u5165STAR-RIS\u6280\u672f\u5b9e\u73b0\u4fe1\u53f7\u7684\u900f\u5c04\u4e0e\u53cd\u5c04\u53cc\u91cd\u529f\u80fd\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u51cf\u5c11\u4e86RIS\u7684\u91cd\u65b0\u914d\u7f6e\u5f00\u9500\uff1bRIS\u5728\u591a\u666e\u52d2\u9891\u79fb\u8865\u507f\u4e2d\u8868\u73b0\u826f\u597d\uff1bSTAR-RIS\u63d0\u5347\u4e86\u8986\u76d6\u8303\u56f4\u3001\u80fd\u6548\u548c\u5b89\u5168\u6027\u3002", "conclusion": "STAR-RIS\u6280\u672f\u4e3a\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u8986\u76d6\u3001\u80fd\u6548\u548c\u5b89\u5168\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2508.15002", "pdf": "https://arxiv.org/pdf/2508.15002", "abs": "https://arxiv.org/abs/2508.15002", "authors": ["Ren\u00e9 Zurbr\u00fcgg", "Andrei Cramariuc", "Marco Hutter"], "title": "GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping", "categories": ["cs.RO"], "comment": null, "summary": "Dexterous robotic hands enable versatile interactions due to the flexibility\nand adaptability of multi-fingered designs, allowing for a wide range of\ntask-specific grasp configurations in diverse environments. However, to fully\nexploit the capabilities of dexterous hands, access to diverse and high-quality\ngrasp data is essential -- whether for developing grasp prediction models from\npoint clouds, training manipulation policies, or supporting high-level task\nplanning with broader action options. Existing approaches for dataset\ngeneration typically rely on sampling-based algorithms or simplified\nforce-closure analysis, which tend to converge to power grasps and often\nexhibit limited diversity. In this work, we propose a method to synthesize\nlarge-scale, diverse, and physically feasible grasps that extend beyond simple\npower grasps to include refined manipulations, such as pinches and tri-finger\nprecision grasps. We introduce a rigorous, differentiable energy formulation of\nforce closure, implicitly defined through a Quadratic Program (QP).\nAdditionally, we present an adjusted optimization method (MALA*) that improves\nperformance by dynamically rejecting gradient steps based on the distribution\nof energy values across all samples. We extensively evaluate our approach and\ndemonstrate significant improvements in both grasp diversity and the stability\nof final grasp predictions. Finally, we provide a new, large-scale grasp\ndataset for 5,700 objects from DexGraspNet, comprising five different grippers\nand three distinct grasp types.\n  Dataset and Code:https://graspqp.github.io/", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u80fd\u91cf\u516c\u5f0f\u548c\u4f18\u5316\u7b97\u6cd5\uff08MALA*\uff09\u751f\u6210\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u4e14\u7269\u7406\u53ef\u884c\u7684\u6293\u53d6\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6293\u53d6\u591a\u6837\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b5700\u4e2a\u7269\u4f53\u7684\u65b0\u6570\u636e\u96c6DexGraspNet\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u5229\u7528\u7075\u5de7\u673a\u68b0\u624b\u7684\u6f5c\u529b\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u4e14\u591a\u6837\u5316\u7684\u6293\u53d6\u6570\u636e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u7684\u6570\u636e\u591a\u6837\u6027\u6709\u9650\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u5f3a\u529b\u6293\u53d6\u4e0a\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u6b21\u89c4\u5212\uff08QP\uff09\u7684\u53ef\u5fae\u5206\u80fd\u91cf\u516c\u5f0f\u6765\u63cf\u8ff0\u529b\u95ed\u5408\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u4f18\u5316\u65b9\u6cd5\uff08MALA*\uff09\u6765\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6293\u53d6\u591a\u6837\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u63d0\u4f9b\u4e86\u5305\u542b5700\u4e2a\u7269\u4f53\u3001\u4e94\u79cd\u5939\u722a\u548c\u4e09\u79cd\u6293\u53d6\u7c7b\u578b\u7684\u5927\u578b\u6570\u636e\u96c6DexGraspNet\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u6293\u53d6\u6570\u636e\u751f\u6210\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u7075\u5de7\u673a\u68b0\u624b\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002"}}
{"id": "2508.15671", "pdf": "https://arxiv.org/pdf/2508.15671", "abs": "https://arxiv.org/abs/2508.15671", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Saif Khan Mohammed", "Ronny Hadani", "Robert Calderbank"], "title": "Discrete Radar based on Modulo Arithmetic", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": "36 pages, 7 figures, submitted to EURASIP JASP", "summary": "Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler\n(DD) domain, converted to the time domain (DD) for transmission and reception,\nthen returned to the DD domain for processing. We describe how to use the same\narchitecture for radar sensing. The intended delay resolution is $\\frac{1}{B}$\nwhere $B$ is the radar bandwidth, and the intended Doppler resolution is\n$\\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in\nthe DD domain, illuminate the scattering environment, match filter the return,\nthen correlate with delay and Doppler shifts of the transmitted waveform. This\nproduces an image of the scattering environment, and the radar ambiguity\nfunction expresses the blurriness of this image. The possible delay and Doppler\nshifts generate the continuous Heisenberg-Weyl group which has been widely\nstudied in the theory of radar. We describe how to approach the problem of\nwaveform design, not from the perspective of this continuous group, but from\nthe perspective of a discrete group of delay and Doppler shifts, where the\ndiscretization is determined by the intended delay and Doppler resolution of\nthe radar. We describe how to approach the problem of shaping the ambiguity\nsurface through symplectic transformations that normalize our discrete\nHeisenberg-Weyl group. The complexity of traditional continuous radar signal\nprocessing is $\\mathcal{O}\\big(B^2T^2\\big)$. We describe how to reduce this\ncomplexity to $\\mathcal{O}\\big(BT\\log T\\big)$ by choosing the radar waveform to\nbe a common eigenvector of a maximal commutative subgroup of our discrete\nHeisenberg-Weyl group. The theory of symplectic transformations also enables\ndefining libraries of optimal radar waveforms with small peak-to-average power\nratios.", "AI": {"tldr": "Zak-OTFS\u662f\u4e00\u79cd\u5728\u5ef6\u8fdf-\u591a\u666e\u52d2\uff08DD\uff09\u57df\u4e2d\u751f\u6210\u4fe1\u53f7\u7684\u8c03\u5236\u65b9\u6848\uff0c\u53ef\u7528\u4e8e\u96f7\u8fbe\u611f\u77e5\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u4f4d\u79fb\u7ec4\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u96f7\u8fbe\u611f\u77e5\u4e2d\u5229\u7528Zak-OTFS\u8c03\u5236\u65b9\u6848\uff0c\u63d0\u9ad8\u5206\u8fa8\u7387\u548c\u964d\u4f4e\u4fe1\u53f7\u5904\u7406\u590d\u6742\u5ea6\u3002", "method": "\u5728DD\u57df\u751f\u6210\u96f7\u8fbe\u6ce2\u5f62\uff0c\u5339\u914d\u6ee4\u6ce2\u56de\u6ce2\u4fe1\u53f7\uff0c\u5229\u7528\u79bb\u6563\u5316\u7684Heisenberg-Weyl\u7ec4\u548c\u8f9b\u53d8\u6362\u4f18\u5316\u6ce2\u5f62\u8bbe\u8ba1\u3002", "result": "\u5c06\u4f20\u7edf\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u7684\u590d\u6742\u5ea6\u4eceO(B\u00b2T\u00b2)\u964d\u4f4e\u5230O(BT log T)\uff0c\u5e76\u5b9a\u4e49\u5cf0\u503c\u529f\u7387\u6bd4\u4f4e\u7684\u4f18\u5316\u6ce2\u5f62\u5e93\u3002", "conclusion": "\u901a\u8fc7\u79bb\u6563\u5316\u548c\u8f9b\u53d8\u6362\uff0cZak-OTFS\u5728\u96f7\u8fbe\u611f\u77e5\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u4f18\u5316\u7684\u6ce2\u5f62\u8bbe\u8ba1\u3002"}}
{"id": "2508.15021", "pdf": "https://arxiv.org/pdf/2508.15021", "abs": "https://arxiv.org/abs/2508.15021", "authors": ["Mark Van der Merwe", "Devesh Jha"], "title": "In-Context Iterative Policy Improvement for Dynamic Manipulation", "categories": ["cs.RO"], "comment": "14 pages. Accepted at CoRL 2025", "summary": "Attention-based architectures trained on internet-scale language data have\ndemonstrated state of the art reasoning ability for various language-based\ntasks, such as logic problems and textual reasoning. Additionally, these Large\nLanguage Models (LLMs) have exhibited the ability to perform few-shot\nprediction via in-context learning, in which input-output examples provided in\nthe prompt are generalized to new inputs. This ability furthermore extends\nbeyond standard language tasks, enabling few-shot learning for general\npatterns. In this work, we consider the application of in-context learning with\npre-trained language models for dynamic manipulation. Dynamic manipulation\nintroduces several crucial challenges, including increased dimensionality,\ncomplex dynamics, and partial observability. To address this, we take an\niterative approach, and formulate our in-context learning problem to predict\nadjustments to a parametric policy based on previous interactions. We show\nacross several tasks in simulation and on a physical robot that utilizing\nin-context learning outperforms alternative methods in the low data regime.\nVideo summary of this work and experiments can be found\nhttps://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u8fdb\u884c\u52a8\u6001\u64cd\u7eb5\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bed\u8a00\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u5728\u52a8\u6001\u64cd\u7eb5\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u5c1a\u9700\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u65b9\u6cd5\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u9884\u6d4b\u57fa\u4e8e\u5386\u53f2\u4ea4\u4e92\u7684\u53c2\u6570\u5316\u7b56\u7565\u8c03\u6574\u3002", "result": "\u5728\u4eff\u771f\u548c\u7269\u7406\u673a\u5668\u4eba\u4efb\u52a1\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e3a\u52a8\u6001\u64cd\u7eb5\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u6570\u636e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15673", "pdf": "https://arxiv.org/pdf/2508.15673", "abs": "https://arxiv.org/abs/2508.15673", "authors": ["Enrico Testi", "Giulia Torcolacci", "Nicol\u00f2 Decarli", "Davide Dardari", "Enrico Paolini"], "title": "A Grant-free Coded Random Access Scheme for Near-field Communications", "categories": ["eess.SP"], "comment": null, "summary": "The industrial Internet of things (IIoT) is revolutionizing industrial\nprocesses by facilitating massive machine-type communications among countless\ninterconnected devices. To efficiently handle the resulting large-scale and\nsporadic traffic, grant-free random access protocols-especially coded random\naccess (CRA)-have emerged as scalable and reliable solutions. At the same time,\nadvancements in wireless hardware, including extremely large-scale MIMO arrays\nand high-frequency communication (e.g., mmWave, Terahertz), are pushing network\noperations into the near-field propagation regime, allowing for dense\nconnectivity and enhanced spatial multiplexing. This paper proposes an\ninnovative approach that combines near-field spatial multiplexing with the\ninterference mitigation capabilities of CRA, utilizing an extremely large\naperture array at the access point. This integration improves reliability and\nreduces access latency, offering a robust framework for IIoT connectivity in\nnext-generation 6G networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8fd1\u573a\u7a7a\u95f4\u590d\u7528\u548cCRA\u7684\u65b0\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347IIoT\u57286G\u7f51\u7edc\u4e2d\u7684\u8fde\u63a5\u53ef\u9760\u6027\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\uff08IIoT\uff09\u9700\u8981\u5927\u89c4\u6a21\u3001\u9ad8\u6548\u7684\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5e94\u5bf9\u8bbe\u5907\u95f4\u7684\u5927\u91cf\u8fde\u63a5\u548c\u7a81\u53d1\u6d41\u91cf\u3002", "method": "\u5229\u7528\u8d85\u5927\u5b54\u5f84\u9635\u5217\u7684\u8fd1\u573a\u7a7a\u95f4\u590d\u7528\u80fd\u529b\uff0c\u7ed3\u5408CRA\u7684\u5e72\u6270\u6291\u5236\u7279\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8fde\u63a5\u7684\u53ef\u9760\u6027\u5e76\u964d\u4f4e\u4e86\u63a5\u5165\u5ef6\u8fdf\u3002", "conclusion": "\u8fd9\u4e00\u6846\u67b6\u4e3a6G\u7f51\u7edc\u4e2d\u7684IIoT\u8fde\u63a5\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15038", "pdf": "https://arxiv.org/pdf/2508.15038", "abs": "https://arxiv.org/abs/2508.15038", "authors": ["Makram Chahine", "William Yang", "Alaa Maalouf", "Justin Siriska", "Ninad Jadhav", "Daniel Vogt", "Stephanie Gil", "Robert Wood", "Daniela Rus"], "title": "Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.MA", "I.2.9"], "comment": null, "summary": "Wildlife field operations demand efficient parallel deployment methods to\nidentify and interact with specific individuals, enabling simultaneous\ncollective behavioral analysis, and health and safety interventions. Previous\nrobotics solutions approach the problem from the herd perspective, or are\nmanually operated and limited in scale. We propose a decentralized vision-based\nmulti-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,\nand sensor-minimal (single onboard RGB camera). Our approach enables robust\nidentification and tracking of large species in their natural habitat. We\ndevelop novel vision-based coordination and tracking algorithms designed for\ndynamic, unstructured environments without reliance on centralized\ncommunication or control. We validate our system through real-world\nexperiments, demonstrating reliable deployment in diverse field conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\uff0c\u7528\u4e8e\u91ce\u751f\u52a8\u7269\u76d1\u6d4b\uff0c\u5177\u6709\u53bb\u4e2d\u5fc3\u5316\u3001\u4f4e\u5e26\u5bbd\u548c\u4f20\u611f\u5668\u6700\u5c11\u7684\u7279\u70b9\u3002", "motivation": "\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u591a\u4e3a\u624b\u52a8\u64cd\u4f5c\u6216\u4ece\u7fa4\u4f53\u89d2\u5ea6\u51fa\u53d1\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u5e76\u884c\u90e8\u7f72\u65b9\u6cd5\uff0c\u4ee5\u540c\u65f6\u8fdb\u884c\u96c6\u4f53\u884c\u4e3a\u5206\u6790\u548c\u5065\u5eb7\u5b89\u5168\u5e72\u9884\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u89c6\u89c9\u7684\u534f\u8c03\u548c\u8ddf\u8e2a\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u548c\u975e\u7ed3\u6784\u5316\u73af\u5883\uff0c\u65e0\u9700\u4f9d\u8d56\u96c6\u4e2d\u901a\u4fe1\u6216\u63a7\u5236\u3002", "result": "\u901a\u8fc7\u5b9e\u5730\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u591a\u6837\u5316\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u90e8\u7f72\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u91ce\u751f\u52a8\u7269\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15687", "pdf": "https://arxiv.org/pdf/2508.15687", "abs": "https://arxiv.org/abs/2508.15687", "authors": ["Masoud Nateghi", "Reza Sameni"], "title": "Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings", "categories": ["eess.SP"], "comment": null, "summary": "Oscillometry is the standard method for non-invasive, cuff-based blood\npressure (BP) measurement, but it introduces systematic errors that may impact\nclinical accuracy. This study investigates the sources of these\nerrors--primarily the limitations of oscillometry itself and\nrespiration-induced fluctuations--using BP waveform data from the MIMIC\ndatabase. Oscillometry tends to underestimate systolic BP and overestimate\ndiastolic BP, while respiration introduces cyclical variations that further\ndegrade measurement precision. To mitigate these effects, we propose an\nestimation-theoretic framework employing least squares (LS) and maximum\nlikelihood (ML) methods for correcting both single and repeated BP\nmeasurements. LS estimation supports conventional multi-measurement averaging\nprotocols, whereas the ML approach incorporates prior knowledge of measurement\nerrors, offering improved performance. Our results demonstrate that leveraging\nstatistical priors across multiple readings can enhance the accuracy of\nnon-invasive BP monitoring, with potential implications for improving\ncardiovascular diagnosis and treatment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u632f\u8361\u6cd5\u5728\u65e0\u521b\u8840\u538b\u6d4b\u91cf\u4e2d\u5f15\u5165\u7684\u7cfb\u7edf\u6027\u8bef\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u5c0f\u4e8c\u4e58\u548c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6821\u6b63\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6d4b\u91cf\u7cbe\u5ea6\u3002", "motivation": "\u632f\u8361\u6cd5\u662f\u6807\u51c6\u7684\u65e0\u521b\u8840\u538b\u6d4b\u91cf\u65b9\u6cd5\uff0c\u4f46\u5176\u5b58\u5728\u7cfb\u7edf\u6027\u8bef\u5dee\uff08\u5982\u4f4e\u4f30\u6536\u7f29\u538b\u548c\u9ad8\u4f30\u8212\u5f20\u538b\uff09\u548c\u547c\u5438\u5f15\u8d77\u7684\u6ce2\u52a8\uff0c\u5f71\u54cd\u4e34\u5e8a\u51c6\u786e\u6027\u3002", "method": "\u5229\u7528MIMIC\u6570\u636e\u5e93\u7684\u8840\u538b\u6ce2\u5f62\u6570\u636e\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6700\u5c0f\u4e8c\u4e58\uff08LS\uff09\u548c\u6700\u5927\u4f3c\u7136\uff08ML\uff09\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6821\u6b63\u5355\u6b21\u548c\u591a\u6b21\u6d4b\u91cf\u4e2d\u7684\u8bef\u5dee\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7edf\u8ba1\u5148\u9a8c\u77e5\u8bc6\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u975e\u4fb5\u5165\u6027\u8840\u538b\u76d1\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u671b\u6539\u5584\u5fc3\u8840\u7ba1\u75be\u75c5\u7684\u8bca\u65ad\u548c\u6cbb\u7597\u3002"}}
{"id": "2508.15160", "pdf": "https://arxiv.org/pdf/2508.15160", "abs": "https://arxiv.org/abs/2508.15160", "authors": ["Hesam Azadjou", "Suraj Chakravarthi Raja", "Ali Marjaninejad", "Francisco J. Valero-Cuevas"], "title": "Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds", "categories": ["cs.RO"], "comment": null, "summary": "Like mammals, robots must rapidly learn to control their bodies and interact\nwith their environment despite incomplete knowledge of their body structure and\nsurroundings. They must also adapt to continuous changes in both. This work\npresents a bio-inspired learning algorithm, General-to-Particular (G2P),\napplied to a tendon-driven quadruped robotic system developed and fabricated\nin-house. Our quadruped robot undergoes an initial five-minute phase of\ngeneralized motor babbling, followed by 15 refinement trials (each lasting 20\nseconds) to achieve specific cyclical movements. This process mirrors the\nexploration-exploitation paradigm observed in mammals. With each refinement,\nthe robot progressively improves upon its initial \"good enough\" solution. Our\nresults serve as a proof-of-concept, demonstrating the hardware-in-the-loop\nsystem's ability to learn the control of a tendon-driven quadruped with\nredundancies in just a few minutes to achieve functional and adaptive cyclical\nnon-convex movements. By advancing autonomous control in robotic locomotion,\nour approach paves the way for robots capable of dynamically adjusting to new\nenvironments, ensuring sustained adaptability and performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4eff\u751f\u5b66\u4e60\u7b97\u6cd5G2P\uff0c\u5e94\u7528\u4e8e\u808c\u8171\u9a71\u52a8\u7684\u56db\u8db3\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc75\u5206\u949f\u7684\u521d\u6b65\u63a2\u7d22\u548c15\u6b2120\u79d2\u7684\u4f18\u5316\u8bd5\u9a8c\uff0c\u5b9e\u73b0\u529f\u80fd\u6027\u5faa\u73af\u8fd0\u52a8\u3002", "motivation": "\u673a\u5668\u4eba\u9700\u5728\u4e0d\u5b8c\u5168\u4e86\u89e3\u81ea\u8eab\u7ed3\u6784\u548c\u73af\u5883\u7684\u60c5\u51b5\u4e0b\u5feb\u901f\u5b66\u4e60\u63a7\u5236\u4e0e\u9002\u5e94\u53d8\u5316\uff0c\u7c7b\u4f3c\u54fa\u4e73\u52a8\u7269\u7684\u63a2\u7d22-\u5229\u7528\u8303\u5f0f\u3002", "method": "\u91c7\u7528\u4ece\u4e00\u822c\u5230\u5177\u4f53\uff08G2P\uff09\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u808c\u8171\u9a71\u52a8\u56db\u8db3\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u521d\u6b65\u7684\u2018\u8fd0\u52a8\u63a2\u7d22\u2019\u548c\u540e\u7eed\u7684\u4f18\u5316\u8bd5\u9a8c\u9010\u6b65\u6539\u8fdb\u63a7\u5236\u3002", "result": "\u7cfb\u7edf\u5728\u51e0\u5206\u949f\u5185\u6210\u529f\u5b66\u4e60\u4e86\u808c\u8171\u9a71\u52a8\u56db\u8db3\u673a\u5668\u4eba\u7684\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u529f\u80fd\u6027\u5faa\u73af\u8fd0\u52a8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u5728\u65b0\u73af\u5883\u4e2d\u52a8\u6001\u8c03\u6574\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u589e\u5f3a\u4e86\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.14917", "pdf": "https://arxiv.org/pdf/2508.14917", "abs": "https://arxiv.org/abs/2508.14917", "authors": ["Weichien Liao"], "title": "Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis", "categories": ["cs.AR", "cs.CV", "cs.DC", "eess.IV", "eess.SP", "physics.ins-det"], "comment": "FPGA-based denoising pipeline for PRISM-scale imaging. Real-time\n  frame subtraction and averaging via burst-mode AXI4 and DRAM buffering.\n  Benchmarked against CPU/GPU workflows; scalable across multi-bank FPGA setups", "summary": "High-throughput imaging workflows, such as Parallel Rapid Imaging with\nSpectroscopic Mapping (PRISM), generate data at rates that exceed conventional\nreal-time processing capabilities. We present a scalable FPGA-based\npreprocessing pipeline for real-time denoising, implemented via High-Level\nSynthesis (HLS) and optimized for DRAM-backed buffering. Our architecture\nperforms frame subtraction and averaging directly on streamed image data,\nminimizing latency through burst-mode AXI4 interfaces. The resulting kernel\noperates below the inter-frame interval, enabling inline denoising and reducing\ndataset size for downstream CPU/GPU analysis. Validated under PRISM-scale\nacquisition, this modular FPGA framework offers a practical solution for\nlatency-sensitive imaging workflows in spectroscopy and microscopy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eFPGA\u7684\u53ef\u6269\u5c55\u9884\u5904\u7406\u7ba1\u9053\uff0c\u7528\u4e8e\u9ad8\u901a\u91cf\u6210\u50cf\u5de5\u4f5c\u6d41\uff08\u5982PRISM\uff09\u7684\u5b9e\u65f6\u53bb\u566a\u3002", "motivation": "\u9ad8\u901a\u91cf\u6210\u50cf\u5de5\u4f5c\u6d41\u751f\u6210\u7684\u6570\u636e\u901f\u7387\u8d85\u8fc7\u4f20\u7edf\u5b9e\u65f6\u5904\u7406\u80fd\u529b\uff0c\u9700\u8981\u4f4e\u5ef6\u8fdf\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528FPGA\u67b6\u6784\uff0c\u901a\u8fc7HLS\u5b9e\u73b0\u5b9e\u65f6\u53bb\u566a\uff0c\u4f18\u5316DRAM\u7f13\u51b2\uff0c\u5229\u7528AXI4\u63a5\u53e3\u6700\u5c0f\u5316\u5ef6\u8fdf\u3002", "result": "\u8be5\u6846\u67b6\u5728PRISM\u89c4\u6a21\u4e0b\u9a8c\u8bc1\u6709\u6548\uff0c\u80fd\u5b9e\u73b0\u5185\u8054\u53bb\u566a\u5e76\u51cf\u5c11\u4e0b\u6e38\u5206\u6790\u6570\u636e\u96c6\u5927\u5c0f\u3002", "conclusion": "\u6b64FPGA\u6846\u67b6\u4e3a\u5149\u8c31\u5b66\u548c\u663e\u5fae\u955c\u5b66\u4e2d\u7684\u5ef6\u8fdf\u654f\u611f\u6210\u50cf\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15201", "pdf": "https://arxiv.org/pdf/2508.15201", "abs": "https://arxiv.org/abs/2508.15201", "authors": ["Haoran Li", "Yuhui Chen", "Wenbo Cui", "Weiheng Liu", "Kai Liu", "Mingcai Zhou", "Zhengtao Zhang", "Dongbin Zhao"], "title": "Survey of Vision-Language-Action Models for Embodied Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "in Chinese language", "summary": "Embodied intelligence systems, which enhance agent capabilities through\ncontinuous environment interactions, have garnered significant attention from\nboth academia and industry. Vision-Language-Action models, inspired by\nadvancements in large foundation models, serve as universal robotic control\nframeworks that substantially improve agent-environment interaction\ncapabilities in embodied intelligence systems. This expansion has broadened\napplication scenarios for embodied AI robots. This survey comprehensively\nreviews VLA models for embodied manipulation. Firstly, it chronicles the\ndevelopmental trajectory of VLA architectures. Subsequently, we conduct a\ndetailed analysis of current research across 5 critical dimensions: VLA model\nstructures, training datasets, pre-training methods, post-training methods, and\nmodel evaluation. Finally, we synthesize key challenges in VLA development and\nreal-world deployment, while outlining promising future research directions.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u5728\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u53d1\u5c55\u3001\u7ed3\u6784\u3001\u6570\u636e\u96c6\u3001\u8bad\u7ec3\u65b9\u6cd5\u53ca\u6311\u6218\uff0c\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\u901a\u8fc7\u73af\u5883\u4e92\u52a8\u63d0\u5347\u80fd\u529b\uff0cVLA\u6a21\u578b\u4f5c\u4e3a\u901a\u7528\u63a7\u5236\u6846\u67b6\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5176\u4ea4\u4e92\u80fd\u529b\uff0c\u6269\u5c55\u4e86\u5e94\u7528\u573a\u666f\u3002", "method": "\u7efc\u8ff0\u4e86VLA\u67b6\u6784\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u4ece\u6a21\u578b\u7ed3\u6784\u3001\u6570\u636e\u96c6\u3001\u9884\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\u53ca\u8bc4\u4f30\u4e94\u4e2a\u7ef4\u5ea6\u5206\u6790\u5f53\u524d\u7814\u7a76\u3002", "result": "\u603b\u7ed3\u4e86VLA\u6a21\u578b\u7684\u5173\u952e\u6280\u672f\u53ca\u5176\u5728\u5177\u8eab\u64cd\u63a7\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3002", "conclusion": "\u6307\u51fa\u4e86VLA\u6a21\u578b\u5f00\u53d1\u548c\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.14949", "pdf": "https://arxiv.org/pdf/2508.14949", "abs": "https://arxiv.org/abs/2508.14949", "authors": ["Patricia Amado-Caballero", "Luis Miguel San-Jos\u00e9-Revuelta", "Mar\u00eda Dolores Aguilar-Garc\u00eda", "Jos\u00e9 Ram\u00f3n Garmendia-Leiza", "Carlos Alberola-L\u00f3pez", "Pablo Casaseca-de-la-Higuera"], "title": "XAI-Driven Spectral Analysis of Cough Sounds for Respiratory Disease Characterization", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "comment": null, "summary": "This paper proposes an eXplainable Artificial Intelligence (XAI)-driven\nmethodology to enhance the understanding of cough sound analysis for\nrespiratory disease management. We employ occlusion maps to highlight relevant\nspectral regions in cough spectrograms processed by a Convolutional Neural\nNetwork (CNN). Subsequently, spectral analysis of spectrograms weighted by\nthese occlusion maps reveals significant differences between disease groups,\nparticularly in patients with COPD, where cough patterns appear more variable\nin the identified spectral regions of interest. This contrasts with the lack of\nsignificant differences observed when analyzing raw spectrograms. The proposed\napproach extracts and analyzes several spectral features, demonstrating the\npotential of XAI techniques to uncover disease-specific acoustic signatures and\nimprove the diagnostic capabilities of cough sound analysis by providing more\ninterpretable results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u5904\u7406\u54b3\u55fd\u58f0\u8c31\u56fe\uff0c\u5229\u7528\u906e\u6321\u56fe\u7a81\u51fa\u76f8\u5173\u9891\u8c31\u533a\u57df\uff0c\u63ed\u793a\u4e0d\u540c\u75be\u75c5\u7ec4\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u5f02\uff0c\u5c24\u5176\u662f\u5728COPD\u60a3\u8005\u4e2d\u3002", "motivation": "\u52a8\u673a\u662f\u901a\u8fc7XAI\u6280\u672f\u63d0\u5347\u54b3\u55fd\u58f0\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u547c\u5438\u7cfb\u7edf\u75be\u75c5\u7ba1\u7406\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528CNN\u5904\u7406\u54b3\u55fd\u58f0\u8c31\u56fe\uff0c\u5e76\u901a\u8fc7\u906e\u6321\u56fe\u6807\u8bb0\u91cd\u8981\u9891\u8c31\u533a\u57df\uff0c\u968f\u540e\u5206\u6790\u52a0\u6743\u540e\u7684\u58f0\u8c31\u56fe\u3002", "result": "\u7ed3\u679c\u53d1\u73b0\u906e\u6321\u56fe\u80fd\u591f\u63ed\u793a\u75be\u75c5\u7ec4\uff08\u5c24\u5176\u662fCOPD\u60a3\u8005\uff09\u4e4b\u95f4\u7684\u663e\u8457\u9891\u8c31\u5dee\u5f02\uff0c\u800c\u539f\u59cb\u58f0\u8c31\u56fe\u5219\u672a\u80fd\u663e\u793a\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660eXAI\u6280\u672f\u80fd\u591f\u53d1\u73b0\u75be\u75c5\u7279\u5f02\u6027\u58f0\u5b66\u7279\u5f81\uff0c\u5e76\u63d0\u4f9b\u66f4\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u7ed3\u679c\u3002"}}
{"id": "2508.15300", "pdf": "https://arxiv.org/pdf/2508.15300", "abs": "https://arxiv.org/abs/2508.15300", "authors": ["William McDonald", "Cedric Le Gentil", "Jennifer Wakulicz", "Teresa Vidal-Calleja"], "title": "Mag-Match: Magnetic Vector Field Features for Map Matching and Registration", "categories": ["cs.RO"], "comment": "To be published in IROS: IEEE/RSJ International Conference on\n  Intelligent Robots and Systems, 2025", "summary": "Map matching and registration are essential tasks in robotics for\nlocalisation and integration of multi-session or multi-robot data. Traditional\nmethods rely on cameras or LiDARs to capture visual or geometric information\nbut struggle in challenging conditions like smoke or dust. Magnetometers, on\nthe other hand, detect magnetic fields, revealing features invisible to other\nsensors and remaining robust in such environments. In this paper, we introduce\nMag-Match, a novel method for extracting and describing features in 3D magnetic\nvector field maps to register different maps of the same area. Our feature\ndescriptor, based on higher-order derivatives of magnetic field maps, is\ninvariant to global orientation, eliminating the need for gravity-aligned\nmapping. To obtain these higher-order derivatives map-wide given point-wise\nmagnetometer data, we leverage a physics-informed Gaussian Process to perform\nefficient and recursive probabilistic inference of both the magnetic field and\nits derivatives. We evaluate Mag-Match in simulated and real-world experiments\nagainst a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,\nand robot-to-robot transformations - even without initial gravitational\nalignment.", "AI": {"tldr": "Mag-Match\u662f\u4e00\u79cd\u5229\u75283D\u78c1\u573a\u56fe\u7279\u5f81\u8fdb\u884c\u5730\u56fe\u5339\u914d\u4e0e\u6ce8\u518c\u7684\u65b0\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u6076\u52a3\u73af\u5883\u5982\u70df\u96fe\u6216\u7070\u5c18\uff0c\u65e0\u9700\u91cd\u529b\u5bf9\u9f50\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6444\u50cf\u5934\u6216\u6fc0\u5149\u96f7\u8fbe\uff0c\u5728\u6076\u52a3\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\uff1b\u78c1\u529b\u8ba1\u80fd\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u7a33\u5b9a\u5de5\u4f5c\u5e76\u63d0\u4f9b\u72ec\u7279\u7279\u5f81\u3002", "method": "\u57fa\u4e8e\u78c1\u573a\u56fe\u7684\u9ad8\u9636\u5bfc\u6570\u63d0\u53d6\u7279\u5f81\uff0c\u5229\u7528\u7269\u7406\u4fe1\u606f\u9ad8\u65af\u8fc7\u7a0b\u8fdb\u884c\u9ad8\u6548\u63a8\u65ad\u3002", "result": "\u5728\u6a21\u62df\u548c\u5b9e\u9645\u5b9e\u9a8c\u4e2d\uff0cMag-Match\u4f18\u4e8e\u57fa\u4e8eSIFT\u7684\u65b9\u6cd5\uff0c\u80fd\u5b9e\u73b0\u7cbe\u786e\u7684\u5730\u56fe\u8f6c\u6362\u3002", "conclusion": "Mag-Match\u4e3a\u6076\u52a3\u73af\u5883\u4e2d\u7684\u5730\u56fe\u5339\u914d\u548c\u6ce8\u518c\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15058", "pdf": "https://arxiv.org/pdf/2508.15058", "abs": "https://arxiv.org/abs/2508.15058", "authors": ["Kaiqiang Lin", "Mohamed-Slim Alouini"], "title": "Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer", "categories": ["cs.NI", "eess.SP"], "comment": "8 pages, 4 figures, 2 tables, submitted to IEEE WCM", "summary": "Wireless underground sensor networks (WUSNs), which enable real-time sensing\nand monitoring of underground resources by underground devices (UDs), hold\ngreat promise for delivering substantial social and economic benefits across\nvarious verticals. However, due to the harsh subterranean environment, scarce\nnetwork resources, and restricted communication coverage, WUSNs face\nsignificant challenges in supporting sustainable massive machine-type\ncommunications (mMTC), particularly in remote, disaster-stricken, and\nhard-to-reach areas. To complement this, we conceptualize in this study a novel\nspace-air-ground-underground integrated network (SAGUIN) architecture that\nseamlessly incorporates satellite systems, aerial platforms, terrestrial\nnetworks, and underground communications. On this basis, we integrate LoRaWAN\nand wireless energy transfer (WET) technologies into SAGUIN to enable\nsustainable subterranean mMTC. We begin by reviewing the relevant technical\nbackground and presenting the architecture and implementation challenges of\nSAGUIN. Then, we employ simulations to model a remote underground pipeline\nmonitoring scenario to evaluate the feasibility and performance of SAGUIN based\non LoRaWAN and WET technologies, focusing on the effects of parameters such as\nunderground conditions, time allocation, LoRaWAN spread factor (SF)\nconfigurations, reporting periods, and harvested energy levels. Our results\nevidence that the proposed SAGUIN system, when combined with the derived time\nallocation strategy and an appropriate SF, can effectively extend the\noperational lifetime of UDs, thereby facilitating sustainable subterranean\nmMTC. Finally, we pinpoint key challenges and future research directions for\nSAGUIN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7a7a\u95f4-\u7a7a\u4e2d-\u5730\u9762-\u5730\u4e0b\u4e00\u4f53\u5316\u7f51\u7edc\uff08SAGUIN\uff09\u67b6\u6784\uff0c\u7ed3\u5408LoRaWAN\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\uff0c\u4ee5\u652f\u6301\u53ef\u6301\u7eed\u7684\u5730\u4e0b\u5927\u89c4\u6a21\u673a\u5668\u901a\u4fe1\uff08mMTC\uff09\u3002\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5730\u4e0b\u7ba1\u9053\u76d1\u6d4b\u4e2d\u7684\u53ef\u884c\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u5730\u4e0b\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\uff08WUSNs\uff09\u5728\u6076\u52a3\u73af\u5883\u4e0b\u652f\u6301\u5927\u89c4\u6a21\u673a\u5668\u901a\u4fe1\uff08mMTC\uff09\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u504f\u8fdc\u6216\u707e\u5bb3\u5730\u533a\u3002", "method": "\u7ed3\u5408\u536b\u661f\u7cfb\u7edf\u3001\u7a7a\u4e2d\u5e73\u53f0\u3001\u5730\u9762\u7f51\u7edc\u548c\u5730\u4e0b\u901a\u4fe1\uff0c\u63d0\u51faSAGUIN\u67b6\u6784\uff0c\u5e76\u96c6\u6210LoRaWAN\u548c\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\u3002\u901a\u8fc7\u4eff\u771f\u8bc4\u4f30\u5173\u952e\u53c2\u6570\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u63d0\u51fa\u7684SAGUIN\u7cfb\u7edf\u7ed3\u5408\u65f6\u95f4\u5206\u914d\u7b56\u7565\u548c\u9002\u5f53\u7684LoRaWAN\u6269\u9891\u56e0\u5b50\uff0c\u53ef\u663e\u8457\u5ef6\u957f\u5730\u4e0b\u8bbe\u5907\u5bff\u547d\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u5730\u4e0bmMTC\u3002", "conclusion": "SAGUIN\u67b6\u6784\u6709\u671b\u89e3\u51b3\u5730\u4e0b\u901a\u4fe1\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u4f46\u4ecd\u9700\u514b\u670d\u6280\u672f\u6311\u6218\u5e76\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.15354", "pdf": "https://arxiv.org/pdf/2508.15354", "abs": "https://arxiv.org/abs/2508.15354", "authors": ["Chaoran Xiong", "Yulong Huang", "Fangwen Yu", "Changhao Chen", "Yue Wang", "Songpengchen Xia", "Ling Pei"], "title": "Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey", "categories": ["cs.RO"], "comment": null, "summary": "Embodied navigation (EN) advances traditional navigation by enabling robots\nto perform complex egocentric tasks through sensing, social, and motion\nintelligence. In contrast to classic methodologies that rely on explicit\nlocalization and pre-defined maps, EN leverages egocentric perception and\nhuman-like interaction strategies. This survey introduces a comprehensive EN\nformulation structured into five stages: Transition, Observation, Fusion,\nReward-policy construction, and Action (TOFRA). The TOFRA framework serves to\nsynthesize the current state of the art, provide a critical review of relevant\nplatforms and evaluation metrics, and identify critical open research\nchallenges. A list of studies is available at\nhttps://github.com/Franky-X/Awesome-Embodied-Navigation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u79f0\u4e3aTOFRA\u7684\u4e94\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u7efc\u5408\u548c\u5206\u6790\u5177\u8eab\u5bfc\u822a\uff08EN\uff09\u7684\u5f53\u524d\u7814\u7a76\u72b6\u6001\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u5bfc\u822a\u65b9\u6cd5\u4f9d\u8d56\u663e\u5f0f\u5b9a\u4f4d\u548c\u9884\u5b9a\u4e49\u5730\u56fe\uff0c\u5177\u8eab\u5bfc\u822a\u5219\u901a\u8fc7\u611f\u77e5\u3001\u793e\u4ea4\u548c\u8fd0\u52a8\u667a\u80fd\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5316\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86TOFRA\u6846\u67b6\uff08Transition\u3001Observation\u3001Fusion\u3001Reward-policy construction\u548cAction\uff09\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u548c\u5206\u6790EN\u7814\u7a76\u3002", "result": "\u7efc\u8ff0\u4e86\u5f53\u524dEN\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5305\u62ec\u5e73\u53f0\u3001\u8bc4\u4ef7\u6807\u51c6\u548c\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "TOFRA\u6846\u67b6\u4e3aEN\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u6790\u89c6\u89d2\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.15225", "pdf": "https://arxiv.org/pdf/2508.15225", "abs": "https://arxiv.org/abs/2508.15225", "authors": ["Yi Yuan", "Joseph Van Duyn", "Runze Yan", "Zhuoyi Huang", "Sulaiman Vesal", "Sergey Plis", "Xiao Hu", "Gloria Hyunjung Kwak", "Ran Xiao", "Alex Fedorov"], "title": "Learning ECG Representations via Poly-Window Contrastive Learning", "categories": ["cs.LG", "eess.SP"], "comment": "This work has been accepted for publication in IEEE-EMBS\n  International Conference on Biomedical and Health Informatics 2025. The final\n  published version will be available via IEEE Xplore", "summary": "Electrocardiogram (ECG) analysis is foundational for cardiovascular disease\ndiagnosis, yet the performance of deep learning models is often constrained by\nlimited access to annotated data. Self-supervised contrastive learning has\nemerged as a powerful approach for learning robust ECG representations from\nunlabeled signals. However, most existing methods generate only pairwise\naugmented views and fail to leverage the rich temporal structure of ECG\nrecordings. In this work, we present a poly-window contrastive learning\nframework. We extract multiple temporal windows from each ECG instance to\nconstruct positive pairs and maximize their agreement via statistics. Inspired\nby the principle of slow feature analysis, our approach explicitly encourages\nthe model to learn temporally invariant and physiologically meaningful features\nthat persist across time. We validate our approach through extensive\nexperiments and ablation studies on the PTB-XL dataset. Our results demonstrate\nthat poly-window contrastive learning consistently outperforms conventional\ntwo-view methods in multi-label superclass classification, achieving higher\nAUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to\nfour times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock\npre-training time reduction. Despite processing multiple windows per sample, we\nachieve a significant reduction in the number of training epochs and total\ncomputation time, making our method practical for training foundational models.\nThrough extensive ablations, we identify optimal design choices and demonstrate\nrobustness across various hyperparameters. These findings establish poly-window\ncontrastive learning as a highly efficient and scalable paradigm for automated\nECG analysis and provide a promising general framework for self-supervised\nrepresentation learning in biomedical time-series data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u7a97\u53e3\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u6bcf\u4e2aECG\u5b9e\u4f8b\u4e2d\u63d0\u53d6\u591a\u4e2a\u65f6\u95f4\u7a97\u53e3\u6784\u5efa\u6b63\u5bf9\uff0c\u5e76\u6700\u5927\u5316\u5b83\u4eec\u7684\u7edf\u8ba1\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u591a\u6807\u7b7e\u8d85\u7c7b\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "ECG\u5206\u6790\u662f\u5fc3\u8840\u7ba1\u75be\u75c5\u8bca\u65ad\u7684\u57fa\u7840\uff0c\u4f46\u6df1\u5ea6\u6a21\u578b\u7531\u4e8e\u6807\u6ce8\u6570\u636e\u6709\u9650\u800c\u6027\u80fd\u53d7\u9650\u3002\u73b0\u6709\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4ec5\u751f\u6210\u6210\u5bf9\u589e\u5f3a\u89c6\u56fe\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528ECG\u7684\u4e30\u5bcc\u65f6\u95f4\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u591a\u7a97\u53e3\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u4eceECG\u5b9e\u4f8b\u4e2d\u63d0\u53d6\u591a\u4e2a\u65f6\u95f4\u7a97\u53e3\u6784\u5efa\u6b63\u5bf9\uff0c\u6700\u5927\u5316\u5176\u7edf\u8ba1\u4e00\u81f4\u6027\uff0c\u5e76\u501f\u52a9\u6162\u7279\u5f81\u5206\u6790\u5b66\u4e60\u8de8\u65f6\u95f4\u7684\u7a33\u5b9a\u7279\u5f81\u3002", "result": "\u5728PTB-XL\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6807\u7b7e\u8d85\u7c7b\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u53cc\u89c6\u56fe\u65b9\u6cd5\uff08AUROC 0.891 vs. 0.888\uff0cF1 0.680 vs. 0.679\uff09\uff0c\u540c\u65f6\u51cf\u5c11\u9884\u8bad\u7ec3\u65f6\u95f4\uff0814.8%\uff09\u548c\u8f6e\u6b21\uff0832 vs. 128\uff09\u3002", "conclusion": "\u591a\u7a97\u53e3\u5bf9\u6bd4\u5b66\u4e60\u4e3aECG\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u751f\u7269\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002"}}
{"id": "2508.15427", "pdf": "https://arxiv.org/pdf/2508.15427", "abs": "https://arxiv.org/abs/2508.15427", "authors": ["Huy Hoang Nguyen", "Johannes Huemer", "Markus Murschitz", "Tobias Glueck", "Minh Nhat Vu", "Andreas Kugi"], "title": "Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 7 figures", "summary": "The logistics and construction industries face persistent challenges in\nautomating pallet handling, especially in outdoor environments with variable\npayloads, inconsistencies in pallet quality and dimensions, and unstructured\nsurroundings. In this paper, we tackle automation of a critical step in pallet\ntransport: the pallet pick-up operation. Our work is motivated by labor\nshortages, safety concerns, and inefficiencies in manually locating and\nretrieving pallets under such conditions. We present Lang2Lift, a framework\nthat leverages foundation models for natural language-guided pallet detection\nand 6D pose estimation, enabling operators to specify targets through intuitive\ncommands such as \"pick up the steel beam pallet near the crane.\" The perception\npipeline integrates Florence-2 and SAM-2 for language-grounded segmentation\nwith FoundationPose for robust pose estimation in cluttered, multi-pallet\noutdoor scenes under variable lighting. The resulting poses feed into a motion\nplanning module for fully autonomous forklift operation. We validate Lang2Lift\non the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet\nsegmentation accuracy on a real-world test dataset. Timing and error analysis\ndemonstrate the system's robustness and confirm its feasibility for deployment\nin operational logistics and construction environments. Video demonstrations\nare available at https://eric-nguyen1402.github.io/lang2lift.github.io/", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLang2Lift\u6846\u67b6\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u6307\u5bfc\u7684\u6258\u76d8\u68c0\u6d4b\u4e0e6D\u59ff\u6001\u4f30\u8ba1\uff0c\u89e3\u51b3\u7269\u6d41\u548c\u5efa\u7b51\u884c\u4e1a\u4e2d\u6258\u76d8\u81ea\u52a8\u5316\u642c\u8fd0\u7684\u96be\u9898\u3002", "motivation": "\u52b3\u52a8\u529b\u77ed\u7f3a\u3001\u5b89\u5168\u95ee\u9898\u548c\u624b\u52a8\u64cd\u4f5c\u7684\u4f4e\u6548\u6027\u662f\u63a8\u52a8\u7814\u7a76\u7684\u4e3b\u8981\u52a8\u673a\u3002", "method": "\u7ed3\u5408Florence-2\u3001SAM-2\u548cFoundationPose\u6a21\u578b\uff0c\u5b9e\u73b0\u8bed\u8a00\u5f15\u5bfc\u7684\u6258\u76d8\u5206\u5272\u4e0e\u59ff\u6001\u4f30\u8ba1\uff0c\u5e76\u96c6\u6210\u8fd0\u52a8\u89c4\u5212\u6a21\u5757\u5b9e\u73b0\u5168\u81ea\u52a8\u53c9\u8f66\u64cd\u4f5c\u3002", "result": "\u5728\u771f\u5b9e\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u8fbe\u52300.76 mIoU\u7684\u5206\u5272\u51c6\u786e\u7387\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u90e8\u7f72\u6027\u3002", "conclusion": "Lang2Lift\u7cfb\u7edf\u5728\u590d\u6742\u5ba4\u5916\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.15639", "pdf": "https://arxiv.org/pdf/2508.15639", "abs": "https://arxiv.org/abs/2508.15639", "authors": ["Eito Kurihara", "Hideki Ochiai"], "title": "High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering", "categories": ["cs.IT", "eess.SP", "math.IT", "94A14", "E.4"], "comment": "13 pages, 13 figures", "summary": "We address a design of high-capacity and low-peak-to-average power ratio\n(PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on\nbit-interleaved coded modulation (BICM) utilizing non-equiprobable and\nnon-uniform (NENU) constellations as well as clipping and filtering (CAF). The\nproposed constellations are generated using a truncated Gaussian distribution,\nand the merging of constellation points, where the former creates a non-uniform\nconstellation (NUC), and the latter decreases the number of signal points\nwithout compromising the achievable bit-wise mutual information (BMI). Since\nthe proposed constellations are uniquely determined by only the two parameters,\neach associated with NUC and cardinality, the complexity required for the\nnumerical optimization process can be significantly low. We focus on the\nconstellation design based on one dimension, i.e., pulse amplitude modulation\n(PAM), which facilitates the reduction of demapping complexity for the BICM\nreceiver. The use of CAF at the transmitter can efficiently reduce the PAPR of\nOFDM signals; however, it introduces clipping noise that may degrade error rate\nperformance, making the application of clipping noise cancellation (CNC) at the\nreceiver essential. Therefore, we optimize the NENU constellations in the\npresence of CAF and CNC. Simulation results demonstrate that the combination of\nconstellation shaping with CAF and CNC enables BICM-OFDM systems to\nsimultaneously achieve low PAPR and high spectral efficiency over additive\nwhite Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading\nchannels. Furthermore, comparative studies confirm that the proposed system\nsignificantly outperforms the single-carrier counterpart (i.e., DFT-precoded\nBICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading\nchannels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u5747\u5300\u975e\u7b49\u6982\u7387\uff08NENU\uff09\u661f\u5ea7\u7684BICM-OFDM\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u7ed3\u5408CAF\u548cCNC\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u5bb9\u91cf\u3001\u4f4ePAPR\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3OFDM\u7cfb\u7edf\u4e2d\u9ad8\u5cf0\u5747\u6bd4\uff08PAPR\uff09\u548c\u9ad8\u9891\u8c31\u6548\u7387\u7684\u9700\u6c42\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u540c\u65f6\u63d0\u9ad8BICM\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528NENU\u661f\u5ea7\u8bbe\u8ba1\uff08\u57fa\u4e8e\u622a\u65ad\u9ad8\u65af\u5206\u5e03\u548c\u70b9\u5408\u5e76\uff09\uff0c\u7ed3\u5408CAF\u964d\u4f4ePAPR\uff0c\u5e76\u5728\u63a5\u6536\u7aef\u5f15\u5165CNC\u6d88\u9664\u88c1\u526a\u566a\u58f0\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728AWGN\u548c\u9891\u7387\u9009\u62e9\u6027\u745e\u5229\u8870\u843d\u4fe1\u9053\u4e2d\u540c\u65f6\u5b9e\u73b0\u4e86\u4f4ePAPR\u548c\u9ad8\u9891\u8c31\u6548\u7387\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u5355\u8f7d\u6ce2\u7cfb\u7edf\u3002", "conclusion": "\u7ed3\u5408NENU\u661f\u5ea7\u3001CAF\u548cCNC\u7684BICM-OFDM\u7cfb\u7edf\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u590d\u6742\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2508.15501", "pdf": "https://arxiv.org/pdf/2508.15501", "abs": "https://arxiv.org/abs/2508.15501", "authors": ["Deyu Zhang", "Xicheng Zhang", "Jiahao Li", "Tingting Long", "Xunhua Dai", "Yongjian Fu", "Jinrui Zhang", "Ju Ren", "Yaoxue Zhang"], "title": "LLM-Driven Self-Refinement for Embodied Drone Task Planning", "categories": ["cs.RO", "cs.AI"], "comment": "14pages", "summary": "We introduce SRDrone, a novel system designed for self-refinement task\nplanning in industrial-grade embodied drones. SRDrone incorporates two key\ntechnical contributions: First, it employs a continuous state evaluation\nmethodology to robustly and accurately determine task outcomes and provide\nexplanatory feedback. This approach supersedes conventional reliance on\nsingle-frame final-state assessment for continuous, dynamic drone operations.\nSecond, SRDrone implements a hierarchical Behavior Tree (BT) modification\nmodel. This model integrates multi-level BT plan analysis with a constrained\nstrategy space to enable structured reflective learning from experience.\nExperimental results demonstrate that SRDrone achieves a 44.87% improvement in\nSuccess Rate (SR) over baseline methods. Furthermore, real-world deployment\nutilizing an experience base optimized through iterative self-refinement\nattains a 96.25% SR. By embedding adaptive task refinement capabilities within\nan industrial-grade BT planning framework, SRDrone effectively integrates the\ngeneral reasoning intelligence of Large Language Models (LLMs) with the\nstringent physical execution constraints inherent to embodied drones. Code is\navailable at https://github.com/ZXiiiC/SRDrone.", "AI": {"tldr": "SRDrone\u662f\u4e00\u79cd\u7528\u4e8e\u5de5\u4e1a\u7ea7\u65e0\u4eba\u673a\u7684\u81ea\u4f18\u5316\u4efb\u52a1\u89c4\u5212\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fde\u7eed\u72b6\u6001\u8bc4\u4f30\u548c\u5206\u5c42\u884c\u4e3a\u6811\u4fee\u6539\u6a21\u578b\u663e\u8457\u63d0\u5347\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u8fde\u7eed\u52a8\u6001\u65e0\u4eba\u673a\u64cd\u4f5c\u4e2d\u4f9d\u8d56\u5355\u5e27\u6700\u7ec8\u72b6\u6001\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u65e0\u4eba\u673a\u7269\u7406\u6267\u884c\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u8fde\u7eed\u72b6\u6001\u8bc4\u4f30\u65b9\u6cd5\u548c\u5206\u5c42\u884c\u4e3a\u6811\u4fee\u6539\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u7ea7\u884c\u4e3a\u6811\u5206\u6790\u4e0e\u7ea6\u675f\u7b56\u7565\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aSRDrone\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6210\u529f\u7387\u63d0\u534744.87%\uff0c\u73b0\u5b9e\u90e8\u7f72\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u5b9e\u73b096.25%\u7684\u6210\u529f\u7387\u3002", "conclusion": "SRDrone\u6210\u529f\u5c06\u81ea\u9002\u5e94\u4efb\u52a1\u4f18\u5316\u80fd\u529b\u96c6\u6210\u5230\u5de5\u4e1a\u7ea7\u884c\u4e3a\u6811\u89c4\u5212\u6846\u67b6\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u4efb\u52a1\u6267\u884c\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2508.15663", "pdf": "https://arxiv.org/pdf/2508.15663", "abs": "https://arxiv.org/abs/2508.15663", "authors": ["Nikita Kachaev", "Andrei Spiridonov", "Andrey Gorodetsky", "Kirill Muravyev", "Nikita Oskolkov", "Aditya Narendra", "Vlad Shakhuro", "Dmitry Makarov", "Aleksandr I. Panov", "Polina Fedotova", "Alexey K. Kovalev"], "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Benchmarks are crucial for evaluating progress in robotics and embodied AI.\nHowever, a significant gap exists between benchmarks designed for high-level\nlanguage instruction following, which often assume perfect low-level execution,\nand those for low-level robot control, which rely on simple, one-step commands.\nThis disconnect prevents a comprehensive evaluation of integrated systems where\nboth task planning and physical execution are critical. To address this, we\npropose Kitchen-R, a novel benchmark that unifies the evaluation of task\nplanning and low-level control within a simulated kitchen environment. Built as\na digital twin using the Isaac Sim simulator and featuring more than 500\ncomplex language instructions, Kitchen-R supports a mobile manipulator robot.\nWe provide baseline methods for our benchmark, including a task-planning\nstrategy based on a vision-language model and a low-level control policy based\non diffusion policy. We also provide a trajectory collection system. Our\nbenchmark offers a flexible framework for three evaluation modes: independent\nassessment of the planning module, independent assessment of the control\npolicy, and, crucially, an integrated evaluation of the whole system. Kitchen-R\nbridges a key gap in embodied AI research, enabling more holistic and realistic\nbenchmarking of language-guided robotic agents.", "AI": {"tldr": "Kitchen-R\u662f\u4e00\u4e2a\u65b0\u578b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5728\u6a21\u62df\u53a8\u623f\u73af\u5883\u4e2d\u7edf\u4e00\u8bc4\u4f30\u4efb\u52a1\u89c4\u5212\u548c\u4f4e\u7ea7\u63a7\u5236\uff0c\u5f25\u8865\u4e86\u9ad8\u5c42\u6b21\u8bed\u8a00\u6307\u4ee4\u548c\u4f4e\u5c42\u6b21\u673a\u5668\u4eba\u63a7\u5236\u4e4b\u95f4\u7684\u8bc4\u4f30\u9e3f\u6c9f\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\u8981\u4e48\u5173\u6ce8\u9ad8\u5c42\u6b21\u8bed\u8a00\u6307\u4ee4\uff0c\u5047\u8bbe\u4f4e\u7ea7\u6267\u884c\u5b8c\u7f8e\uff1b\u8981\u4e48\u5173\u6ce8\u4f4e\u7ea7\u63a7\u5236\uff0c\u4ec5\u4f7f\u7528\u7b80\u5355\u7684\u4e00\u6b65\u6307\u4ee4\u3002\u8fd9\u79cd\u5206\u79bb\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u4efb\u52a1\u89c4\u5212\u548c\u7269\u7406\u6267\u884c\u7ed3\u5408\u7684\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8eIsaac Sim\u6a21\u62df\u5668\u6784\u5efaKitchen-R\uff0c\u63d0\u4f9b500\u591a\u4e2a\u590d\u6742\u8bed\u8a00\u6307\u4ee4\uff0c\u652f\u6301\u79fb\u52a8\u673a\u68b0\u81c2\u673a\u5668\u4eba\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4efb\u52a1\u89c4\u5212\u548c\u57fa\u4e8e\u6269\u6563\u7b56\u7565\u7684\u4f4e\u7ea7\u63a7\u5236\u65b9\u6cd5\u3002", "result": "Kitchen-R\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u8bc4\u4f30\u6a21\u5f0f\uff0c\u53ef\u72ec\u7acb\u6216\u96c6\u6210\u8bc4\u4f30\u89c4\u5212\u548c\u63a7\u5236\u7cfb\u7edf\uff0c\u586b\u8865\u4e86\u5177\u8eabAI\u7814\u7a76\u7684\u7a7a\u767d\u3002", "conclusion": "Kitchen-R\u4e3a\u8bed\u8a00\u5f15\u5bfc\u7684\u673a\u5668\u4eba\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u548c\u73b0\u5b9e\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2508.15669", "pdf": "https://arxiv.org/pdf/2508.15669", "abs": "https://arxiv.org/abs/2508.15669", "authors": ["Annie S. Chen", "Philemon Brakel", "Antonia Bronars", "Annie Xie", "Sandy Huang", "Oliver Groth", "Maria Bauza", "Markus Wulfmeier", "Nicolas Heess", "Dushyant Rao"], "title": "Exploiting Policy Idling for Dexterous Manipulation", "categories": ["cs.RO", "cs.LG", "68T40", "I.2.9"], "comment": "A similar version to this paper was accepted at IROS 2025", "summary": "Learning-based methods for dexterous manipulation have made notable progress\nin recent years. However, learned policies often still lack reliability and\nexhibit limited robustness to important factors of variation. One failure\npattern that can be observed across many settings is that policies idle, i.e.\nthey cease to move beyond a small region of states when they reach certain\nstates. This policy idling is often a reflection of the training data. For\ninstance, it can occur when the data contains small actions in areas where the\nrobot needs to perform high-precision motions, e.g., when preparing to grasp an\nobject or object insertion. Prior works have tried to mitigate this phenomenon\ne.g. by filtering the training data or modifying the control frequency.\nHowever, these approaches can negatively impact policy performance in other\nways. As an alternative, we investigate how to leverage the detectability of\nidling behavior to inform exploration and policy improvement. Our approach,\nPause-Induced Perturbations (PIP), applies perturbations at detected idling\nstates, thus helping it to escape problematic basins of attraction. On a range\nof challenging simulated dual-arm tasks, we find that this simple approach can\nalready noticeably improve test-time performance, with no additional\nsupervision or training. Furthermore, since the robot tends to idle at critical\npoints in a movement, we also find that learning from the resulting episodes\nleads to better iterative policy improvement compared to prior approaches. Our\nperturbation strategy also leads to a 15-35% improvement in absolute success\nrate on a real-world insertion task that requires complex multi-finger\nmanipulation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPause-Induced Perturbations (PIP)\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u6270\u52a8\u7b56\u7565\u7684\u505c\u6ede\u72b6\u6001\u6765\u63d0\u5347\u5b66\u4e60\u7684\u7075\u5de7\u64cd\u4f5c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5b66\u4e60\u7b56\u7565\u5728\u7075\u5de7\u64cd\u4f5c\u4e2d\u5e38\u56e0\u8bad\u7ec3\u6570\u636e\u95ee\u9898\u5bfc\u81f4\u7b56\u7565\u505c\u6ede\uff0c\u5f71\u54cd\u6027\u80fd\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u989d\u5916\u76d1\u7763\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u68c0\u6d4b\u505c\u6ede\u72b6\u6001\u5e76\u65bd\u52a0\u6270\u52a8\uff0c\u5e2e\u52a9\u7b56\u7565\u8df3\u51fa\u5438\u5f15\u76c6\uff0c\u4ece\u800c\u63d0\u5347\u7b56\u7565\u6027\u80fd\u3002", "result": "\u5728\u6a21\u62df\u548c\u73b0\u5b9e\u4efb\u52a1\u4e2d\uff0cPIP\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5c24\u5176\u662f\u73b0\u5b9e\u63d2\u5165\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u63d0\u9ad8\u4e8615-35%\u3002", "conclusion": "PIP\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u6270\u52a8\u505c\u6ede\u72b6\u6001\u663e\u8457\u63d0\u5347\u7b56\u7565\u6027\u80fd\u3002"}}
{"id": "2508.15732", "pdf": "https://arxiv.org/pdf/2508.15732", "abs": "https://arxiv.org/abs/2508.15732", "authors": ["Gargi Das", "Daegyun Choi", "Donghoon Kim"], "title": "Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "17 pages, 7 figures, 2025 AAS/AIAA Astrodynamics Specialist\n  Conference", "summary": "This study proposes a dynamic coupling-informed trajectory optimization\nalgorithm for free-floating space manipulator systems (SMSs). Dynamic coupling\nbetween the base and the manipulator arms plays a critical role in influencing\nthe system's behavior. While prior research has predominantly focused on\nminimizing this coupling, often overlooking its potential advantages, this work\ninvestigates how dynamic coupling can instead be leveraged to improve\ntrajectory planning. Singular value decomposition (SVD) of the dynamic coupling\nmatrix is employed to identify the dominant components governing coupling\nbehavior. A quantitative metric is then formulated to characterize the strength\nand directionality of the coupling and is incorporated into a trajectory\noptimization framework. To assess the feasibility of the optimized trajectory,\na sliding mode control-based tracking controller is designed to generate the\nrequired joint torque inputs. Simulation results demonstrate that explicitly\naccounting for dynamic coupling in trajectory planning enables more informed\nand potentially more efficient operation, offering new directions for the\ncontrol of free-floating SMSs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u8026\u5408\u7684\u8f68\u8ff9\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u81ea\u7531\u6d6e\u52a8\u7a7a\u95f4\u673a\u68b0\u81c2\u7cfb\u7edf\uff08SMSs\uff09\uff0c\u901a\u8fc7\u5229\u7528\u52a8\u6001\u8026\u5408\u63d0\u9ad8\u8f68\u8ff9\u89c4\u5212\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u52a8\u6001\u8026\u5408\u5bf9\u81ea\u7531\u6d6e\u52a8SMSs\u7684\u5f71\u54cd\uff0c\u800c\u975e\u4f20\u7edf\u7684\u6700\u5c0f\u5316\u8026\u5408\uff0c\u4ece\u800c\u53d1\u73b0\u8026\u5408\u5728\u8f68\u8ff9\u4f18\u5316\u4e2d\u7684\u6f5c\u5728\u4f18\u52bf\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u52a8\u6001\u8026\u5408\u77e9\u9635\u7684\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u8bc6\u522b\u4e3b\u5bfc\u8026\u5408\u884c\u4e3a\u7684\u6210\u5206\uff0c\u5e76\u8bbe\u8ba1\u5b9a\u91cf\u6307\u6807\u5c06\u5176\u7eb3\u5165\u8f68\u8ff9\u4f18\u5316\u6846\u67b6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8003\u8651\u52a8\u6001\u8026\u5408\u7684\u8f68\u8ff9\u89c4\u5212\u80fd\u5e26\u6765\u66f4\u9ad8\u6548\u7684\u64cd\u4f5c\uff0c\u4e3aSMSs\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u52a8\u6001\u8026\u5408\u53ef\u4ee5\u88ab\u6709\u6548\u5229\u7528\uff0c\u4f18\u5316\u8f68\u8ff9\u89c4\u5212\uff0c\u4e3a\u81ea\u7531\u6d6e\u52a8SMSs\u7684\u63a7\u5236\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.15755", "pdf": "https://arxiv.org/pdf/2508.15755", "abs": "https://arxiv.org/abs/2508.15755", "authors": ["Jie Xu", "Eric Heiden", "Iretiayo Akinola", "Dieter Fox", "Miles Macklin", "Yashraj Narang"], "title": "Neural Robot Dynamics", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Accurate and efficient simulation of modern robots remains challenging due to\ntheir high degrees of freedom and intricate mechanisms. Neural simulators have\nemerged as a promising alternative to traditional analytical simulators,\ncapable of efficiently predicting complex dynamics and adapting to real-world\ndata; however, existing neural simulators typically require\napplication-specific training and fail to generalize to novel tasks and/or\nenvironments, primarily due to inadequate representations of the global state.\nIn this work, we address the problem of learning generalizable neural\nsimulators for robots that are structured as articulated rigid bodies. We\npropose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models\nfor predicting future states for articulated rigid bodies under contact\nconstraints. NeRD uniquely replaces the low-level dynamics and contact solvers\nin an analytical simulator and employs a robot-centric and spatially-invariant\nsimulation state representation. We integrate the learned NeRD models as an\ninterchangeable backend solver within a state-of-the-art robotics simulator. We\nconduct extensive experiments to show that the NeRD simulators are stable and\naccurate over a thousand simulation steps; generalize across tasks and\nenvironment configurations; enable policy learning exclusively in a neural\nengine; and, unlike most classical simulators, can be fine-tuned from\nreal-world data to bridge the gap between simulation and reality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeRD\u7684\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u4eff\u771f\u5668\uff0c\u7528\u4e8e\u9ad8\u6548\u6a21\u62df\u673a\u5668\u4eba\u52a8\u6001\uff0c\u5c24\u5176\u662f\u5173\u8282\u521a\u6027\u4f53\uff0c\u5177\u6709\u66f4\u597d\u7684\u901a\u7528\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u4eba\u9ad8\u81ea\u7531\u5ea6\u548c\u590d\u6742\u673a\u5236\u5bfc\u81f4\u4f20\u7edf\u6a21\u62df\u5668\u96be\u4ee5\u51c6\u786e\u9ad8\u6548\u6a21\u62df\uff0c\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u5668\u867d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u7528\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faNeRD\uff0c\u901a\u8fc7\u5b66\u4e60\u673a\u5668\u4eba\u4e13\u7528\u52a8\u6001\u6a21\u578b\uff0c\u66ff\u4ee3\u4f20\u7edf\u6a21\u62df\u5668\u4e2d\u7684\u4f4e\u5c42\u52a8\u529b\u5b66\u548c\u63a5\u89e6\u6c42\u89e3\u5668\uff0c\u91c7\u7528\u673a\u5668\u4eba\u4e2d\u5fc3\u548c\u7a7a\u95f4\u4e0d\u53d8\u7684\u6a21\u62df\u72b6\u6001\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660eNeRD\u5728\u5343\u6b65\u6a21\u62df\u4e2d\u7a33\u5b9a\u51c6\u786e\uff0c\u53ef\u8de8\u4efb\u52a1\u548c\u73af\u5883\u901a\u7528\uff0c\u652f\u6301\u7eaf\u795e\u7ecf\u5f15\u64ce\u7b56\u7565\u5b66\u4e60\uff0c\u5e76\u80fd\u901a\u8fc7\u73b0\u5b9e\u6570\u636e\u5fae\u8c03\u7f29\u5c0f\u4eff\u771f\u4e0e\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "conclusion": "NeRD\u4e3a\u673a\u5668\u4eba\u52a8\u6001\u6a21\u62df\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u901a\u7528\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63a8\u52a8\u673a\u5668\u4eba\u4eff\u771f\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.14926", "pdf": "https://arxiv.org/pdf/2508.14926", "abs": "https://arxiv.org/abs/2508.14926", "authors": ["Dianzhao Li", "Ostap Okhrin"], "title": "Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous vehicles hold great promise for reducing traffic fatalities and\nimproving transportation efficiency, yet their widespread adoption hinges on\nembedding robust ethical reasoning into routine and emergency maneuvers. Here,\nwe present a hierarchical Safe Reinforcement Learning (Safe RL) framework that\nexplicitly integrates moral considerations with standard driving objectives. At\nthe decision level, a Safe RL agent is trained using a composite ethical risk\ncost, combining collision probability and harm severity, to generate high-level\nmotion targets. A dynamic Prioritized Experience Replay mechanism amplifies\nlearning from rare but critical, high-risk events. At the execution level,\npolynomial path planning coupled with Proportional-Integral-Derivative (PID)\nand Stanley controllers translates these targets into smooth, feasible\ntrajectories, ensuring both accuracy and comfort. We train and validate our\napproach on rich, real-world traffic datasets encompassing diverse vehicles,\ncyclists, and pedestrians, and demonstrate that it outperforms baseline methods\nin reducing ethical risk and maintaining driving performance. To our knowledge,\nthis is the first study of ethical decision-making for autonomous vehicles via\nSafe RL in real-world scenarios. Our results highlight the potential of\ncombining formal control theory and data-driven learning to advance ethically\naccountable autonomy in complex, human-mixed traffic environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u9053\u5fb7\u8003\u91cf\u4e0e\u6807\u51c6\u9a7e\u9a76\u76ee\u6807\uff0c\u4ee5\u51cf\u5c11\u4f26\u7406\u98ce\u9669\u5e76\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u6027\u80fd\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u867d\u7136\u80fd\u51cf\u5c11\u4ea4\u901a\u4e8b\u6545\u5e76\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u5176\u5e7f\u6cdb\u91c7\u7528\u4f9d\u8d56\u4e8e\u5728\u5e38\u89c4\u548c\u7d27\u6025\u60c5\u51b5\u4e0b\u5d4c\u5165\u7a33\u5065\u7684\u4f26\u7406\u63a8\u7406\u3002", "method": "\u91c7\u7528\u5206\u5c42Safe RL\u6846\u67b6\uff0c\u7ed3\u5408\u4f26\u7406\u98ce\u9669\u6210\u672c\u548c\u52a8\u6001\u4f18\u5148\u7ecf\u9a8c\u56de\u653e\u673a\u5236\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u8def\u5f84\u89c4\u5212\u548cPID\u3001Stanley\u63a7\u5236\u5668\u5b9e\u73b0\u8f68\u8ff9\u4f18\u5316\u3002", "result": "\u5728\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4f26\u7406\u98ce\u9669\u5e76\u4fdd\u6301\u9a7e\u9a76\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408\u5f62\u5f0f\u63a7\u5236\u7406\u8bba\u548c\u6570\u636e\u9a71\u52a8\u5b66\u4e60\uff0c\u53ef\u5728\u590d\u6742\u4eba\u8f66\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2d\u63a8\u8fdb\u4f26\u7406\u8d23\u4efb\u81ea\u52a8\u9a7e\u9a76\u3002"}}
{"id": "2508.14965", "pdf": "https://arxiv.org/pdf/2508.14965", "abs": "https://arxiv.org/abs/2508.14965", "authors": ["Hakjin Lee", "Junghoon Seo", "Jaehoon Sim"], "title": "You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation", "categories": ["cs.CV", "cs.RO"], "comment": "https://mikigom.github.io/YOPO-project-page", "summary": "Accurately recovering the full 9-DoF pose of unseen instances within specific\ncategories from a single RGB image remains a core challenge for robotics and\nautomation. Most existing solutions still rely on pseudo-depth, CAD models, or\nmulti-stage cascades that separate 2D detection from pose estimation. Motivated\nby the need for a simpler, RGB-only alternative that learns directly at the\ncategory level, we revisit a longstanding question: Can object detection and\n9-DoF pose estimation be unified with high performance, without any additional\ndata? We show that they can with our method, YOPO, a single-stage, query-based\nframework that treats category-level 9-DoF estimation as a natural extension of\n2D detection. YOPO augments a transformer detector with a lightweight pose\nhead, a bounding-box-conditioned translation module, and a 6D-aware Hungarian\nmatching cost. The model is trained end-to-end only with RGB images and\ncategory-level pose labels. Despite its minimalist design, YOPO sets a new\nstate of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%\n$\\rm{IoU}_{50}$ and 54.1% under the $10^\\circ$$10{\\rm{cm}}$ metric, surpassing\nprior RGB-only methods and closing much of the gap to RGB-D systems. The code,\nmodels, and additional qualitative results can be found on our project.", "AI": {"tldr": "YOPO\u662f\u4e00\u79cd\u5355\u9636\u6bb5\u7684\u67e5\u8be2\u6846\u67b6\uff0c\u901a\u8fc7RGB\u56fe\u50cf\u76f4\u63a5\u5b66\u4e60\u7c7b\u522b\u7ea7\u522b\u76849\u81ea\u7531\u5ea6\u59ff\u6001\u4f30\u8ba1\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709RGB\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4f2a\u6df1\u5ea6\u3001CAD\u6a21\u578b\u6216\u591a\u9636\u6bb5\u6d41\u7a0b\u7684\u95ee\u9898\uff0c\u7814\u7a76\u5982\u4f55\u4ec5\u901a\u8fc7RGB\u56fe\u50cf\u5b9e\u73b0\u9ad8\u6027\u80fd\u76849\u81ea\u7531\u5ea6\u59ff\u6001\u4f30\u8ba1\u3002", "method": "YOPO\u5728transformer\u68c0\u6d4b\u5668\u57fa\u7840\u4e0a\u589e\u52a0\u8f7b\u91cf\u7ea7\u59ff\u6001\u5934\u3001\u8fb9\u754c\u6846\u6761\u4ef6\u5e73\u79fb\u6a21\u5757\u548c6D\u611f\u77e5\u5308\u7259\u5229\u5339\u914d\u6210\u672c\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u4ec5\u9700RGB\u56fe\u50cf\u548c\u7c7b\u522b\u7ea7\u522b\u59ff\u6001\u6807\u7b7e\u3002", "result": "\u5728REAL275\u6570\u636e\u96c6\u4e0a\uff0cYOPO\u5206\u522b\u4ee579.6%\u548c54.1%\u7684\u6307\u6807\u9886\u5148\u4e8e\u73b0\u6709RGB\u65b9\u6cd5\uff0c\u7f29\u5c0f\u4e86\u4e0eRGB-D\u7cfb\u7edf\u7684\u5dee\u8ddd\u3002", "conclusion": "YOPO\u5c55\u793a\u4e86\u4ec5\u901a\u8fc7RGB\u56fe\u50cf\u5373\u53ef\u5b9e\u73b0\u9ad8\u6027\u80fd\u76849\u81ea\u7531\u5ea6\u59ff\u6001\u4f30\u8ba1\uff0c\u7b80\u5316\u4e86\u6d41\u7a0b\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.15040", "pdf": "https://arxiv.org/pdf/2508.15040", "abs": "https://arxiv.org/abs/2508.15040", "authors": ["Aakash Khandelwal", "Ranjan Mukherjee"], "title": "Discrete VHCs for Propeller Motion of a Devil-Stick using purely Impulsive Inputs", "categories": ["eess.SY", "cs.RO", "cs.SY", "math.DS"], "comment": "16 pages, 11 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "The control problem of realizing propeller motion of a devil-stick in the\nvertical plane using impulsive forces applied normal to the stick is\nconsidered. This problem is an example of underactuated robotic juggling and\nhas not been considered in the literature before. Inspired by virtual holonomic\nconstraints, the concept of discrete virtual holonomic constraints (DVHC) is\nintroduced for the first time to solve this orbital stabilization problem. At\nthe discrete instants when impulsive inputs are applied, the location of the\ncenter-of-mass of the devil-stick is specified in terms of its orientation\nangle. This yields the discrete zero dynamics (DZD), which provides conditions\nfor stable propeller motion. In the limiting case, when the rotation angle\nbetween successive applications of impulsive inputs is chosen to be arbitrarily\nsmall, the problem reduces to that of propeller motion under continuous\nforcing. A controller that enforces the DVHC, and an orbit stabilizing\ncontroller based on the impulse controlled Poincar\\'e map approach are\npresented. The efficacy of the approach to trajectory design and stabilization\nis validated through simulations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u79bb\u6563\u865a\u62df\u5b8c\u6574\u7ea6\u675f\uff08DVHC\uff09\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u89e3\u51b3\u9b54\u9b3c\u68d2\u5728\u5782\u76f4\u5e73\u9762\u4e2d\u901a\u8fc7\u8109\u51b2\u529b\u5b9e\u73b0\u7684\u87ba\u65cb\u6868\u8fd0\u52a8\u7684\u8f68\u9053\u7a33\u5b9a\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u9b54\u9b3c\u68d2\u5728\u5782\u76f4\u5e73\u9762\u4e2d\u7684\u87ba\u65cb\u6868\u8fd0\u52a8\u63a7\u5236\u95ee\u9898\uff0c\u586b\u8865\u4e86\u6587\u732e\u4e2d\u5173\u4e8e\u8fd9\u4e00\u672a\u5145\u5206\u7814\u7a76\u7684\u673a\u5668\u4eba\u6742\u6280\u95ee\u9898\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u79bb\u6563\u865a\u62df\u5b8c\u6574\u7ea6\u675f\uff08DVHC\uff09\u548c\u79bb\u6563\u96f6\u52a8\u529b\u5b66\uff08DZD\uff09\uff0c\u8bbe\u8ba1\u8f68\u9053\u7a33\u5b9a\u63a7\u5236\u5668\uff0c\u5e76\u57fa\u4e8e\u8109\u51b2\u63a7\u5236\u7684Poincar\u00e9\u6620\u5c04\u65b9\u6cd5\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8f68\u8ff9\u8bbe\u8ba1\u548c\u7a33\u5b9a\u5316\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "DVHC\u548cDZD\u4e3a\u672a\u5145\u5206\u7814\u7a76\u7684\u673a\u68b0\u7cfb\u7edf\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15119", "pdf": "https://arxiv.org/pdf/2508.15119", "abs": "https://arxiv.org/abs/2508.15119", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "title": "Open-Universe Assistance Games", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "comment": "7 pages + 2 pages references + 7 pages appendix", "summary": "Embodied AI agents must infer and act in an interpretable way on diverse\nhuman goals and preferences that are not predefined. To formalize this setting,\nwe introduce Open-Universe Assistance Games (OU-AGs), a framework where the\nagent must reason over an unbounded and evolving space of possible goals. In\nthis context, we introduce GOOD (GOals from Open-ended Dialogue), a\ndata-efficient, online method that extracts goals in the form of natural\nlanguage during an interaction with a human, and infers a distribution over\nnatural language goals. GOOD prompts an LLM to simulate users with different\ncomplex intents, using its responses to perform probabilistic inference over\ncandidate goals. This approach enables rich goal representations and\nuncertainty estimation without requiring large offline datasets. We evaluate\nGOOD in a text-based grocery shopping domain and in a text-operated simulated\nhousehold robotics environment (AI2Thor), using synthetic user profiles. Our\nmethod outperforms a baseline without explicit goal tracking, as confirmed by\nboth LLM-based and human evaluations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Open-Universe Assistance Games\uff08OU-AGs\uff09\u6846\u67b6\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aGOOD\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u7ebf\u63d0\u53d6\u548c\u63a8\u7406\u81ea\u7136\u8bed\u8a00\u76ee\u6807\uff0c\u5728\u5bf9\u8bdd\u4e2d\u9ad8\u6548\u63a8\u65ad\u7528\u6237\u590d\u6742\u610f\u56fe\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3AI\u4ee3\u7406\u5728\u5f00\u653e\u73af\u5883\u4e2d\u63a8\u65ad\u548c\u54cd\u5e94\u7528\u6237\u591a\u6837\u5316\u3001\u672a\u9884\u5b9a\u4e49\u7684\u76ee\u6807\u548c\u504f\u597d\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faGOOD\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6a21\u62df\u7528\u6237\u610f\u56fe\uff0c\u901a\u8fc7\u5176\u54cd\u5e94\u8fdb\u884c\u76ee\u6807\u7684\u6982\u7387\u63a8\u65ad\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u79bb\u7ebf\u6570\u636e\u3002", "result": "\u5728\u6587\u672c\u8d2d\u7269\u548c\u673a\u5668\u4eba\u5bb6\u5ead\u73af\u5883\u4e2d\uff0cGOOD\u4f18\u4e8e\u65e0\u663e\u5f0f\u76ee\u6807\u8ffd\u8e2a\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7LLM\u548c\u4eba\u5de5\u8bc4\u4f30\u9a8c\u8bc1\u3002", "conclusion": "GOOD\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u6570\u636e\u9700\u6c42\u4f4e\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5f00\u653e\u4e16\u754c\u4e2d\u7684\u76ee\u6807\u63a8\u7406\u548c\u4ea4\u4e92\u3002"}}
