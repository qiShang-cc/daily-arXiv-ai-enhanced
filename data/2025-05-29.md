<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 10]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.IT](#cs.IT) [Total: 2]
- [eess.IV](#eess.IV) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Gauss-Ramanujan Functions: Constructions, Properties, and Applications in Communications and Signal Processing](https://arxiv.org/abs/2505.21691)
*Sainath Bitragunta*

Main category: eess.SP

TL;DR: 本文构建了一种基于Ramanujan序列、高斯脉冲及其延迟形式的新函数，研究了其数学性质，并展示了在通信和信号处理中的应用。


<details>
  <summary>Details</summary>
Motivation: Ramanujan序列、高斯脉冲及其延迟形式的特殊性质启发了这些函数的构造。

Method: 通过结合Ramanujan序列与高斯脉冲构建GauRam函数，并分析其确定性/随机重叠和数学特性。

Result: 提出了GRM和GRSK调制方案及GauRam小波，展示了其在高效通信系统中的潜力。

Conclusion: 这些新函数和调制方案在下一代通信和信号处理中具有应用前景。

Abstract: In this article, I construct a new set of functions based on Ramanujan
sequences (RSEs), Gaussian pulse (GP), and its delayed Gaussian pulse (DGP).
The motivation for this construction is based on the special properties of
RSEs, GP, and DGP. First, I present a procedure for constructing
Gauss-Ramanujan (GauRam) functions using selected RSEs. I develop an insightful
analysis for deterministic and stochastic overlap between GP and DGP.
Specifically, I present exact and closed form approximation expressions for
delay-averaged GP and DGP overlap and then evaluate them numerically. Later, I
derive and analyze the mathematical (spectral) properties of selected GauRam
functions. I extend the analysis by analyzing the Hilbert transform of the
first-order GauRam function and validating orthogonality and its usefulness in
analytic signal representations.
  Furthermore, I present insightful applications of these functions in
communications and signal processing. Specifically, I present the
continuous-wave Gauss-Ramanujan modulation (GRM) scheme, Gauss-Ramanujan Shift
Keying (GRSK) scheme, and Gauss-Ramanujan wavelets and their analysis and
comparisons with benchmarking. The desirable properties of these novel
modulation schemes and wavelets enable their use in next-generation hybrid and
energy-efficient communication systems and signal processing.

</details>


### [2] [Theoretical Bounds for Optimized Doppler-Based Motion Detection in UHF-RFID Readers](https://arxiv.org/abs/2505.21812)
*Clemens Korn,Joerg Robert*

Main category: eess.SP

TL;DR: 这篇论文提出了一种优化的多普勒频移估计方法，用于提升UHF-RFID系统中的运动检测精度，并基于Cramer-Rao下界理论分析了运动检测的性能界限。


<details>
  <summary>Details</summary>
Motivation: 现代物流中准确检测RFID标签的运动是关键需求，但现有UHF-RFID系统的多普勒频移测量精度不足。

Method: 通过优化多普勒频移估计算法，并利用Cramer-Rao下界理论分析信号强度、持续时间和回复间隔对性能的影响。

Result: 研究揭示了多普勒运动检测的理论性能界限，为系统级优化提供了理论支持。

Conclusion: 该研究为RFID系统的设计和调优提供了性能预测工具，支持了物流中更精确的运动检测应用。

Abstract: Radio Frequency Identification (RFID) is a widely used technology for
identifying and locating objects equipped with low-cost RFID transponders
(tags). UHF (Ultra High Frequency) RFID operates in frequency bands around 900
MHz and supports communication distances of up to 15 m between the reader and
the tag. Reliable motion detection is therefore a highly relevant feature in
modern logistics - for example, to determine whether a tag is actually placed
on a conveyor belt or merely in its vicinity.
  A promising approach for accurate motion detection is the use of the Doppler
effect. Some state-of-the-art UHF-RFID readers already support Doppler shift
measurements. However, their measurement accuracy is insufficient for many
applications. In this paper, we propose an optimized method for the precise
Doppler shift estimation using existing RFID systems - an essential step toward
enabling RFID-based motion detection in future logistics. Further, we also
derive the theoretical bounds for Doppler-based motion detection in UHF-RFID
systems based on the Cramer-Rao Lower Bound. These bounds analyze the influence
of tag signal strength, signal duration, and the intervals between multiple tag
replies on the performance of motion detection and speed estimation algorithms.
In addition, we establish theoretical limits that account for hardware
constraints in current UHF-RFID readers.
  The results of this work provide valuable insights into the limitations of
Doppler-based motion detection and support system-level performance
optimization. They enable prediction of achievable performance based on reader
noise figure, aiding in the design and tuning of RFID systems.

</details>


### [3] [CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing](https://arxiv.org/abs/2505.21866)
*Guozhen Zhu,Yuqian Hu,Weihang Gao,Wei-Hsiang Wang,Beibei Wang,K. J. Ray Liu*

Main category: eess.SP

TL;DR: 一篇关于WiFi传感用于健康监测的研究，提出了大规模真实环境数据集CSI-Bench，支持多任务学习。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi传感系统在真实环境中泛化能力不足，受限于实验室环境和碎片化数据。

Method: 使用商用WiFi设备在26个室内环境收集461小时数据，包含多项任务（如跌倒检测、呼吸监测等）及多任务联合标注。

Result: 提供了标准化评估划分和基线结果，支持单任务和多任务学习的稳健模型开发。

Conclusion: CSI-Bench为可扩展、隐私保护的WiFi传感系统奠定了基础，适用于健康和以人为本的应用。

Abstract: WiFi sensing has emerged as a compelling contactless modality for human
activity monitoring by capturing fine-grained variations in Channel State
Information (CSI). Its ability to operate continuously and non-intrusively
while preserving user privacy makes it particularly suitable for health
monitoring. However, existing WiFi sensing systems struggle to generalize in
real-world settings, largely due to datasets collected in controlled
environments with homogeneous hardware and fragmented, session-based recordings
that fail to reflect continuous daily activity.
  We present CSI-Bench, a large-scale, in-the-wild benchmark dataset collected
using commercial WiFi edge devices across 26 diverse indoor environments with
35 real users. Spanning over 461 hours of effective data, CSI-Bench captures
realistic signal variability under natural conditions. It includes
task-specific datasets for fall detection, breathing monitoring, localization,
and motion source recognition, as well as a co-labeled multitask dataset with
joint annotations for user identity, activity, and proximity. To support the
development of robust and generalizable models, CSI-Bench provides standardized
evaluation splits and baseline results for both single-task and multi-task
learning. CSI-Bench offers a foundation for scalable, privacy-preserving WiFi
sensing systems in health and broader human-centric applications.

</details>


### [4] [Target Localization with Coprime Multistatic MIMO Radar via Coupled Canonical Polyadic Decomposition Based on Joint Eigenvalue Decomposition](https://arxiv.org/abs/2505.21965)
*Guo-Zhao Liao,Xiao-Feng Gong,Wei Liu,Hing Cheung So*

Main category: eess.SP

TL;DR: 论文研究了一种基于多站MIMO雷达系统的目标定位方法，采用两种互质阵列配置（L型和平面型），通过耦合张量分解模型和联合特征值分解实现高效定位，并在精度和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的目标定位方法在计算复杂度和精度上存在局限，尤其是在非正交探测波形和欠定场景下表现不佳。本文旨在通过互质阵列和张量分解技术优化这些问题。

Method: 采用互质阵列配置和耦合张量分解模型，提出基于联合特征值分解的（半）代数及优化算法，结合DOA信息计算目标最优位置。

Result: 实验表明，该方法在准确性和计算效率上优于现有张量方法，且适用于欠定场景。

Conclusion: 所提方法为复杂环境下的目标定位提供了高效且高精度的解决方案。

Abstract: This paper investigates target localization using a multistatic
multiple-input multiple-output (MIMO) radar system with two distinct coprime
array configurations: coprime L-shaped arrays and coprime planar arrays. The
observed signals are modeled as tensors that admit a coupled canonical polyadic
decomposition (C-CPD) model. For each configuration, a C-CPD method is
presented based on joint eigenvalue decomposition (J-EVD). This computational
framework includes (semi-)algebraic and optimization-based C-CPD algorithms and
target localization that fuses direction-of-arrivals (DOAs) information to
calculate the optimal position of each target. Specifically, the proposed
(semi-)algebraic methods exploit the rotational invariance of the Vandermonde
structure in coprime arrays, similar to the multiple invariance property of
\added{estimation of signal parameters via rotational invariance techniques}
(ESPRIT), which transforms the model into a J-EVD problem and reduces
computational complexity. The study also investigates the working conditions of
the algorithm to understand model identifiability. Additionally, the proposed
method does not rely on prior knowledge of non-orthogonal probing waveforms and
is effective in challenging underdetermined scenarios. Experimental results
demonstrate that our method outperforms existing tensor-based approaches in
both accuracy and computational efficiency.

</details>


### [5] [Polarforming Design with Phase Shifter Based Polarization Reconfigurable Antennas](https://arxiv.org/abs/2505.21990)
*Zijian Zhou,Jingze Ding,Rui Zhang*

Main category: eess.SP

TL;DR: 该论文提出了一种新型的可重构极化天线（PRAs），通过移相器（PSs）实现线性、圆形和一般椭圆极化，并展示了其在SISO通信系统中的性能优势。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统天线系统在极化匹配上的限制，论文提出利用PRAs进行极化重构（polarforming），以优化信号接收或发射的极化状态，从而提升通信性能。

Method: 通过移相器实现极化重构，并研究了PRAs在SISO系统中的性能表现。采用了交替优化方法，对发射端和接收端的相位偏移进行优化以最大化信噪比（SNR）。

Result: 仿真结果表明，polarforming能有效减轻通道去极化效应，并在性能上显著优于传统系统。

Conclusion: PRAs结合极化重构技术为通信系统提供了更高的灵活性和性能提升，展示了其在未来无线通信中的应用潜力。

Abstract: In this paper, we propose a new form of polarization reconfigurable antennas
(PRAs) that can form linear, circular, and general elliptical polarizations
assisted by phase shifters (PSs). With PRAs, polarforming is achieved, which
enables the antenna to shape its polarization into a desired state for aligning
with that of the received electromagnetic (EM) wave or reconfiguring that of
the transmit EM wave. To demonstrate the benefits of polarforming, we
investigate a PRA-aided single-input single-output (SISO) communication system
equipped with tunable PSs for polarization adaptation. We characterize the
achievable signal-to-noise ratio (SNR) at the receiver as a function of the
phase shifts of PS-based PRAs. Moreover, we develop an alternating optimization
approach to maximize the SNR by optimizing the phase shifts at both the
transmitter and receiver. Finally, comprehensive simulation results are
presented, which not only validate the effectiveness of polarforming in
mitigating the channel depolarization effects, but also demonstrate its
substantial performance improvement over conventional systems.

</details>


### [6] [Attention-Enhanced Prompt Decision Transformers for UAV-Assisted Communications with AoI](https://arxiv.org/abs/2505.22170)
*Chi Lu,Yiyang Ni,Zhe Wang,Xiaoli Shi,Jun Li,Shi Jin*

Main category: eess.SP

TL;DR: 论文提出了一种注意力增强的Prompt Decision Transformer（APDT）框架，用于优化无人机网络的轨迹规划和用户调度，以最小化信息的平均老化时间（AoI）并应对长期能量约束。APDT通过注意力机制、快速适应新场景的提示机制和长期能量约束的令牌辅助方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统Decision Transformer（DT）在动态资源分配中表现优越，但存在零填充导致性能下降、无法应对长期能量约束及新场景适应困难等问题。为解决这些限制，作者提出APDT框架。

Method: APDT引入了注意力机制以处理变化的用户数量、基于短轨迹演示的提示机制用于快速适应新场景，以及令牌辅助方法来管理长期能量约束。框架先通过离线数据集预训练，再推广到新场景。

Result: 仿真表明，APDT的收敛速度是传统DT的两倍，平均AoI降低了8%。

Conclusion: APDT在无人机辅助物联网网络中显著优化了性能，适应性强且效率高，为解决动态资源分配问题提供了新思路。

Abstract: Decision Transformer (DT) has recently demonstrated strong generalizability
in dynamic resource allocation within unmanned aerial vehicle (UAV) networks,
compared to conventional deep reinforcement learning (DRL). However, its
performance is hindered due to zero-padding for varying state dimensions,
inability to manage long-term energy constraint, and challenges in acquiring
expert samples for few-shot fine-tuning in new scenarios. To overcome these
limitations, we propose an attention-enhanced prompt Decision Transformer
(APDT) framework to optimize trajectory planning and user scheduling, aiming to
minimize the average age of information (AoI) under long-term energy constraint
in UAV-assisted Internet of Things (IoT) networks. Specifically, we enhance the
convenional DT framework by incorporating an attention mechanism to accommodate
varying numbers of terrestrial users, introducing a prompt mechanism based on
short trajectory demonstrations for rapid adaptation to new scenarios, and
designing a token-assisted method to address the UAV's long-term energy
constraint. The APDT framework is first pre-trained on offline datasets and
then efficiently generalized to new scenarios. Simulations demonstrate that
APDT achieves twice faster in terms of convergence rate and reduces average AoI
by $8\%$ compared to conventional DT.

</details>


### [7] [Algorithm Unrolling-based Denoising of Multimodal Graph Signals](https://arxiv.org/abs/2505.22175)
*Hayate Kojima,Keigo Takanami,Junya Hara,Yukihiro Bandoh,Seishi Takamura,Hiroshi Higashi,Yuichi Tanaka*

Main category: eess.SP

TL;DR: 该论文提出了一种通过迭代解决信号恢复和图学习问题的多模态图信号去噪方法，结合深度算法展开技术优化参数，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态数据（如传感器网络数据）在测量点上可能捕获多种模态，且其空间和模态间存在潜在关联。这些数据常受噪声干扰，且其空间/模态关系通常未知，需要同时估计图结构并进行去噪。

Method: 提出基于双重图的信号去噪方法，将信号恢复与图学习问题迭代求解，并通过深度算法展开从训练数据中学习迭代算法的参数。

Result: 在合成和真实数据上的实验表明，该方法优于现有的基于模型和深度学习的图信号去噪方法。

Conclusion: 通过联合优化信号去噪和图学习，并结合深度算法展开，该方法显著提升了多模态图信号去噪的性能。

Abstract: We propose a denoising method of multimodal graph signals by iteratively
solving signal restoration and graph learning problems. Many complex-structured
data, i.e., those on sensor networks, can capture multiple modalities at each
measurement point, referred to as modalities. They are also assumed to have an
underlying structure or correlations in modality as well as space. Such
multimodal data are regarded as graph signals on a twofold graph and they are
often corrupted by noise. Furthermore, their spatial/modality relationships are
not always given a priori: We need to estimate twofold graphs during a
denoising algorithm. In this paper, we consider a signal denoising method on
twofold graphs, where graphs are learned simultaneously. We formulate an
optimization problem for that and parameters in an iterative algorithm are
learned from training data by unrolling the iteration with deep algorithm
unrolling. Experimental results on synthetic and real-world data demonstrate
that the proposed method outperforms existing model- and deep learning-based
graph signal denoising methods.

</details>


### [8] [Aspects of density approximation by tensor trains](https://arxiv.org/abs/2505.22218)
*Jiří Ajgl,Ondřej Straka*

Main category: eess.SP

TL;DR: 论文讨论了点质量滤波器在状态估计中的应用，重点解决了高维问题及负值污染问题，比较了二次函数与离散高斯密度的分解方法，并分析了网格插值的影响。


<details>
  <summary>Details</summary>
Motivation: 解决点质量滤波器在高维状态估计中的计算复杂度问题，并探讨负值污染、函数分解及网格插值对精度的影响。

Method: 采用张量序列分解技术降低多维数组的计算复杂度，比较了不同函数分解方法，并分析了网格插值的效果。

Result: 展示了张量序列分解能有效减轻维度灾难，探讨了相关性与张量秩的关系，并指出网格插值可能带来的误差。

Conclusion: 论文为高维状态估计提供了可行的计算优化方法，但仍需进一步解决网格插值带来的精度损失问题。

Abstract: Point-mass filters solve Bayesian recursive relations by approximating
probability density functions of a system state over grids of discrete points.
The approach suffers from the curse of dimensionality. The exponential increase
of the number of the grid points can be mitigated by application of low-rank
approximations of multidimensional arrays. Tensor train decompositions
represent individual values by the product of matrices. This paper focuses on
selected issues that are substantial in state estimation. Namely, the
contamination of the density approximations by negative values is discussed
first. Functional decompositions of quadratic functions are compared with
decompositions of discretised Gaussian densities next. In particular, the
connection of correlation with tensor train ranks is explored. Last, the
consequences of interpolating the density values from one grid to a new grid
are analysed.

</details>


### [9] [Empowering Intelligent Low-altitude Economy with Large AI Model Deployment](https://arxiv.org/abs/2505.22343)
*Zhonghao Lyu,Yulan Gao,Junting Chen,Hongyang Du,Jie Xu,Kaibin Huang,Dong In Kim*

Main category: eess.SP

TL;DR: 低空经济（LAE）结合大型人工智能模型（LAIMs）面临资源、环境和设计效率的挑战，本文提出分层架构、协同进化技术和任务导向流程，并通过案例验证。


<details>
  <summary>Details</summary>
Motivation: 解决LAIMs在LAE中部署时的资源限制、动态环境适配及传统设计低效的问题，推动低空经济智能化发展。

Method: 提出分层系统架构、关键协同技术及任务导向执行流程，结合真实案例验证框架有效性。

Result: 所提框架在真实场景中验证了可扩展性和适应性，支持高效服务交付。

Conclusion: 论文为LAIMs在LAE中的应用提供了系统性解决方案，并指出未来研究方向。

Abstract: Low-altitude economy (LAE) represents an emerging economic paradigm that
redefines commercial and social aerial activities. Large artificial
intelligence models (LAIMs) offer transformative potential to further enhance
the intelligence of LAE services. However, deploying LAIMs in LAE poses several
challenges, including the significant gap between their computational/storage
demands and the limited onboard resources of LAE entities, the mismatch between
lab-trained LAIMs and dynamic physical environments, and the inefficiencies of
traditional decoupled designs for sensing, communication, and computation. To
address these issues, we first propose a hierarchical system architecture
tailored for LAIM deployment and present representative LAE application
scenarios. Next, we explore key enabling techniques that facilitate the mutual
co-evolution of LAIMs and low-altitude systems, and introduce a task-oriented
execution pipeline for scalable and adaptive service delivery. Then, the
proposed framework is validated through real-world case studies. Finally, we
outline open challenges to inspire future research.

</details>


### [10] [Toward Fully Neuromorphic Receivers for Ultra-Power Efficient Communications](https://arxiv.org/abs/2505.22508)
*George N. Katsaros,Konstantinos Nikitopoulos*

Main category: eess.SP

TL;DR: 论文提出了一种全新的全神经形态通信接收器，直接在模拟域应用神经形态原理，实现了极低功耗的BPSK接收器与联合检测解码。


<details>
  <summary>Details</summary>
Motivation: 现有神经形态计算在通信系统中的应用多局限于孤立算法映射，且伴随传统计算开销，论文旨在探索直接从模拟域实现神经形态通信接收器的可能性。

Method: 采用神经形态原理设计BPSK接收器，通过脉冲信号实现联合检测与解码，并引入动态噪声跟踪机制调整神经参数。

Result: 实验显示该接收器在错误率上优于传统数字实现，功耗仅为微瓦级，与低分辨率ADC相当。

Conclusion: 论文展示了神经形态通信接收器的潜力，为超高效神经形态收发器的发展指明了方向。

Abstract: Neuromorphic computing, inspired by biological neural systems, has emerged as
a promising approach for ultra-energy-efficient data processing by leveraging
analog neuron structures and spike-based computation. However, its application
in communication systems remains largely unexplored, with existing efforts
mainly focused on mapping isolated communication algorithms onto spiking
networks, often accompanied by substantial, traditional computational overhead
due to transformations required to adapt problems to the spiking paradigm. In
this work, we take a fundamentally different route and, for the first time,
propose a fully neuromorphic communication receiver by applying neuromorphic
principles directly in the analog domain from the very start of the receiver
processing chain. Specifically, we examine a simple transmission scenario: a
BPSK receiver with repetition coding, and show that we can achieve joint
detection and decoding entirely through spiking signals. Our approach
demonstrates error-rate performance gains over conventional digital
realizations with power consumption on the order of microwatts, comparable with
a single very low-resolution Analog-to-Digital Converter (ADC) utilized in
digital receivers. To maintain performance under varying noise conditions, we
also introduce a novel noise-tracking mechanism that dynamically adjusts neural
parameters during transmission. Finally, we discuss the key challenges and
directions toward ultra-efficient neuromorphic transceivers.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [11] [A Comb-based Colorless Coherent WDM Transmitter](https://arxiv.org/abs/2505.21607)
*Di Che,Brian Stern,Kwangwoong Kim,Cagri Ozdilek,Timofey Shpakovsky,John D. Jost,Maxim Karpov*

Main category: physics.optics

TL;DR: 提出了一种基于梳的WDM发射器，无需解复用即可调制独立信号到梳线，并在由Kerr微梳和硅I/Q调制器阵列组成的WDM发射器中验证了其概念和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 研究目标是简化WDM发射器的设计，通过避免解复用步骤来提高效率和可扩展性。

Method: 采用Kerr微梳和硅I/Q调制器阵列构建WDM发射器，直接在梳线上调制独立信号。

Result: 实验验证了该发射器的可行性及其在WDM系统中的潜在可扩展性。

Conclusion: 该方法为WDM发射器设计提供了高效且可扩展的解决方案。

Abstract: We propose a comb-based WDM transmitter capable of modulating independent
signals to comb lines without demultiplexing them and prove its concept and
potential scalability in a WDM transmitter consisting of a Kerr microcomb and a
silicon I/Q modulator array.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism](https://arxiv.org/abs/2505.22555)
*Yanyi Qu,Haoyang Ma,Wenhui Xiong*

Main category: cs.CV

TL;DR: MultiFormer利用Transformer的时频双标记特征提取器和多头自注意力机制，通过CSI实现高精度多人姿态估计，并在公开和自采数据集中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于CSI的人体姿态估计面临多人姿态识别和CSI特征学习的挑战，研究旨在提出一个更精确的系统。

Method: 采用Transformer的时频双标记特征提取器建模CSI的子载波间相关性和时间依赖性，并通过多阶段特征融合网络（MSFN）结合解剖学约束。

Result: 在公开MM-Fi数据集和自采数据集上，MultiFormer对高动态关键点（如手腕、肘部）的估计精度显著高于现有方法。

Conclusion: MultiFormer通过创新的特征提取和融合方法，显著提升了基于CSI的姿态估计性能，尤其在复杂场景下表现优异。

Abstract: Human pose estimation based on Channel State Information (CSI) has emerged as
a promising approach for non-intrusive and precise human activity monitoring,
yet faces challenges including accurate multi-person pose recognition and
effective CSI feature learning. This paper presents MultiFormer, a wireless
sensing system that accurately estimates human pose through CSI. The proposed
system adopts a Transformer based time-frequency dual-token feature extractor
with multi-head self-attention. This feature extractor is able to model
inter-subcarrier correlations and temporal dependencies of the CSI. The
extracted CSI features and the pose probability heatmaps are then fused by
Multi-Stage Feature Fusion Network (MSFN) to enforce the anatomical
constraints. Extensive experiments conducted on on the public MM-Fi dataset and
our self-collected dataset show that the MultiFormer achieves higher accuracy
over state-of-the-art approaches, especially for high-mobility keypoints
(wrists, elbows) that are particularly difficult for previous methods to
accurately estimate.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [13] [Real-World Modeling of Computation Offloading for Neural Networks with Early Exits and Splits](https://arxiv.org/abs/2505.22149)
*Jan Danek,Zdenek Becvar,Adam Janes*

Main category: cs.NI

TL;DR: 该论文提出一种基于卷积神经网络（CNN）的计算卸载方法，通过早期退出和分割机制，将移动设备（如机器人或自动驾驶汽车）的CNN推理任务部分或全部卸载到多接入边缘计算（MEC）服务器上，显著减少了处理延迟和能耗，同时保持了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 针对移动设备（如移动机器人或自动驾驶汽车）在执行CNN推理任务时面临的高延迟和高能耗问题，研究如何通过计算卸载技术优化性能。

Method: 设计并实现了带有早期退出和分割机制的CNN，支持灵活的部分或完全卸载，通过真实场景实验评估其对处理延迟、能耗和分类准确率的影响。

Result: 实验结果表明，相比于完全本地处理，该方法能显著降低总处理延迟和能耗，同时不损害分类准确率；并进一步建立了能耗和处理延迟的实用模型。

Conclusion: 通过早期退出和分割机制的CNN计算卸载是一种有效的优化方案，能显著提升移动设备在边缘计算环境下的性能和能效。

Abstract: We focus on computation offloading of applications based on convolutional
neural network (CNN) from moving devices, such as mobile robots or autonomous
vehicles, to MultiAccess Edge Computing (MEC) servers via a mobile network. In
order to reduce overall CNN inference time, we design and implement CNN with
early exits and splits, allowing a flexible partial or full offloading of CNN
inference. Through real-world experiments, we analyze an impact of the CNN
inference offloading on the total CNN processing delay, energy consumption, and
classification accuracy in a practical road sign recognition task. The results
confirm that offloading of CNN with early exits and splits can significantly
reduce both total processing delay and energy consumption compared to full
local processing while not impairing classification accuracy. Based on the
results of real-world experiments, we derive practical models for energy
consumption and total processing delay related to offloading of CNN with early
exits and splits.

</details>


### [14] [Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments](https://arxiv.org/abs/2505.22424)
*Jingxi Lu,Wenhao Li,Jianxiong Guo,Xingjian Ding,Zhiqing Tang,Tian Wang,Weijia Jia*

Main category: cs.NI

TL;DR: 该论文提出了一种结合离线模仿学习（IL）和在线Soft Actor-Critic（SAC）优化的混合学习框架，用于解决边缘节点上微服务调度中的冷启动问题和动态资源分配挑战，实验证明其显著提升了性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备的快速增长，边缘节点上部署的容器化微服务成为一种轻量级和可扩展的解决方案。然而，现有的调度算法通常假设静态资源可用性，且忽视了容器冷启动的低效问题，因此需要一种更高效的动态调度方法。

Method: 论文首先构建了一个基于规则的专家系统生成演示数据用于行为克隆，随后设计了一个GRU增强的策略网络，通过分别编码慢变化的节点状态和快变化的微服务特征来提取多个决策间的相关性，并提出了动作选择机制以加速收敛。

Result: 实验结果表明，该方法显著加速了收敛速度并实现了更优的最终性能。与基线方法相比，算法将总目标提升了50%，收敛速度提高了70%，并且在多种边缘配置中表现出最高的稳定性和鲁棒性。

Conclusion: 论文提出的混合学习框架有效解决了微服务调度中的冷启动和动态资源分配问题，为边缘计算环境下的高效资源管理提供了新思路。

Abstract: With the rapid growth of IoT devices and their diverse workloads,
container-based microservices deployed at edge nodes have become a lightweight
and scalable solution. However, existing microservice scheduling algorithms
often assume static resource availability, which is unrealistic when multiple
containers are assigned to an edge node. Besides, containers suffer from
cold-start inefficiencies during early-stage training in currently popular
reinforcement learning (RL) algorithms. In this paper, we propose a hybrid
learning framework that combines offline imitation learning (IL) with online
Soft Actor-Critic (SAC) optimization to enable a cold-start-aware microservice
scheduling with dynamic allocation for computing resources. We first formulate
a delay-and-energy-aware scheduling problem and construct a rule-based expert
to generate demonstration data for behavior cloning. Then, a GRU-enhanced
policy network is designed in the policy network to extract the correlation
among multiple decisions by separately encoding slow-evolving node states and
fast-changing microservice features, and an action selection mechanism is given
to speed up the convergence. Extensive experiments show that our method
significantly accelerates convergence and achieves superior final performance.
Compared with baselines, our algorithm improves the total objective by $50\%$
and convergence speed by $70\%$, and demonstrates the highest stability and
robustness across various edge configurations.

</details>


### [15] [Frequency Resource Management in 6G User-Centric CFmMIMO: A Hybrid Reinforcement Learning and Metaheuristic Approach](https://arxiv.org/abs/2505.22443)
*Selina Cheggour,Valeria Loscri*

Main category: cs.NI

TL;DR: 该论文提出了一种结合强化学习和元启发式优化的混合多用户分配策略，用于6G用户中心无小区大规模MIMO（UC-CFmMIMO）网络的资源分配，以提高频谱效率、公平性和干扰抑制能力。通过对比实验，验证了该策略在真实信道条件下的优越性。


<details>
  <summary>Details</summary>
Motivation: 6G网络中的用户中心无小区大规模MIMO（UC-CFmMIMO）虽然提升了网络性能，但在密集网络中，如何在有限共享子带频谱中高效分配频率资源成为一个关键挑战。需要同时考虑频率选择性、信号传播的带宽依赖性以及动态环境下的服务质量保障。

Method: 提出了一种混合多用户分配策略，结合了强化学习（RL）和元启发式优化技术，以提高频谱效率（SE）、确保公平性并减少共享子带内的干扰。与其他方法（如生物启发的Aquila优化器AO和基于DDPG的Actor-Critic强化学习AC-RL）进行了对比。

Result: 实验结果表明，该混合策略在多目标优化中表现出色，尤其是在真实信道条件下（基于3GPP-3D信道建模框架QuaDRiGa），能够更好地平衡频谱效率、公平性和干扰问题。

Conclusion: 论文展示了AI驱动的资源分配在UC-CFmMIMO系统中的重要性，为下一代无线网络的动态资源管理提供了有效解决方案。混合方法的成功也验证了结合不同AI技术的潜力。

Abstract: As sixth-generation (6G) networks continue to evolve, AI-driven solutions are
playing a crucial role in enabling more efficient and adaptive resource
management in wireless communication. One of the key innovations in 6G is
user-centric cell-free massive Multiple-Input Multiple-Output (UC-CFmMIMO), a
paradigm that eliminates traditional cell boundaries and enhances network
performance by dynamically assigning access points (APs) to users. This
approach is particularly well-suited for vehicular networks, offering seamless,
homogeneous, ultra-reliable, and low-latency connectivity. However, in dense
networks, a key challenge lies in efficiently allocating frequency resources
within a limited shared subband spectrum while accounting for frequency
selectivity and the dependency of signal propagation on bandwidth. These
factors make resource allocation increasingly complex, especially in dynamic
environments where maintaining Quality of Service (QoS) is critical. This paper
tackles these challenges by proposing a hybrid multi-user allocation strategy
that integrates reinforcement learning (RL) and metaheuristic optimization to
enhance spectral efficiency (SE), ensure fairness, and mitigate interference
within shared subbands. To assess its effectiveness, we compare this hybrid
approach with two other methods: the bio-inspired Aquila Optimizer (AO) and
Deep Deterministic Policy Gradient (DDPG)-based Actor-Critic Reinforcement
Learning (AC-RL). Our evaluation is grounded in real-world patterns and channel
characteristics, utilizing the 3GPP-3D channel modeling framework (QuaDRiGa) to
capture realistic propagation conditions. The results demonstrate that the
proposed hybrid strategy achieves a superior balance among competing
objectives, underscoring the role of AI-driven resource allocation in advancing
UC-CFmMIMO systems for next-generation wireless networks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [16] [When Feedback Empowers the Uplink: Integrating Adaptive Coding with Wireless Power Transfer](https://arxiv.org/abs/2505.21951)
*Zijian Yang,Yulin Shao,Shaodan Ma*

Main category: cs.IT

TL;DR: 论文提出FACET框架，结合自适应反馈信道编码与无线能量传输，显著提升物联网设备能效与寿命。


<details>
  <summary>Details</summary>
Motivation: 电池受限的物联网设备面临能耗与寿命的挑战，需更高效的通信与能量管理方案。

Method: 通过反馈编码的饱和效应设计双用途机制，优化反馈精度与能量收集的权衡，提出最小化最差净能耗的算法。

Result: 仿真显示FACET将设备寿命提升近三倍，且在不同功率条件下表现稳健。

Conclusion: FACET不仅提升通信效率，还重新定义了反馈在能量受限系统中的作用。

Abstract: Energy consumption and device lifetime are critical concerns for
battery-constrained IoT devices. This paper introduces the Feedback-Aided
Coding and Energy Transfer (FACET) framework, which synergistically combines
adaptive feedback channel coding with wireless power transfer. FACET leverages
the saturation effect of feedback coding, where increasing downlink power
yields diminishing returns, to design a dual-purpose feedback mechanism that
simultaneously guides uplink coding and replenishes device energy. We
characterize the inherent tradeoff between feedback precision and harvested
power, and formulate a fairness-constrained min-max optimization problem to
minimize worst-case net energy consumption. An efficient algorithm based on
alternating optimization and Lagrangian duality is developed, with each
subproblem admitting a closed-form solution. Simulations show that FACET nearly
triples device lifetime compared to conventional feedback coding architectures,
and remains robust across a wide range of power regimes. These results suggest
that FACET not only improves communication efficiency but also redefines the
role of feedback in energy-constrained IoT systems.

</details>


### [17] [Wireless Communication for Low-Altitude Economy with UAV Swarm Enabled Two-Level Movable Antenna System](https://arxiv.org/abs/2505.22286)
*Haiquan Lu,Yong Zeng,Shaodan Ma,Bin Li,Shi Jin,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于无人机群的两级可移动天线系统，通过优化无人机群的三维布局及其天线位置，显著提升地面用户的最低可达速率。


<details>
  <summary>Details</summary>
Motivation: 无人机因其三维机动性和灵活的部署能力，成为低空经济的关键平台。本文旨在利用无人机群和可移动天线的灵活性，构建更高效的多用户通信系统。

Method: 提出了两级可移动天线系统，联合优化无人机群的3D布局、单个天线位置和接收波束成形，并在不同用户数量场景下推导了最优解。

Result: 数值结果表明，该系统通过利用两级移动性，显著优于基准方案，尤其是在多用户通信中实现了更优的信道条件。

Conclusion: 无人机群支持的可移动天线系统通过协同优化，能够显著提升通信性能，为低空经济中的多用户通信提供了高效解决方案。

Abstract: Unmanned aerial vehicle (UAV) is regarded as a key enabling platform for
low-altitude economy, due to its advantages such as 3D maneuverability,
flexible deployment, and LoS air-to-air/ground communication links. In
particular, the intrinsic high mobility renders UAV especially suitable for
operating as a movable antenna (MA) from the sky. In this paper, by exploiting
the flexible mobility of UAV swarm and antenna position adjustment of MA, we
propose a novel UAV swarm enabled two-level MA system, where UAVs not only
individually deploy a local MA array, but also form a larger-scale MA system
with their individual MA arrays via swarm coordination. We formulate a general
optimization problem to maximize the minimum achievable rate over all ground
UEs, by jointly optimizing the 3D UAV swarm placement positions, their
individual MAs' positions, and receive beamforming for different UEs. We first
consider the special case where each UAV has only one antenna, under different
scenarios of one single UE, two UEs, and arbitrary number of UEs. In
particular, for the two-UE case, we derive the optimal UAV swarm placement
positions in closed-form that achieves IUI-free communication, where the UAV
swarm forms a uniform sparse array (USA) satisfying collision avoidance
constraint. While for the general case with arbitrary number of UEs, we propose
an efficient alternating optimization algorithm to solve the formulated
non-convex optimization problem. Then, we extend the results to the case where
each UAV is equipped with multiple antennas. Numerical results verify that the
proposed low-altitude UAV swarm enabled MA system significantly outperforms
various benchmark schemes, thanks to the exploitation of two-level mobility to
create more favorable channel conditions for multi-UE communications.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [18] [Beyond 1D: Vision Transformers and Multichannel Signal Images for PPG-to-ECG Reconstruction](https://arxiv.org/abs/2505.21767)
*Xiaoyan Li,Shixin Xu,Faisal Habib,Arvind Gupta,Huaxiong Huang*

Main category: eess.IV

TL;DR: 本文提出了一种基于Vision Transformer (ViT)的四通道PPG信号表示方法，用于ECG信号的重建，通过多通道设计和自注意力机制，显著提高了重建精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有PPG到ECG的重建方法在捕捉精细波形特征方面存在不足，需要一种能够同时提取时间和生理变化特征的新方法。

Method: 采用四通道PPG信号（原始PPG、一阶差分、二阶差分和曲线下面积），结合ViT的自注意力机制，建模心跳内和心跳间的依赖关系。

Result: 实验显示，该方法在PRD和RMSE指标上分别降低了29%和15%，并在新增临床相关指标（如QRS区误差等）上表现优异。

Conclusion: 通过四通道PPG表示和ViT的结合，该方法为PPG到ECG的映射提供了更有效的特征提取和建模能力，拓展了循环信号分析的潜在应用。

Abstract: Reconstructing ECG from PPG is a promising yet challenging task. While recent
advancements in generative models have significantly improved ECG
reconstruction, accurately capturing fine-grained waveform features remains a
key challenge. To address this, we propose a novel PPG-to-ECG reconstruction
method that leverages a Vision Transformer (ViT) as the core network. Unlike
conventional approaches that rely on single-channel PPG, our method employs a
four-channel signal image representation, incorporating the original PPG, its
first-order difference, second-order difference, and area under the curve. This
multi-channel design enriches feature extraction by preserving both temporal
and physiological variations within the PPG. By leveraging the self-attention
mechanism in ViT, our approach effectively captures both inter-beat and
intra-beat dependencies, leading to more robust and accurate ECG
reconstruction. Experimental results demonstrate that our method consistently
outperforms existing 1D convolution-based approaches, achieving up to 29%
reduction in PRD and 15% reduction in RMSE. The proposed approach also produces
improvements in other evaluation metrics, highlighting its robustness and
effectiveness in reconstructing ECG signals. Furthermore, to ensure a
clinically relevant evaluation, we introduce new performance metrics, including
QRS area error, PR interval error, RT interval error, and RT amplitude
difference error. Our findings suggest that integrating a four-channel signal
image representation with the self-attention mechanism of ViT enables more
effective extraction of informative PPG features and improved modeling of
beat-to-beat variations for PPG-to-ECG mapping. Beyond demonstrating the
potential of PPG as a viable alternative for heart activity monitoring, our
approach opens new avenues for cyclic signal analysis and prediction.

</details>


### [19] [MONSTR: Model-Oriented Neutron Strain Tomographic Reconstruction](https://arxiv.org/abs/2505.22187)
*Mohammad Samin Nur Chowdhury,Shimin Tang,Singanallur V. Venkatakrishnan,Hassina Z. Bilheux,Gregery T. Buzzard,Charles A. Bouman*

Main category: eess.IV

TL;DR: 本文介绍了MONSTR算法，用于从布拉格边中子应变测量中重建二维残余应变张量，即使测量数据稀少也能实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 残余应变是影响金属部件性能的关键材料特性，现有中子布拉格边缘应变层析成像技术由于逆问题的不适定性而存在重建困难。

Method: 提出了基于多智能体共识平衡框架的MONSTR算法，结合探测器物理、层析重建过程和连续介质力学约束进行张量重建。

Result: 模拟数据验证表明，MONSTR算法在少量测量数据下仍能高质量重建应变张量。

Conclusion: MONSTR算法有效解决了中子应变层析成像的高效张量重建问题。

Abstract: Residual strain, a tensor quantity, is a critical material property that
impacts the overall performance of metal parts. Neutron Bragg edge strain
tomography is a technique for imaging residual strain that works by making
conventional hyperspectral computed tomography measurements, extracting the
average projected strain at each detector pixel, and processing the resulting
strain sinogram using a reconstruction algorithm. However, the reconstruction
is severely ill-posed as the underlying inverse problem involves inferring a
tensor at each voxel from scalar sinogram data.
  In this paper, we introduce the model-oriented neutron strain tomographic
reconstruction (MONSTR) algorithm that reconstructs the 2D residual strain
tensor from the neutron Bragg edge strain measurements. MONSTR is based on
using the multi-agent consensus equilibrium framework for the tensor
tomographic reconstruction. Specifically, we formulate the reconstruction as a
consensus solution of a collection of agents representing detector physics, the
tomographic reconstruction process, and physics-based constraints from
continuum mechanics. Using simulated data, we demonstrate high-quality
reconstruction of the strain tensor even when using very few measurements.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [20] [Automatic detection of abnormal clinical EEG: comparison of a finetuned foundation model with two deep learning models](https://arxiv.org/abs/2505.21507)
*Aurore Bussalb,François Le Gac,Guillaume Jubien,Mohamed Rahmouni,Ruggero G. Bettinardi,Pedro Marinho R. de Oliveira,Phillipe Derambure,Nicolas Gaspard,Jacques Jonas,Louis Maillard,Laurent Vercueil,Hervé Vespignani,Philippe Laval,Laurent Koessler,Ulysse Gimenez*

Main category: q-bio.NC

TL;DR: 比较三种深度学习模型在EEG数据分类中的性能，发现预训练的BioSerenity-E1表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于EEG数据量大且分析需要专业知识，开发AI工具辅助诊断。

Method: 训练或微调CNN-LSTM、Transformer和BioSerenity-E1模型，评估其在三个数据集上的表现。

Result: BioSerenity-E1在多个数据集上表现最优，最高准确率达89.19%。

Conclusion: 预训练模型在EEG自动分类中具有高效性和鲁棒性。

Abstract: Electroencephalography (EEG) is commonly used by physicians for the diagnosis
of numerous neurological disorders. Due to the large volume of EEGs requiring
interpretation and the specific expertise involved, artificial
intelligence-based tools are being developed to assist in their visual
analysis. In this paper, we compare two deep learning models (CNN-LSTM and
Transformer-based) with BioSerenity-E1, a recently proposed foundation model,
in the task of classifying entire EEG recordings as normal or abnormal. The
three models were trained or finetuned on 2,500 EEG recordings and their
performances were evaluated on two private and one public datasets: a large
multicenter dataset annotated by a single specialist (dataset A composed of n =
4,480 recordings), a small multicenter dataset annotated by three specialists
(dataset B, n = 198), and the Temple University Abnormal (TUAB) EEG corpus
evaluation dataset (n = 276). On dataset A, the three models achieved at least
86% balanced accuracy, with BioSerenity-E1 finetuned achieving the highest
balanced accuracy (89.19% [88.36-90.41]). BioSerenity-E1 finetuned also
achieved the best performance on dataset B, with 94.63% [92.32-98.12] balanced
accuracy. The models were then validated on TUAB evaluation dataset, whose
corresponding training set was not used during training, where they achieved at
least 76% accuracy. Specifically, BioSerenity-E1 finetuned outperformed the
other two models, reaching an accuracy of 82.25% [78.27-87.48]. Our results
highlight the usefulness of leveraging pre-trained models for automatic EEG
classification: enabling robust and efficient interpretation of EEG data with
fewer resources and broader applicability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [21] [From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications](https://arxiv.org/abs/2505.22311)
*Feibo Jiang,Cunhua Pan,Li Dong,Kezhi Wang,Octavia A. Dobre,Merouane Debbah*

Main category: cs.AI

TL;DR: 该教程系统介绍了大型人工智能模型（LAMs）和Agentic AI技术在6G智能通信系统中的设计与应用，旨在为研究人员提供前沿技术概览和实用指导。


<details>
  <summary>Details</summary>
Motivation: 6G通信系统面临感知与响应能力受限、扩展性不足及动态环境适应性低等挑战，需借助LAMs和Agentic AI技术提升效能。

Method: 通过综述LAMs关键技术组件、分类适用性分析，提出以LAM为中心的通信设计范式，并构建基于LAM的Agentic AI系统，涵盖多智能体框架。

Result: 提出了适用于6G通信的LAM-centric设计方法及Agentic AI系统架构，明确了其核心组件与交互机制，并探讨了实际应用场景。

Conclusion: 总结了当前研究的挑战与未来方向，以支持高效、安全、可持续的下一代智能通信系统发展。

Abstract: With the advent of 6G communications, intelligent communication systems face
multiple challenges, including constrained perception and response
capabilities, limited scalability, and low adaptability in dynamic
environments. This tutorial provides a systematic introduction to the
principles, design, and applications of Large Artificial Intelligence Models
(LAMs) and Agentic AI technologies in intelligent communication systems, aiming
to offer researchers a comprehensive overview of cutting-edge technologies and
practical guidance. First, we outline the background of 6G communications,
review the technological evolution from LAMs to Agentic AI, and clarify the
tutorial's motivation and main contributions. Subsequently, we present a
comprehensive review of the key components required for constructing LAMs. We
further categorize LAMs and analyze their applicability, covering Large
Language Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models
(LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a
LAM-centric design paradigm tailored for communications, encompassing dataset
construction and both internal and external learning approaches. Building upon
this, we develop an LAM-based Agentic AI system for intelligent communications,
clarifying its core components such as planners, knowledge bases, tools, and
memory modules, as well as its interaction mechanisms. We also introduce a
multi-agent framework with data retrieval, collaborative planning, and
reflective evaluation for 6G. Subsequently, we provide a detailed overview of
the applications of LAMs and Agentic AI in communication scenarios. Finally, we
summarize the research challenges and future directions in current studies,
aiming to support the development of efficient, secure, and sustainable
next-generation intelligent communication systems.

</details>
