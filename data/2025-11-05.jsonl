{"id": "2511.01867", "pdf": "https://arxiv.org/pdf/2511.01867", "abs": "https://arxiv.org/abs/2511.01867", "authors": ["Zhengdong Hu", "Chong Han", "Wolfgang Gerstacker", "Robert Schober"], "title": "DiffPace: Diffusion-based Plug-and-play Augmented Channel Estimation in mmWave and Terahertz Ultra-Massive MIMO Systems", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "Millimeter-wave (mmWave) and Terahertz (THz)-band communications hold great\npromise in meeting the growing data-rate demands of next-generation wireless\nnetworks, offering abundant bandwidth. To mitigate the severe path loss\ninherent to these high frequencies and reduce hardware costs, ultra-massive\nmultiple-input multiple-output (UM-MIMO) systems with hybrid beamforming\narchitectures can deliver substantial beamforming gains and enhanced spectral\nefficiency. However, accurate channel estimation (CE) in mmWave and THz UM-MIMO\nsystems is challenging due to high channel dimensionality and compressed\nobservations from a limited number of RF chains, while the hybrid near- and\nfar-field radiation patterns, arising from large array apertures and high\ncarrier frequencies, further complicate CE. Conventional compressive sensing\nbased frameworks rely on predefined sparsifying matrices, which cannot\nfaithfully capture the hybrid near-field and far-field channel structures,\nleading to degraded estimation performance. This paper introduces DiffPace, a\ndiffusion-based plug-and-play method for channel estimation. DiffPace uses a\ndiffusion model (DM) to capture the channel distribution based on the hybrid\nspherical and planar-wave (HPSM) model. By applying the plug-and-play approach,\nit leverages the DM as prior knowledge, improving CE accuracy. Moreover, DM\nperforms inference by solving an ordinary differential equation, minimizing the\nnumber of required inference steps compared with stochastic sampling method.\nExperimental results show that DiffPace achieves competitive CE performance,\nattaining -15 dB normalized mean square error (NMSE) at a signal-to-noise ratio\n(SNR) of 10 dB, with 90\\% fewer inference steps compared to state-of-the-art\nschemes, simultaneously providing high estimation precision and enhanced\ncomputational efficiency."}
{"id": "2511.01879", "pdf": "https://arxiv.org/pdf/2511.01879", "abs": "https://arxiv.org/abs/2511.01879", "authors": ["HM Shadman Tabib", "Md. Hasnaen Adil", "Ayesha Rahman", "Ahmmad Nur Swapnil", "Maoyejatun Hasana", "Ahmed Hossain Chowdhury", "A. B. M. Alim Al Islam"], "title": "Affordable EEG, Actionable Insights: An Open Dataset and Evaluation Framework for Epilepsy Patient Stratification", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Access to clinical multi-channel EEG remains limited in many regions\nworldwide. We present NEUROSKY-EPI, the first open dataset of single-channel,\nconsumer-grade EEG for epilepsy, collected in a South Asian clinical setting\nalong with rich contextual metadata. To explore its utility, we introduce\nEmbedCluster, a patient-stratification pipeline that transfers representations\nfrom EEGNet models trained on clinical data and enriches them with contextual\nautoencoder embeddings, followed by unsupervised clustering of patients based\non EEG patterns. Results show that low-cost, single-channel data can support\nmeaningful stratification. Beyond algorithmic performance, we emphasize\nhuman-centered concerns such as deployability in resource-constrained\nenvironments, interpretability for non-specialists, and safeguards for privacy,\ninclusivity, and bias. By releasing the dataset and code, we aim to catalyze\ninterdisciplinary research across health technology, human-computer\ninteraction, and machine learning, advancing the goal of affordable and\nactionable EEG-based epilepsy care."}
{"id": "2511.01882", "pdf": "https://arxiv.org/pdf/2511.01882", "abs": "https://arxiv.org/abs/2511.01882", "authors": ["Tingting Huang", "Jundong Chen", "Huanqiang Zeng", "Guofa Cai", "Haoyu Zhou"], "title": "Design of an M-ary Chaos Shift Keying System Using Combined Chaotic Systems", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": null, "summary": "In traditional chaos shift keying (CSK) communication systems, implementing\nchaotic synchronization techniques is costly but practically unattainable in a\nnoisy environment. This paper proposes a combined chaotic sequences-based\n$M$-ary CSK (CCS-$M$-CSK) system that eliminates the need for chaotic\nsynchronization. At the transmitter, the chaotic sequence is constructed by\ncombining two chaotic segments of different lengths, where each is generated\nfrom distinct chaotic systems and only one kind of chaotic segment modulates\nthe information signal. At the receiver, a deep learning unit with binary\nclassification is meticulously designed to recover information symbols. The\nsymbol error rate (SER) performance of the proposed system is evaluated over\nadditive white Gaussian noise (AWGN) and multipath Rayleigh fading channels.\nSpecifically, the impact of varying misalignment lengths on the SER performance\nof the system is analyzed when the received sequence is misaligned.\nFurthermore, the proposed system demonstrates significant performance\nadvantages over existing CSK-based systems in multipath Rayleigh fading\nchannels. These features establish CCS-$M$-CSK as a promising candidate for\nvarious applications, including Vehicle-to-Everything (V2X)."}
{"id": "2511.02006", "pdf": "https://arxiv.org/pdf/2511.02006", "abs": "https://arxiv.org/abs/2511.02006", "authors": ["Logan Schexnaydre", "Aman Poovalappil", "Darrell Robinette", "Jeremy Bos"], "title": "A Comparison of Road Grade Preview Signals from Lidar and Maps", "categories": ["eess.SP"], "comment": "8 pages, 10 figures, submitted to SAE WCX 2026", "summary": "Road grade can impact the energy efficiency, safety, and comfort associated\nwith automated vehicle control systems. Currently, control systems that attempt\nto compensate for road grade are designed with one of two assumptions. Either\nthe grade is only known once the vehicle is driving over the road segment\nthrough proprioception, or complete knowledge of the oncoming road grade is\nknown from a pre-made map. Both assumptions limit the performance of a control\nsystem, as not having a preview signal prevents proactive grade compensation,\nwhereas relying only on map data potentially subjects the control system to\nmissing or outdated information. These limits can be avoided by measuring the\noncoming grade in real-time using on-board lidar sensors. In this work, we use\npoint returns accumulated during travel to estimate the grade at each waypoint\nalong a path. The estimated grade is defined as the difference in height\nbetween the front and rear wheelbase at a given waypoint. Kalman filtering\ntechniques are used to mitigate the effects of odometry and motion uncertainty\non the grade estimates. This estimator's performance is compared to the\nmeasurements of a map created with a GNSS/INS system via a field experiment.\nWhen compared to the map-based system, the lidar-based estimator produces an\nunbiased error with a standard deviation of 0.6 degrees at an average range of\n52.7 meters. By having similar precision to map-based systems, automotive\nlidar-based grade estimation systems are shown to be a valid approach for\nmeasuring road grade when a map is unavailable or inaccurate. In using lidar as\nan input signal for grade-based control system tasks, autonomous vehicles\nachieve higher redundancy and independence in contrast to existing methods."}
{"id": "2511.01999", "pdf": "https://arxiv.org/pdf/2511.01999", "abs": "https://arxiv.org/abs/2511.01999", "authors": ["Sangyun Park", "Jin Kim", "Yuchen Cui", "Matthew S. Brown"], "title": "TRACE: Textual Reasoning for Affordance Coordinate Extraction", "categories": ["cs.RO", "cs.AI"], "comment": "ICCV 2025. *Equal contribution. {\\dag}Corresponding author", "summary": "Vision-Language Models (VLMs) struggle to translate high-level instructions\ninto the precise spatial affordances required for robotic manipulation. While\nvisual Chain-of-Thought (CoT) methods exist, they are often computationally\nintensive. In this work, we introduce TRACE (Textual Reasoning for Affordance\nCoordinate Extraction), a novel methodology that integrates a textual Chain of\nReasoning (CoR) into the affordance prediction process. We use this methodology\nto create the TRACE dataset, a large-scale collection created via an autonomous\npipeline that pairs instructions with explicit textual rationales. By\nfine-tuning a VLM on this data, our model learns to externalize its spatial\nreasoning before acting. Our experiments show that our TRACE-tuned model\nachieves state-of-the-art performance, reaching 48.1% accuracy on the primary\nWhere2Place (W2P) benchmark (a 9.6% relative improvement) and 55.0% on the more\nchallenging W2P(h) subset. Crucially, an ablation study demonstrates that\nperformance scales directly with the amount of reasoning data used, confirming\nthe CoR's effectiveness. Furthermore, analysis of the model's attention maps\nreveals an interpretable reasoning process where focus shifts dynamically\nacross reasoning steps. This work shows that training VLMs to generate a\ntextual CoR is an effective and robust strategy for enhancing the precision,\nreliability, and interpretability of VLM-based robot control. Our dataset and\ncode are available at https://github.com/jink-ucla/TRACE"}
{"id": "2511.02030", "pdf": "https://arxiv.org/pdf/2511.02030", "abs": "https://arxiv.org/abs/2511.02030", "authors": ["Brian Kim", "Justin H. Kong", "Terrence J. Moore", "Fikadu T. Dagefu"], "title": "Deep Reinforcement Learning for Multi-flow Routing in Heterogeneous Wireless Networks", "categories": ["eess.SP", "cs.NI"], "comment": null, "summary": "Due to the rapid growth of heterogeneous wireless networks (HWNs), where\ndevices with diverse communication technologies coexist, there is increasing\ndemand for efficient and adaptive multi-hop routing with multiple data flows.\nTraditional routing methods, designed for homogeneous environments, fail to\naddress the complexity introduced by links consisting of multiple technologies,\nfrequency-dependent fading, and dynamic topology changes. In this paper, we\npropose a deep reinforcement learning (DRL)-based routing framework using deep\nQ-networks (DQN) to establish routes between multiple source-destination pairs\nin HWNs by enabling each node to jointly select a communication technology, a\nsubband, and a next hop relay that maximizes the rate of the route. Our\napproach incorporates channel and interference-aware neighbor selection\napproaches to improve decision-making beyond conventional distance-based\nheuristics. We further evaluate the robustness and generalizability of the\nproposed method under varying network dynamics, including node mobility,\nchanges in node density, and the number of data flows. Simulation results\ndemonstrate that our DRL-based routing framework significantly enhances\nscalability, adaptability, and end-to-end throughput in complex HWN scenarios."}
{"id": "2511.02015", "pdf": "https://arxiv.org/pdf/2511.02015", "abs": "https://arxiv.org/abs/2511.02015", "authors": ["Jace Aldrich", "Odest Chadwicke Jenkins"], "title": "Stein-based Optimization of Sampling Distributions in Model Predictive Path Integral Control", "categories": ["cs.RO"], "comment": "8 pages, 6 figures", "summary": "This paper presents a novel method for Model Predictive Path Integral (MPPI)\ncontrol that optimizes sample generation towards an optimal trajectory through\nStein Variational Gradient Descent (SVGD). MPPI is traditionally reliant on\nrandomly sampled trajectories, often by a Gaussian distribution. The result can\nlead to sample deprivation, under-representing the space of possible\ntrajectories, and yield suboptimal results. Through introducing SVGD updates in\nbetween MPPI environment steps, we present Stein-Optimized Path-Integral\nInference (SOPPI), an MPPI/SVGD algorithm that can dynamically update noise\ndistributions at runtime to shape a more optimal representation without an\nexcessive increase in computational requirements. We demonstrate the efficacy\nof our method systems ranging from a Cart-Pole to a two-dimensional bipedal\nwalking task, indicating improved performance above standard MPPI across a\nrange of hyper-parameters and demonstrate feasibility at lower particle counts.\nWe discuss the applicability of this MPPI/SVGD method to higher\ndegree-of-freedom systems, as well as its potential to new developments in\nstate-of-the-art differentiable simulators."}
{"id": "2511.02074", "pdf": "https://arxiv.org/pdf/2511.02074", "abs": "https://arxiv.org/abs/2511.02074", "authors": ["Martín Schottlender", "Maximilian Schäfer", "Ricardo A. Veiga"], "title": "Neural Network based Distance Estimation for Branched Molecular Communication Systems", "categories": ["eess.SP", "cs.ET"], "comment": "6 pages, 8 figures, published in International Conference on\n  Nanoscale Computing and Communication (NanoCom 25), 2025, Chengdu, China", "summary": "Molecular Communications (MC) is an emerging research paradigm that utilizes\nmolecules to transmit information, with promising applications in biomedicine\nsuch as targeted drug delivery or tumor detection. It is also envisioned as a\nkey enabler of the Internet of BioNanoThings (IoBNT). In this paper, we propose\nalgorithms based on Recurrent Neural Networks (RNN) for the estimation of\ncommunication channel parameters in MC systems. We focus on a simple branched\ntopology, simulating the molecule movement with a macroscopic MC simulator. The\nDeep Learning architectures proposed for distance estimation demonstrate strong\nperformance within these branched environments, highlighting their potential\nfor future MC applications."}
{"id": "2511.02036", "pdf": "https://arxiv.org/pdf/2511.02036", "abs": "https://arxiv.org/abs/2511.02036", "authors": ["Parsa Hosseininejad", "Kimia Khabiri", "Shishir Gopinath", "Soudabeh Mohammadhashemi", "Karthik Dantu", "Steven Y. Ko"], "title": "TurboMap: GPU-Accelerated Local Mapping for Visual SLAM", "categories": ["cs.RO"], "comment": "Submitted to ICRA 2026", "summary": "This paper presents TurboMap, a GPU-accelerated and CPU-optimized local\nmapping module for visual SLAM systems. We identify key performance bottlenecks\nin the local mapping process for visual SLAM and address them through targeted\nGPU and CPU optimizations. Specifically, we offload map point triangulation and\nfusion to the GPU, accelerate redundant keyframe culling on the CPU, and\nintegrate a GPU-accelerated solver to speed up local bundle adjustment. Our\nimplementation is built on top of ORB-SLAM3 and leverages CUDA for GPU\nprogramming. The experimental results show that TurboMap achieves an average\nspeedup of 1.3x in the EuRoC dataset and 1.6x in the TUM-VI dataset in the\nlocal mapping module, on both desktop and embedded platforms, while maintaining\nthe accuracy of the original system."}
{"id": "2511.02084", "pdf": "https://arxiv.org/pdf/2511.02084", "abs": "https://arxiv.org/abs/2511.02084", "authors": ["Pallav Kumar Bera", "Samita Rani Pani"], "title": "Recurrence Plot and Change Quantile-based Deep Supervised and Semi-supervised Protection for Transmission Lines Connected to Photovoltaic Plants", "categories": ["eess.SP"], "comment": "29 pages", "summary": "Conventional relays encounter difficulties in protecting transmission lines\n(TLs) connected to converter-based energy sources (CBESs) due to the influence\nof power electronics on fault characteristics. This article proposes a\nsingle-ended intelligent protection method for the TL segment between the grid\nand a Photovoltaic (PV) plant. The approach utilizes a Recurrence Matrix and an\nInceptionTime-based system to identify faults by using the mean change in\nquantiles of 3-phase currents. It determines the fault position and identifies\nthe faulty phase. ReliefF feature selection is applied to extract the optimal\nquantile features. The scheme's performance is assessed under abnormal\nconditions, including faults and capacitor and load-switching events, simulated\nin Power Systems Computer Aided Design / Electromagnetic Transients Program\n(PSCAD/EMTDC) on the Western System Coordinating Council (WSCC) 9-bus system,\nwith various fault and switching parameters. The scheme is also validated on\nthe New England IEEE 39-bus system and in presence of partially rated\nconverters. Additionally, the validation of the proposed strategy takes into\naccount various conditions, including double-circuit line configuration, noise,\nseries compensation, high-impedance faults, current transformer (CT)\nsaturation, evolving and cross-country faults, remote and local faults, as well\nas variations in PV capacity, sampling frequency, and data window size. To\naddress label scarcity and improve generalization, semi-supervised learning\nparadigms including label spreading, label propagation, and self-training are\nintegrated with the InceptionTime framework, enabling near-supervised\nperformance with limited annotated fault data. The results demonstrate that the\napproach is effective in handling different system configurations and\nconditions, ensuring the protection of TLs connected to large PV plants."}
{"id": "2511.02060", "pdf": "https://arxiv.org/pdf/2511.02060", "abs": "https://arxiv.org/abs/2511.02060", "authors": ["Hersh Sanghvi", "Spencer Folk", "Vijay Kumar", "Camillo Jose Taylor"], "title": "TACO: Trajectory-Aware Controller Optimization for Quadrotors", "categories": ["cs.RO"], "comment": "8 pages, 6 figures. In submission to ICRA 2026", "summary": "Controller performance in quadrotor trajectory tracking depends heavily on\nparameter tuning, yet standard approaches often rely on fixed, manually tuned\nparameters that sacrifice task-specific performance. We present\nTrajectory-Aware Controller Optimization (TACO), a framework that adapts\ncontroller parameters online based on the upcoming reference trajectory and\ncurrent quadrotor state. TACO employs a learned predictive model and a\nlightweight optimization scheme to optimize controller gains in real time with\nrespect to a broad class of trajectories, and can also be used to adapt\ntrajectories to improve dynamic feasibility while respecting smoothness\nconstraints. To enable large-scale training, we also introduce a parallelized\nquadrotor simulator supporting fast data collection on diverse trajectories.\nExperiments on a variety of trajectory types show that TACO outperforms\nconventional, static parameter tuning while operating orders of magnitude\nfaster than black-box optimization baselines, enabling practical real-time\ndeployment on a physical quadrotor. Furthermore, we show that adapting\ntrajectories using TACO significantly reduces the tracking error obtained by\nthe quadrotor."}
{"id": "2511.02105", "pdf": "https://arxiv.org/pdf/2511.02105", "abs": "https://arxiv.org/abs/2511.02105", "authors": ["Vivien Walter", "Dadi Bi", "Daniel L. Ruiz Blanco", "Yansha Deng"], "title": "CNN-Based Detection of Mixed-Molecule Concentrations in Molecular Communication", "categories": ["eess.SP"], "comment": null, "summary": "Molecular communication (MC) is a promising paradigm for applications where\ntraditional electromagnetic communications are impractical. However, decoding\nchemical signals, especially in multi-transmitter systems, remains a key\nchallenge due to interference and complex propagation dynamics. In this paper,\nwe develop a one-dimensional fractal convolutional neural network (fCNN) to\ndetect the concentrations of multiple types of molecules based on the\nabsorbance spectra measured at a receiver. Our model is trained by both\nexperimental and simulated datasets, with the latter enhanced by noise modeling\nto mimic real-world measurements. We demonstrate that a noiseaugmented\nsimulated dataset can effectively be a substitute for experimental data,\nachieving similar decoding accuracy. Our approach successfully detects bit\nsequences in both binary and quadruple concentration shift keying (BCSK and\nQCSK) scenarios, even when transmitters are desynchronized, highlighting the\npotential of machine learning for robust MC signal detection."}
{"id": "2511.02097", "pdf": "https://arxiv.org/pdf/2511.02097", "abs": "https://arxiv.org/abs/2511.02097", "authors": ["Peng-Fei Zhang", "Ying Cheng", "Xiaofan Sun", "Shijie Wang", "Lei Zhu", "Heng Tao Shen"], "title": "A Step Toward World Models: A Survey on Robotic Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "24 pages, 5 figures", "summary": "Autonomous agents are increasingly expected to operate in complex, dynamic,\nand uncertain environments, performing tasks such as manipulation, navigation,\nand decision-making. Achieving these capabilities requires agents to understand\nthe underlying mechanisms and dynamics of the world, moving beyond purely\nreactive control or simple replication of observed states. This motivates the\ndevelopment of world models as internal representations that encode\nenvironmental states, capture dynamics, and enable prediction, planning, and\nreasoning. Despite growing interest, the definition, scope, architectures, and\nessential capabilities of world models remain ambiguous. In this survey, rather\nthan directly imposing a fixed definition and limiting our scope to methods\nexplicitly labeled as world models, we examine approaches that exhibit the core\ncapabilities of world models through a review of methods in robotic\nmanipulation. We analyze their roles across perception, prediction, and\ncontrol, identify key challenges and solutions, and distill the core\ncomponents, capabilities, and functions that a real world model should possess.\nBuilding on this analysis, we aim to outline a roadmap for developing\ngeneralizable and practical world models for robotics."}
{"id": "2511.02260", "pdf": "https://arxiv.org/pdf/2511.02260", "abs": "https://arxiv.org/abs/2511.02260", "authors": ["Ailton Oliveira", "Amir Khatibi", "Daniel Suzuki", "Ilan Correa", "José Rezende", "Aldebaro Klautau"], "title": "DL-Based Beam Management for mmWave Vehicular Networks Exploring Temporal Correlation", "categories": ["eess.SP"], "comment": "10 pages, pre-print", "summary": "Millimeter wave communications are essential for modern wireless networks. It\nsupports high data rates but suffers from severe path loss, which requires\nprecise beam alignment to maintain reliable links. This beam management is\nparticularly challenging in highly dynamic scenarios such as\nvehicle-to-infrastructure, and several methods have been presented. In this\nwork, we propose a deep learning-based beam tracking framework that combines a\nposition-aware beam pre-selection strategy with sequential prediction using\nrecurrent neural networks. The proposed architecture can support deep learning\nmodels trained for both classification and regression. In contrast to many\nexisting studies that evaluate beam tracking under predominantly line-of-sight\n(LOS) conditions, our work explicitly includes highly challenging non-LOS\nscenarios - with up to 50% non-LOS incidence in certain datasets - to\nrigorously assess model robustness. Experimental results demonstrate that our\napproach maintains high top-K accuracy, even under adverse conditions, while\nreducing the beam measurement overhead by up to 50%."}
{"id": "2511.02147", "pdf": "https://arxiv.org/pdf/2511.02147", "abs": "https://arxiv.org/abs/2511.02147", "authors": ["Tyler M. Paine", "Anastasia Bizyaeva", "Michael R. Benjamin"], "title": "Census-Based Population Autonomy For Distributed Robotic Teaming", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "comment": "16 pages, 17 figures", "summary": "Collaborating teams of robots show promise due in their ability to complete\nmissions more efficiently and with improved robustness, attributes that are\nparticularly useful for systems operating in marine environments. A key issue\nis how to model, analyze, and design these multi-robot systems to realize the\nfull benefits of collaboration, a challenging task since the domain of\nmulti-robot autonomy encompasses both collective and individual behaviors. This\npaper introduces a layered model of multi-robot autonomy that uses the\nprinciple of census, or a weighted count of the inputs from neighbors, for\ncollective decision-making about teaming, coupled with multi-objective behavior\noptimization for individual decision-making about actions. The census component\nis expressed as a nonlinear opinion dynamics model and the multi-objective\nbehavior optimization is accomplished using interval programming. This model\ncan be reduced to recover foundational algorithms in distributed optimization\nand control, while the full model enables new types of collective behaviors\nthat are useful in real-world scenarios. To illustrate these points, a new\nmethod for distributed optimization of subgroup allocation is introduced where\nrobots use a gradient descent algorithm to minimize portions of the cost\nfunctions that are locally known, while being influenced by the opinion states\nfrom neighbors to account for the unobserved costs. With this method the group\ncan collectively use the information contained in the Hessian matrix of the\ntotal global cost. The utility of this model is experimentally validated in\nthree categorically different experiments with fleets of autonomous surface\nvehicles: an adaptive sampling scenario, a high value unit protection scenario,\nand a competitive game of capture the flag."}
{"id": "2511.02423", "pdf": "https://arxiv.org/pdf/2511.02423", "abs": "https://arxiv.org/abs/2511.02423", "authors": ["Mingran Sun", "Lu Bai", "Xiang Cheng", "Jianjun Wu"], "title": "LLM4PG: Adapting Large Language Model for Pathloss Map Generation via Synesthesia of Machines", "categories": ["eess.SP"], "comment": null, "summary": "In this paper, a novel large language model (LLM)-based pathloss map\ngeneration model, termed LLM4PG, is proposed for sixth-generation (6G)\nAI-native communication systems via Synesthesia of Machines (SoM). To explore\nthe mapping mechanism between sensing images and pathloss maps, a new synthetic\nintelligent multi-modal sensing-communication dataset, SynthSoM-U2G, is\nconstructed, covering multiple scenarios, frequency bands, and flight\naltitudes. By adapting the LLM for cross-modal pathloss map generation for the\nfirst time, LLM4PG establishes an effective cross-domain alignment between the\nmulti-modal sensing-communication and natural language domains. A task-specific\nfine-tuning strategy with a tailored layer selection and activation scheme is\ndesigned to meet the demands of massive-scale, high-quality generation.\nCompared with conventional deep learning artificial intelligence generated\ncontent (AIGC) models, LLM4PG achieves more accurate pathloss map generation\nand stronger generalization across diverse conditions. Results show that LLM4PG\nattains an NMSE of 0.0454, outperforming the conventional AIGC model by over\n2.90 dB, while its cross-condition generalization achieves an NMSE of 0.0492,\nexceeding the baseline by 4.52 dB."}
{"id": "2511.02162", "pdf": "https://arxiv.org/pdf/2511.02162", "abs": "https://arxiv.org/abs/2511.02162", "authors": ["Alexander Htet Kyaw", "Richa Gupta", "Dhruv Shah", "Anoop Sinha", "Kory Mathewson", "Stefanie Pender", "Sachin Chitta", "Yotto Koga", "Faez Ahmed", "Lawrence Sass", "Randall Davis"], "title": "Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "Accepted to NeurIPS 2025, Conference on Neural Information Processing\n  Systems, Creative AI Track", "summary": "Advances in 3D generative AI have enabled the creation of physical objects\nfrom text prompts, but challenges remain in creating objects involving multiple\ncomponent types. We present a pipeline that integrates 3D generative AI with\nvision-language models (VLMs) to enable the robotic assembly of multi-component\nobjects from natural language. Our method leverages VLMs for zero-shot,\nmulti-modal reasoning about geometry and functionality to decompose\nAI-generated meshes into multi-component 3D models using predefined structural\nand panel components. We demonstrate that a VLM is capable of determining which\nmesh regions need panel components in addition to structural components, based\non object functionality. Evaluation across test objects shows that users\npreferred the VLM-generated assignments 90.6% of the time, compared to 59.4%\nfor rule-based and 2.5% for random assignment. Lastly, the system allows users\nto refine component assignments through conversational feedback, enabling\ngreater human control and agency in making physical objects with generative AI\nand robotics."}
{"id": "2511.02426", "pdf": "https://arxiv.org/pdf/2511.02426", "abs": "https://arxiv.org/abs/2511.02426", "authors": ["Marios Impraimakis"], "title": "A Kullback-Leibler divergence method for input-system-state identification", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.IT", "cs.SY", "eess.SY", "math.IT", "68T05 (Learning and adaptive systems)", "I.2.6; I.2.8"], "comment": "32 pages, 17 figures, published in Journal of Sound and Vibration", "summary": "The capability of a novel Kullback-Leibler divergence method is examined\nherein within the Kalman filter framework to select the input-parameter-state\nestimation execution with the most plausible results. This identification\nsuffers from the uncertainty related to obtaining different results from\ndifferent initial parameter set guesses, and the examined approach uses the\ninformation gained from the data in going from the prior to the posterior\ndistribution to address the issue. Firstly, the Kalman filter is performed for\na number of different initial parameter sets providing the system\ninput-parameter-state estimation. Secondly, the resulting posterior\ndistributions are compared simultaneously to the initial prior distributions\nusing the Kullback-Leibler divergence. Finally, the identification with the\nleast Kullback-Leibler divergence is selected as the one with the most\nplausible results. Importantly, the method is shown to select the better\nperformed identification in linear, nonlinear, and limited information\napplications, providing a powerful tool for system monitoring."}
{"id": "2511.02167", "pdf": "https://arxiv.org/pdf/2511.02167", "abs": "https://arxiv.org/abs/2511.02167", "authors": ["Tian Hao", "Tong Lu", "Che Chan"], "title": "Kinematic and Ergonomic Design of a Robotic Arm for Precision Laparoscopic Surgery", "categories": ["cs.RO"], "comment": null, "summary": "Robotic assistance in minimally invasive surgery can greatly enhance surgical\nprecision and reduce surgeon fatigue. This paper presents a focused\ninvestigation on the kinematic and ergonomic design principles for a\nlaparoscopic surgical robotic arm aimed at high-precision tasks. We propose a\n7-degree-of-freedom (7-DOF) robotic arm system that incorporates a remote\ncenter of motion (RCM) at the instrument insertion point and ergonomic\nconsiderations to improve surgeon interaction. The design is implemented on a\ngeneral-purpose robotic platform, and a series of simulated surgical tasks were\nperformed to evaluate targeting accuracy, task efficiency, and surgeon comfort\ncompared to conventional manual laparoscopy. Experimental results demonstrate\nthat the optimized robotic design achieves significantly improved targeting\naccuracy (error reduced by over 50%) and shorter task completion times, while\nsubstantially lowering operator muscle strain and discomfort. These findings\nvalidate the importance of kinematic optimization (such as added articulations\nand tremor filtering) and human-centered ergonomic design in enhancing the\nperformance of robot-assisted surgery. The insights from this work can guide\nthe development of next-generation surgical robots that improve surgical\noutcomes and ergonomics for the operating team."}
{"id": "2511.02444", "pdf": "https://arxiv.org/pdf/2511.02444", "abs": "https://arxiv.org/abs/2511.02444", "authors": ["Vered Karp", "Aseel Omar", "Alejandro Cohen"], "title": "Adaptive Compressed Integrate-and-Fire Time Encoding Machine", "categories": ["eess.SP"], "comment": null, "summary": "Integrate-and-Fire Time Encoding Machine (IF-TEM) is a power-efficient\nasynchronous sampler that converts analog signals into non-uniform time-domain\nsamples. Adaptive IF-TEM (AIF-TEM) improves this machine by adapting its\nprocess to the characteristics of the input signal, thereby reducing the\nsampling rate. Compressed IF-TEM (CIF-TEM) reduces bit usage by performing\nanalog compression before quantization. In this paper, we introduce a combined\nAdaptive Compressed IF-TEM (ACIF-TEM) -- a new sampler that leverages the two\nmachines, AIF-TEM and CIF-TEM, where each reinforces the effectiveness of the\nother. We propose an efficient adaptive clockless time-to-digital converter\n(TDC) architecture for the novel sampler that integrates the compression stage\nwithin the TDC, facilitating the realization of the intended integrated system.\n\\ifconf \\else We analyze the total bit usage, and contrast its performance with\nthat of IF-TEM, AIF-TEM, and CIF-TEM.\\fi Via an evaluation study, we\ndemonstrate that the proposed ACIF-TEM sampler achieves lower Mean Square Error\n(MSE) with fewer bits, offering compression gains of at least 3-bit out of\n9-bits over AIF-TEM and 60\\% compression over IF-TEM, for fixed recovery MSE\nwith real audio signals."}
{"id": "2511.02192", "pdf": "https://arxiv.org/pdf/2511.02192", "abs": "https://arxiv.org/abs/2511.02192", "authors": ["Linxin Hou", "Qirui Wu", "Zhihang Qin", "Neil Banerjee", "Yongxin Guo", "Cecilia Laschi"], "title": "A Quantitative Comparison of Centralised and Distributed Reinforcement Learning-Based Control for Soft Robotic Arms", "categories": ["cs.RO"], "comment": "7 pages, 4 figures, 2 tables, submitted to RoboSoft 2026", "summary": "This paper presents a quantitative comparison between centralised and\ndistributed multi-agent reinforcement learning (MARL) architectures for\ncontrolling a soft robotic arm modelled as a Cosserat rod in simulation. Using\nPyElastica and the OpenAI Gym interface, we train both a global Proximal Policy\nOptimisation (PPO) controller and a Multi-Agent PPO (MAPPO) under identical\nbudgets. Both approaches are based on the arm having $n$ number of controlled\nsections. The study systematically varies $n$ and evaluates the performance of\nthe arm to reach a fixed target in three scenarios: default baseline condition,\nrecovery from external disturbance, and adaptation to actuator failure.\nQuantitative metrics used for the evaluation are mean action magnitude, mean\nfinal distance, mean episode length, and success rate. The results show that\nthere are no significant benefits of the distributed policy when the number of\ncontrolled sections $n\\le4$. In very simple systems, when $n\\le2$, the\ncentralised policy outperforms the distributed one. When $n$ increases to $4<\nn\\le 12$, the distributed policy shows a high sample efficiency. In these\nsystems, distributed policy promotes a stronger success rate, resilience, and\nrobustness under local observability and yields faster convergence given the\nsame sample size. However, centralised policies achieve much higher time\nefficiency during training as it takes much less time to train the same size of\nsamples. These findings highlight the trade-offs between centralised and\ndistributed policy in reinforcement learning-based control for soft robotic\nsystems and provide actionable design guidance for future sim-to-real transfer\nin soft rod-like manipulators."}
{"id": "2511.02457", "pdf": "https://arxiv.org/pdf/2511.02457", "abs": "https://arxiv.org/abs/2511.02457", "authors": ["Mohaddese Qaremohammadlou", "Mohammad Bagher Shamsollahi"], "title": "Investigating Brain Connectivity and Information Flow in Mental Workload Using EEG and fNIRS Integration", "categories": ["eess.SP"], "comment": null, "summary": "This study investigates brain connectivity and information flow during mental\nworkload (MWL) by integrating electroencephalogram (EEG) and functional\nnear-infrared spectroscopy (fNIRS) signals. Utilizing the N-back task to induce\nvarying levels of MWL in 26 participants, we analyzed both functional and\neffective connectivity across 25 cortical regions derived from combined EEG and\nfNIRS signals. Functional connectivity was assessed using Pearson Correlation\nCoefficient (PCC), Phase Locking Value (PLV), and Magnitude Squared Coherence\n(MSC), while effective connectivity was evaluated using directed Directed\nTransfer Function (dDTF) and generalized Partial Directed Coherence (gPDC). Our\nfindings reveal increased functional connectivity in frontal regions during\nhigher MWL conditions (3-back compared to 0-back). Furthermore, effective\nconnectivity analysis demonstrates a significant directional information flow\nfrom EEG to fNIRS, indicating a dominant influence of neural activity on\nhemodynamic responses. Statistical tests confirm significant differences in\nconnectivity patterns between low and high MWL states. These results underscore\nthe utility of EEG-fNIRS integration for characterizing brain network dynamics\nunder varying cognitive demands and provide insights into neurovascular\ncoupling mechanisms during mental workload."}
{"id": "2511.02239", "pdf": "https://arxiv.org/pdf/2511.02239", "abs": "https://arxiv.org/abs/2511.02239", "authors": ["Youngjin Hong", "Houjian Yu", "Mingen Li", "Changhyun Choi"], "title": "LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "Preprint. Project page: https://vla2026.github.io/LACY/", "summary": "Learning generalizable policies for robotic manipulation increasingly relies\non large-scale models that map language instructions to actions (L2A). However,\nthis one-way paradigm often produces policies that execute tasks without deeper\ncontextual understanding, limiting their ability to generalize or explain their\nbehavior. We argue that the complementary skill of mapping actions back to\nlanguage (A2L) is essential for developing more holistic grounding. An agent\ncapable of both acting and explaining its actions can form richer internal\nrepresentations and unlock new paradigms for self-supervised learning. We\nintroduce LACY (Language-Action Cycle), a unified framework that learns such\nbidirectional mappings within a single vision-language model. LACY is jointly\ntrained on three synergistic tasks: generating parameterized actions from\nlanguage (L2A), explaining observed actions in language (A2L), and verifying\nsemantic consistency between two language descriptions (L2C). This enables a\nself-improving cycle that autonomously generates and filters new training data\nthrough an active augmentation strategy targeting low-confidence cases, thereby\nimproving the model without additional human labels. Experiments on\npick-and-place tasks in both simulation and the real world show that LACY\nimproves task success rates by 56.46% on average and yields more robust\nlanguage-action grounding for robotic manipulation. Project page:\nhttps://vla2026.github.io/LACY/"}
{"id": "2511.02493", "pdf": "https://arxiv.org/pdf/2511.02493", "abs": "https://arxiv.org/abs/2511.02493", "authors": ["Ana Pérez-Neira", "Marc Martinez-Gost", "Miguel Ángel Lagunas"], "title": "Before AI Takes Over: Rethinking Nonlinear Signal Processing in Communications", "categories": ["eess.SP", "cs.SY", "eess.SY"], "comment": "Submitted to npj Wireless Technology", "summary": "There is an urgent reflection on traditional nonlinear signal processing\nmethods in communications before Artificial Intelligence (AI) dominates the\nfield. It implies a need to reassess or reinterpret established theories and\ntools, highlighting the tension between data-driven and model-based approaches.\nThis paper calls for preserving valuable insights from classical signal\nprocessing while exploring how they can coexist or integrate with emerging AI\nmethods."}
{"id": "2511.02294", "pdf": "https://arxiv.org/pdf/2511.02294", "abs": "https://arxiv.org/abs/2511.02294", "authors": ["Ruiyong Yuan", "Jieji Ren", "Zhanxuan Peng", "Feifei Chen", "Guoying Gu"], "title": "SuckTac: Camera-based Tactile Sucker for Unstructured Surface Perception and Interaction", "categories": ["cs.RO"], "comment": null, "summary": "Suckers are significant for robots in picking, transferring, manipulation and\nlocomotion on diverse surfaces. However, most of the existing suckers lack\nhigh-fidelity perceptual and tactile sensing, which impedes them from resolving\nthe fine-grained geometric features and interaction status of the target\nsurface. This limits their robust performance with irregular objects and in\ncomplex, unstructured environments. Inspired by the adaptive structure and\nhigh-performance sensory capabilities of cephalopod suckers, in this paper, we\npropose a novel, intelligent sucker, named SuckTac, that integrates a\ncamera-based tactile sensor directly within its optimized structure to provide\nhigh-density perception and robust suction. Specifically, through joint\nstructure design and optimization and based on a multi-material integrated\ncasting technique, a camera and light source are embedded into the sucker,\nwhich enables in-situ, high-density perception of fine details like surface\nshape, texture and roughness. To further enhance robustness and adaptability,\nthe sucker's mechanical design is also optimized by refining its profile,\nadding a compliant lip, and incorporating surface microstructure. Extensive\nexperiments, including challenging tasks such as robotic cloth manipulation and\nsoft mobile robot inspection, demonstrate the superior performance and broad\napplicability of the proposed system."}
{"id": "2511.02573", "pdf": "https://arxiv.org/pdf/2511.02573", "abs": "https://arxiv.org/abs/2511.02573", "authors": ["Anastasios T. Sotiropoulos", "Stavros Tsimpoukis", "Dimitrios Tyrovolas", "Sotiris Ioannidis", "George K. Karagiannidis", "Christos K. Liaskos"], "title": "RIS-Assisted 3D Spherical Splatting for Object Composition Visualization using Detection Transformers", "categories": ["eess.SP", "cs.LG"], "comment": "Submitted to IEEE ICC 2026", "summary": "The pursuit of immersive and structurally aware multimedia experiences has\nintensified interest in sensing modalities that reconstruct objects beyond the\nlimits of visible light. Conventional optical pipelines degrade under occlusion\nor low illumination, motivating the use of radio-frequency (RF) sensing, whose\nelectromagnetic waves penetrate materials and encode both geometric and\ncompositional information. Yet, uncontrolled multipath propagation restricts\nreconstruction accuracy. Recent advances in Programmable Wireless Environments\n(PWEs) mitigate this limitation by enabling software-defined manipulation of\npropagation through Reconfigurable Intelligent Surfaces (RISs), thereby\nproviding controllable illumination diversity. Building on this capability,\nthis work introduces a PWE-driven RF framework for three-dimensional object\nreconstruction using material-aware spherical primitives. The proposed approach\ncombines RIS-enabled field synthesis with a Detection Transformer (DETR) that\ninfers spatial and material parameters directly from extracted RF features.\nSimulation results confirm the framework's ability to approximate object\ngeometries and classify material composition with an overall accuracy of\n79.35%, marking an initial step toward programmable and physically grounded\nRF-based 3D object composition visualization."}
{"id": "2511.02315", "pdf": "https://arxiv.org/pdf/2511.02315", "abs": "https://arxiv.org/abs/2511.02315", "authors": ["Zifei Wu", "Lijie Wang", "Zhe Yang", "Shijie Yang", "Liang Wang", "Haoran Fu", "Yinliang Cai", "Rong Xiong"], "title": "ZJUNlict Extended Team Description Paper 2025", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents the ZJUNlict team's work over the past year, covering\nboth hardware and software advancements. In the hardware domain, the\nintegration of an IMU into the v2023 robot was completed to enhance posture\naccuracy and angular velocity planning. On the software side, key modules were\noptimized, including the strategy and CUDA modules, with significant\nimprovements in decision making efficiency, ball pursuit prediction, and ball\npossession prediction to adapt to high-tempo game dynamics."}
{"id": "2511.02672", "pdf": "https://arxiv.org/pdf/2511.02672", "abs": "https://arxiv.org/abs/2511.02672", "authors": ["Adam Umra", "Aya M. Ahmed", "Aydin Sezgin"], "title": "RL-Aided Cognitive ISAC: Robust Detection and Sensing-Communication Trade-offs", "categories": ["eess.SP", "cs.LG"], "comment": "29 pages, 14 figures. Invited paper, submitted to the EURASIP Journal\n  on Wireless Communications and Networking (JWCN)", "summary": "This paper proposes a reinforcement learning (RL)-aided cognitive framework\nfor massive MIMO-based integrated sensing and communication (ISAC) systems\nemploying a uniform planar array (UPA). The focus is on enhancing radar sensing\nperformance in environments with unknown and dynamic disturbance\ncharacteristics. A Wald-type detector is employed for robust target detection\nunder non-Gaussian clutter, while a SARSA-based RL algorithm enables adaptive\nestimation of target positions without prior environmental knowledge. Based on\nthe RL-derived sensing information, a joint waveform optimization strategy is\nformulated to balance radar sensing accuracy and downlink communication\nthroughput. The resulting design provides an adaptive trade-off between\ndetection performance and achievable sum rate through an analytically derived\nclosed-form solution. Monte Carlo simulations demonstrate that the proposed\ncognitive ISAC framework achieves significantly improved detection probability\ncompared to orthogonal and non-learning adaptive baselines, while maintaining\ncompetitive communication performance. These results underline the potential of\nRL-assisted sensing for robust and spectrum-efficient ISAC in next-generation\nwireless networks."}
{"id": "2511.02342", "pdf": "https://arxiv.org/pdf/2511.02342", "abs": "https://arxiv.org/abs/2511.02342", "authors": ["Lin Yang", "Jinwoo Lee", "Domenico Campolo", "H. Jin Kim", "Jeonghyun Byun"], "title": "Whole-body motion planning and safety-critical control for aerial manipulation", "categories": ["cs.RO"], "comment": "Submitted to 2026 IFAC World Congress with the Journal option\n  (MECHATRONICS)", "summary": "Aerial manipulation combines the maneuverability of multirotors with the\ndexterity of robotic arms to perform complex tasks in cluttered spaces. Yet\nplanning safe, dynamically feasible trajectories remains difficult due to\nwhole-body collision avoidance and the conservativeness of common geometric\nabstractions such as bounding boxes or ellipsoids. We present a whole-body\nmotion planning and safety-critical control framework for aerial manipulators\nbuilt on superquadrics (SQs). Using an SQ-plus-proxy representation, we model\nboth the vehicle and obstacles with differentiable, geometry-accurate surfaces.\nLeveraging this representation, we introduce a maximum-clearance planner that\nfuses Voronoi diagrams with an equilibrium-manifold formulation to generate\nsmooth, collision-aware trajectories. We further design a safety-critical\ncontroller that jointly enforces thrust limits and collision avoidance via\nhigh-order control barrier functions. In simulation, our approach outperforms\nsampling-based planners in cluttered environments, producing faster, safer, and\nsmoother trajectories and exceeding ellipsoid-based baselines in geometric\nfidelity. Actual experiments on a physical aerial-manipulation platform confirm\nfeasibility and robustness, demonstrating consistent performance across\nsimulation and hardware settings. The video can be found at\nhttps://youtu.be/hQYKwrWf1Ak."}
{"id": "2511.02673", "pdf": "https://arxiv.org/pdf/2511.02673", "abs": "https://arxiv.org/abs/2511.02673", "authors": ["Adam Umra", "Kevin Weinberger", "Aymen Khaleel", "Aydin Sezgin"], "title": "Short Blocks, Fast Sensing: Finite Blocklength Tradeoffs in RIS-Assisted ISAC", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": "6 pages, 4 figures, submitted to IEEE ICC 2026", "summary": "Integrated sensing and communication (ISAC) is a cornerstone for future\nsixth-generation (6G) networks, enabling simultaneous connectivity and\nenvironmental awareness. However, practical realization faces significant\nchallenges, including residual self-interference (SI) in full-duplex systems\nand performance degradation of short-packet transmissions under finite\nblocklength (FBL) constraints. This work studies a reconfigurable intelligent\nsurface (RIS)-assisted full-duplex ISAC system serving multiple downlink users\nwhile tracking a moving target, explicitly accounting for SI and FBL effects in\nboth communication and sensing. We formulate an optimization framework to\nminimize service adaptation gaps while ensuring sensing reliability, solved via\nalternating optimization and successive convex approximation. Numerical results\nshow that short blocklengths enable fast adaptation but raise radar outage from\nfewer pulses and motion sensitivity. Longer blocklengths improve\nsignal-to-interference-plus-noise ratio (SINR) and reduce outages but allow\nmotion to degrade sensing. A \"sweet spot\" arises where blocklength and\nbeamformer allocation optimize throughput and sensing, seen as a local minimum\nin radar SINR variance. RIS-assisted optimization identifies this balance,\nachieving reliable communication and radar sensing jointly."}
{"id": "2511.02504", "pdf": "https://arxiv.org/pdf/2511.02504", "abs": "https://arxiv.org/abs/2511.02504", "authors": ["Le Chen", "Yi Zhao", "Jan Schneider", "Quankai Gao", "Simon Guist", "Cheng Qian", "Juho Kannala", "Bernhard Schölkopf", "Joni Pajarinen", "Dieter Büchler"], "title": "Dexterous Robotic Piano Playing at Scale", "categories": ["cs.RO"], "comment": null, "summary": "Endowing robot hands with human-level dexterity has been a long-standing goal\nin robotics. Bimanual robotic piano playing represents a particularly\nchallenging task: it is high-dimensional, contact-rich, and requires fast,\nprecise control. We present OmniPianist, the first agent capable of performing\nnearly one thousand music pieces via scalable, human-demonstration-free\nlearning. Our approach is built on three core components. First, we introduce\nan automatic fingering strategy based on Optimal Transport (OT), allowing the\nagent to autonomously discover efficient piano-playing strategies from scratch\nwithout demonstrations. Second, we conduct large-scale Reinforcement Learning\n(RL) by training more than 2,000 agents, each specialized in distinct music\npieces, and aggregate their experience into a dataset named RP1M++, consisting\nof over one million trajectories for robotic piano playing. Finally, we employ\na Flow Matching Transformer to leverage RP1M++ through large-scale imitation\nlearning, resulting in the OmniPianist agent capable of performing a wide range\nof musical pieces. Extensive experiments and ablation studies highlight the\neffectiveness and scalability of our approach, advancing dexterous robotic\npiano playing at scale."}
{"id": "2511.02689", "pdf": "https://arxiv.org/pdf/2511.02689", "abs": "https://arxiv.org/abs/2511.02689", "authors": ["Smilja Stokanović", "Jaka Sodnik", "Nadica Miljković"], "title": "Eye Movement Analysis in Simulated Driving Scenarios", "categories": ["eess.SP"], "comment": "29 pages, 6 figures, and 6 tables", "summary": "This study investigates eye movement behaviour during three conditions:\nBaseline, Ride (simulated drive under normal visibility), and Fog (simulated\ndrive under reduced visibility). Eye tracking data are analyzed using 31\nparameters, organized into three groups: (1) saccade features, (2) Bivariate\nContour Ellipse Area (BCEA), and (3) blinking features. Specifically, the\nanalysis includes 13 saccade, 13 BCEA, and 5 blinking variables. Across all\nfeature groups, numerous statistically significant differences emerge between\nBaseline and the driving conditions, particularly between Baseline and Ride or\nFog. Between Ride and Fog, saccade features show minimal changes (one out of\n13), whereas BCEA (9 of 13) and blink features (four of 5) exhibit pronounced\ndifferences, highlighting the strong impact of reduced visibility on gaze\nstability and blinking behaviour. In addition to conventional measures such as\nMean Squared Error (MSE) and entropy metrics, a new parameter, Guzik's Index\n(GI), is introduced to quantify fixation asymmetry along the major axis of the\nBCEA. This index utilizes eye tracking data to enhance the understanding of eye\nmovement dynamics during driving conditions. Separately from GI, other\nparameters elicit the largest deviations compared to Ride (e.g., number of\nsaccades: Cliff's $\\delta$ = 0.96, BCEA: Cohen's $\\textit{d}$ = 0.89, and\nstandard deviation of blink duration: Cliff's $\\delta$ = 0.80), underscoring\nthe influence of reduced visibility on visual attention. Overall, these\nfindings demonstrate that combining BCEA with saccade and blink parameters\nprovides a comprehensive understanding of visual attention and gaze stability,\nwhile GI offers additional insights into fixation asymmetry under varying\nvisibility conditions."}
{"id": "2511.02761", "pdf": "https://arxiv.org/pdf/2511.02761", "abs": "https://arxiv.org/abs/2511.02761", "authors": ["Seth Stewart", "Joseph Pawelski", "Steve Ward", "Andrew J. Petruska"], "title": "Non-Contact Manipulation of Induced Magnetic Dipoles", "categories": ["cs.RO"], "comment": null, "summary": "Extending the field of magnetic manipulation to conductive, non-magnetic\nobjects opens the door for a wide array of applications previously limited to\nhard or soft magnetic materials. Of particular interest is the recycling of\nspace debris through the use of oscillating magnetic fields, which represent a\ncache of raw materials in an environment particularly suited to the low forces\ngenerated from inductive magnetic manipulation. Building upon previous work\nthat demonstrated 3D open-loop position control by leveraging the opposing\ndipole moment created from induced eddy currents, this work demonstrates\nclosed-loop position control of a semi-buoyant aluminum sphere in lab tests,\nand the efficacy of varying methods for force inversion is explored. The\nclosed-loop methods represent a critical first step towards wider applications\nfor 3-DOF position control of induced magnetic dipoles."}
{"id": "2511.02717", "pdf": "https://arxiv.org/pdf/2511.02717", "abs": "https://arxiv.org/abs/2511.02717", "authors": ["Marios Impraimakis", "Andrew W. Smyth"], "title": "An unscented Kalman filter method for real time input-parameter-state estimation", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.SY", "eess.AS", "eess.SY", "68T05 (Learning and adaptive systems)", "I.2.6; I.2.8"], "comment": "author-accepted manuscript (AAM) published in Mechanical Systems and\n  Signal Processing", "summary": "The input-parameter-state estimation capabilities of a novel unscented Kalman\nfilter is examined herein on both linear and nonlinear systems. The unknown\ninput is estimated in two stages within each time step. Firstly, the predicted\ndynamic states and the system parameters provide an estimation of the input.\nSecondly, the corrected with measurements states and parameters provide a final\nestimation. Importantly, it is demonstrated using the perturbation analysis\nthat, a system with at least a zero or a non-zero known input can potentially\nbe uniquely identified. This output-only methodology allows for a better\nunderstanding of the system compared to classical output-only parameter\nidentification strategies, given that all the dynamic states, the parameters,\nand the input are estimated jointly and in real-time."}
{"id": "2511.02776", "pdf": "https://arxiv.org/pdf/2511.02776", "abs": "https://arxiv.org/abs/2511.02776", "authors": ["Shichao Fan", "Kun Wu", "Zhengping Che", "Xinhua Wang", "Di Wu", "Fei Liao", "Ning Liu", "Yixue Zhang", "Zhen Zhao", "Zhiyuan Xu", "Meng Li", "Qingjie Liu", "Shanghang Zhang", "Min Wan", "Jian Tang"], "title": "XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations", "categories": ["cs.RO"], "comment": null, "summary": "Recent progress in large-scale robotic datasets and vision-language models\n(VLMs) has advanced research on vision-language-action (VLA) models. However,\nexisting VLA models still face two fundamental challenges: (i) producing\nprecise low-level actions from high-dimensional observations, (ii) bridging\ndomain gaps across heterogeneous data sources, including diverse robot\nembodiments and human demonstrations. Existing methods often encode latent\nvariables from either visual dynamics or robotic actions to guide policy\nlearning, but they fail to fully exploit the complementary multi-modal\nknowledge present in large-scale, heterogeneous datasets. In this work, we\npresent X Robotic Model 1 (XR-1), a novel framework for versatile and scalable\nVLA learning across diverse robots, tasks, and environments. XR-1 introduces\nthe \\emph{Unified Vision-Motion Codes (UVMC)}, a discrete latent representation\nlearned via a dual-branch VQ-VAE that jointly encodes visual dynamics and\nrobotic motion. UVMC addresses these challenges by (i) serving as an\nintermediate representation between the observations and actions, and (ii)\naligning multimodal dynamic information from heterogeneous data sources to\ncapture complementary knowledge. To effectively exploit UVMC, we propose a\nthree-stage training paradigm: (i) self-supervised UVMC learning, (ii)\nUVMC-guided pretraining on large-scale cross-embodiment robotic datasets, and\n(iii) task-specific post-training. We validate XR-1 through extensive\nreal-world experiments with more than 14,000 rollouts on six different robot\nembodiments, spanning over 120 diverse manipulation tasks. XR-1 consistently\noutperforms state-of-the-art baselines such as $\\pi_{0.5}$, $\\pi_0$, RDT,\nUniVLA, and GR00T-N1.5 while demonstrating strong generalization to novel\nobjects, background variations, distractors, and illumination changes. Our\nproject is at https://xr-1-vla.github.io/."}
{"id": "2511.02728", "pdf": "https://arxiv.org/pdf/2511.02728", "abs": "https://arxiv.org/abs/2511.02728", "authors": ["Kaluguri Yashaswini", "Anshu Arora", "Satish Mulleti"], "title": "A Non-Uniform Quantization Framework for Time-Encoding Machines", "categories": ["eess.SP"], "comment": "5 pages", "summary": "Time encoding machines (TEMs) provide an event-driven alternative to\nclassical uniform sampling, enabling power-efficient representations without a\nglobal clock. While prior work analyzed uniform quantization (UQ) of firing\nintervals, we show that these intervals are inherently non-uniformly\ndistributed, motivating the use of non-uniform quantization (NUQ). We derive\nthe probability distribution of firing intervals for a class of bandlimited\nsignals and design a power-law-based NUQ scheme tailored to this distribution.\nSimulations demonstrate that NUQ significantly outperforms UQ under the same\nbit budget. We also compare TEMs with non-uniform sampling (NUS), where both\namplitudes and timings require quantization, and show that TEM--NUQ achieves\nlower error at half the transmission cost. These results highlight the\nadvantages of distribution-aware quantization and establish TEM--NUQ as an\nefficient alternative to conventional UQ and NUS schemes."}
{"id": "2511.02832", "pdf": "https://arxiv.org/pdf/2511.02832", "abs": "https://arxiv.org/abs/2511.02832", "authors": ["Yanjie Ze", "Siheng Zhao", "Weizhuo Wang", "Angjoo Kanazawa", "Rocky Duan", "Pieter Abbeel", "Guanya Shi", "Jiajun Wu", "C. Karen Liu"], "title": "TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Website: https://yanjieze.com/TWIST2", "summary": "Large-scale data has driven breakthroughs in robotics, from language models\nto vision-language-action models in bimanual manipulation. However, humanoid\nrobotics lacks equally effective data collection frameworks. Existing humanoid\nteleoperation systems either use decoupled control or depend on expensive\nmotion capture setups. We introduce TWIST2, a portable, mocap-free humanoid\nteleoperation and data collection system that preserves full whole-body control\nwhile advancing scalability. Our system leverages PICO4U VR for obtaining\nreal-time whole-body human motions, with a custom 2-DoF robot neck (cost around\n$250) for egocentric vision, enabling holistic human-to-humanoid control. We\ndemonstrate long-horizon dexterous and mobile humanoid skills and we can\ncollect 100 demonstrations in 15 minutes with an almost 100% success rate.\nBuilding on this pipeline, we propose a hierarchical visuomotor policy\nframework that autonomously controls the full humanoid body based on egocentric\nvision. Our visuomotor policy successfully demonstrates whole-body dexterous\nmanipulation and dynamic kicking tasks. The entire system is fully reproducible\nand open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is also\nopen-sourced at https://twist-data.github.io ."}
{"id": "2511.01868", "pdf": "https://arxiv.org/pdf/2511.01868", "abs": "https://arxiv.org/abs/2511.01868", "authors": ["Ching-Chih Sung", "Shuntaro Suzuki", "Francis Pingfan Chien", "Komei Sugiura", "Yu Tsao"], "title": "Condition-Invariant fMRI Decoding of Speech Intelligibility with Deep State Space Model", "categories": ["q-bio.NC", "cs.LG", "cs.SD", "eess.AS", "eess.SP"], "comment": null, "summary": "Clarifying the neural basis of speech intelligibility is critical for\ncomputational neuroscience and digital speech processing. Recent neuroimaging\nstudies have shown that intelligibility modulates cortical activity beyond\nsimple acoustics, primarily in the superior temporal and inferior frontal gyri.\nHowever, previous studies have been largely confined to clean speech, leaving\nit unclear whether the brain employs condition-invariant neural codes across\ndiverse listening environments. To address this gap, we propose a novel\narchitecture built upon a deep state space model for decoding intelligibility\nfrom fMRI signals, specifically tailored to their high-dimensional temporal\nstructure. We present the first attempt to decode intelligibility across\nacoustically distinct conditions, showing our method significantly outperforms\nclassical approaches. Furthermore, region-wise analysis highlights\ncontributions from auditory, frontal, and parietal regions, and cross-condition\ntransfer indicates the presence of condition-invariant neural codes, thereby\nadvancing understanding of abstract linguistic representations in the brain."}
{"id": "2511.01914", "pdf": "https://arxiv.org/pdf/2511.01914", "abs": "https://arxiv.org/abs/2511.01914", "authors": ["Yuan Zhang", "Chenyu Xue", "Wenjie Xu", "Chao Ji", "Jiajia wu", "Jia Pan"], "title": "iFlyBot-VLA Technical Report", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "We introduce iFlyBot-VLA, a large-scale Vision-Language-Action (VLA) model\ntrained under a novel framework. The main contributions are listed as follows:\n(1) a latent action model thoroughly trained on large-scale human and robotic\nmanipulation videos; (2) a dual-level action representation framework that\njointly supervises both the Vision-Language Model (VLM) and the action expert\nduring training; (3) a mixed training strategy that combines robot trajectory\ndata with general QA and spatial QA datasets, effectively enhancing the 3D\nperceptual and reasoning capabilities of the VLM backbone. Specifically, the\nVLM is trained to predict two complementary forms of actions: latent actions,\nderived from our latent action model pretrained on cross-embodiment\nmanipulation data, which capture implicit high-level intentions; and structured\ndiscrete action tokens, obtained through frequency-domain transformations of\ncontinuous control signals, which encode explicit low-level dynamics. This dual\nsupervision aligns the representation spaces of language, vision, and action,\nenabling the VLM to directly contribute to action generation. Experimental\nresults on the LIBERO Franka benchmark demonstrate the superiority of our\nframe-work, while real-world evaluations further show that iFlyBot-VLA achieves\ncompetitive success rates across diverse and challenging manipulation tasks.\nFurthermore, we plan to open-source a portion of our self-constructed dataset\nto support future research in the community"}
{"id": "2511.01947", "pdf": "https://arxiv.org/pdf/2511.01947", "abs": "https://arxiv.org/abs/2511.01947", "authors": ["Md Abrar Hasnat", "Md Jobayer", "Md. Mehedi Hasan Shawon", "Md. Golam Rabiul Alam"], "title": "Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale Study with SHAP and Surrogate Decision Trees", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Cardiovascular disease (CVD) remains a critical global health concern,\ndemanding reliable and interpretable predictive models for early risk\nassessment. This study presents a large-scale analysis using the Heart Disease\nHealth Indicators Dataset, developing a strategically weighted ensemble model\nthat combines tree-based methods (LightGBM, XGBoost) with a Convolutional\nNeural Network (CNN) to predict CVD risk. The model was trained on a\npreprocessed dataset of 229,781 patients where the inherent class imbalance was\nmanaged through strategic weighting and feature engineering enhanced the\noriginal 22 features to 25. The final ensemble achieves a statistically\nsignificant improvement over the best individual model, with a Test AUC of\n0.8371 (p=0.003) and is particularly suited for screening with a high recall of\n80.0%. To provide transparency and clinical interpretability, surrogate\ndecision trees and SHapley Additive exPlanations (SHAP) are used. The proposed\nmodel delivers a combination of robust predictive performance and clinical\ntransparency by blending diverse learning architectures and incorporating\nexplainability through SHAP and surrogate decision trees, making it a strong\ncandidate for real-world deployment in public health screening."}
{"id": "2511.02025", "pdf": "https://arxiv.org/pdf/2511.02025", "abs": "https://arxiv.org/abs/2511.02025", "authors": ["Rathin Chandra Shit"], "title": "Path-Coordinated Continual Learning with Neural Tangent Kernel-Justified Plasticity: A Theoretical Framework with Near State-of-the-Art Performance", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Under review, IEEE Letters", "summary": "Catastrophic forgetting is one of the fundamental issues of continual\nlearning because neural networks forget the tasks learned previously when\ntrained on new tasks. The proposed framework is a new path-coordinated\nframework of continual learning that unites the Neural Tangent Kernel (NTK)\ntheory of principled plasticity bounds, statistical validation by Wilson\nconfidence intervals, and evaluation of path quality by the use of multiple\nmetrics. Experimental evaluation shows an average accuracy of 66.7% at the cost\nof 23.4% catastrophic forgetting on Split-CIFAR10, a huge improvement over the\nbaseline and competitive performance achieved, which is very close to\nstate-of-the-art results. Further, it is found out that NTK condition numbers\nare predictive indicators of learning capacity limits, showing the existence of\na critical threshold at condition number $>10^{11}$. It is interesting to note\nthat the proposed strategy shows a tendency of lowering forgetting as the\nsequence of tasks progresses (27% to 18%), which is a system stabilization. The\nframework validates 80% of discovered paths with a rigorous statistical\nguarantee and maintains 90-97% retention on intermediate tasks. The core\ncapacity limits of the continual learning environment are determined in the\nanalysis, and actionable insights to enhance the adaptive regularization are\noffered."}
{"id": "2511.02189", "pdf": "https://arxiv.org/pdf/2511.02189", "abs": "https://arxiv.org/abs/2511.02189", "authors": ["Minje Kim", "Hongjae Nam", "Beomsoo Ko", "Hyeongjun Park", "Hwanjin Kim", "Dong-Hyun Jung", "Junil Choi"], "title": "Analysis of Beam Misalignment Effect in Inter-Satellite FSO Links", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": "12 pages, 11 figures, submitted to IEEE Transactions on Wireless\n  Communications (TWC)", "summary": "Free-space optical (FSO) communication has emerged as a promising technology\nfor inter-satellite links (ISLs) due to its high data rate, low power\nconsumption, and reduced interference. However, the performance of\ninter-satellite FSO systems is highly sensitive to beam misalignment. While\npointing-ahead angle (PAA) compensation is commonly employed, the effectiveness\nof PAA compensation depends on precise orbital knowledge and advanced alignment\nhardware, which are not always feasible in practice. To address this challenge,\nthis paper investigates the impact of beam misalignment on inter-satellite FSO\ncommunication. We derive a closed-form expression for the cumulative\ndistribution function (CDF) of the FSO channel under the joint jitter and\nmisalignment-induced pointing error, and introduce a truncated CDF formulation\nwith a bisection algorithm to efficiently compute outage probabilities with\nguaranteed convergence and minimal computational overhead. To make the analysis\nmore practical, we quantify displacement based on orbital dynamics. Numerical\nresults demonstrate that the proposed model closely matches Monte Carlo\nsimulations, making the proposed model highly useful to design inter-satellite\nFSO systems in practice."}
{"id": "2511.02329", "pdf": "https://arxiv.org/pdf/2511.02329", "abs": "https://arxiv.org/abs/2511.02329", "authors": ["Shaohan Li", "Yunpeng Shi", "Gilad Lerman"], "title": "Cycle-Sync: Robust Global Camera Pose Estimation through Enhanced Cycle-Consistent Synchronization", "categories": ["cs.CV", "cs.NA", "cs.RO", "math.NA", "stat.ME", "90C26, 90C17, 68Q87, 65C20, 90-08, 60-08", "G.1.6; I.4.0"], "comment": "NeurIPS 2025 spotlight paper", "summary": "We introduce Cycle-Sync, a robust and global framework for estimating camera\nposes (both rotations and locations). Our core innovation is a location solver\nthat adapts message-passing least squares (MPLS) -- originally developed for\ngroup synchronization -- to camera location estimation. We modify MPLS to\nemphasize cycle-consistent information, redefine cycle consistencies using\nestimated distances from previous iterations, and incorporate a Welsch-type\nrobust loss. We establish the strongest known deterministic exact-recovery\nguarantee for camera location estimation, showing that cycle consistency alone\n-- without access to inter-camera distances -- suffices to achieve the lowest\nsample complexity currently known. To further enhance robustness, we introduce\na plug-and-play outlier rejection module inspired by robust subspace recovery,\nand we fully integrate cycle consistency into MPLS for rotation\nsynchronization. Our global approach avoids the need for bundle adjustment.\nExperiments on synthetic and real datasets show that Cycle-Sync consistently\noutperforms leading pose estimators, including full structure-from-motion\npipelines with bundle adjustment."}
{"id": "2511.02252", "pdf": "https://arxiv.org/pdf/2511.02252", "abs": "https://arxiv.org/abs/2511.02252", "authors": ["Junyi Fan", "Donald S. Williamson"], "title": "From the perspective of perceptual speech quality: The robustness of frequency bands to noise", "categories": ["eess.AS", "cs.SD", "eess.SP"], "comment": "Accepted to J. Acoust. Soc. Am. (JASA) 155, 1916-1927 (2024)", "summary": "Speech quality is one of the main foci of speech-related research, where it\nis frequently studied with speech intelligibility, another essential\nmeasurement. Band-level perceptual speech intelligibility, however, has been\nstudied frequently, whereas speech quality has not been thoroughly analyzed. In\nthis paper, a Multiple Stimuli With Hidden Reference and Anchor (MUSHRA)\ninspired approach was proposed to study the individual robustness of frequency\nbands to noise with perceptual speech quality as the measure. Speech signals\nwere filtered into thirty-two frequency bands with compromising real-world\nnoise employed at different signal-to-noise ratios. Robustness to noise indices\nof individual frequency bands was calculated based on the human-rated\nperceptual quality scores assigned to the reconstructed noisy speech signals.\nTrends in the results suggest the mid-frequency region appeared less robust to\nnoise in terms of perceptual speech quality. These findings suggest future\nresearch aiming at improving speech quality should pay more attention to the\nmid-frequency region of the speech signals accordingly."}
{"id": "2511.02417", "pdf": "https://arxiv.org/pdf/2511.02417", "abs": "https://arxiv.org/abs/2511.02417", "authors": ["Garen Boyadjian", "Cyrille Pierre", "Johann Laconte", "Riccardo Bertoglio"], "title": "Synthetic Crop-Weed Image Generation and its Impact on Model Generalization", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Precise semantic segmentation of crops and weeds is necessary for\nagricultural weeding robots. However, training deep learning models requires\nlarge annotated datasets, which are costly to obtain in real fields. Synthetic\ndata can reduce this burden, but the gap between simulated and real images\nremains a challenge. In this paper, we present a pipeline for procedural\ngeneration of synthetic crop-weed images using Blender, producing annotated\ndatasets under diverse conditions of plant growth, weed density, lighting, and\ncamera angle. We benchmark several state-of-the-art segmentation models on\nsynthetic and real datasets and analyze their cross-domain generalization. Our\nresults show that training on synthetic images leads to a sim-to-real gap of\n10%, surpassing previous state-of-the-art methods. Moreover, synthetic data\ndemonstrates good generalization properties, outperforming real datasets in\ncross-domain scenarios. These findings highlight the potential of synthetic\nagricultural datasets and support hybrid strategies for more efficient model\ntraining."}
{"id": "2511.02282", "pdf": "https://arxiv.org/pdf/2511.02282", "abs": "https://arxiv.org/abs/2511.02282", "authors": ["Nam N. Luong", "Chuyen T. Nguyen", "Thanh V. Pham"], "title": "Performance Analysis of NOMA-Assisted Optical OFDM ISAC Systems with Clipping Distortion", "categories": ["eess.SY", "cs.IT", "cs.SY", "eess.SP", "math.IT"], "comment": null, "summary": "This paper studies the performance of optical orthogonal frequency-division\nmultiplexing (OFDM)-based multi-user integrated sensing and communication\n(ISAC) systems employing non-orthogonal multiple access (NOMA). Due to their\ninherent high peak-to-average power ratio (PAPR), OFDM waveforms are clipped to\nfit the limited dynamic range of the optical transmitters (e.g., light-emitting\ndiodes (LEDs)), resulting in clipping distortion. To alleviate the impact of\nthe distortion, we propose a novel transmitter architecture where the clipping\nprocesses are performed before NOMA superposition coding. We then analyze the\nperformance of the proposed optical ISAC systems considering the effects of\npower allocation and clipping distortion. For the communication subsystem, we\nanalyze the effect of NOMA on the achievable sum rate and bit error rate (BER).\nFor the sensing subsystem, the root mean square error (RMSE) and Cram\\'er-Rao\nbound (CRB) of estimating the transmission distance accuracy are obtained.\nSimulation results reveal that allocating more power to the strong user yields\na higher sum rate, lower BER, and better sensing performance, whereas a more\nbalanced power allocation among users results in degraded BER and sensing\nperformance."}
{"id": "2511.02427", "pdf": "https://arxiv.org/pdf/2511.02427", "abs": "https://arxiv.org/abs/2511.02427", "authors": ["Nicolas Schuler", "Lea Dewald", "Nick Baldig", "Jürgen Graf"], "title": "From the Laboratory to Real-World Application: Evaluating Zero-Shot Scene Interpretation on Edge Devices for Mobile Robotics", "categories": ["cs.CV", "cs.RO"], "comment": "15 pages, 6 figures, 1 table; accepted for AI-2025 Forty-fifth SGAI\n  International Conference on Artificial Intelligence CAMBRIDGE, ENGLAND 16-18\n  DECEMBER 2025", "summary": "Video Understanding, Scene Interpretation and Commonsense Reasoning are\nhighly challenging tasks enabling the interpretation of visual information,\nallowing agents to perceive, interact with and make rational decisions in its\nenvironment. Large Language Models (LLMs) and Visual Language Models (VLMs)\nhave shown remarkable advancements in these areas in recent years, enabling\ndomain-specific applications as well as zero-shot open vocabulary tasks,\ncombining multiple domains. However, the required computational complexity\nposes challenges for their application on edge devices and in the context of\nMobile Robotics, especially considering the trade-off between accuracy and\ninference time. In this paper, we investigate the capabilities of\nstate-of-the-art VLMs for the task of Scene Interpretation and Action\nRecognition, with special regard to small VLMs capable of being deployed to\nedge devices in the context of Mobile Robotics. The proposed pipeline is\nevaluated on a diverse dataset consisting of various real-world cityscape,\non-campus and indoor scenarios. The experimental evaluation discusses the\npotential of these small models on edge devices, with particular emphasis on\nchallenges, weaknesses, inherent model biases and the application of the gained\ninformation. Supplementary material is provided via the following repository:\nhttps://datahub.rz.rptu.de/hstr-csrl-public/publications/scene-interpretation-on-edge-devices/"}
{"id": "2511.02291", "pdf": "https://arxiv.org/pdf/2511.02291", "abs": "https://arxiv.org/abs/2511.02291", "authors": ["Kwonyeol Park", "Gyoseung Lee", "Hyeongtaek Lee", "Hwanjin Kim", "Junil Choi"], "title": "Downlink Channel Estimation for mmWave Systems with Impulsive Interference", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": "5 pages, 2 figures", "summary": "In this paper, we investigate a channel estimation problem in a downlink\nmillimeter-wave (mmWave) multiple-input multiple-output (MIMO) system, which\nsuffers from impulsive interference caused by hardware non-idealities or\nexternal disruptions. Specifically, impulsive interference presents a\nsignificant challenge to channel estimation due to its sporadic, unpredictable,\nand high-power nature. To tackle this issue, we develop a Bayesian channel\nestimation technique based on variational inference (VI) that leverages the\nsparsity of the mmWave channel in the angular domain and the intermittent\nnature of impulsive interference to minimize channel estimation errors. The\nproposed technique employs mean-field approximation to approximate posterior\ninference and integrates VI into the sparse Bayesian learning (SBL) framework.\nSimulation results demonstrate that the proposed technique outperforms\nbaselines in terms of channel estimation accuracy."}
{"id": "2511.02507", "pdf": "https://arxiv.org/pdf/2511.02507", "abs": "https://arxiv.org/abs/2511.02507", "authors": ["Nicolas Schuler", "Lea Dewald", "Jürgen Graf"], "title": "Keeping it Local, Tiny and Real: Automated Report Generation on Edge Computing Devices for Mechatronic-Based Cognitive Systems", "categories": ["cs.CV", "cs.RO"], "comment": "6 pages, 4 figures, 1 table; accepted for MECATRONICS-REM 2025\n  International Conference, PARIS, FRANCE December 3-5 2025", "summary": "Recent advancements in Deep Learning enable hardware-based cognitive systems,\nthat is, mechatronic systems in general and robotics in particular with\nintegrated Artificial Intelligence, to interact with dynamic and unstructured\nenvironments. While the results are impressive, the application of such systems\nto critical tasks like autonomous driving as well as service and care robotics\nnecessitate the evaluation of large amount of heterogeneous data. Automated\nreport generation for Mobile Robotics can play a crucial role in facilitating\nthe evaluation and acceptance of such systems in various domains. In this\npaper, we propose a pipeline for generating automated reports in natural\nlanguage utilizing various multi-modal sensors that solely relies on local\nmodels capable of being deployed on edge computing devices, thus preserving the\nprivacy of all actors involved and eliminating the need for external services.\nIn particular, we evaluate our implementation on a diverse dataset spanning\nmultiple domains including indoor, outdoor and urban environments, providing\nquantitative as well as qualitative evaluation results. Various generated\nexample reports and other supplementary materials are available via a public\nrepository."}
{"id": "2511.02320", "pdf": "https://arxiv.org/pdf/2511.02320", "abs": "https://arxiv.org/abs/2511.02320", "authors": ["Kwonyeol Park", "Hyuckjin Choi", "Beomsoo Ko", "Minje Kim", "Gyoseung Lee", "Daecheol Kwon", "Hyunjae Park", "Byungseung Kim", "Min-Ho Shin", "Junil Choi"], "title": "Anomaly Detection-Based UE-Centric Inter-Cell Interference Suppression", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": "14 pages, 14 figures", "summary": "The increasing spectral reuse can cause significant performance degradation\ndue to interference from neighboring cells. In such scenarios, developing\neffective interference suppression schemes is necessary to improve overall\nsystem performance. To tackle this issue, we propose a novel user\nequipment-centric interference suppression scheme, which effectively detects\ninter-cell interference (ICI) and subsequently applies interference whitening\nto mitigate ICI. The proposed scheme, named Z-refined deep support vector data\ndescription, exploits a one-class classification-based anomaly detection\ntechnique. Numerical results verify that the proposed scheme outperforms\nvarious baselines in terms of interference detection performance with limited\ntime or frequency resources for training and is comparable to the performance\nbased on an ideal genie-aided interference suppression scheme. Furthermore, we\ndemonstrate through test equipment experiments using a commercial\nfifth-generation modem chipset that the proposed scheme shows performance\nimprovements across various 3rd generation partnership project standard channel\nenvironments, including tapped delay line-A, -B, and -C models."}
{"id": "2511.02526", "pdf": "https://arxiv.org/pdf/2511.02526", "abs": "https://arxiv.org/abs/2511.02526", "authors": ["Marc Schneider", "Walter Fichter"], "title": "Many-vs-Many Missile Guidance via Virtual Targets", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY"], "comment": "will be submitted to Journal of Guidance, Control, and Dynamics as\n  Technical Note", "summary": "This paper presents a novel approach to many-vs-many missile guidance using\nvirtual targets (VTs) generated by a Normalizing Flows-based trajectory\npredictor. Rather than assigning n interceptors directly to m physical targets\nthrough conventional weapon target assignment algorithms, we propose a\ncentralized strategy that constructs n VT trajectories representing\nprobabilistic predictions of maneuvering target behavior. Each interceptor is\nguided toward its assigned VT using Zero-Effort-Miss guidance during midcourse\nflight, transitioning to Proportional Navigation guidance for terminal\ninterception. This approach treats many-vs-many engagements as\nmany-vs-distribution scenarios, exploiting numerical superiority (n > m) by\ndistributing interceptors across diverse trajectory hypotheses rather than\npursuing identical deterministic predictions. Monte Carlo simulations across\nvarious target-interceptor configurations (1-6 targets, 1-8 interceptors)\ndemonstrate that the VT method matches or exceeds baseline straight-line\nprediction performance by 0-4.1% when n = m, with improvements increasing to\n5.8-14.4% when n > m. The results confirm that probabilistic VTs enable\neffective exploitation of numerical superiority, significantly increasing\ninterception probability in many-vs-many scenarios."}
{"id": "2511.02373", "pdf": "https://arxiv.org/pdf/2511.02373", "abs": "https://arxiv.org/abs/2511.02373", "authors": ["Jean-Baptiste Courbot", "Hugo Gangloff", "Bruno Colicchio"], "title": "A new class of Markov random fields enabling lightweight sampling", "categories": ["stat.ML", "cs.LG", "eess.SP", "stat.CO"], "comment": null, "summary": "This work addresses the problem of efficient sampling of Markov random fields\n(MRF). The sampling of Potts or Ising MRF is most often based on Gibbs\nsampling, and is thus computationally expensive. We consider in this work how\nto circumvent this bottleneck through a link with Gaussian Markov Random\nfields. The latter can be sampled in several cost-effective ways, and we\nintroduce a mapping from real-valued GMRF to discrete-valued MRF. The resulting\nnew class of MRF benefits from a few theoretical properties that validate the\nnew model. Numerical results show the drastic performance gain in terms of\ncomputational efficiency, as we sample at least 35x faster than Gibbs sampling\nusing at least 37x less energy, all the while exhibiting empirical properties\nclose to classical MRFs."}
{"id": "2511.02484", "pdf": "https://arxiv.org/pdf/2511.02484", "abs": "https://arxiv.org/abs/2511.02484", "authors": ["Ismail Zrigui", "Samira Khoulji", "Mohamed Larbi Kerkeb"], "title": "Using ensemble learning with hybrid graph neural networks and transformers to predict traffic in cities", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": null, "summary": "Intelligent transportation systems (ITS) still have a hard time accurately\npredicting traffic in cities, especially in big, multimodal settings with\ncomplicated spatiotemporal dynamics. This paper presents HybridST, a hybrid\narchitecture that integrates Graph Neural Networks (GNNs), multi-head temporal\nTransformers, and supervised ensemble learning methods (XGBoost or Random\nForest) to collectively capture spatial dependencies, long-range temporal\npatterns, and exogenous signals, including weather, calendar, or control\nstates. We test our model on the METR-LA, PEMS-BAY, and Seattle Loop tree\npublic benchmark datasets. These datasets include situations ranging from\nfreeway sensor networks to vehicle-infrastructure cooperative perception.\nExperimental results show that HybridST consistently beats classical baselines\n(LSTM, GCN, DCRNN, PDFormer) on important metrics like MAE and RMSE, while\nstill being very scalable and easy to understand. The proposed framework\npresents a promising avenue for real-time urban mobility planning, energy\noptimization, and congestion alleviation strategies, especially within the\nframework of smart cities and significant events such as the 2030 FIFA World\nCup."}
{"id": "2511.02765", "pdf": "https://arxiv.org/pdf/2511.02765", "abs": "https://arxiv.org/abs/2511.02765", "authors": ["Saeed Razavikia", "José Mairton Barros Da Silva Junior", "Carlo Fischione"], "title": "VecComp: Vector Computing via MIMO Digital Over-the-Air Computation", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Recently, the ChannelComp framework has proposed digital over-the-air\ncomputation by designing digital modulations that enable the computation of\narbitrary functions. Unlike traditional analog over-the-air computation, which\nis restricted to nomographic functions, ChannelComp enables a broader range of\ncomputational tasks while maintaining compatibility with digital communication\nsystems. This framework is intended for applications that favor local\ninformation processing over the mere acquisition of data. However, ChannelComp\nis currently designed for scalar function computation, while numerous\ndata-centric applications necessitate vector-based computations, and it is\nsusceptible to channel fading. In this work, we introduce a generalization of\nthe ChannelComp framework, called VecComp, by integrating ChannelComp with\nmultiple-antenna technology. This generalization not only enables vector\nfunction computation but also ensures scalability in the computational\ncomplexity, which increases only linearly with the vector dimension. As such,\nVecComp remains computationally efficient and robust against channel\nimpairments, making it suitable for high-dimensional, data-centric\napplications. We establish a non-asymptotic upper bound on the mean squared\nerror of VecComp, affirming its computation efficiency under fading channel\nconditions. Numerical experiments show the effectiveness of VecComp in\nimproving the computation of vector functions and fading compensation over\nnoisy and fading multiple-access channels."}
{"id": "2511.02803", "pdf": "https://arxiv.org/pdf/2511.02803", "abs": "https://arxiv.org/abs/2511.02803", "authors": ["Ismail Cosandal", "Sennur Ulukus"], "title": "Optimal Source Coding of Markov Chains for Real-Time Remote Estimation", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "We revisit the source coding problem for a Markov chain under the assumption\nthat the transmission times and how fast the Markov chain transitions its state\nhappen at the same time-scale. Specifically, we assume that the transmission of\neach bit takes a single time slot, and the Markov chain updates its state in\nthe same time slot. Thus, the length of the codeword assigned to a symbol\ndetermines the number of non-transmitted symbols, as well as, the probability\nof the realization of the next symbol to be transmitted. We aim to minimize the\naverage transmission duration over an infinite horizon by proposing an optimal\nsource coding policy based on the last transmitted symbol and its transmission\nduration. To find the optimal policy, we formulate the problem with a Markov\ndecision process (MDP) by augmenting the symbols alongside the transmission\nduration of the symbols. Finally, we analyze two Huffman-based benchmark\npolicies and compare their performances with the proposed optimal policy. We\nobserve that, in randomly generated processes, our proposed optimal policy\ndecreases the average transmission duration compared to benchmark policies. The\nperformance gain varies based on the parameters of the Markov process."}
