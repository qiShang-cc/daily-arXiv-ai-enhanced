<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 40]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.LG](#cs.LG) [Total: 7]
- [eess.SY](#eess.SY) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [stat.ML](#stat.ML) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Illuminating the Path: Attention-Assisted Beamforming and Predictive Insights in 5G NR Systems](https://arxiv.org/abs/2505.18160)
*Dino Pjanić,Guoda Tian,Andres Reial,Xuesong Cai,Bo Bernhardsson,Fredrik Tufvesson*

Main category: eess.SP

TL;DR: 该研究利用AI驱动的注意力模型优化5G波束管理，通过实时和历史数据预测最佳波束，显著提升复杂非视距环境下的通信效率。


<details>
  <summary>Details</summary>
Motivation: 传统波束管理在复杂信道条件下的移动性表现不佳，需通过AI创新解决高维度信道动态和散射信号变化的挑战。

Method: 采用基于注意力的预测模型，结合实时信道状态和用户定位数据，从完整下行链路中精准筛选最优波束子集。

Result: 模型在信号弥散环境中表现稳健，尤其在移动场景中优于传统穷举式波束预测方法。

Conclusion: 该方法为5G波束管理提供了高效、自适应的新范式，有望推动未来无线通信系统的发展。

Abstract: Artificial intelligence advances have recently influenced wireless
communications, including beam management in fifth-generation (5G) new radio
systems. AI-driven models and algorithms are being applied to enhance tasks
such as beam selection, prediction, and refinement by leveraging real-time and
historical data. These approaches address challenges such as mobility under
complex channel conditions, showing promising results compared to traditional
methods. Beam management in 5G refers to processes that ensure optimal
alignment between the base station and user equipment for effective signal
transmission and reception based on real-time channel state information and
user positioning. This study leverages accurate beam prediction to identify a
smaller subset of beams, resulting in a more efficient, streamlined, and
link-adaptive communication system. The innovative approach presented
introduces a precise, attention-based prediction model that derives the entire
downlink transmission chain in a commercial grade 5G system. The predicted
downlink beams are specifically tailored to handle the complexities of none
line-of-sight environments known for high-dimensional channel dynamics and
scatterer-induced signal variations. This novel method introduces a paradigm
shift in utilizing environmental and channel dynamics in contrast to
conventional procedures of beam management, which entails complex methods
involving exhaustive techniques to predict the best beams. The presented beam
prediction results demonstrate robustness in addressing the challenges posed by
signal-dispersive environments, showcasing great potential in mobility
scenarios.

</details>


### [2] [Accelerating Battery Material Optimization through iterative Machine Learning](https://arxiv.org/abs/2505.18162)
*Seon-Hwa Lee,Insoo Ye,Changhwan Lee,Jieun Kim,Geunho Choi,Sang-Cheol Nam,Inchul Park*

Main category: eess.SP

TL;DR: 论文提出了一种基于机器学习的主动学习框架，用于优化电池材料的制备过程，减少实验次数并克服传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着工业发展，电池材料制备的参数复杂性增加，传统一因次实验方法效率低下且易受人为偏见影响，亟需更高效的方法。

Method: 采用迭代式机器学习框架，结合主动学习指导实验，逐步优化模型，充分利用成功和失败的实验数据。

Result: 主动学习驱动的实验方法显著减少了所需实验次数，加速了高维设计空间的探索。

Conclusion: 基于机器学习的策略在电池材料优化中具有变革潜力，能够高效减少实验成本并提升性能。

Abstract: The performance of battery materials is determined by their composition and
the processing conditions employed during commercial-scale fabrication, where
raw materials undergo complex processing steps with various additives to yield
final products. As the complexity of these parameters expands with the
development of industry, conventional one-factor-at-a-time (OFAT) experiment
becomes old fashioned. While domain expertise aids in parameter optimization,
this traditional approach becomes increasingly vulnerable to cognitive
limitations and anthropogenic biases as the complexity of factors grows.
Herein, we introduce an iterative machine learning (ML) framework that
integrates active learning to guide targeted experimentation and facilitate
incremental model refinement. This method systematically leverages
comprehensive experimental observations, including both successful and
unsuccessful results, effectively mitigating human-induced biases and
alleviating data scarcity. Consequently, it significantly accelerates
exploration within the high-dimensional design space. Our results demonstrate
that active-learning-driven experimentation markedly reduces the total number
of experimental cycles necessary, underscoring the transformative potential of
ML-based strategies in expediting battery material optimization.

</details>


### [3] [Ray Antenna Array: A Novel Cost-Effective Multi-Antenna Architecture for Enhanced Wireless Communication](https://arxiv.org/abs/2505.18163)
*Zhenjun Dong,Zhiwen Zhou,Yong Zeng*

Main category: eess.SP

TL;DR: 论文提出了一种新型多天线架构——射线天线阵列（RAA），通过低成本的大规模天线元素和少量射频链提升无线通信性能。RAA无需依赖模拟或数字波束成形，显著降低了硬件成本，同时通过高方向性配置提高了系统性能。仿真结果显示RAA在性能和成本上均优于传统混合波束成形（HBF）。


<details>
  <summary>Details</summary>
Motivation: 传统多天线架构（如HBF）依赖昂贵的移相器，尤其在高频系统中成本高昂。RAA的设计旨在通过低成本方案提升无线通信性能，解决硬件成本和系统性能的平衡问题。

Method: RAA采用射线状结构，每条射线对应一个简单均匀线性阵列（sULA），通过射频组合器直接形成定向波束。设计了射线选择网络（RSN）动态连接sULA与射频链，并提出了联合射线选择和波束成形的高效算法。

Result: 仿真结果表明，RAA在降低硬件成本（无需移相器）的同时，通过高方向性配置显著提升了系统性能，性能优于传统HBF架构。

Conclusion: RAA是一种低成本高性能的多天线架构解决方案，适用于单用户和多用户无线通信场景，未来在高频系统中具有广泛应用潜力。

Abstract: This paper proposes a novel multi-antenna architecture, termed ray antenna
array (RAA), which aims to enhance wireless communication performance in a
cost-effective manner. RAA is composed of massive cheap antenna elements and a
few radio frequency (RF) chains. The massive antenna elements are arranged in a
novel ray-like structure, with each ray corresponding to a simple uniform
linear array (sULA) with a carefully designed orientation. The antenna elements
of each sULA are directly connected to an RF combiner, so that the sULA in each
ray is able to form a beam towards a direction matching the ray orientation
without relying on any analog or digital beamforming. By further designing a
ray selection network (RSN), appropriate sULAs are selected to connect to the
RF chains for further baseband processing. Compared to conventional
multi-antenna architectures like hybrid analog/digital beamforming (HBF), the
proposed RAA has two major advantages. First, it can significantly reduce
hardware costs since no phase shifters, which are usually expensive especially
in high-frequency systems, are required. Besides, RAA can greatly improve
system performance by configuring antenna elements with higher directionality,
as each sULA only needs to be responsible for a portion of the total coverage
angle. To demonstrate such advantages, in this paper, we first present the
input-output model for RAA-based wireless communications, based on which the
ray orientations of the RAA are designed. Furthermore, efficient algorithms for
joint ray selection and beamforming are proposed for single-user and multi-user
RAA-based wireless communications. Simulation results demonstrate the superior
performance of RAA compared to HBF while significantly reducing hardware cost.

</details>


### [4] [A Comprehensive PPG-based Dataset for HR/HRV Studies](https://arxiv.org/abs/2505.18165)
*Jingye Xu,Yuntong Zhang,Wei Wang,Mimi Xie,Dakai Zhu*

Main category: eess.SP

TL;DR: 该研究提出了一个全面的多模态长期PPG数据集（UTSA-PPG），填补了HR/HRV研究中缺乏一体化数据集的空白，并验证了其价值。


<details>
  <summary>Details</summary>
Motivation: 现有PPG数据集难以满足多场景、长期监测和多模态（如多通道PPG和加速度数据）的需求，因此需要构建一个全面的数据集。

Method: 研究首先回顾了现有数据集的优劣势，随后开发了自定义数据采集系统，收集了UTSA-PPG数据集，并通过五个案例研究验证其价值。

Result: UTSA-PPG数据集在HR/HRV估计研究中表现出实用价值，并有望支持研究人员构建通用模型应对特定挑战。

Conclusion: 该数据集为HR/HRV研究提供了重要资源，推动了多模态长期监测的进一步发展。

Abstract: Heart rate (HR) and heart rate variability (HRV) are important vital signs
for human physical and mental health. Recent research has demonstrated that
photoplethysmography (PPG) sensors can infer HR and HRV. However, it is
difficult to find a comprehensive PPG-based dataset for HR/HRV studies,
especially for various study needs: multiple scenes, long-term monitoring, and
multimodality (multiple PPG channels and extra acceleration data). In this
study, we collected a comprehensive multimodal long-term dataset to address the
gap of missing an all-in-one HR/HRV dataset (denoted as UTSA-PPG). We began by
reviewing state-of-the-art datasets, emphasizing their strengths and
limitations. Following this, we developed a custom data acquisition system and
then collected the UTSA-PPG dataset and compared its key features with those of
existing datasets. Additionally, five case studies were conducted, including
comparisons with state-of-the-art datasets. The outcomes highlight the value of
our dataset, demonstrating its utility for HR/HRV estimation exploration and
its potential to aid researchers in creating generalized models for targeted
research challenges.

</details>


### [5] [Dim and Small Target Detection for Drone Broadcast Frames Based on Time-Frequency Analysis](https://arxiv.org/abs/2505.18167)
*Jie Li,Jing Li,Zhanyu Ju,Fengkui Gong,Lu Lv*

Main category: eess.SP

TL;DR: 提出一种基于通信协议时频分析的无人机广播帧微弱小目标检测算法，通过调制参数和帧结构分析提升检测精度，尤其适用于低信噪比环境。


<details>
  <summary>Details</summary>
Motivation: 无人机广播帧中的微弱小目标在低信噪比环境下检测精度不足，现有算法难以满足需求。

Method: 利用调制参数、帧结构和ZC序列进行频域参数校正，结合分段能量细化法优化时域检测参数，平衡检测精度与速度。

Result: 仿真显示，算法在平均交并比、精确率和召回率上分别提升3%、1.4%和2.4%，且在多种环境下表现稳健。

Conclusion: 所提算法有效提升了无人机广播帧微弱小目标的检测性能，适用于不同监管需求。

Abstract: We propose a dim and small target detection algorithm for drone broadcast
frames based on the time-frequency analysis of communication protocol.
Specifically, by analyzing modulation parameters and frame structures, the
prior knowledge of transmission frequency, signal bandwidth, Zadoff-Chu (ZC)
sequences, and frame length of drone broadcast frames is established. The RF
signals are processed through the designed filter banks, and the frequency
domain parameters of bounding boxes generated by the detector are corrected
with transmission frequency and signal bandwidth. Given the remarkable
correlation characteristics of ZC sequences, the frequency domain parameters of
bounding boxes with low confidence scores are corrected based on ZC sequences
and frame length, which improves the detection accuracy of dim targets under
low signal-to noise ratio (SNR) situations. Besides, a segmented energy
refinement method is applied to mitigate the deviation caused by interference
signals with high energy strength, which ulteriorly corrects the time domain
detection parameters for dim targets. As the sampling duration increases, the
detection speed improves while the detection accuracy of broadcast frames
termed as small targets decreases. The trade-off between detection accuracy and
speed versus sampling duration is established, which helps to meet different
drone regulation requirements. Simulation results demonstrate that the proposed
algorithm improves the average intersection over union, precision, and recall
by 3\%, 1.4\%, and 2.4\%, respectively, compared to existing algorithms. The
proposed algorithm also performs strong robustness under varying flight
distances, diverse types of environment noise, and different flight visual
environment.

</details>


### [6] [Load Forecasting in the Era of Smart Grids: Opportunities and Advanced Machine Learning Models](https://arxiv.org/abs/2505.18170)
*Aurausp Maneshni*

Main category: eess.SP

TL;DR: 论文探讨了电力系统中短期负荷预测的重要性，并比较了四种机器学习框架（XGBoost、LightGBM、LSTM、GRU）及混合框架的表现，结果表明机器学习模型优于传统ARIMA方法。


<details>
  <summary>Details</summary>
Motivation: 电力供需实时平衡对电网稳定至关重要。负荷预测的准确性直接影响资源利用效率与电网可靠性，因此研究高效的短期负荷预测方法是必要的。

Method: 使用了梯度提升决策树方法（XGBoost、LightGBM）和两种循环神经网络（LSTM、GRU），并开发了混合框架。通过Pearson相关系数评估电力需求与外生变量的关系。

Result: 实验结果显示，针对特定数据集和预测任务，机器学习模型在预测性能上优于传统的ARIMA基准模型。

Conclusion: 机器学习框架，尤其是XGBoost和LightGBM，在短期负荷预测中表现出色，混合框架和RNN架构（LSTM、GRU）也展现了潜力。

Abstract: Electric energy is difficult to store, requiring stricter control over its
generation, transmission, and distribution. A persistent challenge in power
systems is maintaining real-time equilibrium between electricity demand and
supply. Oversupply contributes to resource wastage, while undersupply can
strain the grid, increase operational costs, and potentially impact service
reliability. To maintain grid stability, load forecasting is needed. Accurate
load forecasting balances generation and demand by striving to predict future
electricity consumption. This thesis examines and evaluates four machine
learning frameworks for short term load forecasting, including gradient
boosting decision tree methods such as Extreme Gradient Boosting (XGBoost) and
Light Gradient Boosting Machine (LightGBM). A hybrid framework is also
developed. In addition, two recurrent neural network architectures, Long Short
Term Memory (LSTM) networks and Gated Recurrent Units (GRU), are designed and
implemented. Pearson Correlation Coefficient is applied to assess the
relationships between electricity demand and exogenous variables. The
experimental results show that, for the specific dataset and forecasting task
in this study, machine learning-based models achieved improved forecasting
performance compared to a classical ARIMA baseline.

</details>


### [7] [IoT-Enabled Hemodynamic Surveillance System: AD8232 Bioelectric Signal Processing with ESP32](https://arxiv.org/abs/2505.18173)
*Hemalatha R J,Shubham Malhotra,Shivapanchakshari T G,Lokesh K,Dev Anand D,Samson Jebakumar S*

Main category: eess.SP

TL;DR: 这篇论文提出了一种基于物联网的ECG追踪设备，用于诊断心肺问题，通过AD8232心率传感器和ESP32扩展套件实时监测ECG信号，并通过智能手机应用分析数据。


<details>
  <summary>Details</summary>
Motivation: 设计一个经济高效、用户友好的ECG监测系统，为患者和医疗专业人员提供远程实时心血管健康监测，同时探索酒精摄入对心脏健康的影响。

Method: 使用AD8232心率传感器和ESP32扩展套件构建设备，通过Wi-Fi将ECG信号传输至智能手机应用进行数据分析。

Result: 开发了一个实时监测ECG信号的系统，能够测量心率、体温等关键指标，并分析酒精对心脏健康的影响。

Conclusion: 该研究成功实现了一种高效且成本较低的ECG监测方案，适用于远程医疗和健康管理，为心肺问题的早期诊断提供了新工具。

Abstract: This dissertation proposes an electrocardiogram (ECG) tracking device that
diagnoses cardiopulmonary problems using the Internet of Things (IoT) desired
results. The initiative is built on the internet observing an electrocardiogram
with the AD8232 heart rhythm sensor and the ESP32 expansion kit, using an
on-premise connected device platform to transform sensing input into meaningful
data. That subsequently supervises an ECG signal and delivers it to an
intelligent phone via Wi-Fi for data analysis. That is the pace of the
circulating. Assessing body temperature, pulse rate, and coronary arteries are
vital measures to defend your health. The heartbeat rate may be measured in two
ways: there are by palpating the pulse at the wrist or neck directly or other
alternative by utilizing a cardiac sensor. Monitoring alcohol levels in cardiac
patients is critical for measuring the influence of liquor on their health and
the efficacy of therapy. It assists in recognizing the association between
alcohol consumption and cardiac issues, rather than rhythm recorded in beats
per minute (bpm). An IR transmitter/receiver pair (OLED) needs to stay
compatible up near the sensor's knuckle current or voltage pulse. The
detector's electrical output is evaluated by suitable electronic circuits to
produce a visual clue (digital display). We must design a cost-effective,
user-friendly, and efficient ECG monitoring system with contemporary technology
for both persons imprisoned by disease or aging, as well as healthcare
professionals. Microcontroller combined with software. A smartphone application
is created to monitor the cardiovascular health of distant patients in
real-time

</details>


### [8] [NMCSE: Noise-Robust Multi-Modal Coupling Signal Estimation Method via Optimal Transport for Cardiovascular Disease Detection](https://arxiv.org/abs/2505.18174)
*Zhixin li,Peihong Zhang,Rui Sang,Yuxuan Liu,Shengchen Li*

Main category: eess.SP

TL;DR: 论文提出NMCSE方法，通过最优传输理论解决ECG和PCG信号的噪声问题，提升心血管疾病检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统解卷积方法在估计ECG与PCG耦合信号时会放大噪声，限制了临床应用。

Method: 采用最优传输理论重新定义问题为分布匹配，结合时-空特征提取网络。

Result: 在PhysioNet 2016数据上，NMCSE降低30%估计误差，CVD检测准确率达97.38%。

Conclusion: NMCSE在噪声环境下表现稳健，优于现有方法，适合临床推广。

Abstract: Electrocardiogram (ECG) and Phonocardiogram (PCG) signals are linked by a
latent coupling signal representing the electrical-to-mechanical cardiac
transformation. While valuable for cardiovascular disease (CVD) detection, this
coupling signal is traditionally estimated using deconvolution methods that
amplify noise, limiting clinical utility. In this paper, we propose
Noise-Robust Multi-Modal Coupling Signal Estimation (NMCSE), which reformulates
the problem as distribution matching via optimal transport theory. By jointly
optimizing amplitude and temporal alignment, NMCSE mitigates noise
amplification without additional preprocessing. Integrated with our
Temporal-Spatial Feature Extraction network, NMCSE enables robust multi-modal
CVD detection. Experiments on the PhysioNet 2016 dataset with realistic
hospital noise demonstrate that NMCSE reduces estimation errors by
approximately 30% in Mean Squared Error while maintaining higher Pearson
Correlation Coefficients across all tested signal-to-noise ratios. Our approach
achieves 97.38% accuracy and 0.98 AUC in CVD detection, outperforming
state-of-the-art methods and demonstrating robust performance for real-world
clinical applications.

</details>


### [9] [Evaluation in EEG Emotion Recognition: State-of-the-Art Review and Unified Framework](https://arxiv.org/abs/2505.18175)
*Natia Kukhilava,Tatia Tsmindashvili,Rapael Kalandadze,Anchit Gupta,Sofio Katamadze,François Brémond,Laura M. Ferrari,Philipp Müller,Benedikt Emanuel Wirth*

Main category: eess.SP

TL;DR: 该论文分析了216篇关于脑电图情绪识别（EEG-ER）的研究，发现领域内缺乏统一的评估协议。作者提出了EEGain，一个开源软件框架，旨在标准化评估流程并促进研究可比性。


<details>
  <summary>Details</summary>
Motivation: 由于EEG-ER领域缺乏统一的评估协议，导致研究成果难以公平比较和追踪进展。作者旨在解决这一不一致性问题。

Method: 作者分析了216篇论文的评估协议不一致性，并开发了EEGain框架，集成了数据预处理、分割、评估指标等功能，支持六大数据集和四种常用方法。

Result: EEGain框架成功标准化了评估流程，并在六大数据集和四种方法上进行了验证，显著提升了研究的可重复性和可比性。

Conclusion: EEGain的提出为EEG-ER领域提供了一个统一的评估工具，有助于加速该领域的整体进展。

Abstract: Electroencephalography-based Emotion Recognition (EEG-ER) has become a
growing research area in recent years. Analyzing 216 papers published between
2018 and 2023, we uncover that the field lacks a unified evaluation protocol,
which is essential to fairly define the state of the art, compare new
approaches and to track the field's progress. We report the main
inconsistencies between the used evaluation protocols, which are related to
ground truth definition, evaluation metric selection, data splitting types
(e.g., subject-dependent or subject-independent) and the use of different
datasets. Capitalizing on this state-of-the-art research, we propose a unified
evaluation protocol, EEGain (https://github.com/EmotionLab/EEGain), which
enables an easy and efficient evaluation of new methods and datasets. EEGain is
a novel open source software framework, offering the capability to compare -
and thus define - state-of-the-art results. EEGain includes standardized
methods for data pre-processing, data splitting, evaluation metrics, and the
ability to load the six most relevant datasets (i.e., AMIGOS, DEAP, DREAMER,
MAHNOB-HCI, SEED, SEED-IV) in EEG-ER with only a single line of code. In
addition, we have assessed and validated EEGain using these six datasets on the
four most common publicly available methods (EEGNet, DeepConvNet,
ShallowConvNet, TSception). This is a significant step to make research on
EEG-ER more reproducible and comparable, thereby accelerating the overall
progress of the field.

</details>


### [10] [Machine Learning-Based Analysis of ECG and PCG Signals for Rheumatic Heart Disease Detection: A Scoping Review (2015-2025)](https://arxiv.org/abs/2505.18182)
*Damilare Emmanuel Olatunji,Julius Dona Zannu,Carine Pierrette Mukamakuza,Godbright Nixon Uiso,Mona Mamoun Mubarak Aman,John Bosco Thuo,Chol Buol,Nchofon Tagha Ghogomu,Evelyne Umubyeyi*

Main category: eess.SP

TL;DR: 这篇论文系统评估了2015-2025年间利用心电图（ECG）和心音数据开发低成本风湿性心脏病（RHD）检测工具的机器学习应用，并揭示了现有方法的局限性与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 支持世界心脏联合会的‘25 by 25’降低死亡率目标，通过开发替代超声心动图的工具，服务于资源匮乏地区。

Method: 遵循PRISMA-ScR指南，系统检索PubMed、IEEE Xplore、Scopus和Embase中的相关文献，由两名独立评审员筛选，重点关注方法学、验证方式和性能指标。

Result: 分析了37项研究，发现卷积神经网络（CNN）在2020年后成为主流技术，中位准确率达93.7%，但多数研究依赖单中心数据，仅10.8%包含外部验证，且未涉及成本效益。

Conclusion: 机器学习在RHD检测中展现出潜力，但方法学限制阻碍了临床转化。未来需优先标准化基准框架、多模态架构、成本效益评估及前瞻性试验。

Abstract: Objective: To conduct a systematic assessment of machine learning
applications that utilize electrocardiogram (ECG) and heart sound data in the
development of cost-effective detection tools for rheumatic heart disease (RHD)
from the year 2015 to 2025, thereby supporting the World Heart Federation's "25
by 25" mortality reduction objective through the creation of alternatives to
echocardiography in underserved regions. Methods: Following PRISMA-ScR
guidelines, we conducted a comprehensive search across PubMed, IEEE Xplore,
Scopus, and Embase for peer-reviewed literature focusing on ML-based ECG/PCG
analysis for RHD detection. Two independent reviewers screened studies, and
data extraction focused on methodology, validation approaches, and performance
metrics. Results: Analysis of 37 relevant studies revealed that convolutional
neural networks (CNNs) have become the predominant technology in post-2020
implementations, achieving a median accuracy of 93.7%. However, 73% of studies
relied on single-center datasets, only 10.8% incorporated external validation,
and none addressed cost-effectiveness. Performance varied markedly across
different valvular lesions, and despite 44% of studies originating from endemic
regions, significant gaps persisted in implementation science and demographic
diversity. Conclusion: While ML-based ECG/PCG analysis shows promise for RHD
detection, substantial methodological limitations hinder clinical translation.
Future research must prioritize standardized benchmarking frameworks,
multimodal architectures, cost-effectiveness assessments, and prospective
trials in endemic settings. Significance: This review provides a critical
roadmap for developing accessible ML-based RHD screening tools to help bridge
the diagnostic gap in resourceconstrained settings where conventional
auscultation misses up to 90% of cases and echocardiography remains
inaccessible.

</details>


### [11] [FRAME-C: A knowledge-augmented deep learning pipeline for classifying multi-electrode array electrophysiological signals](https://arxiv.org/abs/2505.18183)
*Nisal Ranasinghe,Dzung Do-Ha,Simon Maksour,Tamasha Malepathirana,Sachith Seneviratne,Lezanne Ooi,Saman Halgamuge*

Main category: eess.SP

TL;DR: 文章介绍了一种名为FRAME-C的机器学习流程，结合领域知识、深度学习和手工特征，用于分类MEA信号并识别ALS表型，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统MEA数据分析依赖手工特征，可能无法完全捕捉数据的所有有用特征。深度学习虽能自动学习特征，但手工特征对领域知识编码和解释性很重要。因此，需要结合两者优势。

Method: FRAME-C结合领域知识（如手工特征）和深度学习技术（从波形中学习特征），分类MEA信号并识别ALS表型。

Result: FRAME-C在模拟和真实数据上均表现优越，真实数据性能提升11%，模拟数据提升25%，并能评估手工特征重要性。

Conclusion: FRAME-C结合手工特征和深度学习，有效提升了分类性能和解释性，为ALS研究提供了新工具。

Abstract: Amyotrophic lateral sclerosis (ALS) is a fatal neurodegenerative disorder
characterized by motor neuron degeneration, with alterations in neural
excitability serving as key indicators. Recent advancements in induced
pluripotent stem cell (iPSC) technology have enabled the generation of human
iPSC-derived neuronal cultures, which, when combined with multi-electrode array
(MEA) electrophysiology, provide rich spatial and temporal electrophysiological
data. Traditionally, MEA data is analyzed using handcrafted features based on
potentially imperfect domain knowledge, which while useful may not fully
capture all useful characteristics inherent in the data. Machine learning,
particularly deep learning, has the potential to automatically learn relevant
characteristics from raw data without solely relying on handcrafted feature
extraction. However, handcrafted features remain critical for encoding domain
knowledge and improving interpretability, especially with limited or noisy
data. This study introduces FRAME-C, a knowledge-augmented machine learning
pipeline that combines domain knowledge, raw spike waveform data, and deep
learning techniques to classify MEA signals and identify ALS-specific
phenotypes. FRAME-C leverages deep learning to learn important features from
spike waveforms while incorporating handcrafted features such as spike
amplitude, inter-spike interval, and spike duration, preserving key spatial and
temporal information. We validate FRAME-C on both simulated and real MEA data
from human iPSC-derived neuronal cultures, demonstrating superior performance
over existing classification methods. FRAME-C shows over 11% improvement on
real data and up to 25% on simulated data. We also show FRAME-C can evaluate
handcrafted feature importance, providing insights into ALS phenotypes.

</details>


### [12] [AI- Enhanced Stethoscope in Remote Diagnostics for Cardiopulmonary Diseases](https://arxiv.org/abs/2505.18184)
*Hania Ghouse,Juveria Tanveen,Abdul Muqtadir Ahmed,Uma N. Dulhare*

Main category: eess.SP

TL;DR: 该研究提出了一种结合人工智能的低成本听诊器模型，可同时诊断心肺疾病，适用于资源匮乏地区，通过MFCC特征提取和GRU-CNN混合模型实现高效分析。


<details>
  <summary>Details</summary>
Motivation: 全球内心肺疾病导致的高死亡率问题严峻，现有检测方法在及时性和资源匮乏地区的可用性上存在局限，亟需低成本、高效的解决方案。

Method: 采用MFCC特征提取技术，结合GRU-CNN混合模型处理低成本听诊器采集的音频信号，开发可部署于嵌入式设备的AI模型。

Result: 模型能实时分类六种肺部疾病和五种心血管疾病，并通过网页应用提供低成本、标准化的医疗诊断支持。

Conclusion: 该研究通过AI与低成本硬件的结合，为资源匮乏地区提供了可行的标准化医疗解决方案，具有实际应用潜力。

Abstract: The increase in cardiac and pulmonary diseases presents an alarming and
pervasive health challenge on a global scale responsible for unexpected and
premature mortalities. In spite of how serious these conditions are, existing
methods of detection and treatment encounter challenges, particularly in
achieving timely diagnosis for effective medical intervention. Manual screening
processes commonly used for primary detection of cardiac and respiratory
problems face inherent limitations, increased by a scarcity of skilled medical
practitioners in remote or under-resourced areas. To address this, our study
introduces an innovative yet efficient model which integrates AI for diagnosing
lung and heart conditions concurrently using the auscultation sounds. Unlike
the already high-priced digital stethoscope, our proposed model has been
particularly designed to deploy on low-cost embedded devices and thus ensure
applicability in under-developed regions that actually face an issue of
accessing medical care. Our proposed model incorporates MFCC feature extraction
and engineering techniques to ensure that the signal is well analyzed for
accurate diagnostics through the hybrid model combining Gated Recurrent Unit
with CNN in processing audio signals recorded from the low-cost stethoscope.
Beyond its diagnostic capabilities, the model generates digital audio records
that facilitate in classifying six pulmonary and five cardiovascular diseases.
Hence, the integration of a cost effective stethoscope with an efficient AI
empowered model deployed on a web app providing real-time analysis, represents
a transformative step towards standardized healthcare

</details>


### [13] [BrainOmni: A Brain Foundation Model for Unified EEG and MEG Signals](https://arxiv.org/abs/2505.18185)
*Qinfan Xiao,Ziyun Cui,Chi Zhang,Siqi Chen,Wen Wu,Andrew Thwaites,Alexandra Woolgar,Bowen Zhou,Chao Zhang*

Main category: eess.SP

TL;DR: BrainOmni是一种基础模型，首次统一处理EEG和MEG数据，通过新型Tokenizer和Sensor Encoder实现跨模态兼容，自监督预训练后在下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: EEG和MEG虽然基于相同的生物物理学原理，但信号模式不同，且设备和数据集的差异限制了模型的性能和跨域扩展性。现有方法多为模态和数据集特定，缺乏通用性。

Method: 提出BrainTokenizer量化时空脑活动为离散表示，结合Sensor Encoder编码传感器属性（如空间布局、方向、类型），实现跨设备和模态兼容。通过自监督预训练学习统一语义嵌入。

Result: BrainOmni在多个下游任务中表现超过现有基础模型和任务特定模型，并能泛化到未见过的设备。联合EEG-MEG训练对双方均有提升。

Conclusion: BrainOmni是首个支持EEG和MEG的基础模型，通过统一表征和跨模态训练展示了强大的泛化能力和性能提升。代码和模型将在接受后开源。

Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) measure neural
activity non-invasively by capturing electromagnetic fields generated by
dendritic currents. Although rooted in the same biophysics, EEG and MEG exhibit
distinct signal patterns, further complicated by variations in sensor
configurations across modalities and recording devices. Existing approaches
typically rely on separate, modality- and dataset-specific models, which limits
the performance and cross-domain scalability. This paper proposes BrainOmni,
the first brain foundation model that generalises across heterogeneous EEG and
MEG recordings. To unify diverse data sources, we introduce BrainTokenizer,the
first tokenizer that quantises spatiotemporal brain activity into discrete
representations. Central to BrainTokenizer is a novel Sensor Encoder that
encodes sensor properties such as spatial layout, orientation, and type,
enabling compatibility across devices and modalities. Building upon the
discrete representations, BrainOmni learns unified semantic embeddings of brain
signals by self-supervised pretraining. To the best of our knowledge, it is the
first foundation model to support both EEG and MEG signals, as well as the
first to incorporate large-scale MEG pretraining. A total of 1,997 hours of EEG
and 656 hours of MEG data are curated and standardised from publicly available
sources for pretraining. Experiments show that BrainOmni outperforms both
existing foundation models and state-of-the-art task-specific models on a range
of downstream tasks. It also demonstrates strong generalisation to unseen EEG
and MEG devices. Further analysis reveals that joint EEG-MEG (EMEG) training
yields consistent improvements across both modalities. Code and model
checkpoints will be released upon acceptance.

</details>


### [14] [Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization](https://arxiv.org/abs/2505.18188)
*Beck LaBash,Shahriar Khushrushahi,Fabian Ruehle*

Main category: eess.SP

TL;DR: 提出了一种两阶段深度学习框架，用于矩形贴片天线的逆向设计，结合生成模型和优化技术提高设计准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过深度学习方法解决传统天线设计中的复杂性和耗时问题，提高设计效率和灵活性。

Method: 使用生成模型学习天线频率响应的潜在表示，并基于这些响应生成可行的天线几何形状，同时结合搜索和优化技术优化设计。

Result: 框架能够自然适应不同设计标准，生成更准确的天线设计，并能考虑制造性等附加目标。

Conclusion: 该方法在复杂几何设计空间中具有通用性和可扩展性，为天线设计提供了高效的新途径。

Abstract: We propose a two-stage deep learning framework for the inverse design of
rectangular patch antennas. Our approach leverages generative modeling to learn
a latent representation of antenna frequency response curves and conditions a
subsequent generative model on these responses to produce feasible antenna
geometries. We further demonstrate that leveraging search and optimization
techniques at test-time improves the accuracy of the generated designs and
enables consideration of auxiliary objectives such as manufacturability. Our
approach generalizes naturally to different design criteria, and can be easily
adapted to more complex geometric design spaces.

</details>


### [15] [Generating Realistic Multi-Beat ECG Signals](https://arxiv.org/abs/2505.18189)
*Paul Pöhl,Viktor Schlegel,Hao Li,Anil Bharath*

Main category: eess.SP

TL;DR: 本论文提出了一种新颖的三层合成框架，用于生成逼真的长时程心电图信号，解决了现有扩散模型在生成长序列时的不足，显著提升了合成心电图在下游任务中的实用性。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域中，生成合成心电图数据具有广泛的应用需求，但现有的扩散模型只能生成短时程心电图，难以满足长时程心电图在临床中的应用需求。

Method: 论文采用三层合成框架：首先通过扩散模型生成高质量单心搏信号，其次合成保持关键时间依赖性的心搏间特征，最后通过特征引导匹配将心搏组装成连贯的长序列。

Result: 综合评估表明，合成的长时程心电图既保持了心搏层次的形态保真度，又保留了临床相关的心搏间关系，在心律失常分类任务中显著优于端到端的扩散模型。

Conclusion: 该方法能够前所未有地生成多分钟长度的心电图序列，同时保留了关键的诊断特征，为下游应用提供了更高的实用性。

Abstract: Generating synthetic ECG data has numerous applications in healthcare, from
educational purposes to simulating scenarios and forecasting trends. While
recent diffusion models excel at generating short ECG segments, they struggle
with longer sequences needed for many clinical applications. This paper
proposes a novel three-layer synthesis framework for generating realistic
long-form ECG signals. We first generate high-fidelity single beats using a
diffusion model, then synthesize inter-beat features preserving critical
temporal dependencies, and finally assemble beats into coherent long sequences
using feature-guided matching. Our comprehensive evaluation demonstrates that
the resulting synthetic ECGs maintain both beat-level morphological fidelity
and clinically relevant inter-beat relationships. In arrhythmia classification
tasks, our long-form synthetic ECGs significantly outperform end-to-end
long-form ECG generation using the diffusion model, highlighting their
potential for increasing utility for downstream applications. The approach
enables generation of unprecedented multi-minute ECG sequences while preserving
essential diagnostic characteristics.

</details>


### [16] [PhySense: Sensor Placement Optimization for Accurate Physics Sensing](https://arxiv.org/abs/2505.18190)
*Yuezhou Ma,Haixu Wu,Hang Zhou,Huikun Weng,Jianmin Wang,Mingsheng Long*

Main category: eess.SP

TL;DR: PhySense是一个两阶段框架，联合优化物理场重建和传感器布局，提升物理感知精度，并通过理论验证和实验证明其先进性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏数据重建上进展迅速，但忽略了传感器布局的优化，导致重建与布局未能相互增强。PhySense旨在解决这一问题。

Method: 第一阶段使用基于流的生成模型和交叉注意力融合稀疏观测；第二阶段通过投影梯度下降优化传感器布局，并满足空间约束。

Result: 在三个基准测试（包括3D几何数据集）中，PhySense实现了最先进的物理感知精度，并发现了此前未被考虑的传感器布局。

Conclusion: PhySense通过联合优化重建与布局，实现了更高效的物理感知，同时提供了理论保障。

Abstract: Physics sensing plays a central role in many scientific and engineering
domains, which inherently involves two coupled tasks: reconstructing dense
physical fields from sparse observations and optimizing scattered sensor
placements to observe maximum information. While deep learning has made rapid
advances in sparse-data reconstruction, existing methods generally omit
optimization of sensor placements, leaving the mutual enhancement between
reconstruction and placement on the shelf. To change this suboptimal practice,
we propose PhySense, a synergistic two-stage framework that learns to jointly
reconstruct physical fields and to optimize sensor placements, both aiming for
accurate physics sensing. The first stage involves a flow-based generative
model enhanced by cross-attention to adaptively fuse sparse observations.
\correct{Leveraging the reconstruction feedback, }the second stage performs
sensor placement via projected gradient descent to satisfy spatial constraints.
\correct{We further prove that the learning objectives of the two stages are
consistent with classical variance-minimization principles, providing
theoretical guarantees.} Extensive experiments across three challenging
benchmarks, especially a 3D geometry dataset, indicate PhySense achieves
state-of-the-art physics sensing accuracy and discovers informative sensor
placements previously unconsidered.

</details>


### [17] [SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference](https://arxiv.org/abs/2505.18191)
*Jonathan Dan,Amirhossein Shahbazinia,Christodoulos Kechris,David Atienza*

Main category: eess.SP

TL;DR: 该论文通过组织一个挑战赛，评估了多种癫痫检测算法在长程EEG数据上的表现，结果表明现有算法性能参差不齐，最佳F1分数为43%，并提出了标准化评估框架SzCORE以促进可重复研究。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习模型在长程EEG癫痫检测中泛化性能不足，临床仍依赖人工EEG审查，因此需要开发更鲁棒的模型和标准化评估方法。

Method: 使用65名受试者的4,360小时连续EEG数据（专家标记），要求参赛算法检测癫痫发作的起始和持续时间，采用敏感度、精确率、F1分数等事件指标并通过SzCORE框架标准化评估。

Result: 30份提交中28个算法评估结果显示性能差异大，最佳F1分数为43%（敏感度37%，精确率45%），但整体性能仍有限，最佳算法较之前研究有所提升。

Conclusion: 癫痫检测仍具挑战性，标准化评估框架（如SzCORE）可推动算法临床转化，该平台支持持续对标以促进可重复研究和临床验证。

Abstract: Reliable automatic seizure detection from long-term EEG remains a challenge,
as current machine learning models often fail to generalize across patients or
clinical settings. Manual EEG review remains the clinical standard,
underscoring the need for robust models and standardized evaluation. To
rigorously assess algorithm performance, we organized a challenge using a
private dataset of continuous EEG recordings from 65 subjects (4,360 hours).
Expert neurophysiologists annotated the data, providing ground truth for
seizure events. Participants were required to detect seizure onset and
duration, with evaluation based on event-based metrics, including sensitivity,
precision, F1-score, and false positives per day. The SzCORE framework ensured
standardized evaluation. The primary ranking criterion was the event-based
F1-score, reflecting clinical relevance by balancing sensitivity and false
positives. The challenge received 30 submissions from 19 teams, with 28
algorithms evaluated. Results revealed wide variability in performance, with a
top F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing
difficulty of seizure detection. The challenge also revealed a gap between
reported performance and real-world evaluation, emphasizing the importance of
rigorous benchmarking. Compared to previous challenges and commercial systems,
the best-performing algorithm in this contest showed improved performance.
Importantly, the challenge platform now supports continuous benchmarking,
enabling reproducible research, integration of new datasets, and clinical
evaluation of seizure detection algorithms using a standardized framework.

</details>


### [18] [Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications](https://arxiv.org/abs/2505.18194)
*Yubo Peng,Luping Xiang,Bingxin Zhang,Kun Yang*

Main category: eess.SP

TL;DR: 提出了基于大语言模型的分布式多模态感知与语义通信框架（LLM-DiSAC），通过RF-视觉融合网络、LLM驱动的语义传输网络和分布式聚合模型提升复杂环境下的感知能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统单模态系统在复杂动态环境中的感知局限性，尤其是非视距或城市场景下视角不足和覆盖范围有限的问题。

Method: 使用多设备协同感知，结合RF-视觉融合网络（RVFN）、LLM语义传输网络（LSTN）和基于Transformer的聚合模型（TRAM），并采用两阶段分布式学习保障隐私。

Result: 在合成多视角RF-视觉数据集上验证，LLM-DiSAC表现优异。

Conclusion: LLM-DiSAC通过多模态融合与分布式学习显著提升了感知精度和通信效率，适用于复杂场景。

Abstract: Traditional single-modal sensing systems-based solely on either radio
frequency (RF) or visual data-struggle to cope with the demands of complex and
dynamic environments. Furthermore, single-device systems are constrained by
limited perspectives and insufficient spatial coverage, which impairs their
effectiveness in urban or non-line-of-sight scenarios. To overcome these
challenges, we propose a novel large language model (LLM)-driven distributed
integrated multimodal sensing and semantic communication (LLM-DiSAC) framework.
Specifically, our system consists of multiple collaborative sensing devices
equipped with RF and camera modules, working together with an aggregation
center to enhance sensing accuracy. First, on sensing devices, LLM-DiSAC
develops an RF-vision fusion network (RVFN), which employs specialized feature
extractors for RF and visual data, followed by a cross-attention module for
effective multimodal integration. Second, a LLM-based semantic transmission
network (LSTN) is proposed to enhance communication efficiency, where the
LLM-based decoder leverages known channel parameters, such as transceiver
distance and signal-to-noise ratio (SNR), to mitigate semantic distortion.
Third, at the aggregation center, a transformer-based aggregation model (TRAM)
with an adaptive aggregation attention mechanism is developed to fuse
distributed features and enhance sensing accuracy. To preserve data privacy, a
two-stage distributed learning strategy is introduced, allowing local model
training at the device level and centralized aggregation model training using
intermediate features. Finally, evaluations on a synthetic multi-view RF-visual
dataset generated by the Genesis simulation engine show that LLM-DiSAC achieves
a good performance.

</details>


### [19] [CrossRF: A Domain-Invariant Deep Learning Approach for RF Fingerprinting](https://arxiv.org/abs/2505.18200)
*Fahrettin Emin Tiras,Hayriye Serra Altinoluk*

Main category: eess.SP

TL;DR: CrossRF是一种针对无人机射频指纹识别的域不变深度学习方法，通过对抗学习减少不同射频通道间的域差距，显著提升跨通道识别性能。


<details>
  <summary>Details</summary>
Motivation: 射频指纹识别在无人机安全中潜力巨大，但在不同传输通道上性能下降严重。需要一种方法来解决跨通道识别问题。

Method: 采用对抗学习训练域不变模型，最小化不同射频通道间的域差距，保持识别性能的一致性。

Result: 在UAVSig数据集上验证，CrossRF在从通道3到通道4的适应中达到99.03%准确率（传统方法仅26.39%），多通道场景下保持87.57%准确率，控制器分类精度为89.45%。

Conclusion: CrossRF能显著减少跨通道变化导致的性能下降，仅需少量训练数据即可保持高识别精度，适用于实际无人机安全应用。

Abstract: Radio Frequency (RF) fingerprinting offers a promising approach for drone
identification and security, although it suffers from significant performance
degradation when operating on different transmission channels. This paper
presents CrossRF, a domain-invariant deep learning approach that addresses the
problem of cross-channel RF fingerprinting for Unmanned Aerial Vehicle (UAV)
identification. Our approach aims to minimize the domain gap between different
RF channels by using adversarial learning to train a more robust model that
maintains consistent identification performance despite channel variations. We
validate our approach using the UAVSig dataset, comprising real-world
over-the-air RF signals from identical drone models operating across several
frequency channels, ensuring that the findings correspond to real-world
scenarios. The experimental results show CrossRF's efficiency, achieving up to
99.03% accuracy when adapting from Channel 3 to Channel 4, compared to only
26.39% using conventional methods. The model maintains robust performance in
more difficult multi-channel scenarios (87.57% accuracy adapting from Channels
1,3 to 2,4) and achieves 89.45% accuracy with 0.9 precision for controller
classification. These results confirm CrossRF's ability to significantly reduce
performance degradation due to cross-channel variations while maintaining high
identification accuracy with minimal training data requirements, making it
particularly suitable for practical drone security applications.

</details>


### [20] [CC-OTDR Sequence Shaping Enabling Joint Co-directional Sensing and Communication](https://arxiv.org/abs/2505.18225)
*M. Ali Allousch,André Sandmann*

Main category: eess.SP

TL;DR: 论文介绍了CC-OTDR信号包络整形技术，以减少探测信号与数据信号共传时对相邻波长数据信道的非线性干扰影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解决探测信号与数据信号共传时导致的非线性干扰问题，从而提升共传系统的性能。

Method: 采用CC-OTDR信号包络整形技术，通过优化信号形状来减少非线性干扰。

Result: 实验结果表明，在50公里的链路上实现了联合同向声学传感和200 Gbps的传输。

Conclusion: 通过信号包络整形技术，可以有效减少非线性干扰，同时实现高带宽数据传输和声学传感。

Abstract: CC-OTDR signal envelope shaping is introduced to reduce the impact of
non-linear signal interactions on a neighboring wavelength data channel when
co-propagating the probing signal with the data signal. Joint co-directional
acoustic sensing and 200 Gbps transmission are demonstrated over a 50 km link.

</details>


### [21] [Current-Steering DAC Architecture Design for Amplitude Mismatch Error Minimization](https://arxiv.org/abs/2505.18353)
*Ramin Babaee,Shahab Oveis Gharan,Martin Bouchard*

Main category: eess.SP

TL;DR: 提出一种新型DAC加权架构，通过统计方法最小化随机电流失配导致的失真，采用非整数权重，并结合启发式算法优化静态性能。


<details>
  <summary>Details</summary>
Motivation: 现有的二进制、温度码和分段DAC架构因整数权重限制，无法有效抑制随机电流失配引起的失真，需探索更灵活的加权方案。

Method: 设计非整数权重的DAC架构，并提出启发式算法静态映射输入码字到开关配置，通过Matlab仿真评估性能。

Result: 仿真显示新架构在静态性能上优于传统分段结构，失真显著降低。

Conclusion: 非整数权重结合启发式映射的方法有效提升了DAC精度，为高精度转换器设计提供了新思路。

Abstract: We propose a novel digital-to-analog converter (DAC) weighting architecture
that statistically minimizes the distortion caused by random current
mismatches. Unlike binary, thermometer-coded, and segmented DACs, the current
weights of the proposed architecture are not an integer power of 2 or any other
integer number. We present a heuristic algorithm for a static mapping of DAC
input codewords into corresponding DAC switches. High-level Matlab simulations
are performed to illustrate the static performance improvement over the
segmented structure.

</details>


### [22] [Frequency and Bandwidth Design of FR3-Band Acoustic Filters](https://arxiv.org/abs/2505.18388)
*Taran Anusorn,Omar Barrera,Jack Kramer,Ian Anderson,Ziqian Yao,Vakhtang Chulukhadze,Ruochen Lu*

Main category: eess.SP

TL;DR: 该论文提出了一种控制薄膜铌酸锂（TFLN）微型声学滤波器工作频率和分数带宽（FBW）的方法，基于A1模式的XBARs实现了高效操作，并在20.5 GHz和22.0 GHz展示了优异的滤波性能。


<details>
  <summary>Details</summary>
Motivation: 为了满足未来6G及以上通信对频率分配更严格的需求，需要开发紧凑且高性能的声学滤波器。

Method: 利用A1模式在XBARs中的厚度依赖性共振频率和128° Y-cut TFLN的面内各向异性特性，定制滤波器特性。

Result: 三元件滤波器原型在20.5 GHz下插入损耗1.79 dB，FBW 8.58%，八元件滤波器在22.0 GHz下插入损耗3.80 dB，FBW 6.12%，均展现出优异的带外抑制性能。

Conclusion: 该技术展示了在未来6G通信中实现紧凑、单片滤波器组的潜力。

Abstract: This article presents an approach to control the operating frequency and
fractional bandwidth (FBW) of miniature acoustic filters in thin-film lithium
niobate (TFLN). More specifically, we used the first-order antisymmetric (A1)
mode in lateral-field-excited bulk acoustic wave resonators (XBARs) to achieve
efficient operation at 20.5 GHz. Our technique leverages the
thickness-dependent resonance frequency of A1 XBARs, combined with the in-plane
anisotropic properties of 128$^\circ$ Y-cut TFLN, to customize filter
characteristics. The implemented three-element ladder filter prototype achieves
an insertion loss (IL) of only 1.79 dB and a controlled 3-dB FBW of 8.58% at
20.5 GHz, with an out-of-band (OoB) rejection greater than 14.9 dB across the
entire FR3 band, while featuring a compact footprint of 0.90 $\times$ 0.74
mm$^2$. Moreover, an eight-element filter prototype shows an IL of 3.80 dB, an
FBW of 6.12% at 22.0 GHz, and a high OoB rejection of 22.97 dB, demonstrating
the potential for expanding to higher-order filters. As frequency allocation
requirements become more stringent in future FR3 bands, our technique showcases
promising capability in enabling compact and monolithic filter banks toward
next-generation acoustic filters for 6G and beyond.

</details>


### [23] [A DSP-Free Carrier Phase Recovery System using 16-Offset-QAM Laser Forwarded Links for 400Gb/s and Beyond](https://arxiv.org/abs/2505.18534)
*Marziyeh Rezaei,Dan Sturm,Pengyu Zeng,Sajjad Moazeni*

Main category: eess.SP

TL;DR: 该论文提出了一种新型的无数字信号处理（DSP）的载波相位恢复（CPR）系统，用于高效能光学互连，支持任意偏移QAM调制，验证了其低功耗和高扩展性。


<details>
  <summary>Details</summary>
Motivation: 未来数据中心的光学互连需要更高的数据速率和能效，而传统的相干链路依赖高能耗的DSP实现载波相位恢复，无法满足低功耗需求。

Method: 采用激光转发和偏移QAM调制，提出一种模拟CPR反馈环路，其相位误差检测机制独立于数据速率和调制类型，具有高扩展性。

Result: 通过GlobalFoundry的45nm硅光子工艺验证，系统在100GBaud速率下实现低功耗性能，适用于未来相干精简可插拔收发器和共封装光学应用。

Conclusion: 该方法为未来数据中心的高阶QAM光学互连提供了低功耗、高扩展性的解决方案。

Abstract: Optical interconnects are becoming a major bottleneck in scaling up future
GPU racks and network switches within data centers. Although 200 Gb/s optical
transceivers using PAM-4 modulation have been demonstrated, achieving higher
data rates and energy efficiencies requires high-order coherent modulations
like 16-QAM. Current coherent links rely on energy-intensive digital signal
processing (DSP) for channel impairment compensation and carrier phase recovery
(CPR), which consumes approximately 50pJ/b - 10x higher than future intra-data
center requirements. For shorter links, simpler or DSP-free CPR methods can
significantly reduce power and complexity. While Costas loops enable CPR for
QPSK, they face challenges in scaling to higher-order modulations (e.g.,
16/64-QAM) due to varying symbol amplitudes. In this work, we propose an
optical coherent link architecture using laser forwarding and a novel DSP-free
CPR system using offset-QAM modulation. The proposed analog CPR feedback loop
is highly scalable, capable of supporting arbitrary offset-QAM modulations
without requiring architectural modifications. This scalability is achieved
through its phase error detection mechanism, which operates independently of
the data rate and modulation type. We validated this method using
GlobalFoundry's monolithic 45nm silicon photonics PDK models, with circuit- and
system-level implementation at 100GBaud in the O-band. We will investigate the
feedback loop dynamics, circuit-level implementations, and phase-noise
performance of the proposed CPR loop. Our method can be adopted to realize
low-power QAM optical interconnects for future coherent-lite pluggable
transceivers as well as co-packaged optics (CPO) applications.

</details>


### [24] [FDMA-Based Passive Multiple Users SWIPT Utilizing Resonant Beams](https://arxiv.org/abs/2505.18641)
*Yixuan Guo,Mingliang Xiong,Wen Fang,Qingwei Jiang,Qingwen Liu,Gang Yan*

Main category: eess.SP

TL;DR: 论文提出了一种被动多用户谐振波束系统（MU-RBS），用于解决传统MIMO-SWIPT在目标检测中的问题，通过自适应波束对齐实现高效能量传输和通信，并展示了系统架构和数学模型。


<details>
  <summary>Details</summary>
Motivation: 由于IoT技术快速发展导致的频谱和能源短缺问题，传统MIMO-SWIPT在目标检测中存在挑战，亟需新的解决方案。

Method: 设计了MU-RBS系统，采用FDMA技术在下行链路，上行链路使用频分转换以避免干扰，并提出了系统架构和数学模型。

Result: 仿真表明，MU-RBS无需目标发送导频信号即可实现自适应波束成形，具有高方向性，随着迭代次数增加，系统性能持续优化至最佳状态。

Conclusion: MU-RBS系统能有效解决传统SWIPT的局限性，为能量传输和通信提供了高效且可扩展的解决方案。

Abstract: The rapid development of IoT technology has led to a shortage of spectrum
resources and energy, giving rise to simultaneous wireless information and
power transfer (SWIPT) technology. However, traditional multiple input multiple
output (MIMO)-based SWIPT faces challenges in target detection. We have
designed a passive multi-user resonant beam system (MU-RBS) that can achieve
efficient power transfer and communication through adaptive beam alignment. The
frequency division multiple access (FDMA) is employed in the downlink (DL)
channel, while frequency conversion is utilized in the uplink (UL) channel to
avoid echo interference and co-channel interference, and the system
architecture design and corresponding mathematical model are presented. The
simulation results show that MU-RBS can achieve adaptive beam-forming without
the target transmitting pilot signals, has high directivity, and as the number
of iterations increases, the power transmission efficiency, signal-to-noise
ratio and spectral efficiency of the UL and DL are continuously optimized until
the system reaches the optimal state.

</details>


### [25] [EOTNet: Deep Memory Aided Bayesian Filter for Extended Object Tracking](https://arxiv.org/abs/2505.18684)
*Zhixing Wang,Le Zheng,Shi Yan,Ruud J. G. van Sloun,Nir Shlezinger,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出一种基于贝叶斯递归神经网络的新颖扩展目标跟踪方法，解决了传统随机矩阵方法中非马尔可夫性假设的局限性，通过高斯逼近和矩匹配实现解析解，实验证实其优于传统及深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有随机矩阵方法假设状态和扩展的演变遵循马尔可夫过程，而实际场景中多为非马尔可夫性，导致假设失效。本文旨在开发一种更符合现实的跟踪方法。

Method: 1. 提出非马尔可夫假设下的等效模型；2. 推导其贝叶斯滤波框架；3. 使用高斯逼近和矩匹配求解解析解；4. 设计端到端可训练的贝叶斯递归神经网络。

Result: 在模拟和真实数据集上，新方法优于传统扩展目标跟踪方法和先进深度学习方案。

Conclusion: 通过结合非马尔可夫假设和深度学习，本文方法显著提升了扩展目标跟踪的准确性和适应性。

Abstract: Extended object tracking methods based on random matrices, founded on
Bayesian filters, have been able to achieve efficient recursive processes while
jointly estimating the kinematic states and extension of the targets. Existing
random matrix approaches typically assume that the evolution of state and
extension follows a first-order Markov process, where the current estimate of
the target depends solely on the previous moment. However, in real-world
scenarios, this assumption fails because the evolution of states and extension
is usually non-Markovian. In this paper, we introduce a novel extended object
tracking method: a Bayesian recursive neural network assisted by deep memory.
Initially, we propose an equivalent model under a non-Markovian assumption and
derive the implementation of its Bayesian filtering framework. Thereafter,
Gaussian approximation and moment matching are employed to derive the
analytical solution for the proposed Bayesian filtering framework. Finally,
based on the closed-form solution, we design an end-to-end trainable Bayesian
recursive neural network for extended object tracking. Experiment results on
simulated and real-world datasets show that the proposed methods outperforms
traditional extended object tracking methods and state-of-the-art deep learning
approaches.

</details>


### [26] [Waveform Coexistence-Driven RSMA: A Pioneering Strategy for Future 6G Networks](https://arxiv.org/abs/2505.18739)
*Kenza Abela,Shaima Abidrabbu,Ayoub Ammar Boudjelal,Huseyin Arslan*

Main category: eess.SP

TL;DR: 提出了一种新的RSMA框架，结合AFDM和OFDM，通过不同功率传输公共和私有数据，简化了接收机设计。采用了两种数据映射方法，并在不同信道条件下验证了其高效性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决当前系统在6G网络中的局限性，例如对SIC的依赖和接收机设计的复杂性，以实现更稳健和可扩展的无线网络设计。

Method: 通过AFDM以高功率传输公共数据，OFDM以低功率传输私有数据，消除对SIC的依赖。提出两种数据映射方法（干净导频和嵌入式导频），并进行信道估计。

Result: 仿真结果表明，该框架在效率、可靠性和适应性方面表现优越，适用于不同信道条件。

Conclusion: 该框架为非正交多址设计提供了新思路，为6G网络的可扩展性和高效性奠定了基础。

Abstract: Two critical approaches have emerged in the literature for the successful
realization of 6G wireless networks: the coexistence of multiple waveforms and
the adoption of non-orthogonal multiple access. These strategies hold
transformative potential for addressing the limitations of current systems and
enabling the robust and scalable design of next-generation wireless networks.
This paper presents a novel rate splitting multiple access (RSMA) framework
that leverages the coexistence of affine frequency division multiplexing (AFDM)
and orthogonal frequency division multiplexing (OFDM). By transmitting common
data via AFDM at higher power in the affine domain and private data via OFDM at
lower power in the frequency domain, the proposed framework eliminates the
reliance on successive interference cancellation (SIC), significantly
simplifying receiver design. Furthermore, two data mapping approaches are
proposed: a clean pilot method, where pilots are allocated without any data
overlapping, ensuring clear separation, and an embedded pilot method, where
pilots overlap with data for more efficient resource utilization. Channel
estimation is then performed for different channel types. Simulation results
demonstrate the robustness and efficiency of the proposed approach, achieving
superior performance in efficiency, reliability, and adaptability under diverse
channel conditions. This framework transforms non-orthogonal multi-access
design, paving the way for scalable and efficient solutions in 6G networks.

</details>


### [27] [Season-Independent PV Disaggregation Using Multi-Scale Net Load Temporal Feature Extraction and Weather Factor Fusion](https://arxiv.org/abs/2505.18747)
*Xiaolu Chen,Chenghao Huang,Yanru Zhang,Hao Wang*

Main category: eess.SP

TL;DR: 论文提出了一种结合层次插值（HI）和自注意力机制的方法，用于精确分离光伏（PV）发电与电网负荷，以提升分布式能源系统的监控能力。


<details>
  <summary>Details</summary>
Motivation: 随着分布式光伏系统广泛应用，传统方法难以从电网负荷中提取特征并捕捉天气因素的关联，亟需更精确的PV发电预测方法。

Method: 提出层次插值（HI）提取电网负荷特征，结合多头自注意力机制捕捉天气因素的复杂依赖关系，实现PV发电的精准分离。

Result: 仿真实验验证了该方法在真实数据中的有效性，显著提升了分布式能源系统的监控与管理能力。

Conclusion: 该方法通过结合HI和自注意力机制，为解决PV发电分离问题提供了高效解决方案，具有实际应用价值。

Abstract: With the advancement of energy Internet and energy system integration, the
increasing adoption of distributed photovoltaic (PV) systems presents new
challenges on smart monitoring and measurement for utility companies,
particularly in separating PV generation from net electricity load. Existing
methods struggle with feature extraction from net load and capturing the
relevance between weather factors. This paper proposes a PV disaggregation
method that integrates Hierarchical Interpolation (HI) and multi-head
self-attention mechanisms. By using HI to extract net load features and
multi-head self-attention to capture the complex dependencies between weather
factors, the method achieves precise PV generation predictions. Simulation
experiments demonstrate the effectiveness of the proposed method in real-world
data, supporting improved monitoring and management of distributed energy
systems.

</details>


### [28] [Distributed Expectation Propagation for Multi-Object Tracking over Sensor Networks](https://arxiv.org/abs/2505.18795)
*Qing Li,Runze Gan,James R. Hopgood,Michael E. Davies,Simon J. Godsill*

Main category: eess.SP

TL;DR: 提出了一种新的分布式期望传播算法，用于多传感器多目标跟踪，通过局部操作和协作交换矩估计，无需中心节点传输所有数据。


<details>
  <summary>Details</summary>
Motivation: 解决在多目标和动态传感器连接环境中，传统方法需要将所有数据传输到中心节点的通信和计算效率问题。

Method: 采用快速且可并行的Rao-Blackwellised Gibbs抽样方案来近似倾斜分布，提升期望传播更新的准确性和效率。

Result: 实验表明，该算法在多目标跟踪任务中提高了通信和推理效率，尤其在动态传感器连接和变化杂波环境下表现优异。

Conclusion: 所提算法在多传感器多目标跟踪中有效提升了效率和准确性，适用于动态环境。

Abstract: In this paper, we present a novel distributed expectation propagation
algorithm for multiple sensors, multiple objects tracking in cluttered
environments. The proposed framework enables each sensor to operate locally
while collaboratively exchanging moment estimates with other sensors, thus
eliminating the need to transmit all data to a central processing node.
Specifically, we introduce a fast and parallelisable Rao-Blackwellised Gibbs
sampling scheme to approximate the tilted distributions, which enhances the
accuracy and efficiency of expectation propagation updates. Results demonstrate
that the proposed algorithm improves both communication and inference
efficiency for multi-object tracking tasks with dynamic sensor connectivity and
varying clutter levels.

</details>


### [29] [A Derivative-Free Position Optimization Approach for Movable Antenna Multi-User Communication Systems](https://arxiv.org/abs/2505.19012)
*Xianlong Zeng,Jun Fang,Peilan Wang,Weidong Mei,Ying-Chang Liang*

Main category: eess.SP

TL;DR: 论文提出了一种基于无导数方法的可移动天线（MA）位置优化技术，用于多用户MISO系统，通过零阶梯度逼近优化天线位置，避免了全局信道状态信息（CSI）的获取，提高了样本和计算效率。


<details>
  <summary>Details</summary>
Motivation: 可移动天线（MA）技术通过调整天线位置优化无线信道，但在多用户MISO系统中，全局CSI获取困难且成本高。为解决这一问题，作者提出了一种无需CSI的优化方法。

Method: 采用无导数优化方法，将天线位置优化视为闭箱问题，利用零阶梯度逼近技术计算未知目标函数的梯度，通过自适应调整移动策略逐步收敛到最优解。

Result: 仿真结果表明，该方法在样本和计算效率上优于基于CSI估计的传统方法，特别是在多径成分多或导频信号有限的情况下表现更优。

Conclusion: 无导数优化方法为MA技术在多用户MISO系统中的实际应用提供了高效且可行的解决方案。

Abstract: Movable antennas (MAs) have emerged as a disruptive technology in wireless
communications for enhancing spatial degrees of freedom through continuous
antenna repositioning within predefined regions, thereby creating favorable
channel propagation conditions. In this paper, we study the problem of position
optimization for MA-enabled multi-user MISO systems, where a base station (BS),
equipped with multiple MAs, communicates with multiple users each equipped with
a single fixed-position antenna (FPA). To circumvent the difficulty of
acquiring the channel state information (CSI) from the transmitter to the
receiver over the entire movable region, we propose a derivative-free approach
for MA position optimization. The basic idea is to treat position optimization
as a closed-box optimization problem and calculate the gradient of the unknown
objective function using zeroth-order (ZO) gradient approximation techniques.
Specifically, the proposed method does not need to explicitly estimate the
global CSI. Instead, it adaptively refines its next movement based on previous
measurements such that it eventually converges to an optimum or stationary
solution. Simulation results show that the proposed derivative-free approach is
able to achieve higher sample and computational efficiencies than the CSI
estimation-based position optimization approach, particularly for challenging
scenarios where the number of multi-path components (MPCs) is large or the
number of pilot signals is limited.

</details>


### [30] [Movable-Element STARS-Assisted Near-Field Wideband Communications](https://arxiv.org/abs/2505.19048)
*Guangyu Zhu,Xidong Mu,Li Guo,Ao Huang,Shibiao Xu*

Main category: eess.SP

TL;DR: 论文提出了一种新型可移动STARS辅助的近场宽带通信框架，通过动态调整STARS元件位置来解决近场宽频带波束斜移问题，避免使用昂贵组件。四种移动模式被提出，并设计了两层算法优化系统性能，实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 近场宽频带通信中存在严重的波束斜移问题，传统固定位置STARS无法有效解决。本文旨在通过可移动STARS元件动态调整位置，低成本高效地解决该问题。

Method: 提出四种STARS元件移动模式（RB、HB、VB、DB），并构建双层优化算法：内层通过块坐标下降法优化预编码和波束成形，外层采用粒子群优化确定元件位置。

Result: 1）ME-STARS显著优于固定位置STARS；2）RB模式抑制波束斜移效果最佳，DB模式在性能与硬件开销间取得平衡；3）增加元件或子载波数量可提升系统性能。

Conclusion: ME-STARS通过动态调整元件位置和优化算法，有效解决了近场宽频带通信的波束斜移问题，为实际部署提供了高效低成本的解决方案。

Abstract: A novel movable-element simultaneously transmitting and reflecting surface
(ME-STARS)-assisted near-field wideband communication framework is proposed. In
particular, the position of each STARS element can be adjusted to combat the
significant wideband beam squint issue in the near field instead of using
costly true-time delay components. Four practical ME-STARS element movement
modes are proposed, namely region-based (RB), horizontal-based (HB),
vertical-based (VB), and diagonal-based (DB) modes. Based on this, a near-field
wideband multi-user downlink communication scenario is considered, where a sum
rate maximization problem is formulated by jointly optimizing the base station
(BS) precoding, ME-STARS beamforming, and element positions. To solve this
intractable problem, a two-layer algorithm is developed. For the inner layer,
the block coordinate descent optimization framework is utilized to solve the BS
precoding and ME-STARS beamforming in an iterative manner. For the outer layer,
the particle swarm optimization-based heuristic search method is employed to
determine the desired element positions. Numerical results show that:1) the
ME-STARSs can effectively address the beam squint for near-field wideband
communications compared to conventional STARSs with fixed element positions; 2)
the RB mode achieves the most efficient beam squint effect mitigation, while
the DB mode achieves the best trade-off between performance gain and hardware
overhead; and 3) an increase in the number of ME-STARS elements or BS
subcarriers substantially improves the system performance.

</details>


### [31] [Foundation Model for Wireless Technology Recognition Using IQ Timeseries](https://arxiv.org/abs/2505.19390)
*Mohammad Cheraghinia,Eli De Poorter,Jaron Fontaine,Merouane Debbah,Adnan Shahid*

Main category: eess.SP

TL;DR: 论文提出了一种基于Transformer的基础模型，用于无线技术识别（WTR），旨在解决传统方法在跨环境、设备和信号类别泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统WTR方法缺乏对未见环境、设备和信号类别的鲁棒性和适应性，因此需要一种能够广泛泛化的模型。

Method: 采用Transformer基础模型，通过无监督预训练和轻量级微调的两阶段训练流程，利用输入分块提高计算效率。

Result: 实验表明，该模型在不同采样率和频段上均表现出优异准确性，且计算复杂度低，支持对新技术的快速适应。

Conclusion: 该基础模型为WTR提供了一种可重用且适应性强的解决方案，能通过少量样本快速适应新技术。

Abstract: Wireless Technology Recognition (WTR) is essential in modern communication
systems, enabling efficient spectrum management and the seamless coexistence of
diverse technologies. In real-world conditions, WTR solutions should be able to
handle signals from various resources with different sampling rates, capturing
devices, and frequency bands. However, traditional WTR methods, which rely on
energy detection, Convolutional Neural Network (CNN) models, or Deep Learning
(DL), lack the robustness and adaptability required to generalize across unseen
environments, different sampling devices, and previously unencountered signal
classes. In this work, we introduce a Transformer-based foundation model for
WTR, trained in an unsupervised manner on large-scale, unlabeled wireless
signal datasets. Foundation models are designed to learn general-purpose
representations that transfer effectively across tasks and domains, allowing
generalization towards new technologies and WTR sampling devices. Our approach
leverages input patching for computational efficiency and incorporates a
two-stage training pipeline: unsupervised pre-training followed by lightweight
fine-tuning. This enables the model to generalize to new wireless technologies
and environments using only a small number of labeled samples. Experimental
results demonstrate that our model achieves superior accuracy across varying
sampling rates and frequency bands while maintaining low computational
complexity, supporting the vision of a reusable wireless foundation model
adaptable to new technologies with minimal retraining.

</details>


### [32] [Empirical 3D Channel Modeling for Cellular-Connected UAVs: A Triple-Layer Machine Learning Approach](https://arxiv.org/abs/2505.19478)
*Haider A. H. Alobaidy,Mehran Behjati,Rosdiadee Nordin,Muhammad Aidiel Zulkifley,Nor Fadzilah Abdullah,Nur Fahimah Mat Salleh*

Main category: eess.SP

TL;DR: 论文提出了一种针对蜂窝连接无人机（UAV）的空中到地面（A2G）传播模型，通过三层机器学习框架显著提升了预测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统单层机器学习或计算密集型射线追踪方法在预测无人机A2G传播时存在精度不足或复杂度高的问题，需要一种更高效且准确的解决方案。

Method: 采用三层机器学习框架：前两层（逐步线性回归和袋装树集成）独立生成预测，第三层（高斯过程回归）作为聚合层优化预测，以估计关键性能指标。

Result: 模型在训练中达到约99%的准确率，测试中超过90%，同时通过精简特征集显著降低了计算复杂度。

Conclusion: 该框架在无人机集成蜂窝网络中具有实用性和高效性，显著优于传统方法。

Abstract: This work proposes an empirical air to ground (A2G) propagation model
specifically designed for cellular connected unmanned aerial vehicles (UAVs).
An in depth aerial drive test was carried out within an operating Long Term
Evolution (LTE) network, gathering thorough measurements of key network
parameters. Rigid preprocessing and statistical analysis of these data produced
a strong foundation for training a new triple layer machine learning (ML)
model. The proposed ML framework employs a systematic hierarchical approach.
Accordingly, the first two layers, Stepwise Linear Regression (STW) and
Ensemble of Bagged Trees (EBT) generate predictions independently, meanwhile,
the third layer, Gaussian Process Regression (GPR), explicitly acts as an
aggregation layer, refining these predictions to accurately estimate Key
Performance Indicators (KPIs) such as Reference Signal Received Power (RSRP),
Reference Signal Received Quality (RSRQ), Received Signal Strength (RSSI), and
Path Loss (PL). Compared to traditional single layer ML or computationally
intensive ray tracing approaches, the proposed triple layer ML framework
significantly improves predictive accuracy and robustness, achieving around 99
percent accuracy in training and above 90 percent in testing while utilizing a
minimal but effective feature set log transformed 3D and 2D propagation
distances, azimuth, and elevation angles. This streamlined feature selection
substantially reduces computing complexity, thus enhancing scalability across
various operating environments. The proposed frameworks practicality and
efficacy for real world deployment in UAV integrated cellular networks are
further demonstrated by comparative analyses, which underscore its substantial
improvement.

</details>


### [33] [Near-Field Secure Beamfocusing With Receiver-Centered Protected Zone](https://arxiv.org/abs/2505.19523)
*Cen Liu,Xiangyun Zhou,Nan Yang,Salman Durrani,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 论文研究了近场安全通信中的发射波束聚焦技术，通过定义保护区域和优化设计，实现了对窃听者的有效防护。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用波束聚焦技术和保护区域，提升近场通信的安全性，防止潜在窃听者的干扰。

Method: 采用同步梯度下降-上升框架解决NP-hard的max-min优化问题，并提出低复杂度解决方案。同时探讨了无法物理定义保护区域时的虚拟保护区域方案。

Result: 数值结果表明，无论是物理还是虚拟保护区域，配合优化的波束聚焦设计，均能有效实现近场安全通信。

Conclusion: 通过波束聚焦和保护区域设计，可以显著提升近场通信的安全性能，为实际应用提供了可行的解决方案。

Abstract: This work studies near-field secure communications through transmit
beamfocusing. We examine the benefit of having a protected eavesdropper-free
zone around the legitimate receiver, and we determine the worst-case secrecy
performance against a potential eavesdropper located anywhere outside the
protected zone. A max-min optimization problem is formulated for the
beamfocusing design with and without artificial noise transmission. Despite the
NP-hardness of the problem, we develop a synchronous gradient descent-ascent
framework that approximates the global maximin solution. A low-complexity
solution is also derived that delivers excellent performance over a wide range
of operating conditions. We further extend this study to a scenario where it is
not possible to physically enforce a protected zone. To this end, we consider
secure communications through the creation of a virtual protected zone using a
full-duplex legitimate receiver. Numerical results demonstrate that exploiting
either the physical or virtual receiver-centered protected zone with
appropriately designed beamfocusing is an effective strategy for achieving
secure near-field communications.

</details>


### [34] [Water Level Sensing via Communication Signals in a Bi-Static System](https://arxiv.org/abs/2505.19539)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Y. Jay Guo*

Main category: eess.SP

TL;DR: 该论文提出了一种利用移动网络中的信道状态信息（CSI）进行水位感测的新方法，通过多域滤波和卡尔曼滤波解相位模糊，在不同频段下验证了其高精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统水位感测方法成本高且易受干扰，需要一种更高效、低成本的解决方案。

Method: 使用CSI消除相位偏移，多域滤波提取相位特征，卡尔曼滤波解模糊，通过几何转换计算水位变化。

Result: 实验显示在28 GHz和3.1 GHz频段下平均误差分别仅为0.025 cm和0.198 cm，实际河流监测中误差为4.8 cm。

Conclusion: PMNs-WaterSense方法高效、精准，适用于实际水位监测需求。

Abstract: Accurate water level sensing is essential for flood monitoring, agricultural
irrigation, and water resource optimization. Traditional methods require
dedicated sensor deployments, leading to high installation costs, vulnerability
to interference, and limited resolution. This work proposes PMNs-WaterSense, a
novel scheme leveraging Channel State Information (CSI) from existing mobile
networks for water level sensing. Our scheme begins with a CSI-power method to
eliminate phase offsets caused by clock asynchrony in bi-static systems. We
then apply multi-domain filtering across the time (Doppler), frequency (delay),
and spatial (Angle-of-Arrival, AoA) domains to extract phase features that
finely capture variations in path length over water. To resolve the $2\pi$
phase ambiguity, we introduce a Kalman filter-based unwrapping technique.
Additionally, we exploit transceiver geometry to convert path length variations
into water level height changes, even with limited antenna configurations. We
validate our framework through controlled experiments with 28 GHz mmWave and
3.1 GHz LTE signals in real time, achieving average height estimation errors of
0.025 cm and 0.198 cm, respectively. Moreover, real-world river monitoring with
2.6 GHz LTE signals achieves an average error of 4.8 cm for a 1-meter water
level change, demonstrating its effectiveness in practical deployments.

</details>


### [35] [Accurate Radar-Based Detection of Sleep Apnea Using Overlapping Time-Interval Averaging](https://arxiv.org/abs/2505.19701)
*Kodai Hasegawa,Shigeaki Okumura,Hirofumi Taki,Hironobu Sunadome,Satoshi Hamada,Susumu Sato,Kazuo Chin,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出了一种通过多次应用检测方法并结合多个重叠时间间隔的雷达数据来降低不规则呼吸对睡眠呼吸暂停检测准确性的方法。


<details>
  <summary>Details</summary>
Motivation: 呼吸暂停事件的检测准确性常因后续不规则呼吸而降低，研究人员希望通过新方法解决这一问题。

Method: 将检测方法重复应用于多个重叠时间间隔的雷达数据集，并对检测类别进行平均，以生成介于0和1之间的概率值。

Result: 实验数据证实，该方法能有效减少不规则呼吸对呼吸暂停检测的影响。

Conclusion: 所提出的方法可以提高睡眠呼吸暂停事件的检测准确性，尤其适用于伴随不规则呼吸的病例。

Abstract: Radar-based respiratory measurement is a promising tool for the noncontact
detection of sleep apnea. Our team has reported that apnea events can be
accurately detected using the statistical characteristics of the amplitude of
respiratory displacement. However, apnea and hypopnea events are often followed
by irregular breathing, reducing the detection accuracy. This study proposes a
new method to overcome this performance degradation by repeatedly applying the
detection method to radar data sets corresponding to multiple overlapping time
intervals. Averaging the detected classes over multiple time intervals gives an
analog value between 0 and 1, which can be interpreted as the probability that
there is an apnea event. We show that the proposed method can mitigate the
effect of irregular breathing that occurs after apnea / hypopnea events, and
its performance is confirmed by experimental data taken from seven patients.

</details>


### [36] [Bit Error Rate and Performance Analysis of Multi-User OTFS under Nakagami-m Fading for 6G and Beyond Networks](https://arxiv.org/abs/2505.19843)
*Emir Aslandogan,Haci Ilhan*

Main category: eess.SP

TL;DR: 该论文系统研究了在Nakagami-m衰落信道下，单用户和多用户场景中OTFS调制的误码率性能，通过数学分析和蒙特卡洛仿真验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 6G无线通信系统中，OTFS调制在高移动性和多径衰落环境下表现优异，需对其误码率性能进行系统分析以验证可靠性。

Method: 采用数学框架分析单输入单输出和单输入多输出场景，利用Erlang概率密度函数和Gamma近似推导闭式误码率表达式，并通过蒙特卡洛仿真验证。

Result: 分析结果显示OTFS在高移动性和多径环境下误码率性能优于传统OFDM，且仿真验证了数学推导的准确性。

Conclusion: OTFS在高移动性和多径衰落信道中表现卓越，尤其在多用户干扰场景下仍能保持优异性能，适用于6G及未来无线通信系统。

Abstract: Orthogonal Time-Frequency Space modulation stands out as a promising waveform
for 6G and beyond wireless communication systems, offering superior performance
over conventional methods, particularly in high-mobility scenarios and
dispersive channel conditions. Error performance analysis remains crucial for
accurately characterizing the reliability of wireless communication systems
under practical constraints. In this paper, we systematically investigate the
bit error rate performance of OTFS modulation over Nakagami-m fading channels
in both single-user and multi-user scenarios. In analytical approaches,
mathematical frameworks are employed for distinct receiver configurations: the
Single-input Single-output scenario leverages Erlang probability density
function of squared-Nakagami variables to derive closed-form BER expressions,
while the Single-input Multiple-output case applies moment matching techniques
with Gamma approximation to model multiple user interference, subsequently
yielding Signal-to-interference-plus-noise Ratio characterizations through
Meijer-G functions. This study examines single-path and multi-path channel
conditions, evaluating the relationship between path multiplicity and error
performance metrics while considering various fading intensities through
Nakagami-m fading parameters. The derived closed-form BER expressions are
validated through maximum likelihood detection based Monte Carlo simulations,
demonstrating strong correlation between analytical and numerical results
across various SNR regions. Furthermore, comparative benchmark evaluations
against conventional orthogonal frequency division multiplexing with MLD reveal
that OTFS consistently achieves superior error performance in high-mobility
scenarios. In multipath fading environments, OTFS achieves superior diversity
gain compared to conventional OFDM, which refers to enhanced error performance.

</details>


### [37] [Power allocation for cell-free MIMO integrated sensing and communication](https://arxiv.org/abs/2505.19845)
*Guoqing Xia,Pei Xiao,Qu Luo,Bing Ji,Yue Zhang,Huiyu Zhou*

Main category: eess.SP

TL;DR: 论文研究了在无小区MIMO网络中的综合感知与通信（ISAC），推导了位置和速度估计的闭式CRLB，提出了两种功率分配优化算法，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索在无小区MIMO网络中实现综合感知与通信的可行性，解决功率分配问题以优化通信和感知性能。

Method: 提出了PP-MCG-ILS和PP-MSD-ILS算法解决非线性非凸优化问题，并引入P-NCG-ILS算法用于纯感知场景的功率最小化。

Result: 仿真结果验证了CRLB的准确性，并表明所提算法能有效提升感知和ISAC整体性能。

Conclusion: 论文提出的算法和功率分配策略在无小区MIMO网络中显著提升了ISAC的性能。

Abstract: In this paper, we investigate integrated sensing and communication (ISAC) in
a cell-free (CF) multiple-input multiple-output (MIMO) network with
single-antenna access points (APs), where each AP functions either as a
transmitter for both sensing and communication or as a receiver for
target-reflected signals. We derive closed-form Cramer-Rao lower bounds (CRLBs)
for location and velocity estimation under arbitrary power allocation ratios,
assuming the radar cross-section (RCS) is deterministic and unknown over the
observation interval. A power allocation optimization problem is formulated to
maximize the communication signal-to-interference-plus-noise ratio (SINR),
subject to CRLB-based sensing constraints and per-transmitter power limits. To
solve the resulting nonlinear and non-convex problem, we propose a penalty
function and projection-based modified conjugate gradient algorithm with
inexact line search (PP-MCG-ILS), and an alternative method based on a modified
steepest descent approach (PP-MSD-ILS). Additionally, for power minimization in
pure sensing scenarios, we introduce a penalty function-based normalized
conjugate gradient algorithm (P-NCG-ILS). We analyze the convergence behavior
and qualitatively compare the computational complexity of the proposed
algorithms. Simulation results confirm the accuracy of the derived CRLBs and
demonstrate the effectiveness of the proposed power allocation strategies in
enhancing both sensing and overall ISAC performance.

</details>


### [38] [OFDMA for Pinching Antenna Systems](https://arxiv.org/abs/2505.19902)
*Thrassos K. Oikonomou,Sotiris A. Tegos,Panagiotis D. Diamantoulakis,Yuanwei Liu,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 该论文提出了一种基于OFDMA的框架，用于解决多用户场景下PA系统的频率选择性干扰问题，并通过轻量级算法实现用户公平性。


<details>
  <summary>Details</summary>
Motivation: 现有单载波设计忽略了多PA系统服务多用户时的频率选择性干扰（ISI），导致信道性能下降，亟需一种能有效解决ISI并保障用户公平性的方案。

Method: 1. 将信道建模为FIR滤波器；2. 提出OFDMA框架并设计最大-最小公平性资源分配问题；3. 采用两阶段启发式贪婪子载波分配和用户级注水算法。

Result: 仿真显示，相比单载波时分基线，该方法显著提升最低用户速率，并在中等级别LoS阻塞下保持稳健性。

Conclusion: OFDMA框架结合轻量级优化算法可有效解决PA系统的ISI问题，同时兼顾公平性与复杂度。

Abstract: Pinching-antenna (PA) systems route millimeter wave (mmWave) signals through
a leaky waveguide and radiate them at "pinch" apertures, offering low-cost
line-of-sight (LoS) coverage. However, when multiple PAs serve multiple users
simultaneously, the downlink channel becomes strongly frequency-selective,
creating inter-symbol interference (ISI) that existing single-carrier designs
overlook. This paper models the overall channel as a finite impulse response
(FIR) filter, characterizes its frequency selectivity, and explicitly accounts
for the resulting ISI. To overcome ISI, we introduce an orthogonal
frequency-division multiple access (OFDMA)-based framework and formulate a
max-min resource-allocation problem to achieve user fairness. A lightweight
two-stage heuristic-greedy subcarrier assignment, followed by per-user
water-filling, achieves near-optimal fairness with polynomial complexity.
Simulation results for an indoor layout demonstrate that the proposed scheme
notably increases the minimum user rate compared to time-division
single-carrier baselines and remains robust under moderate LoS blockage.

</details>


### [39] [On the Robustness of RSMA to Adversarial BD-RIS-Induced Interference](https://arxiv.org/abs/2505.20146)
*Arthur S. de Sena,Jacek Kibilda,Nurul H. Mahmood,Andre Gomes,Luiz A. DaSilva,Matti Latva-aho*

Main category: eess.SP

TL;DR: 该研究探讨了在多用户MIMO系统中，速率分多址接入（RSMA）对基于BD-RIS的信道获取干扰攻击的鲁棒性，揭示了在完美和不完美CSI条件下RSMA的性能表现差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于评估RSMA在面对BD-RIS引起的干扰攻击时的鲁棒性，尤其是在信道状态信息（CSI）不完美的实际场景中的表现。

Method: 研究方法包括提出两种干扰攻击策略（随机和对齐干扰），并利用Takagi分解生成随机反射系数，通过QCQP优化和对齐干扰攻击策略。

Result: 结果显示，在完美CSI下，RSMA与SDMA类似，易受攻击且性能损失严重；但在不完美CSI下，RSMA表现更鲁棒，尤其在发射功率增加时。

Conclusion: 结论指出，尽管RSMA在完美CSI下易受BD-RIS攻击，但在实际不完美的CSI条件下表现出更强的鲁棒性，优于SDMA。

Abstract: This article investigates the robustness of rate-splitting multiple access
(RSMA) in multi-user multiple-input multiple-output (MIMO) systems to
interference attacks against channel acquisition induced by beyond-diagonal
RISs (BD-RISs). Two primary attack strategies, random and aligned interference,
are proposed for fully connected and group-connected BD-RIS architectures.
Valid random reflection coefficients are generated exploiting the Takagi
factorization, while potent aligned interference attacks are achieved through
optimization strategies based on a quadratically constrained quadratic program
(QCQP) reformulation followed by projections onto the unitary manifold. Our
numerical findings reveal that, when perfect channel state information (CSI) is
available, RSMA behaves similarly to space-division multiple access (SDMA) and
thus is highly susceptible to the attack, with BD-RIS inducing severe
performance loss and significantly outperforming diagonal RIS. However, under
imperfect CSI, RSMA consistently demonstrates significantly greater robustness
than SDMA, particularly as the system's transmit power increases.

</details>


### [40] [Identification of Power System Dynamic Model Parameters using the Fisher Information Matrix](https://arxiv.org/abs/2505.20200)
*Dawn Virginillo,Asja Derviškadić,Mario Paolone*

Main category: eess.SP

TL;DR: 本文提出了一种基于Fisher信息矩阵数值逼近（nFIM）的方法，用于高效推断电力系统动态模型参数，适用于计算复杂的小型电磁瞬态（EMT）模型。


<details>
  <summary>Details</summary>
Motivation: 由于系统惯性减少、频率稳定性问题以及动态模型参数不可用或不准确（原因包括市场解绑、基础设施老化等），需要开发高效参数推断方法。

Method: 使用Fisher信息矩阵的数值逼近（nFIM）方法，适用于计算复杂的电磁瞬态（EMT）模型。

Result: 案例研究表明，nFIM与单参数和多参数最小二乘估计器的参数方差一致，验证了方法的有效性。

Conclusion: nFIM是一种高效、可扩展的动态模型参数推断方法，尤其适用于计算复杂的EMT模型。

Abstract: The expected decrease in system inertia and frequency stability motivates the
development and maintenance of dynamic system models by Transmission System
Operators. However, some dynamic model parameters can be unavailable due to
market unbundling, or inaccurate due to aging infrastructure, non-documented
tuning of controllers, or other factors. In this paper, we propose the use of a
numerical approximation of the Fisher Information Matrix (nFIM) for efficient
inference of dynamic model parameters. Thanks to the proposed numerical
implementation, the method is scalable to Electromagnetic Transient (EMT)
models, which can quickly become computationally complex even for small study
systems. Case studies show that the nFIM is coherent with parameter variances
of single- and multi-parameter least-squares estimators when applied to an IEEE
9-bus dynamic model with artificial measurements.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [41] [FlowSE: Efficient and High-Quality Speech Enhancement via Flow Matching](https://arxiv.org/abs/2505.19476)
*Ziqian Wang,Zikai Liu,Xinfa Zhu,Yike Zhu,Mingshuai Liu,Jun Chen,Longshuai Xiao,Chao Weng,Lei Xie*

Main category: eess.AS

TL;DR: FlowSE是一种基于流匹配的语音增强模型，解决了现有生成方法在语音增强中的量化损失、训练复杂度和高推理延迟问题，通过单次连续变换实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有语音增强生成方法如语言模型和扩散模型存在量化损失、训练复杂且推理延迟高的问题，FlowSE旨在通过流匹配技术解决这些挑战。

Method: FlowSE基于流匹配技术，学习带噪和干净语音分布的连续变换，训练时使用带噪梅尔谱和可选字符序列，优化条件流匹配损失，监督信号为真实梅尔谱。

Result: FlowSE在有无文本信息的情况下均表现优异，尤其在提供转录文本时效果更佳，显著优于现有生成方法，建立了生成式语音增强的新范式。

Conclusion: FlowSE展示了流匹配技术在语音增强领域的潜力，代码和预训练模型已开源，为生成式语音增强提供了高效高质量的解决方案。

Abstract: Generative models have excelled in audio tasks using approaches such as
language models, diffusion, and flow matching. However, existing generative
approaches for speech enhancement (SE) face notable challenges: language
model-based methods suffer from quantization loss, leading to compromised
speaker similarity and intelligibility, while diffusion models require complex
training and high inference latency. To address these challenges, we propose
FlowSE, a flow-matching-based model for SE. Flow matching learns a continuous
transformation between noisy and clean speech distributions in a single pass,
significantly reducing inference latency while maintaining high-quality
reconstruction. Specifically, FlowSE trains on noisy mel spectrograms and
optional character sequences, optimizing a conditional flow matching loss with
ground-truth mel spectrograms as supervision. It implicitly learns speech's
temporal-spectral structure and text-speech alignment. During inference, FlowSE
can operate with or without textual information, achieving impressive results
in both scenarios, with further improvements when transcripts are available.
Extensive experiments demonstrate that FlowSE significantly outperforms
state-of-the-art generative methods, establishing a new paradigm for
generative-based SE and demonstrating the potential of flow matching to advance
the field. Our code, pre-trained checkpoints, and audio samples are available.

</details>


### [42] [Mel-McNet: A Mel-Scale Framework for Online Multichannel Speech Enhancement](https://arxiv.org/abs/2505.19576)
*Yujie Yang,Bing Yang,Xiaofei Li*

Main category: eess.AS

TL;DR: 论文提出了一种基于Mel尺度的多通道语音增强框架（Mel-McNet），通过压缩STFT特征到Mel域并改进McNet骨干网络，显著降低计算复杂度且保持性能，实验验证其优于其他SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有在线多通道语音增强研究较少在Mel频域实现，尽管Mel尺度更符合人耳听觉感知且计算高效。

Method: 提出Mel-McNet框架，包含STFT-to-Mel模块压缩多通道STFT特征为Mel频域表示，改进的McNet骨干网络直接在Mel域生成增强的LogMel频谱。

Result: 在CHiME-3数据集上，Mel-McNet计算复杂度降低60%，增强和ASR性能与原McNet相当，且优于其他SOTA方法。

Conclusion: Mel-McNet验证了Mel尺度语音增强的潜力，为高效且高性能的语音处理提供了新方案。

Abstract: Online multichannel speech enhancement has been intensively studied recently.
Though Mel-scale frequency is more matched with human auditory perception and
computationally efficient than linear frequency, few works are implemented in a
Mel-frequency domain. To this end, this work proposes a Mel-scale framework
(namely Mel-McNet). It processes spectral and spatial information with two key
components: an effective STFT-to-Mel module compressing multi-channel STFT
features into Mel-frequency representations, and a modified McNet backbone
directly operating in the Mel domain to generate enhanced LogMel spectra. The
spectra can be directly fed to vocoders for waveform reconstruction or ASR
systems for transcription. Experiments on CHiME-3 show that Mel-McNet can
reduce computational complexity by 60% while maintaining comparable enhancement
and ASR performance to the original McNet. Mel-McNet also outperforms other
SOTA methods, verifying the potential of Mel-scale speech enhancement.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [43] [Interpretable Multi-Task PINN for Emotion Recognition and EDA Prediction](https://arxiv.org/abs/2505.18169)
*Nischal Mandal*

Main category: cs.LG

TL;DR: 本文提出了一种新型多任务物理信息神经网络（PINN），同时进行皮肤电活动（EDA）预测和情感分类，利用WESAD数据集验证，性能优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 通过可穿戴传感器理解和预测人类情感及生理状态，有助于压力监测、心理健康评估和情感计算。

Method: 采用多任务物理信息神经网络，结合心理自报告特征和物理启发的微分方程，通过自定义损失函数实现多任务训练。

Result: 模型平均EDA RMSE为0.0362，Pearson相关系数0.9919，F1分数94.08%，性能超过传统模型，且物理参数可解释。

Conclusion: 该框架首次将多任务PINN应用于可穿戴情感识别，性能优越且透明，为未来医疗和人机交互应用奠定基础。

Abstract: Understanding and predicting human emotional and physiological states using
wearable sensors has important applications in stress monitoring, mental health
assessment, and affective computing. This study presents a novel Multi-Task
Physics-Informed Neural Network (PINN) that performs Electrodermal Activity
(EDA) prediction and emotion classification simultaneously, using the publicly
available WESAD dataset. The model integrates psychological self-report
features (PANAS and SAM) with a physics-inspired differential equation
representing EDA dynamics, enforcing biophysically grounded constraints through
a custom loss function. This loss combines EDA regression, emotion
classification, and a physics residual term for improved interpretability.
  The architecture supports dual outputs for both tasks and is trained under a
unified multi-task framework. Evaluated using 5-fold cross-validation, the
model achieves an average EDA RMSE of 0.0362, Pearson correlation of 0.9919,
and F1-score of 94.08 percent. These results outperform classical models such
as SVR and XGBoost, as well as ablated variants like emotion-only and EDA-only
models.
  In addition, the learned physical parameters including decay rate (alpha_0),
emotional sensitivity (beta), and time scaling (gamma) are interpretable and
stable across folds, aligning with known principles of human physiology. This
work is the first to introduce a multi-task PINN framework for wearable emotion
recognition, offering improved performance, generalizability, and model
transparency. The proposed system provides a foundation for future
interpretable and multimodal applications in healthcare and human-computer
interaction.

</details>


### [44] [Riemannian Flow Matching for Brain Connectivity Matrices via Pullback Geometry](https://arxiv.org/abs/2505.18193)
*Antoine Collas,Ce Ju,Nicolas Salvy,Bertrand Thirion*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DiffeoCFM的方法，通过在流形上利用全局微分同胚的拉回度量，实现了高效的条件流匹配（CFM），从而在保留流形约束的同时快速生成脑连接矩阵。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在分析大脑组织异质性、理解疾病及增强分类问题时，生成真实的脑连接矩阵的挑战。流形约束使得传统黎曼工具计算效率低下，因此需要一种高效的方法。

Method: 方法是通过全局微分同胚的拉回度量，在流形上实现条件流匹配（CFM），从而将黎曼CFM转换为标准CFM问题，利用ODE求解器快速采样。具体通过矩阵对数（协方差矩阵）和归一化Cholesky分解（相关矩阵）实例化DiffeoCFM。

Result: 在三个大规模fMRI数据集（4600多次扫描，2800名受试者）和两个EEG运动想象数据集（30000多次试验，26名受试者）上测试，DiffeoCFM实现了快速训练并达到最先进性能，同时保持流形约束。

Conclusion: 结论表明，DiffeoCFM能够高效地在流形约束下生成脑连接矩阵，为脑科学研究和临床应用提供了有力工具。

Abstract: Generating realistic brain connectivity matrices is key to analyzing
population heterogeneity in brain organization, understanding disease, and
augmenting data in challenging classification problems. Functional connectivity
matrices lie in constrained spaces--such as the set of symmetric positive
definite or correlation matrices--that can be modeled as Riemannian manifolds.
However, using Riemannian tools typically requires redefining core operations
(geodesics, norms, integration), making generative modeling computationally
inefficient. In this work, we propose DiffeoCFM, an approach that enables
conditional flow matching (CFM) on matrix manifolds by exploiting pullback
metrics induced by global diffeomorphisms on Euclidean spaces. We show that
Riemannian CFM with such metrics is equivalent to applying standard CFM after
data transformation. This equivalence allows efficient vector field learning,
and fast sampling with standard ODE solvers. We instantiate DiffeoCFM with two
different settings: the matrix logarithm for covariance matrices and the
normalized Cholesky decomposition for correlation matrices. We evaluate
DiffeoCFM on three large-scale fMRI datasets with more than 4600 scans from
2800 subjects (ADNI, ABIDE, OASIS-3) and two EEG motor imagery datasets with
over 30000 trials from 26 subjects (BNCI2014-002 and BNCI2015-001). It enables
fast training and achieves state-of-the-art performance, all while preserving
manifold constraints.

</details>


### [45] [Mechanical in-sensor computing: a programmable meta-sensor for structural damage classification without external electronic power](https://arxiv.org/abs/2505.18579)
*Tingpeng Zhang,Xuzhang Peng,Mingyuan Zhou,Guobiao Hu,Zhilu Lai*

Main category: cs.LG

TL;DR: 本文提出了一种基于超材料的可编程传感器（MM-sensor），用于物理处理结构振动信息，完成结构健康监测任务，无需外部电子供电，适用于资源受限场景。


<details>
  <summary>Details</summary>
Motivation: 当前结构健康监测依赖有线系统和电子计算机，存在高能耗和低吞吐量的问题。物理计算的概念为SHM提供了新的思路，通过超材料实现传感与计算的物理集成。

Method: 采用局部谐振超材料板（LRMP）配置，通过设计其几何参数调整带隙特性，实现结构损伤前后的物理区分。

Result: 该方法适用于一阶自然频率9.54 Hz至81.86 Hz的工程系统，成功实现了结构损伤预警（二元分类）。

Conclusion: MM-sensor为结构健康监测提供了一种无需外部供电的高效解决方案，展示了物理计算在SHM中的潜力。

Abstract: Structural health monitoring (SHM) involves sensor deployment, data
acquisition, and data interpretation, commonly implemented via a tedious wired
system. The information processing in current practice majorly depends on
electronic computers, albeit with universal applications, delivering challenges
such as high energy consumption and low throughput due to the nature of digital
units. In recent years, there has been a renaissance interest in shifting
computations from electronic computing units to the use of real physical
systems, a concept known as physical computation. This approach provides the
possibility of thinking out of the box for SHM, seamlessly integrating sensing
and computing into a pure-physical entity, without relying on external
electronic power supplies, thereby properly coping with resource-restricted
scenarios. The latest advances of metamaterials (MM) hold great promise for
this proactive idea. In this paper, we introduce a programmable
metamaterial-based sensor (termed as MM-sensor) for physically processing
structural vibration information to perform specific SHM tasks, such as
structural damage warning (binary classification) in this initiation, without
the need for further information processing or resource-consuming, that is, the
data collection and analysis are completed in-situ at the sensor level. We
adopt the configuration of a locally resonant metamaterial plate (LRMP) to
achieve the first fabrication of the MM-sensor. We take advantage of the
bandgap properties of LRMP to physically differentiate the dynamic behavior of
structures before and after damage. By inversely designing the geometric
parameters, our current approach allows for adjustments to the bandgap
features. This is effective for engineering systems with a first natural
frequency ranging from 9.54 Hz to 81.86 Hz.

</details>


### [46] [Simultaneous Optimization of Efficiency and Degradation in Tunable HTL-Free Perovskite Solar Cells with MWCNT-Integrated Back Contact Using a Machine Learning-Derived Polynomial Regressor](https://arxiv.org/abs/2505.18693)
*Ihtesham Ibn Malek,Hafiz Imtiaz,Samia Subrina*

Main category: cs.LG

TL;DR: 论文提出了一种机器学习驱动的框架，通过结合实验验证和数值模拟来优化无空穴传输层的钙钛矿太阳能电池效率和稳定性，成功提升效率至16.84%，并减少降解至2.39%。


<details>
  <summary>Details</summary>
Motivation: 无空穴传输层的钙钛矿太阳能电池具有成本低且稳定的优势，但其效率和稳定性需要进一步提升，因此研究采用机器学习方法来优化这些指标。

Method: 研究通过生成1650个样本的数据集，使用四阶多项式回归器进行建模，并结合L-BFGS-B优化算法，通过加权目标函数最大化效率和减少降解。

Result: 最优模型的效率从13.7%提升至16.84%，降解从6.61%降至2.39%。多层感知器分类器实现了100%准确率识别最优配置。

Conclusion: 机器学习框架有效优化了无空穴传输层钙钛矿太阳能电池的性能，为未来设计提供了可靠工具。

Abstract: Perovskite solar cells (PSCs) without a hole transport layer (HTL) offer a
cost-effective and stable alternative to conventional architectures, utilizing
only an absorber layer and an electron transport layer (ETL). This study
presents a machine learning (ML)-driven framework to optimize the efficiency
and stability of HTL-free PSCs by integrating experimental validation with
numerical simulations. Excellent agreement is achieved between a fabricated
device and its simulated counterpart at a molar fraction \( x = 68.7\% \) in
\(\mathrm{MAPb}_{1-x}\mathrm{Sb}_{2x/3}\mathrm{I}_3\), where MA is
methylammonium. A dataset of 1650 samples is generated by varying molar
fraction, absorber defect density, thickness, and ETL doping, with
corresponding efficiency and 50-hour degradation as targets. A fourth-degree
polynomial regressor (PR-4) shows the best performance, achieving RMSEs of
0.0179 and 0.0117, and \( R^2 \) scores of 1 and 0.999 for efficiency and
degradation, respectively. The derived model generalizes beyond the training
range and is used in an L-BFGS-B optimization algorithm with a weighted
objective function to maximize efficiency and minimize degradation. This
improves device efficiency from 13.7\% to 16.84\% and reduces degradation from
6.61\% to 2.39\% over 1000 hours. Finally, the dataset is labeled into superior
and inferior classes, and a multilayer perceptron (MLP) classifier achieves
100\% accuracy, successfully identifying optimal configurations.

</details>


### [47] [Smart Energy Guardian: A Hybrid Deep Learning Model for Detecting Fraudulent PV Generation](https://arxiv.org/abs/2505.18755)
*Xiaolu Chen,Chenghao Huang,Yanru Zhang,Hao Wang*

Main category: cs.LG

TL;DR: 本文提出了一种结合多尺度CNN、LSTM和Transformer的混合深度学习模型，用于高效检测住宅光伏发电中的电力盗窃行为，通过数据嵌入技术整合时间序列和离散温度变量，提升了检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着智能电网的普及，智慧城市面临来自网络攻击和复杂电力盗窃行为的挑战，尤其在住宅光伏发电系统中，传统电力盗窃检测方法难以捕捉复杂的时序依赖和多源数据整合，有效性受限。

Method: 提出一种混合深度学习模型，结合多尺度CNN、LSTM和Transformer，用于捕捉短长期时序依赖，并引入数据嵌入技术整合时间序列和离散温度变量。

Result: 通过真实数据的大规模仿真实验验证，该方法显著提高了复杂电力盗窃行为的检测准确率。

Conclusion: 该方法为智慧城市能源系统的稳定性和公平性提供了有效支持，解决了传统方法的局限性。

Abstract: With the proliferation of smart grids, smart cities face growing challenges
due to cyber-attacks and sophisticated electricity theft behaviors,
particularly in residential photovoltaic (PV) generation systems. Traditional
Electricity Theft Detection (ETD) methods often struggle to capture complex
temporal dependencies and integrating multi-source data, limiting their
effectiveness. In this work, we propose an efficient ETD method that accurately
identifies fraudulent behaviors in residential PV generation, thus ensuring the
supply-demand balance in smart cities. Our hybrid deep learning model,
combining multi-scale Convolutional Neural Network (CNN), Long Short-Term
Memory (LSTM), and Transformer, excels in capturing both short-term and
long-term temporal dependencies. Additionally, we introduce a data embedding
technique that seamlessly integrates time-series data with discrete temperature
variables, enhancing detection robustness. Extensive simulation experiments
using real-world data validate the effectiveness of our approach, demonstrating
significant improvements in the accuracy of detecting sophisticated energy
theft activities, thereby contributing to the stability and fairness of energy
systems in smart cities.

</details>


### [48] [Towards a Spatiotemporal Fusion Approach to Precipitation Nowcasting](https://arxiv.org/abs/2505.19258)
*Felipe Curcio,Pedro Castro,Augusto Fonseca,Rafaela Castro,Raquel Franco,Eduardo Ogasawara,Victor Stepanenko,Fabio Porto,Mariza Ferro,Eduardo Bezerra*

Main category: cs.LG

TL;DR: 该研究提出了一种数据融合方法，结合气象站、雨量站、ERA5再分析数据和GFS数值天气预报数据，利用STConvS2S深度学习架构改进降水临近预报，取得了较高的F1分数。


<details>
  <summary>Details</summary>
Motivation: 随着气象数据来源的多样化，需要高效的数据整合方法来提升天气预报和水文气象研究的准确性。

Method: 采用STConvS2S深度学习架构，整合气象站、雨量站、ERA5数据和GFS数值预报数据，覆盖9 x 11网格，时间跨度为2011年至2024年。

Result: 融合模型在预报强降水事件（大于25毫米/小时）时，一小时内达到了0.2033的F1分数。

Conclusion: 研究展示了数据融合方法在降水临近预报中的有效性，并提出了一种改进的推理策略。

Abstract: With the increasing availability of meteorological data from various sensors,
numerical models and reanalysis products, the need for efficient data
integration methods has become paramount for improving weather forecasts and
hydrometeorological studies. In this work, we propose a data fusion approach
for precipitation nowcasting by integrating data from meteorological and rain
gauge stations in Rio de Janeiro metropolitan area with ERA5 reanalysis data
and GFS numerical weather prediction. We employ the spatiotemporal deep
learning architecture called STConvS2S, leveraging a structured dataset
covering a 9 x 11 grid. The study spans from January 2011 to October 2024, and
we evaluate the impact of integrating three surface station systems. Among the
tested configurations, the fusion-based model achieves an F1-score of 0.2033
for forecasting heavy precipitation events (greater than 25 mm/h) at a one-hour
lead time. Additionally, we present an ablation study to assess the
contribution of each station network and propose a refined inference strategy
for precipitation nowcasting, integrating the GFS numerical weather prediction
(NWP) data with in-situ observations.

</details>


### [49] [Task-Oriented Low-Label Semantic Communication With Self-Supervised Learning](https://arxiv.org/abs/2505.19940)
*Run Gu,Wei Xu,Zhaohui Yang,Dusit Niyato,Aylin Yener*

Main category: cs.LG

TL;DR: 该论文提出了一种自监督学习框架SLSCom，用于在标记样本有限的情况下提升语义通信的任务推理性能，通过对比学习和信息瓶颈优化实现高效语义提取，实验表明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决标记样本稀缺场景下任务导向语义通信的性能瓶颈问题，通过自监督学习利用无标记样本提升效率。

Method: 结合对比学习和信息瓶颈（IB）问题优化语义编码器设计，采用自监督分类与重建任务解决IB计算难题，并提出联合训练方法提升无线信道下的端到端推理精度。

Result: 在图像分类任务中，SLSCom在多径无线信道上显著优于传统数字编码和现有DL方法，尤其在标记数据少或信噪比变化时表现优异。

Conclusion: SLSCom为有限标记场景下的语义通信提供了高效解决方案，自监督机制和联合训练策略展示了强鲁棒性和泛化能力。

Abstract: Task-oriented semantic communication enhances transmission efficiency by
conveying semantic information rather than exact messages. Deep learning
(DL)-based semantic communication can effectively cultivate the essential
semantic knowledge for semantic extraction, transmission, and interpretation by
leveraging massive labeled samples for downstream task training. In this paper,
we propose a self-supervised learning-based semantic communication framework
(SLSCom) to enhance task inference performance, particularly in scenarios with
limited access to labeled samples. Specifically, we develop a task-relevant
semantic encoder using unlabeled samples, which can be collected by devices in
real-world edge networks. To facilitate task-relevant semantic extraction, we
introduce self-supervision for learning contrastive features and formulate the
information bottleneck (IB) problem to balance the tradeoff between the
informativeness of the extracted features and task inference performance. Given
the computational challenges of the IB problem, we devise a practical and
effective solution by employing self-supervised classification and
reconstruction pretext tasks. We further propose efficient joint training
methods to enhance end-to-end inference accuracy over wireless channels, even
with few labeled samples. We evaluate the proposed framework on image
classification tasks over multipath wireless channels. Extensive simulation
results demonstrate that SLSCom significantly outperforms conventional digital
coding methods and existing DL-based approaches across varying labeled data set
sizes and SNR conditions, even when the unlabeled samples are irrelevant to the
downstream tasks.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [50] [Customising Electricity Contracts at Scale with Large Language Models](https://arxiv.org/abs/2505.19551)
*Jochen L. Cremer*

Main category: eess.SY

TL;DR: 论文探讨如何利用大型语言模型（LLM）通过聊天形式让终端用户直接协商个性化的用电合同，以解决电网规划中人工效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 电网系统日益复杂，人工处理终端用户接入请求效率低且成本高，导致标准合同无法满足个性化需求。

Method: 利用LLM构建聊天系统，直接访问电网模型并分析技术约束，替代专家工程师的中间角色。

Result: 初步研究表明，该LLM系统可高效支持用户直接协商个性化合同，提升电网规划效率。

Conclusion: LLM为电网规划和用户管理提供了高效的新途径，未来可进一步开发此类定制系统。

Abstract: The electricity system becomes more complex, connecting massive numbers of
end-users and distributed generators. Adding or removing grid connections
requires expert studies to align technical constraints with user requests. In
times of labour shortages, carrying out these studies represents a significant
amount of time that engineers at system operators spend in planning
departments. As time is limited, only standard block connectivity contracts can
be offered to end-users, or the requests pile up. Even if offers are made,
these often do not perfectly match the user's requirements, leading to
overpaying or underusing the grid capacity. This paper investigates whether
end-users can negotiate individual, flexible time-of-use contracts directly
with the grid using Large Language Models (LLM) in chats at scale. The
LLM-based chat has direct access to a model of the grid and studies the grid's
technical constraints just as an expert engineer. The advantage of this system
is that end-users can directly interact with grid models through natural
language; no intermediate is needed to service, analyse, study, assess, advise,
consult and engineer. This initial study paves the way toward developing this
tailored LLM system, resulting in possible high-efficiency gains for grid
planning and customer management.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [51] [Design of a Wearable Parallel Electrical Impedance Imaging System for Healthcare](https://arxiv.org/abs/2505.19146)
*Bowen Li,Zekun Chen,Xuefei Chen,Luhao Zhang,Shili Liang*

Main category: physics.med-ph

TL;DR: 该论文提出了一种基于AD5933的无线可穿戴电阻抗断层成像（EIT）系统，用于实时肺部呼吸成像，通过并行测量和抑制寄生电容实现高精度、低成本生物组织测量。


<details>
  <summary>Details</summary>
Motivation: 开发一种便携、低成本的EIT系统，用于实时监测肺部呼吸等生物组织阻抗变化，解决现有技术中寄生电容和测量速度的限制。

Method: 采用AD5933器件实现电流注入方法，针对人体阻抗特性设计电压激励与电流测量；使用五个AD5933单元并行测量以提高速度，并通过同步措施确保数据一致性；同时抑制寄生电容的影响。

Result: 系统在水槽、呼吸时的人体肺部及静息时的小腿测量中生成电导率图像，验证了其高精度和低成本特性。

Conclusion: 该无线可穿戴EIT系统能够高效、精准地测量生物组织阻抗，为实时监测应用提供了可行方案。

Abstract: A wireless wearable electrical impedance tomography (EIT) system has been
developed using the AD5933 for real-time lung respiration imaging. The system
uses a current injection method tailored to the human body's impedance
characteristics. It applies a voltage excitation and measures the resulting
current as the voltage passes through the body. Additionally, measures are
taken to suppress the effects of parasitic capacitance, which can lead to
signal oscillations and leakage currents. Additionally, to improve data
acquisition speed, five AD5933 units are used for parallel measurements, with
multiple measures taken to ensure high synchronization during the parallel
acquisition process. The results demonstrate conductivity images generated from
the EIT system, with data collected from a water tank, human lungs during
respiration, and a human calf at rest, confirming that this portable EIT system
can measure biological tissues with high precision and low cost.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [52] [BR-ASR: Efficient and Scalable Bias Retrieval Framework for Contextual Biasing ASR in Speech LLM](https://arxiv.org/abs/2505.19179)
*Xun Gong,Anqi Lv,Zhiming Wang,Huijia Zhu,Yanmin Qian*

Main category: cs.SD

TL;DR: BR-ASR提出了一种基于偏置检索的大规模上下文偏置框架，通过语音与偏置对比学习和动态课程学习提升命名实体和罕见词识别，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决语音大语言模型（SpeechLLMs）在大规模上下文偏置（如命名实体和罕见词）中的挑战，提升自动语音识别（ASR）性能。

Method: 采用语音与偏置对比学习和动态课程学习，减少同音词干扰，支持200k条目的偏置检索。

Result: 在LibriSpeech测试集上，B-WER降低45%，200k条目时仍保持高效率和低延迟。

Conclusion: BR-ASR是一种高效、可扩展的框架，无需微调即可集成到多种ASR系统中，显著提升性能。

Abstract: While speech large language models (SpeechLLMs) have advanced standard
automatic speech recognition (ASR), contextual biasing for named entities and
rare words remains challenging, especially at scale. To address this, we
propose BR-ASR: a Bias Retrieval framework for large-scale contextual biasing
(up to 200k entries) via two innovations: (1) speech-and-bias contrastive
learning to retrieve semantically relevant candidates; (2) dynamic curriculum
learning that mitigates homophone confusion which negatively impacts the final
performance. The is a general framework that allows seamless integration of the
retrieved candidates into diverse ASR systems without fine-tuning. Experiments
on LibriSpeech test-clean/-other achieve state-of-the-art (SOTA) biased word
error rates (B-WER) of 2.8%/7.1% with 2000 bias words, delivering 45% relative
improvement over prior methods. BR-ASR also demonstrates high scalability: when
expanding the bias list to 200k where traditional methods generally fail, it
induces only 0.3 / 2.9% absolute WER / B-WER degradation with a 99.99% pruning
rate and only 20ms latency per query on test-other.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [53] [RIS-Assisted Survivable Fronthaul Design in Cell-Free Massive MIMO System](https://arxiv.org/abs/2505.19152)
*Zhenyu Li,Özlem Tuğfe Demir,Emil Björnson,Cicek Cavdar*

Main category: cs.IT

TL;DR: 论文研究了可重构智能表面（RIS）在无小区大规模MIMO系统中增强前传链路生存性的应用，通过优化算法和资源分配实现成本降低和可靠性提升。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过RIS提升无小区大规模MIMO系统中前传链路的生存性，解决直接链路中断时的可靠性问题并减少冗余资源需求。

Method: 结合改进的加权最小均方误差（WMMSE）算法和黎曼梯度下降优化RIS相位，同时利用冗余电缆容量资源分配机制。

Result: RIS使所需冗余容量减少65.6%，在直接链路完全中断时表现最佳，实现了99%的生存性。

Conclusion: RIS能显著提高前传可靠性并降低基础设施成本，对下一代无线网络具有重要价值。

Abstract: This paper investigates the application of reconfigurable intelligent
surfaces (RISs) to improve fronthaul link survivability in cell-free massive
MIMO (CF mMIMO) systems. To enhance the fronthaul survivability, two
complementary mechanisms are considered. Firstly, RIS is set to provide
reliable line-of-sight (LOS) connectivity and enhance the mmWave backup link.
Secondly, a resource-sharing scheme that leverages redundant cable capacity
through neighboring master access points (APs) to guarantee availability is
considered. We formulate the redundant capacity minimization problem as a
RIS-assisted multi-user MIMO rate control optimization problem, developing a
novel solution that combines a modified weighted minimum mean square error
(WMMSE) algorithm for precoding design with Riemannian gradient descent for RIS
phase shift optimization. Our numerical evaluations show that RIS reduces the
required redundant capacity by 65.6% compared to the no RIS case to reach a 99%
survivability. The results show that the most substantial gains of RIS occur
during complete outages of the direct disconnected master AP-CPU channel. These
results demonstrate RIS's potential to significantly enhance fronthaul
reliability while minimizing infrastructure costs in next-generation wireless
networks.

</details>


### [54] [Capacity-Optimized Pre-Equalizer Design for Visible Light Communication Systems](https://arxiv.org/abs/2505.19709)
*Runxin Zhang,Yulin Shao,Jian Xiong,Lu Lu,Murat Uysal*

Main category: cs.IT

TL;DR: 该文章探讨了商用LED在可见光通信系统中的调制带宽限制问题，并提出了一种新的预均衡器设计方法，以平衡带宽和信号噪声比，从而最大化信道容量。


<details>
  <summary>Details</summary>
Motivation: 商用LED主要用于照明而非数据传输，其有限的调制带宽成为可见光通信系统的瓶颈。现有均衡器设计虽然能扩展带宽，但常忽略信号噪声比的下降，导致信道容量未能最优。本文旨在解决这一问题。

Method: 通过建立信道容量的闭式表达式，并将其作为预均衡器电路参数的显函数，文章提出了一种系统性的模拟预均衡器设计方法，平衡带宽与信号噪声比。

Result: 数值结果表明，所提出的设计方法在多种信道衰减条件下显著优于传统带宽优化的预均衡器设计，有效提升了总体信道容量。

Conclusion: 文章通过理论分析和实验验证，证明了所提出的预均衡器设计方法能够在带宽扩展的同时控制信号噪声比的下降，从而最大化可见光通信系统的信道容量。

Abstract: Since commercial LEDs are primarily designed for illumination rather than
data transmission, their modulation bandwidth is inherently limited to a few
MHz. This becomes a major bottleneck in the implementation of visible light
communication (VLC) systems necessiating the design of pre-equalizers. While
state-of-the-art equalizer designs primarily focus on the data rate increasing
through bandwidth expansion, they often overlook the accompanying degradation
in signal-to-noise ratio (SNR). Achieving effective bandwidth extension without
introducing excessive SNR penalties remains a significant challenge, since the
channel capacity is a non-linear function of both parameters. In this paper, we
present a fundamental analysis of how the parameters of the LED and
pre-equalization circuits influence the channel capacity in intensity
modulation and direct detection (IMDD)-based VLC systems. We derive a
closed-form expression for channel capacity model that is an explicitly
function of analog pre-equalizer circuit parameters. Building upon the derived
capacity expression, we propose a systematic design methodology for analog
pre-equalizers that effectively balances bandwidth and SNR, thereby maximizing
the overall channel capacity across a wide range of channel attenuations. We
present extensive numerical results to validate the effectiveness of the
proposed design and demonstrate the improvements over conventional
bandwidth-optimized pre-equalizer designs.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [55] [ALPCAHUS: Subspace Clustering for Heteroscedastic Data](https://arxiv.org/abs/2505.18918)
*Javier Salazar Cavazos,Jeffrey A Fessler,Laura Balzano*

Main category: stat.ML

TL;DR: 该论文提出了一种名为ALPCAHUS的异方差子空间聚类方法，通过估计样本噪声方差来改进低秩结构的基础估计，并在仿真和真实数据实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的PCA扩展方法在处理异质性数据（如噪声特性不同的数据样本）时存在不足，因此需要开发一种能有效处理混合数据质量的异方差子空间聚类方法。

Method: ALPCAHUS基于K-子空间（KSS）原则，扩展了异方差PCA方法（LR-ALPCAH），通过估计样本噪声方差并利用这些信息改进子空间基的估计。

Result: 仿真和真实数据实验表明，ALPCAHUS在考虑数据异方差性时优于现有的聚类算法。

Conclusion: ALPCAHUS有效地解决了异质性数据子空间聚类问题，特别是在噪声特性变化的场景中表现优越。

Abstract: Principal component analysis (PCA) is a key tool in the field of data
dimensionality reduction. Various methods have been proposed to extend PCA to
the union of subspace (UoS) setting for clustering data that come from multiple
subspaces like K-Subspaces (KSS). However, some applications involve
heterogeneous data that vary in quality due to noise characteristics associated
with each data sample. Heteroscedastic methods aim to deal with such mixed data
quality. This paper develops a heteroscedastic-focused subspace clustering
method, named ALPCAHUS, that can estimate the sample-wise noise variances and
use this information to improve the estimate of the subspace bases associated
with the low-rank structure of the data. This clustering algorithm builds on
K-Subspaces (KSS) principles by extending the recently proposed heteroscedastic
PCA method, named LR-ALPCAH, for clusters with heteroscedastic noise in the UoS
setting. Simulations and real-data experiments show the effectiveness of
accounting for data heteroscedasticity compared to existing clustering
algorithms. Code available at https://github.com/javiersc1/ALPCAHUS.

</details>
