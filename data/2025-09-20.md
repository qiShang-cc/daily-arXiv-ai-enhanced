<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [cs.RO](#cs.RO) [Total: 48]
- [math.OC](#math.OC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.NI](#cs.NI) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [In Planta Tattoo and Kirigami Sensors for Self-Powered Monitoring of Vapor Pressure Deficit and Growth Dynamics](https://arxiv.org/abs/2509.14240)
*Nafize Ishtiaque Hossain,Kundan Saha,Atul Sharma,Sameer Sonkusale*

Main category: eess.SP

TL;DR: 一种可扩展的自供电植物传感器平台，用于持续监测植物水分和生长，通过叶片和茎传感器实现能量自主运行。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需外部电源的传感器，实时监测植物水分和生长状况，以提高农业管理效率。

Method: 结合叶片纹身传感器（测量温湿度并收集能量）和茎基应变传感器（跟踪生长），采用无洁净室兼容的大规模制造方法。

Result: 传感器可持续工作10天（叶片）和20天（茎），能量密度0.1114 μW/cm²，高灵敏度且抗干扰。

Conclusion: 该平台具有大规模农业应用的潜力，可用于监测非生物胁迫和优化作物管理。

Abstract: We report a scalable, self-powered in planta sensor platform for continuous
monitoring of plant hydration and growth. The system integrates two components
a leaf mounted tattoo sensor for estimating vapor pressure deficit and a
kirigami inspired strain sensor for tracking radial stem growth. Uniquely, the
tattoo sensor serves a dual function measuring temperature and humidity beneath
the leaf surface while simultaneously harvesting power from ambient moisture
via a vanadium pentoxide nanosheet membrane. This moist-electric generator
configuration enables energy-autonomous operation, delivering a power density
of 0.1114 miroW per square cm. The V2O5 based sensor exhibits high sensitivity
to humidity and temperature, enabling accurate VPD estimation for over 10 days
until leaf senescence. The eutectogel based kirigami strain sensor, wrapped
around the stem, offers a gauge factor of 1.5 and immunity to unrelated
mechanical disturbances, allowing continuous growth tracking for more than 20
days. Both sensors are fabricated via cleanroom-free, roll to roll compatible
methods, underscoring their potential for large-scale agricultural deployment
to monitor abiotic stress and improve crop management.

</details>


### [2] [Artificial Intelligence-derived Cardiotocography Age as a Digital Biomarker for Predicting Future Adverse Pregnancy Outcomes](https://arxiv.org/abs/2509.14242)
*Jinshuai Gu,Zenghui Lin,Jingying Ma,Jingyu Wang,Linyan Zhang,Rui Bai,Zelin Tu,Youyou Jiang,Donglin Xie,Yuxi Zhou,Guoli Liu,Shenda Hong*

Main category: eess.SP

TL;DR: 该研究开发了一个基于AI的模型（CTGage），通过CTG时间序列预测胎儿生物学年龄，并利用年龄差（CTGage-gap）作为新的数字生物标志物，以预测未来不良妊娠结局。结果显示，CTGage-gap能有效区分高风险群体。


<details>
  <summary>Details</summary>
Motivation: CTG目前主要用于评估胎儿当前状态，而其在预测未来不良妊娠结局方面的潜力尚未充分挖掘。研究旨在填补这一空白。

Method: 采用11,385名孕妇的61,140条CTG记录，基于1D卷积神经网络和分布对齐增强回归技术训练CTGage模型，并将CTGage-gap分为五组进行比较分析。

Result: CTGage模型平均绝对误差为10.91天，高风险组（低估或高估组）的不良结局和母体疾病发生率显著高于正常组。

Conclusion: CTGage作为一种新型非侵入性生物标志物，具有预测未来不良妊娠结局的潜力。

Abstract: Cardiotocography (CTG) is a low-cost, non-invasive fetal health assessment
technique used globally, especially in underdeveloped countries. However, it is
currently mainly used to identify the fetus's current status (e.g., fetal
acidosis or hypoxia), and the potential of CTG in predicting future adverse
pregnancy outcomes has not been fully explored. We aim to develop an AI-based
model that predicts biological age from CTG time series (named CTGage), then
calculate the age gap between CTGage and actual age (named CTGage-gap), and use
this gap as a new digital biomarker for future adverse pregnancy outcomes. The
CTGage model is developed using 61,140 records from 11,385 pregnant women,
collected at Peking University People's Hospital between 2018 and 2022. For
model training, a structurally designed 1D convolutional neural network is
used, incorporating distribution-aligned augmented regression technology. The
CTGage-gap is categorized into five groups: < -21 days (underestimation group),
-21 to -7 days, -7 to 7 days (normal group), 7 to 21 days, and > 21 days
(overestimation group). We further defined the underestimation group and
overestimation group together as the high-risk group. We then compare the
incidence of adverse outcomes and maternal diseases across these groups. The
average absolute error of the CTGage model is 10.91 days. When comparing the
overestimation group with the normal group, premature infants incidence is
5.33% vs. 1.42% (p < 0.05) and gestational diabetes mellitus (GDM) incidence is
31.93% vs. 20.86% (p < 0.05). When comparing the underestimation group with the
normal group, low birth weight incidence is 0.17% vs. 0.15% (p < 0.05) and
anaemia incidence is 37.51% vs. 34.74% (p < 0.05). Artificial
intelligence-derived CTGage can predict the future risk of adverse pregnancy
outcomes and hold potential as a novel, non-invasive, and easily accessible
digital biomarker.

</details>


### [3] [InWaveSR: Topography-Aware Super-Resolution Network for Internal Solitary Waves](https://arxiv.org/abs/2509.14243)
*Xinjie Wang,Zhongrui Li,Peng Han,Chunxin Yuan,Jiexin Xu,Zhiqiang Wei,Jie Nie*

Main category: eess.SP

TL;DR: 提出了一种基于深度学习与物理约束的时空超分辨率模型InWaveSR，用于从低分辨率数据生成高分辨率数据，尤其适用于内部孤立波（ISW）数据。模型通过Navier-Stokes方程约束提升物理一致性，并引入HF-ResBlock组件和FFT方法优化高频特征捕获。


<details>
  <summary>Details</summary>
Motivation: 解决观测数据分辨率不足的问题，尤其是内部孤立波数据的高分辨率重建需求。

Method: 结合深度学习框架与物理约束，使用Navier-Stokes方程确保物理一致性，引入HF-ResBlock和FFT方法提升性能，优化训练过程以适应复杂地形。

Result: 在实测ISW数据上，InWaveSR的信噪比（PSNR）达到36.2，优于传统插值方法和先前神经网络。

Conclusion: InWaveSR在ISW高分辨率重建中表现出色，显著优于传统方法，具有高可靠性和性能。

Abstract: The effective utilization of observational data is frequently hindered by
insufficient resolution. To address this problem, we present a new
spatio-temporal super-resolution (STSR) model, called InWaveSR. It is built on
a deep learning framework with physical restrictions and can efficiently
generate high-resolution data from low-resolution input, especially for data
featuring internal solitary waves (ISWs). To increase generality and
interpretation, the model InWaveSR uses the primitive Navier-Stokes equations
as the constraint, ensuring that the output results are physically consistent.
In addition, the proposed model incorporates an HF-ResBlock component that
combines the attention mechanism and the Fast Fourier Transform (FFT) method to
improve the performance of the model in capturing high-frequency
characteristics. Simultaneously, in order to enhance the adaptability of the
model to complicated bottom topography, an edge sampling and numerical
pre-processing method are carried out to optimize the training process. On
evaluations using the in-situ observational ISW data, the proposed InWaveSR
achieved a peak signal-to-noise ratio (PSNR) score of 36.2, higher than those
of the traditional interpolation method and the previous neural network. This
highlights its significant superiority over traditional methods, demonstrating
its excellent performance and reliability in high-resolution ISW
reconstruction.

</details>


### [4] [Conditional Nearest Level Modulation for Improved Switching Dynamics in Asymmetric Multilevel Converters](https://arxiv.org/abs/2509.14402)
*Jinshui Zhang,Angel V Peterchev,Stefan M Goetz*

Main category: eess.SP

TL;DR: 提出了一种条件最近电平调制（cNLM）方法，通过数学惩罚模型优化开关动态，显著减少输出失真和开关频率。


<details>
  <summary>Details</summary>
Motivation: 模块化多电平转换器在清洁能源等领域应用广泛，但传统方法在非对称电路中会导致开关频率过高和输出失真。

Method: 结合数学惩罚模型改进最近电平调制（NLM），并提出针对特定功能的cNLM变体。

Result: 实验证明，cNLM将总输出失真从66.3%降至15.1%，开关频率降至NLM的8%。

Conclusion: cNLM有效解决了非对称多电平电路的开关和失真问题，适用于多种应用场景。

Abstract: Modular multilevel converters have promising applications in clean energy,
electric vehicles, and biomedical instrumentation, but need many modules to
achieve fine output granularity, particularly of the voltage. Asymmetric
multilevel circuits introduce differences in module voltages so that the
quantity of output levels grows exponentially with the number of modules.
Nearest-level modulation (NLM) is preferred over carrier-based methods in
asymmetric circuits for its simplicity. However, the large number of output
levels can overwhelm NLM and cause excessive transistor switching on some
modules and output voltage spikes. We propose a conditional nearest-level
modulation (cNLM) by incorporating mathematical penalty models to regulate
switching dynamics. This approach improves output quality and reduces switching
rates. Additionally, we present cNLM variations tailored for specific
functions, such as enforcing a minimum switching interval. Experimental
validation on an asymmetric multilevel prototype demonstrates that cNLM reduces
the total output distortion from 66.3% to 15.1% while cutting the switching
rate to just 8% of the original NLM.

</details>


### [5] [Indoor Airflow Imaging Using Physics-Informed Background-Oriented Schlieren Tomography](https://arxiv.org/abs/2509.14442)
*Arjun Teh,Wael H. Ali,Joshua Rapp,Hassan Mansour*

Main category: eess.SP

TL;DR: 提出一种基于背景导向纹影（BOS）的单视角非侵入式室内气流体积估计框架，结合物理信息重建方法解决严重不适定问题。


<details>
  <summary>Details</summary>
Motivation: 旨在通过单视角测量实现室内气流的非侵入式体积估计，解决传统方法的局限性。

Method: 结合改进的射线追踪、物理光线渲染与损失函数，以及利用物理信息神经网络（PINN）进行正则化。

Result: 框架能够从单视角重建与浮力驱动气流控制方程一致的气流分布。

Conclusion: 该框架为单视角BOS成像提供了有效的解决方案，适用于室内气流分析。

Abstract: We develop a framework for non-invasive volumetric indoor airflow estimation
from a single viewpoint using background-oriented schlieren (BOS) measurements
and physics-informed reconstruction. Our framework utilizes a light projector
that projects a pattern onto a target back-wall and a camera that observes
small distortions in the light pattern. While the single-view BOS tomography
problem is severely ill-posed, our proposed framework addresses this using: (1)
improved ray tracing, (2) a physics-based light rendering approach and loss
formulation, and (3) a physics-based regularization using a physics-informed
neural network (PINN) to ensure that the reconstructed airflow is consistent
with the governing equations for buoyancy-driven flows.

</details>


### [6] [Biologically Plausible Online Hebbian Meta-Learning: Two-Timescale Local Rules for Spiking Neural Brain Interfaces](https://arxiv.org/abs/2509.14447)
*Sriram V. C. Nallani,Gautham Ramachandran,Sahil S. Shah*

Main category: eess.SP

TL;DR: 论文提出了一种在线SNN解码器，结合局部三因素学习规则和双时间尺度资格痕迹，无需时间反向传播（BPTT），即可实现高效、内存友好的神经解码。


<details>
  <summary>Details</summary>
Motivation: 解决脑机接口（BCI）中神经信号不稳定性和实时植入应用的内存限制问题，开发一种适应性强且内存高效的解码方法。

Method: 采用局部三因素学习规则和双时间尺度资格痕迹，结合错误调制的Hebbian更新、快速/慢速痕迹整合及自适应学习率控制。

Result: 在两个灵长类数据集上实现了与BPTT方法相当的解码精度（Pearson R ≥0.63 Zenodo，R ≥0.81 MC Maze），内存减少28-35%，收敛更快，同时能够在闭环模拟中适应神经干扰并从零开始学习。

Conclusion: 该方法为资源受限的植入式BCI系统提供了内存高效且持续自适应的神经解码解决方案。

Abstract: Brain-Computer Interfaces face challenges from neural signal instability and
memory constraints for real-time implantable applications. We introduce an
online SNN decoder using local three-factor learning rules with dual-timescale
eligibility traces that avoid backpropagation through time while maintaining
competitive performance. Our approach combines error-modulated Hebbian updates,
fast/slow trace consolidation, and adaptive learning rate control, requiring
only O(1) memory versus O(T) for BPTT methods. Evaluations on two primate
datasets achieve comparable decoding accuracy (Pearson $R \geq 0.63$ Zenodo, $R
\geq 0.81$ MC Maze) with 28-35% memory reduction and faster convergence than
BPTT-trained SNNs. Closed-loop simulations with synthetic neural populations
demonstrate adaptation to neural disruptions and learning from scratch without
offline calibration. This work enables memory-efficient, continuously adaptive
neural decoding suitable for resource-constrained implantable BCI systems.

</details>


### [7] [Secure Blind Graph Signal Recovery and Adversary Detection Using Smoothness Maximization](https://arxiv.org/abs/2509.14449)
*Mahdi Shamsi,Hadi Zayyani,Hasan Abu Hilal,Mohammad Salman*

Main category: eess.SP

TL;DR: 提出了一种安全的盲图信号恢复算法，用于检测对抗节点，并在存在测量噪声和虚假数据注入的情况下恢复信号。


<details>
  <summary>Details</summary>
Motivation: 解决未知对抗节点注入虚假数据时恢复图信号的挑战性问题。

Method: 基于差分平滑度的统计方法检测对抗节点，并通过平滑度最大化进行信号恢复。

Result: 仿真结果显示，该方法在信号恢复方面显著优于中位数GSR算法和其他竞争方法。

Conclusion: 该算法是一种有效的、低复杂度的安全图信号恢复方法。

Abstract: In this letter, we propose a secure blind Graph Signal Recovery (GSR)
algorithm that can detect adversary nodes. Some unknown adversaries are assumed
to be injecting false data at their respective nodes in the graph. The number
and location of adversaries are not known in advance and the goal is to recover
the graph signal in the presence of measurement noise and False Data Injection
(FDI) caused by the adversaries. Consequently, the proposed algorithm would be
a perfect candidate to solve this challenging problem. Moreover, due to the
presence of malicious nodes, the proposed method serves as a secure GSR
algorithm. For adversary detection, a statistical measure based on differential
smoothness is used. Specifically, the difference between the current observed
smoothness and the average smoothness excluding the corresponding node. This
genuine statistical approach leads to an effective and low-complexity adversary
detector. In addition, following malicious node detection, the GSR is performed
using a variant of smoothness maximization, which is solved efficiently as a
fractional optimization problem using a Dinkelbach's algorithm. Analysis of the
detector, which determines the optimum threshold of the detector is also
presented. Simulation results show a significant improvement of the proposed
method in signal recovery compared to the median GSR algorithm and other
competing methods.

</details>


### [8] [Age of Information Aided Intelligent Grant-Free Massive Access for Heterogeneous mMTC Traffic](https://arxiv.org/abs/2509.14503)
*Zhongwen Sun,Wei Chen,Yuxuan Sun,Bo Ai*

Main category: eess.SP

TL;DR: 论文研究了6G时代下IoT设备的非正交无授权随机接入（GF-RA）场景，针对两种不同类型的流量（事件触发和状态更新），提出了一种基于年龄的自动编码器（A-PIAAE）来优化信息时效性和检测成功率。


<details>
  <summary>Details</summary>
Motivation: 现有GF-RA研究主要关注用户检测和数据恢复的准确性，而忽略了流量异构性。本文旨在同时实现事件触发设备的高检测成功率和状态更新设备的高信息时效性。

Method: 分析了基于年龄的随机接入方案，优化了接入参数以最小化MDs的平均信息年龄（AoI），并设计了一个基于年龄的先验信息辅助自动编码器（A-PIAAE）来联合检测活动设备。

Result: 实验表明，提出的A-PIAAE能够有效减少MDs的平均AoI并提高ADs的检测成功率。理论分析证明了其在收敛性能上的优势。

Conclusion: 论文提出的方法在解决异构流量问题中表现出色，为6G时代IoT设备的GF-RA提供了新的优化方向。

Abstract: With the arrival of 6G, the Internet of Things (IoT) traffic is becoming more
and more complex and diverse. To meet the diverse service requirements of IoT
devices, massive machine-type communications (mMTC) becomes a typical scenario,
and more recently, grant-free random access (GF-RA) presents a promising
direction due to its low signaling overhead. However, existing GF-RA research
primarily focuses on improving the accuracy of user detection and data
recovery, without considering the heterogeneity of traffic. In this paper, we
investigate a non-orthogonal GF-RA scenario where two distinct types of traffic
coexist: event-triggered traffic with alarm devices (ADs), and status update
traffic with monitor devices (MDs). The goal is to simultaneously achieve high
detection success rates for ADs and high information timeliness for MDs. First,
we analyze the age-based random access scheme and optimize the access
parameters to minimize the average age of information (AoI) of MDs. Then, we
design an age-based prior information aided autoencoder (A-PIAAE) to jointly
detect active devices, together with learned pilots used in GF-RA to reduce
interference between non-orthogonal pilots. In the decoder, an Age-based
Learned Iterative Shrinkage Thresholding Algorithm (LISTA-AGE) utilizing the
AoI of MDs as the prior information is proposed to enhance active user
detection. Theoretical analysis is provided to demonstrate the proposed A-PIAAE
has better convergence performance. Experiments demonstrate the advantage of
the proposed method in reducing the average AoI of MDs and improving the
successful detection rate of ADs.

</details>


### [9] [Radiolunadiff: Estimation of wireless network signal strength in lunar terrain](https://arxiv.org/abs/2509.14559)
*Paolo Torrado,Anders Pearson,Jason Klein,Alexander Moscibroda,Joshua Smith*

Main category: eess.SP

TL;DR: 提出了一种基于物理信息的深度学习架构，用于预测月球地形上的无线电地图，结合了物理地形生成器和射线追踪引擎，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地预测月球地形上的无线电传播效应，提出了一种结合物理模型与深度学习的新方法。

Method: 使用基于物理的月球地形生成器和射线追踪引擎创建高保真数据集，并引入了包含两个标准UNet和扩散网络的三联体UNet架构。

Result: 实验表明，该方法在多种指标上优于现有的深度学习方法。

Conclusion: 该方法能够有效建模复杂传播效应，为月球无线电地图预测提供了新思路。

Abstract: In this paper, we propose a novel physics-informed deep learning architecture
for predicting radio maps over lunar terrain. Our approach integrates a
physics-based lunar terrain generator, which produces realistic topography
informed by publicly available NASA data, with a ray-tracing engine to create a
high-fidelity dataset of radio propagation scenarios. Building on this dataset,
we introduce a triplet-UNet architecture, consisting of two standard UNets and
a diffusion network, to model complex propagation effects. Experimental results
demonstrate that our method outperforms existing deep learning approaches on
our terrain dataset across various metrics.

</details>


### [10] [Task-Oriented Learning for Automatic EEG Denoising](https://arxiv.org/abs/2509.14665)
*Tian-Yu Xiang,Zheng Lei,Xiao-Hu Zhou,Xiao-Liang Xie,Shi-Qi Liu,Mei-Jiang Gui,Hong-Yun Ou,Xin-Zheng Huang,Xin-Yi Fu,Zeng-Guang Hou*

Main category: eess.SP

TL;DR: 该论文提出了一种基于任务导向学习的自动EEG去噪框架，无需干净参考信号，通过任务标签优化去噪过程，实验证明其在任务性能和信号质量上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统EEG去噪方法依赖人工干预或干净参考信号，限制了自动化和广泛应用。该研究旨在开发一种仅需任务标签的自适应去噪框架。

Method: 先利用盲源分离技术分解EEG信号，再通过学习选择器为各分量分配保留概率，通过代理任务模型的损失优化选择器。

Result: 实验在多种噪声条件下显示，任务准确率提升2.56%，信噪比提高0.82 dB，且框架算法无关，适用于多种分解技术和网络结构。

Conclusion: 该任务导向学习框架为EEG去噪提供了实用解决方案，对神经科学研究和EEG交互系统具有潜在应用价值。

Abstract: Electroencephalography (EEG) denoising methods typically depend on manual
intervention or clean reference signals. This work introduces a task-oriented
learning framework for automatic EEG denoising that uses only task labels
without clean reference signals. EEG recordings are first decomposed into
components based on blind source separation (BSS) techniques. Then, a
learning-based selector assigns a retention probability to each component, and
the denoised signal is reconstructed as a probability-weighted combination. A
downstream proxy-task model evaluates the reconstructed signal, with its task
loss supervising the selector in a collaborative optimization scheme that
relies solely on task labels, eliminating the need for clean EEG references.
Experiments on three datasets spanning two paradigms and multiple noise
conditions show consistent gains in both task performance (accuracy:
$2.56\%\uparrow$) and standard signal-quality metrics (signal-to-noise-ratio:
$0.82$\,dB\,$\uparrow$). Further analyses demonstrate that the task-oriented
learning framework is algorithm-agnostic, as it accommodates diverse
decomposition techniques and network backbones for both the selector and the
proxy model. These promising results indicate that the proposed task-oriented
learning framework is a practical EEG denoising solution with potential
implications for neuroscience research and EEG-based interaction systems.

</details>


### [11] [Mitigating the Impact of Location Uncertainty on Radio Map-Based Predictive Rate Selection via Noisy-Input Gaussian Process](https://arxiv.org/abs/2509.14710)
*Koya Sato*

Main category: eess.SP

TL;DR: 本文提出了一种基于高斯过程（GP）的无线电地图构建的预测速率选择框架，该框架对位置不确定性具有鲁棒性。



<details>
  <summary>Details</summary>
Motivation: 6G网络中，无线电地图是提高通信效率的有力工具，但现有研究通常假设在信道感知中获得的位置信息是完美的（无噪声），而实际上位置信息存在误差，这影响了系统的可靠性。


Method: 作者引入了噪声输入GP（NIGP），通过泰勒近似处理位置噪声，将其视为额外的输出噪声。


Result: 数值结果表明，与纯GP相比，NIGP设计的传输速率选择更可靠，且吞吐量高于基于路径损耗的速率选择。


Conclusion: 本文的NIGP框架有效解决了位置不确定性对无线电地图系统的影响，为6G网络的通信优化提供了可靠方案。

Abstract: This paper proposes a predictive rate-selection framework based on Gaussian
process (GP)-based radio map construction that is robust to location
uncertainty. Radio maps are a promising tool for improving communication
efficiency in 6G networks. Although they enable the design of location-based
maximum transmission rates by exploiting statistical channel information,
existing discussions often assume perfect (i.e., noiseless) location
information during channel sensing. Since such information must be obtained
from positioning systems such as global navigation satellite systems, it
inevitably involves positioning errors; this location uncertainty can degrade
the reliability of radio map-based wireless systems. To mitigate this issue, we
introduce the noisy-input GP (NIGP), which treats location noise as additional
output noise by applying a Taylor approximation of the function of interest.
Numerical results demonstrate that the proposed NIGP-based design achieves more
reliable transmission-rate selection than pure GP and yields higher throughput
than path loss-based rate selection.

</details>


### [12] [LLM4MG: Adapting Large Language Model for Multipath Generation via Synesthesia of Machines](https://arxiv.org/abs/2509.14711)
*Ziwei Huang,Shiliang Lu,Lu Bai,Xuesong Cai,Xiang Cheng*

Main category: eess.SP

TL;DR: 该论文基于机器联觉（SoM）首次将大型语言模型（LLM）应用于多路径生成（LLM4MG）。通过构建多模态感知-通信数据集SynthSoM-V2I，结合LLaMA模型和参数高效微调技术，提出了一种高效的多路径生成方法，性能优于传统深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决6G车联网（V2I）场景中多路径生成问题，利用多模态数据（如毫米波雷达、RGB-D图像和LiDAR点云）实现高精度的多路径预测。

Method: 方法包括构建SynthSoM-V2I数据集，利用LLaMA模型的语义空间，通过特征提取与融合网络对齐多模态特征，并使用低秩适应（LoRA）和传播感知提示工程实现高效微调。

Result: 实验结果表明，LLM4MG在线/非视距分类（准确率92.76%）、多路径功率/延迟生成（NMSE为0.099/0.032）以及跨场景泛化方面优于传统方法。

Conclusion: 结论表明，LLM4MG在真实场景中具有实用价值，且高精度多路径生成对系统设计至关重要。

Abstract: Based on Synesthesia of Machines (SoM), a large language model (LLM) is
adapted for multipath generation (LLM4MG) for the first time. Considering a
typical sixth-generation (6G) vehicle-to-infrastructure (V2I) scenario, a new
multi-modal sensing-communication dataset is constructed, named SynthSoM-V2I,
including channel multipath information, millimeter wave (mmWave) radar sensory
data, RGB-D images, and light detection and ranging (LiDAR) point clouds. Based
on the SynthSoM-V2I dataset, the proposed LLM4MG leverages Large Language Model
Meta AI (LLaMA) 3.2 for multipath generation via multi-modal sensory data. The
proposed LLM4MG aligns the multi-modal feature space with the LLaMA semantic
space through feature extraction and fusion networks. To further achieve
general knowledge transfer from the pre-trained LLaMA for multipath generation
via multi-modal sensory data, the low-rank adaptation (LoRA)
parameter-efficient fine-tuning and propagation-aware prompt engineering are
exploited. Simulation results demonstrate that the proposed LLM4MG outperforms
conventional deep learning-based methods in terms of line-of-sight
(LoS)/non-LoS (NLoS) classification with accuracy of 92.76%, multipath
power/delay generation precision with normalized mean square error (NMSE) of
0.099/0.032, and cross-vehicular traffic density (VTD), cross-band, and
cross-scenario generalization. The utility of the proposed LLM4MG is validated
by real-world generalization. The necessity of high-precision multipath
generation for system design is also demonstrated by channel capacity
comparison.

</details>


### [13] [Efficient Solutions for Mitigating Initialization Bias in Unsupervised Self-Adaptive Auditory Attention Decoding](https://arxiv.org/abs/2509.14764)
*Yuanyuan Yao,Simon Geirnaert,Tinne Tuytelaars,Alexander Bertrand*

Main category: eess.SP

TL;DR: 论文提出三种计算效率高的无监督自适应听觉注意解码方法，解决了现有方法的初始化偏差和计算复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督自适应听觉注意解码方法存在初始化偏差和高计算复杂度的问题，限制了其实际应用。

Method: 提出了三种计算效率高的替代方法，通过降低和固定计算成本来优化性能。

Result: 新方法在性能上与现有方法相当，同时显著降低了计算复杂度。

Conclusion: 这些方法为无监督听觉注意解码提供了更实用的解决方案，适合实际应用场景。

Abstract: Decoding the attended speaker in a multi-speaker environment from
electroencephalography (EEG) has attracted growing interest in recent years,
with neuro-steered hearing devices as a driver application. Current approaches
typically rely on ground-truth labels of the attended speaker during training,
necessitating calibration sessions for each user and each EEG set-up to achieve
optimal performance. While unsupervised self-adaptive auditory attention
decoding (AAD) for stimulus reconstruction has been developed to eliminate the
need for labeled data, it suffers from an initialization bias that can
compromise performance. Although an unbiased variant has been proposed to
address this limitation, it introduces substantial computational complexity
that scales with data size. This paper presents three computationally efficient
alternatives that achieve comparable performance, but with a significantly
lower and constant computational cost. The code for the proposed algorithms is
available at https://github.com/YYao-42/Unsupervised_AAD.

</details>


### [14] [Comparative Performance Analysis of Different Hybrid NOMA Schemes](https://arxiv.org/abs/2509.14809)
*Ning Wang,Chenyu Zhang,Yanshi Sun,Minghui Min,Shiyin Li*

Main category: eess.SP

TL;DR: 本文分析了三种混合非正交多址（H-NOMA）方案在随机信道增益排序下的性能，并推导了理论表达式和渐近分析，为下一代无线系统中H-NOMA的部署提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 现有的H-NOMA分析通常假设固定信道增益排序，忽略了信道系数随机的特性。本文旨在填补这一研究空白。

Method: 比较了三种H-NOMA方案（FSIC、HSIC-NPA、HSIC-PA）的性能，并推导了它们在随机信道条件下的性能表现。

Result: 理论分析和仿真结果表明，H-NOMA在不同信噪比（SNR）场景下均优于传统OMA。

Conclusion: H-NOMA在随机信道条件下具有显著优势，为未来无线网络的部署提供了理论依据。

Abstract: Hybrid non-orthogonal multiple access (H-NOMA), which combines the advantages
of pure NOMA and conventional OMA organically, has emerged as a highly
promising multiple access technology for future wireless networks. Recent
studies have proposed various H-NOMA systems by employing different successive
interference cancellation (SIC) methods for the NOMA transmission phase.
However, existing analyses typically assume a fixed channel gain order between
paired users, despite the fact that channel coefficients follow random
distribution, leading to their magnitude relationships inherently stochastic
and time varying. This paper analyzes the performance of three H-NOMA schemes
under stochastic channel gain ordering: a) fixed order SIC (FSIC) aided H-NOMA
scheme; b) hybrid SIC with non-power adaptation (HSIC-NPA) aided H-NOMA scheme;
c) hybrid SIC with power adaptation (HSIC-PA) aided H-NOMA scheme. Theoretical
analysis derives closed-form expressions for the probability that H-NOMA
schemes underperform conventional OMA. Asymptotic results in the high
signal-to-noise ratio (SNR) regime are also developed. Simulation results
validate our analysis and demonstrate the performance of H-NOMA schemes across
different SNR scenarios, providing a theoretical foundation for the deployment
of H-NOMA in next-generation wireless systems.

</details>


### [15] [Sampling Method for Generalized Graph Signals with Pre-selected Vertices via DC Optimization](https://arxiv.org/abs/2509.14836)
*Keitaro Yamashita,Kazuki Naganuma,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出了一种针对图信号的顶点灵活采样方法，通过优化设计采样算子，提升恢复精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法结合先验知识（如必须或禁止采样的顶点），因此提出新方法解决这一限制。

Method: 将算子设计转化为非凸优化问题，并通过DC优化和核范数处理约束，开发了收敛求解器。

Result: 实验表明，该方法在不同图信号模型（包括真实数据）中恢复精度优于现有方法。

Conclusion: 新方法有效解决了顶点采样中的先验知识整合问题，显著提升了信号恢复性能。

Abstract: This paper proposes a method for vertex-wise flexible sampling of a broad
class of graph signals, designed to attain the best possible recovery based on
the generalized sampling theory. This is achieved by designing a sampling
operator by an optimization problem, which is inherently non-convex, as the
best possible recovery imposes a rank constraint. An existing method for
vertex-wise flexible sampling is able to control the number of active vertices
but cannot incorporate prior knowledge of mandatory or forbidden vertices. To
address these challenges, we formulate the operator design as a problem that
handles a constraint of the number of active vertices and prior knowledge on
specific vertices for sampling, mandatory inclusion or exclusion. We
transformed this constrained problem into a difference-of-convex (DC)
optimization problem by using the nuclear norm and a DC penalty for vertex
selection. To solve this, we develop a convergent solver based on the general
double-proximal gradient DC algorithm. The effectiveness of our method is
demonstrated through experiments on various graph signal models, including
real-world data, showing superior performance in the recovery accuracy by
comparing to existing methods.

</details>


### [16] [Hybrid Table-Assisted and RL-Based Dynamic Routing for NGSO Satellite Networks](https://arxiv.org/abs/2509.14909)
*Flor Ortiz,Eva Lagunas*

Main category: eess.SP

TL;DR: 摘要提出了NGSO星座中的动态路由混合策略，结合预计算路由表和DQL备用机制，以提高性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是针对完全基于强化学习的路由方案在拓扑动态变化时的高复杂性、长收敛时间和大流量下性能不稳定的问题。

Method: 方法是在正常情况下使用确定性表查找，仅在链路不可用或拥塞时选择性激活DQL代理。

Result: 结果表明，混合策略在大型NGSO网络中表现出更高的包交付率、更低端到端延迟、更短平均跳数和更高吞吐量。

Conclusion: 结论是混合路由是一种可扩展且稳健的解决方案，适用于延迟敏感的卫星宽带服务。

Abstract: This letter investigates dynamic routing in Next-Generation Satellite Orbit
(NGSO) constellations and proposes a hybrid strategy that combines precomputed
routing tables with a Deep Q-Learning (DQL) fallback mechanism. While fully
RL-based schemes offer adaptability to topology dynamics, they often suffer
from high complexity, long convergence times, and unstable performance under
heavy traffic. In contrast, the proposed framework exploits deterministic table
lookups under nominal conditions and selectively activates the DQL agent only
when links become unavailable or congested. Simulation results in large-scale
NGSO networks show that the hybrid approach consistently achieves higher packet
delivery ratio, lower end-to-end delay, shorter average hop count, and improved
throughput compared to a pure RL baseline. These findings highlight the
effectiveness of hybrid routing as a scalable and resilient solution for
delay-sensitive satellite broadband services

</details>


### [17] [Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators](https://arxiv.org/abs/2509.15069)
*Deijany Rodriguez Linares,Oksana Moryakova,Håkan Johansson*

Main category: eess.SP

TL;DR: 论文提出了一种新的高效计算时间索引加权和的方法，通过级联累加器减少计算和存储需求。


<details>
  <summary>Details</summary>
Motivation: 传统方法在大数据量时计算和存储成本过高，需要通过创新方法解决。

Method: 利用累加器特性消除数据块存储需求，将乘法成本减少到K+1次常数乘法。

Result: 方法实现了高效的实时计算，适用于逐样本处理系统。

Conclusion: 该方法显著提升了计算效率，适合高需求场景。

Abstract: This letter presents a novel approach for \mbox{efficiently} computing
time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$
using cascaded accumulators. Traditional direct computation requires
$K{\times}N$ general multiplications, which become prohibitive for large $N$,
while alternative strategies based on lookup tables or signal reversal require
storing entire data blocks. By exploiting accumulator properties, the proposed
method eliminates the need for such storage and reduces the multiplicative cost
to only $K{+}1$ constant multiplications, enabling efficient real-time
implementation. The approach is particularly useful when such sums need to be
efficiently computed in sample-by-sample processing systems.

</details>


### [18] [Doppler Radiance Field-Guided Antenna Selection for Improved Generalization in Multi-Antenna Wi-Fi-based Human Activity Recognition](https://arxiv.org/abs/2509.15129)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 本文提出了一种基于Wi-Fi信号的多天线接入点（AP）框架，通过Doppler Radiance Fields（DoRFs）减少噪声并选择信息量最大的天线，显著提升了基于Wi-Fi的人类活动识别（HAR）的泛化能力。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi信号的CSI受异步AP时钟和环境噪声影响，限制了HAR性能，因此需要一种新的方法来抑制噪声并提升信号质量。

Method: 提出了一种基于DoRF的多天线AP框架，通过分析DoRF拟合误差来抑制噪声并选择最优天线。

Result: 在小规模手势识别数据集上，该方法显著提升了HAR的泛化能力。

Conclusion: 该方法为Wi-Fi信号的稳健实际应用提供了新思路。

Abstract: With the IEEE 802.11bf Task Group introducing amendments to the WLAN standard
for advanced sensing, interest in using Wi-Fi Channel State Information (CSI)
for remote sensing has surged. Recent findings indicate that learning a unified
three-dimensional motion representation through Doppler Radiance Fields (DoRFs)
derived from CSI significantly improves the generalization capabilities of
Wi-Fi-based human activity recognition (HAR). Despite this progress, CSI
signals remain affected by asynchronous access point (AP) clocks and additive
noise from environmental and hardware sources. Consequently, even with existing
preprocessing techniques, both the CSI data and Doppler velocity projections
used in DoRFs are still susceptible to noise and outliers, limiting HAR
performance. To address this challenge, we propose a novel framework for
multi-antenna APs to suppress noise and identify the most informative antennas
based on DoRF fitting errors, which capture inconsistencies among Doppler
velocity projections. Experimental results on a challenging small-scale hand
gesture recognition dataset demonstrate that the proposed DoRF-guided
Wi-Fi-based HAR approach significantly improves generalization capability,
paving the way for robust real-world sensing deployments.

</details>


### [19] [A Unified Distributed Algorithm for Hybrid Near-Far Field Activity Detection in Cell-Free Massive MIMO](https://arxiv.org/abs/2509.15162)
*Jingreng Lei,Yang Li,Ziyue Wang,Qingfeng Lin,Ya-Feng Liu,Yik-Chung Wu*

Main category: eess.SP

TL;DR: 本文提出了一种基于协方差的混合近远场信道活动检测方法，理论证明近场信道比例提高能增强检测性能，并提出了一种分布式算法，显著降低计算复杂性和通信开销。


<details>
  <summary>Details</summary>
Motivation: 随着接入点天线数量的增加，传统远场传播假设不适用，需解决混合近远场信道的活动检测问题。

Method: 建立基于协方差的混合近远场信道统计模型，提出分布式检测算法，各接入点执行本地检测并仅交换结果到中央处理单元。

Result: 仿真结果验证了理论分析，表明所提方法在性能和效率上优于现有方法。

Conclusion: 该算法统一适用于单细胞或无细胞系统，且能处理近场或远场设备的混合情况。

Abstract: A great amount of endeavor has recently been devoted to activity detection
for massive machine-type communications in cell-free multiple-input
multiple-output (MIMO) systems. However, as the number of antennas at the
access points (APs) increases, the Rayleigh distance that separates the
near-field and far-field regions also expands, rendering the conventional
assumption of far-field propagation alone impractical. To address this
challenge, this paper establishes a covariance-based formulation that can
effectively capture the statistical property of hybrid near-far field channels.
Based on this formulation, we theoretically reveal that increasing the
proportion of near-field channels enhances the detection performance.
Furthermore, we propose a distributed algorithm, where each AP performs local
activity detection and only exchanges the detection results to the central
processing unit, thus significantly reducing the computational complexity and
the communication overhead. Not only with convergence guarantee, the proposed
algorithm is unified in the sense that it can handle single-cell or cell-free
systems with either near-field or far-field devices as special cases.
Simulation results validate the theoretical analyses and demonstrate the
superior performance of the proposed approach compared with existing methods.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [AEGIS: Automated Error Generation and Identification for Multi-Agent Systems](https://arxiv.org/abs/2509.14295)
*Fanqi Kong,Ruijie Zhang,Huaxiao Yin,Guibin Zhang,Xiaofei Zhang,Ziang Chen,Zhaowei Zhang,Xiaoyuan Zhang,Song-Chun Zhu,Xue Feng*

Main category: cs.RO

TL;DR: 论文介绍了一个名为AEGIS的框架，用于自动生成和识别多智能体系统中的错误，以解决缺乏大规模多样化标注数据集的问题，并通过实验验证其在错误识别任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统（MAS）的自主性和复杂性增加，理解其错误模式对确保其可靠性和安全性至关重要，但目前缺乏大规模且标注精确的数据集限制了相关研究。

Method: AEGIS框架通过系统性地在有成功结果的轨迹中注入可控且可追踪的错误，生成丰富的真实失败数据集。这利用了基于LLM的上下文感知自适应操纵器，执行复杂的攻击（如提示注入和响应破坏）来诱发特定错误。

Result: 实验表明，使用AEGIS数据训练的模型在监督微调、强化学习和对比学习三种学习范式下均显著提升性能，部分微调模型甚至能与更大规模的专有系统竞争或超越。

Conclusion: AEGIS框架是开发更鲁棒和可解释多智能体系统的重要资源，其自动化数据生成方法为解决数据瓶颈问题提供了有效途径。

Abstract: As Multi-Agent Systems (MAS) become increasingly autonomous and complex,
understanding their error modes is critical for ensuring their reliability and
safety. However, research in this area has been severely hampered by the lack
of large-scale, diverse datasets with precise, ground-truth error labels. To
address this bottleneck, we introduce \textbf{AEGIS}, a novel framework for
\textbf{A}utomated \textbf{E}rror \textbf{G}eneration and
\textbf{I}dentification for Multi-Agent \textbf{S}ystems. By systematically
injecting controllable and traceable errors into initially successful
trajectories, we create a rich dataset of realistic failures. This is achieved
using a context-aware, LLM-based adaptive manipulator that performs
sophisticated attacks like prompt injection and response corruption to induce
specific, predefined error modes. We demonstrate the value of our dataset by
exploring three distinct learning paradigms for the error identification task:
Supervised Fine-Tuning, Reinforcement Learning, and Contrastive Learning. Our
comprehensive experiments show that models trained on AEGIS data achieve
substantial improvements across all three learning paradigms. Notably, several
of our fine-tuned models demonstrate performance competitive with or superior
to proprietary systems an order of magnitude larger, validating our automated
data generation framework as a crucial resource for developing more robust and
interpretable multi-agent systems. Our project website is available at
https://kfq20.github.io/AEGIS-Website.

</details>


### [21] [FlowDrive: Energy Flow Field for End-to-End Autonomous Driving](https://arxiv.org/abs/2509.14303)
*Hao Jiang,Zhipeng Zhang,Yu Gao,Zhigang Sun,Yiru Wang,Yuwen Heng,Shuo Wang,Jinhao Chai,Zhuo Chen,Hao Zhao,Hao Sun,Xi Zhang,Anqing Jiang,Chuan Hu*

Main category: cs.RO

TL;DR: FlowDrive提出了一种新的BEV框架，通过显式建模风险潜在场和车道吸引场，提升自动驾驶运动规划的安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶框架缺乏对风险和语义先验的显式建模，导致规划不够安全和可解释。

Method: FlowDrive引入能量基流场（如风险潜在场和车道吸引场），并结合条件扩散规划器解耦运动意图预测和轨迹去噪。

Result: 在NAVSIM v2基准测试中，FlowDrive以86.3的EPDMS得分取得了最优性能。

Conclusion: FlowDrive通过显式建模流场和条件扩散规划器，显著提升了运动规划的安全性和多样性。

Abstract: Recent advances in end-to-end autonomous driving leverage multi-view images
to construct BEV representations for motion planning. In motion planning,
autonomous vehicles need considering both hard constraints imposed by
geometrically occupied obstacles (e.g., vehicles, pedestrians) and soft,
rule-based semantics with no explicit geometry (e.g., lane boundaries, traffic
priors). However, existing end-to-end frameworks typically rely on BEV features
learned in an implicit manner, lacking explicit modeling of risk and guidance
priors for safe and interpretable planning. To address this, we propose
FlowDrive, a novel framework that introduces physically interpretable
energy-based flow fields-including risk potential and lane attraction fields-to
encode semantic priors and safety cues into the BEV space. These flow-aware
features enable adaptive refinement of anchor trajectories and serve as
interpretable guidance for trajectory generation. Moreover, FlowDrive decouples
motion intent prediction from trajectory denoising via a conditional diffusion
planner with feature-level gating, alleviating task interference and enhancing
multimodal diversity. Experiments on the NAVSIM v2 benchmark demonstrate that
FlowDrive achieves state-of-the-art performance with an EPDMS of 86.3,
surpassing prior baselines in both safety and planning quality. The project is
available at https://astrixdrive.github.io/FlowDrive.github.io/.

</details>


### [22] [Multi-Quadruped Cooperative Object Transport: Learning Decentralized Pinch-Lift-Move](https://arxiv.org/abs/2509.14342)
*Bikram Pandit,Aayam Kumar Shrestha,Alan Fern*

Main category: cs.RO

TL;DR: 研究了多机器人协同搬运无抓取性物体的任务，通过接触力和隐含同步实现无通信协作。


<details>
  <summary>Details</summary>
Motivation: 解决独立机器人在无通信和集中控制下，仅通过接触力协同搬运物体的挑战性问题。

Method: 采用分层策略架构，分离基座运动与手臂控制，并通过星座奖励公式统一位置和方向跟踪，模拟刚性连接行为。

Result: 方法支持任意规模的机器人团队，无需重新训练，成功在2-10台机器人上验证了多样物体几何和质量的搬运。

Conclusion: 通过奖励设计和训练课程，实现了机器人在无刚性连接条件下的高效协同搬运，展示了从仿真到真实环境的迁移潜力。

Abstract: We study decentralized cooperative transport using teams of N-quadruped
robots with arm that must pinch, lift, and move ungraspable objects through
physical contact alone. Unlike prior work that relies on rigid mechanical
coupling between robots and objects, we address the more challenging setting
where mechanically independent robots must coordinate through contact forces
alone without any communication or centralized control. To this end, we employ
a hierarchical policy architecture that separates base locomotion from arm
control, and propose a constellation reward formulation that unifies position
and orientation tracking to enforce rigid contact behavior. The key insight is
encouraging robots to behave as if rigidly connected to the object through
careful reward design and training curriculum rather than explicit mechanical
constraints. Our approach enables coordination through shared policy parameters
and implicit synchronization cues - scaling to arbitrary team sizes without
retraining. We show extensive simulation experiments to demonstrate robust
transport across 2-10 robots on diverse object geometries and masses, along
with sim2real transfer results on lightweight objects.

</details>


### [23] [LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation](https://arxiv.org/abs/2509.14349)
*Zhengyang Kris Weng,Matthew L. Elwin,Han Liu*

Main category: cs.RO

TL;DR: LeVR是一个专为解决机器人模仿学习中的两个关键问题而设计的模块化软件框架，提供VR远程操作并集成LeRobot模仿学习框架。


<details>
  <summary>Details</summary>
Motivation: 解决现有系统中机器人臂和灵巧手数据收集的局限性，并简化示范数据的收集流程。

Method: 通过LeVR框架提供VR远程操作，与LeRobot模仿学习框架集成，并实现端到端工作流。

Result: 成功收集100个专家示范数据集，并用于微调视觉运动策略。

Conclusion: LeVR及其开放资源将加速机器人模仿学习的研究。

Abstract: We introduce LeVR, a modular software framework designed to bridge two
critical gaps in robotic imitation learning. First, it provides robust and
intuitive virtual reality (VR) teleoperation for data collection using robot
arms paired with dexterous hands, addressing a common limitation in existing
systems. Second, it natively integrates with the powerful LeRobot imitation
learning (IL) framework, enabling the use of VR-based teleoperation data and
streamlining the demonstration collection process. To demonstrate LeVR, we
release LeFranX, an open-source implementation for the Franka FER arm and
RobotEra XHand, two widely used research platforms. LeFranX delivers a
seamless, end-to-end workflow from data collection to real-world policy
deployment. We validate our system by collecting a public dataset of 100 expert
demonstrations and use it to successfully fine-tune state-of-the-art visuomotor
policies. We provide our open-source framework, implementation, and dataset to
accelerate IL research for the robotics community.

</details>


### [24] [DreamControl: Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion](https://arxiv.org/abs/2509.14353)
*Dvij Kalaria,Sudarshan S Harithas,Pushkal Katara,Sangkyung Kwak,Sarthak Bhagat,Shankar Sastry,Srinath Sridhar,Sai Vemprala,Ashish Kapoor,Jonathan Chung-Kuan Huang*

Main category: cs.RO

TL;DR: DreamControl是一个结合扩散模型和强化学习的新方法，用于学习人形机器人的全身技能。它通过人类运动数据的扩散先验指导RL策略，提高了任务完成能力和动作自然性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决人形机器人在复杂任务中同时控制上下肢并交互物体的挑战性需求。

Method: 采用了扩散模型和强化学习的结合方法，利用人类运动数据的扩散先验指导RL策略。

Result: 在Unitree G1机器人上验证了方法的有效性，能够完成直接RL难以实现的任务，并生成自然的动作。

Conclusion: DreamControl通过结合扩散先验和RL，实现了高效且自然的机器人技能学习，具有从仿真到现实的迁移潜力。

Abstract: We introduce DreamControl, a novel methodology for learning autonomous
whole-body humanoid skills. DreamControl leverages the strengths of diffusion
models and Reinforcement Learning (RL): our core innovation is the use of a
diffusion prior trained on human motion data, which subsequently guides an RL
policy in simulation to complete specific tasks of interest (e.g., opening a
drawer or picking up an object). We demonstrate that this human motion-informed
prior allows RL to discover solutions unattainable by direct RL, and that
diffusion models inherently promote natural looking motions, aiding in
sim-to-real transfer. We validate DreamControl's effectiveness on a Unitree G1
robot across a diverse set of challenging tasks involving simultaneous lower
and upper body control and object interaction.

</details>


### [25] [CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks](https://arxiv.org/abs/2509.14380)
*Seoyeon Choi,Kanghyun Ryu,Jonghoon Ock,Negar Mehr*

Main category: cs.RO

TL;DR: 论文提出了CRAFT框架，利用基础模型的分步教学能力解决多智能体强化学习中复杂协调任务的挑战。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在机器人领域的应用面临高维度连续动作空间和复杂奖励设计的挑战，人类通过分阶段学习复杂协调行为的启发，作者提出了CRAFT框架。

Method: CRAFT利用大型语言模型（LLMs）的规划能力，将长期协调任务分解为子任务序列，并通过视觉语言模型（VLM）指导奖励优化循环。

Result: CRAFT在多四足机器人导航和双边操控任务中展示了学习复杂协调行为的能力，并在真实硬件实验中验证了导航策略。

Conclusion: CRAFT通过结合基础模型的推理能力，有效解决了多智能体协调的复杂性问题，为机器人强化学习提供了新方法。

Abstract: Multi-Agent Reinforcement Learning (MARL) provides a powerful framework for
learning coordination in multi-agent systems. However, applying MARL to
robotics still remains challenging due to high-dimensional continuous joint
action spaces, complex reward design, and non-stationary transitions inherent
to decentralized settings. On the other hand, humans learn complex coordination
through staged curricula, where long-horizon behaviors are progressively built
upon simpler skills. Motivated by this, we propose CRAFT: Coaching
Reinforcement learning Autonomously using Foundation models for multi-robot
coordination Tasks, a framework that leverages the reasoning capabilities of
foundation models to act as a "coach" for multi-robot coordination. CRAFT
automatically decomposes long-horizon coordination tasks into sequences of
subtasks using the planning capability of Large Language Models (LLMs). In what
follows, CRAFT trains each subtask using reward functions generated by LLM, and
refines them through a Vision Language Model (VLM)-guided reward-refinement
loop. We evaluate CRAFT on multi-quadruped navigation and bimanual manipulation
tasks, demonstrating its capability to learn complex coordination behaviors. In
addition, we validate the multi-quadruped navigation policy in real hardware
experiments.

</details>


### [26] [RLBind: Adversarial-Invariant Cross-Modal Alignment for Unified Robust Embeddings](https://arxiv.org/abs/2509.14383)
*Yuhong Lu*

Main category: cs.RO

TL;DR: RLBind是一个新型的双阶段对抗性不变跨模态对齐框架，旨在提升多模态编码器的鲁棒性和安全性，适用于机器人在导航和操作等任务中的多传感器感知。


<details>
  <summary>Details</summary>
Motivation: 多模态编码器在机器人感知和决策中非常重要，但其视觉分支容易受到对抗性和自然干扰的影响。现有的方法未能充分利用跨模态对应关系，导致性能提升有限且可能影响零样本迁移能力。

Method: RLBind分为两个阶段：第一阶段通过无监督微调视觉编码器以增强其抗干扰能力；第二阶段利用跨模态对应关系，最小化干净/对抗性特征与文本锚点之间的差异，并实现跨模态的类别分布对齐。

Result: 在图像、音频、热像和视频数据上的实验表明，RLBind在干净数据和对抗性环境下的性能均优于LanguageBind和标准微调基线。

Conclusion: RLBind通过提高鲁棒性而不牺牲泛化能力，为机器人在多传感器感知任务中提供了一条更安全的实践路径。

Abstract: Unified multi-modal encoders that bind vision, audio, and other sensors into
a shared embedding space are attractive building blocks for robot perception
and decision-making. However, on-robot deployment exposes the vision branch to
adversarial and natural corruptions, making robustness a prerequisite for
safety. Prior defenses typically align clean and adversarial features within
CLIP-style encoders and overlook broader cross-modal correspondence, yielding
modest gains and often degrading zero-shot transfer. We introduce RLBind, a
two-stage adversarial-invariant cross-modal alignment framework for robust
unified embeddings. Stage 1 performs unsupervised fine-tuning on
clean-adversarial pairs to harden the visual encoder. Stage 2 leverages
cross-modal correspondence by minimizing the discrepancy between
clean/adversarial features and a text anchor, while enforcing class-wise
distributional alignment across modalities. Extensive experiments on Image,
Audio, Thermal, and Video data show that RLBind consistently outperforms the
LanguageBind backbone and standard fine-tuning baselines in both clean accuracy
and norm-bounded adversarial robustness. By improving resilience without
sacrificing generalization, RLBind provides a practical path toward safer
multi-sensor perception stacks for embodied robots in navigation, manipulation,
and other autonomy settings.

</details>


### [27] [GestOS: Advanced Hand Gesture Interpretation via Large Language Models to control Any Type of Robot](https://arxiv.org/abs/2509.14412)
*Artem Lykov,Oleg Kobzarev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: GestOS是一个基于手势的操作系统，通过语义解析和动态任务分配控制多机器人团队，结合视觉感知和大语言模型实现智能交互。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统手势系统只能映射固定命令或单机器人动作的问题，GestOS意图实现语义化手势解析和多机器人动态协作，提升灵活性。

Method: 系统通过视觉感知将手势转换为结构化文本描述，利用大语言模型推断意图并生成机器人专用指令，再通过机器人选择模块实时匹配最适合的执行者。

Result: GestOS实现了无需用户明确指定目标或命令的上下文感知自适应控制，支持动态环境中与机器人系统的灵活协作。

Conclusion: GestOS通过将手势交互从识别提升至智能编排，为用户提供了高效、灵活且友好的多机器人协作方案。

Abstract: We present GestOS, a gesture-based operating system for high-level control of
heterogeneous robot teams. Unlike prior systems that map gestures to fixed
commands or single-agent actions, GestOS interprets hand gestures semantically
and dynamically distributes tasks across multiple robots based on their
capabilities, current state, and supported instruction sets. The system
combines lightweight visual perception with large language model (LLM)
reasoning: hand poses are converted into structured textual descriptions, which
the LLM uses to infer intent and generate robot-specific commands. A robot
selection module ensures that each gesture-triggered task is matched to the
most suitable agent in real time. This architecture enables context-aware,
adaptive control without requiring explicit user specification of targets or
commands. By advancing gesture interaction from recognition to intelligent
orchestration, GestOS supports scalable, flexible, and user-friendly
collaboration with robotic systems in dynamic environments.

</details>


### [28] [Perception-Integrated Safety Critical Control via Analytic Collision Cone Barrier Functions on 3D Gaussian Splatting](https://arxiv.org/abs/2509.14421)
*Dario Tscholl,Yashwanth Nakka,Brian Gunter*

Main category: cs.RO

TL;DR: 该论文提出了一种基于感知的安全过滤器，将3D高斯喷溅转换为碰撞锥，并嵌入CBF-QP框架中，实现了高效且连续的碰撞约束表示，显著提升了避障的平滑性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于距离的CBF方法反应滞后的问题，研究人员希望通过几何解析方法主动调整机器人的避障行为，从而在复杂环境中实现更平滑和安全的导航。

Method: 利用3D高斯喷溅的解析几何特性，将其转换为闭合形式的碰撞锥，并嵌入CBF-QP框架中，形成一种连续且高效的计算方法。

Result: 在大规模合成场景（17万个喷溅）中验证，该方法将规划时间减少3倍，显著降低轨迹抖动，同时保持安全性。

Conclusion: 该方法无需高阶CBF扩展，计算高效，适用于实时导航，尤其在空间机器人等极端环境中具有广泛应用潜力。

Abstract: We present a perception-driven safety filter that converts each 3D Gaussian
Splat (3DGS) into a closed-form forward collision cone, which in turn yields a
first-order control barrier function (CBF) embedded within a quadratic program
(QP). By exploiting the analytic geometry of splats, our formulation provides a
continuous, closed-form representation of collision constraints that is both
simple and computationally efficient. Unlike distance-based CBFs, which tend to
activate reactively only when an obstacle is already close, our collision-cone
CBF activates proactively, allowing the robot to adjust earlier and thereby
produce smoother and safer avoidance maneuvers at lower computational cost. We
validate the method on a large synthetic scene with approximately 170k splats,
where our filter reduces planning time by a factor of 3 and significantly
decreased trajectory jerk compared to a state-of-the-art 3DGS planner, while
maintaining the same level of safety. The approach is entirely analytic,
requires no high-order CBF extensions (HOCBFs), and generalizes naturally to
robots with physical extent through a principled Minkowski-sum inflation of the
splats. These properties make the method broadly applicable to real-time
navigation in cluttered, perception-derived extreme environments, including
space robotics and satellite systems.

</details>


### [29] [Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control](https://arxiv.org/abs/2509.14431)
*Keqin Wang,Tao Zhong,David Chang,Christine Allen-Blanchette*

Main category: cs.RO

TL;DR: LEGO框架通过图神经网络和规范化技术解决了多智能体强化学习中的训练不稳定性和泛化问题，实验证明其优于基线方法并具备鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在竞争性多智能体强化学习任务中，同时适应可能导致训练不稳定，现有方法在恶劣条件下表现不佳且难以泛化到不同规模的智能体群。

Method: LEGO框架结合图神经网络（捕捉置换等变性和泛化能力）、规范化技术（强制E(n)-等变性）和异构表示（编码角色特定的归纳偏差）。

Result: LEGO在合作与竞争性群智能任务中优于基线方法，实验显示其对团队规模变化和智能体故障具有鲁棒性。

Conclusion: LEGO为多智能体强化学习提供了有效的解决方案，显著提升了训练的稳定性和泛化能力。

Abstract: Multi-agent reinforcement learning (MARL) has emerged as a powerful paradigm
for coordinating swarms of agents in complex decision-making, yet major
challenges remain. In competitive settings such as pursuer-evader tasks,
simultaneous adaptation can destabilize training; non-kinetic countermeasures
often fail under adverse conditions; and policies trained in one configuration
rarely generalize to environments with a different number of agents. To address
these issues, we propose the Local-Canonicalization Equivariant Graph Neural
Networks (LEGO) framework, which integrates seamlessly with popular MARL
algorithms such as MAPPO. LEGO employs graph neural networks to capture
permutation equivariance and generalization to different agent numbers,
canonicalization to enforce E(n)-equivariance, and heterogeneous
representations to encode role-specific inductive biases. Experiments on
cooperative and competitive swarm benchmarks show that LEGO outperforms strong
baselines and improves generalization. In real-world experiments, LEGO
demonstrates robustness to varying team sizes and agent failure.

</details>


### [30] [Online Learning of Deceptive Policies under Intermittent Observation](https://arxiv.org/abs/2509.14453)
*Gokul Puthumanaillam,Ram Padmanabhan,Jose Fuentes,Nicole Cruz,Paulo Padrao,Ruben Hernandez,Hao Jiang,William Schafer,Leonardo Bobadilla,Melkior Ornik*

Main category: cs.RO

TL;DR: 论文研究了在监督控制环境中，自主系统通过利用'心智理论'（Theory of Mind）实现欺骗行为，即在追求私人目标的同时保持对监督者参考策略的合规性。通过在线强化学习，方法成功在硬件实验中实现了高回报与合规性。


<details>
  <summary>Details</summary>
Motivation: 动机源于真实监督环境中监督者的行为模式，研究如何在非连续监控条件下，利用心智理论实现自主系统的欺骗行为。

Method: 方法包括建模监督者的期望，并从中提取一个标量（预期偏差证据），通过在线强化学习结合KL正则化政策改进步骤，动态平衡自我利益与合规性。

Result: 在真实硬件实验中（如海洋和空中导航），方法能够在线运行，实现高回报和成功，同时保持监督者对痕迹证据的预期。

Conclusion: 论文表明，心智理论能够有效指导在线强化学习，实现自主系统在监督环境中的欺骗行为，且无需手工或启发式政策。

Abstract: In supervisory control settings, autonomous systems are not monitored
continuously. Instead, monitoring often occurs at sporadic intervals within
known bounds. We study the problem of deception, where an agent pursues a
private objective while remaining plausibly compliant with a supervisor's
reference policy when observations occur. Motivated by the behavior of real,
human supervisors, we situate the problem within Theory of Mind: the
representation of what an observer believes and expects to see. We show that
Theory of Mind can be repurposed to steer online reinforcement learning (RL)
toward such deceptive behavior. We model the supervisor's expectations and
distill from them a single, calibrated scalar -- the expected evidence of
deviation if an observation were to happen now. This scalar combines how unlike
the reference and current action distributions appear, with the agent's belief
that an observation is imminent. Injected as a state-dependent weight into a
KL-regularized policy improvement step within an online RL loop, this scalar
informs a closed-form update that smoothly trades off self-interest and
compliance, thus sidestepping hand-crafted or heuristic policies. In
real-world, real-time hardware experiments on marine (ASV) and aerial (UAV)
navigation, our ToM-guided RL runs online, achieves high return and success
with observed-trace evidence calibrated to the supervisor's expectations.

</details>


### [31] [Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring](https://arxiv.org/abs/2509.14460)
*Abhiroop Ajith,Constantinos Chamzas*

Main category: cs.RO

TL;DR: 论文提出了一种从视觉数据中自动发现抽象层次的方法，用于机器人重组任务，结合结构约束和视觉距离，实现高效的规划。


<details>
  <summary>Details</summary>
Motivation: 机器人领域中，人工设计的抽象层次限制了可扩展性和实际应用，直接从视觉数据中发现抽象层次成为关键挑战。

Method: 结合结构约束和注意力引导的视觉距离，提出了一种诱导离散图结构抽象的方法，适用于以图像为状态表示的重组任务。

Result: 在仿真环境中验证了方法的有效性，其发现的抽象层次优于现有方法，支持高效规划。

Conclusion: 该方法能够自主地从视觉数据中发现有意义的抽象，为机器人规划提供了新的可能性。

Abstract: Learning abstractions directly from data is a core challenge in robotics.
Humans naturally operate at an abstract level, reasoning over high-level
subgoals while delegating execution to low-level motor skills -- an ability
that enables efficient problem solving in complex environments. In robotics,
abstractions and hierarchical reasoning have long been central to planning, yet
they are typically hand-engineered, demanding significant human effort and
limiting scalability. Automating the discovery of useful abstractions directly
from visual data would make planning frameworks more scalable and more
applicable to real-world robotic domains. In this work, we focus on
rearrangement tasks where the state is represented with raw images, and propose
a method to induce discrete, graph-structured abstractions by combining
structural constraints with an attention-guided visual distance. Our approach
leverages the inherent bipartite structure of rearrangement problems,
integrating structural constraints and visual embeddings into a unified
framework. This enables the autonomous discovery of abstractions from vision
alone, which can subsequently support high-level planning. We evaluate our
method on two rearrangement tasks in simulation and show that it consistently
identifies meaningful abstractions that facilitate effective planning and
outperform existing approaches.

</details>


### [32] [Object Recognition and Force Estimation with the GelSight Baby Fin Ray](https://arxiv.org/abs/2509.14510)
*Sandra Q. Liu,Yuxiang Ma,Edward H. Adelson*

Main category: cs.RO

TL;DR: 该论文探讨了软体机器人手的触觉感知，通过机器学习和GelSight Baby Fin Ray技术，实现复杂的任务处理能力。


<details>
  <summary>Details</summary>
Motivation: 研究GelSight Baby Fin Ray在区分壳内坚果纹理、力与位置估计方面的潜力，以提升软体机器人对环境的理解与互动能力。

Method: 采用ResNet50、GoogLeNet及3层和5层CNN结构进行消融研究，分析高分辨率触觉图像的信息提取效果。

Result: 机器学习能有效从触觉图像中提取有用信息，提升软体机器人的任务处理能力。

Conclusion: 机器学习是提升软体机器人触觉感知与环境互动能力的有前景的技术。

Abstract: Recent advances in soft robotic hands and tactile sensing have enabled both
to perform an increasing number of complex tasks with the aid of machine
learning. In particular, we presented the GelSight Baby Fin Ray in our previous
work, which integrates a camera with a soft, compliant Fin Ray structure.
Camera-based tactile sensing gives the GelSight Baby Fin Ray the ability to
capture rich contact information like forces, object geometries, and textures.
Moreover, our previous work showed that the GelSight Baby Fin Ray can dig
through clutter, and classify in-shell nuts. To further examine the potential
of the GelSight Baby Fin Ray, we leverage learning to distinguish nut-in-shell
textures and to perform force and position estimation. We implement ablation
studies with popular neural network structures, including ResNet50, GoogLeNet,
and 3- and 5-layer convolutional neural network (CNN) structures. We conclude
that machine learning is a promising technique to extract useful information
from high-resolution tactile images and empower soft robotics to better
understand and interact with the environments.

</details>


### [33] [Event-LAB: Towards Standardized Evaluation of Neuromorphic Localization Methods](https://arxiv.org/abs/2509.14516)
*Adam D. Hines,Alejandro Fontan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Event-LAB是一个新框架，旨在统一基于事件的定位方法，解决多数据和依赖问题。


<details>
  <summary>Details</summary>
Motivation: 基于事件的定位研究快速发展，但数据格式和依赖的多样性使比较和实现变得困难。

Method: 使用Pixi包和依赖管理器实现Event-LAB，支持一键安装和调用多种方法及数据集。

Result: 展示了Event-LAB在VPR和SLAM中的应用，揭示了事件生成参数对性能的影响。

Conclusion: Event-LAB为研究社区提供了统一的工作流程，确保方法比较的公平性。

Abstract: Event-based localization research and datasets are a rapidly growing area of
interest, with a tenfold increase in the cumulative total number of published
papers on this topic over the past 10 years. Whilst the rapid expansion in the
field is exciting, it brings with it an associated challenge: a growth in the
variety of required code and package dependencies as well as data formats,
making comparisons difficult and cumbersome for researchers to implement
reliably. To address this challenge, we present Event-LAB: a new and unified
framework for running several event-based localization methodologies across
multiple datasets. Event-LAB is implemented using the Pixi package and
dependency manager, that enables a single command-line installation and
invocation for combinations of localization methods and datasets. To
demonstrate the capabilities of the framework, we implement two common
event-based localization pipelines: Visual Place Recognition (VPR) and
Simultaneous Localization and Mapping (SLAM). We demonstrate the ability of the
framework to systematically visualize and analyze the results of multiple
methods and datasets, revealing key insights such as the association of
parameters that control event collection counts and window sizes for frame
generation to large variations in performance. The results and analysis
demonstrate the importance of fairly comparing methodologies with consistent
event image generation parameters. Our Event-LAB framework provides this
ability for the research community, by contributing a streamlined workflow for
easily setting up multiple conditions.

</details>


### [34] [Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking](https://arxiv.org/abs/2509.14530)
*Zhenghao Fei,Wenwu Lu,Linsheng Hou,Chen Peng*

Main category: cs.RO

TL;DR: 草莓自然生长时会相互遮挡，传统机器人采摘系统难以应对。本文提出一种基于人类演示学习的机器人系统，用于精确采摘被遮挡的草莓。


<details>
  <summary>Details</summary>
Motivation: 草莓生长时相互遮挡导致采摘困难，传统机器人系统难以胜任，需要一种更智能的方法来完成任务。

Method: 采用4自由度SCARA机械臂和人类远程操作接口收集数据，并结合端位辅助的动作分块变换器（ACT）开发精细的视觉运动采摘策略。

Result: 实验表明，该方法在各种遮挡场景下显著优于直接使用ACT的效果。

Conclusion: 该方法有效解决了草莓采摘中的遮挡问题，具有实际应用潜力。

Abstract: Strawberries naturally grow in clusters, interwoven with leaves, stems, and
other fruits, which frequently leads to occlusion. This inherent growth habit
presents a significant challenge for robotic picking, as traditional
percept-plan-control systems struggle to reach fruits amid the clutter.
Effectively picking an occluded strawberry demands dexterous manipulation to
carefully bypass or gently move the surrounding soft objects and precisely
access the ideal picking point located at the stem just above the calyx. To
address this challenge, we introduce a strawberry-picking robotic system that
learns from human demonstrations. Our system features a 4-DoF SCARA arm paired
with a human teleoperation interface for efficient data collection and
leverages an End Pose Assisted Action Chunking Transformer (ACT) to develop a
fine-grained visuomotor picking policy. Experiments under various occlusion
scenarios demonstrate that our modified approach significantly outperforms the
direct implementation of ACT, underscoring its potential for practical
application in occluded strawberry picking.

</details>


### [35] [Dual-Arm Hierarchical Planning for Laboratory Automation: Vibratory Sieve Shaker Operations](https://arxiv.org/abs/2509.14531)
*Haoran Xiao,Xue Wang,Huimin Lu,Zhiwen Zeng,Zirui Guo,Ziqi Ni,Yicong Ye,Wei Dai*

Main category: cs.RO

TL;DR: 该论文提出了一种分层规划框架，用于自动化振动筛分器操作，解决了狭窄空间中的路径规划问题，显著减少了规划时间和路径点。


<details>
  <summary>Details</summary>
Motivation: 解决材料实验室中振动筛分器自动化操作的三个关键挑战：狭窄空间的双臂操作、重叠工作区的双手交接以及有方向约束的粉末容器输送。

Method: 提出了结合先验引导路径规划和多步轨迹优化的分层规划框架。前者使用高斯混合模型提高采样效率，后者通过简化、约束和平滑优化路径。

Result: 实验结果表明，规划时间减少了80.4%，路径点减少了89.4%，并在物理实验中完成了完整的振动筛分器工作流程。

Conclusion: 该框架在复杂实验室自动化中具有实际应用价值，能够高效完成高精度任务。

Abstract: This paper addresses the challenges of automating vibratory sieve shaker
operations in a materials laboratory, focusing on three critical tasks: 1)
dual-arm lid manipulation in 3 cm clearance spaces, 2) bimanual handover in
overlapping workspaces, and 3) obstructed powder sample container delivery with
orientation constraints. These tasks present significant challenges, including
inefficient sampling in narrow passages, the need for smooth trajectories to
prevent spillage, and suboptimal paths generated by conventional methods. To
overcome these challenges, we propose a hierarchical planning framework
combining Prior-Guided Path Planning and Multi-Step Trajectory Optimization.
The former uses a finite Gaussian mixture model to improve sampling efficiency
in narrow passages, while the latter refines paths by shortening, simplifying,
imposing joint constraints, and B-spline smoothing. Experimental results
demonstrate the framework's effectiveness: planning time is reduced by up to
80.4%, and waypoints are decreased by 89.4%. Furthermore, the system completes
the full vibratory sieve shaker operation workflow in a physical experiment,
validating its practical applicability for complex laboratory automation.

</details>


### [36] [SimCoachCorpus: A naturalistic dataset with language and trajectories for embodied teaching](https://arxiv.org/abs/2509.14548)
*Emily Sumner,Deepak E. Gopinath,Laporsha Dees,Patricio Reyes Gomez,Xiongyi Cui,Andrew Silva,Jean Costa,Allison Morgan,Mariah Schrum,Tiffany L. Chen,Avinash Balachandran,Guy Rosman*

Main category: cs.RO

TL;DR: SimCoachCorpus数据集填补了语言与动作结合领域的空白，记录赛车模拟驾驶中教练指导与自主学习的过程，包含丰富的多模态数据和标注，适用于研究运动学习和教学模型。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在语言与动作结合领域稀缺，尤其是缺乏记录通过语言指导学习运动技能的数据，因此需要新数据集以支持相关研究。

Method: 采集29名参与者在赛车模拟器中的驾驶数据，包括教练指导与非指导组，记录车辆状态、语音反馈、认知负荷等多模态信息，并进行详细标注。

Result: 数据集包含20,000+实时反馈语句、400+总结反馈语句及40+小时驾驶数据，已应用于情境学习、模仿学习和主题建模等任务。

Conclusion: SimCoachCorpus为运动学习和语言交互研究提供了独特资源，未来将公开支持更多研究应用。

Abstract: Curated datasets are essential for training and evaluating AI approaches, but
are often lacking in domains where language and physical action are deeply
intertwined. In particular, few datasets capture how people acquire embodied
skills through verbal instruction over time. To address this gap, we introduce
SimCoachCorpus: a unique dataset of race car simulator driving that allows for
the investigation of rich interactive phenomena during guided and unguided
motor skill acquisition. In this dataset, 29 humans were asked to drive in a
simulator around a race track for approximately ninety minutes. Fifteen
participants were given personalized one-on-one instruction from a professional
performance driving coach, and 14 participants drove without coaching. \name\
includes embodied features such as vehicle state and inputs, map (track
boundaries and raceline), and cone landmarks. These are synchronized with
concurrent verbal coaching from a professional coach and additional feedback at
the end of each lap. We further provide annotations of coaching categories for
each concurrent feedback utterance, ratings on students' compliance with
coaching advice, and self-reported cognitive load and emotional state of
participants (gathered from surveys during the study). The dataset includes
over 20,000 concurrent feedback utterances, over 400 terminal feedback
utterances, and over 40 hours of vehicle driving data. Our naturalistic dataset
can be used for investigating motor learning dynamics, exploring linguistic
phenomena, and training computational models of teaching. We demonstrate
applications of this dataset for in-context learning, imitation learning, and
topic modeling. The dataset introduced in this work will be released publicly
upon publication of the peer-reviewed version of this paper. Researchers
interested in early access may register at
https://tinyurl.com/SimCoachCorpusForm.

</details>


### [37] [Hierarchical Planning and Scheduling for Reconfigurable Multi-Robot Disassembly Systems under Structural Constraints](https://arxiv.org/abs/2509.14564)
*Takuya Kiyokawa,Tomoki Ishikura,Shingo Hamada,Genichiro Matsuda,Kensuke Harada*

Main category: cs.RO

TL;DR: 研究提出了一种用于可重构机器人自动非破坏性拆卸约束结构的系统集成方法，通过多目标优化和约束编程生成计划。


<details>
  <summary>Details</summary>
Motivation: 解决可重构机器人在复杂拆卸任务中因搜索空间大而容易陷入局部最优的问题。

Method: 整合多臂机器人与旋转台，采用分层优化方法，结合多种目标遗传算法和约束编程进行序列、任务和运动规划。

Result: 模拟结果表明该方法能有效解决复杂拆卸问题。

Conclusion: 该方法为可重构机器人在约束结构拆卸中的应用提供了高效解决方案。

Abstract: This study presents a system integration approach for planning schedules,
sequences, tasks, and motions for reconfigurable robots to automatically
disassemble constrained structures in a non-destructive manner. Such systems
must adapt their configuration and coordination to the target structure, but
the large and complex search space makes them prone to local optima. To address
this, we integrate multiple robot arms equipped with different types of tools,
together with a rotary stage, into a reconfigurable setup. This flexible system
is based on a hierarchical optimization method that generates plans meeting
multiple preferred conditions under mandatory requirements within a realistic
timeframe. The approach employs two many-objective genetic algorithms for
sequence and task planning with motion evaluations, followed by constraint
programming for scheduling. Because sequence planning has a much larger search
space, we introduce a chromosome initialization method tailored to constrained
structures to mitigate the risk of local optima. Simulation results demonstrate
that the proposed method effectively solves complex problems in reconfigurable
robotic disassembly.

</details>


### [38] [Toward Embodiment Equivariant Vision-Language-Action Policy](https://arxiv.org/abs/2509.14630)
*Anzhe Chen,Yifei Yang,Zhenjie Zhu,Kechun Xu,Zhongxiang Zhou,Rong Xiong,Yue Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种跨体现预训练框架，通过设计对体现配置变换等变的策略，解决现有多模态动作策略在新型机器人配置上泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作策略虽然在多样任务、环境和体现中进行大规模预训练，但在应对新型机器人配置时泛化能力有限。主要问题在于忽视动作空间设计，导致配置泛化问题需要昂贵的适应性调整。

Method: 论文提出三点方法：(i)建立体现等变性理论指导动作空间和策略设计；(ii)引入强制配置等变的动作解码器；(iii)结合几何感知网络架构以增强体现在空间推理上的无关性。

Result: 模拟和真实环境下的实验表明，该方法提升了预训练效果，并能在新型机器人体现上高效微调。

Conclusion: 通过理论驱动的动作空间和策略设计，该方法有效解决配置泛化问题，为跨体现预训练提供了新思路。

Abstract: Vision-language-action policies learn manipulation skills across tasks,
environments and embodiments through large-scale pre-training. However, their
ability to generalize to novel robot configurations remains limited. Most
approaches emphasize model size, dataset scale and diversity while paying less
attention to the design of action spaces. This leads to the configuration
generalization problem, which requires costly adaptation. We address this
challenge by formulating cross-embodiment pre-training as designing policies
equivariant to embodiment configuration transformations. Building on this
principle, we propose a framework that (i) establishes a embodiment
equivariance theory for action space and policy design, (ii) introduces an
action decoder that enforces configuration equivariance, and (iii) incorporates
a geometry-aware network architecture to enhance embodiment-agnostic spatial
reasoning. Extensive experiments in both simulation and real-world settings
demonstrate that our approach improves pre-training effectiveness and enables
efficient fine-tuning on novel robot embodiments. Our code is available at
https://github.com/hhcaz/e2vla

</details>


### [39] [BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots](https://arxiv.org/abs/2509.14636)
*Yufei Wei,Wangtao Lu,Sha Lu,Chenxiao Hu,Fuzhang Han,Rong Xiong,Yue Wang*

Main category: cs.RO

TL;DR: BEV-ODOM2是一种改进的BEV表示方法，通过密集BEV光流监督和PV-BEV融合，解决了稀疏监督信号和信息丢失问题，显著提升了单目视觉里程计性能。


<details>
  <summary>Details</summary>
Motivation: 现有BEV方法存在稀疏监督信号和透视到BEV投影中的信息丢失问题，限制了单目视觉里程计的性能。

Method: 引入密集BEV光流监督和PV-BEV融合技术，保留6-DoF运动线索同时保持尺度一致性。

Result: 在多个数据集上验证了其卓越性能，RTE指标较之前方法提升了40%。

Conclusion: BEV-ODOM2显著提升了BEV方法的性能，并公开了新数据集ZJH-VO以支持未来研究。

Abstract: Bird's-Eye-View (BEV) representation offers a metric-scaled planar workspace,
facilitating the simplification of 6-DoF ego-motion to a more robust 3-DoF
model for monocular visual odometry (MVO) in intelligent transportation
systems. However, existing BEV methods suffer from sparse supervision signals
and information loss during perspective-to-BEV projection. We present
BEV-ODOM2, an enhanced framework addressing both limitations without additional
annotations. Our approach introduces: (1) dense BEV optical flow supervision
constructed from 3-DoF pose ground truth for pixel-level guidance; (2) PV-BEV
fusion that computes correlation volumes before projection to preserve 6-DoF
motion cues while maintaining scale consistency. The framework employs three
supervision levels derived solely from pose data: dense BEV flow, 5-DoF for the
PV branch, and final 3-DoF output. Enhanced rotation sampling further balances
diverse motion patterns in training. Extensive evaluation on KITTI, NCLT,
Oxford, and our newly collected ZJH-VO multi-scale dataset demonstrates
state-of-the-art performance, achieving 40 improvement in RTE compared to
previous BEV methods. The ZJH-VO dataset, covering diverse ground vehicle
scenarios from underground parking to outdoor plazas, is publicly available to
facilitate future research.

</details>


### [40] [Efficient 3D Perception on Embedded Systems via Interpolation-Free Tri-Plane Lifting and Volume Fusion](https://arxiv.org/abs/2509.14641)
*Sibaek Lee,Jiung Yeon,Hyeonwoo Yu*

Main category: cs.RO

TL;DR: 提出了一种新型的无插值三平面提升和体积融合框架，通过直接投影3D体素到平面特征并重构特征体积，降低了计算复杂度，适用于嵌入式3D推理。


<details>
  <summary>Details</summary>
Motivation: 现有三平面方法依赖于2D图像特征和插值，计算量大且不适用于嵌入式3D推理，因此需要一种更高效的方法。

Method: 采用无插值的三平面提升和体积融合框架，将非线性转移到2D卷积，同时添加低分辨率体积分支以捕获全局上下文。

Result: 实验表明，分类和补全任务保留或提高了准确性，分割和检测任务在计算效率上有显著提升但稍微降低了准确性。

Conclusion: 该方法在嵌入式设备上实现了高效的实时处理，适用于机器人感知任务。

Abstract: Dense 3D convolutions provide high accuracy for perception but are too
computationally expensive for real-time robotic systems. Existing tri-plane
methods rely on 2D image features with interpolation, point-wise queries, and
implicit MLPs, which makes them computationally heavy and unsuitable for
embedded 3D inference. As an alternative, we propose a novel interpolation-free
tri-plane lifting and volumetric fusion framework, that directly projects 3D
voxels into plane features and reconstructs a feature volume through broadcast
and summation. This shifts nonlinearity to 2D convolutions, reducing complexity
while remaining fully parallelizable. To capture global context, we add a
low-resolution volumetric branch fused with the lifted features through a
lightweight integration layer, yielding a design that is both efficient and
end-to-end GPU-accelerated. To validate the effectiveness of the proposed
method, we conduct experiments on classification, completion, segmentation, and
detection, and we map the trade-off between efficiency and accuracy across
tasks. Results show that classification and completion retain or improve
accuracy, while segmentation and detection trade modest drops in accuracy for
significant computational savings. On-device benchmarks on an NVIDIA Jetson
Orin nano confirm robust real-time throughput, demonstrating the suitability of
the approach for embedded robotic perception.

</details>


### [41] [RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI](https://arxiv.org/abs/2509.14687)
*Cong Tai,Zhaoyu Zheng,Haixu Long,Hansheng Wu,Haodong Xiang,Zhengbin Long,Jun Xiong,Rong Shi,Shizhuang Zhang,Gang Qiu,He Wang,Ruifeng Li,Jun Huang,Bin Chang,Shuai Feng,Tao Shen*

Main category: cs.RO

TL;DR: RealMirror是一个开源平台，解决人形机器人Vision-Language-Action（视觉-语言-动作）研究中数据获取成本高、缺乏标准化基准和仿真与现实差距大的问题。


<details>
  <summary>Details</summary>
Motivation: 人形机器人VLA研究面临的高成本、缺乏标准基准和仿真-现实鸿沟阻碍了发展。

Method: 提出RealMirror平台，集成低成本数据收集、模型训练和推理系统，引入多场景VLA基准，结合生成模型和3D高斯泼溅实现零样本Sim2Real迁移。

Result: 成功实现仿真模型直接应用于真实机器人，无需微调。

Conclusion: RealMirror通过整合关键组件，显著加速了人形机器人VLA模型的发展。

Abstract: The emerging field of Vision-Language-Action (VLA) for humanoid robots faces
several fundamental challenges, including the high cost of data acquisition,
the lack of a standardized benchmark, and the significant gap between
simulation and the real world. To overcome these obstacles, we propose
RealMirror, a comprehensive, open-source embodied AI VLA platform. RealMirror
builds an efficient, low-cost data collection, model training, and inference
system that enables end-to-end VLA research without requiring a real robot. To
facilitate model evolution and fair comparison, we also introduce a dedicated
VLA benchmark for humanoid robots, featuring multiple scenarios, extensive
trajectories, and various VLA models. Furthermore, by integrating generative
models and 3D Gaussian Splatting to reconstruct realistic environments and
robot models, we successfully demonstrate zero-shot Sim2Real transfer, where
models trained exclusively on simulation data can perform tasks on a real robot
seamlessly, without any fine-tuning. In conclusion, with the unification of
these critical components, RealMirror provides a robust framework that
significantly accelerates the development of VLA models for humanoid robots.
Project page: https://terminators2025.github.io/RealMirror.github.io

</details>


### [42] [exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation](https://arxiv.org/abs/2509.14688)
*Yue Xu,Litao Wei,Pengyu An,Qingyu Zhang,Yong-Lu Li*

Main category: cs.RO

TL;DR: 提出了一种结合硬件和算法的触觉机器人学习系统exUMI，通过高效数据收集和TPP框架解决触觉数据稀缺和稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 解决触觉机器人学习中数据稀缺、稀疏及缺乏力反馈的挑战。

Method: 开发exUMI设备提升数据收集，提出TPP框架进行动作感知时间触觉预测。

Result: TPP优于传统触觉模仿学习，实现100%数据可用性。

Conclusion: 通过硬件与算法协同设计，推动接触密集操作研究，提供开源资源。

Abstract: Tactile-aware robot learning faces critical challenges in data collection and
representation due to data scarcity and sparsity, and the absence of force
feedback in existing systems. To address these limitations, we introduce a
tactile robot learning system with both hardware and algorithm innovations. We
present exUMI, an extensible data collection device that enhances the vanilla
UMI with robust proprioception (via AR MoCap and rotary encoder), modular
visuo-tactile sensing, and automated calibration, achieving 100% data
usability. Building on an efficient collection of over 1 M tactile frames, we
propose Tactile Prediction Pretraining (TPP), a representation learning
framework through action-aware temporal tactile prediction, capturing contact
dynamics and mitigating tactile sparsity. Real-world experiments show that TPP
outperforms traditional tactile imitation learning. Our work bridges the gap
between human tactile intuition and robot learning through co-designed hardware
and algorithms, offering open-source resources to advance contact-rich
manipulation research. Project page: https://silicx.github.io/exUMI.

</details>


### [43] [Wohlhart's Three-Loop Mechanism: An Overconstrained and Shaky Linkage](https://arxiv.org/abs/2509.14698)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 本文重新分析了一种三环空间连杆机构，发现其在参考配置下具有5个微分自由度，但实际自由度为3，表现为过约束。


<details>
  <summary>Details</summary>
Motivation: 重新审视Wohlhart在2004年提出的三环连杆机构及其后续研究，探讨其自由度和运动特性。

Method: 通过局部分析和计算运动学切线锥，以及c空间的局部近似，深入研究连杆机构的高阶行为。

Result: 分析表明该连杆机构在参考配置下不是c空间奇点，且微分自由度在局部恒定，导致机构晃动。

Conclusion: 该连杆机构的运动特性揭示了其在参考配置下的非奇异性，为后续研究提供了新视角。

Abstract: This paper revisits a three-loop spatial linkage that was proposed in an ARK
2004 paper by Karl Wohlhart (as extension of a two-loop linkage proposed by
Eddie Baker in 1980) and later analyzed in an ARK 2006 paper by Diez-Martinez
et. al. A local analysis shows that this linkage has a finite degree of freedom
(DOF) 3 (and is thus overconstrained) while in its reference configuration the
differential DOF is 5. It is shown that its configuration space is locally a
smooth manifold so that the reference configuration is not a c-space
singularity. It is shown that the differential DOF is locally constant, which
makes this linkage shaky (so that the reference configuration is not a
singularity). The higher-order local analysis is facilitated by the computation
of the kinematic tangent cone as well as a local approximation of the c-space.

</details>


### [44] [Rethinking Reference Trajectories in Agile Drone Racing: A Unified Reference-Free Model-Based Controller via MPPI](https://arxiv.org/abs/2509.14726)
*Fangguo Zhao,Xin Guan,Shuo Li*

Main category: cs.RO

TL;DR: 论文提出了一种无参考的无人机竞速控制方法，通过将基于强化学习的目标直接纳入MPPI框架，优化门进度目标，展示了与传统参考方法的竞争性能。


<details>
  <summary>Details</summary>
Motivation: 传统模型控制器依赖预计算参考轨迹，限制了性能。作者希望直接优化竞速目标（通过门进度），而非间接的轨迹跟踪，从而提高性能。

Method: 方法将门进度目标引入MPPI框架，利用其采样特性优化非连续目标；同时构建统一框架，比较三种目标函数（轨迹跟踪、轮廓控制和门进度）。

Result: 结果显示，无参考方法在竞速性能上与参考方法相当或更优。

Conclusion: 直接优化竞速目标的无参考方法优于传统参考方法，MPPI框架提供了高效优化的可能性。

Abstract: While model-based controllers have demonstrated remarkable performance in
autonomous drone racing, their performance is often constrained by the reliance
on pre-computed reference trajectories. Conventional approaches, such as
trajectory tracking, demand a dynamically feasible, full-state reference,
whereas contouring control relaxes this requirement to a geometric path but
still necessitates a reference. Recent advancements in reinforcement learning
(RL) have revealed that many model-based controllers optimize surrogate
objectives, such as trajectory tracking, rather than the primary racing goal of
directly maximizing progress through gates. Inspired by these findings, this
work introduces a reference-free method for time-optimal racing by
incorporating this gate progress objective, derived from RL reward shaping,
directly into the Model Predictive Path Integral (MPPI) formulation. The
sampling-based nature of MPPI makes it uniquely capable of optimizing the
discontinuous and non-differentiable objective in real-time. We also establish
a unified framework that leverages MPPI to systematically and fairly compare
three distinct objective functions with a consistent dynamics model and
parameter set: classical trajectory tracking, contouring control, and the
proposed gate progress objective. We compare the performance of these three
objectives when solved via both MPPI and a traditional gradient-based solver.
Our results demonstrate that the proposed reference-free approach achieves
competitive racing performance, rivaling or exceeding reference-based methods.
Videos are available at https://zhaofangguo.github.io/racing_mppi/

</details>


### [45] [Investigating the Effect of LED Signals and Emotional Displays in Human-Robot Shared Workspaces](https://arxiv.org/abs/2509.14748)
*Maria Ibrahim,Alap Kshirsagar,Dorothea Koert,Jan Peters*

Main category: cs.RO

TL;DR: 研究表明，在共享工作空间中，非语言沟通（如LED信号和情感表达）能提升机器人的互动性，但对任务效率的改善效果不显著。


<details>
  <summary>Details</summary>
Motivation: 探索非语言沟通（如LED信号和情感表达）对人类与机器人协作中安全性和效率的影响。

Method: 为机器人配备LED灯条和动画面部显示屏，通过颜色信号和表情传达意图，并在实验中比较不同条件的效果。

Result: 情感表达提升了互动性，但对碰撞预测、沟通清晰性和任务效率无显著改善。

Conclusion: 情感提示可增强用户参与感，但对共享工作空间中的任务绩效影响有限。

Abstract: Effective communication is essential for safety and efficiency in human-robot
collaboration, particularly in shared workspaces. This paper investigates the
impact of nonverbal communication on human-robot interaction (HRI) by
integrating reactive light signals and emotional displays into a robotic
system. We equipped a Franka Emika Panda robot with an LED strip on its end
effector and an animated facial display on a tablet to convey movement intent
through colour-coded signals and facial expressions. We conducted a human-robot
collaboration experiment with 18 participants, evaluating three conditions: LED
signals alone, LED signals with reactive emotional displays, and LED signals
with pre-emptive emotional displays. We collected data through questionnaires
and position tracking to assess anticipation of potential collisions, perceived
clarity of communication, and task performance. The results indicate that while
emotional displays increased the perceived interactivity of the robot, they did
not significantly improve collision anticipation, communication clarity, or
task efficiency compared to LED signals alone. These findings suggest that
while emotional cues can enhance user engagement, their impact on task
performance in shared workspaces is limited.

</details>


### [46] [Designing Latent Safety Filters using Pre-Trained Vision Models](https://arxiv.org/abs/2509.14758)
*Ihab Tabbara,Yuxuan Yang,Ahmad Hamzeh,Maxwell Astafyev,Hussein Sibai*

Main category: cs.RO

TL;DR: 论文探讨了预训练视觉模型（PVRs）在基于视觉的安全过滤器设计中的有效性，分析了不同任务中的表现权衡及实际部署考虑。


<details>
  <summary>Details</summary>
Motivation: 解决基于视觉的控制系统在关键场景中的安全问题，探索预训练视觉模型作为安全过滤器组件的潜力。

Method: 使用PVRs作为分类器、HJ可达性安全过滤器以及潜在世界模型的骨干，比较从头训练、微调和冻结三种策略，并评估不同任务中的表现。

Result: 研究发现不同PVRs在不同任务中表现各异，讨论了学习世界模型与Q函数在切换安全策略时的优劣，并提出资源受限设备的部署建议。

Conclusion: 预训练视觉模型在基于视觉的安全过滤器中具有潜力，但需根据具体任务选择最优方法，同时需考虑实际部署的资源和效率问题。

Abstract: Ensuring safety of vision-based control systems remains a major challenge
hindering their deployment in critical settings. Safety filters have gained
increased interest as effective tools for ensuring the safety of classical
control systems, but their applications in vision-based control settings have
so far been limited. Pre-trained vision models (PVRs) have been shown to be
effective perception backbones for control in various robotics domains. In this
paper, we are interested in examining their effectiveness when used for
designing vision-based safety filters. We use them as backbones for classifiers
defining failure sets, for Hamilton-Jacobi (HJ) reachability-based safety
filters, and for latent world models. We discuss the trade-offs between
training from scratch, fine-tuning, and freezing the PVRs when training the
models they are backbones for. We also evaluate whether one of the PVRs is
superior across all tasks, evaluate whether learned world models or Q-functions
are better for switching decisions to safe policies, and discuss practical
considerations for deploying these PVRs on resource-constrained devices.

</details>


### [47] [COMPASS: Confined-space Manipulation Planning with Active Sensing Strategy](https://arxiv.org/abs/2509.14787)
*Qixuan Li,Chen Le,Dongyue Huang,Jincheng Yu,Xinlei Chen*

Main category: cs.RO

TL;DR: 论文提出了COMPASS框架，通过多阶段探索和操作策略，结合感知和规划，提高了受限和杂乱环境中的操作成功率。


<details>
  <summary>Details</summary>
Motivation: 受限和杂乱环境中的操作面临部分可观测性和复杂配置空间的挑战，需要智能探索策略以确保安全和高效操作。

Method: 采用感知-规划结合的方法，包括局部碰撞地图构建、多目标效用函数优化和受限操作姿态生成。

Result: 仿真中操作成功率提高24.25%，实际实验验证了框架在受限环境中的主动感知和操作能力。

Conclusion: COMPASS框架通过多阶段策略有效解决了受限环境中的操作问题，具有实际应用价值。

Abstract: Manipulation in confined and cluttered environments remains a significant
challenge due to partial observability and complex configuration spaces.
Effective manipulation in such environments requires an intelligent exploration
strategy to safely understand the scene and search the target. In this paper,
we propose COMPASS, a multi-stage exploration and manipulation framework
featuring a manipulation-aware sampling-based planner. First, we reduce
collision risks with a near-field awareness scan to build a local collision
map. Additionally, we employ a multi-objective utility function to find
viewpoints that are both informative and conducive to subsequent manipulation.
Moreover, we perform a constrained manipulation optimization strategy to
generate manipulation poses that respect obstacle constraints. To
systematically evaluate method's performance under these difficulties, we
propose a benchmark of confined-space exploration and manipulation containing
four level challenging scenarios. Compared to exploration methods designed for
other robots and only considering information gain, our framework increases
manipulation success rate by 24.25% in simulations. Real-world experiments
demonstrate our method's capability for active sensing and manipulation in
confined environments.

</details>


### [48] [Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution](https://arxiv.org/abs/2509.14816)
*Humphrey Munn,Brendan Tidd,Peter Böhm,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: GCR-PPO是一种改进的强化学习方法，通过分解任务目标解决梯度冲突，在多目标任务中表现优于PPO。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习将多任务目标聚合为单一标量奖励，导致奖励调优困难且容易陷入局部最优，多目标方法因计算成本和优化难度未被广泛应用。

Method: 提出GCR-PPO，利用多头批评家分解目标梯度，并根据目标优先级解决冲突。

Result: 在IsaacLab基准测试中，GCR-PPO性能平均提升9.5%，高冲突任务提升更显著。

Conclusion: GCR-PPO在多目标强化学习中表现出更高的可扩展性和性能优势。

Abstract: Reinforcement Learning (RL) robot controllers usually aggregate many task
objectives into one scalar reward. While large-scale proximal policy
optimisation (PPO) has enabled impressive results such as robust robot
locomotion in the real world, many tasks still require careful reward tuning
and are brittle to local optima. Tuning cost and sub-optimality grow with the
number of objectives, limiting scalability. Modelling reward vectors and their
trade-offs can address these issues; however, multi-objective methods remain
underused in RL for robotics because of computational cost and optimisation
difficulty. In this work, we investigate the conflict between gradient
contributions for each objective that emerge from scalarising the task
objectives. In particular, we explicitly address the conflict between
task-based rewards and terms that regularise the policy towards realistic
behaviour. We propose GCR-PPO, a modification to actor-critic optimisation that
decomposes the actor update into objective-wise gradients using a multi-headed
critic and resolves conflicts based on the objective priority. Our methodology,
GCR-PPO, is evaluated on the well-known IsaacLab manipulation and locomotion
benchmarks and additional multi-objective modifications on two related tasks.
We show superior scalability compared to parallel PPO (p = 0.04), without
significant computational overhead. We also show higher performance with more
conflicting tasks. GCR-PPO improves on large-scale PPO with an average
improvement of 9.5%, with high-conflict tasks observing a greater improvement.
The code is available at https://github.com/humphreymunn/GCR-PPO.

</details>


### [49] [CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human](https://arxiv.org/abs/2509.14889)
*Nan Sun,Yongchang Li,Chenxu Wang,Huiying Li,Huaping Liu*

Main category: cs.RO

TL;DR: CollabVLA是一个自反思的视觉-语言-动作框架，通过结合VLM反思推理和扩散动作生成，解决了现有VLA的领域过拟合、不可解释推理和延迟高等问题。其两阶段训练方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）框架存在领域过拟合、推理不可解释和延迟高的问题，CollabVLA旨在通过自反思和协作设计解决这些限制。

Method: 采用两阶段训练：动作基础化和反思调优，结合VLM反思推理与扩散动作生成，并引入混合专家设计。

Result: 相比生成式代理，CollabVLA将标准化时间缩短约2倍，失败次数减少4倍，同时提高了成功率、可解释性和低延迟性。

Conclusion: CollabVLA首次将VLA从黑盒控制器转变为能与人类推理、行动和协作的真正辅助工具。

Abstract: In this work, we present CollabVLA, a self-reflective vision-language-action
framework that transforms a standard visuomotor policy into a collaborative
assistant. CollabVLA tackles key limitations of prior VLAs, including domain
overfitting, non-interpretable reasoning, and the high latency of auxiliary
generative models, by integrating VLM-based reflective reasoning with
diffusion-based action generation under a mixture-of-experts design. Through a
two-stage training recipe of action grounding and reflection tuning, it
supports explicit self-reflection and proactively solicits human guidance when
confronted with uncertainty or repeated failure. It cuts normalized Time by ~2x
and Dream counts by ~4x vs. generative agents, achieving higher success rates,
improved interpretability, and balanced low latency compared with existing
methods. This work takes a pioneering step toward shifting VLAs from opaque
controllers to genuinely assistive agents capable of reasoning, acting, and
collaborating with humans.

</details>


### [50] [PERAL: Perception-Aware Motion Control for Passive LiDAR Excitation in Spherical Robots](https://arxiv.org/abs/2509.14915)
*Shenghai Yuan,Jason Wai Hao Yee,Weixiang Guo,Zhongyuan Liu,Thien-Minh Nguyen,Lihua Xie*

Main category: cs.RO

TL;DR: PERAL是一种感知感知运动控制框架，通过被动激发LiDAR扫描以提升垂直多样性，无需额外硬件，显著提升了地图完整性和轨迹跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 解决水平LiDAR在地形感知和特征稀少环境中的性能限制，避免传统方案（如静态倾斜或主动旋转）的额外成本和复杂度。

Method: 引入PERAL框架，通过微分驱动与传感器姿态的耦合模型，叠加非周期性振荡以丰富LiDAR扫描多样性。

Result: 在实验中，PERAL实现了96%的地图完整性、27%的轨迹误差降低，并提高了近地面检测能力，且成本更低。

Conclusion: PERAL为球形机器人提供了一种高效、低成本的LiDAR-IMU方案，性能优于传统方法，未来将开源。

Abstract: Autonomous mobile robots increasingly rely on LiDAR-IMU odometry for
navigation and mapping, yet horizontally mounted LiDARs such as the MID360
capture few near-ground returns, limiting terrain awareness and degrading
performance in feature-scarce environments. Prior solutions - static tilt,
active rotation, or high-density sensors - either sacrifice horizontal
perception or incur added actuators, cost, and power. We introduce PERAL, a
perception-aware motion control framework for spherical robots that achieves
passive LiDAR excitation without dedicated hardware. By modeling the coupling
between internal differential-drive actuation and sensor attitude, PERAL
superimposes bounded, non-periodic oscillations onto nominal goal- or
trajectory-tracking commands, enriching vertical scan diversity while
preserving navigation accuracy. Implemented on a compact spherical robot, PERAL
is validated across laboratory, corridor, and tactical environments.
Experiments demonstrate up to 96 percent map completeness, a 27 percent
reduction in trajectory tracking error, and robust near-ground human detection,
all at lower weight, power, and cost compared with static tilt, active
rotation, and fixed horizontal baselines. The design and code will be
open-sourced upon acceptance.

</details>


### [51] [Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale](https://arxiv.org/abs/2509.14932)
*Tobias Jülg,Pierre Krack,Seongjin Bien,Yannik Blei,Khaled Gamal,Ken Nakahara,Johannes Hechtl,Roberto Calandra,Wolfram Burgard,Florian Walter*

Main category: cs.RO

TL;DR: 论文提出了Robot Control Stack（RCS），一个专为支持大规模通用策略机器人学习研究设计的轻量级生态系统，解决了传统机器人软件框架在机器学习工作流中的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人软件框架在大规模数据驱动的机器学习工作流中成为瓶颈，模拟环境对真实实验的过渡支持有限，亟需一种新工具来弥补这一鸿沟。

Method: 引入RCS，采用模块化和可扩展的分层架构，统一模拟与真实机器人的接口，支持从模拟到现实的迁移，同时具备轻量化和完整功能集。

Result: RCS的实用性和性能在VLA和RL策略的开发周期中得到验证，实验还评估了Octo、OpenVLA和Pi Zero在多机器人上的表现，并探索了模拟数据对真实策略性能的提升。

Conclusion: RCS成功填补了机器人学习研究中的工具缺口，支持高效的大规模训练和真实实验，为通用策略的开发和评估提供了强大支持。

Abstract: Vision-Language-Action models (VLAs) mark a major shift in robot learning.
They replace specialized architectures and task-tailored components of expert
policies with large-scale data collection and setup-specific fine-tuning. In
this machine learning-focused workflow that is centered around models and
scalable training, traditional robotics software frameworks become a
bottleneck, while robot simulations offer only limited support for
transitioning from and to real-world experiments. In this work, we close this
gap by introducing Robot Control Stack (RCS), a lean ecosystem designed from
the ground up to support research in robot learning with large-scale generalist
policies. At its core, RCS features a modular and easily extensible layered
architecture with a unified interface for simulated and physical robots,
facilitating sim-to-real transfer. Despite its minimal footprint and
dependencies, it offers a complete feature set, enabling both real-world
experiments and large-scale training in simulation. Our contribution is
twofold: First, we introduce the architecture of RCS and explain its design
principles. Second, we evaluate its usability and performance along the
development cycle of VLA and RL policies. Our experiments also provide an
extensive evaluation of Octo, OpenVLA, and Pi Zero on multiple robots and shed
light on how simulation data can improve real-world policy performance. Our
code, datasets, weights, and videos are available at:
https://robotcontrolstack.github.io/

</details>


### [52] [CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids](https://arxiv.org/abs/2509.14935)
*Punith Reddy Vanteddu,Davide Gorbani,Giuseppe L'Erario,Hosameldin Awadalla Omer Mohamed,Fabio Bergonti,Daniele Pucci*

Main category: cs.RO

TL;DR: 该论文提出了一种CAD驱动的协同设计框架，用于优化喷气动力空中人形机器人以执行动态约束轨迹。通过实验设计和聚类分析，框架生成了5,000种可行的机器人设计，并通过多目标优化最终输出一组已验证的飞行配置。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种系统化的方法，优化喷气动力空中人形机器人的设计，以高效执行动态约束的任务轨迹，弥补现有研究的不足。

Method: 采用实验设计生成5,000种几何变体设计，通过K-means聚类筛选代表模型，结合最小抖动轨迹和线性化MPC策略评估性能，最终使用NSGA-II算法进行多目标优化。

Result: 框架成功输出了一组飞行就绪的人形机器人配置和已验证的控制参数，显著减少了轨迹跟踪误差和机械能耗。

Conclusion: 该框架为设计和实现可行的空中人形机器人提供了一种结构化方法，具有实际应用潜力。

Abstract: This paper presents a CAD-driven co-design framework for optimizing
jet-powered aerial humanoid robots to execute dynamically constrained
trajectories. Starting from the iRonCub-Mk3 model, a Design of Experiments
(DoE) approach is used to generate 5,000 geometrically varied and mechanically
feasible designs by modifying limb dimensions, jet interface geometry (e.g.,
angle and offset), and overall mass distribution. Each model is constructed
through CAD assemblies to ensure structural validity and compatibility with
simulation tools. To reduce computational cost and enable parameter sensitivity
analysis, the models are clustered using K-means, with representative centroids
selected for evaluation. A minimum-jerk trajectory is used to assess flight
performance, providing position and velocity references for a momentum-based
linearized Model Predictive Control (MPC) strategy. A multi-objective
optimization is then conducted using the NSGA-II algorithm, jointly exploring
the space of design centroids and MPC gain parameters. The objectives are to
minimize trajectory tracking error and mechanical energy expenditure. The
framework outputs a set of flight-ready humanoid configurations with validated
control parameters, offering a structured method for selecting and implementing
feasible aerial humanoid designs.

</details>


### [53] [A Novel Task-Driven Diffusion-Based Policy with Affordance Learning for Generalizable Manipulation of Articulated Objects](https://arxiv.org/abs/2509.14939)
*Hao Zhang,Zhen Kan,Weiwei Shang,Yongduan Song*

Main category: cs.RO

TL;DR: DART提出了一个结合扩散策略、功能学习和线性时序逻辑的新框架，以提高多关节物体操作的效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多关节物体的操作及跨类别泛化是目前的研究难点，DART旨在解决这些问题。

Method: DART通过线性时序逻辑理解任务语义，功能学习识别交互点，扩散策略泛化操作，并通过优化方法改进动作生成。

Result: 实验表明，DART在操作能力、泛化性能、迁移推理和鲁棒性方面优于现有方法。

Conclusion: DART是一个高效、泛化性强的多关节物体操作框架，具有广泛的应用潜力。

Abstract: Despite recent advances in dexterous manipulations, the manipulation of
articulated objects and generalization across different categories remain
significant challenges. To address these issues, we introduce DART, a novel
framework that enhances a diffusion-based policy with affordance learning and
linear temporal logic (LTL) representations to improve the learning efficiency
and generalizability of articulated dexterous manipulation. Specifically, DART
leverages LTL to understand task semantics and affordance learning to identify
optimal interaction points. The {diffusion-based policy} then generalizes these
interactions across various categories. Additionally, we exploit an
optimization method based on interaction data to refine actions, overcoming the
limitations of traditional diffusion policies that typically rely on offline
reinforcement learning or learning from demonstrations. Experimental results
demonstrate that DART outperforms most existing methods in manipulation
ability, generalization performance, transfer reasoning, and robustness. For
more information, visit our project website at:
https://sites.google.com/view/dart0257/.

</details>


### [54] [Multi-CAP: A Multi-Robot Connectivity-Aware Hierarchical Coverage Path Planning Algorithm for Unknown Environments](https://arxiv.org/abs/2509.14941)
*Zongyuan Shen,Burhanuddin Shirose,Prasanna Sriganesh,Bhaskar Vundurthy,Howie Choset,Matthew Travers*

Main category: cs.RO

TL;DR: Multi-CAP是一种分层覆盖路径规划算法，通过连接感知方法协调多机器人，有效减少覆盖路径长度和冲突。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在未知大环境中协调覆盖的挑战，旨在最小化路径长度和减少机器人冲突。

Method: 构建动态邻接图表示环境，将任务建模为车辆路径问题（VRP），为机器人分配无冲突子区域并独立执行覆盖策略。

Result: 在覆盖时间、总路径长度和路径重叠率等关键指标上显著优于现有方法。

Conclusion: Multi-CAP的连接感知图和全局路径规划是性能提升的关键。

Abstract: Efficient coordination of multiple robots for coverage of large, unknown
environments is a significant challenge that involves minimizing the total
coverage path length while reducing inter-robot conflicts. In this paper, we
introduce a Multi-robot Connectivity-Aware Planner (Multi-CAP), a hierarchical
coverage path planning algorithm that facilitates multi-robot coordination
through a novel connectivity-aware approach. The algorithm constructs and
dynamically maintains an adjacency graph that represents the environment as a
set of connected subareas. Critically, we make the assumption that the
environment, while unknown, is bounded. This allows for incremental refinement
of the adjacency graph online to ensure its structure represents the physical
layout of the space, both in observed and unobserved areas of the map as robots
explore the environment. We frame the task of assigning subareas to robots as a
Vehicle Routing Problem (VRP), a well-studied problem for finding optimal
routes for a fleet of vehicles. This is used to compute disjoint tours that
minimize redundant travel, assigning each robot a unique, non-conflicting set
of subareas. Each robot then executes its assigned tour, independently adapting
its coverage strategy within each subarea to minimize path length based on
real-time sensor observations of the subarea. We demonstrate through
simulations and multi-robot hardware experiments that Multi-CAP significantly
outperforms state-of-the-art methods in key metrics, including coverage time,
total path length, and path overlap ratio. Ablation studies further validate
the critical role of our connectivity-aware graph and the global tour planner
in achieving these performance gains.

</details>


### [55] [Human Interaction for Collaborative Semantic SLAM using Extended Reality](https://arxiv.org/abs/2509.14949)
*Laura Ribeiro,Muhammad Shaheer,Miguel Fernandez-Cortizas,Ali Tourani,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: HICS-SLAM 是一种结合人类交互的语义 SLAM 框架，通过在扩展现实环境中实时协作，提高了语义地图的准确性和完整性。


<details>
  <summary>Details</summary>
Motivation: 现有语义 SLAM 系统在复杂真实场景（如遮挡或数据不全）中表现不佳，未能充分利用人类的高层次空间语义知识。

Method: 通过共享扩展现实环境，人类操作者可以干预机器人的 3D 场景图，并添加高级语义概念（如房间或结构实体）。

Result: 在建筑工地数据上的实验表明，该方法提高了房间检测精度、地图精度和语义完整性。

Conclusion: HICS-SLAM 展示了人类干预对语义 SLAM 的有效性，并具备未来扩展潜力。

Abstract: Semantic SLAM (Simultaneous Localization and Mapping) systems enrich robot
maps with structural and semantic information, enabling robots to operate more
effectively in complex environments. However, these systems struggle in
real-world scenarios with occlusions, incomplete data, or ambiguous geometries,
as they cannot fully leverage the higher-level spatial and semantic knowledge
humans naturally apply. We introduce HICS-SLAM, a Human-in-the-Loop semantic
SLAM framework that uses a shared extended reality environment for real-time
collaboration. The system allows human operators to directly interact with and
visualize the robot's 3D scene graph, and add high-level semantic concepts
(e.g., rooms or structural entities) into the mapping process. We propose a
graph-based semantic fusion methodology that integrates these human
interventions with robot perception, enabling scalable collaboration for
enhanced situational awareness. Experimental evaluations on real-world
construction site datasets demonstrate improvements in room detection accuracy,
map precision, and semantic completeness compared to automated baselines,
demonstrating both the effectiveness of the approach and its potential for
future extensions.

</details>


### [56] [Exploratory Movement Strategies for Texture Discrimination with a Neuromorphic Tactile Sensor](https://arxiv.org/abs/2509.14954)
*Xingchen Xu,Ao Li,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 提出了一种受人类探索策略启发的神经形态触觉感知框架，用于机器人纹理分类，通过NeuroTac传感器采集数据，滑动加旋转动作为最佳策略，准确率达87.33%，功耗极低。


<details>
  <summary>Details</summary>
Motivation: 受人类探索策略启发，旨在提升机器人对环境的触觉感知能力，特别是纹理分类任务。

Method: 使用NeuroTac传感器采集神经形态触觉数据，测试六种不同动作，并在固定环境和复杂条件下评估滑动加旋转动作的性能。

Result: 滑动加旋转动作在复杂条件下达到87.33%的最高准确率，功耗仅为8.04 mW。

Conclusion: 滑动加旋转是神经形态触觉感知在纹理分类任务中的最佳探索策略，具有显著的应用潜力。

Abstract: We propose a neuromorphic tactile sensing framework for robotic texture
classification that is inspired by human exploratory strategies. Our system
utilizes the NeuroTac sensor to capture neuromorphic tactile data during a
series of exploratory motions. We first tested six distinct motions for texture
classification under fixed environment: sliding, rotating, tapping, as well as
the combined motions: sliding+rotating, tapping+rotating, and tapping+sliding.
We chose sliding and sliding+rotating as the best motions based on final
accuracy and the sample timing length needed to reach converged accuracy. In
the second experiment designed to simulate complex real-world conditions, these
two motions were further evaluated under varying contact depth and speeds.
Under these conditions, our framework attained the highest accuracy of 87.33\%
with sliding+rotating while maintaining an extremely low power consumption of
only 8.04 mW. These results suggest that the sliding+rotating motion is the
optimal exploratory strategy for neuromorphic tactile sensing deployment in
texture classification tasks and holds significant promise for enhancing
robotic environmental interaction.

</details>


### [57] [Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery](https://arxiv.org/abs/2509.14967)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 论文提出了一个机器人手术助手的框架，通过结合视觉上下文解释和消歧外科医生的口头指令，以提高手术中人机协作的效果。


<details>
  <summary>Details</summary>
Motivation: 由于口头指令的固有歧义性，影响了手术中的人机协作效果，因此需要一种能够消歧并提供安全决策的方法。

Method: 系统采用基于两层级联的可供性推理方法，结合多模态视觉-语言模型和工具能力知识库，并使用双重集合规预测方法确保决策的统计置信度。

Result: 在胆囊切除术视频数据集上评估，展示了60%的消歧率，并提出了一种更安全的人机交互方法。

Conclusion: 该框架显著提升了手术中机器人对口头指令的理解能力，并通过统计方法增强了患者安全性。

Abstract: Effective human-robot collaboration in surgery is affected by the inherent
ambiguity of verbal communication. This paper presents a framework for a
robotic surgical assistant that interprets and disambiguates verbal
instructions from a surgeon by grounding them in the visual context of the
operating field. The system employs a two-level affordance-based reasoning
process that first analyzes the surgical scene using a multimodal
vision-language model and then reasons about the instruction using a knowledge
base of tool capabilities. To ensure patient safety, a dual-set conformal
prediction method is used to provide a statistically rigorous confidence
measure for robot decisions, allowing it to identify and flag ambiguous
commands. We evaluated our framework on a curated dataset of ambiguous surgical
requests from cholecystectomy videos, demonstrating a general disambiguation
rate of 60% and presenting a method for safer human-robot interaction in the
operating room.

</details>


### [58] [PA-MPPI: Perception-Aware Model Predictive Path Integral Control for Quadrotor Navigation in Unknown Environments](https://arxiv.org/abs/2509.14978)
*Yifan Zhai,Rudolf Reiter,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 论文提出了一种感知感知的MPPI（PA-MPPI）方法，通过在线调整轨迹以探索未知区域，解决四旋翼在未知环境中的导航问题。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼在未知环境中导航的三个关键挑战：障碍物导致的非凸自由空间、四旋翼特定动力学和目标、以及对未知区域的探索需求。

Method: 提出了PA-MPPI方法，当目标被遮挡时，通过感知成本偏置轨迹以探索未知区域，从而扩大可通行的地图空间。

Result: 硬件实验表明，PA-MPPI在50Hz运行时性能比基线提升了100%，并且在导航基础模型中表现出安全性和鲁棒性。

Conclusion: PA-MPPI是一种有效的解决方案，能够显著提升四旋翼在未知环境中的导航能力，并为导航基础模型提供安全可靠的动作策略。

Abstract: Quadrotor navigation in unknown environments is critical for practical
missions such as search-and-rescue. Solving it requires addressing three key
challenges: the non-convexity of free space due to obstacles,
quadrotor-specific dynamics and objectives, and the need for exploration of
unknown regions to find a path to the goal. Recently, the Model Predictive Path
Integral (MPPI) method has emerged as a promising solution that solves the
first two challenges. By leveraging sampling-based optimization, it can
effectively handle non-convex free space while directly optimizing over the
full quadrotor dynamics, enabling the inclusion of quadrotor-specific costs
such as energy consumption. However, its performance in unknown environments is
limited, as it lacks the ability to explore unknown regions when blocked by
large obstacles. To solve this issue, we introduce Perception-Aware MPPI
(PA-MPPI). Here, perception-awareness is defined as adapting the trajectory
online based on perception objectives. Specifically, when the goal is occluded,
PA-MPPI's perception cost biases trajectories that can perceive unknown
regions. This expands the mapped traversable space and increases the likelihood
of finding alternative paths to the goal. Through hardware experiments, we
demonstrate that PA-MPPI, running at 50 Hz with our efficient perception and
mapping module, performs up to 100% better than the baseline in our challenging
settings where the state-of-the-art MPPI fails. In addition, we demonstrate
that PA-MPPI can be used as a safe and robust action policy for navigation
foundation models, which often provide goal poses that are not directly
reachable.

</details>


### [59] [M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation](https://arxiv.org/abs/2509.14980)
*Ju Dong,Lei Zhang,Liding Zhang,Yao Ling,Yu Fu,Kaixin Bai,Zoltán-Csaba Márton,Zhenshan Bing,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: M4Diffuser是一个结合多视图扩散策略和新型QP控制器的混合框架，用于提升移动机械臂在非结构化环境中的操作能力，显著提高了成功率和减少了碰撞。


<details>
  <summary>Details</summary>
Motivation: 现有单视图方法和经典控制器在非结构化环境中表现不佳，存在视野受限、探索能力弱、通用性差以及效率低的问题。

Method: 提出M4Diffuser框架，结合多视图扩散策略和ReM-QP控制器，前者生成任务相关的末端执行器目标，后者高效且稳健地执行这些目标。

Result: 实验表明，M4Diffuser比基线方法成功率高7%至56%，碰撞减少3%至31%，并在未见任务中表现出强泛化能力。

Conclusion: M4Diffuser为提升非结构化环境中的移动机械臂操作可靠性提供了有效途径。

Abstract: Mobile manipulation requires the coordinated control of a mobile base and a
robotic arm while simultaneously perceiving both global scene context and
fine-grained object details. Existing single-view approaches often fail in
unstructured environments due to limited fields of view, exploration, and
generalization abilities. Moreover, classical controllers, although stable,
struggle with efficiency and manipulability near singularities. To address
these challenges, we propose M4Diffuser, a hybrid framework that integrates a
Multi-View Diffusion Policy with a novel Reduced and Manipulability-aware QP
(ReM-QP) controller for mobile manipulation. The diffusion policy leverages
proprioceptive states and complementary camera perspectives with both
close-range object details and global scene context to generate task-relevant
end-effector goals in the world frame. These high-level goals are then executed
by the ReM-QP controller, which eliminates slack variables for computational
efficiency and incorporates manipulability-aware preferences for robustness
near singularities. Comprehensive experiments in simulation and real-world
environments show that M4Diffuser achieves 7 to 56 percent higher success rates
and reduces collisions by 3 to 31 percent over baselines. Our approach
demonstrates robust performance for smooth whole-body coordination, and strong
generalization to unseen tasks, paving the way for reliable mobile manipulation
in unstructured environments. Details of the demo and supplemental material are
available on our project website https://sites.google.com/view/m4diffuser.

</details>


### [60] [The Role of Touch: Towards Optimal Tactile Sensing Distribution in Anthropomorphic Hands for Dexterous In-Hand Manipulation](https://arxiv.org/abs/2509.14984)
*João Damião Almeida,Egidio Falotico,Cecilia Laschi,José Santos-Victor*

Main category: cs.RO

TL;DR: 研究探讨了机器人手的分布式触觉传感器配置对物体重新定向任务的影响，强调了不同手指和手掌区域的触觉反馈对深度学习控制政策的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决机器人手中触觉传感器的最优配置问题，特别是非指尖区域的触感信息常被忽视的问题。

Method: 方法包括分析手指和手掌不同区域的触觉反馈对深度学习控制政策的影响，并研究物体特性与最佳传感器布置之间的关系。

Result: 研究结果确定了哪些触觉传感器配置能提高操作的效率和准确性。

Conclusion: 结论为设计了具有增强操作能力的人形末端效应器提供了有价值的见解。

Abstract: In-hand manipulation tasks, particularly in human-inspired robotic systems,
must rely on distributed tactile sensing to achieve precise control across a
wide variety of tasks. However, the optimal configuration of this network of
sensors is a complex problem, and while the fingertips are a common choice for
placing sensors, the contribution of tactile information from other regions of
the hand is often overlooked. This work investigates the impact of tactile
feedback from various regions of the fingers and palm in performing in-hand
object reorientation tasks. We analyze how sensory feedback from different
parts of the hand influences the robustness of deep reinforcement learning
control policies and investigate the relationship between object
characteristics and optimal sensor placement. We identify which tactile sensing
configurations contribute to improving the efficiency and accuracy of
manipulation. Our results provide valuable insights for the design and use of
anthropomorphic end-effectors with enhanced manipulation capabilities.

</details>


### [61] [ExT: Towards Scalable Autonomous Excavation via Large-Scale Multi-Task Pretraining and Fine-Tuning](https://arxiv.org/abs/2509.14992)
*Yifan Zhai,Lorenzo Terenzi,Patrick Frey,Diego Garcia Soto,Pascal Egli,Marco Hutter*

Main category: cs.RO

TL;DR: 本文介绍了ExT框架，用于大规模演示收集、预训练和多任务挖掘策略微调，展示了其在模拟和实际环境中的高性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 自主挖掘机的规模化部署具有重要经济和社会意义，但现有方法依赖高度工程化、特定任务的控制器，缺乏通用性。

Method: 提出ExT框架，通过大规模演示收集和预训练，采用监督或强化学习微调策略，以适应新任务和环境。

Result: ExT策略在模拟和实际环境中均表现出厘米级精度，且能快速适应新任务和机器配置，性能媲美专用控制器。

Conclusion: ExT框架为可扩展和通用的自主挖掘提供了潜力，为未来研究奠定了基础。

Abstract: Scaling up the deployment of autonomous excavators is of great economic and
societal importance. Yet it remains a challenging problem, as effective systems
must robustly handle unseen worksite conditions and new hardware
configurations. Current state-of-the-art approaches rely on highly engineered,
task-specific controllers, which require extensive manual tuning for each new
scenario. In contrast, recent advances in large-scale pretrained models have
shown remarkable adaptability across tasks and embodiments in domains such as
manipulation and navigation, but their applicability to heavy construction
machinery remains largely unexplored. In this work, we introduce ExT, a unified
open-source framework for large-scale demonstration collection, pretraining,
and fine-tuning of multitask excavation policies. ExT policies are first
trained on large-scale demonstrations collected from a mix of experts, then
fine-tuned either with supervised fine-tuning (SFT) or reinforcement learning
fine-tuning (RLFT) to specialize to new tasks or operating conditions. Through
both simulation and real-world experiments, we show that pretrained ExT
policies can execute complete excavation cycles with centimeter-level accuracy,
successfully transferring from simulation to real machine with performance
comparable to specialized single-task controllers. Furthermore, in simulation,
we demonstrate that ExT's fine-tuning pipelines allow rapid adaptation to new
tasks, out-of-distribution conditions, and machine configurations, while
maintaining strong performance on previously learned tasks. These results
highlight the potential of ExT to serve as a foundation for scalable and
generalizable autonomous excavation.

</details>


### [62] [Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments](https://arxiv.org/abs/2509.14999)
*Haoxuan Jiang,Peicong Qian,Yusen Xie,Linwei Zheng,Xiaocong Li,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种紧耦合的语义-LiDAR-惯性-轮式里程计融合框架，用于大规模动态环境中的高精度状态估计和鲁棒定位。


<details>
  <summary>Details</summary>
Motivation: 在大规模动态环境中实现可靠且无漂移的全局定位是自主导航的关键挑战。

Method: 采用高效的语义体素地图表示和改进的扫描匹配算法，结合紧耦合多传感器融合的迭代误差状态卡尔曼滤波器（iESKF），并引入3D自适应缩放策略调整轮式里程计测量权重。

Result: 在一百万平方米自动化港口的3,575小时实际测试中，系统表现优于现有LiDAR定位方法。

Conclusion: 该框架在大规模动态环境中表现出高可靠性和实用价值。

Abstract: Reliable, drift-free global localization presents significant challenges yet
remains crucial for autonomous navigation in large-scale dynamic environments.
In this paper, we introduce a tightly-coupled Semantic-LiDAR-Inertial-Wheel
Odometry fusion framework, which is specifically designed to provide
high-precision state estimation and robust localization in large-scale dynamic
environments. Our framework leverages an efficient semantic-voxel map
representation and employs an improved scan matching algorithm, which utilizes
global semantic information to significantly reduce long-term trajectory drift.
Furthermore, it seamlessly fuses data from LiDAR, IMU, and wheel odometry using
a tightly-coupled multi-sensor fusion Iterative Error-State Kalman Filter
(iESKF). This ensures reliable localization without experiencing abnormal
drift. Moreover, to tackle the challenges posed by terrain variations and
dynamic movements, we introduce a 3D adaptive scaling strategy that allows for
flexible adjustments to wheel odometry measurement weights, thereby enhancing
localization precision. This study presents extensive real-world experiments
conducted in a one-million-square-meter automated port, encompassing 3,575
hours of operational data from 35 Intelligent Guided Vehicles (IGVs). The
results consistently demonstrate that our system outperforms state-of-the-art
LiDAR-based localization methods in large-scale dynamic environments,
highlighting the framework's reliability and practical value.

</details>


### [63] [Online Multi-Robot Coordination and Cooperation with Task Precedence Relationships](https://arxiv.org/abs/2509.15052)
*Walker Gosrich,Saurav Agarwal,Kashish Garg,Siddharth Mayya,Matthew Malencia,Mark Yim,Vijay Kumar*

Main category: cs.RO

TL;DR: 提出了一个多机器人任务分配的新模型，结合任务间复杂的前驱关系、高效的任务内协调及通过机器人联盟的合作，通过任务图和奖励函数建模，提出高效的网络流算法进行近似求解。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人任务分配中复杂任务关系、协调与合作的挑战，以提高任务执行效率和鲁棒性。

Method: 利用任务图描述任务及其关系，通过奖励函数建模联盟大小和前置任务效果，提出网络流算法近似求解NP难问题，并设计在线算法进行动态重分配。

Result: 在随机任务和奖励函数的测试平台中表现优于混合整数求解器和贪婪启发式算法，在高级仿真器中验证了模型的真实性和高效性。

Conclusion: 该方法能有效建模复杂任务关系，生成高质量任务计划，提升任务执行效率。

Abstract: We propose a new formulation for the multi-robot task allocation problem that
incorporates (a) complex precedence relationships between tasks, (b) efficient
intra-task coordination, and (c) cooperation through the formation of robot
coalitions. A task graph specifies the tasks and their relationships, and a set
of reward functions models the effects of coalition size and preceding task
performance. Maximizing task rewards is NP-hard; hence, we propose network
flow-based algorithms to approximate solutions efficiently. A novel online
algorithm performs iterative re-allocation, providing robustness to task
failures and model inaccuracies to achieve higher performance than offline
approaches. We comprehensively evaluate the algorithms in a testbed with random
missions and reward functions and compare them to a mixed-integer solver and a
greedy heuristic. Additionally, we validate the overall approach in an advanced
simulator, modeling reward functions based on realistic physical phenomena and
executing the tasks with realistic robot dynamics. Results establish efficacy
in modeling complex missions and efficiency in generating high-fidelity task
plans while leveraging task relationships.

</details>


### [64] [Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue](https://arxiv.org/abs/2509.15061)
*Xingyao Lin,Xinghao Zhu,Tianyi Lu,Sicheng Xie,Hui Zhang,Xipeng Qiu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: 提出了Ask-to-Clarify框架，通过多轮对话解决指令模糊问题，并结合VLM和扩散模型生成动作，在8个现实任务中优于现有VLA方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA-based embodied agents多为单向执行指令，无法处理模糊指令，因此需要一种能主动澄清指令并协作的框架。

Method: 结合VLM和扩散模型，通过两阶段知识隔离策略训练，先解决指令模糊问题，再生成动作。

Result: 在8个现实任务中优于现有VLA方法。

Conclusion: Ask-to-Clarify框架及其训练策略为协作式embodied agents提供了可行路径。

Abstract: The ultimate goal of embodied agents is to create collaborators that can
interact with humans, not mere executors that passively follow instructions.
This requires agents to communicate, coordinate, and adapt their actions based
on human feedback. Recently, advances in VLAs have offered a path toward this
goal. However, most current VLA-based embodied agents operate in a one-way
mode: they receive an instruction and execute it without feedback. This
approach fails in real-world scenarios where instructions are often ambiguous.
In this paper, we address this problem with the Ask-to-Clarify framework. Our
framework first resolves ambiguous instructions by asking questions in a
multi-turn dialogue. Then it generates low-level actions end-to-end.
Specifically, the Ask-to-Clarify framework consists of two components, one VLM
for collaboration and one diffusion for action. We also introduce a connection
module that generates conditions for the diffusion based on the output of the
VLM. This module adjusts the observation by instructions to create reliable
conditions. We train our framework with a two-stage knowledge-insulation
strategy. First, we fine-tune the collaboration component using
ambiguity-solving dialogue data to handle ambiguity. Then, we integrate the
action component while freezing the collaboration one. This preserves the
interaction abilities while fine-tuning the diffusion to generate actions. The
training strategy guarantees our framework can first ask questions, then
generate actions. During inference, a signal detector functions as a router
that helps our framework switch between asking questions and taking actions. We
evaluate the Ask-to-Clarify framework in 8 real-world tasks, where it
outperforms existing state-of-the-art VLAs. The results suggest that our
proposed framework, along with the training strategy, provides a path toward
collaborative embodied agents.

</details>


### [65] [Energy-Constrained Navigation for Planetary Rovers under Hybrid RTG-Solar Power](https://arxiv.org/abs/2509.15062)
*Tianxin Hu,Weixiang Guo,Ruimeng Liu,Xinhang Xu,Rui Qian,Jinyu Chen,Shenghai Yuan,Lihua Xie*

Main category: cs.RO

TL;DR: 本文提出一种能量约束轨迹规划框架，整合了物理模型和混合能源输入，确保轨迹平滑、可行且符合功率限制。仿真结果表明，该方法显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 未来行星探测车需在混合能源（RTG和太阳能）下长时间运行，现有轨迹规划方法未充分整合能量约束，导致能量可行性不足。

Method: 基于SE(2)的多项式轨迹优化框架，结合平移、旋转和阻力功率的物理模型，同时考虑累积能量预算和瞬时功率限制。

Result: 仿真中，规划器生成的轨迹峰值功率仅超出限值0.55%，而现有方法超出17%。

Conclusion: 该方法为长期行星任务提供了一种高效的能量感知自主规划方案。

Abstract: Future planetary exploration rovers must operate for extended durations on
hybrid power inputs that combine steady radioisotope thermoelectric generator
(RTG) output with variable solar photovoltaic (PV) availability. While
energy-aware planning has been studied for aerial and underwater robots under
battery limits, few works for ground rovers explicitly model power flow or
enforce instantaneous power constraints. Classical terrain-aware planners
emphasize slope or traversability, and trajectory optimization methods
typically focus on geometric smoothness and dynamic feasibility, neglecting
energy feasibility. We present an energy-constrained trajectory planning
framework that explicitly integrates physics-based models of translational,
rotational, and resistive power with baseline subsystem loads, under hybrid
RTG-solar input. By incorporating both cumulative energy budgets and
instantaneous power constraints into SE(2)-based polynomial trajectory
optimization, the method ensures trajectories that are simultaneously smooth,
dynamically feasible, and power-compliant. Simulation results on lunar-like
terrain show that our planner generates trajectories with peak power within
0.55 percent of the prescribed limit, while existing methods exceed limits by
over 17 percent. This demonstrates a principled and practical approach to
energy-aware autonomy for long-duration planetary missions.

</details>


### [66] [AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](https://arxiv.org/abs/2509.15153)
*Yating Lin,Zixuan Huang,Fan Yang,Dmitry Berenson*

Main category: cs.RO

TL;DR: AnoF-Diff是一种基于扩散模型的多变量时间序列异常检测方法，专为处理强力工具使用任务中的噪声和非平稳数据而设计。


<details>
  <summary>Details</summary>
Motivation: 强力工具任务中的传感器数据通常噪声大、非平稳且任务间差异大，传统的异常检测方法难以适用。

Method: 提出AnoF-Diff方法，利用扩散模型提取力-扭矩特征并检测异常。

Result: 在四项任务中，AnoF-Diff在F1分数和AUROC上优于其他方法，且对噪声更鲁棒。

Conclusion: AnoF-Diff在强力工具任务中表现优越，适合在线异常检测。

Abstract: Multivariate time-series anomaly detection, which is critical for identifying
unexpected events, has been explored in the field of machine learning for
several decades. However, directly applying these methods to data from forceful
tool use tasks is challenging because streaming sensor data in the real world
tends to be inherently noisy, exhibits non-stationary behavior, and varies
across different tasks and tools. To address these challenges, we propose a
method, AnoF-Diff, based on the diffusion model to extract force-torque
features from time-series data and use force-torque features to detect
anomalies. We compare our method with other state-of-the-art methods in terms
of F1-score and Area Under the Receiver Operating Characteristic curve (AUROC)
on four forceful tool-use tasks, demonstrating that our method has better
performance and is more robust to a noisy dataset. We also propose the method
of parallel anomaly score evaluation based on one-step diffusion and
demonstrate how our method can be used for online anomaly detection in several
forceful tool use experiments.

</details>


### [67] [Parallel Simulation of Contact and Actuation for Soft Growing Robots](https://arxiv.org/abs/2509.15180)
*Yitian Gao,Lucas Chen,Priyanka Bhovad,Sicheng Wang,Zachary Kingston,Laura H. Blumenschein*

Main category: cs.RO

TL;DR: 研究提出了一个统一的建模框架，用于集成软生长机器人的生长、弯曲、驱动和障碍物接触，并通过实验验证了模型的准确性。该框架用于优化设计，以减少驱动器的数量并利用环境接触提升导航能力。


<details>
  <summary>Details</summary>
Motivation: 软生长机器人在非结构化和动态环境中表现出卓越的交互能力，但其主动转向功能尚未充分开发，尤其在复杂环境中的导航需求迫切。

Method: 扩展梁矩模型以整合生长和驱动对运动学的影响，并开发快速并行仿真框架。实验验证模型和仿真器的准确性。

Result: 优化设计的软生长机器人在复杂环境中表现出高效导航能力，且对环境及制造不确定性具有鲁棒性。

Conclusion: 提出的统一框架为软生长机器人的设计和规划提供了有效工具，展示了其在复杂环境中的实际应用潜力。

Abstract: Soft growing robots, commonly referred to as vine robots, have demonstrated
remarkable ability to interact safely and robustly with unstructured and
dynamic environments. It is therefore natural to exploit contact with the
environment for planning and design optimization tasks. Previous research has
focused on planning under contact for passively deforming robots with
pre-formed bends. However, adding active steering to these soft growing robots
is necessary for successful navigation in more complex environments. To this
end, we develop a unified modeling framework that integrates vine robot growth,
bending, actuation, and obstacle contact. We extend the beam moment model to
include the effects of actuation on kinematics under growth and then use these
models to develop a fast parallel simulation framework. We validate our model
and simulator with real robot experiments. To showcase the capabilities of our
framework, we apply our model in a design optimization task to find designs for
vine robots navigating through cluttered environments, identifying designs that
minimize the number of required actuators by exploiting environmental contacts.
We show the robustness of the designs to environmental and manufacturing
uncertainties. Finally, we fabricate an optimized design and successfully
deploy it in an obstacle-rich environment.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [68] [Graph-Aware Learning Rates for Decentralized Optimization](https://arxiv.org/abs/2509.14854)
*Aaron Fainman,Stefan Vlaski*

Main category: math.OC

TL;DR: 提出了一种自适应步长规则用于分布式优化，解决了步长选择的挑战，并在单智能体情况下简化为Polyak规则，性能接近最优调优步长。


<details>
  <summary>Details</summary>
Motivation: 在分布式优化中，选择合适的步长以平衡收敛性和稳定性是一个挑战，因为智能体只能观察到局部的（可能随机的）梯度，缺乏全局信息（如平滑性）。

Method: 从基本原理推导出一种自适应步长规则，适用于随机梯度，无需额外参数，仅需最优目标值。

Result: 数值模拟表明，该方法的性能与最优调优步长相当。

Conclusion: 提出的自适应步长规则解决了分布式优化中的步长选择问题，且在实际应用中表现良好。

Abstract: We propose an adaptive step-size rule for decentralized optimization.
Choosing a step-size that balances convergence and stability is challenging.
This is amplified in the decentralized setting as agents observe only local
(possibly stochastic) gradients and global information (like smoothness) is
unavailable. We derive a step-size rule from first principles. The resulting
formulation reduces to the well-known Polyak's rule in the single-agent
setting, and is suitable for use with stochastic gradients. The method is
parameter free, apart from requiring the optimal objective value, which is
readily available in many applications. Numerical simulations demonstrate that
the performance is comparable to the optimally fine-tuned step-size.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [69] [A Real-Time Multi-Model Parametric Representation of Point Clouds](https://arxiv.org/abs/2509.14773)
*Yuan Gao,Wei Dong*

Main category: cs.CV

TL;DR: 该论文提出了一种多模型参数表示方法，结合高斯混合模型和B样条曲面，实时检测和拟合点云表面，提高了效率和精度。


<details>
  <summary>Details</summary>
Motivation: 为解决点云参数表示中高适应性模型计算成本高而实时方法精度低的问题。

Method: 使用高斯混合模型分割点云，平面区域通过2D体素边界描述拟合，曲面则通过B样条曲面拟合。

Result: 在多个公共数据集上验证，效率提高3.78倍，精度比高斯混合模型提高2倍，实时运行速度36.4 fps。

Conclusion: 该方法在效率和精度上均优于现有技术，适合低功耗设备实时应用。

Abstract: In recent years, parametric representations of point clouds have been widely
applied in tasks such as memory-efficient mapping and multi-robot
collaboration. Highly adaptive models, like spline surfaces or quadrics, are
computationally expensive in detection or fitting. In contrast, real-time
methods, such as Gaussian mixture models or planes, have low degrees of
freedom, making high accuracy with few primitives difficult. To tackle this
problem, a multi-model parametric representation with real-time surface
detection and fitting is proposed. Specifically, the Gaussian mixture model is
first employed to segment the point cloud into multiple clusters. Then, flat
clusters are selected and merged into planes or curved surfaces. Planes can be
easily fitted and delimited by a 2D voxel-based boundary description method.
Surfaces with curvature are fitted by B-spline surfaces and the same boundary
description method is employed. Through evaluations on multiple public
datasets, the proposed surface detection exhibits greater robustness than the
state-of-the-art approach, with 3.78 times improvement in efficiency.
Meanwhile, this representation achieves a 2-fold gain in accuracy over Gaussian
mixture models, operating at 36.4 fps on a low-power onboard computer.

</details>


### [70] [RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching](https://arxiv.org/abs/2509.14966)
*Xingwu Zhang,Guanxuan Li,Zhuocheng Zhang,Zijun Long*

Main category: cs.CV

TL;DR: RoboEye是一个两阶段物体识别框架，结合2D语义特征与3D推理，提升电商仓储自动化包装中的物品识别准确率。


<details>
  <summary>Details</summary>
Motivation: 解决电商产品类别激增导致的物体识别难题，尤其是面对类内差异、相似物品、遮挡等问题时，传统2D方法性能下降明显。

Method: 采用两阶段方法，首阶段提取2D特征生成候选排名，第二阶段通过轻量级3D模块动态判断是否需要3D重排，使用3D特征提取和关键点匹配替代传统相似度评分。

Result: 实验显示RoboEye在Recall@1上比当前最优方法（RoboLLM）提升7.1%，且仅需RGB图像，降低部署成本。

Conclusion: RoboEye通过结合2D和3D特征，显著提升复杂场景下的物体识别性能，同时避免依赖显式3D输入，具有高效和低成本的优势。

Abstract: The rapidly growing number of product categories in large-scale e-commerce
makes accurate object identification for automated packing in warehouses
substantially more difficult. As the catalog grows, intra-class variability and
a long tail of rare or visually similar items increase, and when combined with
diverse packaging, cluttered containers, frequent occlusion, and large
viewpoint changes-these factors amplify discrepancies between query and
reference images, causing sharp performance drops for methods that rely solely
on 2D appearance features. Thus, we propose RoboEye, a two-stage identification
framework that dynamically augments 2D semantic features with domain-adapted 3D
reasoning and lightweight adapters to bridge training deployment gaps. In the
first stage, we train a large vision model to extract 2D features for
generating candidate rankings. A lightweight 3D-feature-awareness module then
estimates 3D feature quality and predicts whether 3D re-ranking is necessary,
preventing performance degradation and avoiding unnecessary computation. When
invoked, the second stage uses our robot 3D retrieval transformer, comprising a
3D feature extractor that produces geometry-aware dense features and a
keypoint-based matcher that computes keypoint-correspondence confidences
between query and reference images instead of conventional cosine-similarity
scoring. Experiments show that RoboEye improves Recall@1 by 7.1% over the prior
state of the art (RoboLLM). Moreover, RoboEye operates using only RGB images,
avoiding reliance on explicit 3D inputs and reducing deployment costs. The code
used in this paper is publicly available at:
https://github.com/longkukuhi/RoboEye.

</details>


### [71] [RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation](https://arxiv.org/abs/2509.15212)
*Yuming Jiang,Siteng Huang,Shengke Xue,Yaxi Zhao,Jun Cen,Sicong Leng,Kehan Li,Jiayan Guo,Kexiang Wang,Mingxiu Chen,Fan Wang,Deli Zhao,Xin Li*

Main category: cs.CV

TL;DR: 该研究提出了RynnVLA-001，一种基于大规模视频生成预训练的视觉-语言-动作模型，通过两阶段预训练方法，结合未来帧和关键点轨迹预测，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地初始化视觉-语言-动作（VLA）模型，研究团队提出了一种结合视频生成和动作预测的两阶段预训练方法。

Method: 研究分为两个阶段：自我中心视频生成预训练和人类中心轨迹感知建模。第二阶段扩展为联合预测未来关键点轨迹，并结合ActionVAE压缩动作序列。

Result: 在相同下游机器人数据集上微调后，RynnVLA-001性能优于现有基准模型。

Conclusion: 提出的预训练策略为VLA模型提供了更有效的初始化方法，显著提升了模型性能。

Abstract: This paper presents RynnVLA-001, a vision-language-action(VLA) model built
upon large-scale video generative pretraining from human demonstrations. We
propose a novel two-stage pretraining methodology. The first stage, Ego-Centric
Video Generative Pretraining, trains an Image-to-Video model on 12M ego-centric
manipulation videos to predict future frames conditioned on an initial frame
and a language instruction. The second stage, Human-Centric Trajectory-Aware
Modeling, extends this by jointly predicting future keypoint trajectories,
thereby effectively bridging visual frame prediction with action prediction.
Furthermore, to enhance action representation, we propose ActionVAE, a
variational autoencoder that compresses sequences of actions into compact
latent embeddings, reducing the complexity of the VLA output space. When
finetuned on the same downstream robotics datasets, RynnVLA-001 achieves
superior performance over state-of-the-art baselines, demonstrating that the
proposed pretraining strategy provides a more effective initialization for VLA
models.

</details>


### [72] [Out-of-Sight Trajectories: Tracking, Fusion, and Prediction](https://arxiv.org/abs/2509.15219)
*Haichao Zhang,Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: 论文提出了一种新的任务——视线外轨迹预测（OOSTraj），旨在利用噪声传感器数据预测视线外物体的无噪声视觉轨迹，并通过增强的视觉定位去噪模块取得了先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖完整且无噪声的观测数据，忽略了视线外物体和传感器数据噪声的挑战，导致实际场景中的预测不可靠和安全风险。

Method: 通过增强的Vision-Positioning Denoising Module，利用相机校准建立视觉定位映射，以无监督方式去噪。

Result: 在Vi-Fi和JRDB数据集上实现了领先的轨迹去噪和预测性能，显著优于传统方法。

Conclusion: 该研究首次将视觉定位投影用于视线外目标轨迹去噪，为未来研究奠定了基础。

Abstract: Trajectory prediction is a critical task in computer vision and autonomous
systems, playing a key role in autonomous driving, robotics, surveillance, and
virtual reality. Existing methods often rely on complete and noise-free
observational data, overlooking the challenges associated with out-of-sight
objects and the inherent noise in sensor data caused by limited camera
coverage, obstructions, and the absence of ground truth for denoised
trajectories. These limitations pose safety risks and hinder reliable
prediction in real-world scenarios. In this extended work, we present
advancements in Out-of-Sight Trajectory (OST), a novel task that predicts the
noise-free visual trajectories of out-of-sight objects using noisy sensor data.
Building on our previous research, we broaden the scope of Out-of-Sight
Trajectory Prediction (OOSTraj) to include pedestrians and vehicles, extending
its applicability to autonomous driving, robotics, surveillance, and virtual
reality. Our enhanced Vision-Positioning Denoising Module leverages camera
calibration to establish a vision-positioning mapping, addressing the lack of
visual references, while effectively denoising noisy sensor data in an
unsupervised manner. Through extensive evaluations on the Vi-Fi and JRDB
datasets, our approach achieves state-of-the-art performance in both trajectory
denoising and prediction, significantly surpassing previous baselines.
Additionally, we introduce comparisons with traditional denoising methods, such
as Kalman filtering, and adapt recent trajectory prediction models to our task,
providing a comprehensive benchmark. This work represents the first initiative
to integrate vision-positioning projection for denoising noisy sensor
trajectories of out-of-sight agents, paving the way for future advances. The
code and preprocessed datasets are available at github.com/Hai-chao-Zhang/OST

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [73] [Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization](https://arxiv.org/abs/2509.14848)
*Houssem Sifaou,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 论文提出了一种基于信息增益最大化的多保真度混合强化学习方法（MF-HRL-IGM），通过结合离线数据和多保真度模拟器优化策略，在固定成本预算下实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖高保真度模拟器，成本高昂；离线强化学习受限于数据集质量和规模。多保真度模拟器的存在为优化策略提供了新机会。

Method: 提出MF-HRL-IGM算法，通过信息增益最大化选择模拟器保真度，结合离线数据和在线交互，采用引导方法来优化策略。

Result: 理论分析表明MF-HRL-IGM具有无后悔特性，实验验证其性能优于现有基准方法。

Conclusion: MF-HRL-IGM在多保真度环境下是一种高效且成本可控的策略优化方法。

Abstract: Optimizing a reinforcement learning (RL) policy typically requires extensive
interactions with a high-fidelity simulator of the environment, which are often
costly or impractical. Offline RL addresses this problem by allowing training
from pre-collected data, but its effectiveness is strongly constrained by the
size and quality of the dataset. Hybrid offline-online RL leverages both
offline data and interactions with a single simulator of the environment. In
many real-world scenarios, however, multiple simulators with varying levels of
fidelity and computational cost are available. In this work, we study
multi-fidelity hybrid RL for policy optimization under a fixed cost budget. We
introduce multi-fidelity hybrid RL via information gain maximization
(MF-HRL-IGM), a hybrid offline-online RL algorithm that implements fidelity
selection based on information gain maximization through a bootstrapping
approach. Theoretical analysis establishes the no-regret property of
MF-HRL-IGM, while empirical evaluations demonstrate its superior performance
compared to existing benchmarks.

</details>


### [74] [Learning Graph from Smooth Signals under Partial Observation: A Robustness Analysis](https://arxiv.org/abs/2509.14887)
*Hoang-Son Nguyen,Hoi-To Wai*

Main category: cs.LG

TL;DR: 论文研究了在部分观测条件下，基于平滑性的图学习方法可以恢复真实图拓扑，证明了传统方法的隐式鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究在存在隐藏节点时，传统图学习方法如何隐式地保持鲁棒性，从而恢复观测节点的真实图拓扑。

Method: 扩展了受限等距性质（RIP）到图学习目标中的Dirichlet能量函数，验证了平滑性方法（如GL-SigRep）的有效性。

Result: 理论和实验表明，平滑性方法可以在部分观测条件下恢复真实图拓扑。

Conclusion: 传统图学习方法对部分观测的低通滤波图信号具有隐式鲁棒性，为实际应用提供了理论基础。

Abstract: Learning the graph underlying a networked system from nodal signals is
crucial to downstream tasks in graph signal processing and machine learning.
The presence of hidden nodes whose signals are not observable might corrupt the
estimated graph. While existing works proposed various robustifications of
vanilla graph learning objectives by explicitly accounting for the presence of
these hidden nodes, a robustness analysis of "naive", hidden-node agnostic
approaches is still underexplored. This work demonstrates that vanilla graph
topology learning methods are implicitly robust to partial observations of
low-pass filtered graph signals. We achieve this theoretical result through
extending the restricted isometry property (RIP) to the Dirichlet energy
function used in graph learning objectives. We show that smoothness-based graph
learning formulation (e.g., the GL-SigRep method) on partial observations can
recover the ground truth graph topology corresponding to the observed nodes.
Synthetic and real data experiments corroborate our findings.

</details>


### [75] [Self-Improving Embodied Foundation Models](https://arxiv.org/abs/2509.15155)
*Seyed Kamyar Seyed Ghasemipour,Ayzaan Wahid,Jonathan Tompson,Pannag Sanketi,Igor Mordatch*

Main category: cs.LG

TL;DR: 提出一种结合监督微调与自我改进的两阶段后训练方法，显著提升机器人控制的样本效率和成功率，并实现超越模仿学习的自主技能获取。


<details>
  <summary>Details</summary>
Motivation: 探索如何将基础模型应用于低级控制，解决现有行为克隆方法的局限性，并利用在线自我改进提升机器人自主性。

Method: 1) 监督微调(SFT)：结合行为克隆和步骤预测目标；2) 自我改进：利用步骤预测提取奖励函数和成功检测器，实现机器人自主训练。

Result: 结合SFT与自我改进显著优于单纯模仿学习，样本效率更高且成功率更高；能够自主获取超越训练数据的新技能。

Conclusion: 基础模型与在线自我改进的结合具有变革潜力，能够实现机器人自主技能获取。

Abstract: Foundation models trained on web-scale data have revolutionized robotics, but
their application to low-level control remains largely limited to behavioral
cloning. Drawing inspiration from the success of the reinforcement learning
stage in fine-tuning large language models, we propose a two-stage
post-training approach for robotics. The first stage, Supervised Fine-Tuning
(SFT), fine-tunes pretrained foundation models using both: a) behavioral
cloning, and b) steps-to-go prediction objectives. In the second stage,
Self-Improvement, steps-to-go prediction enables the extraction of a
well-shaped reward function and a robust success detector, enabling a fleet of
robots to autonomously practice downstream tasks with minimal human
supervision. Through extensive experiments on real-world and simulated robot
embodiments, our novel post-training recipe unveils significant results on
Embodied Foundation Models. First, we demonstrate that the combination of SFT
and Self-Improvement is significantly more sample-efficient than scaling
imitation data collection for supervised learning, and that it leads to
policies with significantly higher success rates. Further ablations highlight
that the combination of web-scale pretraining and Self-Improvement is the key
to this sample-efficiency. Next, we demonstrate that our proposed combination
uniquely unlocks a capability that current methods cannot achieve: autonomously
practicing and acquiring novel skills that generalize far beyond the behaviors
observed in the imitation learning datasets used during training. These
findings highlight the transformative potential of combining pretrained
foundation models with online Self-Improvement to enable autonomous skill
acquisition in robotics. Our project website can be found at
https://self-improving-efms.github.io .

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [76] [Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting](https://arxiv.org/abs/2509.15170)
*Aarushi Mahajan,Wayne Burleson*

Main category: cs.CR

TL;DR: 本文提出了一种结合水印技术和异常检测的射频指纹识别系统，以提高安全性和抗篡改性，在LoRa数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的射频指纹识别技术虽然通过深度学习提高了精度，但仍易受复制、篡改和规避攻击。因此，需要一种更安全的系统，既能证明所有权，又能检测异常输入。

Method: 使用ResNet-34处理log-Mel频谱图，嵌入三种水印：简单触发器、抗噪声和滤波的对抗训练触发器，以及隐藏的梯度/权重签名。同时，采用卷积变分自编码器（VAE）和KL预热技术检测异常输入。

Result: 在LoRa数据集上，系统实现了94.6%的准确率，98%的水印成功率，以及0.94的AUROC值。

Conclusion: 该系统提供了一种可验证、抗篡改的认证方案，有效提升了射频指纹识别的安全性。

Abstract: Radio frequency fingerprint identification (RFFI) distinguishes wireless
devices by the small variations in their analog circuits, avoiding heavy
cryptographic authentication. While deep learning on spectrograms improves
accuracy, models remain vulnerable to copying, tampering, and evasion. We
present a stronger RFFI system combining watermarking for ownership proof and
anomaly detection for spotting suspicious inputs. Using a ResNet-34 on log-Mel
spectrograms, we embed three watermarks: a simple trigger, an adversarially
trained trigger robust to noise and filtering, and a hidden gradient/weight
signature. A convolutional Variational Autoencoders (VAE) with Kullback-Leibler
(KL) warm-up and free-bits flags off-distribution queries. On the LoRa dataset,
our system achieves 94.6% accuracy, 98% watermark success, and 0.94 AUROC,
offering verifiable, tamper-resistant authentication.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [77] [Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation](https://arxiv.org/abs/2509.14632)
*Miseul Kim,Soo Jin Park,Kyungguen Byun,Hyeon-Kyeong Shin,Sunkuk Moon,Shuhua Zhang,Erik Visser*

Main category: eess.AS

TL;DR: 提出了一种风格可控的语音生成模型，用于增强说话人日志系统的鲁棒性，减少由于说话人内部高可变性（如情绪变化）导致的误分类。


<details>
  <summary>Details</summary>
Motivation: 说话人日志系统在处理说话人内部高可变性（如情绪、健康或内容的变化）时表现不佳，容易将同一说话人的不同片段误分类为不同个体。

Method: 利用风格可控的语音生成模型，对日志化的语音片段生成多样化的语音样本，结合原始和生成语音的说话人嵌入，提升系统鲁棒性。

Result: 在模拟情感语音数据集和截断的AMI数据集上，错误率分别降低了49%和35%。

Conclusion: 所提方法有效提升了说话人日志系统对高内部可变性的鲁棒性，显著减少了误分类。

Abstract: Speaker diarization systems often struggle with high intrinsic intra-speaker
variability, such as shifts in emotion, health, or content. This can cause
segments from the same speaker to be misclassified as different individuals,
for example, when one raises their voice or speaks faster during conversation.
To address this, we propose a style-controllable speech generation model that
augments speech across diverse styles while preserving the target speaker's
identity. The proposed system starts with diarized segments from a conventional
diarizer. For each diarized segment, it generates augmented speech samples
enriched with phonetic and stylistic diversity. And then, speaker embeddings
from both the original and generated audio are blended to enhance the system's
robustness in grouping segments with high intrinsic intra-speaker variability.
We validate our approach on a simulated emotional speech dataset and the
truncated AMI dataset, demonstrating significant improvements, with error rate
reductions of 49% and 35% on each dataset, respectively.

</details>


### [78] [SpeechMLC: Speech Multi-label Classification](https://arxiv.org/abs/2509.14677)
*Miseul Kim,Seyun Um,Hyeonjin Cha,Hong-goo Kang*

Main category: eess.AS

TL;DR: 提出了一种多标签分类框架，用于检测语音样本中的多种说话风格，适用于人机交互应用。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单一风格的识别，而本文旨在捕捉多样的说话者特征，以满足更广泛的人机交互需求。

Method: 结合交叉注意力机制的Transformer解码器提取语音中的关键特征，并使用基于语音生成模型的数据增强技术解决数据不平衡问题。

Result: 通过多组客观评估验证模型的有效性，并分析了人类标注一致性对分类准确性的影响。

Conclusion: 该框架在多标签分类任务中表现出色，且对数据不平衡和人类感知差异具有鲁棒性。

Abstract: In this paper, we propose a multi-label classification framework to detect
multiple speaking styles in a speech sample. Unlike previous studies that have
primarily focused on identifying a single target style, our framework
effectively captures various speaker characteristics within a unified
structure, making it suitable for generalized human-computer interaction
applications. The proposed framework integrates cross-attention mechanisms
within a transformer decoder to extract salient features associated with each
target label from the input speech. To mitigate the data imbalance inherent in
multi-label speech datasets, we employ a data augmentation technique based on a
speech generation model. We validate our model's effectiveness through multiple
objective evaluations on seen and unseen corpora. In addition, we provide an
analysis of the influence of human perception on classification accuracy by
considering the impact of human labeling agreement on model performance.

</details>


### [79] [Acoustic Simulation Framework for Multi-channel Replay Speech Detection](https://arxiv.org/abs/2509.14789)
*Michael Neri,Tuomas Virtanen*

Main category: eess.AS

TL;DR: 该论文提出了一个声学仿真框架，用于模拟多通道重放语音攻击，以增强语音控制系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 重放语音攻击对语音控制系统构成重大威胁，但目前的数据集和方法主要依赖单通道录音，无法充分利用多通道音频的空间线索。

Method: 引入一个声学仿真框架，模拟多通道重放语音配置，包括真实和伪造语音在不同环境中的表现，并使用测量的扬声器方向性增强模拟真实性。

Result: 通过M-ALRAD模型评估，证明合成数据可以提高检测器在未见环境中的泛化能力。

Conclusion: 该框架为多通道重放语音攻击的检测提供了有效的仿真工具，有助于提升语音助手的安全性。

Abstract: Replay speech attacks pose a significant threat to voice-controlled systems,
especially in smart environments where voice assistants are widely deployed.
While multi-channel audio offers spatial cues that can enhance replay detection
robustness, existing datasets and methods predominantly rely on single-channel
recordings. In this work, we introduce an acoustic simulation framework
designed to simulate multi-channel replay speech configurations using publicly
available resources. Our setup models both genuine and spoofed speech across
varied environments, including realistic microphone and loudspeaker impulse
responses, room acoustics, and noise conditions. The framework employs measured
loudspeaker directionalities during the replay attack to improve the realism of
the simulation. We define two spoofing settings, which simulate whether a
reverberant or an anechoic speech is used in the replay scenario, and evaluate
the impact of omnidirectional and diffuse noise on detection performance. Using
the state-of-the-art M-ALRAD model for replay speech detection, we demonstrate
that synthetic data can support the generalization capabilities of the detector
across unseen enclosures.

</details>


### [80] [Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance](https://arxiv.org/abs/2509.14934)
*Francisco Messina,Francesca Ronchini,Luca Comanducci,Paolo Bestagini,Fabio Antonacci*

Main category: eess.AS

TL;DR: 研究了通过反记忆策略解决文本到音频扩散模型中数据复制问题，使用反记忆指导（AMG）技术，显著减少了记忆化现象。


<details>
  <summary>Details</summary>
Motivation: 解决生成音频模型中数据复制问题，避免预训练扩散模型在推理时生成训练数据片段。

Method: 采用反记忆指导（AMG）技术，探索三种不同类型的指导策略，以平衡生成质量和减少复制。

Result: AMG显著减少了记忆化现象，同时保持了音频保真度和语义对齐。

Conclusion: AMG是解决文本到音频扩散模型中数据复制问题的有效方法。

Abstract: A persistent challenge in generative audio models is data replication, where
the model unintentionally generates parts of its training data during
inference. In this work, we address this issue in text-to-audio diffusion
models by exploring the use of anti-memorization strategies. We adopt
Anti-Memorization Guidance (AMG), a technique that modifies the sampling
process of pre-trained diffusion models to discourage memorization. Our study
explores three types of guidance within AMG, each designed to reduce
replication while preserving generation quality. We use Stable Audio Open as
our backbone, leveraging its fully open-source architecture and training
dataset. Our comprehensive experimental analysis suggests that AMG
significantly mitigates memorization in diffusion-based text-to-audio
generation without compromising audio fidelity or semantic alignment.

</details>


### [81] [Real-Time Streaming Mel Vocoding with Generative Flow Matching](https://arxiv.org/abs/2509.15085)
*Simon Welker,Tal Peer,Timo Gerkmann*

Main category: eess.AS

TL;DR: 提出了一种低延迟、实时流式生成的Mel声码器MelFlow，性能优于非流式基线模型。


<details>
  <summary>Details</summary>
Motivation: Mel声码器在TTS系统中至关重要，现有流式声码器在延迟和性能方面仍有改进空间。

Method: 基于生成流匹配、STFT相位恢复及Mel滤波器的伪逆操作，设计低延迟流式Mel声码器。

Result: MelFlow在16 kHz语音下实现48 ms总延迟，性能优于HiFi-GAN等非流式基线模型。

Conclusion: MelFlow是一种高效实时的流式Mel声码器，适用于TTS系统。

Abstract: The task of Mel vocoding, i.e., the inversion of a Mel magnitude spectrogram
to an audio waveform, is still a key component in many text-to-speech (TTS)
systems today. Based on generative flow matching, our prior work on generative
STFT phase retrieval (DiffPhase), and the pseudoinverse operator of the Mel
filterbank, we develop MelFlow, a streaming-capable generative Mel vocoder for
speech sampled at 16 kHz with an algorithmic latency of only 32 ms and a total
latency of 48 ms. We show real-time streaming capability at this latency not
only in theory, but in practice on a consumer laptop GPU. Furthermore, we show
that our model achieves substantially better PESQ and SI-SDR values compared to
well-established not streaming-capable baselines for Mel vocoding including
HiFi-GAN.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [82] [Chameleon: Integrated Sensing and Communication with Sub-Symbol Beam Switching in mmWave Networks](https://arxiv.org/abs/2509.14628)
*Zhihui Gao,Zhecun Liu,Tingjun Chen*

Main category: cs.NI

TL;DR: Chameleon框架通过在5G毫米波网络中快速切换波束成形器，实现了通信与感知的集成，同时支持多用户通信和高分辨率成像。


<details>
  <summary>Details</summary>
Motivation: 当前的5G网络中，波束成形通常仅用于通信或感知，未能实现两者的高效集成。

Method: Chameleon框架在每个DMRS符号期间快速切换波束成形器，同时维持通信波束并增加感知波束。

Result: 实验表明，Chameleon支持最高0.80 Gbps的多用户通信速率，同时完成高分辨率成像和精准目标定位。

Conclusion: 该方法为下一代蜂窝网络中的通信与感知集成提供了实用解决方案。

Abstract: Next-generation cellular networks are envisioned to integrate sensing
capabilities with communication, particularly in the millimeter-wave (mmWave)
spectrum, where beamforming using large-scale antenna arrays enables
directional signal transmissions for improved spatial multiplexing. In current
5G networks, however, beamforming is typically designed either for
communication or sensing (e.g., beam training during link establishment). In
this paper, we present Chameleon, a novel framework that augments and rapidly
switches beamformers during each demodulation reference signal (DMRS) symbol to
achieve integrated sensing and communication (ISAC) in 5G mmWave networks. Each
beamformer introduces an additional sensing beam toward target angles while
maintaining the communication beams toward multiple users. We implement
Chameleon on a 28 GHz software-defined radio testbed supporting over-the-air 5G
physical downlink shared channel (PDSCH) transmissions. Extensive experiments
in open environments show that Chameleon achieves multi-user communication with
a sum data rate of up to 0.80 Gbps across two users. Simultaneously, Chameleon
employs a beamformer switching interval of only 0.24 {\mu}s, therefore
producing a 31x31-point 2D imaging within just 0.875 ms. Leveraging machine
learning, Chameleon further enables object localization with median errors of
0.14 m (distance) and 0.24{\deg} (angle), and material classification with
99.0% accuracy.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [83] [Nonlinear Cooperative Salvo Guidance with Seeker-Limited Interceptors](https://arxiv.org/abs/2509.15136)
*Lohitvel Gopikannan,Shashi Ranjan Kumar,Abhinav Sinha*

Main category: eess.SY

TL;DR: 提出了一种协同制导策略，用于同时拦截匀速非机动目标，解决了部分拦截器无探测器的现实问题，通过固定时间分布式观测器和高阶滑模一致性协议实现目标状态估计和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决部分拦截器缺乏探测器导致的目标观测异质性问题，提升拦截效率。

Method: 采用固定时间分布式观测器和高阶滑模一致性协议，结合偏航制导策略。

Result: 仿真验证了所提架构的有效性。

Conclusion: 该策略在部分拦截器无探测器的情况下仍能高效协同拦截目标。

Abstract: This paper presents a cooperative guidance strategy for the simultaneous
interception of a constant-velocity, non-maneuvering target, addressing the
realistic scenario where only a subset of interceptors are equipped with
onboard seekers. To overcome the resulting heterogeneity in target
observability, a fixed-time distributed observer is employed, enabling
seeker-less interceptors to estimate the target state using information from
seeker-equipped agents and local neighbors over a directed communication
topology. Departing from conventional strategies that approximate time-to-go
via linearization or small-angle assumptions, the proposed approach leverages
deviated pursuit guidance where the time-to-go expression is exact for such a
target. Moreover, a higher-order sliding mode consensus protocol is utilized to
establish time-to-go consensus within a finite time. The effectiveness of the
proposed guidance and estimation architecture is demonstrated through
simulations.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [84] [How Does Instrumental Music Help SingFake Detection?](https://arxiv.org/abs/2509.14675)
*Xuanjun Chen,Chia-Yu Hu,I-Ming Lin,Yi-Cheng Lin,I-Hsiang Chiu,You Zhang,Sung-Feng Huang,Yi-Hsuan Yang,Haibin Wu,Hung-yi Lee,Jyh-Shing Roger Jang*

Main category: cs.SD

TL;DR: 论文研究了乐器伴奏对歌唱声音深度伪造检测的影响，发现伴奏主要起到数据增强作用，而非提供内在线索；微调会模型更依赖浅层说话人特征。


<details>
  <summary>Details</summary>
Motivation: 探讨乐器伴奏如何影响歌唱声音深度伪造检测模型的行为和表现，以提升模型的解释性和鲁棒性。

Method: 通过测试不同主干网络、未配对的乐器音轨和频率子带来研究行为影响；通过分析微调对编码器语音和音乐能力的影响来研究表现影响。

Result: 乐器伴奏主要起数据增强作用；微调增加对浅层说话人特征的依赖，降低对内容、副语言和语义信息的敏感性。

Conclusion: 研究阐明了模型如何利用声音和乐器线索，为设计更可解释和鲁棒的检测系统提供了指导。

Abstract: Although many models exist to detect singing voice deepfakes (SingFake), how
these models operate, particularly with instrumental accompaniment, is unclear.
We investigate how instrumental music affects SingFake detection from two
perspectives. To investigate the behavioral effect, we test different
backbones, unpaired instrumental tracks, and frequency subbands. To analyze the
representational effect, we probe how fine-tuning alters encoders' speech and
music capabilities. Our results show that instrumental accompaniment acts
mainly as data augmentation rather than providing intrinsic cues (e.g., rhythm
or harmony). Furthermore, fine-tuning increases reliance on shallow speaker
features while reducing sensitivity to content, paralinguistic, and semantic
information. These insights clarify how models exploit vocal versus
instrumental cues and can inform the design of more interpretable and robust
SingFake detection systems.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [85] [Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space](https://arxiv.org/abs/2509.14905)
*Wenyan Ma,Lipeng Zhu,Rui Zhang*

Main category: cs.IT

TL;DR: 提出了一种基于可移动天线（MA）的新型无线感知系统，通过优化天线轨迹显著提升了角度到达（AoA）估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定天线（FPA）在感知性能上存在局限，通过MA的动态移动可以提升角度估计精度。

Method: 推导了1D和2D天线移动的CRB，提出全局最优轨迹（1D）和交替优化算法（2D）来最小化估计误差。

Result: 与FPA相比，MA方案显著降低了CRB和实际AoA估计误差，并提高了角度分辨率。

Conclusion: MA轨迹设计和优化是提升无线感知性能的有效途径，尤其在时间和空间约束下表现出色。

Abstract: In this paper, we present a new wireless sensing system utilizing a movable
antenna (MA) that continuously moves and receives sensing signals to enhance
sensing performance over the conventional fixed-position antenna (FPA) sensing.
We show that the angle estimation performance is fundamentally determined by
the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square
error (MSE) for angle-of-arrival (AoA) estimation as a function of the
trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna
movement. For the 1D case, a globally optimal trajectory that minimizes the CRB
is derived in closed form. Notably, the resulting CRB decreases cubically with
sensing time in the time-constrained regime, whereas it decreases linearly with
sensing time and quadratically with the movement line segment's length in the
space-constrained regime. For the 2D case, we aim to achieve the minimum of
maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the
horizontal and vertical axes. To this end, we design an efficient alternating
optimization algorithm that iteratively updates the MA's horizontal or vertical
coordinates with the other being fixed, yielding a locally optimal trajectory.
Numerical results show that the proposed 1D/2D MA-based sensing schemes
significantly reduce both the CRB and actual AoA estimation MSE compared to
conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as
well as various benchmark MA trajectories. Moreover, it is revealed that the
steering vectors of our designed 1D/2D MA trajectories have low correlation in
the angular domain, thereby effectively increasing the angular resolution for
achieving higher AoA estimation accuracy.

</details>


### [86] [Version Age of Information with Contact Mobility in Gossip Networks](https://arxiv.org/abs/2509.15184)
*Irtiza Hasan,Ahmed Arafa*

Main category: cs.IT

TL;DR: 研究分析了在八卦网络中接触移动性对信息新鲜度的影响，并通过优化移动成本证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨移动节点对八卦网络中信息传播的影响，以提升节点信息的新鲜度。

Method: 使用随机混合系统（SHS）框架分析不同拓扑和移动性规模，并结合优化问题最小化版本年龄和移动成本的加权和。

Result: 接触移动性显著提高了网络的信息新鲜度，尤其是在完全连接和完全断开网络中。

Conclusion: 优化的移动性策略可以显著改善八卦网络中的信息传播效率。

Abstract: A gossip network is considered in which a source node updates its status
while other nodes in the network aim at keeping track of it as it varies over
time. Information gets disseminated by the source sending status updates to the
nodes, and the nodes gossiping with each other. In addition, the nodes in the
network are mobile, and can move to other nodes to get information, which we
term contact mobility. The goal for the nodes is to remain as fresh as
possible, i.e., to have the same information as the source's. To evaluate the
freshness of information, we use the Version Age-of-Information (VAoI) metric,
defined as the difference between the version of information available at a
given node and that at the source. We analyze the effect of contact mobility on
information dissemination in the gossip network using a Stochastic Hybrid
System (SHS) framework for different topologies and mobility scalings with
increasing number of nodes. It is shown that with the presence of contact
mobility the freshness of the network improves in both ends of the network
connectivity spectrum: disconnected and fully connected gossip networks. We
mathematically analyze the average version age scalings and validate our
theoretical results via simulations. Finally, we incorporate the cost of
mobility for the network by formulating and solving an optimization problem
that minimizes a weighted sum of version age and mobility cost. Our results
show that contact mobility, with optimized mobility cost, improves the average
version age in the network.

</details>
