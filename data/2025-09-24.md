<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 17]
- [cs.RO](#cs.RO) [Total: 55]
- [cs.LG](#cs.LG) [Total: 3]
- [math.OC](#math.OC) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [eess.SY](#eess.SY) [Total: 5]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [math.NA](#math.NA) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [On Multi-entity, Multivariate Quickest Change Point Detection](https://arxiv.org/abs/2509.18310)
*Bahar Kor,Bipin Gaikwad,Abani Patra,Eric L. Miller*

Main category: eess.SP

TL;DR: 提出了一个在线变化点检测（CPD）框架，适用于多实体多元时间序列数据，解决了复杂动态环境中系统级行为变化的检测问题。


<details>
  <summary>Details</summary>
Motivation: 传统监测方法（如视频监控）可能不可行，需在不依赖标注数据或特征提取的情况下检测系统范围内的行为变化。

Method: 通过基于重构误差的自编码器计算个体偏离正常值（IDfN），聚合为系统级异常分数（SWAS），并使用统计偏差度量和CUSUM技术检测变化。

Result: 在合成数据集和人群模拟中验证了方法的有效性，能准确检测系统级变化，并提供可扩展且保护隐私的解决方案。

Conclusion: 该框架为复杂多智能体系统的监测提供了新方法，并填补了公开数据集的空白。

Abstract: We propose a framework for online Change Point Detection (CPD) from
multi-entity, multivariate time series data, motivated by applications in crowd
monitoring where traditional sensing methods (e.g., video surveillance) may be
infeasible. Our approach addresses the challenge of detecting system-wide
behavioral shifts in complex, dynamic environments where the number and
behavior of individual entities may be uncertain or evolve. We introduce the
concept of Individual Deviation from Normality (IDfN), computed via a
reconstruction-error-based autoencoder trained on normal behavior. We aggregate
these individual deviations using mean, variance, and Kernel Density Estimates
(KDE) to yield a System-Wide Anomaly Score (SWAS). To detect persistent or
abrupt changes, we apply statistical deviation metrics and the Cumulative Sum
(CUSUM) technique to these scores. Our unsupervised approach eliminates the
need for labeled data or feature extraction, enabling real-time operation on
streaming input. Evaluations on both synthetic datasets and crowd simulations,
explicitly designed for anomaly detection in group behaviors, demonstrate that
our method accurately detects significant system-level changes, offering a
scalable and privacy-preserving solution for monitoring complex multi-agent
systems. In addition to this methodological contribution, we introduce new,
challenging multi-entity multivariate time series datasets generated from crowd
simulations in Unity and coupled nonlinear oscillators. To the best of our
knowledge, there is currently no publicly available dataset of this type
designed explicitly to evaluate CPD in complex collective and interactive
systems, highlighting an essential gap that our work addresses.

</details>


### [2] [Multi-Target Detection for Cognitive MIMO Radar Networks](https://arxiv.org/abs/2509.18381)
*Nicholas L. K. Goradia,Harpreet S. Dhillon,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 本文开发了集中式和分散式信号融合技术，用于未知噪声和杂波分布下的CFAR多目标检测，并首次提出了一种适用于共置单基地MIMO雷达的检测统计量。通过强化学习提高多目标检测性能，并推广到认知雷达网络中。


<details>
  <summary>Details</summary>
Motivation: 为了解决未知噪声和杂波分布下的多目标检测问题，并探索雷达网络中的协作检测性能平衡。

Method: 开发集中式和分散式信号融合技术，提出一种新的检测统计量并验证其有效性；利用强化学习优化目标检测；推广到认知雷达网络中。

Result: 证明了空间和时间域之间的权衡关系，展示了认知雷达网络中集中式和分散式检测的优势与权衡。

Conclusion: 本文提出的方法和理论为未知噪声和杂波分布下的CFAR多目标检测提供了有效解决方案，并通过雷达网络协作进一步优化了性能。

Abstract: In this work, we develop centralized and decentralized signal fusion
techniques for constant false alarm rate (CFAR) multi-target detection with a
cognitive radar network in unknown noise and clutter distributions. Further, we
first develop a detection statistic for co-located monostatic MIMO radar in
unknown noise and clutter distributions which is asymptotically CFAR as the
number of received pulses over all antennas grows large, and we provide
conditions under which this detection statistic is valid. We leverage
reinforcement learning (RL) for improved multi-target detection performance,
where the radar learns likely target locations in a search area. These results
are then generalized to the setting of cognitive radar networks, where radars
collaborate to learn where targets are likely to appear in a search area. We
show a fundamental tradeoff between the spatial and temporal domain for CFAR
detection in unknown noise and clutter distributions; in other words, we show a
tradeoff between the number of radar antennas and the number of temporal
samples. We show the benefits and tradeoffs with centralized and decentralized
detection with a network of cognitive radars.

</details>


### [3] [Automatic Model Extraction of the Match Standard in Symmetric--Reciprocal--Match Calibration](https://arxiv.org/abs/2509.18426)
*Ziad Hatab,Michael Ernst Gadringer,Arash Arsanjani,Wolfgang Boesch*

Main category: eess.SP

TL;DR: 本文提出了一种用于矢量网络分析仪对称互易匹配校准中寄生参数的建模方法，通过非线性全局优化实现频率相关模型。数值测试验证了其有效性，并与传统方法进行了对比。


<details>
  <summary>Details</summary>
Motivation: 研究对称互易匹配校准中寄生参数建模问题，解决传统方法中对匹配标准完全已知的假设限制。

Method: 采用非线性全局优化程序对匹配标准进行任意频率相关建模，并通过数值测试和微带线测量验证。

Result: 数值测试表明该方法能精确恢复寄生模型；实测数据表明其精度与传统TRL校准相当。

Conclusion: 提出的自动模型提取方法在精度上与传统TRL校准相当，为寄生建模提供了有效解决方案。

Abstract: This paper addresses the modeling of parasitics of the match standard in the
symmetric-reciprocal-match (SRM) calibration method of vector network analyzers
(VNAs). In the general SRM procedure, the match standard is assumed to be fully
known. Here, we demonstrate that the match can be modeled with an arbitrary
frequency-dependent model using a non-linear global optimization procedure. To
highlight the validity of the suggested approach, numerical tests were
conducted, demonstrating the ability to recover the match standard parasitic
model down to software numerical precision. Additionally, we performed
microstrip line measurements to compare the SRM calibration with match modeling
to the multiline thru-reflect-line (TRL) calibration one, showing that
automatic model extraction can achieve accuracy similar to using a match
standard defined through multiline TRL calibration.

</details>


### [4] [A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems](https://arxiv.org/abs/2509.18555)
*Ping Wang,Zulin Wang,Yuanfang Ma,Xiaosi Tian,Yuanhan Ni*

Main category: eess.SP

TL;DR: 这篇论文提出了一种安全的仿射频分复用（SE-AFDM）技术，用于增强无线通信系统的安全性。通过配置参数c1和时变参数c2，既保证了通信可靠性，又提升了安全性。理论分析表明，窃听者无法分离时变的c2和随机信息符号，导致其误码率性能严重下降。数值结果验证了SE-AFDM在高移动性场景中既有良好的误码率性能，又能显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的无线通信系统在高移动性场景下面临安全性挑战，尤其是如何在不牺牲可靠性的情况下增强通信安全。

Method: 作者提出了一种SE-AFDM技术，结合参数c1（确保可靠性）和时变参数c2（增强安全性），并通过理论推导和数值模拟验证其性能。

Result: 结果表明，合法接收者可以消除c2的非线性影响，而窃听者因无法分离c2和信息符号，误码率性能大幅下降。此外，窃听者的信干噪比（SINR）随c2值范围的扩大而降低。

Conclusion: SE-AFDM在高移动性场景中既能保持低误码率，又能显著提升通信安全性，是一种有潜力的解决方案。

Abstract: This paper introduces a secure affine frequency division multiplexing
(SE-AFDM) for wireless communication systems to enhance communication security.
Besides configuring the parameter c1 to obtain communication reliability under
doubly selective channels, we also utilize the time-varying parameter c2 to
improve the security of the communications system. The derived input-output
relation shows that the legitimate receiver can eliminate the nonlinear impact
introduced by the time-varying c2 without losing the bit error rate (BER)
performance. Moreover, it is theoretically proved that the eavesdropper cannot
separate the time-varying c2 and random information symbols, such that the BER
performance of the eavesdropper is severely deteriorated. Meanwhile, the
analysis of the effective signal-to-interference-plus-noise ratio (SINR) of the
eavesdropper illustrates that the SINR decreases as the value range of c2
expands. Numerical results verify that the proposed SE-AFDM waveform has
significant security while maintaining good BER performance in high-mobility
scenarios.

</details>


### [5] [Integrated Cellular and LEO-based Positioning and Synchronization under User Mobility](https://arxiv.org/abs/2509.18727)
*Yasaman Ettefagh,Sharief Saleh,Musa Furkan Keskin,Hui Chen,Gonzalo Seco-Granados,Henk Wymeersch*

Main category: eess.SP

TL;DR: 本文研究了在整合地面与非地面网络（如低地球轨道卫星）的情况下，对移动用户设备进行定位、同步和速度估计的方法，重点关注仅从一个基站和一颗LEO卫星接收信号的简单场景。


<details>
  <summary>Details</summary>
Motivation: 随着6G技术的发展，整合地面与非地面网络的需求日益增长，尤其是在移动场景下的定位与同步性能优化。

Method: 作者提出了一套考虑移动性、时钟和频率偏移的通用信号模型，并基于此开发了不同计算复杂度的简化模型和估计算法。

Result: 通过严格的仿真验证了所提模型的有效性，展示了其在不同场景下的适用性。

Conclusion: 研究表明，在复杂性与性能之间可以针对不同部署环境和应用需求进行优化，为6G移动场景下的定位与同步系统提供了重要参考。

Abstract: This paper investigates the localization, synchronization, and speed
estimation of a mobile user equipment (UE) leveraging integrated terrestrial
and non-terrestrial networks (NTNs), in particular low Earth orbit (LEO)
satellites. We focus on a minimal setup in which the UE received signal from
only one base station (BS) and one LEO satellite. We derive a generic signal
model accounting for mobility, clock and frequency offsets, based on which a
hierarchy of simplified models are proposed and organized by computational
complexity. Estimation algorithms are developed for each model to facilitate
efficient and accurate parameter recovery. Rigorous simulations validate the
effectiveness of the proposed models, demonstrating their suitability across
diverse scenarios. The findings highlight how the trade-off between complexity
and performance can be optimized for varying deployment environments and
application requirements, offering valuable insights for 6G positioning and
synchronization systems under user mobility.

</details>


### [6] [Detection Capability Comparison Between Intensity Detection and Splitting Detection for Rydberg-Atomic Sensors](https://arxiv.org/abs/2509.18753)
*Hao Wu,Xinyuan Yao,Rui Ni,Chen Gong,Kaibin Huang*

Main category: eess.SP

TL;DR: 该论文系统地分类和建模了Rydberg原子量子接收器的两种信号读出方案（强度检测和分裂检测），并提出了基于最大似然估计的优化策略，显著降低了估计方差。


<details>
  <summary>Details</summary>
Motivation: Rydberg原子量子接收器因其高灵敏度在多频段通信接收中具有潜力，但其独特的物理特性需要更深入的系统性研究以优化信号读出方法。

Method: 通过最大似然估计和Cramér-Rao下界（CRLB）分析，提出了两种信号读出方案的优化策略：在斜率最大区域采集数据。

Result: 非均匀频率扫描结合最大似然分裂估计方法显著降低了估计方差，优于传统的多项式拟合方法。

Conclusion: 该研究不仅优化了两种信号读出方案的性能，还提升了微波校准的准确性，为Rydberg接收器的实际应用提供了理论基础。

Abstract: Rydberg atomic quantum receivers have been seen as novel radio frequency
measurements and the high sensitivity to a large range of frequencies makes it
attractive for communications reception. However, their unique physical
characteristics enable two fundamental signal readout schemes: intensity-based
detection and splitting-based detection. The former measures the electric
fields through laser intensity, while the latter utilizes Autler-Townes
splitting. In this work, we systematically categorize and model existing signal
readout methods, classifying them into these two paradigms. Then, we derive the
maximum likelihood estimation procedures and corresponding Cram\'er-Rao lower
bounds (CRLB) for each detection modality. Through the analysis of the CRLB, we
propose strategy for both readout schemes to enhance sensitivity and minimize
estimation variance: acquiring data in regions with maximal slope magnitudes.
While this approach has been implemented in intensity-based detection (e.g.,
superheterodyne schemes), its application to splitting-based detection remains
unexplored. Implementation of non-uniform frequency scanning, with preferential
sampling at regions exhibiting maximum peak slopes combined with our proposed
maximum likelihood splitting estimation method, achieves significantly reduced
estimation variance compared to conventional polynomial fitting. The
comparative analysis reveals the optimal detection performance of the two
detection schemes. This work also contributes to enhancing the accuracy of
microwave calibration. Numerical results reveal that both fundamental signal
readout methods achieve lower estimation variance based on our proposed maximum
likelihood estimation approach.

</details>


### [7] [Highly Parallel Singular Value Decomposition for Low-Latency MIMO Processing](https://arxiv.org/abs/2509.18799)
*Sijia Cheng,Liang Liu,Ove Edfors,Juan Vidal Alegria*

Main category: eess.SP

TL;DR: 论文分析了SVD在无线系统中的计算延迟问题，提出了一种高效的并行方法，并通过硬件评测验证其在大规模MIMO场景中的时间效率。


<details>
  <summary>Details</summary>
Motivation: 由于传统的SVD方法在处理大规模系统时延迟高，无法满足实时和低延迟应用的需求，论文旨在解决这一问题。

Method: 论文提出了一种基于Gram矩阵三对角化的4步高效并行方法，并开发了一个结合硬件评测的时间复杂度分析框架。

Result: 数值结果表明，该方法在大规模MIMO场景中具有显著的时间效率优势。

Conclusion: 该并行方法为SVD在实时和低延迟应用中的部署提供了可行的解决方案。

Abstract: Singular value decomposition (SVD) is widely used in wireless systems,
including multiple-input multiple-output (MIMO) processing and dimension
reduction in distributed MIMO (D-MIMO). However, the iterative nature of
decomposition methods results in increased execution time as system size grows,
posing challenges for real-time and low-latency applications. To address this,
we analyze the latency of state-of-art SVD methods, and highlight the
efficiency of a 4-step highly parallel method based on Gram matrix
tridiagonalization. Furthermore, we develop a time complexity (processing
latency) analysis framework with hardware profiling, allowing scalable and
realistic evaluation without full implementation. The numerical results
demonstrate the superior time efficiency of the selected parallel method,
particularly in massive MIMO scenarios.

</details>


### [8] [Normal mode parameters estimation by a VLA in single-shooting](https://arxiv.org/abs/2509.18853)
*Xiaolei Li,Pengyu Wang,Wenhua Song,Yangjin Xu,Wei Gao*

Main category: eess.SP

TL;DR: 本文提出了一种基于正交性约束的模态搜索方法（OCMS），用于通过垂直线性阵列（VLA）估计模态波数及模态深度函数。该方法在已知声速剖面下表现稳健，并通过实验数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在已知声速剖面的情况下，高效且鲁棒地估计模态波数和模态深度函数，同时解决VLA在不同条件下的性能挑战。

Method: 利用模态深度函数的正交性约束，提出OCMS方法，通过VLA提取模态参数，并在数值模拟和实验数据中验证其性能。

Result: OCMS对噪声、VLA孔径变化及元素数量变化具有鲁棒性；在SSP不确定度小于1 m/s且VLA倾角小于5度时表现可靠；实验数据与理论计算结果误差为10^-4量级。

Conclusion: OCMS方法在多种条件下均可有效估计模态参数，为海洋声学中的模态分析提供了可靠工具。

Abstract: This paper proposes an orthogonality-constrained modal search (OCMS) method
for estimating modal wavenumbers and modal depth functions using a vertical
linear array (VLA). Under the assumption of a known sound speed profile, OCMS
leverages the orthogonality of distinct modal depth functions to extract both
the modal depth functions and their corresponding wavenumbers, even when the
VLA and a monochromatic sound source remain stationary.The performance of OCMS
is evaluated through numerical simulations under varying signal-to-noise ratios
(SNRs), different VLA apertures, varying numbers of VLA elements, VLA tilt and
sound speed profile (SSP) uncertainty. The results demonstrate that OCMS is
robust against noise, VLA aperture variations, and changes in the number of VLA
elements, meanwhile, the algorithm maintains reliable performance when SSP
uncertainty < 1 m/s and VLA tilt angle <5{\deg}. Furthermore, the effectiveness
of OCMS is validated using SwellEx96 experimental data. The relative error
between the modal wavenumbers derived from experimental data and those computed
via Kraken is on the order of $10^{-4}$.

</details>


### [9] [Quaternion LMS for Graph Signal Recovery](https://arxiv.org/abs/2509.18918)
*Hamideh-Sadat Fazael-Ardekani,Hadi Zayyani,Hamid Soltanian-Zadeh*

Main category: eess.SP

TL;DR: 本文提出了一种名为QGLMS的新算法，将图信号恢复问题扩展到了四元数领域，并进行了收敛性分析，验证了算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决图信号处理中的信号恢复问题，尤其是在四元数领域的应用，通过扩展QLMS和GLMS算法来开发新的算法。

Method: 提出了基于四元数代数的QGLMS算法，并推导了其适应公式，同时进行了均值和均方收敛分析。

Result: 模拟结果验证了QGLMS算法在图信号重建中的有效性，并提出了一种关于步长参数的充分条件。

Conclusion: QGLMS算法在图信号处理中表现出良好的性能，为进一步研究四元数图信号处理提供了基础。

Abstract: This letter generalizes the Graph Signal Recovery (GSR) problem in Graph
Signal Processing (GSP) to the Quaternion domain. It extends the Quaternion
Least Mean Square (QLMS) in adaptive filtering literature, and Graph LMS (GLMS)
algorithm in GSP literature, to an algorithm called Quaternion GLMS (QGLMS).
The basic adaptation formula using Quaternion-based algebra is derived.
Moreover, mean convergence analysis and mean-square convergence analysis are
mathematically performed. Hence, a sufficient condition on the step-size
parameter of QGLMS is suggested. Also, simulation results demonstrate the
effectiveness of the proposed algorithm in graph signal reconstruction.

</details>


### [10] [Bayesian Convolutional Neural Networks for Prior Learning in Graph Signal Recovery](https://arxiv.org/abs/2509.19056)
*Razieh Torkamani,Arash Amini,Hadi Zayyani,Mehdi Korki*

Main category: eess.SP

TL;DR: 论文提出了一种基于贝叶斯卷积神经网络的数据驱动框架，用于学习图信号的先验分布，并通过变分贝叶斯推理实现高效准确的图信号恢复。


<details>
  <summary>Details</summary>
Motivation: 图信号恢复的核心挑战是信号统计模型往往未知或复杂难描述，现有方法难以泛化到复杂的非高斯信号模型。

Method: 使用基于切比雪夫多项式的图感知滤波器构建贝叶斯卷积神经网络（BCNN），将隐藏层解释为吉布斯分布并结合高斯混合模型非线性，形成闭合形式的先验表达。

Result: 实验表明，BCNN-GSR算法在不同信号分布下均能实现准确且鲁棒的恢复，尤其适用于复杂非高斯信号模型。

Conclusion: 该方法具有计算高效性和良好泛化能力，适用于大规模实际图恢复任务。

Abstract: Graph signal recovery (GSR) is a fundamental problem in graph signal
processing, where the goal is to reconstruct a complete signal defined over a
graph from a subset of noisy or missing observations. A central challenge in
GSR is that the underlying statistical model of the graph signal is often
unknown or too complex to specify analytically. To address this, we propose a
flexible, data-driven framework that learns the signal prior directly from
training samples. We develop a Bayesian convolutional neural network (BCNN)
architecture that models the prior distribution of graph signals using
graph-aware filters based on Chebyshev polynomials. By interpreting the hidden
layers of the CNN as Gibbs distributions and employing Gaussian mixture model
(GMM) nonlinearities, we obtain a closed-form and expressive prior. This prior
is integrated into a variational Bayesian (VB) inference framework to estimate
the posterior distribution of the signal and noise precision. Extensive
experiments on synthetic and real-world graph datasets demonstrate that the
proposed BCNN-GSR algorithm achieves accurate and robust recovery across a
variety of signal distributions. The method generalizes well to complex,
non-Gaussian signal models and remains computationally efficient, making it
suitable for practical large-scale graph recovery tasks.

</details>


### [11] [Data-Free Knowledge Distillation for LiDAR-Aided Beam Tracking in MmWave Systems](https://arxiv.org/abs/2509.19092)
*Abolfazl Zakeri,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 论文提出了一种无需真实数据（DF）的知识蒸馏（KD）框架，通过生成合成数据来优化LiDAR辅助的毫米波波束跟踪，减少了机器学习复杂性和数据需求。


<details>
  <summary>Details</summary>
Motivation: 多模态感知虽然能减少波束训练的开销，但受限于机器学习复杂性和数据集需求。为了解决这一问题，研究者提出了无需真实数据的知识蒸馏框架。

Method: 采用知识反转框架，通过生成器从随机噪声合成LiDAR输入数据，利用预训练教师模型的输出和特征定义损失函数。学生模型则通过合成数据和教师模型的知识进行训练。

Result: 实验表明，所提出的DF-KD框架在Top-1和Top-5准确率上略优于教师模型，且元数据损失对生成器性能贡献显著。

Conclusion: 该方法不仅减少了数据依赖性，还优化了学生模型的训练过程，展示了在波束跟踪任务中的潜力。

Abstract: Multimodal sensing reduces beam training overhead but is constrained by
machine learning complexity and dataset demands. To address this, we propose a
data-free (DF) knowledge distillation (KD) framework for efficient LiDAR-aided
mmWave beam tracking, i.e., predicting the best current and future beams.
Specifically, we propose a knowledge inversion framework, where a generator
synthesizes LiDAR input data from random noise, guided by a loss function
defined on the features and outputs of a pre-trained teacher model. The student
model is then trained using the synthetic data and knowledge distilled from the
teacher. The generator loss combines three terms, called metadata loss,
activation loss, and entropy loss. For student training, in addition to the
standard Kullback-Leibler divergence loss, we also consider a mean-squared
error (MSE) loss between the teacher and student logits. Simulation results
show that the proposed DF-KD (slightly) outperforms the teacher in Top-1 and
Top-5 accuracies. Moreover, we observe that the metadata loss contributes
significantly to the generator performance, and that the MSE loss for the
student can effectively replace the standard KD loss while requiring fewer
fine-tuned hyperparameters.

</details>


### [12] [Enabling Drone Detection with SWARM Repeater-Assisted MIMO ISAC](https://arxiv.org/abs/2509.19119)
*Palatip Jopanya,Diana P. M. Osorio*

Main category: eess.SP

TL;DR: 本文探讨了通过部署中继器群组实现成本高效的蜂窝网络密集化，并研究了其在MIMO ISAC系统中增强雷达探测能力的效果。


<details>
  <summary>Details</summary>
Motivation: 随着ISAC的新架构、用例和标准的出现，蜂窝系统通过新型网络组件的集成支持新兴用例，本文旨在探索中继器群组在增强系统感知性能方面的潜力。

Method: 利用中继器即时重传信号的能力，研究其在MIMO ISAC系统中如何优化中继器增益以提升无人机探测能力。

Result: 结果表明，在足够大的最大增益下，增加中继器数量可以显著提升系统的感知性能。

Conclusion: 通过优化中继器增益和数量，可以显著提升MIMO ISAC系统的感知性能，为未来网络密集化提供有效解决方案。

Abstract: As definitions about new architectural aspects, use cases, and standards for
integrated sensing and communication (ISAC) continue to appear, cellular
systems based on massive multiple-input multiple-output (MIMO) antenna
technology are also experiencing a parallel evolution through the integration
of novel network components. This evolution should support emerging ISAC use
cases and services. In particular, this paper explores a recent vision for
cost-efficient cellular network densification through the deployment of swarms
of repeaters. Leveraging their ability to retransmit signals instantaneously,
we investigate how these repeaters can enhance radar sensing capabilities for
drone detection in a swarm repeater-assisted MIMO ISAC system. Our results
demonstrate that, by optimizing the gains of repeaters given a sufficient
maximum amplification gain, increasing the number of repeaters can lead to
gains in sensing performance.

</details>


### [13] [Deep Reinforcement Learning for Dynamic Sensing and Communications](https://arxiv.org/abs/2509.19130)
*Abolfazl Zakeri,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 提出了一种统一的机器学习框架，动态决定何时进行环境感知，并利用感知数据进行波束预测，以减少感知开销并保持通信性能。


<details>
  <summary>Details</summary>
Motivation: 通过环境感知辅助毫米波通信中的波束训练，但需要在感知成本和性能之间找到平衡。

Method: 联合感知和波束成形问题，使用Lyapunov优化强制感知约束，深度Q网络决定感知时机，预训练的深度神经网络映射感知数据到最优波束。

Result: 基于DeepSense数据集的仿真表明，提出的方法显著降低了感知开销，同时保持了满意的通信性能。

Conclusion: 框架有效平衡了感知成本和通信性能，为毫米波通信中的动态感知提供了可行方案。

Abstract: Environmental sensing can significantly enhance mmWave communications by
assisting beam training, yet its benefits must be balanced against the
associated sensing costs. To this end, we propose a unified machine learning
framework that dynamically determines when to sense and leverages sensory data
for beam prediction. Specifically, we formulate a joint sensing and beamforming
problem that maximizes the av- erage signal-to-noise ratio under an average
sensing budget. Lyapunov optimization is employed to enforce the sensing
constraint, while a deep Q-Network determines the sensing slots. A pretrained
deep neural network then maps the sens- ing data to optimal beams in the
codebook. Simulations based on the real-world DeepSense dataset demonstrate
that the pro- posed approach substantially reduces sensing overhead while
maintaining satisfactory communications performance.

</details>


### [14] [On the Performance of THz Wireless Systems over $α$-$\mathcal{F}$ Channels with Beam Misalignment and Mobility](https://arxiv.org/abs/2509.19235)
*Wamberto J. L. Queiroz,Hugerles S. Silva,Higo T. P. Silva,Alexandros-Apostolos A. Boulogeorgos*

Main category: eess.SP

TL;DR: 该论文研究了太赫兹无线系统在α-F衰落信道中的性能，分析了波束未对准和移动性的影响，推导了新的统计表达式，并提出了性能指标，通过蒙特卡洛仿真验证。


<details>
  <summary>Details</summary>
Motivation: 研究太赫兹无线系统在复杂信道条件下的性能表现，尤其是波束未对准和移动性对通信质量的影响。

Method: 推导了信号噪声比的概率密度、累积分布及矩生成函数等新表达式，并基于这些表达式计算了中断概率、符号错误概率和平均信道容量等指标。

Result: 提出了渐近性能指标，并通过蒙特卡洛仿真验证了分析框架的有效性。

Conclusion: 该研究为太赫兹无线系统在α-F衰落信道中的性能分析提供了理论支持，对实际系统设计具有指导意义。

Abstract: This paper investigates the performance of terahertz~(THz) wireless systems
over the $\alpha$-$\mathcal{F}$ fading channels with beam misalignment and
mobility. New expressions are derived for the probability density, cumulative
distribution, and moment generating functions, as well as higher-order moments
of the instantaneous signal-to-noise ratio. Building upon the aforementioned
expressions, we extract novel formulas for the outage probability, symbol error
probability, and average channel capacity. Asymptotic metrics are also deduced,
which provide useful insights. Monte Carlo simulations results are presented to
support the derived analytical framework.

</details>


### [15] [Faster-Than-Nyquist Signalling - Theoretical Limits on Capacity and Techniques to Approach Capacity](https://arxiv.org/abs/2509.19272)
*Sathwik Chadaga*

Main category: eess.SP

TL;DR: 论文研究了FTN信号中的ISI问题，提出了避免ISI的脉冲形状和时间加速因子条件，并通过理论容量界限进行了验证。此外，还探讨了功率分配和自适应加载技术在OFDM FTN系统中降低ISI和提高吞吐量的应用。


<details>
  <summary>Details</summary>
Motivation: FTN信号传输方案因其非正交性可以提供比Nyquist方案更高的吞吐量和频谱效率，但其带来的ISI问题需要解决。

Method: 研究了FTN信号中ISI的条件，推导了避免ISI的脉冲形状和时间加速因子要求，并通过理论容量分析验证。同时探索了功率分配和自适应加载技术在OFDM FTN系统中的应用。

Result: 提出了避免ISI的具体条件，并通过仿真展示了功率分配和自适应加载技术在减少ISI和提高系统吞吐量方面的有效性。

Conclusion: FTN信号传输方案在合理设计条件下可以有效避免ISI，并通过优化技术进一步提升系统性能。

Abstract: Faster-Than-Nyquist (FTN) Signalling is a non-orthogonal transmission scheme
that violates the Nyquist zero-ISI criterion providing higher throughput and
better spectral efficiency than a Nyquist transmission scheme. In this thesis,
the inter symbol interference (ISI) introduced by FTN signalling is studied,
and conditions on pulse shapes and $\tau$ (time acceleration factor) are
derived so that the ISI can be avoided completely. Further, these conditions
are reinforced by investigating the theoretical limits on the capacities of FTN
systems. Finally, the use of power allocation and adaptive loading techniques
are explored in reducing the effect of ISI and increasing the throughput of
orthogonal frequency division multiplexing (OFDM) FTN systems. The
implementation of these techniques and simulation results are also
demonstrated.

</details>


### [16] [A Novel Site-Specific Inference Model for Urban Canyon Channels: From Measurements to Modeling](https://arxiv.org/abs/2509.19275)
*Junzhe Song,Ruisi He,Mi Yang,Zhengyu Zhang,Xinwen Chen,Xiaoying Zhang,Bo Ai*

Main category: eess.SP

TL;DR: 该论文提出了一种基于环境几何的特定站点信道推断模型，通过亚6GHz信道测量参数化，并验证了模型在不同城市峡谷场景中的高准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着智能交通和智慧城市应用的快速发展，城市峡谷成为无线通信系统设计和评估的重要场景。由于现有信道模型未充分捕捉其独特的信道特性，需要一种更精确的模型。

Method: 提出了一种基于环境几何的信道推断模型，通过亚6GHz信道测量参数化，多径分量（MPCs）根据几何传播提取和聚类，建立物理环境与MPCs统计特性的可解释映射。

Result: 通过比较模型和实测信道的二阶统计特性，验证了模型在不同城市峡谷场景中的高准确性和鲁棒性。

Conclusion: 该研究为城市峡谷场景的信道建模提供了一种高精度且鲁棒的方法，填补了现有模型的不足。

Abstract: With the rapid development of intelligent transportation and smart city
applications, urban canyon has become a critical scenario for the design and
evaluation of wireless communication systems. Due to its unique environmental
layout, the channel characteristics in urban canyon are strongly a street
geometry and building distribution, thereby exhibiting significant
site-specific channel condition. However, this feature has not been well
captured in existing channel models. In this paper, we propose a site-specific
channel inference model based on environmental geometry, the model is
parameterized using sub-6GHz channel measurements. Multipath components (MPCs)
are extracted and clustered according to geometric propagation, which are
explicitly derived from the influence of canyon width, thereby establishing an
interpretable mapping between the physical environment and statistical
characteristics of MPCs. A step-by-step implementation scheme is presented.
Subsequently, the proposed site-specific channel inference model is validated
by comparing second-order statistics of channels, derived from the model and
measurements. The results show that the proposed model achieves high accuracy
and robustness in different urban canyon scenarios.

</details>


### [17] [STFT-AECNN: An Attention-Enhanced CNN for Efficient Φ-OTDR Event Recognition in IoT-Enabled Distributed Acoustic Sensing](https://arxiv.org/abs/2509.19281)
*Xiyang Lan,Xin Li*

Main category: eess.SP

TL;DR: 提出STFT-AECNN模型，结合STFT和注意力机制，优化Φ-OTDR数据的事件识别，准确率达99.94%。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习方法在Φ-OTDR数据中破坏时空结构或计算成本高的问题，以适用于资源受限的IoT场景。

Method: 使用STFT将多通道时序数据转为频谱图，引入SEAM注意力模块和联合损失函数，增强特征判别性。

Result: 在BJTU Φ-OTDR数据集上达到99.94%准确率，计算高效。

Conclusion: STFT-AECNN适用于IoT-DAS系统，实现实时、可扩展的智能事件识别。

Abstract: Phase-sensitive optical time-domain reflectometry ({\Phi}-OTDR) has emerged
as a promising sensing technology in Internet of Things (IoT) infrastructures,
enabling large-scale distributed acoustic sensing (DAS) for smart city
surveillance, industrial pipeline monitoring, and critical infrastructure
protection. However, accurately recognizing events from massive {\Phi}-OTDR
data streams remains challenging, as existing deep learning methods either
disrupt the inherent spatiotemporal structure of signals or incur prohibitive
computational costs, limiting their applicability in resource-constrained IoT
scenarios. To overcome these challenges, we propose a novel STFT-based
Attention-Enhanced Convolutional Neural Network (STFT-AECNN), which represents
multi-channel time-series data as stacked spectrograms to fully exploit their
spatiotemporal characteristics while enabling efficient 2D CNN processing. A
Spatial Efficient Attention Module (SEAM) is further introduced to adaptively
emphasize the most informative channels, and a joint Cross-Entropy and Triplet
loss is adopted to enhance the discriminability of the learned feature space.
Extensive experiments on the public BJTU {\Phi}-OTDR dataset demonstrate that
STFT-AECNN achieves a peak accuracy of 99.94% while maintaining high
computational efficiency. These results highlight its potential for real-time,
scalable, and robust event recognition in IoT-enabled DAS systems, paving the
way for reliable and intelligent IoT sensing applications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies](https://arxiv.org/abs/2509.18282)
*Jesse Zhang,Marius Memmel,Kevin Kim,Dieter Fox,Jesse Thomason,Fabio Ramos,Erdem Bıyık,Abhishek Gupta,Anqi Li*

Main category: cs.RO

TL;DR: PEEK通过利用视觉语言模型生成统一的基于点的中间表示，提升了机器人操作策略的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作策略在学习注意力、动作选择和执行时的泛化不足问题，通过将高级推理任务卸载给视觉语言模型。

Method: 使用PEEK框架微调视觉语言模型，预测末端执行器路径和任务相关掩码，生成策略无关的中间表示。

Result: 在真实世界中，PEEK显著提升了零样本泛化能力，例如在仿真训练的3D策略上实现了41.4倍的改进。

Conclusion: PEEK通过简化机器人策略的学习任务，使其专注于执行动作，从而提高了泛化能力和效率。

Abstract: Robotic manipulation policies often fail to generalize because they must
simultaneously learn where to attend, what actions to take, and how to execute
them. We argue that high-level reasoning about where and what can be offloaded
to vision-language models (VLMs), leaving policies to specialize in how to act.
We present PEEK (Policy-agnostic Extraction of Essential Keypoints), which
fine-tunes VLMs to predict a unified point-based intermediate representation:
1. end-effector paths specifying what actions to take, and 2. task-relevant
masks indicating where to focus. These annotations are directly overlaid onto
robot observations, making the representation policy-agnostic and transferable
across architectures. To enable scalable training, we introduce an automatic
annotation pipeline, generating labeled data across 20+ robot datasets spanning
9 embodiments. In real-world evaluations, PEEK consistently boosts zero-shot
generalization, including a 41.4x real-world improvement for a 3D policy
trained only in simulation, and 2-3.5x gains for both large VLAs and small
manipulation policies. By letting VLMs absorb semantic and visual complexity,
PEEK equips manipulation policies with the minimal cues they need--where, what,
and how. Website at https://peek-robot.github.io/.

</details>


### [19] [Fine-Tuning Robot Policies While Maintaining User Privacy](https://arxiv.org/abs/2509.18311)
*Benjamin A. Christie,Sagar Parekh,Dylan P. Losey*

Main category: cs.RO

TL;DR: PRoP框架提供了一种个性化且隐私保护的机器人策略，通过用户密钥实现策略转换，保护用户偏好隐私。


<details>
  <summary>Details</summary>
Motivation: 当前通用机器人策略在个性化时可能泄露用户偏好数据，需解决隐私保护问题。

Method: 为每个用户分配唯一密钥，通过数学变换改变机器人网络权重，以匹配用户偏好。

Result: PRoP在模仿学习、强化学习和分类任务中表现优越，保留原始策略架构和行为。

Conclusion: PRoP有效平衡了机器人个性化与隐私保护的需求。

Abstract: Recent works introduce general-purpose robot policies. These policies provide
a strong prior over how robots should behave -- e.g., how a robot arm should
manipulate food items. But in order for robots to match an individual person's
needs, users typically fine-tune these generalized policies -- e.g., showing
the robot arm how to make their own preferred dinners. Importantly, during the
process of personalizing robots, end-users leak data about their preferences,
habits, and styles (e.g., the foods they prefer to eat). Other agents can
simply roll-out the fine-tuned policy and see these personally-trained
behaviors. This leads to a fundamental challenge: how can we develop robots
that personalize actions while keeping learning private from external agents?
We here explore this emerging topic in human-robot interaction and develop
PRoP, a model-agnostic framework for personalized and private robot policies.
Our core idea is to equip each user with a unique key; this key is then used to
mathematically transform the weights of the robot's network. With the correct
key, the robot's policy switches to match that user's preferences -- but with
incorrect keys, the robot reverts to its baseline behaviors. We show the
general applicability of our method across multiple model types in imitation
learning, reinforcement learning, and classification tasks. PRoP is practically
advantageous because it retains the architecture and behaviors of the original
policy, and experimentally outperforms existing encoder-based approaches. See
videos and code here: https://prop-icra26.github.io.

</details>


### [20] [Haptic Communication in Human-Human and Human-Robot Co-Manipulation](https://arxiv.org/abs/2509.18327)
*Katherine H. Allen,Chris Rogers,Elaine S. Short*

Main category: cs.RO

TL;DR: 论文研究了人类与人类及人类与机器人在共同操纵物体时的运动差异，发现人类协作更流畅，并提出未来机器人可通过模拟触觉信号改进协作能力。


<details>
  <summary>Details</summary>
Motivation: 探索人类与机器人在物理任务中协作的差异，以提升机器人助手的能力。

Method: 通过IMU追踪人类与人类及人类与机器人协作时的物体运动，并结合问卷反馈分析。

Result: 人类协作更流畅，IMU数据揭示了运动差异，主观反馈支持这一结论。

Conclusion: 未来研究应改进机器人触觉信号传递能力，以提升协作效果。

Abstract: When a human dyad jointly manipulates an object, they must communicate about
their intended motion plans. Some of that collaboration is achieved through the
motion of the manipulated object itself, which we call "haptic communication."
In this work, we captured the motion of human-human dyads moving an object
together with one participant leading a motion plan about which the follower is
uninformed. We then captured the same human participants manipulating the same
object with a robot collaborator. By tracking the motion of the shared object
using a low-cost IMU, we can directly compare human-human shared manipulation
to the motion of those same participants interacting with the robot.
Intra-study and post-study questionnaires provided participant feedback on the
collaborations, indicating that the human-human collaborations are
significantly more fluent, and analysis of the IMU data indicates that it
captures objective differences in the motion profiles of the conditions. The
differences in objective and subjective measures of accuracy and fluency
between the human-human and human-robot trials motivate future research into
improving robot assistants for physical tasks by enabling them to send and
receive anthropomorphic haptic signals.

</details>


### [21] [The Landform Contextual Mesh: Automatically Fusing Surface and Orbital Terrain for Mars 2020](https://arxiv.org/abs/2509.18330)
*Marsette Vona*

Main category: cs.RO

TL;DR: 利用火星2020探测车图像及火星勘测轨道飞行器数据自动构建地形可视化网格，支持任务科学家和公众使用。


<details>
  <summary>Details</summary>
Motivation: 目的是通过融合2D和3D数据，为火星探测任务提供高精度的地形可视化工具，支持任务规划和公众科普。

Method: 利用探测车图像和轨道飞行器的数据，自动构建地形网格，集成到任务规划工具和公众网站。

Result: 成功生成了交互式3D地形网格，并为任务科学家和公众提供了实用的工具。

Conclusion: 通过自动化技术实现了高效的地形数据处理与共享，提升了任务规划和科普效率。

Abstract: The Landform contextual mesh fuses 2D and 3D data from up to thousands of
Mars 2020 rover images, along with orbital elevation and color maps from Mars
Reconnaissance Orbiter, into an interactive 3D terrain visualization.
Contextual meshes are built automatically for each rover location during
mission ground data system processing, and are made available to mission
scientists for tactical and strategic planning in the Advanced Science
Targeting Tool for Robotic Operations (ASTTRO). A subset of them are also
deployed to the "Explore with Perseverance" public access website.

</details>


### [22] [Semantic-Aware Particle Filter for Reliable Vineyard Robot Localisation](https://arxiv.org/abs/2509.18342)
*Rajitha de Silva,Jonathan Cox,James R. Heselden,Marija Popovic,Cesar Cadena,Riccardo Polvara*

Main category: cs.RO

TL;DR: 论文提出了一种语义粒子滤波器，通过在似然估计中融合稳定物体检测（如葡萄树干和支撑杆），并结合激光雷达扫描生成语义观测，解决了结构化户外环境中机器人定位困难的问题。


<details>
  <summary>Details</summary>
Motivation: 在结构化户外环境（如葡萄园）中，激光雷达定位方法因重复的行几何和感知混淆而效果不佳，需要一种更鲁棒的定位方法。

Method: 提出了一种语义粒子滤波器，将物体级检测（如葡萄树干和支撑杆）投影到俯视图并与激光雷达数据融合，同时引入语义墙和噪声GPS先验以保持全局一致性。

Result: 实验表明，该方法能在真实葡萄园中准确保持在正确行内定位，从偏差中恢复，并优于视觉SLAM方法（如RTAB-Map）。

Conclusion: 语义粒子滤波器结合物体检测和激光雷达，有效解决了葡萄园中的定位问题，并展现出优于现有方法的性能。

Abstract: Accurate localisation is critical for mobile robots in structured outdoor
environments, yet LiDAR-based methods often fail in vineyards due to repetitive
row geometry and perceptual aliasing. We propose a semantic particle filter
that incorporates stable object-level detections, specifically vine trunks and
support poles into the likelihood estimation process. Detected landmarks are
projected into a birds eye view and fused with LiDAR scans to generate semantic
observations. A key innovation is the use of semantic walls, which connect
adjacent landmarks into pseudo-structural constraints that mitigate row
aliasing. To maintain global consistency in headland regions where semantics
are sparse, we introduce a noisy GPS prior that adaptively supports the filter.
Experiments in a real vineyard demonstrate that our approach maintains
localisation within the correct row, recovers from deviations where AMCL fails,
and outperforms vision-based SLAM methods such as RTAB-Map.

</details>


### [23] [AD-VF: LLM-Automatic Differentiation Enables Fine-Tuning-Free Robot Planning from Formal Methods Feedback](https://arxiv.org/abs/2509.18384)
*Yunhao Yang,Junyuan Hong,Gabriel Jacob Perin,Zhiwen Fan,Li Yin,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: 论文提出LAD-VF框架，通过形式化验证反馈自动优化提示，无需微调模型，显著提升LLM驱动控制系统的规范遵从性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的规划在物理世界中常因幻觉或弱对齐而违反安全和监管约束，需解决这一问题。

Method: 提出LAD-VF框架，结合形式化验证反馈与LLM-AutoDiff，通过优化提示而非模型参数实现对齐。

Result: 实验表明，LAD-VF将规范遵从性从60%提升至90%以上。

Conclusion: LAD-VF提供了一种可扩展且可解释的方法，用于构建可信赖的LLM驱动控制系统。

Abstract: Large language models (LLMs) can translate natural language instructions into
executable action plans for robotics, autonomous driving, and other domains.
Yet, deploying LLM-driven planning in the physical world demands strict
adherence to safety and regulatory constraints, which current models often
violate due to hallucination or weak alignment. Traditional data-driven
alignment methods, such as Direct Preference Optimization (DPO), require costly
human labeling, while recent formal-feedback approaches still depend on
resource-intensive fine-tuning. In this paper, we propose LAD-VF, a
fine-tuning-free framework that leverages formal verification feedback for
automated prompt engineering. By introducing a formal-verification-informed
text loss integrated with LLM-AutoDiff, LAD-VF iteratively refines prompts
rather than model parameters. This yields three key benefits: (i) scalable
adaptation without fine-tuning; (ii) compatibility with modular LLM
architectures; and (iii) interpretable refinement via auditable prompts.
Experiments in robot navigation and manipulation tasks demonstrate that LAD-VF
substantially enhances specification compliance, improving success rates from
60% to over 90%. Our method thus presents a scalable and interpretable pathway
toward trustworthy, formally-verified LLM-driven control systems.

</details>


### [24] [Assistive Decision-Making for Right of Way Navigation at Uncontrolled Intersections](https://arxiv.org/abs/2509.18407)
*Navya Tiwari,Joseph Vazhaeparampil,Victoria Preston*

Main category: cs.RO

TL;DR: 提出了一个基于POMDP的驾驶员辅助框架，用于无控制交叉口的通行权决策，通过模拟测试证明概率规划器优于规则基线。


<details>
  <summary>Details</summary>
Motivation: 无控制交叉口因通行规则模糊、遮挡和驾驶员行为不可预测导致事故频发，亟需辅助导航系统支持。

Method: 框架以POMDP建模，并在模拟环境中测试了四种方法：确定性FSM及三种概率规划器（QMDP、POMCP、DESPOT）。

Result: 概率规划器表现优于规则基线，POMCP安全性最佳，DESPOT在效率与可行性间平衡，最高实现97.5%无碰撞导航。

Conclusion: 强调不确定性感知规划的重要性，并呼吁未来整合传感器融合与环境感知模块以实现实时部署。

Abstract: Uncontrolled intersections account for a significant fraction of roadway
crashes due to ambiguous right-of-way rules, occlusions, and unpredictable
driver behavior. While autonomous vehicle research has explored
uncertainty-aware decision making, few systems exist to retrofit human-operated
vehicles with assistive navigation support. We present a driver-assist
framework for right-of-way reasoning at uncontrolled intersections, formulated
as a Partially Observable Markov Decision Process (POMDP). Using a custom
simulation testbed with stochastic traffic agents, pedestrians, occlusions, and
adversarial scenarios, we evaluate four decision-making approaches: a
deterministic finite state machine (FSM), and three probabilistic planners:
QMDP, POMCP, and DESPOT. Results show that probabilistic planners outperform
the rule-based baseline, achieving up to 97.5 percent collision-free navigation
under partial observability, with POMCP prioritizing safety and DESPOT
balancing efficiency and runtime feasibility. Our findings highlight the
importance of uncertainty-aware planning for driver assistance and motivate
future integration of sensor fusion and environment perception modules for
real-time deployment in realistic traffic environments.

</details>


### [25] [Latent Action Pretraining Through World Modeling](https://arxiv.org/abs/2509.18428)
*Bahey Tharwat,Yara Nasser,Ali Abouzeid,Ian Reid*

Main category: cs.RO

TL;DR: 本文提出了一种模型无关的框架LAWM，通过从无标签视频数据中学习潜在动作表示，以自监督方式预训练模仿学习模型，适用于跨任务、环境和实体迁移。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作(VLA)模型虽然表现优异，但模型规模大且依赖人工标注数据，难以在现实场景中部署。因此，作者旨在设计一个更高效且无需标注的预训练框架。

Method: 提出了LAWM框架，通过世界建模从无标签视频（如机器人记录或人类动作视频）中学习潜在动作表示，实现自监督预训练。

Result: 在LIBERO基准测试和真实场景中，LAWM优于基于真实机器人动作训练的模型和其他类似预训练方法，且更高效实用。

Conclusion: LAWM为模仿学习提供了一种高效的自监督预训练框架，显著减少了模型对标注数据的依赖，并提升了跨任务和场景的适用性。

Abstract: Vision-Language-Action (VLA) models have gained popularity for learning
robotic manipulation tasks that follow language instructions. State-of-the-art
VLAs, such as OpenVLA and $\pi_{0}$, were trained on large-scale, manually
labeled action datasets collected through teleoperation. More recent
approaches, including LAPA and villa-X, introduce latent action representations
that enable unsupervised pretraining on unlabeled datasets by modeling abstract
visual changes between frames. Although these methods have shown strong
results, their large model sizes make deployment in real-world settings
challenging. In this work, we propose LAWM, a model-agnostic framework to
pretrain imitation learning models in a self-supervised way, by learning latent
action representations from unlabeled video data through world modeling. These
videos can be sourced from robot recordings or videos of humans performing
actions with everyday objects. Our framework is designed to be effective for
transferring across tasks, environments, and embodiments. It outperforms models
trained with ground-truth robotics actions and similar pretraining methods on
the LIBERO benchmark and real-world setup, while being significantly more
efficient and practical for real-world settings.

</details>


### [26] [PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction](https://arxiv.org/abs/2509.18447)
*Rishabh Madan,Jiawei Lin,Mahika Goel,Angchen Xie,Xiaoyu Liang,Marcus Lee,Justin Guo,Pranav N. Thakkar,Rohan Banerjee,Jose Barreiros,Kate Tsui,Tom Silver,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: PrioriTouch是一个用于优先级排序和执行多接触控制目标的框架，适用于护理和多接触场景，结合了学习排序和分层控制方法。


<details>
  <summary>Details</summary>
Motivation: 在物理人机交互中，适应个体接触偏好（如力和位置）是一个复杂问题，尤其在多接触场景中因冲突需求而难以解决。

Method: 框架结合了学习排序方法和分层操作空间控制，利用仿真数据高效且安全地探索偏好。

Result: 通过用户研究、仿真和实验验证，PrioriTouch能够适应用户偏好、保持任务性能并提升安全性和舒适度。

Conclusion: PrioriTouch提供了一种有效的方法来处理多接触交互中的冲突需求，具有广泛的应用潜力。

Abstract: Physical human-robot interaction (pHRI) requires robots to adapt to
individual contact preferences, such as where and how much force is applied.
Identifying preferences is difficult for a single contact; with whole-arm
interaction involving multiple simultaneous contacts between the robot and
human, the challenge is greater because different body parts can impose
incompatible force requirements. In caregiving tasks, where contact is frequent
and varied, such conflicts are unavoidable. With multiple preferences across
multiple contacts, no single solution can satisfy all objectives--trade-offs
are inherent, making prioritization essential. We present PrioriTouch, a
framework for ranking and executing control objectives across multiple
contacts. PrioriTouch can prioritize from a general collection of controllers,
making it applicable not only to caregiving scenarios such as bed bathing and
dressing but also to broader multi-contact settings. Our method combines a
novel learning-to-rank approach with hierarchical operational space control,
leveraging simulation-in-the-loop rollouts for data-efficient and safe
exploration. We conduct a user study on physical assistance preferences, derive
personalized comfort thresholds, and incorporate them into PrioriTouch. We
evaluate PrioriTouch through extensive simulation and real-world experiments,
demonstrating its ability to adapt to user contact preferences, maintain task
performance, and enhance safety and comfort. Website:
https://emprise.cs.cornell.edu/prioritouch.

</details>


### [27] [Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands](https://arxiv.org/abs/2509.18455)
*Yunshuang Li,Yiyang Ling,Gaurav S. Sukhatme,Daniel Seita*

Main category: cs.RO

TL;DR: 论文提出了一种名为GD2P的方法，利用灵巧手进行非抓取操作（如推拉），通过多样化手部姿态生成和物理模拟训练，实现了高效的物体操作。实验验证了方法的可扩展性和对不同手形态的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有非抓取操作多依赖平行夹爪或简单工具，灵巧手虽接触模式更丰富但难以建模动态过程。GD2P旨在利用灵巧手的灵活性提升非抓取操作的稳定性和多样性。

Method: 通过接触引导采样生成多样化手部姿态，利用物理模拟筛选并训练扩散模型预测可行姿态。测试时结合运动规划执行推拉动作。

Result: 840次真实实验表明GD2P优于基线方法，适用于不同手形态（如Allegro Hand和LEAP Hand）。

Conclusion: GD2P为灵巧非抓取操作的训练提供了可扩展方案，开源模型和数据集将进一步推动研究。

Abstract: Nonprehensile manipulation, such as pushing and pulling, enables robots to
move, align, or reposition objects that may be difficult to grasp due to their
geometry, size, or relationship to the robot or the environment. Much of the
existing work in nonprehensile manipulation relies on parallel-jaw grippers or
tools such as rods and spatulas. In contrast, multi-fingered dexterous hands
offer richer contact modes and versatility for handling diverse objects to
provide stable support over the objects, which compensates for the difficulty
of modeling the dynamics of nonprehensile manipulation. Therefore, we propose
Geometry-aware Dexterous Pushing and Pulling (GD2P) for nonprehensile
manipulation with dexterous robotic hands. We study pushing and pulling by
framing the problem as synthesizing and learning pre-contact dexterous hand
poses that lead to effective manipulation. We generate diverse hand poses via
contact-guided sampling, filter them using physics simulation, and train a
diffusion model conditioned on object geometry to predict viable poses. At test
time, we sample hand poses and use standard motion planners to select and
execute pushing and pulling actions. We perform 840 real-world experiments with
an Allegro Hand, comparing our method to baselines. The results indicate that
GD2P offers a scalable route for training dexterous nonprehensile manipulation
policies. We further demonstrate GD2P on a LEAP Hand, highlighting its
applicability to different hand morphologies. Our pre-trained models and
dataset, including 1.3 million hand poses across 2.3k objects, will be
open-source to facilitate further research. Our project website is available
at: geodex2p.github.io.

</details>


### [28] [A Counterfactual Reasoning Framework for Fault Diagnosis in Robot Perception Systems](https://arxiv.org/abs/2509.18460)
*Haeyoon Han,Mahdi Taheri,Soon-Jo Chung,Fred Y. Hadaegh*

Main category: cs.RO

TL;DR: 该论文提出了一种基于反事实推理的感知系统故障检测与隔离（FDI）框架，通过分析冗余而非物理冗余来提升可靠性，并展示了在机器人探索场景中的应用。


<details>
  <summary>Details</summary>
Motivation: 感知系统的故障对环境理解至关重要，但因其复杂性和多阶段特性，难以检测和隔离，因此需要一种高效的方法来解决这一问题。

Method: 采用反事实推理构建感知可靠性测试，区分被动和主动FDI方法。主动FDI通过蒙特卡洛树搜索（MCTS）和上置信界（UCB）优化控制输入，最大化有效信息（EI）。

Result: 在机器人导航场景中验证了方法的有效性，能够准确隔离传感器损坏、动态场景和感知退化等故障。

Conclusion: 反事实推理结合主动FDI方法为感知系统故障检测与隔离提供了高效且可靠的解决方案。

Abstract: Perception systems provide a rich understanding of the environment for
autonomous systems, shaping decisions in all downstream modules. Hence,
accurate detection and isolation of faults in perception systems is important.
Faults in perception systems pose particular challenges: faults are often tied
to the perceptual context of the environment, and errors in their multi-stage
pipelines can propagate across modules. To address this, we adopt a
counterfactual reasoning approach to propose a framework for fault detection
and isolation (FDI) in perception systems. As opposed to relying on physical
redundancy (i.e., having extra sensors), our approach utilizes analytical
redundancy with counterfactual reasoning to construct perception reliability
tests as causal outcomes influenced by system states and fault scenarios.
Counterfactual reasoning generates reliability test results under hypothesized
faults to update the belief over fault hypotheses. We derive both passive and
active FDI methods. While the passive FDI can be achieved by belief updates,
the active FDI approach is defined as a causal bandit problem, where we utilize
Monte Carlo Tree Search (MCTS) with upper confidence bound (UCB) to find
control inputs that maximize a detection and isolation metric, designated as
Effective Information (EI). The mentioned metric quantifies the informativeness
of control inputs for FDI. We demonstrate the approach in a robot exploration
scenario, where a space robot performing vision-based navigation actively
adjusts its attitude to increase EI and correctly isolate faults caused by
sensor damage, dynamic scenes, and perceptual degradation.

</details>


### [29] [Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task](https://arxiv.org/abs/2509.18463)
*Jannick van Buuren,Roberto Giglio,Loris Roveda,Luka Peternel*

Main category: cs.RO

TL;DR: 本文研究了通过故意突变强化学习中的奖励函数来产生多样化的机器人操作技能，并以液体倾倒任务为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过奖励函数突变来生成多样化的机器人技能，为新任务提供潜在的有用技能。

Method: 提出了一个基于高斯噪声的奖励函数突变框架，设计了包含准确性、时间和努力等关键项的奖励函数，并在模拟环境中使用PPO算法进行训练。

Result: 突变奖励函数权重产生的策略展示了从原始倾倒任务到新技能（如容器边缘清洁、液体混合和浇水）的多样化行为。

Conclusion: 该方法为机器人系统在特定任务中多样化学习以及未来任务中有意义技能的衍生提供了有前景的方向。

Abstract: This paper explores how deliberate mutations of reward function in
reinforcement learning can produce diversified skill variations in robotic
manipulation tasks, examined with a liquid pouring use case. To this end, we
developed a new reward function mutation framework that is based on applying
Gaussian noise to the weights of the different terms in the reward function.
Inspired by the cost-benefit tradeoff model from human motor control, we
designed the reward function with the following key terms: accuracy, time, and
effort. The study was performed in a simulation environment created in NVIDIA
Isaac Sim, and the setup included Franka Emika Panda robotic arm holding a
glass with a liquid that needed to be poured into a container. The
reinforcement learning algorithm was based on Proximal Policy Optimization. We
systematically explored how different configurations of mutated weights in the
rewards function would affect the learned policy. The resulting policies
exhibit a wide range of behaviours: from variations in execution of the
originally intended pouring task to novel skills useful for unexpected tasks,
such as container rim cleaning, liquid mixing, and watering. This approach
offers promising directions for robotic systems to perform diversified learning
of specific tasks, while also potentially deriving meaningful skills for future
tasks.

</details>


### [30] [RL-augmented Adaptive Model Predictive Control for Bipedal Locomotion over Challenging Terrain](https://arxiv.org/abs/2509.18466)
*Junnosuke Kamohara,Feiyang Wu,Chinmayee Wamorkar,Seth Hutchinson,Ye Zhao*

Main category: cs.RO

TL;DR: 摘要提出了一种RL增强的MPC框架，用于双足机器人在复杂地形上的运动控制，结合了MPC和RL的优势。


<details>
  <summary>Details</summary>
Motivation: 解决现有MPC在建模地形交互时的局限性，以及RL在约束满足和奖励设计上的不足。

Method: 通过参数化MPC的关键组件（系统动力学、摆动腿控制器和步频），并结合RL进行优化。

Result: 在多种复杂地形上的仿真实验表明，该框架比基线MPC和RL更具适应性和鲁棒性。

Conclusion: RL与MPC的结合能够有效提升双足机器人在复杂地形上的运动性能。

Abstract: Model predictive control (MPC) has demonstrated effectiveness for humanoid
bipedal locomotion; however, its applicability in challenging environments,
such as rough and slippery terrain, is limited by the difficulty of modeling
terrain interactions. In contrast, reinforcement learning (RL) has achieved
notable success in training robust locomotion policies over diverse terrain,
yet it lacks guarantees of constraint satisfaction and often requires
substantial reward shaping. Recent efforts in combining MPC and RL have shown
promise of taking the best of both worlds, but they are primarily restricted to
flat terrain or quadrupedal robots. In this work, we propose an RL-augmented
MPC framework tailored for bipedal locomotion over rough and slippery terrain.
Our method parametrizes three key components of
single-rigid-body-dynamics-based MPC: system dynamics, swing leg controller,
and gait frequency. We validate our approach through bipedal robot simulations
in NVIDIA IsaacLab across various terrains, including stairs, stepping stones,
and low-friction surfaces. Experimental results demonstrate that our
RL-augmented MPC framework produces significantly more adaptive and robust
behaviors compared to baseline MPC and RL.

</details>


### [31] [Spatial Envelope MPC: High Performance Driving without a Reference](https://arxiv.org/abs/2509.18506)
*Siyuan Yu,Congkai Shen,Yufei Xi,James Dallas,Michael Thompson,John Subosits,Hiroshi Yasuda,Tulga Ersal*

Main category: cs.RO

TL;DR: 本文提出了一种新型基于包络的模型预测控制（MPC）框架，使自动驾驶车辆能在无预定义参考的情况下高效驾驶。


<details>
  <summary>Details</summary>
Motivation: 当前基于参考的规划和控制框架在车辆动态极限下表现受限，需要一种无需预定义参考的实时规划与控制方法。

Method: 结合高效车辆动力学模型、可微数学公式及强化学习与优化技术，实现动态可行性与安全约束的直接整合。

Result: 通过仿真和实际实验验证，该框架在赛车、紧急避障和越野导航等多种任务中表现优异。

Conclusion: 该框架具有广泛适用性和扩展性，适用于多样化的自动驾驶场景。

Abstract: This paper presents a novel envelope based model predictive control (MPC)
framework designed to enable autonomous vehicles to handle high performance
driving across a wide range of scenarios without a predefined reference. In
high performance autonomous driving, safe operation at the vehicle's dynamic
limits requires a real time planning and control framework capable of
accounting for key vehicle dynamics and environmental constraints when
following a predefined reference trajectory is suboptimal or even infeasible.
State of the art planning and control frameworks, however, are predominantly
reference based, which limits their performance in such situations. To address
this gap, this work first introduces a computationally efficient vehicle
dynamics model tailored for optimization based control and a continuously
differentiable mathematical formulation that accurately captures the entire
drivable envelope. This novel model and formulation allow for the direct
integration of dynamic feasibility and safety constraints into a unified
planning and control framework, thereby removing the necessity for predefined
references. The challenge of envelope planning, which refers to maximally
approximating the safe drivable area, is tackled by combining reinforcement
learning with optimization techniques. The framework is validated through both
simulations and real world experiments, demonstrating its high performance
across a variety of tasks, including racing, emergency collision avoidance and
off road navigation. These results highlight the framework's scalability and
broad applicability across a diverse set of scenarios.

</details>


### [32] [LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA](https://arxiv.org/abs/2509.18576)
*Zeyi Kang,Liang He,Yanxin Zhang,Zuheng Ming,Kaixing Zhao*

Main category: cs.RO

TL;DR: 本文提出轻量级LCMF框架，解决多模态学习中异构数据融合和计算效率问题，通过跨模态参数共享机制显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态学习中异构数据融合和计算效率的挑战，提升机器人在资源受限环境中的智能决策能力。

Method: 提出LCMF框架，结合Cross-Attention和选择性参数共享SSMs，实现异构模态的高效融合与语义对齐。

Result: 在VQA任务中准确率达74.29%，EQA任务中达到中游性能，计算量减少4.35倍，参数规模轻量（166.51M-219M）。

Conclusion: LCMF为资源受限场景下的人机交互提供了高效解决方案，具备强大的多模态决策泛化能力。

Abstract: Multimodal semantic learning plays a critical role in embodied intelligence,
especially when robots perceive their surroundings, understand human
instructions, and make intelligent decisions. However, the field faces
technical challenges such as effective fusion of heterogeneous data and
computational efficiency in resource-constrained environments. To address these
challenges, this study proposes the lightweight LCMF cascaded attention
framework, introducing a multi-level cross-modal parameter sharing mechanism
into the Mamba module. By integrating the advantages of Cross-Attention and
Selective parameter-sharing State Space Models (SSMs), the framework achieves
efficient fusion of heterogeneous modalities and semantic complementary
alignment. Experimental results show that LCMF surpasses existing multimodal
baselines with an accuracy of 74.29% in VQA tasks and achieves competitive
mid-tier performance within the distribution cluster of Large Language Model
Agents (LLM Agents) in EQA video tasks. Its lightweight design achieves a
4.35-fold reduction in FLOPs relative to the average of comparable baselines
while using only 166.51M parameters (image-text) and 219M parameters
(video-text), providing an efficient solution for Human-Robot Interaction (HRI)
applications in resource-constrained scenarios with strong multimodal decision
generalization capabilities.

</details>


### [33] [VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation](https://arxiv.org/abs/2509.18592)
*Neel P. Bhatt,Yunhao Yang,Rohan Siva,Pranay Samineni,Daniel Milan,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: VLN-Zero是一个两阶段的视觉语言导航框架，通过在探索阶段高效构建符号场景图，并在部署阶段结合神经符号规划和缓存执行，显著提升了在未知环境中的导航性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言导航方法在未知环境中计算效率低和泛化能力差的问题，提出一种能够快速适应和高效导航的新框架。

Method: 分两阶段进行：探索阶段使用视觉语言模型构建符号场景图；部署阶段通过神经符号规划和缓存执行模块生成可执行计划。

Result: VLN-Zero在成功率和效率上显著优于现有方法，成功率提升2倍，时间减半，且视觉语言模型调用减少55%。

Conclusion: VLN-Zero通过结合快速探索、符号推理和缓存执行，显著提升了视觉语言导航的适应性和扩展性，适用于未知环境。

Abstract: Rapid adaptation in unseen environments is essential for scalable real-world
autonomy, yet existing approaches rely on exhaustive exploration or rigid
navigation policies that fail to generalize. We present VLN-Zero, a two-phase
vision-language navigation framework that leverages vision-language models to
efficiently construct symbolic scene graphs and enable zero-shot neurosymbolic
navigation. In the exploration phase, structured prompts guide VLM-based search
toward informative and diverse trajectories, yielding compact scene graph
representations. In the deployment phase, a neurosymbolic planner reasons over
the scene graph and environmental observations to generate executable plans,
while a cache-enabled execution module accelerates adaptation by reusing
previously computed task-location trajectories. By combining rapid exploration,
symbolic reasoning, and cache-enabled execution, the proposed framework
overcomes the computational inefficiency and poor generalization of prior
vision-language navigation methods, enabling robust and scalable
decision-making in unseen environments. VLN-Zero achieves 2x higher success
rate compared to state-of-the-art zero-shot models, outperforms most fine-tuned
baselines, and reaches goal locations in half the time with 55% fewer VLM calls
on average compared to state-of-the-art models across diverse environments.
Codebase, datasets, and videos for VLN-Zero are available at:
https://vln-zero.github.io/.

</details>


### [34] [Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills](https://arxiv.org/abs/2509.18597)
*Yuan Meng,Zhenguo Sun,Max Fest,Xukun Li,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 论文提出了一种基于大型语言模型的代码生成框架，结合人类反馈和外部记忆，显著提升了机器人任务的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长时任务和通用性上表现不足，且存在灾难性遗忘问题，因此需要学习可重用技能以提高性能。

Method: 框架采用人类参与循环设计，将校正信息编码为可重用技能，并通过外部记忆和检索增强生成实现动态复用。

Result: 实验显示，该框架在多种任务中成功率达0.93，校正效率提升42%，并能解决20个原始任务的长时任务。

Conclusion: 结合人类反馈和可重用技能的框架显著提升了机器人任务的性能和适用范围。

Abstract: Large language models (LLMs)-based code generation for robotic manipulation
has recently shown promise by directly translating human instructions into
executable code, but existing methods remain noisy, constrained by fixed
primitives and limited context windows, and struggle with long-horizon tasks.
While closed-loop feedback has been explored, corrected knowledge is often
stored in improper formats, restricting generalization and causing catastrophic
forgetting, which highlights the need for learning reusable skills. Moreover,
approaches that rely solely on LLM guidance frequently fail in extremely
long-horizon scenarios due to LLMs' limited reasoning capability in the robotic
domain, where such issues are often straightforward for humans to identify. To
address these challenges, we propose a human-in-the-loop framework that encodes
corrections into reusable skills, supported by external memory and
Retrieval-Augmented Generation with a hint mechanism for dynamic reuse.
Experiments on Ravens, Franka Kitchen, and MetaWorld, as well as real-world
settings, show that our framework achieves a 0.93 success rate (up to 27%
higher than baselines) and a 42% efficiency improvement in correction rounds.
It can robustly solve extremely long-horizon tasks such as "build a house",
which requires planning over 20 primitives.

</details>


### [35] [End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2509.18608)
*Ana Luiza Mineiro,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种基于深度强化学习的端到端导航系统，通过3D LiDAR数据直接生成控制命令，解决了GNSS不可靠、复杂环境和光照变化的问题。


<details>
  <summary>Details</summary>
Motivation: 解决在冠层下农业环境中导航的挑战，如GNSS不可靠、密集行和可变光照。

Method: 使用深度强化学习策略，通过模拟训练将原始3D LiDAR数据直接映射到控制命令，采用基于体素的下采样策略减少输入数据量。

Result: 在模拟中验证，直线行种植的成功率为100%，但随着行弯曲度的增加，性能逐渐下降。

Conclusion: 该方法无需标记数据集或手动设计控制接口，展示出在复杂农业环境中的导航潜力。

Abstract: Reliable navigation in under-canopy agricultural environments remains a
challenge due to GNSS unreliability, cluttered rows, and variable lighting. To
address these limitations, we present an end-to-end learning-based navigation
system that maps raw 3D LiDAR data directly to control commands using a deep
reinforcement learning policy trained entirely in simulation. Our method
includes a voxel-based downsampling strategy that reduces LiDAR input size by
95.83%, enabling efficient policy learning without relying on labeled datasets
or manually designed control interfaces. The policy was validated in
simulation, achieving a 100% success rate in straight-row plantations and
showing a gradual decline in performance as row curvature increased, tested
across varying sinusoidal frequencies and amplitudes.

</details>


### [36] [PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving](https://arxiv.org/abs/2509.18609)
*Chengran Yuan,Zijian Lu,Zhanqi Zhang,Yimin Zhao,Zefan Huang,Shuo Sun,Jiawei Sun,Jiahui Li,Christina Dao Wen Lee,Dongen Li,Marcelo H. Ang Jr*

Main category: cs.RO

TL;DR: PIE是一种端到端运动规划框架，通过先进的感知、推理和意图建模优化自主驾驶决策，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 简化复杂自主驾驶流程，克服场景理解和决策预测等挑战。

Method: 集成双向Mamba融合处理多模态数据压缩损失，推理增强解码器优化轨迹推断，动作-运动交互模块提升规划。

Result: NAVSIM基准测试中PDM和EPDM分数分别为88.9和85.6，超越现有最优方法。

Conclusion: PIE能可靠生成高质量轨迹，适用于实际部署。

Abstract: End-to-end motion planning is promising for simplifying complex autonomous
driving pipelines. However, challenges such as scene understanding and
effective prediction for decision-making continue to present substantial
obstacles to its large-scale deployment. In this paper, we present PIE, a
pioneering framework that integrates advanced perception, reasoning, and
intention modeling to dynamically capture interactions between the ego vehicle
and surrounding agents. It incorporates a bidirectional Mamba fusion that
addresses data compression losses in multimodal fusion of camera and LiDAR
inputs, alongside a novel reasoning-enhanced decoder integrating Mamba and
Mixture-of-Experts to facilitate scene-compliant anchor selection and optimize
adaptive trajectory inference. PIE adopts an action-motion interaction module
to effectively utilize state predictions of surrounding agents to refine ego
planning. The proposed framework is thoroughly validated on the NAVSIM
benchmark. PIE, without using any ensemble and data augmentation techniques,
achieves an 88.9 PDM score and 85.6 EPDM score, surpassing the performance of
prior state-of-the-art methods. Comprehensive quantitative and qualitative
analyses demonstrate that PIE is capable of reliably generating feasible and
high-quality ego trajectories.

</details>


### [37] [SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones](https://arxiv.org/abs/2509.18610)
*Maximilian Adang,JunEn Low,Ola Shorinwa,Mac Schwager*

Main category: cs.RO

TL;DR: SINGER是一个基于语言引导的无人机自主导航系统，利用高斯泼溅模拟器和轻量级视觉运动策略，实现零样本迁移到新环境和目标对象。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇无人机导航的挑战，包括大规模演示数据的稀缺、实时控制需求和缺乏可靠的外部姿态估计模块。

Method: 采用高斯泼溅模拟器生成数据，RRT专家生成多轨迹演示，训练轻量级视觉运动策略。

Result: SINGER在硬件实验中表现优异，零样本迁移能力突出，达到目标的次数比基线高23.33%，视野保持率提高16.67%，碰撞减少10%。

Conclusion: SINGER通过创新的模拟器和策略设计，成功实现了高效、可靠的无人机自主导航。

Abstract: Large vision-language models have driven remarkable progress in
open-vocabulary robot policies, e.g., generalist robot manipulation policies,
that enable robots to complete complex tasks specified in natural language.
Despite these successes, open-vocabulary autonomous drone navigation remains an
unsolved challenge due to the scarcity of large-scale demonstrations, real-time
control demands of drones for stabilization, and lack of reliable external pose
estimation modules. In this work, we present SINGER for language-guided
autonomous drone navigation in the open world using only onboard sensing and
compute. To train robust, open-vocabulary navigation policies, SINGER leverages
three central components: (i) a photorealistic language-embedded flight
simulator with minimal sim-to-real gap using Gaussian Splatting for efficient
data generation, (ii) an RRT-inspired multi-trajectory generation expert for
collision-free navigation demonstrations, and these are used to train (iii) a
lightweight end-to-end visuomotor policy for real-time closed-loop control.
Through extensive hardware flight experiments, we demonstrate superior
zero-shot sim-to-real transfer of our policy to unseen environments and unseen
language-conditioned goal objects. When trained on ~700k-1M observation action
pairs of language conditioned visuomotor data and deployed on hardware, SINGER
outperforms a velocity-controlled semantic guidance baseline by reaching the
query 23.33% more on average, and maintains the query in the field of view
16.67% more on average, with 10% fewer collisions.

</details>


### [38] [The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving](https://arxiv.org/abs/2509.18626)
*Jay Patrikar,Apoorva Sharma,Sushant Veer,Boyi Li,Sebastian Scherer,Marco Pavone*

Main category: cs.RO

TL;DR: 这篇论文提出了一种方法，通过将事故报告与常规驾驶数据统一表示为场景-动作形式，并结合检索与反事实推理，提升自动驾驶系统的决策安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶系统主要基于无事故数据训练，难以处理安全边界情况。事故报告提供了关键的反事实证据，但由于其非结构化和第三人称特点，难以直接利用。

Method: 将事故报告转化为自我中心语言，并与驾驶日志统一表示为场景-动作形式。通过检索相关先例和反事实推理，优化决策。

Result: 在nuScenes基准测试中，先例检索将上下文中更优动作的召回率从24%提升到53%。反事实变体进一步优化了风险决策。

Conclusion: 采用统一表示和反事实推理的方法显著提升了自动驾驶系统的决策校准和安全性。

Abstract: Learning-based autonomous driving systems are trained mostly on incident-free
data, offering little guidance near safety-performance boundaries. Real crash
reports contain precisely the contrastive evidence needed, but they are hard to
use: narratives are unstructured, third-person, and poorly grounded to sensor
views. We address these challenges by normalizing crash narratives to
ego-centric language and converting both logs and crashes into a unified
scene-action representation suitable for retrieval. At decision time, our
system adjudicates proposed actions by retrieving relevant precedents from this
unified index; an agentic counterfactual extension proposes plausible
alternatives, retrieves for each, and reasons across outcomes before deciding.
On a nuScenes benchmark, precedent retrieval substantially improves
calibration, with recall on contextually preferred actions rising from 24% to
53%. The counterfactual variant preserves these gains while sharpening
decisions near risk.

</details>


### [39] [Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training](https://arxiv.org/abs/2509.18631)
*Shuo Cheng,Liqian Ma,Zhenyang Chen,Ajay Mandlekar,Caelan Garrett,Danfei Xu*

Main category: cs.RO

TL;DR: 该论文提出了一种结合仿真和真实数据的联合训练框架，通过学习域不变特征空间，显著提高了机器人操作任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人操作演示数据获取成本高，而仿真数据虽可大规模生成，但存在仿真与现实的领域差异问题。论文旨在利用少量真实数据和大量仿真数据，实现政策的泛化。

Method: 提出了一种基于最优运输（OT）的联合训练框架，通过对齐观察与动作的联合分布（而非仅观察），学习域不变特征空间，并扩展为不平衡OT以处理数据不平衡问题。

Result: 实验表明，该方法在真实世界中实现了高达30%的成功率提升，并能泛化到仅在仿真中见过的场景。

Conclusion: 该框架有效利用了仿真数据的规模优势，结合少量真实数据，显著提升了机器人操作任务的泛化性和实际性能。

Abstract: Behavior cloning has shown promise for robot manipulation, but real-world
demonstrations are costly to acquire at scale. While simulated data offers a
scalable alternative, particularly with advances in automated demonstration
generation, transferring policies to the real world is hampered by various
simulation and real domain gaps. In this work, we propose a unified
sim-and-real co-training framework for learning generalizable manipulation
policies that primarily leverages simulation and only requires a few real-world
demonstrations. Central to our approach is learning a domain-invariant,
task-relevant feature space. Our key insight is that aligning the joint
distributions of observations and their corresponding actions across domains
provides a richer signal than aligning observations (marginals) alone. We
achieve this by embedding an Optimal Transport (OT)-inspired loss within the
co-training framework, and extend this to an Unbalanced OT framework to handle
the imbalance between abundant simulation data and limited real-world examples.
We validate our method on challenging manipulation tasks, showing it can
leverage abundant simulation data to achieve up to a 30% improvement in the
real-world success rate and even generalize to scenarios seen only in
simulation.

</details>


### [40] [Number Adaptive Formation Flight Planning via Affine Deformable Guidance in Narrow Environments](https://arxiv.org/abs/2509.18636)
*Yuan Zhou,Jialiang Hou,Guangtong Xu,Fei Gao*

Main category: cs.RO

TL;DR: 本文提出了一种基于可变形虚拟结构（DVS）的无人机编队规划方法，解决了窄环境中无人机数量变化时编队维护的挑战，通过分区和分配算法（PAAS）以及时空轨迹优化，实现了快速编队恢复和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 窄环境中无人机数量变化导致编队配置难以收敛，亟需一种能够自适应调整并保持编队完整性的规划方法。

Method: 结合Lloyd算法的均匀分区和匈牙利算法的分配（PAAS），以及基于原始路径搜索和非线性轨迹优化的DVS时空轨迹规划，实现了分布式轨迹规划和避碰。

Result: 仿真中支持15%的无人机数量变化，并快速恢复编队形状；实验验证了方法的有效性和鲁棒性。

Conclusion: 该方法在编队恢复速度和环境适应性上优于现有技术，实际应用中表现出色。

Abstract: Formation maintenance with varying number of drones in narrow environments
hinders the convergence of planning to the desired configurations. To address
this challenge, this paper proposes a formation planning method guided by
Deformable Virtual Structures (DVS) with continuous spatiotemporal
transformation. Firstly, to satisfy swarm safety distance and preserve
formation shape filling integrity for irregular formation geometries, we employ
Lloyd algorithm for uniform $\underline{PA}$rtitioning and Hungarian algorithm
for $\underline{AS}$signment (PAAS) in DVS. Subsequently, a spatiotemporal
trajectory involving DVS is planned using primitive-based path search and
nonlinear trajectory optimization. The DVS trajectory achieves adaptive
transitions with respect to a varying number of drones while ensuring
adaptability to narrow environments through affine transformation. Finally,
each agent conducts distributed trajectory planning guided by desired
spatiotemporal positions within the DVS, while incorporating collision
avoidance and dynamic feasibility requirements. Our method enables up to 15\%
of swarm numbers to join or leave in cluttered environments while rapidly
restoring the desired formation shape in simulation. Compared to cutting-edge
formation planning method, we demonstrate rapid formation recovery capacity and
environmental adaptability. Real-world experiments validate the effectiveness
and resilience of our formation planning method.

</details>


### [41] [Do You Need Proprioceptive States in Visuomotor Policies?](https://arxiv.org/abs/2509.18644)
*Juntu Zhao,Wenbo Lu,Di Zhang,Yufeng Liu,Yushen Liang,Tianluo Zhang,Yifeng Cao,Junyuan Xie,Yingdong Hu,Shengjie Wang,Junliang Guo,Dequan Wang,Yang Gao*

Main category: cs.RO

TL;DR: 该研究发现模仿学习中的视觉运动策略过度依赖本体感觉输入，导致空间泛化能力差，提出仅依赖视觉观察的无状态策略，显著提升了空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索视觉运动策略中本体感觉输入对空间泛化的负面影响，并提出解决方案以提升机器人操作的适应性和效率。

Method: 提出无状态策略，仅基于视觉观察预测动作，并通过双腕宽角相机提供全面的任务相关视觉观察。

Result: 在真实任务中，无状态策略在高度和水平泛化中的成功率分别从0%提升至85%和从6%提升至64%，并展示了更好的数据效率和跨机器人适应性。

Conclusion: 无状态策略通过去除本体感觉输入，显著提升了空间泛化能力和实用性，适用于多种机器人操作任务。

Abstract: Imitation-learning-based visuomotor policies have been widely used in robot
manipulation, where both visual observations and proprioceptive states are
typically adopted together for precise control. However, in this study, we find
that this common practice makes the policy overly reliant on the proprioceptive
state input, which causes overfitting to the training trajectories and results
in poor spatial generalization. On the contrary, we propose the State-free
Policy, removing the proprioceptive state input and predicting actions only
conditioned on visual observations. The State-free Policy is built in the
relative end-effector action space, and should ensure the full task-relevant
visual observations, here provided by dual wide-angle wrist cameras. Empirical
results demonstrate that the State-free policy achieves significantly stronger
spatial generalization than the state-based policy: in real-world tasks such as
pick-and-place, challenging shirt-folding, and complex whole-body manipulation,
spanning multiple robot embodiments, the average success rate improves from 0\%
to 85\% in height generalization and from 6\% to 64\% in horizontal
generalization. Furthermore, they also show advantages in data efficiency and
cross-embodiment adaptation, enhancing their practicality for real-world
deployment.

</details>


### [42] [SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer](https://arxiv.org/abs/2509.18648)
*Yarden As,Chengrui Qu,Benjamin Unger,Dongho Kang,Max van der Hart,Laixi Shi,Stelian Coros,Adam Wierman,Andreas Krause*

Main category: cs.RO

TL;DR: SPiDR是一种通过悲观域随机化实现安全模拟到现实传输的可扩展算法，解决了强化学习在现实应用中的安全问题。


<details>
  <summary>Details</summary>
Motivation: 由于模拟与现实的差距可能导致安全约束在现实环境中失效，现有的鲁棒安全强化学习方法难以与标准可扩展训练流程兼容，促使开发一种更兼容且安全的新方法。

Method: SPiDR利用域随机化技术，将模拟到现实的差距不确定性融入安全约束中，确保训练过程中考虑现实环境的不确定性。

Result: 在模拟到模拟基准测试和两种真实机器人平台上的实验中，SPiDR显著提高了安全性，同时保持了高性能。

Conclusion: SPiDR提供了一种高效的解决方案，能够在模拟到现实的传输中有效保障安全性，且易于与现有训练流程集成。

Abstract: Safety remains a major concern for deploying reinforcement learning (RL) in
real-world applications. Simulators provide safe, scalable training
environments, but the inevitable sim-to-real gap introduces additional safety
concerns, as policies must satisfy constraints in real-world conditions that
differ from simulation. To address this challenge, robust safe RL techniques
offer principled methods, but are often incompatible with standard scalable
training pipelines. In contrast, domain randomization, a simple and popular
sim-to-real technique, stands out as a promising alternative, although it often
results in unsafe behaviors in practice. We present SPiDR, short for
Sim-to-real via Pessimistic Domain Randomization -- a scalable algorithm with
provable guarantees for safe sim-to-real transfer. SPiDR uses domain
randomization to incorporate the uncertainty about the sim-to-real gap into the
safety constraints, making it versatile and highly compatible with existing
training pipelines. Through extensive experiments on sim-to-sim benchmarks and
two distinct real-world robotic platforms, we demonstrate that SPiDR
effectively ensures safety despite the sim-to-real gap while maintaining strong
performance.

</details>


### [43] [Distributionally Robust Safe Motion Planning with Contextual Information](https://arxiv.org/abs/2509.18666)
*Kaizer Rahaman,Simran Kumari,Ashish R. Hota*

Main category: cs.RO

TL;DR: 提出了一种基于上下文信息的分布鲁棒碰撞避免方法，通过RKHS嵌入障碍物未来轨迹的条件分布，并在运动规划中应用。


<details>
  <summary>Details</summary>
Motivation: 解决传统碰撞避免方法未考虑上下文信息和分布不确定性的问题。

Method: 使用RKHS嵌入条件分布，构建分布模糊集，并纳入运动规划的滚动时域框架。

Result: 仿真显示该方法在不包含上下文或分布鲁棒性的场景中效果更优。

Conclusion: 结合上下文和分布鲁棒性显著提升了碰撞避免的成功率。

Abstract: We present a distributionally robust approach for collision avoidance by
incorporating contextual information. Specifically, we embed the conditional
distribution of future trajectory of the obstacle conditioned on the motion of
the ego agent in a reproducing kernel Hilbert space (RKHS) via the conditional
kernel mean embedding operator. Then, we define an ambiguity set containing all
distributions whose embedding in the RKHS is within a certain distance from the
empirical estimate of conditional mean embedding learnt from past data.
Consequently, a distributionally robust collision avoidance constraint is
formulated, and included in the receding horizon based motion planning
formulation of the ego agent. Simulation results show that the proposed
approach is more successful in avoiding collision compared to approaches that
do not include contextual information and/or distributional robustness in their
formulation in several challenging scenarios.

</details>


### [44] [N2M: Bridging Navigation and Manipulation by Learning Pose Preference from Rollout](https://arxiv.org/abs/2509.18671)
*Kaixin Chai,Hyunjun Lee,Joseph J. Lim*

Main category: cs.RO

TL;DR: 论文提出N2M模块，用于在机器人到达任务区域后引导其调整到更有利的初始位姿，显著提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 导航模块与操作策略之间的位姿偏好不匹配，导致任务成功率低。

Method: N2M模块仅依赖机器人自身观测，实时适应环境变化，具有高鲁棒性和广泛适用性。

Result: 在PnPCounterToCab任务中，成功率从3%提升到54%；在Toybox Handover任务中，仅需15个数据样本即可在未见环境中可靠预测。

Conclusion: N2M显著提升了任务成功率和数据效率，具有广泛的应用潜力。

Abstract: In mobile manipulation, the manipulation policy has strong preferences for
initial poses where it is executed. However, the navigation module focuses
solely on reaching the task area, without considering which initial pose is
preferable for downstream manipulation. To address this misalignment, we
introduce N2M, a transition module that guides the robot to a preferable
initial pose after reaching the task area, thereby substantially improving task
success rates. N2M features five key advantages: (1) reliance solely on
ego-centric observation without requiring global or historical information; (2)
real-time adaptation to environmental changes; (3) reliable prediction with
high viewpoint robustness; (4) broad applicability across diverse tasks,
manipulation policies, and robot hardware; and (5) remarkable data efficiency
and generalizability. We demonstrate the effectiveness of N2M through extensive
simulation and real-world experiments. In the PnPCounterToCab task, N2M
improves the averaged success rate from 3% with the reachability-based baseline
to 54%. Furthermore, in the Toybox Handover task, N2M provides reliable
predictions even in unseen environments with only 15 data samples, showing
remarkable data efficiency and generalizability.

</details>


### [45] [3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space](https://arxiv.org/abs/2509.18676)
*Sangjun Noh,Dongwoo Nam,Kangmin Kim,Geonhyup Lee,Yeonguk Yu,Raeyoung Kang,Kyoobin Lee*

Main category: cs.RO

TL;DR: 论文提出了一种名为3D Flow Diffusion Policy（3D FDP）的新框架，利用3D流作为中间表示来捕捉局部运动线索，显著提升了机器人操作的泛化能力和精确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽视局部运动线索，而精确的接触式操作需要这些线索。本文旨在通过引入场景级3D流来填补这一空白。

Method: 通过预测采样查询点的时间轨迹，并结合扩散架构生成动作，3D FDP能够在局部动力学的基础上推理更广泛的场景影响。

Result: 在MetaWorld基准测试中，3D FDP在50项任务中表现最佳，特别是在中等和困难任务中。实物机器人测试也验证了其在接触式和非抓取任务中的优越性。

Conclusion: 3D流是学习泛化视觉运动策略的有效结构化先验，为开发更鲁棒和多功能的机器人操作提供了支持。

Abstract: Learning robust visuomotor policies that generalize across diverse objects
and interaction dynamics remains a central challenge in robotic manipulation.
Most existing approaches rely on direct observation-to-action mappings or
compress perceptual inputs into global or object-centric features, which often
overlook localized motion cues critical for precise and contact-rich
manipulation. We present 3D Flow Diffusion Policy (3D FDP), a novel framework
that leverages scene-level 3D flow as a structured intermediate representation
to capture fine-grained local motion cues. Our approach predicts the temporal
trajectories of sampled query points and conditions action generation on these
interaction-aware flows, implemented jointly within a unified diffusion
architecture. This design grounds manipulation in localized dynamics while
enabling the policy to reason about broader scene-level consequences of
actions. Extensive experiments on the MetaWorld benchmark show that 3D FDP
achieves state-of-the-art performance across 50 tasks, particularly excelling
on medium and hard settings. Beyond simulation, we validate our method on eight
real-robot tasks, where it consistently outperforms prior baselines in
contact-rich and non-prehensile scenarios. These results highlight 3D flow as a
powerful structural prior for learning generalizable visuomotor policies,
supporting the development of more robust and versatile robotic manipulation.
Robot demonstrations, additional results, and code can be found at
https://sites.google.com/view/3dfdp/home.

</details>


### [46] [Query-Centric Diffusion Policy for Generalizable Robotic Assembly](https://arxiv.org/abs/2509.18686)
*Ziyi Xu,Haohong Lin,Shiqi Liu,Ding Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于查询的层次化策略（QDP），用于解决机器人装配任务中高层规划和底层控制之间的不匹配问题，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人装配任务中因部件复杂性和噪声扰动导致的层次化策略实施困难。

Method: 提出查询为中心的扩散策略（QDP），通过对象、接触点和技能信息的查询，指导底层控制，并利用点云观测提升鲁棒性。

Result: 在仿真和真实环境中，QDP在技能精度和长时程任务成功率上表现优异，插入和拧螺丝任务成功率比基线提高50%以上。

Conclusion: QDP通过查询机制有效连接了高层规划和底层控制，显著提升了机器人装配任务的性能。

Abstract: The robotic assembly task poses a key challenge in building generalist robots
due to the intrinsic complexity of part interactions and the sensitivity to
noise perturbations in contact-rich settings. The assembly agent is typically
designed in a hierarchical manner: high-level multi-part reasoning and
low-level precise control. However, implementing such a hierarchical policy is
challenging in practice due to the mismatch between high-level skill queries
and low-level execution. To address this, we propose the Query-centric
Diffusion Policy (QDP), a hierarchical framework that bridges high-level
planning and low-level control by utilizing queries comprising objects, contact
points, and skill information. QDP introduces a query-centric mechanism that
identifies task-relevant components and uses them to guide low-level policies,
leveraging point cloud observations to improve the policy's robustness. We
conduct comprehensive experiments on the FurnitureBench in both simulation and
real-world settings, demonstrating improved performance in skill precision and
long-horizon success rate. In the challenging insertion and screwing tasks, QDP
improves the skill-wise success rate by over 50% compared to baselines without
structured queries.

</details>


### [47] [Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation](https://arxiv.org/abs/2509.18734)
*Nishant Doshi,Amey Sutvani,Sanket Gujar*

Main category: cs.RO

TL;DR: 论文探讨了自主飞行器在城市环境中导航的挑战，提出了一种基于深度摄像头和强化学习的虚拟四旋翼机器人避障方法。


<details>
  <summary>Details</summary>
Motivation: 城市环境中由于GPS精度下降、狭窄空间和动态障碍物等因素，飞行器的路径规划变得复杂，需要有效的避障能力。

Method: 使用深度摄像头和强化学习训练虚拟四旋翼机器人，模拟城市环境中的导航任务。

Result: 展示了如何通过强化学习提升飞行器在城市环境中的避障能力。

Conclusion: 该方法为自主飞行器在城市环境中的导航提供了新的解决方案。

Abstract: One of the challenges faced by Autonomous Aerial Vehicles is reliable
navigation through urban environments. Factors like reduction in precision of
Global Positioning System (GPS), narrow spaces and dynamically moving obstacles
make the path planning of an aerial robot a complicated task. One of the skills
required for the agent to effectively navigate through such an environment is
to develop an ability to avoid collisions using information from onboard depth
sensors. In this paper, we propose Reinforcement Learning of a virtual
quadcopter robot agent equipped with a Depth Camera to navigate through a
simulated urban environment.

</details>


### [48] [MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning](https://arxiv.org/abs/2509.18757)
*Omar Rayyan,John Abanes,Mahmoud Hafez,Anthony Tzes,Fares Abu-Dakka*

Main category: cs.RO

TL;DR: MV-UMI框架通过结合第三人称视角与第一人称视角相机，提高了手持设备数据采集的多样性，减少了领域差异，提升了任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习依赖于高质量数据集，但采集成本高且受限于特定机器人本体。手持设备虽便捷，但仅依靠第一人称视角相机难以捕捉完整场景信息。

Method: 提出MV-UMI框架，整合第三人称与第一人称视角相机，弥补手持设备在场景理解上的不足。

Result: 实验结果显示，MV-UMI在需要广泛场景理解的任务中性能提升约47%，验证了其有效性。

Conclusion: MV-UMI成功扩展了手持设备的学习任务范围，同时保留了其跨本体优势。

Abstract: Recent advances in imitation learning have shown great promise for developing
robust robot manipulation policies from demonstrations. However, this promise
is contingent on the availability of diverse, high-quality datasets, which are
not only challenging and costly to collect but are often constrained to a
specific robot embodiment. Portable handheld grippers have recently emerged as
intuitive and scalable alternatives to traditional robotic teleoperation
methods for data collection. However, their reliance solely on first-person
view wrist-mounted cameras often creates limitations in capturing sufficient
scene contexts. In this paper, we present MV-UMI (Multi-View Universal
Manipulation Interface), a framework that integrates a third-person perspective
with the egocentric camera to overcome this limitation. This integration
mitigates domain shifts between human demonstration and robot deployment,
preserving the cross-embodiment advantages of handheld data-collection devices.
Our experimental results, including an ablation study, demonstrate that our
MV-UMI framework improves performance in sub-tasks requiring broad scene
understanding by approximately 47% across 3 tasks, confirming the effectiveness
of our approach in expanding the range of feasible manipulation tasks that can
be learned using handheld gripper systems, without compromising the
cross-embodiment advantages inherent to such systems.

</details>


### [49] [VGGT-DP: Generalizable Robot Control via Vision Foundation Models](https://arxiv.org/abs/2509.18778)
*Shijia Ge,Yinxin Zhang,Shuzhao Xie,Weixiang Zhang,Mingcai Zhou,Zhi Wang*

Main category: cs.RO

TL;DR: VGGT-DP 是一个结合几何先验和本体感受反馈的视觉模仿学习框架，显著提升了空间理解和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉模仿学习框架主要关注策略设计，而忽视了视觉编码器的结构和能力，这限制了空间理解和泛化能力。

Method: 提出 VGGT-DP 框架，结合预训练的 3D 感知模型的几何先验和本体感受反馈，采用 VGGT 作为视觉编码器，并引入本体感受引导的视觉学习策略。设计了帧级标记重用机制和随机标记剪枝以提升效率和鲁棒性。

Result: 在 MetaWorld 任务中，VGGT-DP 显著优于 DP 和 DP3 基线，尤其在需要高精度和长周期任务中表现突出。

Conclusion: VGGT-DP 通过结合几何先验和本体感受反馈，提升了视觉模仿学习的空间理解和泛化能力，适用于复杂任务。

Abstract: Visual imitation learning frameworks allow robots to learn manipulation
skills from expert demonstrations. While existing approaches mainly focus on
policy design, they often neglect the structure and capacity of visual
encoders, limiting spatial understanding and generalization. Inspired by
biological vision systems, which rely on both visual and proprioceptive cues
for robust control, we propose VGGT-DP, a visuomotor policy framework that
integrates geometric priors from a pretrained 3D perception model with
proprioceptive feedback. We adopt the Visual Geometry Grounded Transformer
(VGGT) as the visual encoder and introduce a proprioception-guided visual
learning strategy to align perception with internal robot states, improving
spatial grounding and closed-loop control. To reduce inference latency, we
design a frame-wise token reuse mechanism that compacts multi-view tokens into
an efficient spatial representation. We further apply random token pruning to
enhance policy robustness and reduce overfitting. Experiments on challenging
MetaWorld tasks show that VGGT-DP significantly outperforms strong baselines
such as DP and DP3, particularly in precision-critical and long-horizon
scenarios.

</details>


### [50] [Human-Interpretable Uncertainty Explanations for Point Cloud Registration](https://arxiv.org/abs/2509.18786)
*Johannes A. Gaus,Loris Schneider,Yitian Shi,Jongseok Lee,Rania Rayyes,Rudolph Triebel*

Main category: cs.RO

TL;DR: 该论文提出了一种名为GP-CA的新方法，用于解决点云配准问题中的不确定性，并通过主动学习识别新的不确定性来源，实验证明其在运行时间、样本效率和准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 点云配准问题在传感器噪声、位姿估计误差和遮挡等不确定性条件下，传统方法（如ICP）表现不佳。本文旨在开发一种能够量化和解释这些不确定性的新方法，并在机器人感知中实现更稳健的性能。

Method: 提出了高斯过程概念归因（GP-CA）方法，通过主动学习查询信息性实例来识别不确定性来源，并在三个公开数据集和真实机器人实验中验证其有效性。

Result: GP-CA在运行时间、样本效率和准确性上优于现有方法，并且在真实机器人实验中显示出良好的适用性，能够实现有效的失败恢复行为。

Conclusion: GP-CA为点云配准问题提供了一种能够解释不确定性并提高鲁棒性的解决方案，尤其在机器人感知领域具有实际应用价值。

Abstract: In this paper, we address the point cloud registration problem, where
well-known methods like ICP fail under uncertainty arising from sensor noise,
pose-estimation errors, and partial overlap due to occlusion. We develop a
novel approach, Gaussian Process Concept Attribution (GP-CA), which not only
quantifies registration uncertainty but also explains it by attributing
uncertainty to well-known sources of errors in registration problems. Our
approach leverages active learning to discover new uncertainty sources in the
wild by querying informative instances. We validate GP-CA on three publicly
available datasets and in our real-world robot experiment. Extensive ablations
substantiate our design choices. Our approach outperforms other
state-of-the-art methods in terms of runtime, high sample-efficiency with
active learning, and high accuracy. Our real-world experiment clearly
demonstrates its applicability. Our video also demonstrates that GP-CA enables
effective failure-recovery behaviors, yielding more robust robotic perception.

</details>


### [51] [Application Management in C-ITS: Orchestrating Demand-Driven Deployments and Reconfigurations](https://arxiv.org/abs/2509.18793)
*Lukas Zanger,Bastian Lampe,Lennart Reiher,Lutz Eckstein*

Main category: cs.RO

TL;DR: 论文提出了一种基于Kubernetes的需求驱动应用管理方法，用于动态协调车辆互联系统中的微服务部署与资源优化。


<details>
  <summary>Details</summary>
Motivation: 随着车辆自动化和互联程度的提高，大规模协同智能交通系统（C-ITS）的应用编排面临动态环境和高效资源利用的挑战。

Method: 利用Kubernetes和ROS 2构建的应用管理框架，动态响应C-ITS中不同实体的需求，自动化微服务的部署、重构、更新和扩展。

Result: 该方法降低了计算资源消耗和网络流量，并在集体环境感知用例中验证了其有效性。

Conclusion: 研究表明，基于需求驱动的云原生技术能有效解决C-ITS中的动态应用管理问题。

Abstract: Vehicles are becoming increasingly automated and interconnected, enabling the
formation of cooperative intelligent transport systems (C-ITS) and the use of
offboard services. As a result, cloud-native techniques, such as microservices
and container orchestration, play an increasingly important role in their
operation. However, orchestrating applications in a large-scale C-ITS poses
unique challenges due to the dynamic nature of the environment and the need for
efficient resource utilization. In this paper, we present a demand-driven
application management approach that leverages cloud-native techniques -
specifically Kubernetes - to address these challenges. Taking into account the
demands originating from different entities within the C-ITS, the approach
enables the automation of processes, such as deployment, reconfiguration,
update, upgrade, and scaling of microservices. Executing these processes on
demand can, for example, reduce computing resource consumption and network
traffic. A demand may include a request for provisioning an external supporting
service, such as a collective environment model. The approach handles changing
and new demands by dynamically reconciling them through our proposed
application management framework built on Kubernetes and the Robot Operating
System (ROS 2). We demonstrate the operation of our framework in the C-ITS use
case of collective environment perception and make the source code of the
prototypical framework publicly available at
https://github.com/ika-rwth-aachen/application_manager .

</details>


### [52] [DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation](https://arxiv.org/abs/2509.18830)
*Suzannah Wistreich,Baiyu Shi,Stephen Tian,Samuel Clarke,Michael Nath,Chengyi Xu,Zhenan Bao,Jiajun Wu*

Main category: cs.RO

TL;DR: DexSkin是一种柔软的电容式电子皮肤，用于机器人手的触觉感知，支持学习和数据驱动方法。


<details>
  <summary>Details</summary>
Motivation: 复制人类皮肤的触觉感知能力，以提升机器人操作系统的灵活性和适应性。

Method: 开发DexSkin电子皮肤，并将其应用于平行夹爪手指，进行触觉覆盖。通过示范学习和在线强化学习评估其性能。

Result: DexSkin在复杂操作任务（如物体重新定向和弹性带缠绕）中表现出色，并能跨传感器实例进行模型转移。

Conclusion: DexSkin适用于学习真实世界中接触密集的操作任务，具有实际应用潜力。

Abstract: Human skin provides a rich tactile sensing stream, localizing intentional and
unintentional contact events over a large and contoured region. Replicating
these tactile sensing capabilities for dexterous robotic manipulation systems
remains a longstanding challenge. In this work, we take a step towards this
goal by introducing DexSkin. DexSkin is a soft, conformable capacitive
electronic skin that enables sensitive, localized, and calibratable tactile
sensing, and can be tailored to varying geometries. We demonstrate its efficacy
for learning downstream robotic manipulation by sensorizing a pair of parallel
jaw gripper fingers, providing tactile coverage across almost the entire finger
surfaces. We empirically evaluate DexSkin's capabilities in learning
challenging manipulation tasks that require sensing coverage across the entire
surface of the fingers, such as reorienting objects in hand and wrapping
elastic bands around boxes, in a learning-from-demonstration framework. We then
show that, critically for data-driven approaches, DexSkin can be calibrated to
enable model transfer across sensor instances, and demonstrate its
applicability to online reinforcement learning on real robots. Our results
highlight DexSkin's suitability and practicality for learning real-world,
contact-rich manipulation. Please see our project webpage for videos and
visualizations: https://dex-skin.github.io/.

</details>


### [53] [Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation](https://arxiv.org/abs/2509.18865)
*Masato Kobayashi,Thanpimon Buamanee*

Main category: cs.RO

TL;DR: Bi-VLA是一种新型框架，通过视觉-语言融合扩展了双边控制模仿学习，支持多任务处理，提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的双边控制方法需要针对特定任务的模型，缺乏通用性。Bi-VLA旨在通过结合视觉和语言信息，克服这一限制。

Method: Bi-VLA利用机器人关节角度、速度、扭矩数据，结合视觉特征和自然语言指令，通过SigLIP和FiLM融合处理多任务。

Result: 实验证明，Bi-VLA能有效解释视觉-语言组合，提升任务成功率，优于传统方法。

Conclusion: Bi-VLA突破了传统双边方法的单任务限制，证实了视觉与语言结合对增强通用性的重要性。

Abstract: We propose Bilateral Control-Based Imitation Learning via Vision-Language
Fusion for Action Generation (Bi-VLA), a novel framework that extends bilateral
control-based imitation learning to handle more than one task within a single
model. Conventional bilateral control methods exploit joint angle, velocity,
torque, and vision for precise manipulation but require task-specific models,
limiting their generality. Bi-VLA overcomes this limitation by utilizing robot
joint angle, velocity, and torque data from leader-follower bilateral control
with visual features and natural language instructions through SigLIP and
FiLM-based fusion. We validated Bi-VLA on two task types: one requiring
supplementary language cues and another distinguishable solely by vision.
Real-robot experiments showed that Bi-VLA successfully interprets
vision-language combinations and improves task success rates compared to
conventional bilateral control-based imitation learning. Our Bi-VLA addresses
the single-task limitation of prior bilateral approaches and provides empirical
evidence that combining vision and language significantly enhances versatility.
Experimental results validate the effectiveness of Bi-VLA in real-world tasks.
For additional material, please visit the website:
https://mertcookimg.github.io/bi-vla/

</details>


### [54] [Lang2Morph: Language-Driven Morphological Design of Robotic Hands](https://arxiv.org/abs/2509.18937)
*Yanyuan Qiao,Kieran Gilday,Yutong Xie,Josie Hughes*

Main category: cs.RO

TL;DR: Lang2Morph利用大型语言模型（LLM）生成任务特定的机器人手部形态设计，通过自然语言任务描述转换为符号结构和参数，实现零样本设计推理。


<details>
  <summary>Details</summary>
Motivation: 现有机器人手部设计方法依赖专家启发式或计算密集型优化，而LLM因其广泛的人类-物体交互知识和生成能力，提供了新的设计可能性。

Method: Lang2Morph分为形态设计（任务映射到语义标签、结构语法和参数）和选择与细化（评估语义对齐和尺寸兼容性，可选LLM引导细化）。

Result: 实验表明，Lang2Morph能生成多样且任务相关的手部形态，首次实现了基于LLM的任务条件化机器人手部设计。

Conclusion: Lang2Morph为机器人手部设计提供了高效且无需手动调优的新框架，展示了LLM在形态设计中的潜力。

Abstract: Designing robotic hand morphologies for diverse manipulation tasks requires
balancing dexterity, manufacturability, and task-specific functionality. While
open-source frameworks and parametric tools support reproducible design, they
still rely on expert heuristics and manual tuning. Automated methods using
optimization are often compute-intensive, simulation-dependent, and rarely
target dexterous hands. Large language models (LLMs), with their broad
knowledge of human-object interactions and strong generative capabilities,
offer a promising alternative for zero-shot design reasoning. In this paper, we
present Lang2Morph, a language-driven pipeline for robotic hand design. It uses
LLMs to translate natural-language task descriptions into symbolic structures
and OPH-compatible parameters, enabling 3D-printable task-specific
morphologies. The pipeline consists of: (i) Morphology Design, which maps tasks
into semantic tags, structural grammars, and OPH-compatible parameters; and
(ii) Selection and Refinement, which evaluates design candidates based on
semantic alignment and size compatibility, and optionally applies LLM-guided
refinement when needed. We evaluate Lang2Morph across varied tasks, and results
show that our approach can generate diverse, task-relevant morphologies. To our
knowledge, this is the first attempt to develop an LLM-based framework for
task-conditioned robotic hand design.

</details>


### [55] [Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations](https://arxiv.org/abs/2509.18953)
*Hanqing Liu,Jiahuan Long,Junqi Wu,Jiacheng Hou,Huili Tang,Tingsong Jiang,Weien Zhou,Wen Yao*

Main category: cs.RO

TL;DR: Eva-VLA框架系统评估Vision-Language-Action模型的鲁棒性，将离散物理变化转化为连续优化问题，揭示了现有模型对真实世界物理变化的脆弱性。


<details>
  <summary>Details</summary>
Motivation: Vision-Language-Action模型在机器人操纵中具有潜力，但其对真实世界物理变化的鲁棒性研究不足。为解决这一问题，提出Eva-VLA框架。

Method: 将物理变化分解为对象3D变换、光照变化和对抗性补丁三个领域，并引入连续黑盒优化框架，探索最坏情况场景。

Result: 实验显示，OpenVLA模型对所有变化的故障率超过60%，对象变换在长时任务中故障率高达97.8%。

Conclusion: Eva-VLA框架为提升VLA模型在真实世界部署中的鲁棒性提供了实用途径。

Abstract: Vision-Language-Action (VLA) models have emerged as promising solutions for
robotic manipulation, yet their robustness to real-world physical variations
remains critically underexplored. To bridge this gap, we propose Eva-VLA, the
first unified framework that systematically evaluates the robustness of VLA
models by transforming discrete physical variations into continuous
optimization problems. However, comprehensively assessing VLA robustness
presents two key challenges: (1) how to systematically characterize diverse
physical variations encountered in real-world deployments while maintaining
evaluation reproducibility, and (2) how to discover worst-case scenarios
without prohibitive real-world data collection costs efficiently. To address
the first challenge, we decompose real-world variations into three critical
domains: object 3D transformations that affect spatial reasoning, illumination
variations that challenge visual perception, and adversarial patches that
disrupt scene understanding. For the second challenge, we introduce a
continuous black-box optimization framework that transforms discrete physical
variations into parameter optimization, enabling systematic exploration of
worst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models
across multiple benchmarks reveal alarming vulnerabilities: all variation types
trigger failure rates exceeding 60%, with object transformations causing up to
97.8% failure in long-horizon tasks. Our findings expose critical gaps between
controlled laboratory success and unpredictable deployment readiness, while the
Eva-VLA framework provides a practical pathway for hardening VLA-based robotic
manipulation models against real-world deployment challenges.

</details>


### [56] [Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation](https://arxiv.org/abs/2509.18954)
*Minoo Dolatabadi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.RO

TL;DR: 该论文提出了一种基于深度学习的框架，用于在无参考地图的情况下预测ICP的配准误差协方差，从而提高LiDAR定位和SLAM的精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: ICP算法在特征缺失环境或动态场景中表现不佳，现有方法难以准确估计误差协方差，且依赖预建地图或提供二元分类，无法有效建模不确定性。

Method: 采用深度学习框架，预先估计LiDAR扫描的6自由度误差协方差，无需依赖参考地图，并将结果无缝集成到卡尔曼滤波中。

Result: 在KITTI数据集上的实验表明，该方法能准确预测协方差，显著减少定位误差并提升鲁棒性。

Conclusion: 该数据驱动框架为ICP在复杂环境中的不确定性建模提供了有效解决方案，增强了SLAM和定位系统的可靠性。

Abstract: LiDAR-based localization and SLAM often rely on iterative matching
algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align
sensor data with pre-existing maps or previous scans. However, ICP is prone to
errors in featureless environments and dynamic scenes, leading to inaccurate
pose estimation. Accurately predicting the uncertainty associated with ICP is
crucial for robust state estimation but remains challenging, as existing
approaches often rely on handcrafted models or simplified assumptions.
Moreover, a few deep learning-based methods for localizability estimation
either depend on a pre-built map, which may not always be available, or provide
a binary classification of localizable versus non-localizable, which fails to
properly model uncertainty. In this work, we propose a data-driven framework
that leverages deep learning to estimate the registration error covariance of
ICP before matching, even in the absence of a reference map. By associating
each LiDAR scan with a reliable 6-DoF error covariance estimate, our method
enables seamless integration of ICP within Kalman filtering, enhancing
localization accuracy and robustness. Extensive experiments on the KITTI
dataset demonstrate the effectiveness of our approach, showing that it
accurately predicts covariance and, when applied to localization using a
pre-built map or SLAM, reduces localization errors and improves robustness.

</details>


### [57] [Category-Level Object Shape and Pose Estimation in Less Than a Millisecond](https://arxiv.org/abs/2509.18979)
*Lorenzo Shaikewitz,Tim Nguyen,Luca Carlone*

Main category: cs.RO

TL;DR: 本文提出了一种快速局部求解器，用于物体形状和姿态估计，仅需类别级别的物体先验，并提供高效的全局最优性证明。通过RGB-D图像和学习的语义关键点检测，结合线性主动形状模型，解决了姿态和形状的同时优化问题。


<details>
  <summary>Details</summary>
Motivation: 物体形状和姿态估计是机器人学中的基础问题，对操纵、场景理解和导航等任务至关重要。本文旨在提供一种高效且可靠的估计方法。

Method: 使用学习的前端检测类别级别的语义关键点，通过线性主动形状模型表示物体形状，并将问题转化为基于单位四元数的最大后验优化问题，利用自洽场迭代高效求解。

Result: 该方法在合成数据和真实场景中（包括两个公共数据集和无人机跟踪场景）表现出色，每次迭代仅需约100微秒，并能快速剔除异常值。

Conclusion: 本文提出的方法在速度和最优性证明方面具有优势，为物体形状和姿态估计任务提供了高效且可靠的解决方案。代码已开源。

Abstract: Object shape and pose estimation is a foundational robotics problem,
supporting tasks from manipulation to scene understanding and navigation. We
present a fast local solver for shape and pose estimation which requires only
category-level object priors and admits an efficient certificate of global
optimality. Given an RGB-D image of an object, we use a learned front-end to
detect sparse, category-level semantic keypoints on the target object. We
represent the target object's unknown shape using a linear active shape model
and pose a maximum a posteriori optimization problem to solve for position,
orientation, and shape simultaneously. Expressed in unit quaternions, this
problem admits first-order optimality conditions in the form of an eigenvalue
problem with eigenvector nonlinearities. Our primary contribution is to solve
this problem efficiently with self-consistent field iteration, which only
requires computing a 4-by-4 matrix and finding its minimum eigenvalue-vector
pair at each iterate. Solving a linear system for the corresponding Lagrange
multipliers gives a simple global optimality certificate. One iteration of our
solver runs in about 100 microseconds, enabling fast outlier rejection. We test
our method on synthetic data and a variety of real-world settings, including
two public datasets and a drone tracking scenario. Code is released at
https://github.com/MIT-SPARK/Fast-ShapeAndPose.

</details>


### [58] [Pure Vision Language Action (VLA) Models: A Comprehensive Survey](https://arxiv.org/abs/2509.19012)
*Dapeng Zhang,Jin Sun,Chenghui Hu,Xiaoyan Wu,Zhenlong Yuan,Rui Zhou,Fei Shen,Qingguo Zhou*

Main category: cs.RO

TL;DR: 该论文综述了视觉语言动作（VLA）模型的最新进展，从传统策略控制转向通用机器人技术，并详细分类了VLA方法及其应用。


<details>
  <summary>Details</summary>
Motivation: 研究VLA模型的动机是从被动序列生成转向主动决策，以应对复杂动态环境中的操作任务。

Method: 论文通过对300多项研究的综合分析，将VLA方法分为自回归、扩散、强化学习、混合和专用方法，并探讨其核心策略与实现。

Result: 提出了VLA在各个场景中的应用分析，并介绍了基础数据集、基准和仿真平台。

Conclusion: 综述指出了VLA研究的挑战与未来方向，为通用VLA方法的发展提供了前瞻性视角。

Abstract: The emergence of Vision Language Action (VLA) models marks a paradigm shift
from traditional policy-based control to generalized robotics, reframing Vision
Language Models (VLMs) from passive sequence generators into active agents for
manipulation and decision-making in complex, dynamic environments. This survey
delves into advanced VLA methods, aiming to provide a clear taxonomy and a
systematic, comprehensive review of existing research. It presents a
comprehensive analysis of VLA applications across different scenarios and
classifies VLA approaches into several paradigms: autoregression-based,
diffusion-based, reinforcement-based, hybrid, and specialized methods; while
examining their motivations, core strategies, and implementations in detail. In
addition, foundational datasets, benchmarks, and simulation platforms are
introduced. Building on the current VLA landscape, the review further proposes
perspectives on key challenges and future directions to advance research in VLA
models and generalizable robotics. By synthesizing insights from over three
hundred recent studies, this survey maps the contours of this rapidly evolving
field and highlights the opportunities and challenges that will shape the
development of scalable, general-purpose VLA methods.

</details>


### [59] [Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion](https://arxiv.org/abs/2509.19023)
*Shuai Liu,Meng Cheng Lau*

Main category: cs.RO

TL;DR: 论文提出了一种两阶段的强化学习框架ROM-GRL，用于人形机器人行走，无需运动捕捉数据或复杂奖励设计。该方法通过轻量级ROM生成能量高效的步态模板，再引导高维策略训练，实现了稳定、对称的步态表现优于纯奖励基线。


<details>
  <summary>Details</summary>
Motivation: 传统的人形机器人步态控制方法通常依赖运动捕捉数据或复杂的奖励设计，限制了其通用性和自然性。

Method: ROM-GRL分为两个阶段：1) 使用PPO训练4-DOF的轻量级ROM生成步态模板；2) 通过对抗判别器引导SAC训练全身体策略，确保步态特征分布与ROM一致。

Result: 实验显示ROM-GRL在1-4米/秒速度下生成了稳定、对称的步态，跟踪误差显著低于纯奖励基线。

Conclusion: ROM-GRL结合了奖励和模仿方法的优点，无需人类演示即可实现自然、通用的人形机器人步态控制。

Abstract: We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a
two-stage reinforcement learning framework for humanoid walking that requires
no motion capture data or elaborate reward shaping. In the first stage, a
compact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via
Proximal Policy Optimization. This generates energy-efficient gait templates.
In the second stage, those dynamically consistent trajectories guide a
full-body policy trained with Soft Actor--Critic augmented by an adversarial
discriminator, ensuring the student's five-dimensional gait feature
distribution matches the ROM's demonstrations. Experiments at 1
meter-per-second and 4 meter-per-second show that ROM-GRL produces stable,
symmetric gaits with substantially lower tracking error than a pure-reward
baseline. By distilling lightweight ROM guidance into high-dimensional
policies, ROM-GRL bridges the gap between reward-only and imitation-based
locomotion methods, enabling versatile, naturalistic humanoid behaviors without
any human demonstrations.

</details>


### [60] [TacEva: A Performance Evaluation Framework For Vision-Based Tactile Sensors](https://arxiv.org/abs/2509.19037)
*Qingzheng Cong,Steven Oh,Wen Fan,Shan Luo,Kaspar Althoefer,Dandan Zhang*

Main category: cs.RO

TL;DR: 论文摘要介绍了一种名为TacEva的评估框架，用于定量分析视觉触觉传感器（VBTS）的性能，解决了现有VBTS缺乏标准化指标的问题。


<details>
  <summary>Details</summary>
Motivation: 现有VBTS在传感机制和结构参数上存在差异，导致性能差异显著，缺乏标准化指标使其难以针对特定任务进行优化和选择。

Method: TacEva框架定义了一套性能指标，并设计了结构化实验流程，确保一致性和可重复性，用于评估不同VBTS的性能。

Result: 框架成功应用于多种VBTS，提供了全面评估和定量指标，帮助研究者按任务选择合适的传感器并优化设计。

Conclusion: TacEva为VBTS的标准化评估提供了有效工具，促进了传感器选择和性能优化。

Abstract: Vision-Based Tactile Sensors (VBTSs) are widely used in robotic tasks because
of the high spatial resolution they offer and their relatively low
manufacturing costs. However, variations in their sensing mechanisms,
structural dimension, and other parameters lead to significant performance
disparities between existing VBTSs. This makes it challenging to optimize them
for specific tasks, as both the initial choice and subsequent fine-tuning are
hindered by the lack of standardized metrics. To address this issue, TacEva is
introduced as a comprehensive evaluation framework for the quantitative
analysis of VBTS performance. The framework defines a set of performance
metrics that capture key characteristics in typical application scenarios. For
each metric, a structured experimental pipeline is designed to ensure
consistent and repeatable quantification. The framework is applied to multiple
VBTSs with distinct sensing mechanisms, and the results demonstrate its ability
to provide a thorough evaluation of each design and quantitative indicators for
each performance dimension. This enables researchers to pre-select the most
appropriate VBTS on a task by task basis, while also offering
performance-guided insights into the optimization of VBTS design. A list of
existing VBTS evaluation methods and additional evaluations can be found on our
website: https://stevenoh2003.github.io/TacEva/

</details>


### [61] [ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation](https://arxiv.org/abs/2509.19047)
*Geonhyup Lee,Yeongjin Lee,Kangmin Kim,Seongju Lee,Sangjun Noh,Seunghyeok Back,Kyoobin Lee*

Main category: cs.RO

TL;DR: ManipForce系统通过捕捉高频力扭矩和RGB数据，结合FMT模型提升了接触密集型任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法主要依赖视觉演示，无法精确控制交互力，尤其是在接触密集型任务如精密装配中。

Method: 设计了ManipForce手持系统，捕捉高频力扭矩和RGB数据；提出FMT模型，通过频率和模态感知的嵌入以及双向交叉注意力融合多模态数据。

Result: 在六个现实任务中，FMT的平均成功率为83%，显著优于仅基于RGB的基线。

Conclusion: 高频力扭矩数据和跨模态整合显著提升了策略性能，尤其是在高精度和稳定接触需求的任务中。

Abstract: Contact-rich manipulation tasks such as precision assembly require precise
control of interaction forces, yet existing imitation learning methods rely
mainly on vision-only demonstrations. We propose ManipForce, a handheld system
designed to capture high-frequency force-torque (F/T) and RGB data during
natural human demonstrations for contact-rich manipulation. Building on these
demonstrations, we introduce the Frequency-Aware Multimodal Transformer (FMT).
FMT encodes asynchronous RGB and F/T signals using frequency- and
modality-aware embeddings and fuses them via bi-directional cross-attention
within a transformer diffusion policy. Through extensive experiments on six
real-world contact-rich manipulation tasks - such as gear assembly, box
flipping, and battery insertion - FMT trained on ManipForce demonstrations
achieves robust performance with an average success rate of 83% across all
tasks, substantially outperforming RGB-only baselines. Ablation and
sampling-frequency analyses further confirm that incorporating high-frequency
F/T data and cross-modal integration improves policy performance, especially in
tasks demanding high precision and stable contact.

</details>


### [62] [SlicerROS2: A Research and Development Module for Image-Guided Robotic Interventions](https://arxiv.org/abs/2509.19076)
*Laura Connolly,Aravind S. Kumar,Kapi Ketan Mehta,Lidia Al-Zogbi,Peter Kazanzides,Parvin Mousavi,Gabor Fichtinger,Axel Krieger,Junichi Tokuda,Russell H. Taylor,Simon Leonard,Anton Deguet*

Main category: cs.RO

TL;DR: SlicerROS2是一个结合3D Slicer和ROS的软件模块，旨在为医学机器人研究提供标准集成方案。本文介绍了其新设计及四个应用案例。


<details>
  <summary>Details</summary>
Motivation: 通过整合3D Slicer和ROS，为医学机器人研究提供一个标准化的集成平台。

Method: 重新设计和改进了SlicerROS2模块，增加了模块化、低层次功能访问、Python API支持及数据传输协议优化。

Result: 展示了SlicerROS2模块的核心功能在四个真实图像引导机器人场景中的应用。

Conclusion: SlicerROS2为医学机器人研究提供了一个高效且标准化的集成方案。

Abstract: Image-guided robotic interventions involve the use of medical imaging in
tandem with robotics. SlicerROS2 is a software module that combines 3D Slicer
and robot operating system (ROS) in pursuit of a standard integration approach
for medical robotics research. The first release of SlicerROS2 demonstrated the
feasibility of using the C++ API from 3D Slicer and ROS to load and visualize
robots in real time. Since this initial release, we've rewritten and redesigned
the module to offer greater modularity, access to low-level features, access to
3D Slicer's Python API, and better data transfer protocols. In this paper, we
introduce this new design as well as four applications that leverage the core
functionalities of SlicerROS2 in realistic image-guided robotics scenarios.

</details>


### [63] [World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](https://arxiv.org/abs/2509.19080)
*Zhennan Jiang,Kai Liu,Yuxin Qin,Shuai Tian,Yupeng Zheng,Mingcai Zhou,Chao Yu,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: World4RL是一种基于扩散模型的世界模型框架，用于在仿真环境中优化预训练的机器人操作策略，避免了真实世界的高成本和安全性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作策略通常依赖于模仿学习，但专家数据的稀缺性限制了性能；强化学习虽可优化策略，但真实世界的训练成本高且不安全，仿真训练则存在仿真与现实的差距。

Method: 提出了World4RL框架，利用扩散模型作为高保真仿真器，通过多任务数据集预训练世界模型，并在冻结的世界模型中完全优化策略。设计了适合机器人操作的双热点动作编码方案和扩散模型主干以提高建模保真度。

Result: 仿真和真实世界的实验表明，World4RL能够提供高保真的环境建模，并显著提高策略的成功率，优于模仿学习和其他基线方法。

Conclusion: World4RL展示了扩散模型在机器人操作策略优化中的潜力，通过仿真环境实现了高效且安全的策略改进。

Abstract: Robotic manipulation policies are commonly initialized through imitation
learning, but their performance is limited by the scarcity and narrow coverage
of expert data. Reinforcement learning can refine polices to alleviate this
limitation, yet real-robot training is costly and unsafe, while training in
simulators suffers from the sim-to-real gap. Recent advances in generative
models have demonstrated remarkable capabilities in real-world simulation, with
diffusion models in particular excelling at generation. This raises the
question of how diffusion model-based world models can be combined to enhance
pre-trained policies in robotic manipulation. In this work, we propose
World4RL, a framework that employs diffusion-based world models as
high-fidelity simulators to refine pre-trained policies entirely in imagined
environments for robotic manipulation. Unlike prior works that primarily employ
world models for planning, our framework enables direct end-to-end policy
optimization. World4RL is designed around two principles: pre-training a
diffusion world model that captures diverse dynamics on multi-task datasets and
refining policies entirely within a frozen world model to avoid online
real-world interactions. We further design a two-hot action encoding scheme
tailored for robotic manipulation and adopt diffusion backbones to improve
modeling fidelity. Extensive simulation and real-world experiments demonstrate
that World4RL provides high-fidelity environment modeling and enables
consistent policy refinement, yielding significantly higher success rates
compared to imitation learning and other baselines. More visualization results
are available at https://world4rl.github.io/.

</details>


### [64] [FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.19102)
*Hongli Xu,Lei Zhang,Xiaoyue Hu,Boyang Zhong,Kaixin Bai,Zoltán-Csaba Márton,Zhenshan Bing,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: FunCanon框架通过将长周期任务分解为动作块，利用功能对象对齐和扩散策略提升机器人技能的通用性。


<details>
  <summary>Details</summary>
Motivation: 解决端到端演示中任务特定策略泛化能力差的问题。

Method: 通过功能对象对齐和FuncDiffuser扩散策略，将对象映射到共享功能框架。

Result: 在仿真和实境基准测试中表现出类别级泛化和任务间行为重用能力。

Conclusion: 功能对齐为复杂操作领域的模仿学习提供了强归纳偏置。

Abstract: General-purpose robotic skills from end-to-end demonstrations often leads to
task-specific policies that fail to generalize beyond the training
distribution. Therefore, we introduce FunCanon, a framework that converts
long-horizon manipulation tasks into sequences of action chunks, each defined
by an actor, verb, and object. These chunks focus policy learning on the
actions themselves, rather than isolated tasks, enabling compositionality and
reuse. To make policies pose-aware and category-general, we perform functional
object canonicalization for functional alignment and automatic manipulation
trajectory transfer, mapping objects into shared functional frames using
affordance cues from large vision language models. An object centric and action
centric diffusion policy FuncDiffuser trained on this aligned data naturally
respects object affordances and poses, simplifying learning and improving
generalization ability. Experiments on simulated and real-world benchmarks
demonstrate category-level generalization, cross-task behavior reuse, and
robust sim2real deployment, showing that functional canonicalization provides a
strong inductive bias for scalable imitation learning in complex manipulation
domains. Details of the demo and supplemental material are available on our
project website https://sites.google.com/view/funcanon.

</details>


### [65] [Spectral Signature Mapping from RGB Imagery for Terrain-Aware Navigation](https://arxiv.org/abs/2509.19105)
*Sarvesh Prajapati,Ananya Trivedi,Nathaniel Hanson,Bruce Maxwell,Taskin Padir*

Main category: cs.RO

TL;DR: 论文提出了RS-Net，一种从RGB图像预测光谱特征的神经网络，用于解决户外导航中地形分类和摩擦系数估计的问题，无需依赖昂贵的光谱传感器。


<details>
  <summary>Details</summary>
Motivation: 户外导航中，传统方法依赖几何或语义标签分类可通行表面，但无法区分视觉相似但材质不同的表面。光谱传感器能提供材质信息，但受限于硬件集成和高成本。

Method: 提出RS-Net，通过深度学习从RGB图像预测光谱特征，并进一步映射为地形标签和摩擦系数，应用于轮式机器人和四足机器人的运动规划。

Result: 实现了仅依赖RGB图像的材质信息预测，成功应用于机器人导航任务。

Conclusion: RS-Net提供了一种低成本、高效的替代方案，使机器人在户外环境中更易获取材质信息。

Abstract: Successful navigation in outdoor environments requires accurate prediction of
the physical interactions between the robot and the terrain. To this end,
several methods rely on geometric or semantic labels to classify traversable
surfaces. However, such labels cannot distinguish visually similar surfaces
that differ in material properties. Spectral sensors enable inference of
material composition from surface reflectance measured across multiple
wavelength bands. Although spectral sensing is gaining traction in robotics,
widespread deployment remains constrained by the need for custom hardware
integration, high sensor costs, and compute-intensive processing pipelines. In
this paper, we present RGB Image to Spectral Signature Neural Network (RS-Net),
a deep neural network designed to bridge the gap between the accessibility of
RGB sensing and the rich material information provided by spectral data. RS-Net
predicts spectral signatures from RGB patches, which we map to terrain labels
and friction coefficients. The resulting terrain classifications are integrated
into a sampling-based motion planner for a wheeled robot operating in outdoor
environments. Likewise, the friction estimates are incorporated into a
contact-force-based MPC for a quadruped robot navigating slippery surfaces.
Thus, we introduce a framework that learns the task-relevant physical property
once during training and thereafter relies solely on RGB sensing at test time.
The code is available at https://github.com/prajapatisarvesh/RS-Net.

</details>


### [66] [BiGraspFormer: End-to-End Bimanual Grasp Transformer](https://arxiv.org/abs/2509.19142)
*Kangmin Kim,Seunghyeok Back,Geonhyup Lee,Sangbeom Lee,Sangjun Noh,Kyoobin Lee*

Main category: cs.RO

TL;DR: BiGraspFormer是一个统一的端到端Transformer框架，直接从物体点云生成协调的双臂抓取，解决了现有方法中协调不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的双臂抓取方法要么仅关注单臂抓取，要么采用分离的抓取生成和双臂评估阶段，导致碰撞风险和不平衡力分布等协调问题。

Method: BiGraspFormer通过Single-Guided Bimanual（SGB）策略，首先生成多样的单抓取候选，然后利用其学习特征通过注意力机制联合预测双臂姿态和质量分数。

Result: 实验证明BiGraspFormer在性能和速度（<0.05秒）上均优于现有方法，并验证了其有效性。

Conclusion: BiGraspFormer能够高效生成协调的双臂抓取，为复杂物体的操作提供了可行方案。

Abstract: Bimanual grasping is essential for robots to handle large and complex
objects. However, existing methods either focus solely on single-arm grasping
or employ separate grasp generation and bimanual evaluation stages, leading to
coordination problems including collision risks and unbalanced force
distribution. To address these limitations, we propose BiGraspFormer, a unified
end-to-end transformer framework that directly generates coordinated bimanual
grasps from object point clouds. Our key idea is the Single-Guided Bimanual
(SGB) strategy, which first generates diverse single grasp candidates using a
transformer decoder, then leverages their learned features through specialized
attention mechanisms to jointly predict bimanual poses and quality scores. This
conditioning strategy reduces the complexity of the 12-DoF search space while
ensuring coordinated bimanual manipulation. Comprehensive simulation
experiments and real-world validation demonstrate that BiGraspFormer
consistently outperforms existing methods while maintaining efficient inference
speed (<0.05s), confirming the effectiveness of our framework. Code and
supplementary materials are available at https://sites.google.com/bigraspformer

</details>


### [67] [A Multimodal Stochastic Planning Approach for Navigation and Multi-Robot Coordination](https://arxiv.org/abs/2509.19168)
*Mark Gonzales,Ethan Oh,Joseph Moore*

Main category: cs.RO

TL;DR: 提出了一种基于采样和滚动时域的多模态策略规划方法，通过交叉熵优化提升鲁棒性和探索能力，适用于多机器人碰撞避免和全局目标优化。


<details>
  <summary>Details</summary>
Motivation: 解决传统规划方法在局部最小值和探索能力上的不足，同时扩展到多机器人协作的场景。

Method: 使用交叉熵方法优化多模态策略，并通过采样和滚动时域规划实现鲁棒性和实时性。

Result: 仿真表明多模态策略显著提高了陷阱环境和多机器人避障的成功率；硬件实验验证了实时可行性。

Conclusion: 该方法在多模态策略优化和多机器人规划中表现出色，兼具计算效率和实用性。

Abstract: In this paper, we present a receding-horizon, sampling-based planner capable
of reasoning over multimodal policy distributions. By using the cross-entropy
method to optimize a multimodal policy under a common cost function, our
approach increases robustness against local minima and promotes effective
exploration of the solution space. We show that our approach naturally extends
to multi-robot collision-free planning, enables agents to share diverse
candidate policies to avoid deadlocks, and allows teams to minimize a global
objective without incurring the computational complexity of centralized
optimization. Numerical simulations demonstrate that employing multiple modes
significantly improves success rates in trap environments and in multi-robot
collision avoidance. Hardware experiments further validate the approach's
real-time feasibility and practical performance.

</details>


### [68] [MagiClaw: A Dual-Use, Vision-Based Soft Gripper for Bridging the Human Demonstration to Robotic Deployment Gap](https://arxiv.org/abs/2509.19169)
*Tianyu Wu,Xudong Han,Haoran Sun,Zishang Zhang,Bangchao Huang,Chaoyang Song,Fang Wan*

Main category: cs.RO

TL;DR: MagiClaw是一个多功能双指末端执行器，通过软多面体网络和嵌入式摄像头实现6自由度力及接触形变的视觉估计，结合iPhone的环境感知，降低接触密集型数据集收集门槛。


<details>
  <summary>Details</summary>
Motivation: 解决人类演示与机器人执行之间因传感和形态差异导致的领域鸿沟问题。

Method: 设计MagiClaw末端执行器，结合软多面体网络、嵌入式摄像头和iPhone的多模态数据采集，支持实时遥操作和策略学习。

Result: 成功构建统一系统架构，提升高保真接触密集型数据集的收集效率，加速通用操作策略开发。

Conclusion: MagiClaw通过硬件一致性和多模态感知，有效弥合了人机技能转移的领域鸿沟。

Abstract: The transfer of manipulation skills from human demonstration to robotic
execution is often hindered by a "domain gap" in sensing and morphology. This
paper introduces MagiClaw, a versatile two-finger end-effector designed to
bridge this gap. MagiClaw functions interchangeably as both a handheld tool for
intuitive data collection and a robotic end-effector for policy deployment,
ensuring hardware consistency and reliability. Each finger incorporates a Soft
Polyhedral Network (SPN) with an embedded camera, enabling vision-based
estimation of 6-DoF forces and contact deformation. This proprioceptive data is
fused with exteroceptive environmental sensing from an integrated iPhone, which
provides 6D pose, RGB video, and LiDAR-based depth maps. Through a custom iOS
application, MagiClaw streams synchronized, multi-modal data for real-time
teleoperation, offline policy learning, and immersive control via mixed-reality
interfaces. We demonstrate how this unified system architecture lowers the
barrier to collecting high-fidelity, contact-rich datasets and accelerates the
development of generalizable manipulation policies. Please refer to the iOS app
at https://apps.apple.com/cn/app/magiclaw/id6661033548 for further details.

</details>


### [69] [Proactive-reactive detection and mitigation of intermittent faults in robot swarms](https://arxiv.org/abs/2509.19246)
*Sinan Oğuz,Emanuele Garone,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 论文提出了一种针对机器人群体中间歇性故障的新型主动-被动检测与缓解策略，利用自组织备份层和多路复用网络的分布式共识来解决问题。


<details>
  <summary>Details</summary>
Motivation: 间歇性故障对机器人群体的可靠性和协调性构成挑战，但现有研究主要关注永久性故障，而间歇性故障检测在自组织网络中尤为困难。

Method: 提出主动-被动策略：主动自组织动态备份路径，被动使用单次似然比测试检测故障，并通过自组织方式临时重定向通信。

Result: 在代表场景中验证，间歇性故障未破坏群体形成控制的收敛性，且故障检测准确率高、误报率低。

Conclusion: 该方法有效解决了间歇性故障问题，提升了机器人群体在持久网络中的可靠性。

Abstract: Intermittent faults are transient errors that sporadically appear and
disappear. Although intermittent faults pose substantial challenges to
reliability and coordination, existing studies of fault tolerance in robot
swarms focus instead on permanent faults. One reason for this is that
intermittent faults are prohibitively difficult to detect in the fully
self-organized ad-hoc networks typical of robot swarms, as their network
topologies are transient and often unpredictable. However, in the recently
introduced self-organizing nervous systems (SoNS) approach, robot swarms are
able to self-organize persistent network structures for the first time, easing
the problem of detecting intermittent faults. To address intermittent faults in
robot swarms that have persistent networks, we propose a novel
proactive-reactive strategy to detection and mitigation, based on
self-organized backup layers and distributed consensus in a multiplex network.
Proactively, the robots self-organize dynamic backup paths before faults occur,
adapting to changes in the primary network topology and the robots' relative
positions. Reactively, robots use one-shot likelihood ratio tests to compare
information received along different paths in the multiplex network, enabling
early fault detection. Upon detection, communication is temporarily rerouted in
a self-organized way, until the detected fault resolves. We validate the
approach in representative scenarios of faulty positional data occurring during
formation control, demonstrating that intermittent faults are prevented from
disrupting convergence to desired formations, with high fault detection
accuracy and low rates of false positives.

</details>


### [70] [Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces](https://arxiv.org/abs/2509.19261)
*Kuanqi Cai,Chunfeng Wang,Zeqi Li,Haowen Yao,Weinan Chen,Luis Figueredo,Aude Billard,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种模仿引导的双臂规划框架，结合高效抓取过渡策略和运动优化，提升了机器人在动态环境中的稳定性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 机器人在动态环境中需要无缝切换抓取方式以保持稳定和高效，但现有方法对外力和复杂运动约束处理不足。

Method: 采用模仿引导的策略采样稳定抓取流形交点，结合分层双阶段运动架构（全局路径生成器和局部规划器）。

Result: 在力密集型任务中显著提高了抓取过渡效率和运动性能。

Conclusion: 该方法有效解决了动态环境中抓取过渡的挑战，提升了机器人操作的稳定性和灵活性。

Abstract: Robotic manipulation in dynamic environments often requires seamless
transitions between different grasp types to maintain stability and efficiency.
However, achieving smooth and adaptive grasp transitions remains a challenge,
particularly when dealing with external forces and complex motion constraints.
Existing grasp transition strategies often fail to account for varying external
forces and do not optimize motion performance effectively. In this work, we
propose an Imitation-Guided Bimanual Planning Framework that integrates
efficient grasp transition strategies and motion performance optimization to
enhance stability and dexterity in robotic manipulation. Our approach
introduces Strategies for Sampling Stable Intersections in Grasp Manifolds for
seamless transitions between uni-manual and bi-manual grasps, reducing
computational costs and regrasping inefficiencies. Additionally, a Hierarchical
Dual-Stage Motion Architecture combines an Imitation Learning-based Global Path
Generator with a Quadratic Programming-driven Local Planner to ensure real-time
motion feasibility, obstacle avoidance, and superior manipulability. The
proposed method is evaluated through a series of force-intensive tasks,
demonstrating significant improvements in grasp transition efficiency and
motion performance. A video demonstrating our simulation results can be viewed
at
\href{https://youtu.be/3DhbUsv4eDo}{\textcolor{blue}{https://youtu.be/3DhbUsv4eDo}}.

</details>


### [71] [SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration](https://arxiv.org/abs/2509.19292)
*Yang Jin,Jun Lv,Han Xue,Wendi Chen,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: SOE 是一个通过限制探索在有效动作流形上，提升机器人政策探索和改进的框架，确保安全、多样性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖随机扰动鼓励探索，不安全且不稳定。SOE 旨在通过流形约束探索，解决这些问题。

Method: SOE 学习任务相关因素的紧凑潜在表示，将探索限制在有效动作流形上，并可无缝集成到任意政策模型中。

Result: SOE 在仿真和实际任务中表现优于现有方法，具有更高的任务成功率、更平滑安全的探索和更优的样本效率。

Conclusion: SOE 证明了流形探索是一种高效的样本政策自我改进方法。

Abstract: Intelligent agents progress by continually refining their capabilities
through actively exploring environments. Yet robot policies often lack
sufficient exploration capability due to action mode collapse. Existing methods
that encourage exploration typically rely on random perturbations, which are
unsafe and induce unstable, erratic behaviors, thereby limiting their
effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a
framework that enhances policy exploration and improvement in robotic
manipulation. SOE learns a compact latent representation of task-relevant
factors and constrains exploration to the manifold of valid actions, ensuring
safety, diversity, and effectiveness. It can be seamlessly integrated with
arbitrary policy models as a plug-in module, augmenting exploration without
degrading the base policy performance. Moreover, the structured latent space
enables human-guided exploration, further improving efficiency and
controllability. Extensive experiments in both simulation and real-world tasks
demonstrate that SOE consistently outperforms prior methods, achieving higher
task success rates, smoother and safer exploration, and superior sample
efficiency. These results establish on-manifold exploration as a principled
approach to sample-efficient policy self-improvement. Project website:
https://ericjin2002.github.io/SOE

</details>


### [72] [Residual Off-Policy RL for Finetuning Behavior Cloning Policies](https://arxiv.org/abs/2509.19301)
*Lars Ankile,Zhenyu Jiang,Rocky Duan,Guanya Shi,Pieter Abbeel,Anusha Nagabandi*

Main category: cs.RO

TL;DR: 论文提出了一种结合行为克隆（BC）和强化学习（RL）的残差学习方法，解决RL在现实机器人中的效率和安全问题，并在高自由度系统中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为解决行为克隆依赖高质量演示数据、强化学习在现实机器人中样本效率低和安全性问题，研究提出结合两者的方法。

Method: 通过残差学习框架，利用BC策略作为基础，学习轻量级的残差修正，使用高效的离策略RL训练。

Result: 方法仅需稀疏二进制奖励信号，在高自由度系统中显著提升性能，首次实现类人机器人的真实世界RL训练。

Conclusion: 研究展示了一种实用的RL部署路径，为现实世界的高自由度机器人任务提供了高效解决方案。

Abstract: Recent advances in behavior cloning (BC) have enabled impressive visuomotor
control policies. However, these approaches are limited by the quality of human
demonstrations, the manual effort required for data collection, and the
diminishing returns from increasing offline data. In comparison, reinforcement
learning (RL) trains an agent through autonomous interaction with the
environment and has shown remarkable success in various domains. Still,
training RL policies directly on real-world robots remains challenging due to
sample inefficiency, safety concerns, and the difficulty of learning from
sparse rewards for long-horizon tasks, especially for high-degree-of-freedom
(DoF) systems. We present a recipe that combines the benefits of BC and RL
through a residual learning framework. Our approach leverages BC policies as
black-box bases and learns lightweight per-step residual corrections via
sample-efficient off-policy RL. We demonstrate that our method requires only
sparse binary reward signals and can effectively improve manipulation policies
on high-degree-of-freedom (DoF) systems in both simulation and the real world.
In particular, we demonstrate, to the best of our knowledge, the first
successful real-world RL training on a humanoid robot with dexterous hands. Our
results demonstrate state-of-the-art performance in various vision-based tasks,
pointing towards a practical pathway for deploying RL in the real world.
Project website: https://residual-offpolicy-rl.github.io

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [73] [Subspace Clustering of Subspaces: Unifying Canonical Correlation Analysis and Subspace Clustering](https://arxiv.org/abs/2509.18653)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 提出一种基于矩阵列空间的新型聚类框架SCoS，利用张量分解实现高维度数据的鲁棒聚类。


<details>
  <summary>Details</summary>
Motivation: 传统子空间聚类方法假设数据为向量形式，而实际应用中数据常为矩阵形式，需直接建模矩阵数据进行更准确聚类。

Method: 基于块项分解（BTD）构建三阶张量，联合估计聚类成员和部分共享子空间。

Result: 实验证明该方法在噪声和干扰下优于现有子空间聚类技术。

Conclusion: SCoS框架在高维数据中具有潜力，尤其适用于超越单个数据向量的结构场景。

Abstract: We introduce a novel framework for clustering a collection of tall matrices
based on their column spaces, a problem we term Subspace Clustering of
Subspaces (SCoS). Unlike traditional subspace clustering methods that assume
vectorized data, our formulation directly models each data sample as a matrix
and clusters them according to their underlying subspaces. We establish
conceptual links to Subspace Clustering and Generalized Canonical Correlation
Analysis (GCCA), and clarify key differences that arise in this more general
setting. Our approach is based on a Block Term Decomposition (BTD) of a
third-order tensor constructed from the input matrices, enabling joint
estimation of cluster memberships and partially shared subspaces. We provide
the first identifiability results for this formulation and propose scalable
optimization algorithms tailored to large datasets. Experiments on real-world
hyperspectral imaging datasets demonstrate that our method achieves superior
clustering accuracy and robustness, especially under high noise and
interference, compared to existing subspace clustering techniques. These
results highlight the potential of the proposed framework in challenging
high-dimensional applications where structure exists beyond individual data
vectors.

</details>


### [74] [Stability and Generalization of Adversarial Diffusion Training](https://arxiv.org/abs/2509.19234)
*Hesam Hosseini,Ying Cao,Ali H. Sayed*

Main category: cs.LG

TL;DR: 该研究通过算法稳定性分析了分散式网络中对抗训练在凸损失下的泛化性质，发现泛化误差随对抗扰动力度和训练步数增加而增长。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索分散式网络中对抗训练的泛化性质，填补现有研究的空白。

Method: 采用基于稳定性的分析方法，针对凸损失下的对抗训练进行理论推导，并通过逻辑回归实验验证。

Result: 理论推导表明泛化误差与对抗扰动力度和训练步数正相关，实验结果与理论一致。

Conclusion: 结论表明对抗训练在分散式网络中的泛化性质与单智能体情况相似，但这是首次在分散式环境中证明这一现象。

Abstract: Algorithmic stability is an established tool for analyzing generalization.
While adversarial training enhances model robustness, it often suffers from
robust overfitting and an enlarged generalization gap. Although recent work has
established the convergence of adversarial training in decentralized networks,
its generalization properties remain unexplored. This work presents a
stability-based generalization analysis of adversarial training under the
diffusion strategy for convex losses. We derive a bound showing that the
generalization error grows with both the adversarial perturbation strength and
the number of training steps, a finding consistent with single-agent case but
novel for decentralized settings. Numerical experiments on logistic regression
validate these theoretical predictions.

</details>


### [75] [Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.18200)
*Yu Ti Huang*

Main category: cs.LG

TL;DR: 该论文提出了一种用于多模态空间定向的MCoT框架，解决了在无GPS和详细地图的复杂环境中由自我中心到他人中心的定向问题，并在台湾LLM-13B模型上通过课程学习策略实现高精度。


<details>
  <summary>Details</summary>
Motivation: 在GPS信号弱且缺乏详细地图的室内或复杂环境中，会话代理需将自我中心表达转换为他人中心定向，但目前多模态空间定向的研究较少。

Method: 提出了多模态链式思维（MCoT）框架，结合ASR转录语音和地标坐标，通过三步推理过程（提取空间关系、映射坐标到绝对方向、推断用户方向）实现定向。

Result: MCoT在干净转录本上实现100%定向准确率，ASR转录本上达98.1%，优于单模态和非结构化基线，且在噪声和多语言环境下表现出鲁棒性。

Conclusion: 结构化MCoT空间推理为高效且可解释的具身导航提供了一种可行途径。

Abstract: Conversational agents must translate egocentric utterances (e.g., "on my
right") into allocentric orientations (N/E/S/W). This challenge is particularly
critical in indoor or complex facilities where GPS signals are weak and
detailed maps are unavailable. While chain-of-thought (CoT) prompting has
advanced reasoning in language and vision tasks, its application to multimodal
spatial orientation remains underexplored. We introduce Conversational
Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese
conversational navigation projected from real-world environments, addressing
egocentric-to-allocentric reasoning in non-English and ASR-transcribed
scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which
integrates ASR-transcribed speech with landmark coordinates through a
structured three-step reasoning process: (1) extracting spatial relations, (2)
mapping coordinates to absolute directions, and (3) inferring user orientation.
A curriculum learning strategy progressively builds these capabilities on
Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of
resource-constrained settings. Experiments show that MCoT achieves 100%
orientation accuracy on clean transcripts and 98.1% with ASR transcripts,
substantially outperforming unimodal and non-structured baselines. Moreover,
MCoT demonstrates robustness under noisy conversational conditions, including
ASR recognition errors and multilingual code-switching. The model also
maintains high accuracy in cross-domain evaluation and resilience to linguistic
variation, domain shift, and referential ambiguity. These findings highlight
the potential of structured MCoT spatial reasoning as a path toward
interpretable and resource-efficient embodied navigation.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [76] [Guaranteed Robust Nonlinear MPC via Disturbance Feedback](https://arxiv.org/abs/2509.18760)
*Antoine P. Leeman,Johannes Köhler,Melanie N. Zeilinger*

Main category: math.OC

TL;DR: 本文提出了一种快速、可扩展且适用于实时应用的鲁棒模型预测控制（RMPC）方法，确保在干扰和模型不匹配情况下的安全和稳定性。


<details>
  <summary>Details</summary>
Motivation: 机器人在干扰和模型不匹配的情况下仍需满足关键的安全约束。

Method: 将不确定非线性系统分解为名义非线性动态模型、干扰反馈控制器和模型误差界限，并通过顺序凸规划联合优化。

Result: 方法在多种动力学系统中验证有效，包括火箭着陆问题。开源实现已发布。

Conclusion: 该方法保证了鲁棒约束满足、输入-状态稳定性（ISS）和递归可行性，适用于实时应用。

Abstract: Robots must satisfy safety-critical state and input constraints despite
disturbances and model mismatch. We introduce a robust model predictive control
(RMPC) formulation that is fast, scalable, and compatible with real-time
implementation. Our formulation guarantees robust constraint satisfaction,
input-to-state stability (ISS) and recursive feasibility. The key idea is to
decompose the uncertain nonlinear system into (i) a nominal nonlinear dynamic
model, (ii) disturbance-feedback controllers, and (iii) bounds on the model
error. These components are optimized jointly using sequential convex
programming. The resulting convex subproblems are solved efficiently using a
recent disturbance-feedback MPC solver. The approach is validated across
multiple dynamics, including a rocket-landing problem with steerable thrust. An
open-source implementation is available at
https://github.com/antoineleeman/robust-nonlinear-mpc.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [77] [Optimum Spectrum Extension for PAPR Reduction of DFT-s-OFDM](https://arxiv.org/abs/2509.19064)
*Renaud-Alexandre Pitaval,Fredrik Berggren,Branislav M. Popovic*

Main category: cs.IT

TL;DR: 论文提出了结合频谱扩展（FDSS-SE）的参数化FDSS窗口和子载波系数循环移位技术，优化PAPR和速率，揭示了最佳SE大小与窗口衰减和带宽的关系，为5G以后的上行覆盖增强提供了实用指南。


<details>
  <summary>Details</summary>
Motivation: 为了解决蜂窝网络中由于最大UE发射功率限制导致的PAPR问题，尤其是在高传输速率下PAPR过高的问题，提出了结合FDSS-SE的技术。

Method: 论文研究了FDSS-SE中参数化FDSS窗口和子载波系数循环移位的优化，包括频移和SE大小的调整，以降低PAPR并提高速率。

Result: 研究结果表明，PAPR和速率的最佳SE大小主要取决于窗口衰减，而与带宽的比例关系几乎不变。此外，PAPR最优SE大小几乎不受常规QAM星座阶数的影响，而速率最优SE大小还依赖于SNR。

Conclusion: 论文结论强调，应根据用户的FDSS窗口和链路质量单独配置SE大小，这为5G以后的上行覆盖增强提供了重要指导。

Abstract: Uplink coverage in cellular networks is constrained by the maximum UE
transmit power, making peak-to-average power ratio (PAPR) reduction essential.
While DFT-s-OFDM with frequency-domain spectral shaping (FDSS) achieves
significantly lower PAPR than OFDM, especially with pi/2-BPSK, the PAPR remains
too high for higher-rate transmission. Spectrum extension (SE) combined with
FDSS (FDSS-SE) can further reduce the PAPR for higher-order QAM. This paper
considers FDSS-SE with parametrized FDSS windows spanning a range of possible
power ripples, as well as arbitrary circular shifts of the subcarrier
coefficients. We optimize both the frequency shift and the SE size, and show
that there exists an optimal SE size for reducing the PAPR and another one for
increasing the rate. Analysis and simulations reveal that both optima largely
depend on the window attenuation but are nearly invariant in proportion to the
bandwidth. While the PAPR-optimal SE size is nearly invariant to the
constellation order of regular QAM, the rate-optimal SE size depends also on
the SNR. These insights provide practical guidelines for beyond-5G uplink
coverage enhancement, highlighting that SE size should be individually
configured according to the user's FDSS window and link quality.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [78] [Integrating Stacked Intelligent Metasurfaces and Power Control for Dynamic Edge Inference via Over-The-Air Neural Networks](https://arxiv.org/abs/2509.18906)
*Kyriakos Stylianopoulos,George C. Alexandropoulos*

Main category: cs.ET

TL;DR: 论文提出了一种基于智能超表面的边缘推理框架，利用无线信道进行空中计算，减少了计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统方法将无线信道视为噪声，而该框架通过智能超表面控制无线传播，利用信道直接进行计算。

Method: 将发射-信道-接收系统建模为端到端深度神经网络，智能超表面的响应为可训练参数，并引入动态调整传输功率的DNN模块。

Result: 在多样化场景下，该框架能平衡分类精度和功耗，显著提升能源效率。

Conclusion: 提出的方法通过智能超表面和DNN的结合，实现了高效的边缘推理，减少了传统方法的开销。

Abstract: This paper introduces a novel framework for Edge Inference (EI) that bypasses
the conventional practice of treating the wireless channel as noise. We utilize
Stacked Intelligent Metasurfaces (SIMs) to control wireless propagation,
enabling the channel itself to perform over-the-air computation. This
eliminates the need for symbol estimation at the receiver, significantly
reducing computational and communication overhead. Our approach models the
transmitter-channel-receiver system as an end-to-end Deep Neural Network (DNN)
where the response of the SIM elements are trainable parameters. To address
channel variability, we incorporate a dedicated DNN module responsible for
dynamically adjusting transmission power leveraging user location information.
Our performance evaluations showcase that the proposed metasurfaces-integrated
DNN framework with deep SIM architectures are capable of balancing
classification accuracy and power consumption under diverse scenarios, offering
significant energy efficiency improvements.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [79] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出一种轻量级框架，通过分析文本内部结构（对词汇变化不变）来检测AI生成文本，解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: ChatGPT广泛使用引发滥用担忧，现有词汇级检测器易受改写或简单提示影响，且存在偏见和性能下降问题。

Method: 编码预训练语言模型的句子嵌入，通过注意力建模关系，采用对比学习和因果图反事实方法减少偏见。

Result: 在两个精选数据集上的实验验证了方法的有效性，包括摘要对比和修订的生活问答。

Conclusion: 新框架能有效检测AI生成文本，解决了词汇级检测器的不足，具有轻量化和鲁棒性优势。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [80] [Reversible Kalman Filter for state estimation with Manifold](https://arxiv.org/abs/2509.18224)
*Svyatoslav Covanov,Cedric Pradalier*

Main category: eess.SY

TL;DR: 本文提出了一种在卡尔曼滤波框架下处理流形状态估计的算法，旨在为合成数据中卡尔曼滤波变体的精度评估提供方法，并修正了先前变体的发散问题。


<details>
  <summary>Details</summary>
Motivation: 该工作的主要动机是为卡尔曼滤波变体在合成数据上的精度评估提供一种方法，填补了现有研究的空白。此外，还希望解决先前变体中的数值发散问题。

Method: 提出了一种新的滤波器，具有更好的数值特性，消除了先前卡尔曼滤波变体中的发散问题。新滤波器不再受限于小速度假设，精度仅由传感器噪声决定。此外，滤波器假设传感器具有高精度，并通过启发式检测步骤扩展至实际应用场景。

Result: 新滤波器在合成数据上能够以任意精度评估卡尔曼滤波变体的性能，并显著改善了数值稳定性。适用于9轴IMU或组合传感器配置，尤其是水下环境中的轨迹重建。

Conclusion: 本文提出的方法不仅解决了卡尔曼滤波变体的精度评估问题，还通过改进数值特性和适用范围，为实际应用提供了更可靠的解决方案。

Abstract: This work introduces an algorithm for state estimation on manifolds within
the framework of the Kalman filter. Its primary objective is to provide a
methodology enabling the evaluation of the precision of existing Kalman filter
variants with arbitrary accuracy on synthetic data, something that, to the best
of our knowledge, has not been addressed in prior work. To this end, we develop
a new filter that exhibits favorable numerical properties, thereby correcting
the divergences observed in previous Kalman filter variants. In this
formulation, the achievable precision is no longer constrained by the
small-velocity assumption and is determined solely by sensor noise. In
addition, this new filter assumes high precision on the sensors, which, in real
scenarios require a detection step that we define heuristically, allowing one
to extend this approach to scenarios, using either a 9-axis IMU or a
combination of odometry, accelerometer, and pressure sensors. The latter
configuration is designed for the reconstruction of trajectories in underwater
environments.

</details>


### [81] [Policy Gradient with Self-Attention for Model-Free Distributed Nonlinear Multi-Agent Games](https://arxiv.org/abs/2509.18371)
*Eduardo Sebastián,Maitrayee Keskar,Eeman Iqbal,Eduardo Montijano,Carlos Sagüés,Nikolay Atanasov*

Main category: eess.SY

TL;DR: 该论文提出了一种模型无关的策略梯度方法，用于学习分布式策略，解决多团队游戏中非线性动态环境下的多智能体问题。


<details>
  <summary>Details</summary>
Motivation: 解决动态非线性环境中多智能体游戏因时间变化的交互和非稳态纳什均衡带来的挑战。

Method: 利用自注意力层参数化非线性反馈增益的策略梯度方法，模拟多智能体通信拓扑。

Result: 在分布式线性和非线性调节以及多机器人追捕-逃避游戏中表现出色。

Conclusion: 提出的方法在多种场景中有效，为非线性多智能体游戏提供了可行的解决方案。

Abstract: Multi-agent games in dynamic nonlinear settings are challenging due to the
time-varying interactions among the agents and the non-stationarity of the
(potential) Nash equilibria. In this paper we consider model-free games, where
agent transitions and costs are observed without knowledge of the transition
and cost functions that generate them. We propose a policy gradient approach to
learn distributed policies that follow the communication structure in
multi-team games, with multiple agents per team. Our formulation is inspired by
the structure of distributed policies in linear quadratic games, which take the
form of time-varying linear feedback gains. In the nonlinear case, we model the
policies as nonlinear feedback gains, parameterized by self-attention layers to
account for the time-varying multi-agent communication topology. We demonstrate
that our distributed policy gradient approach achieves strong performance in
several settings, including distributed linear and nonlinear regulation, and
simulated and real multi-robot pursuit-and-evasion games.

</details>


### [82] [Dual Iterative Learning Control for Multiple-Input Multiple-Output Dynamics with Validation in Robotic Systems](https://arxiv.org/abs/2509.18723)
*Jan-Hendrik Ewering,Alessandro Papa,Simon F. G. Ehlers,Thomas Seel,Michael Meindl*

Main category: eess.SY

TL;DR: 提出了一种名为MIMO Dual Iterative Learning Control (DILC)的新方法，用于无需先验系统知识或手动调参的情况下实现跟踪控制和模型学习。


<details>
  <summary>Details</summary>
Motivation: 解决智能系统在复杂MIMO系统中未知动态和手动调参的挑战，实现真正的自主性。

Method: DILC结合了数据驱动的迭代学习控制方法，适用于重复性MIMO系统，并提供了线性时不变系统中误差单调收敛的条件。

Result: 在工业机器人仿真和实际非线性MIMO系统中，DILC能在10-20次试验内完成任务，复杂任务也少于100次迭代。

Conclusion: DILC因其快速自主的学习能力，有望成为复杂学习框架的高效组成部分。

Abstract: Solving motion tasks autonomously and accurately is a core ability for
intelligent real-world systems. To achieve genuine autonomy across multiple
systems and tasks, key challenges include coping with unknown dynamics and
overcoming the need for manual parameter tuning, which is especially crucial in
complex Multiple-Input Multiple-Output (MIMO) systems.
  This paper presents MIMO Dual Iterative Learning Control (DILC), a novel
data-driven iterative learning scheme for simultaneous tracking control and
model learning, without requiring any prior system knowledge or manual
parameter tuning. The method is designed for repetitive MIMO systems and
integrates seamlessly with established iterative learning control methods. We
provide monotonic convergence conditions for both reference tracking error and
model error in linear time-invariant systems.
  The DILC scheme -- rapidly and autonomously -- solves various motion tasks in
high-fidelity simulations of an industrial robot and in multiple nonlinear
real-world MIMO systems, without requiring model knowledge or manually tuning
the algorithm. In our experiments, many reference tracking tasks are solved
within 10-20 trials, and even complex motions are learned in less than 100
iterations. We believe that, because of its rapid and autonomous learning
capabilities, DILC has the potential to serve as an efficient building block
within complex learning frameworks for intelligent real-world systems.

</details>


### [83] [An Extended Kalman Filter for Systems with Infinite-Dimensional Measurements](https://arxiv.org/abs/2509.18749)
*Maxwell M. Varley,Timothy L. Molloy,Girish N. Nair*

Main category: eess.SY

TL;DR: 研究了离散时间非线性随机系统中的状态估计问题，提出了扩展卡尔曼滤波器（EKF），证明了其应用于视觉定位时的优越性。


<details>
  <summary>Details</summary>
Motivation: 针对现实应用（如基于视觉的定位和跟踪），研究有限维状态与无限维测量的非线性随机系统的状态估计。

Method: 开发了扩展卡尔曼滤波器（EKF），将测量噪声建模为无限维随机场，并证明测量雅可比矩阵对应于图像梯度。

Result: 在公开数据集上的实验表明，EKF在视觉定位任务中优于VINS-MONO算法，误差减少了若干数量级。

Conclusion: EKF为图像梯度在视觉状态估计中的应用提供了系统理论支持，并展示了实际优势。

Abstract: This article examines state estimation in discrete-time nonlinear stochastic
systems with finite-dimensional states and infinite-dimensional measurements,
motivated by real-world applications such as vision-based localization and
tracking. We develop an extended Kalman filter (EKF) for real-time state
estimation, with the measurement noise modeled as an infinite-dimensional
random field. When applied to vision-based state estimation, the measurement
Jacobians required to implement the EKF are shown to correspond to image
gradients. This result provides a novel system-theoretic justification for the
use of image gradients as features for vision-based state estimation,
contrasting with their (often heuristic) introduction in many computer-vision
pipelines. We demonstrate the practical utility of the EKF on a public
real-world dataset involving the localization of an aerial drone using video
from a downward-facing monocular camera. The EKF is shown to outperform
VINS-MONO, an established visual-inertial odometry algorithm, in some cases
achieving mean squared error reductions of up to an order of magnitude.

</details>


### [84] [A Fast Initialization Method for Neural Network Controllers: A Case Study of Image-based Visual Servoing Control for the multicopter Interception](https://arxiv.org/abs/2509.19110)
*Chenxu Ke,Congling Tian,Kaichen Xu,Ye Li,Lingcong Bao*

Main category: eess.SY

TL;DR: 该论文提出了一种基于神经网络快速初始化的方法，通过构建符合稳定性条件的数据集来设计初始稳定的神经网络控制策略，解决了强化学习训练初期数据需求大、收敛慢等问题，并通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的控制器设计方法在初始训练阶段需要大量数据，且训练过程随机性高、收敛慢。另外，基于Lyapunov稳定性理论的方法需要初始稳定的神经网络控制策略。本文旨在解决这些问题，提供一种快速初始化神经网络控制策略的方法。

Method: 提出一种神经网络快速初始化方法，通过构建符合稳定性条件的数据集来训练初始稳定的神经网络控制策略。该方法结合系统模型，确保策略满足稳定性要求。

Result: 实验结果表明，训练的控制策略在无人机拦截任务中达到了15 m/s的最终拦截速度，验证了方法的有效性和实用性。

Conclusion: 该方法能够快速初始化稳定的神经网络控制策略，解决了传统方法对控制设计知识的高要求问题，同时提升了强化学习和Lyapunov控制方法的效率和性能。

Abstract: Reinforcement learning-based controller design methods often require
substantial data in the initial training phase. Moreover, the training process
tends to exhibit strong randomness and slow convergence. It often requires
considerable time or high computational resources. Another class of
learning-based method incorporates Lyapunov stability theory to obtain a
control policy with stability guarantees. However, these methods generally
require an initially stable neural network control policy at the beginning of
training. Evidently, a stable neural network controller can not only serve as
an initial policy for reinforcement learning, allowing the training to focus on
improving controller performance, but also act as an initial state for
learning-based Lyapunov control methods. Although stable controllers can be
designed using traditional control theory, designers still need to have a great
deal of control design knowledge to address increasingly complicated control
problems. The proposed neural network rapid initialization method in this paper
achieves the initial training of the neural network control policy by
constructing datasets that conform to the stability conditions based on the
system model. Furthermore, using the image-based visual servoing control for
multicopter interception as a case study, simulations and experiments were
conducted to validate the effectiveness and practical performance of the
proposed method. In the experiment, the trained control policy attains a final
interception velocity of 15 m/s.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [85] [A Low-cost Quasi-planar Array Probe for Photoacoustic Imaging](https://arxiv.org/abs/2509.19268)
*Xiyu Chen,Junxiang Cai,Rui Zheng,Tao Wu,Fei Gao*

Main category: physics.med-ph

TL;DR: 提出了一种准平面阵列技术，用于光声成像（PAI），以低成本实现实时3D成像，填补了2D和3D PAI之间的技术空白。


<details>
  <summary>Details</summary>
Motivation: 现有线性阵列无法实现3D成像，而平面阵列成本高昂，因此需要一种低成本的3D PAI解决方案。

Method: 采用双16单元线性阵列并行排列的准平面阵列，通过仿真和琼脂糖模型实验验证其3D成像能力。

Result: 仿真和实验证明该探头能实现3D成像，定位不同深度的吸收体。

Conclusion: 准平面阵列为低成本实时3D PAI提供了可行方案，未来将探索其在活检针尖跟踪中的应用。

Abstract: Photoacoustic imaging (PAI) is a novel hybrid imaging technique that combines
the benefits of both optical and acoustic imaging modalities, which provides
functional and molecular optical contrasts of deep tissue. Commonly used
ultrasound transducers for PAI include linear and planar arrays, which can
provide two-dimensional (2D) and three-dimensional (3D) image reconstruction,
respectively. However, linear arrays cannot provide reconstruction of 3D
images, which makes it impossible to locate chromophores in 3D space. Although
planar array can provide fast 3D imaging in real time, it usually requires
thousands of analog-to-digital conversion channels for data acquisition, which
is costly. To fill the gap between 2D and 3D PAI, we propose a quasi-planar
array that uses double 16-elements-linear arrays arranged in parallel to
achieve real-time 3D imaging. We first conducted simulation studies to prove
that the quasi-planar probe can perform 3D imaging to localize simple
chromophores. Then, the agarose phantom experiment demonstrated that the probe
can reconstruct 3D imaging of multiple absorbers in different depths. A
potential application of this device is to provide a low-cost 3D PAI solution
for fast tracking of needle tip during needle biopsy, which will be further
explored in our future work.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [86] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 该论文提出了一个新的框架MMCD，用于多模态协作决策，以解决自动驾驶中的传感器或协作车辆缺失问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在事故多发环境中面临传感器视野受限和协作车辆缺失的挑战，现有方法通常假设所有模态数据在训练和测试中均可用，这在现实中不切实际。

Method: 提出的MMCD框架通过多模态协作车辆的数据融合增强决策能力，并采用跨模态知识蒸馏的师生模型结构，确保在部分数据缺失时的鲁棒性。

Result: 在自动驾驶和空地车辆协作实验中，该方法将驾驶安全性提高了20.7%，超过了现有基线。

Conclusion: MMCD框架在提升自动驾驶安全性和鲁棒性方面表现出色，尤其是在数据缺失的情况下。

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [87] [Tractable Approximation of Labeled Multi-Object Posterior Densities](https://arxiv.org/abs/2509.18780)
*Thi Hong Thai Nguyen,Ba-Ngu Vo,Ba-Tuong Vo*

Main category: stat.ME

TL;DR: 该论文提出了一种可处理的广义标记多伯努利（GLMB）近似方法，用于状态空间模型中的多目标估计，以匹配标记多目标后验密度的轨迹基数分布。该方法还最小化了Kullback-Leibler散度，并通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多目标状态空间模型的非标准特性使得闭式多目标后验不可行，而功能性近似需求迫切。

Method: 提出了一种多扫描GLMB近似方法，匹配轨迹基数分布并优化Kullback-Leibler散度，开发了计算有限窗口内近似后验的算法。

Result: 通过数值实验（包括社交力模型和信息不足观测的多目标SSM）验证了方法的适用性。

Conclusion: 提出的GLMB近似方法在多目标状态空间模型中具有实际应用价值，能有效近似高维后验密度。

Abstract: Multi-object estimation in state-space models (SSMs) wherein the system state
is represented as a finite set has attracted significant interest in recent
years. In Bayesian inference, the posterior density captures all information on
the system trajectory since it considers the past history of states. In most
multi-object SSM applications, closed-form multi-object posteriors are not
available for non-standard multi-object models. Thus, functional approximation
is necessary because these posteriors are very high-dimensional. This work
provides a tractable multi-scan Generalized Labeled Multi-Bernoulli (GLMB)
approximation that matches the trajectory cardinality distribution of the
labeled multi-object posterior density. The proposed approximation is also
proven to minimize the Kullback-Leibler divergence over a special class of
multi-scan GLMB model. Additionally, we develop a tractable algorithm for
computing the approximate multi-object posteriors over finite windows.
Numerical experiments, including simulation results on a multi-object SSM with
social force model and uninformative observations, are presented to validate
the applicability of the approximation method.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [88] [WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction](https://arxiv.org/abs/2509.19073)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: WaveletGaussian提出了一种在稀疏视角下更高效的3D高斯对象重建框架，通过将扩散过程移至小波域并减少计算量，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D高斯溅射（3DGS）在稀疏视角下性能急剧下降的问题，同时降低扩散修复方法的高计算成本。

Method: 将扩散过程应用于小波域的低分辨率LL子带，高频子带则通过轻量级网络细化；提出在线随机掩码策略优化训练对生成。

Result: 在Mip-NeRF 360和OmniObject3D数据集上表现优异，渲染质量接近现有方法，但训练时间大幅减少。

Conclusion: WaveletGaussian框架通过小波域扩散和高效训练策略，在稀疏视角3D重建中实现了性能与效率的平衡。

Abstract: 3D Gaussian Splatting (3DGS) has become a powerful representation for
image-based object reconstruction, yet its performance drops sharply in
sparse-view settings. Prior works address this limitation by employing
diffusion models to repair corrupted renders, subsequently using them as pseudo
ground truths for later optimization. While effective, such approaches incur
heavy computation from the diffusion fine-tuning and repair steps. We present
WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object
reconstruction. Our key idea is to shift diffusion into the wavelet domain:
diffusion is applied only to the low-resolution LL subband, while
high-frequency subbands are refined with a lightweight network. We further
propose an efficient online random masking strategy to curate training pairs
for diffusion fine-tuning, replacing the commonly used, but inefficient,
leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360
and OmniObject3D, show WaveletGaussian achieves competitive rendering quality
while substantially reducing training time.

</details>


### [89] [OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata](https://arxiv.org/abs/2509.18350)
*Oussema Dhaouadi,Riccardo Marin,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: OrthoLoC是一个新的大规模数据集，用于解决无人机图像与地理空间数据之间的域偏移问题，并提供了多种模态的16245张图像。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的场景下（如无互联网或GNSS/GPS支持），实现高精度的视觉定位是一个重要挑战。现有的方法通常依赖大型图像数据库或重型3D模型，而这在实际应用中不切实际。

Method: 提出了OrthoLoC数据集，包含了来自德国和美国的16245张无人机图像，支持多模态。通过解耦图像检索和特征匹配，实现了定位和校准性能的独立评估。此外，提出了AdHoP细化技术，可集成到任何特征匹配器中。

Result: AdHoP技术提高了匹配性能（高达95%）并降低了平移误差（高达63%）。数据集和代码已公开。

Conclusion: OrthoLoC为无人机视觉定位提供了一个轻量级且高效的解决方案，填补了现有研究的空白。

Abstract: Accurate visual localization from aerial views is a fundamental problem with
applications in mapping, large-area inspection, and search-and-rescue
operations. In many scenarios, these systems require high-precision
localization while operating with limited resources (e.g., no internet
connection or GNSS/GPS support), making large image databases or heavy 3D
models impractical. Surprisingly, little attention has been given to leveraging
orthographic geodata as an alternative paradigm, which is lightweight and
increasingly available through free releases by governmental authorities (e.g.,
the European Union). To fill this gap, we propose OrthoLoC, the first
large-scale dataset comprising 16,425 UAV images from Germany and the United
States with multiple modalities. The dataset addresses domain shifts between
UAV imagery and geospatial data. Its paired structure enables fair benchmarking
of existing solutions by decoupling image retrieval from feature matching,
allowing isolated evaluation of localization and calibration performance.
Through comprehensive evaluation, we examine the impact of domain shifts, data
resolutions, and covisibility on localization accuracy. Finally, we introduce a
refinement technique called AdHoP, which can be integrated with any feature
matcher, improving matching by up to 95% and reducing translation error by up
to 63%. The dataset and code are available at:
https://deepscenario.github.io/OrthoLoC.

</details>


### [90] [Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction](https://arxiv.org/abs/2509.18566)
*Xiaoting Yin,Hao Shi,Kailun Yang,Jiajun Zhai,Shangwei Guo,Lin Wang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种基于事件相机的动态人类与静态场景重建框架，通过3D高斯溅射技术联合建模，并设计了事件引导的损失函数以提升模糊区域的局部保真度。


<details>
  <summary>Details</summary>
Motivation: 传统的单目视频在快速运动下易受运动模糊影响，而事件相机因其高时间分辨率更适合动态重建，为解决这一问题提出了新方法。

Method: 使用统一的3D高斯集合，其中人类高斯具有可学习的语义属性并通过变形实现动画；提出事件引导损失以匹配亮度变化与事件流。

Result: 在两个基准数据集上实现了最先进的性能，PSNR/SSIM指标显著提升，LPIPS降低，尤其适用于高速运动对象。

Conclusion: 该方法无需外部人类掩码，简化了高斯集管理，有效解决了动态重建中的模糊问题。

Abstract: Reconstructing dynamic humans together with static scenes from monocular
videos remains difficult, especially under fast motion, where RGB frames suffer
from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond
temporal resolution, making them a superior sensing choice for dynamic human
reconstruction. Accordingly, we present a novel event-guided human-scene
reconstruction framework that jointly models human and scene from a single
monocular event camera via 3D Gaussian Splatting. Specifically, a unified set
of 3D Gaussians carries a learnable semantic attribute; only Gaussians
classified as human undergo deformation for animation, while scene Gaussians
stay static. To combat blur, we propose an event-guided loss that matches
simulated brightness changes between consecutive renderings with the event
stream, improving local fidelity in fast-moving regions. Our approach removes
the need for external human masks and simplifies managing separate Gaussian
sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers
state-of-the-art human-scene reconstruction, with notable gains over strong
baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [91] [Tensor Train Completion from Fiberwise Observations Along a Single Mode](https://arxiv.org/abs/2509.18149)
*Shakir Showkat Sofi,Lieven De Lathauwer*

Main category: math.NA

TL;DR: 该论文提出了一种针对特定“纤维式”观测张量的快速张量补全方法，利用标准线性代数操作计算张量序列分解，并在确定性条件下保证恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有的张量补全方法多基于随机均匀观测和低秩假设，而本研究旨在利用观测模式中的低秩结构设计更高效的算法，特别适用于沿特定模式（如时间）采样的多路数据。

Method: 通过标准线性代数操作计算特定“纤维式”观测张量的张量序列分解，提出了快速完成补全的方法。

Result: 数值实验验证了该方法在确定性条件下的有效性和高效性，展示了其在实际应用中的潜力。

Conclusion: 该方法为特定观测模式的张量补全问题提供了高效的解决方案，扩展了张量补全的应用场景。

Abstract: Tensor completion is an extension of matrix completion aimed at recovering a
multiway data tensor by leveraging a given subset of its entries (observations)
and the pattern of observation. The low-rank assumption is key in establishing
a relationship between the observed and unobserved entries of the tensor. The
low-rank tensor completion problem is typically solved using numerical
optimization techniques, where the rank information is used either implicitly
(in the rank minimization approach) or explicitly (in the error minimization
approach). Current theories concerning these techniques often study
probabilistic recovery guarantees under conditions such as random uniform
observations and incoherence requirements. However, if an observation pattern
exhibits some low-rank structure that can be exploited, more efficient
algorithms with deterministic recovery guarantees can be designed by leveraging
this structure. This work shows how to use only standard linear algebra
operations to compute the tensor train decomposition of a specific type of
``fiber-wise" observed tensor, where some of the fibers of a tensor (along a
single specific mode) are either fully observed or entirely missing, unlike the
usual entry-wise observations. From an application viewpoint, this setting is
relevant when it is easier to sample or collect a multiway data tensor along a
specific mode (e.g., temporal). The proposed completion method is fast and is
guaranteed to work under reasonable deterministic conditions on the observation
pattern. Through numerical experiments, we showcase interesting applications
and use cases that illustrate the effectiveness of the proposed approach.

</details>
