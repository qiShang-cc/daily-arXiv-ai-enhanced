<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 6]
- [cs.RO](#cs.RO) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks](https://arxiv.org/abs/2508.11640)
*Danny Scott,William LaForest,Hritom Das,Ioannis Polykretis,Catherine D. Schuman,Charles Rizzo,James Plank,Sai Swaminathan*

Main category: eess.SP

TL;DR: Vibe2Spike是一种无电池、无线传感框架，利用可见光通信和脉冲神经网络实现振动活动识别，具有高能效和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 稠密、低成本传感器的部署对实现无处不在的智能环境至关重要，但现有方案在能源、扩展性和可靠性方面面临挑战。

Method: 系统使用仅由压电盘、齐纳二极管和LED组成的超低成本标签，通过振动能量驱动LED发射稀疏可见光脉冲，事件相机捕捉并由优化的SNN模型分类。

Result: 在五类设备上的平均分类准确率达到94.9%，分析了不同时间分箱策略的延迟-准确性权衡。

Conclusion: Vibe2Spike展示了无电池环境下实现智能环境的可扩展和高能效方法。

Abstract: The deployment of dense, low-cost sensors is critical for realizing
ubiquitous smart environments. However, existing sensing solutions struggle
with the energy, scalability, and reliability trade-offs imposed by battery
maintenance, wireless transmission overhead, and data processing complexity. In
this work, we present Vibe2Spike, a novel battery-free, wireless sensing
framework that enables vibration-based activity recognition using visible light
communication (VLC) and spiking neural networks (SNNs). Our system uses
ultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and
an LED, which harvest vibration energy and emit sparse visible light spikes
without requiring batteries or RF radios. These optical spikes are captured by
event cameras and classified using optimized SNN models evolved via the EONS
framework. We evaluate Vibe2Spike across five device classes, achieving 94.9\%
average classification fitness while analyzing the latency-accuracy trade-offs
of different temporal binning strategies. Vibe2Spike demonstrates a scalable,
and energy-efficient approach for enabling intelligent environments in a
batteryless manner.

</details>


### [2] [Data-driven RF Tomography via Cross-modal Sensing and Continual Learning](https://arxiv.org/abs/2508.11654)
*Yang Zhao,Tao Wang,Said Elhadi*

Main category: eess.SP

TL;DR: 提出了一种数据驱动的射频断层扫描（DRIFT）框架，结合跨模态学习和持续学习，显著提升了动态环境中地下目标检测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 射频信号穿透土壤的特性使其在地下目标检测中具有潜力，但在动态环境中实现高准确性和鲁棒性仍具挑战性。

Method: 设计了结合射频与视觉传感器的跨模态感知系统，采用跨模态学习方法训练深度神经网络（DNN）模型，并应用持续学习在环境变化时自动更新模型。

Result: 实验结果显示，该方法平均等效直径误差为2.29厘米，比现有最优方法提升了23.2%。

Conclusion: 提出的DRIFT框架在动态环境中显示出优越性能，代码和数据集已开源。

Abstract: Data-driven radio frequency (RF) tomography has demonstrated significant
potential for underground target detection, due to the penetrative nature of RF
signals through soil. However, it is still challenging to achieve accurate and
robust performance in dynamic environments. In this work, we propose a
data-driven radio frequency tomography (DRIFT) framework with the following key
components to reconstruct cross section images of underground root tubers, even
with significant changes in RF signals. First, we design a cross-modal sensing
system with RF and visual sensors, and propose to train an RF tomography deep
neural network (DNN) model following the cross-modal learning approach. Then we
propose to apply continual learning to automatically update the DNN model, once
environment changes are detected in a dynamic environment. Experimental results
show that our approach achieves an average equivalent diameter error of 2.29
cm, 23.2% improvement upon the state-of-the-art approach. Our DRIFT code and
dataset are publicly available on https://github.com/Data-driven-RTI/DRIFT.

</details>


### [3] [Inductive transfer learning from regression to classification in ECG analysis](https://arxiv.org/abs/2508.11656)
*Ridma Jayasundara,Ishan Fernando,Adeepa Fernando,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: eess.SP

TL;DR: 本研究探讨了合成心电图（ECG）数据在深度学习模型训练中的潜力，并通过回归到分类的迁移学习提升了真实ECG数据的分类性能。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病（CVDs）是全球主要死因，其诊断依赖心电图（ECG），但患者数据隐私问题促使对合成数据的探索。

Method: 使用深度学习模型预测四个关键心脏参数，并通过迁移学习将回归模型应用于5类ECG信号分类。

Result: 研究表明，从回归到分类的迁移学习能显著提升分类性能。

Conclusion: 迁移学习可充分利用合成和开放ECG数据，推动深度学习在该领域的应用。

Abstract: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide,
accounting for over 30% of global deaths according to the World Health
Organization (WHO). Importantly, one-third of these deaths are preventable with
timely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive
method for recording the electrical activity of the heart, is crucial for
diagnosing CVDs. However, privacy concerns surrounding the use of patient ECG
data in research have spurred interest in synthetic data, which preserves the
statistical properties of real data without compromising patient
confidentiality. This study explores the potential of synthetic ECG data for
training deep learning models from regression to classification tasks and
evaluates the feasibility of transfer learning to enhance classification
performance on real ECG data. We experimented with popular deep learning models
to predict four key cardiac parameters, namely, Heart Rate (HR), PR interval,
QT interval, and QRS complex-using separate regression models. Subsequently, we
leveraged these regression models for transfer learning to perform 5-class ECG
signal classification. Our experiments systematically investigate whether
transfer learning from regression to classification is viable, enabling better
utilization of diverse open-access and synthetic ECG datasets. Our findings
demonstrate that transfer learning from regression to classification improves
classification performance, highlighting its potential to maximize the utility
of available data and advance deep learning applications in this domain.

</details>


### [4] [Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding](https://arxiv.org/abs/2508.11657)
*Yuanhao Li,Badong Chen,Wenjun Bai,Yasuharu Koike,Okito Yamashita*

Main category: eess.SP

TL;DR: 提出了一种基于最小误差熵（MEE）的稀疏贝叶斯学习框架，用于解决高维度大脑信号解码中的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 传统的高斯和二项分布假设可能不足以描述大脑活动信号中的噪声，因此需要一种更鲁棒的方法。

Method: 提出了基于最小误差熵（MEE）的似然函数，以提高稀疏贝叶斯学习在噪声数据中的推断准确性。

Result: 在两个高维度大脑解码任务中，该方法在回归和分类任务中均表现出优于传统和最先进方法的性能。

Conclusion: 所提出的MEE框架能够同时解决大脑解码任务中的噪声和高维度问题，为生物医学工程应用提供了有力工具。

Abstract: Objective: Sparse Bayesian learning provides an effective scheme to solve the
high-dimensional problem in brain signal decoding. However, traditional
assumptions regarding data distributions such as Gaussian and binomial are
potentially inadequate to characterize the noisy signals of brain activity.
Hence, this study aims to propose a robust sparse Bayesian learning framework
to address noisy highdimensional brain activity decoding. Methods: Motivated by
the commendable robustness of the minimum error entropy (MEE) criterion for
handling complex data distributions, we proposed an MEE-based likelihood
function to facilitate the accurate inference of sparse Bayesian learning in
analyzing noisy brain datasets. Results: Our proposed approach was evaluated
using two high-dimensional brain decoding tasks in regression and
classification contexts, respectively. The experimental results showed that,
our approach can realize superior decoding metrics and physiological patterns
than the conventional and state-of-the-art methods. Conclusion: Utilizing the
proposed MEE-based likelihood model, sparse Bayesian learning is empowered to
simultaneously address the challenges of noise and high dimensionality in the
brain decoding task. Significance: This work provides a powerful tool to
realize robust brain decoding, advancing biomedical engineering applications
such as brain-computer interface.

</details>


### [5] [CECGSR: Circular ECG Super-Resolution](https://arxiv.org/abs/2508.11658)
*Honggui Li,Zhengyang Zhang,Dingtai Li,Sinan Chen,Nahid Md Lokman Hossain,Xinfeng Xu,Yuting Feng,Hantao Lu,Yinlu Qin,Ruobing Wang,Maria Trocan,Dimitri Galayko,Amara Amara,Mohamad Sawan*

Main category: eess.SP

TL;DR: 该论文提出了一种基于闭环框架的心电图超分辨率方法（CECGSR），通过建模高分辨率到低分辨率信号的降级过程，利用负反馈机制提升性能。实验表明，CECGSR在PTB-XL数据集上的表现优于现有开环方法。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）信号常因设备限制和噪声干扰而分辨率较低，传统开环超分辨率方法性能有限。论文旨在通过闭环框架提升ECG信号重建的准确性和稳定性。

Method: 提出闭环方法CECGSR，建模高分辨率到低分辨率信号的降级过程，利用负反馈机制和数学环路方程优化性能。采用即插即用策略整合现有开环超分辨率方法。

Result: 在PTB-XL数据集的无噪和含噪子集上，CECGSR的表现优于现有开环算法，展示了更高的重建性能。

Conclusion: 闭环框架CECGSR显著提升了ECG信号超分辨率的效果，为心脏疾病诊断提供了更可靠的工具。

Abstract: The electrocardiogram (ECG) plays a crucial role in the diagnosis and
treatment of various cardiac diseases. ECG signals suffer from low-resolution
(LR) due to the use of convenient acquisition devices, as well as internal and
external noises and artifacts. Classical ECG super-resolution (ECGSR) methods
adopt an open-loop architecture that converts LR ECG signals to
super-resolution (SR) ones. According to the theory of automatic control, a
closed-loop framework exhibits superior dynamic and static performance compared
with its open-loop counterpart. This paper proposes a closed-loop approach,
termed circular ECGSR (CECGSR), which models the degradation process from SR
ECG signals to LR ones. The negative feedback mechanism of the closed-loop
system is based on the differences between the LR ECG signals. A mathematical
loop equation is constructed to characterize the closed-loop infrastructure.
The Taylor series expansion is employed to demonstrate the near-zero
steady-state error of the proposed method. A Plug-and-Play strategy is
considered to establish the SR unit of the proposed architecture, leveraging
any existing advanced open-loop ECGSR methods. Simulation experiments on both
noiseless and noisy subsets of the PTB-XL datasets demonstrate that the
proposed CECGSR outperforms state-of-the-art open-loop ECGSR algorithms in the
reconstruction performance of ECG signals.

</details>


### [6] [Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation](https://arxiv.org/abs/2508.11663)
*Guangli Li,Canbiao Wu,Zhen Liang*

Main category: eess.SP

TL;DR: 论文提出了一种基于域对抗迁移学习的优化方法（McdPL），通过双对抗分类器和三阶段对抗训练，解决跨数据库情感识别中的特征对齐问题，并在实验中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 由于受试者生理差异及实验环境和设备的变化，跨数据库情感识别面临挑战，特别是边界样本的分类问题。

Method: 采用双对抗分类器（Ada和RMS）和三阶段对抗训练，结合成对学习，最大化分类差异并最小化特征分布差异，实现精准特征对齐。

Result: 在SEED、SEED-IV和SEED-V数据库上的实验表明，McdPL模型在跨数据库情感识别任务中优于基线模型，准确率平均提升4.76%和3.97%。

Conclusion: McdPL为跨数据库情感识别提供了一种有效的解决方案，代码已开源。

Abstract: Affective computing is a rapidly developing interdisciplinary research
direction in the field of brain-computer interface. In recent years, the
introduction of deep learning technology has greatly promoted the development
of the field of emotion recognition. However, due to physiological differences
between subjects, as well as the variations in experimental environments and
equipment, cross-corpus emotion recognition faces serious challenges,
especially for samples near the decision boundary. To solve the above problems,
we propose an optimization method based on domain adversarial transfer learning
to fine-grained alignment of affective features, named Maximum classifier
discrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a
dual adversarial classifier (Ada classifier and RMS classifier), and apply a
three-stage adversarial training to maximize classification discrepancy and
minimize feature distribution to align controversy samples near the decision
boundary. In the process of domain adversarial training, the two classifiers
also maintain an adversarial relationship, ultimately enabling precise
cross-corpus feature alignment. In addition, the introduction of pairwise
learning transforms the classification problem of samples into a similarity
problem between samples, alleviating the influence of label noise. We conducted
systematic experimental evaluation of the model using publicly available SEED,
SEED-IV and SEED-V databases. The results show that the McdPL model is superior
to other baseline models in the cross-corpus emotion recognition task, and the
average accuracy improvements of 4.76\% and 3.97\%, respectively. Our work
provides a promising solution for emotion recognition cross-corpus. The source
code is available at https://github.com/WuCB-BCI/Mcd_PL.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [7] [Using Natural Language for Human-Robot Collaboration in the Real World](https://arxiv.org/abs/2508.11759)
*Peter Lindes,Kaoutar Skiker*

Main category: cs.RO

TL;DR: 论文探讨了利用大型语言模型（LLMs）提升自主机器人语言理解能力，以改善与人类的协作任务，并提出了一种整合认知代理、物理机器人和LLMs的方法


<details>
  <summary>Details</summary>
Motivation: 实现自主机器人通过自然语言与人类协作完成复杂任务的愿景，弥补传统交互式任务学习（ITL）系统语言理解能力的不足

Method: 通过结合认知代理、物理机器人和LLMs，构建AI系统，并针对语言理解的三个具体挑战，使用ChatGPT进行概念验证实验

Result: 提出了一种可能的方法，初步验证了LLMs在机器人语言理解中的应用潜力

Conclusion: 需进一步研究将概念验证发展为可操作的集成系统，实现LLM辅助的机器人语言协作

Abstract: We have a vision of a day when autonomous robots can collaborate with humans
as assistants in performing complex tasks in the physical world. This vision
includes that the robots will have the ability to communicate with their human
collaborators using language that is natural to the humans. Traditional
Interactive Task Learning (ITL) systems have some of this ability, but the
language they can understand is very limited. The advent of large language
models (LLMs) provides an opportunity to greatly improve the language
understanding of robots, yet integrating the language abilities of LLMs with
robots that operate in the real physical world is a challenging problem.
  In this chapter we first review briefly a few commercial robot products that
work closely with humans, and discuss how they could be much better
collaborators with robust language abilities. We then explore how an AI system
with a cognitive agent that controls a physical robot at its core, interacts
with both a human and an LLM, and accumulates situational knowledge through its
experiences, can be a possible approach to reach that vision. We focus on three
specific challenges of having the robot understand natural language, and
present a simple proof-of-concept experiment using ChatGPT for each. Finally,
we discuss what it will take to turn these simple experiments into an
operational system where LLM-assisted language understanding is a part of an
integrated robotic assistant that uses language to collaborate with humans.

</details>


### [8] [Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots](https://arxiv.org/abs/2508.11802)
*Luigi Penco,Beomyeong Park,Stefan Fasano,Nehar Poddar,Stephen McCrory,Nicholas Kitchel,Tomasz Bialek,Dexton Anderson,Duncan Calvert,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种实时步态同步方法，通过预测和调整用户步态，使机器人能在复杂地形上保持平衡。


<details>
  <summary>Details</summary>
Motivation: 解决高速度任务中用户与机器人运动同步的挑战，尤其是地形不匹配问题。

Method: 重定向用户步态到机器人脚步位置，预测脚步并动态调整以适应地形。

Result: 在Nadia人形机器人上验证了系统的有效性。

Conclusion: 该方法提升了机器人运动的平衡性和稳定性。

Abstract: Achieving seamless synchronization between user and robot motion in
teleoperation, particularly during high-speed tasks, remains a significant
challenge. In this work, we propose a novel approach for transferring stepping
motions from the user to the robot in real-time. Instead of directly
replicating user foot poses, we retarget user steps to robot footstep
locations, allowing the robot to utilize its own dynamics for locomotion,
ensuring better balance and stability. Our method anticipates user footsteps to
minimize delays between when the user initiates and completes a step and when
the robot does it. The step estimates are continuously adapted to converge with
the measured user references. Additionally, the system autonomously adjusts the
robot's steps to account for its surrounding terrain, overcoming challenges
posed by environmental mismatches between the user's flat-ground setup and the
robot's uneven terrain. Experimental results on the humanoid robot Nadia
demonstrate the effectiveness of the proposed system.

</details>
