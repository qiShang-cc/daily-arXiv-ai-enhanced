<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [cs.RO](#cs.RO) [Total: 35]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [eess.SY](#eess.SY) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Signals vs. Videos: Advancing Motion Intention Recognition for Human-Robot Collaboration in Construction](https://arxiv.org/abs/2509.07990)
*Charan Gajjala Chenchu,Kinam Kim,Gao Lu,Zia Ud Din*

Main category: eess.SP

TL;DR: 该研究比较了信号（sEMG）和视频两种数据模态在干墙安装任务中识别工人运动意图的效果，发现视频模态准确率更高（94% vs 87%），但信号模态预测速度更快（0.04秒 vs 0.15秒）。


<details>
  <summary>Details</summary>
Motivation: 提升人机协作（HRC）在建筑行业中的安全性和效率，解决不同数据模态在运动意图识别中的研究空白。

Method: 使用CNN-LSTM模型处理sEMG信号，以及预训练的Video Swin Transformer结合迁移学习处理视频序列。

Result: sEMG模态准确率87%，预测时间0.04秒；视频模态准确率94%，预测时间0.15秒。

Conclusion: 研究强调了两种数据模态的优劣势，为实际建筑项目中HRC的系统性部署提供了指导。

Abstract: Human-robot collaboration (HRC) in the construction industry depends on
precise and prompt recognition of human motion intentions and actions by robots
to maximize safety and workflow efficiency. There is a research gap in
comparing data modalities, specifically signals and videos, for motion
intention recognition. To address this, the study leverages deep learning to
assess two different modalities in recognizing workers' motion intention at the
early stage of movement in drywall installation tasks. The Convolutional Neural
Network - Long Short-Term Memory (CNN-LSTM) model utilizing surface
electromyography (sEMG) data achieved an accuracy of around 87% with an average
time of 0.04 seconds to perform prediction on a sample input. Meanwhile, the
pre-trained Video Swin Transformer combined with transfer learning harnessed
video sequences as input to recognize motion intention and attained an accuracy
of 94% but with a longer average time of 0.15 seconds for a similar prediction.
This study emphasizes the unique strengths and trade-offs of both data formats,
directing their systematic deployments to enhance HRC in real-world
construction projects.

</details>


### [2] [Privacy Preserving Semantic Communications Using Vision Language Models: A Segmentation and Generation Approach](https://arxiv.org/abs/2509.08142)
*Haoran Chang,Mingzhe Chen,Huaxia Wang,Qianqian Zhang*

Main category: eess.SP

TL;DR: 摘要提出了一种隐私保护的语义通信框架，利用视觉语言模型保护图像数据中的敏感内容，并通过共享隐私数据库和生成模块实现高效重建。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信依赖单模态表示，在信道条件差时重建性能下降，且语义信息攻击的隐私问题日益突出。

Method: 利用视觉语言模型识别并去除输入图像中的隐私内容区域；共享隐私数据库确保发送和接收端对敏感实体的一致识别；接收端通过生成模块基于文本嵌入重建被掩蔽区域。

Result: 仿真结果表明，该框架能适应未见过的图像处理任务，在授权接收端重建质量提升超过10%，窃听者身份泄露减少50%以上。

Conclusion: 该框架有效提升了语义通信的隐私保护能力，同时通过多模态语义对齐改善了重建性能。

Abstract: Semantic communication has emerged as a promising paradigm for
next-generation wireless systems, improving the communication efficiency by
transmitting high-level semantic features. However, reliance on unimodal
representations can degrade reconstruction under poor channel conditions, and
privacy concerns of the semantic information attack also gain increasing
attention. In this work, a privacy-preserving semantic communication framework
is proposed to protect sensitive content of the image data. Leveraging a
vision-language model (VLM), the proposed framework identifies and removes
private content regions from input images prior to transmission. A shared
privacy database enables semantic alignment between the transmitter and
receiver to ensure consistent identification of sensitive entities. At the
receiver, a generative module reconstructs the masked regions using learned
semantic priors and conditioned on the received text embedding. Simulation
results show that generalizes well to unseen image processing tasks, improves
reconstruction quality at the authorized receiver by over 10% using text
embedding, and reduces identity leakage to the eavesdropper by more than 50%.

</details>


### [3] [RTR: A Transformer-Based Lossless Crossover with Perfect Phase Alignment](https://arxiv.org/abs/2509.08272)
*Xiangying Li,Jiankuan Li,Yong Tang*

Main category: eess.SP

TL;DR: 本文提出了一种基于Transformer的无损交叉方法RTR，实现了频率分离和相位对齐，并通过实验验证了其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决传统LC交叉和数字滤波器在能效、相位一致性和鲁棒性方面的不足。

Method: 提出了Resonant Transformer Router (RTR)，满足频率响应的线性互补关系HLF(f)+HHF(f)=1。

Result: 理论推导和电路仿真表明，RTR具有高能效、相位一致性和对元件容差的鲁棒性。

Conclusion: RTR为高保真音频和通信前端提供了低损耗、低延迟的硬件辅助滤波方案。

Abstract: This paper proposes a transformer-based lossless crossover method, termed
Resonant Transformer Router (RTR), which achieves frequency separation while
ensuring perfect phase alignment between low-frequency (LF) and high-frequency
(HF) channels at the crossover frequency. The core property of RTR is that its
frequency responses satisfy a linear complementary relation HLF(f)+HHF(f)=1. so
that the original signal can be perfectly reconstructed by linear summation of
the two channels. Theoretical derivation and circuit simulations demonstrate
that RTR provides superior energy efficiency, phase consistency, and robustness
against component tolerances. Compared with conventional LC crossovers and
digital FIR/IIR filters, RTR offers a low-loss, low-latency hardware-assisted
filtering solution suitable for high-fidelity audio and communication
front-ends.
  The core theory behind this paper's work, lossless crossover, is based on a
Chinese patent [CN116318117A] developed from the previous research of one of
the authors, Jianluan Li. We provide a comprehensive experimental validation of
this theory and propose a new extension.

</details>


### [4] [Fundamental Trade-off in Wideband Stacked Intelligent Metasurface Assisted OFDMA Systems](https://arxiv.org/abs/2509.08294)
*Zheao Li,Jiancheng An,Chau Yuen*

Main category: eess.SP

TL;DR: 论文提出了一种灵活的载波分配策略，通过联合优化载波分配矩阵和智能超表面传输系数，实现低干扰的宽频多用户全模拟波束成形。


<details>
  <summary>Details</summary>
Motivation: 传统的数字波束成形在宽频多用户OFDM系统中功耗高且硬件复杂，而智能超表面可实现高速模拟波束成形，但需解决跨子载波的干扰问题。

Method: 提出灵活载波分配策略和迭代算法，优化载波分配与超表面传输系数，平衡干扰与资源利用率。

Result: 系统拟合误差低，用户可利用更多子载波，且无需数字预编码硬件即可实现高可靠性和低干扰。

Conclusion: 该方案在宽频多用户系统中实现了高效的全模拟波束成形，硬件负担小且性能优越。

Abstract: Conventional digital beamforming for wideband multiuser orthogonal
frequency-division multiplexing (OFDM) demands numerous power-hungry
components, increasing hardware costs and complexity. By contrast, the stacked
intelligent metasurfaces (SIM) can perform wave-based precoding at near-light
speed, drastically reducing baseband overhead. However, realizing SIM-enhanced
fully-analog beamforming for wideband multiuser transmissions remains
challenging, as the SIM configuration has to handle interference across all
subcarriers. To address this, this paper proposes a flexible subcarrier
allocation strategy to fully reap the SIM-assisted fully-analog beamforming
capability in an orthogonal frequency-division multiple access (OFDMA) system,
where each subcarrier selectively serves one or more users to balance
interference mitigation and resource utilization of SIM. We propose an
iterative algorithm to jointly optimize the subcarrier assignment matrix and
SIM transmission coefficients, approximating an interference-free channel for
those selected subcarriers. Results show that the proposed system has low
fitting errors yet allows each user to exploit more subcarriers. Further
comparisons highlight a fundamental trade-off: our system achieves near-zero
interference and robust data reliability without incurring the hardware burdens
of digital precoding.

</details>


### [5] [Fluid-Antenna-aided AAV Secure Communications in Eavesdropper Uncertain Location](https://arxiv.org/abs/2509.08432)
*Yingjie Wu,Junshan Luo,Weiyu Chen,Shilian Wang,Fanggang Wang,Haiyang Ding*

Main category: eess.SP

TL;DR: 论文提出了一种结合流体天线和人工噪声技术的框架，以解决自主飞行器通信中的安全性问题，通过优化部署和天线位置最大化保密率。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线设计因缺乏空间自由度，使自主飞行器的通信易受窃听，因此需要更安全的解决方案。

Method: 提出了一种联合优化AAV部署、信号预编码、人工噪声预编码及流体天线位置的框架，并考虑了窃听位置不确定性。

Result: 数值结果表明，流体天线方案通过利用空间自由度提升了安全性，而人工噪声在高功率下表现显著，二者协同作用更佳。

Conclusion: 流体天线与人工噪声的结合在有限资源下实现了安全性与可靠性的平衡，表现出超越单独使用的优势。

Abstract: For autonomous aerial vehicle (AAV) secure communications, traditional
designs based on fixed position antenna (FPA) lack sufficient spatial degrees
of freedom (DoF), which leaves the line-of-sight-dominated AAV links vulnerable
to eavesdropping. To overcome this problem, this paper proposes a framework
that effectively incorporates the fluid antenna (FA) and the artificial noise
(AN) techniques. Specifically, the minimum secrecy rate (MSR) among multiple
eavesdroppers is maximized by jointly optimizing AAV deployment, signal and AN
precoders, and FA positions. In particular, the worst-case MSR is considered by
taking the channel uncertainties due to the uncertainty about eavesdropping
locations into account. To tackle the highly coupled optimization variables and
the channel uncertainties in the formulated problem, an efficient and robust
algorithm is proposed. Particularly, the uncertain regions of eavesdroppers,
whose shapes can be arbitrary, are disposed by constructing convex hull. In
addition, two movement modes of FAs are considered, namely, free movement mode
and zonal movement mode, for which different optimization techniques are
applied, respectively. Numerical results show that, the proposed FA schemes
boost security by exploiting additional spatial DoF rather than transmit power,
while AN provides remarkable gains under high transmit power. Furthermore, the
synergy between FA and AN results in a secure advantage that exceeds the sum of
their individual contributions, achieving a balance between security and
reliability under limited resources.

</details>


### [6] [Information and Communication Theoretical Foundations of the Internet of Plants, Principles, Challenges, and Future Directions](https://arxiv.org/abs/2509.08434)
*Ahmet B. Kilic,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文综述了植物通过化学、电、菌根和声音信号等多模态通信方式，从信息与通信技术（ICT）角度重新定义植物间通信，并为未来研究和应用提供指导。


<details>
  <summary>Details</summary>
Motivation: 目前对植物通信的系统性ICT分析有限，论文旨在填补这一空白。

Method: 结合生物学背景和ICT框架，综述现有研究并提出发射、信道和接收模型。

Result: 提出了植物互联网（IoP）概念，为精准农业和生态系统监测等应用提供新方向。

Conclusion: 论文为通信研究社区提供了植物通信的全面教程，并促进了跨学科进展。

Abstract: Plants exchange information through multiple modalities, including chemical,
electrical, mycorrhizal, and acoustic signaling, which collectively support
survival, defense, and adaptation. While these processes are well documented in
biology, their systematic analysis from an Information and Communication
Technology (ICT) perspective remains limited. To address this gap, this article
is presented as a tutorial with survey elements. It provides the necessary
biological background, reformulates inter-plant signaling within ICT
frameworks, and surveys empirical studies to guide future research and
applications. First, the paper introduces the fundamental biological processes
to establish a foundation for readers in communications and networking.
Building on this foundation, existing models of emission, propagation, and
reception are synthesized for each modality and reformulated in terms of
transmitter, channel, and receiver blocks. To complement theory, empirical
studies and state-of-the-art sensing approaches are critically examined.
Looking forward, the paper identifies open challenges and outlines future
research directions, with particular emphasis on the emerging vision of the
Internet of Plants (IoP). This paradigm frames plants as interconnected nodes
within ecological and technological networks, offering new opportunities for
applications in precision agriculture, ecosystem monitoring, climate
resilience, and bio-inspired communication systems. By integrating biological
insights with ICT frameworks and projecting toward the IoP, this article
provides a comprehensive tutorial on plant communication for the communications
research community and establishes a foundation for interdisciplinary advances.

</details>


### [7] [On the Performance of ISAC over the D-Band in a Phase-Noise Aware OFDM Systems](https://arxiv.org/abs/2509.08504)
*Didem Aydogan,Mohaned Chraiti,Korkut Kaan Tokgöz*

Main category: eess.SP

TL;DR: 论文研究了D波段（110至170 GHz）频段中的相位噪声（PN）对OFDM ISAC系统性能的影响，使用硬件调谐的3GPP PN模型和FFT雷达处理在130 GHz下进行分析。结果表明，PN会导致测距和测速的性能限制，并影响多普勒旁瓣。强调了PN感知的波形设计的重要性，并指出未来研究可探索PN缓解策略。


<details>
  <summary>Details</summary>
Motivation: D波段频段是未来5G/6G ISAC系统的潜在候选频段，但相位噪声（PN）是一个关键问题。研究旨在评估PN对OFDM ISAC系统性能的影响，为未来多频段收发器设计提供参考。

Method: 使用硬件调谐的3GPP PN模型在130 GHz下进行实验，结合FFT雷达处理，分析了480 kHz载波频率下的ISAC感知性能。

Result: PN导致测距RMSE趋近于0.04-0.05米，测速RMSE趋近于0.12-0.18米/秒。多普勒旁瓣指标的PSLR和ISLR分别趋近于-6 dB和-4 dB。

Conclusion: 测距精度仍受带宽限制，而测速和多普勒旁瓣强烈依赖于PN。研究强调了PN感知的波形设计的重要性，并指出了未来PN缓解策略的研究方向。

Abstract: Phase noise (PN) is a critical impairment at D-band frequencies (110 to 170
GHz), which are widely investigated as promising candidates for beyond 5G/6G
ISAC systems. This paper evaluates OFDM based ISAC sensing performance under
realistic oscillator impairments using a hardware-tuned 3GPP PN model at 130
GHz and FFT based radar processing. With a numerology of 480 kHz, results show
that PN introduces range RMSE floors of 0.04 to 0.05 m and velocity RMSE floors
of 0.12 to 0.18 m/s. Doppler sidelobe metrics also saturate, with PSLR around
minus 6 dB and ISLR around minus 4 dB. These findings confirm that range
accuracy remains bandwidth limited, while velocity estimation and sidelobe
suppression are strongly PN-sensitive. The study highlights the importance of
PN-aware waveform and numerology design for sub-THz ISAC and provides insights
for future multi-band transceivers. Communication metrics and PN mitigation
strategies such as PTRS and CPE tracking are left for future work.

</details>


### [8] [Modular PE-Structured Learning for Cross-Task Wireless Communications](https://arxiv.org/abs/2509.08614)
*Yuxuan Duan,Chenyang Yang*

Main category: eess.SP

TL;DR: 论文提出了一种基于置换等变（PE）特性的模块化深度学习框架PE-MoFormer，用于高效学习多种无线策略，显著提升了学习效率和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大型模型，难以在无线边缘进行预训练和微调，而通过利用无线问题的结构化知识（PE特性），可以设计更紧凑且高效的DNN模型。

Method: 设计了三种类型的PE感知模块（包括两种Transformer风格的子层），分析每种PE特性的假设空间，并利用模块组装提升学习效率。提出的PE-MoFormer框架支持多种无线策略的学习。

Result: 实验表明，模块化PE框架在学习和推理效率上均优于现有大型模型，适用于预编码、波束成形、功率分配和信道估计等任务。

Conclusion: 基于PE的结构化学习方法为无线通信任务提供了一种高效且通用的新方向。

Abstract: Recent trends in learning wireless policies attempt to develop deep neural
networks (DNNs) for handling multiple tasks with a single model. Existing
approaches often rely on large models, which are hard to pre-train and
fine-tune at the wireless edge. In this work, we challenge this paradigm by
leveraging the structured knowledge of wireless problems -- specifically,
permutation equivariant (PE) properties. We design three types of PE-aware
modules, two of which are Transformer-style sub-layers. These modules can serve
as building blocks to assemble compact DNNs applicable to the wireless policies
with various PE properties. To guide the design, we analyze the hypothesis
space associated with each PE property, and show that the PE-structured module
assembly can boost the learning efficiency. Inspired by the reusability of the
modules, we propose PE-MoFormer, a compositional DNN capable of learning a wide
range of wireless policies -- including but not limited to precoding,
coordinated beamforming, power allocation, and channel estimation -- with
strong generalizability, low sample and space complexity. Simulations
demonstrate that the proposed modular PE-based framework outperforms relevant
large model in both learning efficiency and inference time, offering a new
direction for structured cross-task learning for wireless communications.

</details>


### [9] [RIS-Assisted Near-Field ISAC for Multi-Target Indication in NLoS Scenarios](https://arxiv.org/abs/2509.08642)
*Hang Ruan,Homa Nikbakht,Ruizhi Zhang,Honglei Chen,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 论文提出了一种近场ISAC系统中基于RIS的波束成形框架，以提高多目标感知能力，尤其是在视线路径受阻的情况下。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC系统中，多目标感知的主要挑战在于视线路径受阻时难以区分多个目标或用户。

Method: 通过扩展经典波束增益和跨目标相关性指标至近场，并利用角度和距离信息，提出了联合优化基站波束成形和RIS相位偏移的框架，使用AO算法和SDR解决非凸问题。

Result: 仿真结果表明，该RIS辅助框架能够在视线受阻时实现高分辨率的多目标感知。

Conclusion: 提出的方法有效提升了近场ISAC系统中的多目标感知能力，特别是在视线受阻场景下。

Abstract: Enabling multi-target sensing in near-field integrated sensing and
communication (ISAC) systems is a key challenge, particularly when
line-of-sight paths are blocked. This paper proposes a beamforming framework
that leverages a reconfigurable intelligent surface (RIS) to achieve
multi-target indication. Our contribution is the extension of classic
beampattern gain and inter-target cross-correlation metrics to the near-field,
leveraging both angle and distance information to discriminate between multiple
users and targets. We formulate a problem to maximize the worst-case sensing
performance by jointly designing the beamforming at the base station and the
phase shifts at the RIS, while guaranteeing communication rates. The non-convex
problem is solved via an efficient alternating optimization (AO) algorithm that
utilizes semidefinite relaxation (SDR). Simulations demonstrate that our
RIS-assisted framework enables high-resolution sensing of co-angle targets in
blocked scenarios.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [10] [A Novel Theoretical Approach on Micro-Nano Robotic Networks Based on Density Matrices and Swarm Quantum Mechanics](https://arxiv.org/abs/2509.08002)
*Maria Mannone,Mahathi Anand,Peppino Fazio,Abdalla Swikir*

Main category: cs.RO

TL;DR: 论文提出了一种将机器人群体定义为混合量子态的新方法，使用密度矩阵表示，矩阵大小不随机器人数量变化，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 通过量子方法描述群体机器人中的参数（如位置和目标接近度），探索更高效的群体表示形式。

Method: 将群体定义为混合量子态，并使用密度矩阵表示，确保矩阵大小恒定，不随机器人数量增加而变化。

Result: 提出了一种新型的群体表示方法，简化了计算复杂度。

Conclusion: 该方法为机器人群体研究提供了新思路，未来可进一步探索其应用。

Abstract: In a robotic swarm, parameters such as position and proximity to the target
can be described in terms of probability amplitudes. This idea led to recent
studies on a quantum approach to the definition of the swarm, including a
block-matrix representation. Here, we propose an advancement of the idea,
defining a swarm as a mixed quantum state, to be described with a density
matrix, whose size does not change with the number of robots. We end the
article with some directions for future research.

</details>


### [11] [PySensors 2.0: A Python Package for Sparse Sensor Placement](https://arxiv.org/abs/2509.08017)
*Niharika Karnik,Yash Bhangale,Mohammad G. Abdo,Andrei A. Klishin,Joshua J. Cogliati,Bingni W. Brunton,J. Nathan Kutz,Steven L. Brunton,Krithika Manohar*

Main category: cs.RO

TL;DR: PySensors是一个Python包，用于在稀疏传感器布置任务中选择和放置传感器。本次更新引入了空间约束功能、自定义基础输入支持、热力学方法以及噪声不确定性量化等新特性。


<details>
  <summary>Details</summary>
Motivation: 为了提供更灵活的传感器布置方案，并能适应不同应用场景的需求，PySensors进行了功能扩展和优化。

Method: 通过引入空间约束、自定义基础输入、热力学方法和正则化最小二乘法等技术，优化传感器的选择和布置策略。

Result: 新功能支持更多样化的传感器布置方案，并提供可视化工具和不确定性量化，提升了实用性和鲁棒性。

Conclusion: PySensors的更新显著增强了其在多领域的适用性，并为未来的进一步扩展奠定了基础。

Abstract: PySensors is a Python package for selecting and placing a sparse set of
sensors for reconstruction and classification tasks. In this major update to
\texttt{PySensors}, we introduce spatially constrained sensor placement
capabilities, allowing users to enforce constraints such as maximum or exact
sensor counts in specific regions, incorporate predetermined sensor locations,
and maintain minimum distances between sensors. We extend functionality to
support custom basis inputs, enabling integration of any data-driven or
spectral basis. We also propose a thermodynamic approach that goes beyond a
single ``optimal'' sensor configuration and maps the complete landscape of
sensor interactions induced by the training data. This comprehensive view
facilitates integration with external selection criteria and enables assessment
of sensor replacement impacts. The new optimization technique also accounts for
over- and under-sampling of sensors, utilizing a regularized least squares
approach for robust reconstruction. Additionally, we incorporate noise-induced
uncertainty quantification of the estimation error and provide visual
uncertainty heat maps to guide deployment decisions. To highlight these
additions, we provide a brief description of the mathematical algorithms and
theory underlying these new capabilities. We demonstrate the usage of new
features with illustrative code examples and include practical advice for
implementation across various application domains. Finally, we outline a
roadmap of potential extensions to further enhance the package's functionality
and applicability to emerging sensing challenges.

</details>


### [12] [SVN-ICP: Uncertainty Estimation of ICP-based LiDAR Odometry using Stein Variational Newton](https://arxiv.org/abs/2509.08069)
*Shiping Ma,Haoming Zhang,Marc Toussaint*

Main category: cs.RO

TL;DR: SVN-ICP是一种新颖的ICP算法，结合了Stein变分牛顿方法，用于多传感器系统中的LiDAR里程计融合，能够在恶劣环境下提供高精度的位姿估计和噪声参数推断。


<details>
  <summary>Details</summary>
Motivation: 解决在多传感器系统中，尤其是在LiDAR性能下降的环境下，实现高精度的位姿估计和噪声参数推断的问题。

Method: 利用Stein变分推断框架，通过粒子逼近后验分布，避免了显式噪声建模或手动参数调优。

Result: 在多个数据集上的实验表明，SVN-ICP在复杂场景中的表现优于同类最佳方法，并提供可靠的噪声估计。

Conclusion: SVN-ICP在多传感器系统中展现出高效且可靠的性能，适用于多样化的环境和机器人类型。

Abstract: This letter introduces SVN-ICP, a novel Iterative Closest Point (ICP)
algorithm with uncertainty estimation that leverages Stein Variational Newton
(SVN) on manifold. Designed specifically for fusing LiDAR odometry in
multisensor systems, the proposed method ensures accurate pose estimation and
consistent noise parameter inference, even in LiDAR-degraded environments. By
approximating the posterior distribution using particles within the Stein
Variational Inference framework, SVN-ICP eliminates the need for explicit noise
modeling or manual parameter tuning. To evaluate its effectiveness, we
integrate SVN-ICP into a simple error-state Kalman filter alongside an IMU and
test it across multiple datasets spanning diverse environments and robot types.
Extensive experimental results demonstrate that our approach outperforms
best-in-class methods on challenging scenarios while providing reliable
uncertainty estimates.

</details>


### [13] [Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor Fusion](https://arxiv.org/abs/2509.08095)
*Lamiaa H. Zain,Raafat E. Shalaby*

Main category: cs.RO

TL;DR: 该研究训练并评估了三种端到端卷积神经网络（CNN）模型，用于移动机器人在复杂环境中的实时避障。其中NetConEmb表现最优，离线评估误差低，且在实时导航中表现稳健。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是通过深度学习技术提高移动机器人在未知和复杂环境中的避障能力。

Method: 采用了三种CNN模型（NetConEmb、NetEmb、NetGated），通过RGB-D摄像头获取同步图像，生成低级转向命令。

Result: NetConEmb离线评估误差最低（MedAE为0.58×10−3 rad/s），实时导航成功率达100%；NetEmb表现接近。

Conclusion: NetConEmb在避障任务中表现最佳，证明了深度学习方法在移动机器人导航中的有效性。

Abstract: Obstacle avoidance is a critical component of the navigation stack required
for mobile robots to operate effectively in complex and unknown environments.
In this research, three end-to-end Convolutional Neural Networks (CNNs) were
trained and evaluated offline and deployed on a differential-drive mobile robot
for real-time obstacle avoidance to generate low-level steering commands from
synchronized color and depth images acquired by an Intel RealSense D415 RGB-D
camera in diverse environments. Offline evaluation showed that the NetConEmb
model achieved the best performance with a notably low MedAE of $0.58 \times
10^{-3}$ rad/s. In comparison, the lighter NetEmb architecture adopted in this
study, which reduces the number of trainable parameters by approximately 25\%
and converges faster, produced comparable results with an RMSE of $21.68 \times
10^{-3}$ rad/s, close to the $21.42 \times 10^{-3}$ rad/s obtained by
NetConEmb. Real-time navigation further confirmed NetConEmb's robustness,
achieving a 100\% success rate in both known and unknown environments, while
NetEmb and NetGated succeeded only in navigating the known environment.

</details>


### [14] [Online Learning and Coverage of Unknown Fields Using Random-Feature Gaussian Processes](https://arxiv.org/abs/2509.08117)
*Ruijie Du,Ruoyu Lin,Yanning Shen,Magnus Egerstedt*

Main category: cs.RO

TL;DR: 提出了一种多机器人系统框架，用于同时学习和覆盖未知且可能时变的密度函数域，结合了随机特征高斯过程（RFGP）和Voronoi覆盖控制。


<details>
  <summary>Details</summary>
Motivation: 解决高斯过程回归在处理未知和时变密度函数时的局限性。

Method: 采用随机特征高斯过程（RFGP）及其在线版本（O-RFGP），结合Voronoi覆盖控制和UCB采样策略。

Result: 在时间不变和时间变化场景下均有效，并通过模拟和实验验证。

Conclusion: 该框架在多机器人系统中能自适应聚焦重要区域并高效覆盖，具有理论保证和实践可行性。

Abstract: This paper proposes a framework for multi-robot systems to perform
simultaneous learning and coverage of the domain of interest characterized by
an unknown and potentially time-varying density function. To overcome the
limitations of Gaussian Process (GP) regression, we employ Random Feature GP
(RFGP) and its online variant (O-RFGP) that enables online and incremental
inference. By integrating these with Voronoi-based coverage control and Upper
Confidence Bound (UCB) sampling strategy, a team of robots can adaptively focus
on important regions while refining the learned spatial field for efficient
coverage. Under mild assumptions, we provide theoretical guarantees and
evaluate the framework through simulations in time-invariant scenarios.
Furthermore, its effectiveness in time-varying settings is demonstrated through
additional simulations and a physical experiment.

</details>


### [15] [Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning](https://arxiv.org/abs/2509.08126)
*Houjian Yu,Zheming Zhou,Min Sun,Omid Ghasemalizadeh,Yuyin Sun,Cheng-Hao Kuo,Arnie Sen,Changhyun Choi*

Main category: cs.RO

TL;DR: OGRG框架通过自然语言理解实现机器人抓取，支持开放语言表达和重复对象场景，提升了抓取准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理开放语言表达和重复对象场景，且依赖高成本密集标注。需要更高效的解决方案。

Method: 提出OGRG框架，结合双向视觉语言融合模块和深度信息，支持RGS和RGA两种监督学习设置。

Result: 实验显示OGRG在抓取准确性和速度上优于基线方法，RGS达17.59 FPS，RGA在仿真和实际场景中表现优异。

Conclusion: OGRG通过空间推理设计，显著提升机器人抓取性能，支持高效闭环或多对象顺序操作。

Abstract: Enabling robots to grasp objects specified through natural language is
essential for effective human-robot interaction, yet it remains a significant
challenge. Existing approaches often struggle with open-form language
expressions and typically assume unambiguous target objects without duplicates.
Moreover, they frequently rely on costly, dense pixel-wise annotations for both
object grounding and grasp configuration. We present Attribute-based Object
Grounding and Robotic Grasping (OGRG), a novel framework that interprets
open-form language expressions and performs spatial reasoning to ground target
objects and predict planar grasp poses, even in scenes containing duplicated
object instances. We investigate OGRG in two settings: (1) Referring Grasp
Synthesis (RGS) under pixel-wise full supervision, and (2) Referring Grasp
Affordance (RGA) using weakly supervised learning with only single-pixel grasp
annotations. Key contributions include a bi-directional vision-language fusion
module and the integration of depth information to enhance geometric reasoning,
improving both grounding and grasping performance. Experiment results show that
OGRG outperforms strong baselines in tabletop scenes with diverse spatial
language instructions. In RGS, it operates at 17.59 FPS on a single NVIDIA RTX
2080 Ti GPU, enabling potential use in closed-loop or multi-object sequential
grasping, while delivering superior grounding and grasp prediction accuracy
compared to all the baselines considered. Under the weakly supervised RGA
setting, OGRG also surpasses baseline grasp-success rates in both simulation
and real-robot trials, underscoring the effectiveness of its spatial reasoning
design. Project page: https://z.umn.edu/ogrg

</details>


### [16] [Mean Field Game-Based Interactive Trajectory Planning Using Physics-Inspired Unified Potential Fields](https://arxiv.org/abs/2509.08147)
*Zhen Tian,Fujiang Yuan,Chunhong Yuan,Yanhong Peng*

Main category: cs.RO

TL;DR: 提出了一种基于平均场博弈理论的交互增强统一势场框架(IUPF)，用于自动驾驶中的轨迹规划，兼具安全性、效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶轨迹规划中计算成本高和依赖外部安全评估的问题。

Method: 通过物理启发的变分模型融合风格依赖的效益与风险场，利用随机微分方程保证纳什均衡的指数收敛。

Result: 仿真验证IUPF在安全距离保持、轨迹平滑性和计算效率上优于传统优化和博弈论方法。

Conclusion: IUPF框架在不依赖额外安全模块的情况下，有效捕获多种驾驶行为，实现了高效且安全的轨迹规划。

Abstract: Interactive trajectory planning in autonomous driving must balance safety,
efficiency, and scalability under heterogeneous driving behaviors. Existing
methods often face high computational cost or rely on external safety critics.
To address this, we propose an Interaction-Enriched Unified Potential Field
(IUPF) framework that fuses style-dependent benefit and risk fields through a
physics-inspired variational model, grounded in mean field game theory. The
approach captures conservative, aggressive, and cooperative behaviors without
additional safety modules, and employs stochastic differential equations to
guarantee Nash equilibrium with exponential convergence. Simulations on lane
changing and overtaking scenarios show that IUPF ensures safe distances,
generates smooth and efficient trajectories, and outperforms traditional
optimization and game-theoretic baselines in both adaptability and
computational efficiency.

</details>


### [17] [Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation](https://arxiv.org/abs/2509.08157)
*Viraj Parimi,Brian C. Williams*

Main category: cs.RO

TL;DR: 论文提出了一种动态调整风险预算的多智能体路径规划方法RB-CBS，以解决传统图剪枝方法在安全和效率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 在危险环境中，多智能体协调导航需要平衡安全和效率，但现有方法要么过于保守，要么难以处理复杂场景。

Method: 通过动态分配用户指定的风险预算（Δ），并结合冲突搜索（CBS），改进路径规划。

Result: 实验证明，RB-C框架在多智能体复杂环境中能更高效地找到无碰撞路径。

Conclusion: RB-CBS在保证安全的前提下，显著提高了导航效率。

Abstract: Safe navigation is essential for autonomous systems operating in hazardous
environments, especially when multiple agents must coordinate using just visual
inputs over extended time horizons. Traditional planning methods excel at
solving long-horizon tasks but rely on predefined distance metrics, while safe
Reinforcement Learning (RL) can learn complex behaviors using high-dimensional
inputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work
combined these paradigms by leveraging goal-conditioned RL (GCRL) to build an
intermediate graph from replay buffer states, pruning unsafe edges, and using
Conflict-Based Search (CBS) for multi-agent path planning. Although effective,
this graph-pruning approach can be overly conservative, limiting mission
efficiency by precluding missions that must traverse high-risk regions. To
address this limitation, we propose RB-CBS, a novel extension to CBS that
dynamically allocates and adjusts user-specified risk bound ($\Delta$) across
agents to flexibly trade off safety and speed. Our improved planner ensures
that each agent receives a local risk budget ($\delta$) enabling more efficient
navigation while still respecting overall safety constraints. Experimental
results demonstrate that this iterative risk-allocation framework yields
superior performance in complex environments, allowing multiple agents to find
collision-free paths within the user-specified $\Delta$.

</details>


### [18] [Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation](https://arxiv.org/abs/2509.08159)
*Steven Yang,Xiaoyu Tian,Kshitij Goel,Wennie Tabib*

Main category: cs.RO

TL;DR: 本文提出了一种通过单目RGB图像和IMU预测度量深度的方法，用于无人机避障。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖重型传感器或复杂的数据调优，而本文旨在提供轻量化的零样本深度估计方案。

Method: 提出了几种轻量化的零样本重缩放策略，利用视觉-惯性导航系统生成的稀疏3D特征图从相对深度估计中获得度量深度。

Result: 在多种仿真环境中验证了策略的准确性，最优方法在实际计算受限的四旋翼无人机上实现了15 Hz的度量深度估计并成功避障。

Conclusion: 该方法通过轻量化策略实现了高效的度量深度估计和避障，适用于计算受限的实际场景。

Abstract: This paper presents a methodology to predict metric depth from monocular RGB
images and an inertial measurement unit (IMU). To enable collision avoidance
during autonomous flight, prior works either leverage heavy sensors (e.g.,
LiDARs or stereo cameras) or data-intensive and domain-specific fine-tuning of
monocular metric depth estimation methods. In contrast, we propose several
lightweight zero-shot rescaling strategies to obtain metric depth from relative
depth estimates via the sparse 3D feature map created using a visual-inertial
navigation system. These strategies are compared for their accuracy in diverse
simulation environments. The best performing approach, which leverages
monotonic spline fitting, is deployed in the real-world on a
compute-constrained quadrotor. We obtain on-board metric depth estimates at 15
Hz and demonstrate successful collision avoidance after integrating the
proposed method with a motion primitives-based planner.

</details>


### [19] [Diffusion-Guided Multi-Arm Motion Planning](https://arxiv.org/abs/2509.08160)
*Viraj Parimi,Brian C. Williams*

Main category: cs.RO

TL;DR: 提出了一种扩散引导的多臂运动规划器（DG-MAP），通过分解问题和生成模型，有效解决了多臂运动规划的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 多臂运动规划在共享空间中完成复杂任务具有重要性，但现有方法因状态空间指数增长和大规模训练数据集依赖而难以扩展。

Method: 结合多智能体路径规划（MAPF）的思想，训练两个条件扩散模型：一个生成单臂轨迹，另一个解决双臂碰撞问题。

Result: DG-MAP在扩展性和减少数据集依赖方面优于其他基于学习的方法。

Conclusion: DG-MAP通过结构化分解和生成模型，显著提升了多臂运动规划的效率和适用性。

Abstract: Multi-arm motion planning is fundamental for enabling arms to complete
complex long-horizon tasks in shared spaces efficiently but current methods
struggle with scalability due to exponential state-space growth and reliance on
large training datasets for learned models. Inspired by Multi-Agent Path
Finding (MAPF), which decomposes planning into single-agent problems coupled
with collision resolution, we propose a novel diffusion-guided multi-arm
planner (DG-MAP) that enhances scalability of learning-based models while
reducing their reliance on massive multi-arm datasets. Recognizing that
collisions are primarily pairwise, we train two conditional diffusion models,
one to generate feasible single-arm trajectories, and a second, to model the
dual-arm dynamics required for effective pairwise collision resolution. By
integrating these specialized generative models within a MAPF-inspired
structured decomposition, our planner efficiently scales to larger number of
arms. Evaluations against alternative learning-based methods across various
team sizes demonstrate our method's effectiveness and practical applicability.
Project website can be found at https://diff-mapf-mers.csail.mit.edu

</details>


### [20] [Quadrotor Navigation using Reinforcement Learning with Privileged Information](https://arxiv.org/abs/2509.08177)
*Jonathan Lee,Abhishek Rathod,Kshitij Goel,John Stecklein,Wennie Tabib*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习的四旋翼导航方法，通过高效的可微模拟、新颖的损失函数和特权信息（如到达时间地图）来绕过大障碍物导航。


<details>
  <summary>Details</summary>
Motivation: 现有的学习方法在小障碍物场景中表现良好，但在大障碍物如墙壁或地形遮挡目标位置时表现不佳。

Method: 该方法利用到达时间（ToA）地图作为特权信息，并设计了一种偏航对齐损失函数来引导机器人绕过大障碍物。

Result: 在包含大障碍物、锐角和死角的仿真环境中，该方法实现了86%的成功率，比基线策略高出34%。实际飞行测试中，在室外杂乱环境中完成了20次飞行，覆盖589米无碰撞，最高速度达4米/秒。

Conclusion: 该方法通过结合特权信息和强化学习，显著提升了四旋翼在大障碍物环境中的导航能力。

Abstract: This paper presents a reinforcement learning-based quadrotor navigation
method that leverages efficient differentiable simulation, novel loss
functions, and privileged information to navigate around large obstacles. Prior
learning-based methods perform well in scenes that exhibit narrow obstacles,
but struggle when the goal location is blocked by large walls or terrain. In
contrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged
information and a yaw alignment loss to guide the robot around large obstacles.
The policy is evaluated in photo-realistic simulation environments containing
large obstacles, sharp corners, and dead-ends. Our approach achieves an 86%
success rate and outperforms baseline strategies by 34%. We deploy the policy
onboard a custom quadrotor in outdoor cluttered environments both during the
day and night. The policy is validated across 20 flights, covering 589 meters
without collisions at speeds up to 4 m/s.

</details>


### [21] [Online Dynamic SLAM with Incremental Smoothing and Mapping](https://arxiv.org/abs/2509.08197)
*Jesse Morris,Yiduo Wang,Viorela Ila*

Main category: cs.RO

TL;DR: 本文提出了一种基于增量优化的动态SLAM方法，首次在动态SLAM中应用增量优化技术，新设计了因子图框架和系统架构，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有动态SLAM方法准确但计算成本高，无法在线应用。

Method: 采用增量优化技术，设计新因子图框架和系统架构。

Result: 在多数据集上表现优于或等于现有方法，计算速度提升5倍。

Conclusion: 增量优化适合动态SLAM，系统架构进一步增强了性能。

Abstract: Dynamic SLAM methods jointly estimate for the static and dynamic scene
components, however existing approaches, while accurate, are computationally
expensive and unsuitable for online applications. In this work, we present the
first application of incremental optimisation techniques to Dynamic SLAM. We
introduce a novel factor-graph formulation and system architecture designed to
take advantage of existing incremental optimisation methods and support online
estimation. On multiple datasets, we demonstrate that our method achieves equal
to or better than state-of-the-art in camera pose and object motion accuracy.
We further analyse the structural properties of our approach to demonstrate its
scalability and provide insight regarding the challenges of solving Dynamic
SLAM incrementally. Finally, we show that our formulation results in problem
structure well-suited to incremental solvers, while our system architecture
further enhances performance, achieving a 5x speed-up over existing methods.

</details>


### [22] [A Comprehensive Review of Reinforcement Learning for Autonomous Driving in the CARLA Simulator](https://arxiv.org/abs/2509.08221)
*Elahe Delavari,Feeza Khan Khanzada,Jaerock Kwon*

Main category: cs.RO

TL;DR: 本文系统分析了约100篇在CARLA模拟器中训练、测试或验证强化学习策略的论文，总结了RL在自动驾驶中的应用现状、方法分类及挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶研究中，强化学习（RL）被认为是数据驱动决策的有前景框架，但对其当前应用、基准和评估方法的全面梳理仍然缺乏。

Method: 通过分类文献（模型无关、模型相关、分层和混合方法），量化研究趋势，并分析状态、动作、奖励的多样配置及评估指标。

Result: 超过80%的研究仍依赖模型无关方法（如DQN、PPO、SAC）。研究揭示了评估标准的多样性，并提出开放性问题和未来方向。

Conclusion: 本文为新人提供参考，并为RL在自动驾驶中的实际部署提供路线图。

Abstract: Autonomous-driving research has recently embraced deep Reinforcement Learning
(RL) as a promising framework for data-driven decision making, yet a clear
picture of how these algorithms are currently employed, benchmarked and
evaluated is still missing. This survey fills that gap by systematically
analysing around 100 peer-reviewed papers that train, test or validate RL
policies inside the open-source CARLA simulator. We first categorize the
literature by algorithmic family model-free, model-based, hierarchical, and
hybrid and quantify their prevalence, highlighting that more than 80% of
existing studies still rely on model-free methods such as DQN, PPO and SAC.
Next, we explain the diverse state, action and reward formulations adopted
across works, illustrating how choices of sensor modality (RGB, LiDAR, BEV,
semantic maps, and carla kinematics states), control abstraction (discrete vs.
continuous) and reward shaping are used across various literature. We also
consolidate the evaluation landscape by listing the most common metrics
(success rate, collision rate, lane deviation, driving score) and the towns,
scenarios and traffic configurations used in CARLA benchmarks. Persistent
challenges including sparse rewards, sim-to-real transfer, safety guarantees
and limited behaviour diversity are distilled into a set of open research
questions, and promising directions such as model-based RL, meta-learning and
richer multi-agent simulations are outlined. By providing a unified taxonomy,
quantitative statistics and a critical discussion of limitations, this review
aims to serve both as a reference for newcomers and as a roadmap for advancing
RL-based autonomous driving toward real-world deployment.

</details>


### [23] [Input-gated Bilateral Teleoperation: An Easy-to-implement Force Feedback Teleoperation Method for Low-cost Hardware](https://arxiv.org/abs/2509.08226)
*Yoshiki Kanai,Akira Kanazawa,Hideyuki Ichiwara,Hiroshi Ito,Naoaki Noguchi,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 提出了一种无需力传感器的双边遥操作方法，适用于低成本硬件，实现了高操作性和接触稳定性，且易于实施和推广。


<details>
  <summary>Details</summary>
Motivation: 在接触丰富的操作中，力反馈数据收集至关重要，但传统双边遥操作技术复杂且难以实现，亟需简化方案。

Method: 采用简单的反馈控制器和低成本硬件，设计了一种无需力传感器的双边遥操作方法，适用于领导者-跟随者设置。

Result: 数值模拟和实际实验证明，该方法参数调整少，性能优于传统技术，且在不同通信速率下保持高鲁棒性。

Conclusion: 该方法显著简化了力反馈遥操作系统的实施，有望推动低成本硬件上的接触丰富任务自主化。

Abstract: Effective data collection in contact-rich manipulation requires force
feedback during teleoperation, as accurate perception of contact is crucial for
stable control. However, such technology remains uncommon, largely because
bilateral teleoperation systems are complex and difficult to implement. To
overcome this, we propose a bilateral teleoperation method that relies only on
a simple feedback controller and does not require force sensors. The approach
is designed for leader-follower setups using low-cost hardware, making it
broadly applicable. Through numerical simulations and real-world experiments,
we demonstrate that the method requires minimal parameter tuning, yet achieves
both high operability and contact stability, outperforming conventional
approaches. Furthermore, we show its high robustness: even at low communication
cycle rates between leader and follower, control performance degradation is
minimal compared to high-speed operation. We also prove our method can be
implemented on two types of commercially available low-cost hardware with zero
parameter adjustments. This highlights its high ease of implementation and
versatility. We expect this method will expand the use of force feedback
teleoperation systems on low-cost hardware. This will contribute to advancing
contact-rich task autonomy in imitation learning.

</details>


### [24] [Deep Visual Odometry for Stereo Event Cameras](https://arxiv.org/abs/2509.08235)
*Sheng Zhong,Junkai Niu,Yi Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习的立体事件视觉里程计（Stereo-DEVO），通过静态立体关联策略和紧密耦合的束调整优化，实现了高精度的姿态估计，并在低光高动态范围（HDR）场景中表现稳定。


<details>
  <summary>Details</summary>
Motivation: 事件相机的微秒级分辨率和高动态范围使其在运动模糊和高动态照明条件下具有优势，但传统的手工数据关联方法在低光HDR条件下不可靠。深度神经网络为解决这些挑战提供了新可能性。

Method: 基于DEVO框架，Stereo-DEVO引入了一种高效的静态立体关联策略，并通过紧密耦合的束调整优化和基于体素的事件表示进行光流估计。

Result: 系统能够在实时处理VGA分辨率的事件数据，并在多个公开数据集和自采数据中表现优异，特别是在夜间HDR场景中实现了稳定的姿态估计。

Conclusion: Stereo-DEVO在性能和实时性上均优于现有的事件视觉里程计方法，能够广泛应用于低光HDR环境。

Abstract: Event-based cameras are bio-inspired sensors with pixels that independently
and asynchronously respond to brightness changes at microsecond resolution,
offering the potential to handle state estimation tasks involving motion blur
and high dynamic range (HDR) illumination conditions. However, the versatility
of event-based visual odometry (VO) relying on handcrafted data association
(either direct or indirect methods) is still unreliable, especially in field
robot applications under low-light HDR conditions, where the dynamic range can
be enormous and the signal-to-noise ratio is spatially-and-temporally varying.
Leveraging deep neural networks offers new possibilities for overcoming these
challenges. In this paper, we propose a learning-based stereo event visual
odometry. Building upon Deep Event Visual Odometry (DEVO), our system (called
Stereo-DEVO) introduces a novel and efficient static-stereo association
strategy for sparse depth estimation with almost no additional computational
burden. By integrating it into a tightly coupled bundle adjustment (BA)
optimization scheme, and benefiting from the recurrent network's ability to
perform accurate optical flow estimation through voxel-based event
representations to establish reliable patch associations, our system achieves
high-precision pose estimation in metric scale. In contrast to the offline
performance of DEVO, our system can process event data of \zs{Video Graphics
Array} (VGA) resolution in real time. Extensive evaluations on multiple public
real-world datasets and self-collected data justify our system's versatility,
demonstrating superior performance compared to state-of-the-art event-based VO
methods. More importantly, our system achieves stable pose estimation even in
large-scale nighttime HDR scenarios.

</details>


### [25] [Sample-Efficient Online Control Policy Learning with Real-Time Recursive Model Updates](https://arxiv.org/abs/2509.08241)
*Zixin Zhang,James Avtges,Todd D. Murphey*

Main category: cs.RO

TL;DR: 本文提出了一种高效的Koopman学习框架（RKL），能够在数据有限的情况下实现实时更新，并验证了其在样本效率和稳定性上的优越性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的控制在数据获取和计算资源有限（如硬件学习）时需要高效且轻量级的方法。现有方法通常需要大数据集且难以实时更新，限制了其在动态环境中的表现。

Method: 基于Koopman理论，将非线性系统线性化为可观测模型，提出递归Koopman学习（RKL），理论基础支持其轻量级和快速更新的特性。

Result: 实验验证表明，RKL在数据样本效率和稳定性上表现优异，仅需基准方法10%的数据。

Conclusion: RKL是一种高效且轻量级的数据驱动控制方法，适用于数据有限和计算资源受限的场景。开源高性能代码库进一步增强了实用性。

Abstract: Data-driven control methods need to be sample-efficient and lightweight,
especially when data acquisition and computational resources are limited --
such as during learning on hardware. Most modern data-driven methods require
large datasets and struggle with real-time updates of models, limiting their
performance in dynamic environments. Koopman theory formally represents
nonlinear systems as linear models over observables, and Koopman
representations can be determined from data in an optimization-friendly setting
with potentially rapid model updates. In this paper, we present a highly
sample-efficient, Koopman-based learning pipeline: Recursive Koopman Learning
(RKL). We identify sufficient conditions for model convergence and provide
formal algorithmic analysis supporting our claim that RKL is lightweight and
fast, with complexity independent of dataset size. We validate our method on a
simulated planar two-link arm and a hybrid nonlinear hardware system with soft
actuators, showing that real-time recursive Koopman model updates improve the
sample efficiency and stability of data-driven controller synthesis --
requiring only <10% of the data compared to benchmarks. The high-performance
C++ codebase is open-sourced. Website:
https://www.zixinatom990.com/home/robotics/corl-2025-recursive-koopman-learning.

</details>


### [26] [Behaviorally Heterogeneous Multi-Agent Exploration Using Distributed Task Allocation](https://arxiv.org/abs/2509.08242)
*Nirabhra Mandal,Aamodh Suresh,Carlos Nieto-Granda,Sonia Martínez*

Main category: cs.RO

TL;DR: 本文研究了行为异构机器人的多智能体探索问题，通过SLAM构建地图并评估前沿区域的探索价值，采用分布式算法解决任务分配问题，实验证明了算法的高效性和异构团队的优势。


<details>
  <summary>Details</summary>
Motivation: 研究行为异构机器人在探索环境中的表现，探讨如何通过分布式算法优化任务分配，以提高探索效率和减少通信成本。

Method: 使用SLAM构建环境地图，通过行为熵（BE）评估前沿区域的探索价值，并采用分布式非合作博弈算法（d-PBRAG）收敛至纳什均衡，实现最优任务分配。对于未知效用情况，提供基于近似奖励的鲁棒性边界。

Result: 实验结果表明，算法通信成本低且收敛速度快。异构行为团队在探索完成时间和路径长度方面表现更优。

Conclusion: 行为异构机器人团队在多智能体探索任务中具有优势，分布式算法d-PBRAG在任务分配中表现出高效性和鲁棒性。

Abstract: We study a problem of multi-agent exploration with behaviorally heterogeneous
robots. Each robot maps its surroundings using SLAM and identifies a set of
areas of interest (AoIs) or frontiers that are the most informative to explore
next. The robots assess the utility of going to a frontier using Behavioral
Entropy (BE) and then determine which frontier to go to via a distributed task
assignment scheme. We convert the task assignment problem into a
non-cooperative game and use a distributed algorithm (d-PBRAG) to converge to
the Nash equilibrium (which we show is the optimal task allocation solution).
For unknown utility cases, we provide robust bounds using approximate rewards.
We test our algorithm (which has less communication cost and fast convergence)
in simulation, where we explore the effect of sensing radii, sensing accuracy,
and heterogeneity among robotic teams with respect to the time taken to
complete exploration and path traveled. We observe that having a team of agents
with heterogeneous behaviors is beneficial.

</details>


### [27] [Symmetry-Guided Multi-Agent Inverse Reinforcement Learnin](https://arxiv.org/abs/2509.08257)
*Yongkai Tian,Yirong Qi,Xin Yu,Wenjun Wu,Jie Luo*

Main category: cs.RO

TL;DR: 本文提出了一种利用多智能体系统的对称性提升逆强化学习样本效率的通用框架，实验验证了其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统逆强化学习依赖大量专家示范数据，但在多机器人系统中收集此类数据成本高昂，因此提高样本效率成为关键挑战。

Method: 利用多智能体系统的对称性，提出了一种通用框架，并将其集成到现有多智能体对抗逆强化学习算法中。

Result: 实验结果表明，该方法能显著提升样本效率，且在物理多机器人系统中验证了其实际应用价值。

Conclusion: 对称性在多智能体逆强化学习中具有重要作用，提出的框架为解决样本效率问题提供了有效方案。

Abstract: In robotic systems, the performance of reinforcement learning depends on the
rationality of predefined reward functions. However, manually designed reward
functions often lead to policy failures due to inaccuracies. Inverse
Reinforcement Learning (IRL) addresses this problem by inferring implicit
reward functions from expert demonstrations. Nevertheless, existing methods
rely heavily on large amounts of expert demonstrations to accurately recover
the reward function. The high cost of collecting expert demonstrations in
robotic applications, particularly in multi-robot systems, severely hinders the
practical deployment of IRL. Consequently, improving sample efficiency has
emerged as a critical challenge in multi-agent inverse reinforcement learning
(MIRL). Inspired by the symmetry inherent in multi-agent systems, this work
theoretically demonstrates that leveraging symmetry enables the recovery of
more accurate reward functions. Building upon this insight, we propose a
universal framework that integrates symmetry into existing multi-agent
adversarial IRL algorithms, thereby significantly enhancing sample efficiency.
Experimental results from multiple challenging tasks have demonstrated the
effectiveness of this framework. Further validation in physical multi-robot
systems has shown the practicality of our method.

</details>


### [28] [Foundation Models for Autonomous Driving Perception: A Survey Through Core Capabilities](https://arxiv.org/abs/2509.08302)
*Rajendramayavan Sathyam,Yueqi Li*

Main category: cs.RO

TL;DR: 该论文调查了基础模型在自动驾驶感知领域的应用，探讨了如何通过通用架构解决泛化性、可扩展性和分布偏移等挑战，并提出了一种基于四大关键能力的新分类法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知领域正从任务专用的深度学习模型转向通用基础模型，但如何实现其在实际驾驶环境中的稳健性能仍面临挑战。

Method: 论文提出了一种以四大关键能力（泛化知识、空间理解、多传感器稳健性和时间推理）为核心的新分类法，并从概念设计原则出发，综述了前沿方法。

Result: 论文总结了基础模型在自动驾驶感知中的最新进展，并突出了其潜力与当前局限。

Conclusion: 基础模型在自动驾驶感知中具有巨大潜力，但仍需解决实时性、计算需求和模型可靠性等关键问题，未来研究应关注这些方向以实现安全部署。

Abstract: Foundation models are revolutionizing autonomous driving perception,
transitioning the field from narrow, task-specific deep learning models to
versatile, general-purpose architectures trained on vast, diverse datasets.
This survey examines how these models address critical challenges in autonomous
perception, including limitations in generalization, scalability, and
robustness to distributional shifts. The survey introduces a novel taxonomy
structured around four essential capabilities for robust performance in dynamic
driving environments: generalized knowledge, spatial understanding,
multi-sensor robustness, and temporal reasoning. For each capability, the
survey elucidates its significance and comprehensively reviews cutting-edge
approaches. Diverging from traditional method-centric surveys, our unique
framework prioritizes conceptual design principles, providing a
capability-driven guide for model development and clearer insights into
foundational aspects. We conclude by discussing key challenges, particularly
those associated with the integration of these capabilities into real-time,
scalable systems, and broader deployment challenges related to computational
demands and ensuring model reliability against issues like hallucinations and
out-of-distribution failures. The survey also outlines crucial future research
directions to enable the safe and effective deployment of foundation models in
autonomous driving systems.

</details>


### [29] [Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry](https://arxiv.org/abs/2509.08333)
*Sai Puneeth Reddy Gottam,Haoming Zhang,Eivydas Keras*

Main category: cs.RO

TL;DR: 论文通过自监督学习增强深度特征提取和跟踪，以应对视觉定位中的光照变化和低纹理区域等挑战。


<details>
  <summary>Details</summary>
Motivation: 视觉定位在大规模户外和长期场景中因光照变化、动态场景和低纹理区域等问题性能下降，现有学习方法在非分布数据上泛化能力不足。

Method: 采用自监督学习并结合任务特定反馈，提升深度特征提取和跟踪的稳定性与信息量。

Result: 提出的方法能够生成更稳定和丰富的信息特征，从而在复杂环境中提升泛化能力和可靠性。

Conclusion: 通过自监督学习改进的特征提取和跟踪方法显著提升了在挑战性环境中的视觉定位性能。

Abstract: Visual-based localization has made significant progress, yet its performance
often drops in large-scale, outdoor, and long-term settings due to factors like
lighting changes, dynamic scenes, and low-texture areas. These challenges
degrade feature extraction and tracking, which are critical for accurate motion
estimation. While learning-based methods such as SuperPoint and SuperGlue show
improved feature coverage and robustness, they still face generalization issues
with out-of-distribution data. We address this by enhancing deep feature
extraction and tracking through self-supervised learning with task specific
feedback. Our method promotes stable and informative features, improving
generalization and reliability in challenging environments.

</details>


### [30] [Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration](https://arxiv.org/abs/2509.08354)
*Ce Guo,Xieyuanli Chen,Zhiwen Zeng,Zirui Guo,Yihong Li,Haoran Xiao,Dewen Hu,Huimin Lu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Tactile and kinesthetic perceptions are crucial for human dexterous
manipulation, enabling reliable grasping of objects via proprioceptive
sensorimotor integration. For robotic hands, even though acquiring such tactile
and kinesthetic feedback is feasible, establishing a direct mapping from this
sensory feedback to motor actions remains challenging. In this paper, we
propose a novel glove-mediated tactile-kinematic perception-prediction
framework for grasp skill transfer from human intuitive and natural operation
to robotic execution based on imitation learning, and its effectiveness is
validated through generalized grasping tasks, including those involving
deformable objects. Firstly, we integrate a data glove to capture tactile and
kinesthetic data at the joint level. The glove is adaptable for both human and
robotic hands, allowing data collection from natural human hand demonstrations
across different scenarios. It ensures consistency in the raw data format,
enabling evaluation of grasping for both human and robotic hands. Secondly, we
establish a unified representation of multi-modal inputs based on graph
structures with polar coordinates. We explicitly integrate the morphological
differences into the designed representation, enhancing the compatibility
across different demonstrators and robotic hands. Furthermore, we introduce the
Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN), which leverage
multidimensional subgraph convolutions and attention-based LSTM layers to
extract spatio-temporal features from graph inputs to predict node-based states
for each hand joint. These predictions are then mapped to final commands
through a force-position hybrid mapping.

</details>


### [31] [PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching](https://arxiv.org/abs/2509.08435)
*Lei Ye,Haibo Gao,Peng Xu,Zhelin Zhang,Junqi Shan,Ao Zhang,Wei Zhang,Ruyi Zhou,Zongquan Deng,Liang Ding*

Main category: cs.RO

TL;DR: PegasusFlow是一种无需专家数据的轨迹规划框架，通过层次化滚动去噪和WBFO算法实现高效采样，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在机器人轨迹规划中依赖专家数据的问题，特别是在数据稀缺的专用机器人上。

Method: 提出PegasusFlow框架和WBFO算法，利用样条基函数优化和并行模拟架构实现高效采样。

Result: 在复杂任务中实现100%成功率和18%的速度提升，验证了方法的有效性。

Conclusion: PegasusFlow为复杂地形运动规划提供了高效且无需专家数据的解决方案。

Abstract: Diffusion models offer powerful generative capabilities for robot trajectory
planning, yet their practical deployment on robots is hindered by a critical
bottleneck: a reliance on imitation learning from expert demonstrations. This
paradigm is often impractical for specialized robots where data is scarce and
creates an inefficient, theoretically suboptimal training pipeline. To overcome
this, we introduce PegasusFlow, a hierarchical rolling-denoising framework that
enables direct and parallel sampling of trajectory score gradients from
environmental interaction, completely bypassing the need for expert data. Our
core innovation is a novel sampling algorithm, Weighted Basis Function
Optimization (WBFO), which leverages spline basis representations to achieve
superior sample efficiency and faster convergence compared to traditional
methods like MPPI. The framework is embedded within a scalable, asynchronous
parallel simulation architecture that supports massively parallel rollouts for
efficient data collection. Extensive experiments on trajectory optimization and
robotic navigation tasks demonstrate that our approach, particularly
Action-Value WBFO (AVWBFO) combined with a reinforcement learning warm-start,
significantly outperforms baselines. In a challenging barrier-crossing task,
our method achieved a 100% success rate and was 18% faster than the next-best
method, validating its effectiveness for complex terrain locomotion planning.
https://masteryip.github.io/pegasusflow.github.io/

</details>


### [32] [Augmenting Neural Networks-based Model Approximators in Robotic Force-tracking Tasks](https://arxiv.org/abs/2509.08440)
*Kevin Saad,Vincenzo Petrone,Enrico Ferrentino,Pasquale Chiacchio,Francesco Braghin,Loris Roveda*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的交互控制策略VAICAM，通过预测接触力并优化动作，显著提升了力跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统交互控制器需要大量调参或环境专业知识，限制了实际应用，因此需要更智能的解决方案。

Method: 使用前馈神经网络预测接触力，并通过优化生成最优动作，结合直接力控制器和阻抗控制器。

Result: 在Gazebo模拟器中验证，VAICAM在多种轨迹下表现优于两种基线控制器。

Conclusion: VAICAM是一种高效且无需大量调参的交互控制方法，适用于实际机器人任务。

Abstract: As robotics gains popularity, interaction control becomes crucial for
ensuring force tracking in manipulator-based tasks. Typically, traditional
interaction controllers either require extensive tuning, or demand expert
knowledge of the environment, which is often impractical in real-world
applications. This work proposes a novel control strategy leveraging Neural
Networks (NNs) to enhance the force-tracking behavior of a Direct Force
Controller (DFC). Unlike similar previous approaches, it accounts for the
manipulator's tangential velocity, a critical factor in force exertion,
especially during fast motions. The method employs an ensemble of feedforward
NNs to predict contact forces, then exploits the prediction to solve an
optimization problem and generate an optimal residual action, which is added to
the DFC output and applied to an impedance controller. The proposed
Velocity-augmented Artificial intelligence Interaction Controller for Ambiguous
Models (VAICAM) is validated in the Gazebo simulator on a Franka Emika Panda
robot. Against a vast set of trajectories, VAICAM achieves superior performance
compared to two baseline controllers.

</details>


### [33] [Dual-Stage Safe Herding Framework for Adversarial Attacker in Dynamic Environment](https://arxiv.org/abs/2509.08460)
*Wenqing Wang,Ye Zhang,Haoyu Li,Jingyu Wang*

Main category: cs.RO

TL;DR: 论文提出了一种基于可达-避障博弈理论和局部运动规划的分层混合框架，用于动态环境中对抗性多智能体的安全引导。


<details>
  <summary>Details</summary>
Motivation: 传统固定的编队方法在复杂环境中效果不佳，尤其在对抗性智能体行为未知且自适应时。

Method: 采用层次化混合框架，结合虚拟边界和事件触发的追逐机制，实现多智能体协调。

Result: 仿真结果表明，该方法能安全高效地将对抗性智能体引导至指定区域。

Conclusion: 提出的框架在动态环境中对抗性智能体的引导上表现出色，兼具安全性和可扩展性。

Abstract: Recent advances in robotics have enabled the widespread deployment of
autonomous robotic systems in complex operational environments, presenting both
unprecedented opportunities and significant security problems. Traditional
shepherding approaches based on fixed formations are often ineffective or risky
in urban and obstacle-rich scenarios, especially when facing adversarial agents
with unknown and adaptive behaviors. This paper addresses this challenge as an
extended herding problem, where defensive robotic systems must safely guide
adversarial agents with unknown strategies away from protected areas and into
predetermined safe regions, while maintaining collision-free navigation in
dynamic environments. We propose a hierarchical hybrid framework based on
reach-avoid game theory and local motion planning, incorporating a virtual
containment boundary and event-triggered pursuit mechanisms to enable scalable
and robust multi-agent coordination. Simulation results demonstrate that the
proposed approach achieves safe and efficient guidance of adversarial agents to
designated regions.

</details>


### [34] [CLAP: Clustering to Localize Across n Possibilities, A Simple, Robust Geometric Approach in the Presence of Symmetries](https://arxiv.org/abs/2509.08495)
*Gabriel I. Fernandez,Ruochen Hou,Alex Xu,Colin Togashi,Dennis W. Hong*

Main category: cs.RO

TL;DR: CLAP是一种基于聚类的定位方法，适用于动态环境下的机器人定位，具有高鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 由于机器人传感器受限并需应对动态环境和噪声干扰，需要一种准确且鲁棒的定位算法。

Method: CLAP通过聚类从场对特征估计的机器人状态来确定全局位置和方向，并结合粒子滤波和扩展卡尔曼滤波提高一致性。

Result: CLAP在精度上与其他基于地标的方法相当，但在高误检率环境下表现出更强的鲁棒性。

Conclusion: CLAP在比赛中表现优异，支持了机器人的路径规划和比赛策略。

Abstract: In this paper, we present our localization method called CLAP, Clustering to
Localize Across $n$ Possibilities, which helped us win the RoboCup 2024
adult-sized autonomous humanoid soccer competition. Competition rules limited
our sensor suite to stereo vision and an inertial sensor, similar to humans. In
addition, our robot had to deal with varying lighting conditions, dynamic
feature occlusions, noise from high-impact stepping, and mistaken features from
bystanders and neighboring fields. Therefore, we needed an accurate, and most
importantly robust localization algorithm that would be the foundation for our
path-planning and game-strategy algorithms. CLAP achieves these requirements by
clustering estimated states of our robot from pairs of field features to
localize its global position and orientation. Correct state estimates naturally
cluster together, while incorrect estimates spread apart, making CLAP resilient
to noise and incorrect inputs. CLAP is paired with a particle filter and an
extended Kalman filter to improve consistency and smoothness. Tests of CLAP
with other landmark-based localization methods showed similar accuracy.
However, tests with increased false positive feature detection showed that CLAP
outperformed other methods in terms of robustness with very little divergence
and velocity jumps. Our localization performed well in competition, allowing
our robot to shoot faraway goals and narrowly defend our goal.

</details>


### [35] [Facilitating the Emergence of Assistive Robots to Support Frailty: Psychosocial and Environmental Realities](https://arxiv.org/abs/2509.08510)
*Angela Higgins,Stephen Potter,Mauro Dragone,Mark Hawley,Farshid Amirabdollahian,Alessandro Di Nuovo,Praminda Caleb-Solly*

Main category: cs.RO

TL;DR: 研究表明，辅助机器人虽有潜力帮助老年人，但实际应用少，原因是实验室开发与实际需求存在差距。通过研讨会收集用户需求，强调需考虑心理和社会因素。


<details>
  <summary>Details</summary>
Motivation: 探索辅助机器人为何在实际应用中较少，并通过用户参与的设计方法填补实验室开发与现实需求之间的差距。

Method: 通过7场共61名参与者（包括老年人、护理者和医疗专业人员）的共同设计研讨会，采用人物角色方法分析情感、社会和心理需求。

Result: 研究发现辅助机器人设计需综合心理社会和环境因素，并提出了直接与衰弱相关的设计要求。

Conclusion: 研究为辅助机器人设计提供了更实用的思路，推动其更接近实际应用。

Abstract: While assistive robots have much potential to help older people with
frailty-related needs, there are few in use. There is a gap between what is
developed in laboratories and what would be viable in real-world contexts.
Through a series of co-design workshops (61 participants across 7 sessions)
including those with lived experience of frailty, their carers, and healthcare
professionals, we gained a deeper understanding of everyday issues concerning
the place of new technologies in their lives. A persona-based approach surfaced
emotional, social, and psychological issues. Any assistive solution must be
developed in the context of this complex interplay of psychosocial and
environmental factors. Our findings, presented as design requirements in direct
relation to frailty, can help promote design thinking that addresses people's
needs in a more pragmatic way to move assistive robotics closer to real-world
use.

</details>


### [36] [FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast Marching Tree for Dynamic Replanning](https://arxiv.org/abs/2509.08521)
*Soheil Espahbodini Nia*

Main category: cs.RO

TL;DR: 本文提出了FMT^x算法，改进了FMT*路径规划算法，使其能够在动态环境中高效地进行路径重新规划，同时在计算效率和最优性上保持平衡。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的路径规划是机器人技术的核心挑战，传统算法如FMT*在静态环境中表现良好，但无法适应实时变化的环境需求。

Method: FMT^x通过修改FMT*的邻居选择规则，引入了成本有序优先队列和选择性更新条件，以在不牺牲最优性或效率的情况下支持路径更新。

Result: 实验证明，FMT^x在处理动态事件时比RRT^x更快速且计算开销更低，能够提供更有效的实时导航解决方案。

Conclusion: FMT^x填补了动态环境中路径规划的空白，结合了最优性和实时适应能力，为机器人导航提供了一种高效的方法。

Abstract: Path planning in dynamic environments remains a core challenge in robotics,
especially as autonomous systems are deployed in unpredictable spaces such as
warehouses and public roads. While algorithms like Fast Marching Tree
(FMT$^{*}$) offer asymptotically optimal solutions in static settings, their
single-pass design prevents path revisions which are essential for real-time
adaptation. On the other hand, full replanning is often too computationally
expensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching
Tree algorithm that enables efficient and consistent replanning in dynamic
environments. We revisit the neighbor selection rule of FMT$^{*}$ and
demonstrate that a minimal change overcomes its single-pass limitation,
enabling the algorithm to update cost-to-come values upon discovering better
connections without sacrificing asymptotic optimality or computational
efficiency. By maintaining a cost-ordered priority queue and applying a
selective update condition that uses an expanding neighbor to identify and
trigger the re-evaluation of any node with a potentially suboptimal path,
FMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the
environment evolves. This targeted strategy preserves the inherent efficiency
of FMT$^{*}$ while enabling robust adaptation to changes in obstacle
configuration. FMT$^{x}$ is proven to recover an asymptotically optimal
solution after environmental changes. Experimental results demonstrate that
FMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more
swiftly to dynamic events with lower computational overhead and thus offering a
more effective solution for real-time robotic navigation in unpredictable
worlds.

</details>


### [37] [RoboMatch: A Mobile-Manipulation Teleoperation Platform with Auto-Matching Network Architecture for Long-Horizon Manipulation](https://arxiv.org/abs/2509.08522)
*Hanyu Liu,Yunsheng Ma,Jiaxin Huang,Keqiang Ren,Jiayi Wen,Yilin Zheng,Baishu Wan,Pan Li,Jiejun Hou,Haoru Luan,Zhihua Wang,Zhigong Song*

Main category: cs.RO

TL;DR: RoboMatch是一个新颖的统一遥操作平台，通过自动匹配网络架构和增强的扩散策略，显著提升了动态环境中长时程任务的性能和数据收集效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决动态环境中长时程任务的挑战，设计一种能够同时操作移动底座和双臂的遥操作平台。

Method: 采用驾驶舱式控制接口实现同步操作，结合基于DWT的多尺度视觉特征提取和高精度IMU的PVE-DP策略，以及动态分配预训练模型的AMN架构。

Result: 实验结果显示，数据收集效率提升20%以上，任务成功率提高20-30%，长时程推理性能提升约40%。

Conclusion: RoboMatch为复杂操纵任务提供了高效的解决方案，显著提升了性能和稳定性。

Abstract: This paper presents RoboMatch, a novel unified teleoperation platform for
mobile manipulation with an auto-matching network architecture, designed to
tackle long-horizon tasks in dynamic environments. Our system enhances
teleoperation performance, data collection efficiency, task accuracy, and
operational stability. The core of RoboMatch is a cockpit-style control
interface that enables synchronous operation of the mobile base and dual arms,
significantly improving control precision and data collection. Moreover, we
introduce the Proprioceptive-Visual Enhanced Diffusion Policy (PVE-DP), which
leverages Discrete Wavelet Transform (DWT) for multi-scale visual feature
extraction and integrates high-precision IMUs at the end-effector to enrich
proprioceptive feedback, substantially boosting fine manipulation performance.
Furthermore, we propose an Auto-Matching Network (AMN) architecture that
decomposes long-horizon tasks into logical sequences and dynamically assigns
lightweight pre-trained models for distributed inference. Experimental results
demonstrate that our approach improves data collection efficiency by over 20%,
increases task success rates by 20-30% with PVE-DP, and enhances long-horizon
inference performance by approximately 40% with AMN, offering a robust solution
for complex manipulation tasks.

</details>


### [38] [AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models](https://arxiv.org/abs/2509.08638)
*Rebecca Martin,Jay Patrikar,Sebastian Scherer*

Main category: cs.RO

TL;DR: 论文提出了一个基于LLM-Agent的框架，用于自动生成语义相关的测试用例，以搜索黑盒模型的故障模式。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习模型在高风险场景中的应用日益增多，确定其操作设计域（ODD）对于确保安全性和合规性至关重要。但由于输入空间维度高，这一过程通常需要大量人力和领域知识。

Method: 作者提出了一个名为\coolname的框架，通过LLM-Agent作为工具协调器，将高维输入空间投影到低维文本嵌入潜空间，并迭代构建故障分布模型。

Result: 通过MNIST数据集中的缺失数字模型和无人机视觉入侵检测的实际场景，验证了该方法的有效性。

Conclusion: 该框架能够自动化生成测试用例，帮助发现黑盒模型的潜在故障模式，从而提升模型的安全性和可靠性。

Abstract: Specialized machine learning models, regardless of architecture and training,
are susceptible to failures in deployment. With their increasing use in high
risk situations, the ability to audit these models by determining their
operational design domain (ODD) is crucial in ensuring safety and compliance.
However, given the high-dimensional input spaces, this process often requires
significant human resources and domain expertise. To alleviate this, we
introduce \coolname, an LLM-Agent centric framework for automated generation of
semantically relevant test cases to search for failure modes in specialized
black-box models. By leveraging LLM-Agents as tool orchestrators, we aim to fit
a uncertainty-aware failure distribution model on a learned text-embedding
manifold by projecting the high-dimension input space to low-dimension
text-embedding latent space. The LLM-Agent is tasked with iteratively building
the failure landscape by leveraging tools for generating test-cases to probe
the model-under-test (MUT) and recording the response. The agent also guides
the search using tools to probe uncertainty estimate on the low dimensional
manifold. We demonstrate this process in a simple case using models trained
with missing digits on the MNIST dataset and in the real world setting of
vision-based intruder detection for aerial vehicles.

</details>


### [39] [TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals](https://arxiv.org/abs/2509.08699)
*Stefan Podgorski,Sourav Garg,Mehdi Hosseinzadeh,Lachlan Mares,Feras Dayoub,Ian Reid*

Main category: cs.RO

TL;DR: 提出了一种无需全局3D地图或预训练控制器的RGB视觉导航方法，结合全局拓扑路径规划和局部轨迹控制，实现零样本长距离导航。


<details>
  <summary>Details</summary>
Motivation: 传统视觉导航依赖全局3D地图或学习控制器，计算成本高且泛化能力差，需要一种更高效且通用的解决方案。

Method: 采用对象级拓扑导航管道，结合单目深度和可通行性估计预测局部轨迹，并引入自动切换机制至基线控制器。

Result: 在仿真和现实环境中表现优异，优于现有方法，适应性强且开源。

Conclusion: 该方案为开放环境中的视觉导航提供了更灵活高效的解决方案。

Abstract: Visual navigation in robotics traditionally relies on globally-consistent 3D
maps or learned controllers, which can be computationally expensive and
difficult to generalize across diverse environments. In this work, we present a
novel RGB-only, object-level topometric navigation pipeline that enables
zero-shot, long-horizon robot navigation without requiring 3D maps or
pre-trained controllers. Our approach integrates global topological path
planning with local metric trajectory control, allowing the robot to navigate
towards object-level sub-goals while avoiding obstacles. We address key
limitations of previous methods by continuously predicting local trajectory
using monocular depth and traversability estimation, and incorporating an
auto-switching mechanism that falls back to a baseline controller when
necessary. The system operates using foundational models, ensuring open-set
applicability without the need for domain-specific fine-tuning. We demonstrate
the effectiveness of our method in both simulated environments and real-world
tests, highlighting its robustness and deployability. Our approach outperforms
existing state-of-the-art methods, offering a more adaptable and effective
solution for visual navigation in open-set environments. The source code is
made publicly available: https://github.com/podgorki/TANGO.

</details>


### [40] [Parallel, Asymptotically Optimal Algorithms for Moving Target Traveling Salesman Problems](https://arxiv.org/abs/2509.08743)
*Anoop Bhat,Geordan Gutow,Bhaskar Vundurthy,Zhongqiang Ren,Sivakumar Rathinam,Howie Choset*

Main category: cs.RO

TL;DR: 论文提出了IRG框架来解决移动目标旅行商问题（MT-TSP），通过交替随机采样和求解广义TSP实现渐进最优。两种并行算法IRG-PGLNS和PCG显著提升了收敛速度。


<details>
  <summary>Details</summary>
Motivation: 移动目标旅行商问题在非线性目标轨迹或代理运动约束下缺乏收敛保证，因此需要一种新方法。

Method: IRG框架结合随机采样和广义TSP求解，并引入了IRG-PGLNS和PCG两种并行算法。

Result: 实验显示IRG-PGLNS和PCG在MT-TSP的三个变体中比基线方法收敛更快。

Conclusion: IRG框架解决了MT-TSP的收敛性问题，并行算法显著提升了效率。

Abstract: The Moving Target Traveling Salesman Problem (MT-TSP) seeks an agent
trajectory that intercepts several moving targets, within a particular time
window for each target. In the presence of generic nonlinear target
trajectories or kinematic constraints on the agent, no prior algorithm
guarantees convergence to an optimal MT-TSP solution. Therefore, we introduce
the Iterated Random Generalized (IRG) TSP framework. The key idea behind IRG is
to alternate between randomly sampling a set of agent configuration-time
points, corresponding to interceptions of targets, and finding a sequence of
interception points by solving a generalized TSP (GTSP). This alternation
enables asymptotic convergence to the optimum. We introduce two parallel
algorithms within the IRG framework. The first algorithm, IRG-PGLNS, solves
GTSPs using PGLNS, our parallelized extension of the state-of-the-art solver
GLNS. The second algorithm, Parallel Communicating GTSPs (PCG), solves GTSPs
corresponding to several sets of points simultaneously. We present numerical
results for three variants of the MT-TSP: one where intercepting a target only
requires coming within a particular distance, another where the agent is a
variable-speed Dubins car, and a third where the agent is a redundant robot
arm. We show that IRG-PGLNS and PCG both converge faster than a baseline based
on prior work.

</details>


### [41] [SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation](https://arxiv.org/abs/2509.08757)
*Michael J. Munje,Chen Tang,Shuijing Liu,Zichao Hu,Yifeng Zhu,Jiaxun Cui,Garrett Warnell,Joydeep Biswas,Peter Stone*

Main category: cs.RO

TL;DR: 该论文介绍了SocialNav-SUB，一个用于评估视觉语言模型（VLMs）在社交机器人导航场景中理解能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs是否能理解复杂社交导航场景（如推断代理之间的时空关系和人类意图），以支持安全且符合社交规范的机器人导航。

Method: 创建SocialNav-SUB数据集，通过视觉问答（VQA）任务评估VLMs在空间、时空和社交推理方面的表现。

Result: 实验表明，虽然表现最佳的VLM与人类答案的一致性较高，但仍不及基于规则的方法和人类共识基准。

Conclusion: SocialNav-SUB为未来社交机器人导航基础模型的研究提供了框架，揭示了当前VLMs在社交场景理解中的关键不足。

Abstract: Robot navigation in dynamic, human-centered environments requires
socially-compliant decisions grounded in robust scene understanding. Recent
Vision-Language Models (VLMs) exhibit promising capabilities such as object
recognition, common-sense reasoning, and contextual understanding-capabilities
that align with the nuanced requirements of social robot navigation. However,
it remains unclear whether VLMs can accurately understand complex social
navigation scenes (e.g., inferring the spatial-temporal relations among agents
and human intentions), which is essential for safe and socially compliant robot
navigation. While some recent works have explored the use of VLMs in social
robot navigation, no existing work systematically evaluates their ability to
meet these necessary conditions. In this paper, we introduce the Social
Navigation Scene Understanding Benchmark (SocialNav-SUB), a Visual Question
Answering (VQA) dataset and benchmark designed to evaluate VLMs for scene
understanding in real-world social robot navigation scenarios. SocialNav-SUB
provides a unified framework for evaluating VLMs against human and rule-based
baselines across VQA tasks requiring spatial, spatiotemporal, and social
reasoning in social robot navigation. Through experiments with state-of-the-art
VLMs, we find that while the best-performing VLM achieves an encouraging
probability of agreeing with human answers, it still underperforms simpler
rule-based approach and human consensus baselines, indicating critical gaps in
social scene understanding of current VLMs. Our benchmark sets the stage for
further research on foundation models for social robot navigation, offering a
framework to explore how VLMs can be tailored to meet real-world social robot
navigation needs. An overview of this paper along with the code and data can be
found at https://larg.github.io/socialnav-sub .

</details>


### [42] [Joint Model-based Model-free Diffusion for Planning with Constraints](https://arxiv.org/abs/2509.08775)
*Wonsuhk Jung,Utkarsh A. Mishra,Nadun Ranawaka Arachchige,Yongxin Chen,Danfei Xu,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出了一种名为JM2D的新框架，结合了模型自由和模型基础的扩散规划方法，通过联合采样优化模块兼容性，提升了任务性能且不牺牲安全性。


<details>
  <summary>Details</summary>
Motivation: 实际机器人系统中，模型自由扩散规划与模型基础优化模块的结合常因兼容性问题导致性能下降。

Method: JM2D框架通过联合采样和重要性采样最大化模块兼容性，无需额外训练。

Result: 在离线强化学习和机器人操控任务中，JM2D显著提升性能同时保持安全性。

Conclusion: JM2D为模块整合提供了新思路，并展示了其优于现有梯度基础和投影基础方法的潜力。

Abstract: Model-free diffusion planners have shown great promise for robot motion
planning, but practical robotic systems often require combining them with
model-based optimization modules to enforce constraints, such as safety.
Naively integrating these modules presents compatibility challenges when
diffusion's multi-modal outputs behave adversarially to optimization-based
modules. To address this, we introduce Joint Model-based Model-free Diffusion
(JM2D), a novel generative modeling framework. JM2D formulates module
integration as a joint sampling problem to maximize compatibility via an
interaction potential, without additional training. Using importance sampling,
JM2D guides modules outputs based only on evaluations of the interaction
potential, thus handling non-differentiable objectives commonly arising from
non-convex optimization modules. We evaluate JM2D via application to aligning
diffusion planners with safety modules on offline RL and robot manipulation.
JM2D significantly improves task performance compared to conventional safety
filters without sacrificing safety. Further, we show that conditional
generation is a special case of JM2D and elucidate key design choices by
comparing with SOTA gradient-based and projection-based diffusion planners.
More details at: https://jm2d-corl25.github.io/.

</details>


### [43] [Calib3R: A 3D Foundation Model for Multi-Camera to Robot Calibration and 3D Metric-Scaled Scene Reconstruction](https://arxiv.org/abs/2509.08813)
*Davide Allegro,Matteo Terreran,Stefano Ghidoni*

Main category: cs.RO

TL;DR: Calib3R是一种无需模式的方法，通过统一优化同时完成相机到机器人的校准和度量尺度的3D重建，适用于单和多相机设置，优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 机器人任务通常需要3D场景表示，传统方法需分开处理校准和重建，依赖模式且复杂。

Method: 利用3D基础模型MASt3R从RGB图像提取点图，结合机器人姿态重建对齐的3D场景。

Result: 实验显示，Calib3R仅需少于10张图像即可实现精准校准，优于无目标和标记方法。

Conclusion: Calib3R为解决机器人3D校准和重建问题提供了高效的一体化解决方案。

Abstract: Robots often rely on RGB images for tasks like manipulation and navigation.
However, reliable interaction typically requires a 3D scene representation that
is metric-scaled and aligned with the robot reference frame. This depends on
accurate camera-to-robot calibration and dense 3D reconstruction, tasks usually
treated separately, despite both relying on geometric correspondences from RGB
data. Traditional calibration needs patterns, while RGB-based reconstruction
yields geometry with an unknown scale in an arbitrary frame. Multi-camera
setups add further complexity, as data must be expressed in a shared reference
frame. We present Calib3R, a patternless method that jointly performs
camera-to-robot calibration and metric-scaled 3D reconstruction via unified
optimization. Calib3R handles single- and multi-camera setups on robot arms or
mobile robots. It builds on the 3D foundation model MASt3R to extract pointmaps
from RGB images, which are combined with robot poses to reconstruct a scaled 3D
scene aligned with the robot. Experiments on diverse datasets show that Calib3R
achieves accurate calibration with less than 10 images, outperforming
target-less and marker-based methods.

</details>


### [44] [RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation](https://arxiv.org/abs/2509.08820)
*Zongzheng Zhang,Chenghao Yue,Haobo Xu,Minwen Liao,Xianglin Qi,Huan-ang Gao,Ziwei Wang,Hao Zhao*

Main category: cs.RO

TL;DR: 该论文提出了一种名为RoboChemist的双环框架，结合视觉语言模型（VLM）和视觉语言动作模型（VLA），用于解决化学实验中复杂任务的规划、执行和监控问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM或VLA的系统在透明实验器皿或缺乏语义反馈等问题上表现不佳，无法满足化学实验中的复杂需求。

Method: 通过VLM作为任务分解器、视觉提示生成器和监控器，结合VLA模型实现精确的目标控制。

Result: 实验表明，系统在多步化学协议任务中平均成功率提高23.57%，合规率提升0.298，且具有强泛化能力。

Conclusion: RoboChemist框架能有效提升机器人化学家的任务执行能力和合规性，具有广泛应用潜力。

Abstract: Robotic chemists promise to both liberate human experts from repetitive tasks
and accelerate scientific discovery, yet remain in their infancy. Chemical
experiments involve long-horizon procedures over hazardous and deformable
substances, where success requires not only task completion but also strict
compliance with experimental norms. To address these challenges, we propose
\textit{RoboChemist}, a dual-loop framework that integrates Vision-Language
Models (VLMs) with Vision-Language-Action (VLA) models. Unlike prior VLM-based
systems (e.g., VoxPoser, ReKep) that rely on depth perception and struggle with
transparent labware, and existing VLA systems (e.g., RDT, pi0) that lack
semantic-level feedback for complex tasks, our method leverages a VLM to serve
as (1) a planner to decompose tasks into primitive actions, (2) a visual prompt
generator to guide VLA models, and (3) a monitor to assess task success and
regulatory compliance. Notably, we introduce a VLA interface that accepts
image-based visual targets from the VLM, enabling precise, goal-conditioned
control. Our system successfully executes both primitive actions and complete
multi-step chemistry protocols. Results show 23.57% higher average success rate
and a 0.298 average increase in compliance rate over state-of-the-art VLA
baselines, while also demonstrating strong generalization to objects and tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [45] [Learning-Based Planning for Improving Science Return of Earth Observation Satellites](https://arxiv.org/abs/2509.07997)
*Abigail Breitfeld,Alberto Candela,Juan Delfa,Akseli Kangaslahti,Itai Zilberstein,Steve Chien,David Wettergreen*

Main category: cs.AI

TL;DR: 动态目标定位通过强化学习和模仿学习优化卫星数据收集，相比传统方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星受限于轨道和传感器，需优化数据收集，动态目标定位能提升科学信息获取效率。

Method: 采用强化学习和模仿学习方法，结合动态规划生成采样序列，并与启发式方法对比。

Result: 模仿学习平均优于最佳启发式方法10.0%，强化学习优13.7%，且数据需求量小。

Conclusion: 学习方法显著提升动态目标定位效率，适用于卫星数据优化。

Abstract: Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [46] [3D and 4D World Modeling: A Survey](https://arxiv.org/abs/2509.07996)
*Lingdong Kong,Wesley Yang,Jianbiao Mei,Youquan Liu,Ao Liang,Dekai Zhu,Dongyue Lu,Wei Yin,Xiaotao Hu,Mingkai Jia,Junyuan Deng,Kaiwen Zhang,Yang Wu,Tianyi Yan,Shenyuan Gao,Song Wang,Linfeng Li,Liang Pan,Yong Liu,Jianke Zhu,Wei Tsang Ooi,Steven C. H. Hoi,Ziwei Liu*

Main category: cs.CV

TL;DR: 这篇综述填补了3D和4D世界建模领域的空白，提供了明确的定义和分类，并总结了相关数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于2D图像和视频数据的生成方法，缺乏对3D和4D表示的统一讨论，且世界模型的定义和分类不清晰，导致研究分散且不一致。

Method: 通过提出明确的定义和分类（VideoGen、OccGen、LiDARGen），系统总结了适用于3D/4D场景的数据集和评估指标。

Result: 首次全面回顾了3D和4D世界建模与生成研究，为领域提供了清晰的结构和参考。

Conclusion: 该综述为3D/4D世界建模领域奠定了统一的基础，并指出了未来研究方向和应用潜力。

Abstract: World modeling has become a cornerstone in AI research, enabling agents to
understand, represent, and predict the dynamic environments they inhabit. While
prior work largely emphasizes generative methods for 2D image and video data,
they overlook the rapidly growing body of work that leverages native 3D and 4D
representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds
for large-scale scene modeling. At the same time, the absence of a standardized
definition and taxonomy for ``world models'' has led to fragmented and
sometimes inconsistent claims in the literature. This survey addresses these
gaps by presenting the first comprehensive review explicitly dedicated to 3D
and 4D world modeling and generation. We establish precise definitions,
introduce a structured taxonomy spanning video-based (VideoGen),
occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and
systematically summarize datasets and evaluation metrics tailored to 3D/4D
settings. We further discuss practical applications, identify open challenges,
and highlight promising research directions, aiming to provide a coherent and
foundational reference for advancing the field. A systematic summary of
existing literature is available at https://github.com/worldbench/survey

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [47] [RAPID Quantum Detection and Demodulation of Covert Communications: Breaking the Noise Limit with Solid-State Spin Sensors](https://arxiv.org/abs/2509.08171)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: quant-ph

TL;DR: 论文提出了一种基于固态自旋传感器的隐蔽电磁信号检测与解调框架RAPID，通过两阶段混合策略结合量子费希尔信息矩阵和深度强化学习，实现了高灵敏度和抗噪性能。


<details>
  <summary>Details</summary>
Motivation: 解决电子战和隐蔽监视等安全关键应用中量子传感器的实际部署问题，突破经典噪声限制。

Method: 提出RAPID框架，先基于量子费希尔信息矩阵计算非自适应基线协议，再通过深度强化学习（Soft Actor-Critic）在线学习自适应策略，动态优化控制参数。

Result: 数值模拟显示RAPID在灵敏度、抗噪性能和阵列协同（量子波束成形）方面优于静态方法，达到海森堡级精度。

Conclusion: RAPID为量子传感器在安全领域的应用提供了理论与实用的可行路径。

Abstract: We introduce a comprehensive framework for the detection and demodulation of
covert electromagnetic signals using solid-state spin sensors. Our approach,
named RAPID, is a two-stage hybrid strategy that leverages nitrogen-vacancy
(NV) centers to operate below the classical noise floor employing a robust
adaptive policy via imitation and distillation. We first formulate the joint
detection and estimation task as a unified stochastic optimal control problem,
optimizing a composite Bayesian risk objective under realistic physical
constraints. The RAPID algorithm solves this by first computing a robust,
non-adaptive baseline protocol grounded in the quantum Fisher information
matrix (QFIM), and then using this baseline to warm-start an online, adaptive
policy learned via deep reinforcement learning (Soft Actor-Critic). This method
dynamically optimizes control pulses, interrogation times, and measurement
bases to maximize information gain while actively suppressing non-Markovian
noise and decoherence. Numerical simulations demonstrate that the protocol
achieves a significant sensitivity gain over static methods, maintains high
estimation precision in correlated noise environments, and, when applied to
sensor arrays, enables coherent quantum beamforming that achieves
Heisenberg-like scaling in precision. This work establishes a theoretically
rigorous and practically viable pathway for deploying quantum sensors in
security-critical applications such as electronic warfare and covert
surveillance.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [48] [Analysis and Control of Acoustic Emissions from Marine Energy Converters](https://arxiv.org/abs/2509.08656)
*Jiaqin He,Max Malyi,Jonathan Shek*

Main category: eess.SY

TL;DR: 研究通过优化控制策略减少潮汐能转换器的水下噪声，以提升发电效率并降低对海洋生物的生态影响，最终提出了兼顾能效与环保的操作策略。


<details>
  <summary>Details</summary>
Motivation: 潮汐能转换器在发电过程中会产生水下噪声，可能对海洋生物（如哺乳类和鱼类）的听觉系统造成损害。研究旨在通过优化控制策略减少噪声，同时不降低发电效率。

Method: 开发了基于MATLAB/Simulink的潮汐能转换系统模型，分析了开关频率、MPPT系数和去除变速箱等参数对水下噪声的影响，量化了声压级并评估了对海洋生物的潜在危害。

Result: 调整控制参数可显著降低噪声，去除变速箱效果最佳。研究还确定了可能对海洋生物造成听觉损伤的运行条件，并提出了兼顾发电效率的噪声控制策略。

Conclusion: 控制系统的优化能够在提升潮汐能转换器效率的同时减少生态影响，为环保兼容的设备设计提供了指导。

Abstract: This study investigates the mitigation of acoustic emissions from tidal
current converters (TCCs) through optimized control strategies to enhance power
generation efficiency while minimizing environmental impacts on marine life. A
MATLAB/Simulink-based model of a Tidal Current Conversion System (TCCS) was
developed to simulate the effects of variable control parameters, including
switching frequencies, maximum power point tracking (MPPT) coefficients, and
the elimination of the gearbox, on underwater noise levels. Acoustic emissions
were quantified in terms of sound pressure levels (SPLs), and their potential
impacts on marine mammals and fish were evaluated against species-specific
auditory thresholds for temporary and permanent hearing threshold shifts. The
results indicate that adjusting control parameters can significantly reduce
SPLs, with the removal of the gearbox yielding the greatest noise reduction.
The study identifies operational conditions under which marine species are at
risk of auditory damage and proposes control strategies to mitigate these risks
without compromising energy output. These findings contribute to the
understanding of how control system modifications can balance the efficiency of
marine energy systems with ecological considerations, offering guidance for the
design and operation of environmentally compliant TCCs.

</details>


### [49] [Universal Graph Learning for Power System Reconfigurations: Transfer Across Topology Variations](https://arxiv.org/abs/2509.08672)
*Tong Wu,Anna Scaglione,Sandy Miguel,Daniel Arnold*

Main category: eess.SY

TL;DR: 提出了一种通用图卷积网络（UGCN），解决了深度学习在电力系统中无法跨系统拓扑变化迁移的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的方法多为系统专用，难以适应电力系统拓扑和维度的变化，限制了实际应用。

Method: 设计了UGCN，无需新网格拓扑的先验知识或重新训练，即可适应任何系统重新配置。

Result: 实验表明UGCN在跨系统零样本迁移能力上显著优于现有方法。

Conclusion: UGCN为解决电力系统中深度学习迁移问题提供了有效的通用解决方案。

Abstract: This work addresses a fundamental challenge in applying deep learning to
power systems: developing neural network models that transfer across
significant system changes, including networks with entirely different
topologies and dimensionalities, without requiring training data from unseen
reconfigurations. Despite extensive research, most ML-based approaches remain
system-specific, limiting real-world deployment. This limitation stems from a
dual barrier. First, topology changes shift feature distributions and alter
input dimensions due to power flow physics. Second, reconfigurations redefine
output semantics and dimensionality, requiring models to handle
configuration-specific outputs while maintaining transferable feature
extraction. To overcome this challenge, we introduce a Universal Graph
Convolutional Network (UGCN) that achieves transferability to any
reconfiguration or variation of existing power systems without any prior
knowledge of new grid topologies or retraining during implementation. Our
approach applies to both transmission and distribution networks and
demonstrates generalization capability to completely unseen system
reconfigurations, such as network restructuring and major grid expansions.
Experimental results across power system applications, including false data
injection detection and state forecasting, show that UGCN significantly
outperforms state-of-the-art methods in cross-system zero-shot transferability
of new reconfigurations.

</details>


### [50] [Planar Juggling of a Devil-Stick using Discrete VHCs](https://arxiv.org/abs/2509.08085)
*Aakash Khandelwal,Ranjan Mukherjee*

Main category: eess.SY

TL;DR: 论文研究使用离散虚拟全息约束（DVHC）和冲动输入实现平面魔鬼棍杂技，通过离散零动力学（DZD）提供稳定杂技的条件，并通过仿真验证了控制设计的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是通过离散虚拟全息约束和冲动输入方法，解决魔鬼棍杂技的控制问题，实现稳定的平面杂技表演。

Method: 方法是通过指定魔鬼棍的质心位置与其在控制冲动时刻的取向关系，建立离散零动力学，设计控制方案以确保DVHC和轨道稳定。

Result: 结果表明，提出的控制设计能够有效实现稳定的魔鬼棍杂技，并通过仿真验证了其可行性。

Conclusion: 结论是通过DVHC和DZD的结合，能够成功解决平面魔鬼棍杂技的控制问题，为类似系统的控制提供了新思路。

Abstract: Planar juggling of a devil-stick using impulsive inputs is addressed using
the concept of discrete virtual holonomic constraints (DVHC). The location of
the center-of-mass of the devil-stick is specified in terms of its orientation
at the discrete instants when impulsive control inputs are applied. The
discrete zero dynamics (DZD) resulting from the choice of DVHC provides
conditions for stable juggling. A control design that enforces the DVHC and an
orbit stabilizing controller are presented. The approach is validated in
simulation.

</details>
