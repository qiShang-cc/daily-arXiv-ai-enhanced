<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 25]
- [cs.RO](#cs.RO) [Total: 108]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [eess.AS](#eess.AS) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.CV](#cs.CV) [Total: 12]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.IT](#cs.IT) [Total: 4]
- [cs.GR](#cs.GR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.DS](#cs.DS) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Generative Modeling and Decision Fusion for Unknown Event Detection and Classification Using Synchrophasor Data](https://arxiv.org/abs/2509.22795)
*Yi Hu,Zheyuan Cheng*

Main category: eess.SP

TL;DR: 该论文提出了一种结合生成建模、滑动窗口处理和决策融合的新框架，用于电力系统中鲁棒的事件检测与分类，能够在识别已知事件的同时分类未知扰动。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于有限的标注数据，难以推广到罕见或未见过的扰动，因此需要一种更鲁棒的检测与分类方法。

Method: 采用变分自编码器-生成对抗网络建模正常操作条件，提取重构误差和判别误差作为异常指标，并结合阈值规则和凸包方法进行决策。

Result: 实验结果显示该方法在准确率上优于现有基准，并能识别未知事件，展示了其适应性和实用价值。

Conclusion: 该框架有效解决了监督分类器的局限性，适用于现代电力系统的广域事件分析。

Abstract: Reliable detection and classification of power system events are critical for
maintaining grid stability and situational awareness. Existing approaches often
depend on limited labeled datasets, which restricts their ability to generalize
to rare or unseen disturbances. This paper proposes a novel framework that
integrates generative modeling, sliding-window temporal processing, and
decision fusion to achieve robust event detection and classification using
synchrophasor data. A variational autoencoder-generative adversarial network is
employed to model normal operating conditions, where both reconstruction error
and discriminator error are extracted as anomaly indicators. Two complementary
decision strategies are developed: a threshold-based rule for computational
efficiency and a convex hull-based method for robustness under complex error
distributions. These features are organized into spatiotemporal detection and
classification matrices through a sliding-window mechanism, and an
identification and decision fusion stage integrates the outputs across PMUs.
This design enables the framework to identify known events while systematically
classifying previously unseen disturbances into a new category, addressing a
key limitation of supervised classifiers. Experimental results demonstrate
state-of-the-art accuracy, surpassing machine learning, deep learning, and
envelope-based baselines. The ability to recognize unknown events further
highlights the adaptability and practical value of the proposed approach for
wide-area event analysis in modern power systems.

</details>


### [2] [Introducing Multimodal Paradigm for Learning Sleep Staging PSG via General-Purpose Model](https://arxiv.org/abs/2509.22810)
*Jianheng Zhou,Chenyu Liu,Jinan Zhou,Yi Ding,Yang Liu,Haoran Luo,Ziyu Jia,Xinliang Zhou*

Main category: eess.SP

TL;DR: 提出了一种基于多模态通用模型的新睡眠分期方法，通过将PSG信号转换为二维波形图像，显著提升了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统睡眠分期方法依赖复杂PSG信号和领域专用模型，缺乏直观性且需要大量数据。新方法旨在通过通用模型模拟临床诊断流程，克服这些限制。

Method: 将一维PSG时间序列转换为直观的二维波形图像，并微调多模态大型模型进行学习。

Result: 在三个公开数据集上，该方法展示了优异的准确性和鲁棒性，且未预先接触睡眠数据。模型能模仿专家的视觉诊断流程。

Conclusion: 该方法优于现有基线，具有高效性和实用价值，将为医学应用提供便利。

Abstract: Sleep staging is essential for diagnosing sleep disorders and assessing
neurological health. Existing automatic methods typically extract features from
complex polysomnography (PSG) signals and train domain-specific models, which
often lack intuitiveness and require large, specialized datasets. To overcome
these limitations, we introduce a new paradigm for sleep staging that leverages
large multimodal general-purpose models to emulate clinical diagnostic
practices. Specifically, we convert raw one-dimensional PSG time-series into
intuitive two-dimensional waveform images and then fine-tune a multimodal large
model to learn from these representations. Experiments on three public datasets
(ISRUC, MASS, SHHS) demonstrate that our approach enables general-purpose
models, without prior exposure to sleep data, to acquire robust staging
capabilities. Moreover, explanation analysis reveals our model learned to mimic
the visual diagnostic workflow of human experts for sleep staging by PSG
images. The proposed method consistently outperforms state-of-the-art baselines
in accuracy and robustness, highlighting its efficiency and practical value for
medical applications. The code for the signal-to-image pipeline and the PSG
image dataset will be released.

</details>


### [3] [Scalable Wi-Fi RSS-Based Indoor Localization via Automatic Vision-Assisted Calibration](https://arxiv.org/abs/2509.22869)
*Abdulkadir Bilge,Erdem Ergen,Burak Soner,Sinem Coleri*

Main category: eess.SP

TL;DR: 这篇论文介绍了一种轻量级框架，通过短时间摄像头辅助校准自动收集高分辨率同步RSS-位置数据，解决了室内Wi-Fi定位中数据标注成本高的问题。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi基于RSS的定位方法广泛可用，但RSS对多径、信道变化和接收器特性敏感。有监督学习方法需要大量标注数据，成本高昂。本文旨在解决这些问题。

Method: 提出一个框架，利用摄像头辅助校准阶段自动收集RSS-位置数据。通过ArUco标记校准摄像头并跟踪设备，生成数据集用于训练定位算法。

Result: 实验展示了该框架在不同信号条件和设备类型下的优势，验证了其准确性和泛化能力。所有代码和数据开源。

Conclusion: 该框架为室内Wi-Fi定位提供了一种高效、隐私友好的解决方案，并展示了实际应用的潜力。

Abstract: Wi-Fi-based positioning promises a scalable and privacy-preserving solution
for location-based services in indoor environments such as malls, airports, and
campuses. RSS-based methods are widely deployable as RSS data is available on
all Wi-Fi-capable devices, but RSS is highly sensitive to multipath, channel
variations, and receiver characteristics. While supervised learning methods
offer improved robustness, they require large amounts of labeled data, which is
often costly to obtain. We introduce a lightweight framework that solves this
by automating high-resolution synchronized RSS-location data collection using a
short, camera-assisted calibration phase. An overhead camera is calibrated only
once with ArUco markers and then tracks a device collecting RSS data from
broadcast packets of nearby access points across Wi-Fi channels. The resulting
(x, y, RSS) dataset is used to automatically train mobile-deployable
localization algorithms, avoiding the privacy concerns of continuous video
monitoring. We quantify the accuracy limits of such vision-assisted RSS data
collection under key factors such as tracking precision and label
synchronization. Using the collected experimental data, we benchmark
traditional and supervised learning approaches under varying signal conditions
and device types, demonstrating improved accuracy and generalization,
validating the utility of the proposed framework for practical use. All code,
tools, and datasets are released as open source.

</details>


### [4] [Time-Frequency Analysis of Non-Uniformly Sampled Signals via Sample Density Adaptation](https://arxiv.org/abs/2509.22891)
*Ashwini Kulkarni,Santosh Nannuru*

Main category: eess.SP

TL;DR: 提出了一种适用于非均匀采样数据的时频分析方法NUST，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决非均匀采样数据中非平稳信号分析的挑战，尤其是瞬态事件的检测。

Method: 引入非均匀Stockwell变换(NUST)，采用双重自适应窗口，直接分析非均匀数据。

Result: 在合成信号和HD 10180行星系统数据中，NUST表现出优于GLS的性能。

Conclusion: NUST为非均匀数据提供了更好的时频分析工具，能区分行星信号与恒星活动。

Abstract: The analysis of non-stationary signals in non-uniformly sampled data is a
challenging task. Time-integrated methods, such as the generalised Lomb-Scargle
(GLS) periodogram, provide a robust statistical assessment of persistent
periodicities but are insensitive to transient events. Conversely, existing
time-frequency methods often rely on fixed-duration windows or interpolation,
which can be suboptimal for non-uniform data. We introduce the non-uniform
Stockwell-transform (NUST), a time-frequency framework that applies a localized
density adaptive spectral analysis directly to non-uniformly sampled data. NUST
employs a doubly adaptive window that adjusts its width based on both frequency
and local data density, providing detailed time-frequency information for both
transient and persistent signals. We validate the NUST on numerous
non-uniformly sampled synthetic signals, demonstrating its superior
time-localization performance compared to GLS. Furthermore, we apply NUST to
HARPS radial velocity data of the multi-planetary system HD 10180, successfully
distinguishing coherent planetary signals from stellar activity.

</details>


### [5] [Resource Allocation in Cooperative Mid-band/THz Networks in the Presence of Mobility](https://arxiv.org/abs/2509.23065)
*Mohammad Amin Saeidi,Hina Tabassum*

Main category: eess.SP

TL;DR: 本文提出了一个全面的框架来优化协作多频段网络（MBN）的下行性能，涵盖联合用户关联、混合波束成形和切换感知资源分配，并通过数值结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究协作多频段网络在UMB和THz频段中的性能优化，尤其是用户移动性和近场信道模型对系统性能的影响。

Method: 利用分数规划和主优化技术提出迭代算法解决非凸优化问题，并针对移动用户设计切换感知资源分配方法。

Result: 提出的算法显著提升了系统总速率，并减少了切换次数，协作UMB/THz网络优于独立THz网络。

Conclusion: 该框架和算法在实际系统中表现优异，尤其强调了近场建模和切换管理的重要性。

Abstract: This paper develops a comprehensive framework to investigate and optimize the
downlink performance of cooperative multi-band networks (MBNs) operating on
upper mid-band (UMB) and terahertz (THz) frequencies, where base stations (BSs)
in each band cooperatively serve users. The framework captures sophisticated
features such as near-field channel modeling, fully and partially connected
antenna architectures, and users' mobility. First, we consider joint user
association and hybrid beamforming optimization to maximize the system
sum-rate, subject to power constraints, maximum cluster size of cooperating
BSs, and users' quality-of-service (QoS) constraints. By leveraging fractional
programming FP and majorization-minimization techniques, an iterative algorithm
is proposed to solve the non-convex optimization problem. We then consider
handover (HO)-aware resource allocation for moving users in a cooperative
UMB/THz MBN. Two HO-aware resource allocation methods are proposed. The first
method focuses on maximizing the HO-aware system sum-rate subject to HO-aware
QoS constraints. Using Jensen's inequality and properties of logarithmic
functions, the non-convex optimization problem is tightly approximated with a
convex one and solved. The second method addresses a multi-objective
optimization problem to maximize the system sum-rate, while minimizing the
total number of HOs. Numerical results demonstrate the efficacy of the proposed
algorithms, cooperative UMB/THz MBN over stand-alone THz networks, as well as
the critical importance of accurate near-field modeling in extremely large
antenna arrays. Moreover, the proposed HO-aware resource allocation methods
effectively mitigate the impact of HOs, enhancing performance in the considered
system.

</details>


### [6] [Dual-Function Beam Pattern Design for Multi-Target ISAC Systems: A Decoupled Approach](https://arxiv.org/abs/2509.23302)
*Wilson de Souza Junior,Taufik Abrao,Amine Mezghani,Ekram Hossain*

Main category: eess.SP

TL;DR: 本文研究了多用户多点目标的单基地ISAC系统中的波束方向图设计问题，提出了一种基于感知引导的双功能波束设计方法，并通过分解问题和使用低复杂度算法实现了更好的性能-复杂度权衡。


<details>
  <summary>Details</summary>
Motivation: 在ISAC系统中，感知和通信对资源的竞争可能导致波束方向图的重塑，降低感知精度。传统方法常忽视这种权衡，本文旨在解决这一问题。

Method: 将感知问题分解为两个子问题，提出SGCDF波束设计方法，并利用Riemannian流形优化和凸闭集投影开发低复杂度扩展。

Result: 仿真结果表明，与传统方法相比，所提方法提高了多目标估计精度，同时低复杂度版本在保持高精度的前提下大幅降低了计算成本。

Conclusion: 通过分解问题和优化设计，本文方法在ISAC系统中实现了更好的感知精度与计算复杂度的平衡。

Abstract: We investigate the beampattern design problem for mono-static multi-user (MU)
multi-point-target integrated sensing and communication (ISAC) systems, where a
dual-function multiple-input multiple-output (DF-MIMO) base station (BS)
performs downlink communication and radar sensing simultaneously. In ISAC
systems, sensing and communication inherently compete for resources. As
communication demand increases, the beam pattern is reshaped, which might
degrade the direction of arrival (DoA) sensing accuracy, measured in terms of
mean-squared error (MSE) and lower-bounded by the Cramer-Rao lower bound
(CRLB). Since conventional joint formulations of the sensing-based problem
often overlook this trade-off, our work addresses it by decomposing the
sensing-based problem into two subproblems (SPs). This decomposition enables a
more effective exploitation of the beam pattern's physical properties, which we
refer to as the Sensing-Guided Communication Dual-Function (SGCDF) beam pattern
design. We further develop a low-complexity extension using the Riemannian
Manifold Optimization (RMO) and convex closed-set projection. Simulation
results confirm that the proposed method improves multi-target estimation
accuracy, compared to traditional joint optimization strategies, by preserving
the beam pattern, while the low-complexity version offers an excellent
performance-complexity tradeoff, maintaining high accuracy with significantly
reduced computational cost.

</details>


### [7] [HoloTrace: a Location Privacy Preservation Solution for mmWave MIMO-OFDM Systems](https://arxiv.org/abs/2509.23444)
*Lorenzo Italiano,Alireza Pourafzal,Hui Chen,Mattia Brambilla,Gonzalo Seco-Granados,Monica Nicoli,Henk Wymeersch*

Main category: eess.SP

TL;DR: HoloTrace是一种针对6G网络中用户定位隐私的保护框架，通过用户端对信号参数的欺骗来防止基站提取精确位置信息，无需修改协议或网络支持。


<details>
  <summary>Details</summary>
Motivation: 6G网络技术带来了前所未有的用户定位能力，但也引发了物理层位置隐私的严重担忧。HoloTrace旨在解决这一问题，保护用户隐私免受非授权定位。

Method: HoloTrace通过对到达角（AoA）、出发角（AoD）和到达时间差（TDoA）等定位相关参数的欺骗，干扰基站的定位能力。该方法将欺骗建模为一个统一的有秩约束投影问题，并提供了闭式解。

Result: 仿真结果表明，HoloTrace能够有效欺骗基站，导致显著的定位误差，同时对链路容量的影响取决于欺骗的位置。

Conclusion: HoloTrace是一种实用且鲁棒的隐私保护解决方案，适用于未来6G网络。

Abstract: The technological innovation towards 6G cellular networks introduces
unprecedented capabilities for user equipment (UE) localization, but it also
raises serious concerns about physical layer location privacy. This paper
introduces HoloTrace, a signal-level privacy preservation framework that relies
on user-side spoofing of localization-relevant features to prevent the
extraction of precise location information from the signals received by a base
station (BS) in a mmWave MIMO-OFDM system. Spoofing is performed by the user on
location parameters such as angle of arrival (AoA), angle of departure (AoD),
and time difference of arrival (TDoA). Without requiring any protocol
modification nor network-side support, our method strategically perturbs pilot
transmissions to prevent a BS from performing non-consensual UE localization.
The methodology allows the UE to spoof its position, keeping the precoder
unchanged. We formulate spoofing as a unified rank-constrained projection
problem, and provide closed-form solutions under varying levels of channel
state information (CSI) at the UE, including scenarios with and without CSI
knowledge. Simulation results confirm that the proposed approach enables the UE
to deceive the BS, inducing significant localization errors, while the impact
on link capacity varies depending on the spoofed position. Our findings
establish HoloTrace as a practical and robust privacy-preserving solution for
future 6G networks.

</details>


### [8] [Theoretical framework of passive ME antenna arrays enabling in-vivo monitoring: A pathway to smart implants](https://arxiv.org/abs/2509.23520)
*Kalpesh Jaykar,Prasanth Velvaluri,Nian X. Sun,Richard D. James*

Main category: eess.SP

TL;DR: 该论文探讨了一种新型脑机接口技术Stentrode，通过微创手术在大脑血管中部署，结合磁电天线阵列以提升信号传输和接收能力，解决了传统天线输出增益低的问题。


<details>
  <summary>Details</summary>
Motivation: 传统脑机接口设备中的电池和电子元件通过有线连接，可能导致损坏或植入故障。磁电天线因其尺寸小和对地平面干扰免疫的优势，有望用于血管植入物中。

Method: 提出了利用天线阵列的设计，通过在指定远场点产生相长干涉来增强信号传输能力，并开发了数学模型优化天线的空间排列和相位同步。

Result: 基于模型的仿真显示，通过相位操控，天线阵列在指定远场位置展现出优异的高增益性能。

Conclusion: 磁电天线阵列的应用为脑机接口技术提供了更高的信号传输效率，展现了在微创监测和通讯中的潜力。

Abstract: A new brain-computer interface (BCI) technology, deployed through minimally
invasive surgery, is changing the way we think about treating severe
neurological conditions. The central idea is to place a device called Stentrode
in the brain's vasculature, which enables neuromodulation and helps patients
regain the ability to communicate. However, in such devices, the battery and
electronics are wired and could introduce damage or implant malfunction. In
these cases, a Stentrode integrated with magnetoelectric (ME) antennas could be
of great interest. ME antennas offer significant advantages over traditional
antennas, leveraging acoustic resonance rather than electromagnetic resonance
to achieve a size reduction of up to five orders of magnitude. In addition to
their compactness and immunity to ground-plane interference, ME antennas could
be adopted for use in vascular implants, such as coronary stents, potentially
enabling minimally invasive monitoring and communication. Despite these
advantages, a single antenna embedded in the implant may be constrained by the
limited volume of magnetostrictive material, which could result in low output
gain. To address this gain limitation, we propose using antenna arrays designed
to produce constructive interference at a designated far-field point, ideally
located outside the patient, to enhance signal transmission and receiving
capabilities. We develop a mathematical model to represent the antennas and
optimize their spatial arrangement and phase synchronization. Simulations based
on this model demonstrate promising high-gain performance at the prescribed
far-field location through phase manipulation.

</details>


### [9] [Learnable Kernels for FRI -- Joint Kernel Encoder Optimization and Hardware Validation](https://arxiv.org/abs/2509.23644)
*Omkar Nitsure,Sampath Kumar Dondapati,Satish Mulleti*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可学习核策略的FRI信号重构框架，通过优化采样核和重构编码器，提高了分辨率和噪声鲁棒性，并实现了硬件实现。


<details>
  <summary>Details</summary>
Motivation: 传统的FRI重构方法依赖于预定义核，限制了硬件实现和噪声条件下的重构精度。

Method: 提出了一种学习核策略，包括固定核和联合优化采样核与重构编码器的自适应核，并设计了硬件实现方案。

Result: 实验验证了该方法在分辨率和噪声鲁棒性上的显著优势，且计算复杂性更低。

Conclusion: 该方法适合资源受限的边缘部署，具有实际应用潜力。

Abstract: Finite Rate of Innovation (FRI) sampling techniques provide efficient
frameworks for reconstructing signals with inherent sparsity at rates below
Nyquist. However, traditional FRI reconstruction methods rely heavily on
pre-defined kernels, often limiting hardware implementation and reconstruction
accuracy under noisy conditions. In this paper, we propose a robust, flexible,
and practically implementable framework for FRI reconstruction by introducing
novel learnable kernel strategies. First, we demonstrate effective
reconstruction using known, fixed kernels such as truncated Gaussian and
Gaussian pair kernels, which mitigate the requirement that the samples should
have a sum-of-exponentials (SoE) form. Next, we extend this concept by jointly
optimizing both the sampling kernel and reconstruction encoder through a
unified learning approach, yielding adaptive kernels that significantly
outperform traditional methods in resolution and noise robustness, with reduced
sampling rates. Furthermore, we propose a practical hardware realization by
representing kernels as sums of two exponential decay signals with jointly
optimized poles, facilitating compact, efficient analog implementations. Our
approach is validated experimentally through hardware implementations using a
unity-gain Sallen-Key analog filter, achieving accurate real-world signal
recovery. The developed convolutional neural network-based encoder
substantially reduces computational complexity, demonstrating competitive
performance with fewer parameters, making our method particularly suitable for
resource-constrained, edge-based deployments.

</details>


### [10] [Joint Hybrid Beamforming and Artificial Noise Design for Secure Multi-UAV ISAC Networks](https://arxiv.org/abs/2509.23687)
*Runze Dong,Buhong Wang,Cunqian Feng,Jiang Weng,Chen Han,Jiwei Tian*

Main category: eess.SP

TL;DR: 该论文提出了一种多无人机网络的安全且高效的信感一体化（ISAC）框架，采用两阶段优化方法设计混合波束成形（HBF）、人工噪声（AN）注入和无人机轨迹，并通过仿真验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将无人机视为空中基站，而忽视了其作为ISAC用户的角色，且未充分利用地面基站的大规模天线阵列提升安全性和频谱效率。因此，论文提出了一种新的框架来解决这些问题。

Method: 论文开发了一种两阶段优化方法：第一阶段使用近端策略优化（PPO）优化数字波束成形器和无人机轨迹；第二阶段通过低复杂度矩阵分解将数字解分解为模拟和数字组件。

Result: 仿真结果表明，所提出的框架在多无人机网络中具有更高的保密率和频谱效率，优于基准方案。

Conclusion: 论文提出的ISAC框架和优化方法在多无人机网络中能够有效提升安全性和频谱效率，为未来空中动态环境中的应用提供了实用解决方案。

Abstract: Integrated sensing and communication (ISAC) emerges as a key enabler for
next-generation applications such as smart cities and autonomous systems. Its
integration with unmanned aerial vehicles (UAVs) unlocks new potentials for
reliable communication and precise sensing in dynamic aerial environments.
However, existing research predominantly treats UAVs as aerial base stations,
overlooking their role as ISAC users, and fails to leverage large-scale antenna
arrays at terrestrial base stations to enhance security and spectral
efficiency. This paper propose a secure and spectral efficient ISAC framework
for multi-UAV networks, and a two-stage optimization approach is developed to
jointly design hybrid beamforming (HBF), artificial noise (AN) injection, and
UAV trajectories. Aiming at maximizing the sum secrecy rate, the first stage
employs Proximal Policy Optimization (PPO) to optimize digital beamformers and
trajectories, and the second stage decomposes the digital solution into analog
and digital components via low-complexity matrix factorization. Simulation
results demonstrate the effectiveness of the proposed framework compared to
benchmark schemes.

</details>


### [11] [Expectation Propagation-Based Signal Detection for Highly Correlated MIMO Systems](https://arxiv.org/abs/2509.23792)
*Kabuto Arai,Takumi Yoshida,Takumi Takahashi,Koji Ishibashi*

Main category: eess.SP

TL;DR: 本文提出了一种基于期望传播（EP）的低复杂度检测器OvEP，用于解决大规模MIMO系统中高度相关和病态信道矩阵导致的性能下降问题。通过重叠块分区和LMMSE滤波，有效减少了计算复杂度并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模MIMO系统中因信道矩阵高度相关和病态导致的性能下降问题。

Method: 提出重叠块分区EP（OvEP）检测器，将测量向量划分为重叠块，设计低复杂度LMMSE滤波器，并合并输出以减少计算复杂度和改善性能。

Result: OvEP在较低计算复杂度下实现接近传统LMMSE-EP的性能，并通过仿真验证了理论预测的性能提升机制。

Conclusion: OvEP是一种高效且低复杂度的检测器，适用于大规模MIMO系统，能有效应对高相关性问题。

Abstract: Large-scale multiple-input-multiple-output (MIMO) systems typically operate
in dense array deployments with limited scattering environments, leading to
highly correlated and ill-conditioned channel matrices that severely degrade
the performance of message-passing-based detectors. To tackle this issue, this
paper proposes an expectation propagation (EP)-based detector, termed
overlapping block partitioning EP (OvEP). In OvEP, the large-scale measurement
vector is partitioned into partially overlapping blocks. For each block and its
overlapping part, a low-complexity linear minimum mean square error
(LMMSE)-based filter is designed according to the partitioned structure. The
resulting LMMSE outputs are then combined to generate the input to the
denoiser. In this combining process, subtracting the overlapping-part outputs
from the block outputs effectively mitigates the adverse effects of inter-block
correlation induced by high spatial correlation. The proposed algorithm is
consistently derived within the EP framework, and its fixed point is
theoretically proven to coincide with the stationary point of a relaxed
Kullback- Leibler (KL) minimization problem. The mechanisms underlying the
theoretically predicted performance improvement are further clarified through
numerical simulations. The proposed algorithm achieves performance close to
conventional LMMSE-EP with lower computational complexity.

</details>


### [12] [Online Specific Emitter Identification via Collision-Alleviated Signal Hash](https://arxiv.org/abs/2509.23807)
*Hongyu Wang,Wenjia Xu,Guangzuo Li,Siyuan Wan,Yaohua Sun,Jiuniu Wang,Mugen Peng*

Main category: eess.SP

TL;DR: 本文提出了在线特定发射器识别（OSEI）任务，并通过新型哈希模型CASH解决了现有模型在识别未见发射器信号时的偏差问题，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实场景中需要识别未见发射器的信号，但现有模型对此表现不佳，本文旨在解决这一挑战。

Method: 提出了一种哈希模型CASH，包括两个步骤：识别已知发射器和为信号样本分配哈希码。

Result: 在ADSB和ORACLE数据集上，CASH在few-shot和广义零样本学习任务中的准确率分别提升了至少6.08%和8.55%。

Conclusion: CASH模型能够有效识别已知和未见发射器的信号，性能优于现有方法。

Abstract: Specific Emitter Identification (SEI) has been widely studied, aiming to
distinguish signals from different emitters given training samples from those
emitters. However, real-world scenarios often require identifying signals from
novel emitters previously unseen. Since these novel emitters only have a few or
no prior samples, existing models struggle to identify signals from novel
emitters online and tend to bias toward the distribution of seen emitters. To
address these challenges, we propose the Online Specific Emitter Identification
(OSEI) task, comprising both online \revise{few-shot and generalized zero-shot}
learning tasks. It requires constructing models using signal samples from seen
emitters and then identifying new samples from seen and novel emitters online
during inference. We propose a novel hash-based model, Collision-Alleviated
Signal Hash (CASH), providing a unified approach for addressing the OSEI task.
The CASH operates in two steps: in the seen emitters identifying step, a signal
encoder and a seen emitters identifier determine whether the signal sample is
from seen emitters, mitigating the model from biasing toward seen emitters
distribution. In the signal hash coding step, an online signal hasher assigns a
hash code to each signal sample, identifying its specific emitter. Experimental
results on real-world signal datasets (i.e., ADSB and ORACLE) demonstrate that
our method accurately identifies signals from both seen and novel emitters
online. This model outperforms existing methods by a minimum of 6.08\% and
8.55\% in accuracy for the few-shot and \revise{generalized zero-shot learning
}tasks, respectively. The code will be open-sourced at
\href{https://github.com/IntelliSensing/OSEI-CASH}{https://github.com/IntelliSensing/OSEI-CASH}.

</details>


### [13] [Asymptotic Expansion for Nonlinear Filtering in the Small System Noise Regime](https://arxiv.org/abs/2509.23920)
*Masahiro Kurisaki*

Main category: eess.SP

TL;DR: 提出了一种基于系统噪声小参数的非线性滤波渐近展开方法，通过求解ODE系数提高计算效率和准确性，适用于复杂条件分布。


<details>
  <summary>Details</summary>
Motivation: 现有方法如高斯近似和粒子滤波在计算效率和准确性之间存在权衡，需要改进以捕捉条件分布的复杂特征。

Method: 利用噪声水平作为小参数，将条件期望展开为幂级数，并通过求解ODE计算系数，结合Edgeworth型展开捕捉多模态等特征。

Result: 相比传统滤波算法，新方法在较低计算成本下实现了对复杂条件分布的准确捕捉。

Conclusion: 该方法显著提升了非线性滤波的计算效率和准确性，适用于复杂分布场景。

Abstract: We propose a new asymptotic expansion method for nonlinear filtering, based
on a small parameter in the system noise. The conditional expectation is
expanded as a power series in the noise level, with each coefficient computed
by solving a system of ordinary differential equations. This approach mitigates
the trade-off between computational efficiency and accuracy inherent in
existing methods such as Gaussian approximations and particle filters.
Moreover, by incorporating an Edgeworth-type expansion, our method captures
complex features of the conditional distribution, such as multimodality, with
significantly lower computational cost than conventional filtering algorithms.

</details>


### [14] [Wideband Integrated Sensing and Communications: Spectral Efficiency and Signaling Design](https://arxiv.org/abs/2509.24097)
*Henglin Pu,Zhu Han,Athina P. Petropulu,Husheng Li*

Main category: eess.SP

TL;DR: 研究6G网络中集成感知与通信（ISAC）的波形合成问题，提出在宽带条件下通过OFDM信号的相位调制通信消息，并通过PSD控制优化感知性能，同时揭示OTFS波形的类似效果。


<details>
  <summary>Details</summary>
Motivation: 解决在6G网络中集成感知与通信功能的主要挑战，即在同一波形中整合二者功能，并通过宽带分析简化设计。

Method: 假设标准OFDM信号，在宽带条件下通过PSD形状控制优化感知性能，并采用低复杂度的水填充分配器平衡通信与感知性能。

Result: 提出的宽带ISAC方案通过数值仿真和硬件实验验证了其有效性，OTFS波形的延迟轴PSD平坦化也能达到类似效果。

Conclusion: 宽带波形设计能有效平衡通信与感知性能，为6G ISAC提供了实用的解决方案。

Abstract: In integrated sensing and communications (ISAC), a distinguishing feature of
6G wireless networks, the main challenge lies in integrating the two distinct
functions of sensing and communication within the same waveform. In this paper,
the ISAC waveform synthesis is studied in the wideband regime, since a large
bandwidth can simplify the analysis and is justified by the employment of
millimeter wave or higher frequency band. Standard orthogonal frequency
division multiplexing (OFDM) signaling is assumed, and the wideband analysis of
sensing is a counterpart of the existing studies on wideband communications. It
is proposed that the phase over such OFDM subcarriers is for modulating
communication messages while the power spectral density (PSD) is shaped for the
sensing performance. Beyond OFDM, we further reveal a duality between the
proposed PSD-shaping rule and the orthogonal time frequency space (OTFS)
waveform. Flattening the OTFS delay-axis PSD produces the same integrated
sidelobe level (ISL) reduction effect in the delay-Doppler domain as PSD
control achieves for OFDM in the frequency domain. To balance communication and
sensing performance over frequency-selective channels, we propose a
low-complexity, water-filling-like allocator with an explicit PSD-flatness
(variance) constraint. The performance of the proposed wideband ISAC scheme is
demonstrated using both numerical simulations and hardware experiments.

</details>


### [15] [BladderFormer: A Streaming Transformer for Real-Time Urological State Monitoring](https://arxiv.org/abs/2509.24178)
*Chengwei Zhou,Steve Majerus,Gourav Datta*

Main category: eess.SP

TL;DR: 论文提出了一种基于单层流式Transformer的模型，用于实时分类膀胱压力状态，通过小波变换处理原始时间序列数据，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有膀胱压力监测系统依赖手工特征和浅层分类器，难以适应复杂信号动态。

Method: 采用小波变换处理原始时间序列数据，并设计了一种单层流式Transformer模型，包含时间多头自注意力和状态缓存。

Result: 在91名患者的数据集上验证，模型表现出更高的准确性、能量效率和延迟效率。

Conclusion: 该模型适用于低功耗边缘硬件部署，如边缘GPU和微控制器。

Abstract: Bladder pressure monitoring systems are increasingly vital in diagnosing and
managing urinary tract dysfunction. Existing solutions rely heavily on
hand-crafted features and shallow classifiers, limiting their adaptability to
complex signal dynamics. We propose a one-layer streaming transformer model for
real-time classification of bladder pressure states, operating on
wavelet-transformed representations of raw time-series data. Our model
incorporates temporal multi-head self-attention and state caching, enabling
efficient online inference with high adaptability. Trained on a dataset of 91
patients with 20,000-80,000 samples each, our method demonstrates improved
accuracy, higher energy- and latency-efficiency. Implementation considerations
for edge deployment on low-power hardware, such as edge graphical processing
units (GPU) and micro-controllers, are also discussed.

</details>


### [16] [Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning](https://arxiv.org/abs/2509.24222)
*Zhisheng Chen,Yingwei Zhang,Qizhen Lan,Tianyu Liu,Huacan Wang,Yi Ding,Ziyu Jia,Ronghao Chen,Kun Wang,Xinliang Zhou*

Main category: eess.SP

TL;DR: Uni-NTFM是一种基于神经科学原理的统一神经拓扑基础模型，解决了EEG信号处理的三大挑战，并在多项下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的脑基础模型在处理EEG信号时存在时间域与频率域特征混淆、忽略电极空间拓扑以及依赖密集网络的局限性，亟需改进。

Method: 提出了Uni-NTFM模型，采用解耦架构并行处理时间、频率和原始信号，结合拓扑嵌入机制和Mixture-of-Experts Transformer。

Result: Uni-NTFM在九项下游任务中显著优于现有方法，证明了其学习大脑活动通用表示的能力。

Conclusion: Uni-NTFM通过创新设计和规模扩展，为EEG信号处理提供了高效且通用的解决方案。

Abstract: Foundation models pretrained on various and unlabeled data have demonstrated
significant success in natural language and vision, but their application to
electroencephalography (EEG) remains challenged due to the signal's unique
properties. Existing brain foundation models that inherit architectures
designed for text or images lead to three limitations in pre-training: 1)
conflating time-domain waveform patterns with frequency-domain rhythmic
features in a single processing stream, 2) ignoring the critical spatial
topology of electrodes with different standards, and 3) reliance on the
inflexible, dense network to process functionally distinct EEG patterns. To
address these challenges, we introduce the Unified Neural Topological
Foundation Model (Uni-NTFM), which is designed based on neuroscience principles
to produce universal and interpretable representations. Uni-NTFM integrates
three core innovations: 1) a decoupled architecture parallelly encodes time,
frequency, and raw signal representations before performing cross-domain
feature integration; 2) a topological embedding mechanism to unify electrodes
from different international standards and generate structured input sequences
for brain regions; and 3) a Mixture-of-Experts neural Transformer that
efficiently scales model capacity by routing signal patterns to specialized
subnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B
parameters and was pretrained on over 28,000 hours of diverse EEG data via a
dual-domain masked reconstruction objective. Uni-NTFM significantly outperforms
existing task-specific methods and foundation models across nine distinct
downstream tasks under both linear probing and fine-tuning settings,
demonstrating a superior ability to learn universal representations of brain
activity.

</details>


### [17] [N78 Frequency Band Modular RIS Design and Implementation](https://arxiv.org/abs/2509.24355)
*Sefa Kayraklık,Recep Baş,Hasan Oğuzhan Çalışkan,Samed Şahinoğlu,Sercan Erdoğan,İlhami Ünal,İbrahim Hökelek,Kıvanç Nurdan,Ali Görçin*

Main category: eess.SP

TL;DR: 论文提出了一种模块化的可重构智能表面（RIS）原型设计流程，展示了其在n78频段提升信号功率的效果。


<details>
  <summary>Details</summary>
Motivation: 通过RIS技术动态控制无线传播特性，增强下一代无线网络的信号覆盖和终端连接性。

Method: 设计了包含主从模块的RIS原型，每个模块具有8×8反射表面单元和控制器板，通过PIN二极管控制相位差。

Result: 实验显示，RIS在n78频段可将接收信号功率提升超过15dB。

Conclusion: 该RIS原型设计有效提升了信号功率，证明了其在实际应用中的潜力。

Abstract: Reconfigurable intelligent surface (RIS), capable of dynamically controlling
wireless propagation characteristics using reflecting antenna elements, is a
promising technology for enhancing signal coverage and improving end-user
connectivity in next-generation wireless networks. This paper presents a
complete design flow of a modular RIS prototype operating at the n78 frequency
band, starting from the simulations to the prototype development and testing.
An RIS prototype includes one master and up to sixteen slave blocks, each of
which has an identical hardware structure with $8\times 8$ reflecting surface
elements and a controller board. The phase shift response of each unit element
is controlled with a PIN diode to form a $180^\circ$ phase difference between
the ON and OFF states. The measurement experiment using two RIS blocks, horn
antennas, and a vector network analyzer showed that the improvement of the
received signal power is more than $15$ dB across the n78 frequency band for a
given placement.

</details>


### [18] [Strong Basin of Attraction for Unmixing Kernels With the Variable Projection Method](https://arxiv.org/abs/2509.24428)
*Santos Michelena,Maxime Ferreira Da Costa,José Picheral*

Main category: eess.SP

TL;DR: 研究了在已知尖峰信号位置的情况下，从参数流形上不同点扩散函数（PSF）的混合中恢复信号的问题，提出了投影非线性最小二乘估计器，并分析了其收敛性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中PSF混叠信号的恢复问题，尤其是在未知PSF的情况下，避免手动校准的需求。

Method: 采用投影非线性最小二乘估计器，通过分析流形相干性和Lipschitz性质，建立强凸区域的半径下界。

Result: 理论分析和数值实验表明，该估计器具有良好的收敛性和稳定性，且在真实光谱数据（LIBS）上验证了有效性。

Conclusion: 该方法不仅理论可靠，还能在实际应用中显著减少手动校准的依赖，具有实用价值。

Abstract: The problem of recovering a mixture of spike signals convolved with distinct
point spread functions (PSFs) lying on a parametric manifold, under the
assumption that the spike locations are known, is studied. The PSF unmixing
problem is formulated as a projected non-linear least squares estimator. A
lower bound on the radius of the region of strong convexity is established in
the presence of noise as a function of the manifold coherence and Lipschitz
properties, guaranteeing convergence and stability of the optimization program.
Numerical experiments highlight the speed of decay of the PSF class in the
problem's conditioning and confirm theoretical findings. Finally, the proposed
estimator is deployed on real-world spectroscopic data from laser-induced
breakdown spectroscopy (LIBS), removing the need for manual calibration and
validating the method's practical relevance.

</details>


### [19] [Low-Complexity Wireless Multi-Port Sensing by Multiplexed De-Embedding of an Over-the-Air Fixture](https://arxiv.org/abs/2509.24537)
*Philipp del Hougne*

Main category: eess.SP

TL;DR: 论文提出了一种无线多端口传感方法，通过OTA夹具和可调负载网络实现DUT的散射矩阵远程估计，解决了测量多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 解决在无线多端口传感中，由于OTA夹具特性已知但独立测量不足时，DUT特性无法准确恢复的问题。

Method: 使用可调负载网络（TLN）增加测量多样性，并通过多个PF实现联合解嵌入（multiplexed de-embedding）技术。

Result: 实验成功远程估计了一个4端口DUT的散射矩阵，并通过30种PF实现验证了方法的有效性。

Conclusion: 该方法为RFID和无线生物电子等领域的低硬件复杂度无线多端口传感提供了可行路径。

Abstract: Wireless multi-port sensing remotely retrieves the scattering matrix of a
multi-port device under test (DUT) connected to a set of
not-directly-accessible (NDA) antennas that couple over-the-air (OTA) to a set
of accessible antennas. If (i) the OTA fixture characteristics are known, and
(ii) the number of independent measurements at the accessible antennas is
sufficient, the OTA fixture can be de-embedded to recover the DUT
characteristics. In recent prior work, we solved (i) by connecting the NDA
antennas to a specific known tunable load network (TLN). Here, we tackle (ii)
by additionally using the TLN to provide measurement diversity. The connection
between OTA fixture and TLN constitutes a programmable fixture (PF). When the
DUT characteristics cannot be identified based on a single PF realization, we
add measurement diversity with multiple PF realizations. The underlying
"multiplexed de-embedding" achieves the joint de-embedding of an ensemble of PF
realizations when a single PF realization cannot be de-embedded. We
experimentally demonstrate our concept by remotely estimating the scattering
matrix of a reciprocal, non-unitary 4-port DUT (10 complex-valued unknowns) via
a rich-scattering OTA fixture purely based on measurements of a single
transmission coefficient between two accessible antennas across 30 different PF
realizations. We systematically study the trade-off between the number of
independent measurements at the accessible antennas and the number of PF
realizations. Multiplexed de-embedding of the OTA fixture paves the path to
implementing wireless multi-port sensing with low hardware complexity in areas
like RFID and wireless bioelectronics.

</details>


### [20] [BARProp: Fast-Converging and Memory-Efficient RSS-Based Localization Algorithm for IoT](https://arxiv.org/abs/2509.24588)
*Luis F. Abanto-Leon,Muhammad Salman,Lismer Andres Caceres-Najarro*

Main category: eess.SP

TL;DR: BARProp是一种基于RSS的快速、内存高效的室内定位算法，通过动态调整衰减因子提升收敛速度和稳定性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用RSS进行室内定位虽然具有吸引力，但现有方法依赖复杂算法或专用硬件，限制了其在低成本设备上的应用。

Method: 提出BARProp算法，通过监测梯度能量变化动态调整衰减因子，减少内存占用并加速收敛。

Result: 实验证明BARProp在定位精度和收敛速度上均优于现有基准方法，内存占用仅为其15%。

Conclusion: BARProp为低成本设备提供了一种高效、稳定的RSS定位解决方案。

Abstract: Leveraging received signal strength (RSS) measurements for indoor
localization is highly attractive due to their inherent availability in
ubiquitous wireless protocols. However, prevailing RSS-based methods often
depend on complex computational algorithms or specialized hardware, rendering
them impractical for low-cost access points. To address these challenges, this
paper introduces buffer-aided RMSProp (BARProp), a fast and memory-efficient
localization algorithm specifically designed for RSS-based tasks. The key
innovation of BARProp lies in a novel mechanism that dynamically adapts the
decay factor by monitoring the energy variations of recent gradients stored in
a buffer, thereby achieving both accelerated convergence and enhanced
stability. Furthermore, BARProp requires less than 15% of the memory used by
state-of-the-art methods. Extensive evaluations with real-world data
demonstrate that BARProp not only achieves higher localization accuracy but
also delivers at least a fourfold improvement in convergence speed compared to
existing benchmarks.

</details>


### [21] [Impedance Modeling of Magnetometers: A Path Toward Low-Noise Readout Circuits](https://arxiv.org/abs/2509.24683)
*Johan Arbustini,Eric Elzenheimer,Elizaveta Spetzler,Pablo Mendoza,Daniel Fernández,Jordi Madrenas,Jeffrey McCord,Michael Höft,Robert Rieger,Andreas Bahr*

Main category: eess.SP

TL;DR: 该研究提出了一种新颖的双端口阻抗模型，用于估计一种磁电传感器的行为，并通过实验和仿真验证了模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 优化传感器读出方案和集成电路设计需要精确的建模和仿真策略，尤其是在高精度磁感应应用中。

Method: 通过阻抗分析仪测量S参数并转换为Z参数，构建传递函数，使用MATLAB和LTSpice进行仿真验证。

Result: 模型通过实验验证，成功优化了系统模拟电路部分的噪声，为高性能磁传感应用提供了重要依据。

Conclusion: 该方法为混合信号电路设计提供了噪声分析和传递函数的推导，拓宽了其在高性能传感器接口电子中的应用范围。

Abstract: Optimizing sensor readout schemes and integrated circuit designs for both
open-loop and closed-loop implementations requires precise modeling and
simulation strategies. This study introduces a novel two-port impedance model
to estimate the behavior of a converse Magnetoelectric (cME) sensor. This model
provides a possible framework for calculating transfer functions and simulating
magnetometer behavior in both continuous- and discrete-time simulation
environments, and it is also possibly transferable to other magnetometer types.
Common S-parameters were measured experimentally using an impedance analyzer
and converted to Z-parameters to create a transfer function for system-level
simulations. The model was validated through an analysis of output-related
noise using MATLAB and LTSpice simulations to optimize the noise of the analog
circuit parts of the system. The simulation results were compared with
experimental measurements using a Zurich Instruments lock-in amplifier and the
custom-designed low-noise printed circuit board (PCB) under model
considerations. The proposed methodology derives noise considerations and the
transfer function of a magnetometer. These are essential for readout schemes
for mixed-signal circuit design. This allows low-noise electronics to be
designed and extended to other sensor interface electronics, broadening their
applicability in high-performance magnetic sensing.

</details>


### [22] [RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off](https://arxiv.org/abs/2509.24805)
*Andriy Enttsel,Alex Marchioni,Andrea Zanellini,Mauro Mangia,Gianluca Setti,Riccardo Rovatti*

Main category: eess.SP

TL;DR: 论文探讨了压缩数据对异常检测的影响，提出了一种信息理论框架，通过权衡压缩效率、失真度和信号可区分性来优化系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有压缩传输的数据可能因信息损失影响异常检测的准确性，需要一种方法来同时优化压缩、失真和信号区分度。

Method: 扩展信息理论框架，利用高斯假设绘制Pareto曲线，权衡压缩效率、失真和信号可区分性。

Result: 通过权衡三个关键特征，系统能够更好地管理压缩与异常检测的性能平衡。

Conclusion: 提出的方法优于仅依赖最优率失真压缩的策略，显著提升了压缩信号的异常检测能力。

Abstract: Extensive monitoring systems generate data that is usually compressed for
network transmission. This compressed data might then be processed in the cloud
for tasks such as anomaly detection. However, compression can potentially
impair the detector's ability to distinguish between regular and irregular
patterns due to information loss. Here we extend the information-theoretic
framework introduced in [1] to simultaneously address the trade-off between the
three features on which the effectiveness of the system depends: the
effectiveness of compression, the amount of distortion it introduces, and the
distinguishability between compressed normal signals and compressed anomalous
signals. We leverage a Gaussian assumption to draw curves showing how moving on
a Pareto surface helps administer such a trade-off better than simply relying
on optimal rate-distortion compression and hoping that compressed signals can
be distinguished from each other.

</details>


### [23] [Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2509.24819)
*Kunyu Wu,Qiushi Zhao,Zihan Feng,Yunxi Mu,Hao Qin,Xinyu Zhang,Xingqi Zhang*

Main category: eess.SP

TL;DR: 提出了一种结合深度强化学习（DRL）、抛物波方程（PWE）信道建模和条件生成对抗网络（cGAN）的框架，用于优化隧道中通信基列车控制系统（CBTC）的接入点（AP）部署。该方法显著减少了仿真成本并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法如经验模型优化算法需要大量测量且结果不理想，而机器学习方法在复杂隧道环境中表现不佳。因此，需要一种高效且准确的方法来优化AP部署。

Method: 该方法集成了PWE生成高保真路径损耗分布，cGAN用于数据增强生成高分辨率路径损耗图，并使用Dueling DQN进行AP位置优化。状态空间捕获AP位置和覆盖范围，动作空间定义AP调整，奖励函数平衡信号改善与部署成本。

Result: 实验表明，该方法比传统的Hooke Jeeves优化器和标准DQN表现更优，提供了更高的平均接收功率、更好的最坏情况覆盖和计算效率。

Conclusion: 该方法结合了高保真电磁模拟、生成模型和AI驱动的优化，为复杂隧道环境中的CBTC系统提供了可扩展和数据高效的解决方案。

Abstract: Urban railway systems increasingly rely on communication based train control
(CBTC) systems, where optimal deployment of access points (APs) in tunnels is
critical for robust wireless coverage. Traditional methods, such as empirical
model-based optimization algorithms, are hindered by excessive measurement
requirements and suboptimal solutions, while machine learning (ML) approaches
often struggle with complex tunnel environments. This paper proposes a deep
reinforcement learning (DRL) driven framework that integrates parabolic wave
equation (PWE) channel modeling, conditional generative adversarial network
(cGAN) based data augmentation, and a dueling deep Q network (Dueling DQN) for
AP placement optimization. The PWE method generates high-fidelity path loss
distributions for a subset of AP positions, which are then expanded by the cGAN
to create high resolution path loss maps for all candidate positions,
significantly reducing simulation costs while maintaining physical accuracy. In
the DRL framework, the state space captures AP positions and coverage, the
action space defines AP adjustments, and the reward function encourages signal
improvement while penalizing deployment costs. The dueling DQN enhances
convergence speed and exploration exploitation balance, increasing the
likelihood of reaching optimal configurations. Comparative experiments show
that the proposed method outperforms a conventional Hooke Jeeves optimizer and
traditional DQN, delivering AP configurations with higher average received
power, better worst-case coverage, and improved computational efficiency. This
work integrates high-fidelity electromagnetic simulation, generative modeling,
and AI-driven optimization, offering a scalable and data-efficient solution for
next-generation CBTC systems in complex tunnel environments.

</details>


### [24] [Low-Complexity Receiver Design for Multicarrier CAPA-based Systems in Doubly-Dispersive Channels](https://arxiv.org/abs/2509.24941)
*Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种低复杂度接收器设计，用于多载波连续孔径阵列（CAPA）系统在双分散信道中的操作，通过高斯置信传播（GaBP）框架实现高性能检测。


<details>
  <summary>Details</summary>
Motivation: 针对双分散信道中多载波连续孔径阵列系统的信号检测问题，设计一种低复杂度接收器以提高性能。

Method: 采用高斯置信传播（GaBP）框架，仅需标量运算实现符号检测。

Result: 仿真结果显示，与传统离散天线阵列系统相比，OFDM、OTFS和AFDM波形在未编码比特误码率（BER）方面显著提升。

Conclusion: 该方法在保持极低计算复杂度的同时实现了显著的性能改进。

Abstract: We propose a novel low-complexity receiver design for multicarrier continuous
aperture array (CAPA) systems operating over doubly-dispersive (DD) channels.
The receiver leverages a Gaussian Belief Propagation (GaBP)-based framework
that hinges only on element-wise scalar operations for the detection of the
transmitted symbols. Simulation results for the orthogonal frequency division
multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine
frequency division multiplexing (AFDM) waveforms demonstrate significant
performance improvements in terms of uncoded bit error rate (BER) compared to
conventional discrete antenna array systems, while maintaining very low
computational complexity.

</details>


### [25] [Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks](https://arxiv.org/abs/2509.25095)
*M A Al-Masud,Juan Miguel Lopez Alcaraz,Nils Strodthoff*

Main category: eess.SP

TL;DR: 论文研究了12导联心电图（ECG）基础模型在26个临床任务中的表现，发现它们在成人ECG分析中表现优异，但在其他任务中仍有不足，尤其是ECG-CPC模型在资源消耗较少的情况下表现突出。


<details>
  <summary>Details</summary>
Motivation: 探索ECG基础模型是否能够在多样化的临床任务中表现出通用性和适应性，填补当前机器学习在ECG解释中的局限性。

Method: 在12个公共数据集上对8种ECG基础模型进行了基准测试，涵盖1,650个回归和分类任务，评估了模型在微调和冻结设置下的性能，并分析了数据集大小对性能的影响。

Result: 在成人ECG解释任务中，三种基础模型表现优于传统监督学习方法，而ECG-CPC在资源有限的条件下表现出色；但在心脏结构、结果预测和患者特征分析等任务中，基础模型仍有较大差距。

Conclusion: 基础模型在成人ECG分析中显示出潜力，但在其他任务中表现不均；ECG-CPC的高效性为未来ECG基础模型的优化提供了方向。

Abstract: The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yet
machine learning for ECG interpretation remains fragmented, often limited to
narrow tasks or datasets. Foundation models promise broader adaptability, but
their generalization across diverse ECG tasks is not well understood. We
benchmarked eight ECG foundation models on 26 clinically relevant tasks using
12 public datasets comprising 1,650 regression and classification targets.
Models were evaluated under fine-tuning and frozen settings, with scaling
analyses across dataset sizes. Results show heterogeneous performance across
domains: in the most widely studied domain, adult ECG interpretation, three
foundation models consistently outperformed strong supervised baselines. In
contrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,
dominated other categories where most foundation models failed to surpass
supervised learning. Foundation models also displayed distinct scaling
behaviors with dataset size, which are critical for small-scale clinical
applications. Overall, while foundation models show promise for adult ECG
analysis, substantial gaps remain in cardiac structure, outcome prediction, and
patient characterization. Notably, ECG-CPC's strong performance despite being
orders of magnitude smaller and consuming minimal computational resources
highlights untapped opportunities for advancing ECG foundation models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [26] [Mobile Robot Localization via Indoor Positioning System and Odometry Fusion](https://arxiv.org/abs/2509.22693)
*Muhammad Hafil Nugraha,Fauzi Abdul,Lastiko Bramantyo,Estiko Rijanto,Roni Permana Saputra,Oka Mahendra*

Main category: cs.RO

TL;DR: 本文提出了一种结合超声波室内定位系统（IPS）和车轮里程计的传感器融合方法，通过扩展卡尔曼滤波器（EKF）增强移动机器人的定位精度和可靠性。实验结果显示该方法显著优于独立系统。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在室内环境中的准确定位是其有效操作的关键。单独依赖IPS或车轮里程计存在局限，需要一种融合方法来克服各自的问题。

Method: 采用EKF融合IPS和车轮里程计的数据，结合两者的优势并弥补各自的不足。

Result: 实验表明，融合系统显著提高了定位精度和轨迹跟踪能力，减少了车轮打滑和传感器噪声带来的误差。

Conclusion: EKF融合方法为移动机器人提供了一种鲁棒且可靠的室内定位解决方案。

Abstract: Accurate localization is crucial for effectively operating mobile robots in
indoor environments. This paper presents a comprehensive approach to mobile
robot localization by integrating an ultrasound-based indoor positioning system
(IPS) with wheel odometry data via sensor fusion techniques. The fusion
methodology leverages the strengths of both IPS and wheel odometry,
compensating for the individual limitations of each method. The Extended Kalman
Filter (EKF) fusion method combines the data from the IPS sensors and the
robot's wheel odometry, providing a robust and reliable localization solution.
Extensive experiments in a controlled indoor environment reveal that the
fusion-based localization system significantly enhances accuracy and precision
compared to standalone systems. The results demonstrate significant
improvements in trajectory tracking, with the EKF-based approach reducing
errors associated with wheel slippage and sensor noise.

</details>


### [27] [Nonlinear Model Predictive Control with Single-Shooting Method for Autonomous Personal Mobility Vehicle](https://arxiv.org/abs/2509.22694)
*Rakha Rahmadani Pratama,Catur Hilman A. H. B. Baskoro,Joga Dharma Setiawan,Dyah Kusuma Dewi,P Paryanto,Mochammad Ariyanto,Roni Permana Saputra*

Main category: cs.RO

TL;DR: 本文提出了一种基于非线性模型预测控制（NMPC）的自主个人移动车辆（SEATER）控制方法，通过单射击方法解决最优控制问题，并在Gazebo和ROS框架中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为自主个人移动车辆（如SEATER）设计一种高效且鲁棒的控制方法，以满足目标定位和避障等约束条件。

Method: 采用非线性模型预测控制（NMPC）和单射击方法，结合差速驱动系统和里程计数据进行定位反馈。

Result: 仿真结果表明，该方法能有效控制车辆到达目标位置，并在障碍物环境中保持鲁棒性和实时性。

Conclusion: NMPC结合单射击方法在自主车辆控制中表现优异，适用于复杂环境。

Abstract: This paper introduces a proposed control method for autonomous personal
mobility vehicles, specifically the Single-passenger Electric Autonomous
Transporter (SEATER), using Nonlinear Model Predictive Control (NMPC). The
proposed method leverages a single-shooting approach to solve the optimal
control problem (OCP) via non-linear programming (NLP). The proposed NMPC is
implemented to a non-holonomic vehicle with a differential drive system, using
odometry data as localization feedback to guide the vehicle towards its target
pose while achieving objectives and adhering to constraints, such as obstacle
avoidance. To evaluate the performance of the proposed method, a number of
simulations have been conducted in both obstacle-free and static obstacle
environments. The SEATER model and testing environment have been developed in
the Gazebo Simulation and the NMPC are implemented within the Robot Operating
System (ROS) framework. The simulation results demonstrate that the NMPC-based
approach successfully controls the vehicle to reach the desired target location
while satisfying the imposed constraints. Furthermore, this study highlights
the robustness and real-time effectiveness of NMPC with a single-shooting
approach for autonomous vehicle control in the evaluated scenarios.

</details>


### [28] [ReSeFlow: Rectifying SE(3)-Equivariant Policy Learning Flows](https://arxiv.org/abs/2509.22695)
*Zhitao Wang,Yanke Wang,Jiangtao Wen,Roberto Horowitz,Yuxing Han*

Main category: cs.RO

TL;DR: ReSeFlow结合SE(3)-等变扩散模型与整流流，实现快速、高效的轨迹策略生成，显著降低推理时间和误差。


<details>
  <summary>Details</summary>
Motivation: 解决SE(3)-等变扩散模型在非结构化环境中推理时间成本高的问题。

Method: 引入整流流到SE(3)-扩散模型，提出ReSeFlow，实现一步推理生成策略。

Result: 在模拟基准测试中，一步推理的性能优于基线方法，误差显著降低。

Conclusion: ReSeFlow结合SE(3)-等变性和整流流，为生成策略模型的实际应用提供了高效解决方案。

Abstract: Robotic manipulation in unstructured environments requires the generation of
robust and long-horizon trajectory-level policy with conditions of perceptual
observations and benefits from the advantages of SE(3)-equivariant diffusion
models that are data-efficient. However, these models suffer from the inference
time costs. Inspired by the inference efficiency of rectified flows, we
introduce the rectification to the SE(3)-diffusion models and propose the
ReSeFlow, i.e., Rectifying SE(3)-Equivariant Policy Learning Flows, providing
fast, geodesic-consistent, least-computational policy generation. Crucially,
both components employ SE(3)-equivariant networks to preserve rotational and
translational symmetry, enabling robust generalization under rigid-body
motions. With the verification on the simulated benchmarks, we find that the
proposed ReSeFlow with only one inference step can achieve better performance
with lower geodesic distance than the baseline methods, achieving up to a 48.5%
error reduction on the painting task and a 21.9% reduction on the rotating
triangle task compared to the baseline's 100-step inference. This method takes
advantages of both SE(3) equivariance and rectified flow and puts it forward
for the real-world application of generative policy learning models with the
data and inference efficiency.

</details>


### [29] [Advancing Audio-Visual Navigation Through Multi-Agent Collaboration in 3D Environments](https://arxiv.org/abs/2509.22698)
*Hailong Zhang,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.RO

TL;DR: MASTAVN是一个多代理协作框架，通过交叉代理通信协议和联合音频-视觉融合机制，提升了在3D环境中的协作导航能力。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉导航研究多集中于单代理系统，但在动态3D环境中多代理协作至关重要，尤其是在应急响应等时间敏感场景中。

Method: 提出MASTAVN框架，集成交叉代理通信协议和联合音频-视觉融合机制，增强空间推理和时间同步。

Result: 在Replica和Matterport3D模拟器中验证，MASTAVN显著减少任务完成时间并提高导航成功率。

Conclusion: MASTAVN在时间敏感场景中表现出色，为复杂3D环境中的多代理协作提供了范式。

Abstract: Intelligent agents often require collaborative strategies to achieve complex
tasks beyond individual capabilities in real-world scenarios. While existing
audio-visual navigation (AVN) research mainly focuses on single-agent systems,
their limitations emerge in dynamic 3D environments where rapid multi-agent
coordination is critical, especially for time-sensitive applications like
emergency response. This paper introduces MASTAVN (Multi-Agent Scalable
Transformer Audio-Visual Navigation), a scalable framework enabling two agents
to collaboratively localize and navigate toward an audio target in shared 3D
environments. By integrating cross-agent communication protocols and joint
audio-visual fusion mechanisms, MASTAVN enhances spatial reasoning and temporal
synchronization. Through rigorous evaluation in photorealistic 3D simulators
(Replica and Matterport3D), MASTAVN achieves significant reductions in task
completion time and notable improvements in navigation success rates compared
to single-agent and non-collaborative baselines. This highlights the essential
role of spatiotemporal coordination in multi-agent systems. Our findings
validate MASTAVN's effectiveness in time-sensitive emergency scenarios and
establish a paradigm for advancing scalable multi-agent embodied intelligence
in complex 3D environments.

</details>


### [30] [Large Language Models for 3D IC Space Planning](https://arxiv.org/abs/2509.22716)
*Hung-Ying Chu,Guan-Wei Chen,Shao-Yu Wei,Yu-Cheng Lin*

Main category: cs.RO

TL;DR: 该研究提出了一种基于大型语言模型（LLMs）的三维集成电路（3D ICs）空间规划方法，通过后序切片树表示生成合法布局并减少死区。实验显示该方法在效率、合法性和死区减少方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 随着三维集成电路设计复杂度的增加，有效的空间规划对于减少死区和确保布局质量至关重要。

Method: 使用开源LLMs在大规模合成数据集上进行微调，并通过后序切片树表示生成合法空间规划。

Result: 在MCNC基准测试中，该方法在效率和死区减少方面表现良好，部分测试案例中实现了零死区布局。

Conclusion: LLM-based的空间规划可作为传统EDA方法的数据驱动补充，为可扩展的3D布局生成提供新思路。

Abstract: Three-dimensional integrated circuits (3D ICs) have emerged as a promising
solution to the scaling limits of two-dimensional designs, offering higher
integration density, shorter interconnects, and improved performance. As design
complexity increases, effective space planning becomes essential to reduce dead
space and ensure layout quality. This study investigates the use of large
language models (LLMs) for 3D IC space planning through a post-order slicing
tree representation, which guarantees legal space plans while aiming to
minimize dead space. Open-source LLMs were fine-tuned on large-scale synthetic
datasets and further evaluated on MCNC-derived 3D benchmarks. Experimental
results indicate that the proposed framework achieves a favorable balance
between runtime efficiency, legality, and dead-space reduction, with
zero-dead-space layouts obtained in a significant portion of test cases under
practical runtime budgets. Beyond synthetic benchmarks, the method generalizes
to MCNC cases such as ami33 and ami49, though larger and irregular instances
remain challenging. The approach also shows potential for cross-domain
applications, including logistics and 3D object placement, where spatial
efficiency is critical. Overall, the results suggest that LLM-based space
planning can serve as a data-driven complement to traditional electronic design
automation (EDA) methods, providing new insights for scalable 3D layout
generation.

</details>


### [31] [Self-driving cars: Are we there yet?](https://arxiv.org/abs/2509.22754)
*Merve Atasever,Zhuochen Liu,Qingpei Li,Akshay Hitendra Shah,Hans Walker,Jyotirmoy V. Deshmukh,Rahul Jain*

Main category: cs.RO

TL;DR: 论文对CARLA、nuPlan和Waymo Open Dataset三大平台的运动规划方法进行了比较分析，使用CARLA leaderboard v2.0作为统一评估平台，总结了当前方法的优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要标准化数据集和评估协议，现有平台如CARLA、nuPlan和Waymo Open Dataset已成为运动规划算法的主要基准，但缺乏统一的比较分析。

Method: 采用CARLA leaderboard v2.0作为统一评估平台，对三大平台的运动规划方法进行调整以确保兼容性，并进行综合分析。

Result: 揭示了当前方法的优势与不足，总结了主要趋势和共同挑战。

Conclusion: 研究为运动规划的未来发展提供了方向，强调了标准化评估的重要性。

Abstract: Autonomous driving remains a highly active research domain that seeks to
enable vehicles to perceive dynamic environments, predict the future
trajectories of traffic agents such as vehicles, pedestrians, and cyclists and
plan safe and efficient future motions. To advance the field, several
competitive platforms and benchmarks have been established to provide
standardized datasets and evaluation protocols. Among these, leaderboards by
the CARLA organization and nuPlan and the Waymo Open Dataset have become
leading benchmarks for assessing motion planning algorithms. Each offers a
unique dataset and challenging planning problems spanning a wide range of
driving scenarios and conditions. In this study, we present a comprehensive
comparative analysis of the motion planning methods featured on these three
leaderboards. To ensure a fair and unified evaluation, we adopt CARLA
leaderboard v2.0 as our common evaluation platform and modify the selected
models for compatibility. By highlighting the strengths and weaknesses of
current approaches, we identify prevailing trends, common challenges, and
suggest potential directions for advancing motion planning research.

</details>


### [32] [Persistent Autoregressive Mapping with Traffic Rules for Autonomous Driving](https://arxiv.org/abs/2509.22756)
*Shiyi Liang,Xinyuan Chang,Changjie Wu,Huiyuan Yan,Yifan Bai,Xinran Liu,Hang Zhang,Yujian Yuan,Shuang Zeng,Mu Xu,Xing Wei*

Main category: cs.RO

TL;DR: PAMR提出了一种新的框架，结合车道几何和交通规则的自回归建模，解决了现有方法在长序列驾驶中规则持续性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长时间驾驶中的交通规则时，往往忽略了规则的持续性，导致自动驾驶的安全性不足。

Method: PAMR通过Map-Rule Co-Construction和Map-Rule Cache机制，实现了车道几何与交通规则的自回归协同建模。

Result: 实验表明，PAMR在联合向量-规则映射任务中表现优异，并在长序列驾驶中保持了规则的持续性。

Conclusion: PAMR为高精度地图构建和交通规则持续性感知提供了有效解决方案。

Abstract: Safe autonomous driving requires both accurate HD map construction and
persistent awareness of traffic rules, even when their associated signs are no
longer visible. However, existing methods either focus solely on geometric
elements or treat rules as temporary classifications, failing to capture their
persistent effectiveness across extended driving sequences. In this paper, we
present PAMR (Persistent Autoregressive Mapping with Traffic Rules), a novel
framework that performs autoregressive co-construction of lane vectors and
traffic rules from visual observations. Our approach introduces two key
mechanisms: Map-Rule Co-Construction for processing driving scenes in temporal
segments, and Map-Rule Cache for maintaining rule consistency across these
segments. To properly evaluate continuous and consistent map generation, we
develop MapDRv2, featuring improved lane geometry annotations. Extensive
experiments demonstrate that PAMR achieves superior performance in joint
vector-rule mapping tasks, while maintaining persistent rule effectiveness
throughout extended driving sequences.

</details>


### [33] [Towards Developing Standards and Guidelines for Robot Grasping and Manipulation Pipelines in the COMPARE Ecosystem](https://arxiv.org/abs/2509.22801)
*Huajing Zhao,Brian Flynn,Adam Norton,Holly Yanco*

Main category: cs.RO

TL;DR: COMPARE生态系统旨在通过一系列活动提升开源机器人操作产品的兼容性和基准测试能力，包括组件级别和管道级别的模块化标准和指南开发。


<details>
  <summary>Details</summary>
Motivation: 提高开源机器人操作产品的兼容性和性能评估标准化。

Method: 开发标准和指南，构建开源产品库，研究现有模块化管道以总结最佳实践，并开发新的模块化管道。

Result: 工作进展包括识别管道中各组件的共同特征、总结最佳实践以及开发符合标准的新管道。

Conclusion: COMPARE生态系统通过模块化标准和指南的开发和实践应用，推动了机器人操作开源产品的兼容性和性能提升。

Abstract: The COMPARE Ecosystem aims to improve the compatibility and benchmarking of
open-source products for robot manipulation through a series of activities. One
such activity is the development of standards and guidelines to specify
modularization practices at the component-level for individual modules (e.g.,
perception, grasp planning, motion planning) and integrations of components
that form robot manipulation capabilities at the pipeline-level. This paper
briefly reviews our work-in-progress to date to (1) build repositories of
open-source products to identify common characteristics of each component in
the pipeline, (2) investigate existing modular pipelines to glean best
practices, and (3) develop new modular pipelines that advance prior work while
abiding by the proposed standards and guidelines.

</details>


### [34] [Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots](https://arxiv.org/abs/2509.22815)
*Ruturaj Sambhus,Muneeb Ahmad,Basit Muhammad Imran,Sujith Vijayan,Dylan P. Losey,Kaveh Akbari Hamed*

Main category: cs.RO

TL;DR: 提出了一种自适应非线性模型预测控制（ANMPC）框架，用于四足机器人在避障任务中的共享自主权，结合人类意图建模和安全约束，实现安全高效的协作。


<details>
  <summary>Details</summary>
Motivation: 解决人类与自主四足机器人在共享自主权中的安全和效率问题，尤其是在杂乱环境中固定混合策略无法适应动态步态的挑战。

Method: 采用分层控制架构，结合Boltzmann模型在线学习人类意图，并通过CBF约束集成到NMPC中，确保安全性和高效性。

Result: 通过数值模拟、硬件实验和用户研究验证了框架的有效性，实现了实时避障和安全的远程协作。

Conclusion: 提出的ANMPC框架能有效提升四足机器人与人类协作的安全性和适应性，适用于复杂环境。

Abstract: Ensuring safe and effective collaboration between humans and autonomous
legged robots is a fundamental challenge in shared autonomy, particularly for
teleoperated systems navigating cluttered environments. Conventional
shared-control approaches often rely on fixed blending strategies that fail to
capture the dynamics of legged locomotion and may compromise safety. This paper
presents a teleoperator-aware, safety-critical, adaptive nonlinear model
predictive control (ANMPC) framework for shared autonomy of quadrupedal robots
in obstacle-avoidance tasks. The framework employs a fixed arbitration weight
between human and robot actions but enhances this scheme by modeling the human
input with a noisily rational Boltzmann model, whose parameters are adapted
online using a projected gradient descent (PGD) law from observed joystick
commands. Safety is enforced through control barrier function (CBF) constraints
integrated into a computationally efficient NMPC, ensuring forward invariance
of safe sets despite uncertainty in human behavior. The control architecture is
hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended
human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz)
enforces reduced-order single rigid body (SRB) dynamics to track these
references, and a low-level nonlinear whole-body controller (500 Hz) imposes
the full-order dynamics via quadratic programming to track the mid-level
trajectories. Extensive numerical and hardware experiments, together with a
user study, on a Unitree Go2 quadrupedal robot validate the framework,
demonstrating real-time obstacle avoidance, online learning of human intent
parameters, and safe teleoperator collaboration.

</details>


### [35] [Parameter Identification of a Differentiable Human Arm Musculoskeletal Model without Deep Muscle EMG Reconstruction](https://arxiv.org/abs/2509.22825)
*Philip Sanderink,Yingfan Zhou,Shuzhen Luo,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了一种无需重建深层肌肉EMG信号的人类手臂骨骼肌肉模型参数识别方法，通过最小二乘解计算损失梯度，实现了与现有方法相当的估计精度。


<details>
  <summary>Details</summary>
Motivation: 个性化骨骼肌肉模型的参数识别对协作机器人系统（如辅助外骨骼）的安全性和可靠性至关重要，但现有EMG-based方法因难以测量深层肌肉EMG信号而受限。

Method: 仅使用表层肌肉EMG信号和深层肌肉力的最小二乘解，通过可微优化框架识别模型参数，避免了深层肌肉行为的假设。

Result: 广泛对比实验表明，该方法在不依赖深层肌肉EMG信号的情况下，达到了与全肌肉EMG信号方法相当的估计精度。

Conclusion: 提出的方法为无创参数识别提供了可靠途径，显著提升了模型的实用性与鲁棒性。

Abstract: Accurate parameter identification of a subject-specific human musculoskeletal
model is crucial to the development of safe and reliable physically
collaborative robotic systems, for instance, assistive exoskeletons.
Electromyography (EMG)-based parameter identification methods have demonstrated
promising performance for personalized musculoskeletal modeling, whereas their
applicability is limited by the difficulty of measuring deep muscle EMGs
invasively. Although several strategies have been proposed to reconstruct deep
muscle EMGs or activations for parameter identification, their reliability and
robustness are limited by assumptions about the deep muscle behavior. In this
work, we proposed an approach to simultaneously identify the bone and
superficial muscle parameters of a human arm musculoskeletal model without
reconstructing the deep muscle EMGs. This is achieved by only using the
least-squares solution of the deep muscle forces to calculate a loss gradient
with respect to the model parameters for identifying them in a framework of
differentiable optimization. The results of extensive comparative simulations
manifested that our proposed method can achieve comparable estimation accuracy
compared to a similar method, but with all the muscle EMGs available.

</details>


### [36] [Dynamic Buffers: Cost-Efficient Planning for Tabletop Rearrangement with Stacking](https://arxiv.org/abs/2509.22828)
*Arman Barghi,Hamed Hosseini,Seraj Ghasemi,Mehdi Tale Masouleh,Ahmad Kalhor*

Main category: cs.RO

TL;DR: 论文提出了一种称为“动态缓冲区”的新规划原语，用于解决密集桌面环境中物体重新排列的低效问题。该方法通过允许临时、可移动的堆叠来提升规划效率和可行性，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的物体重新排列规划器在处理密集环境时效率低下，因使用固定缓冲区（如静态堆叠或空闲桌面区域）而限制了灵活性。为了解决这一问题，作者提出了动态缓冲区方法。

Method: 动态缓冲区受人类分组策略启发，允许机器人形成临时、可移动的堆叠单元，从而提升规划的可行性和效率。该方法在静态和移动机器人场景下进行了测试。

Result: 相比现有最优规划器，动态缓冲区在密集环境中减少了11.89%的机械臂移动成本，在低密度环境中减少了5.69%。实验通过在Delta并行机器人上验证了其实用性。

Conclusion: 动态缓冲区被确立为高效、鲁棒的重新排列规划的关键原语，显著提升了规划性能和适用性。

Abstract: Rearranging objects in cluttered tabletop environments remains a
long-standing challenge in robotics. Classical planners often generate
inefficient, high-cost plans by shuffling objects individually and using fixed
buffers--temporary spaces such as empty table regions or static stacks--to
resolve conflicts. When only free table locations are used as buffers, dense
scenes become inefficient, since placing an object can restrict others from
reaching their goals and complicate planning. Allowing stacking provides extra
buffer capacity, but conventional stacking is static: once an object supports
another, the base cannot be moved, which limits efficiency. To overcome these
issues, a novel planning primitive called the Dynamic Buffer is introduced.
Inspired by human grouping strategies, it enables robots to form temporary,
movable stacks that can be transported as a unit. This improves both
feasibility and efficiency in dense layouts, and it also reduces travel in
large-scale settings where space is abundant. Compared with a state-of-the-art
rearrangement planner, the approach reduces manipulator travel cost by 11.89%
in dense scenarios with a stationary robot and by 5.69% in large, low-density
settings with a mobile manipulator. Practicality is validated through
experiments on a Delta parallel robot with a two-finger gripper. These findings
establish dynamic buffering as a key primitive for cost-efficient and robust
rearrangement planning.

</details>


### [37] [Empart: Interactive Convex Decomposition for Converting Meshes to Parts](https://arxiv.org/abs/2509.22847)
*Brandon Vu,Shameek Ganguly,Pushkar Joshi*

Main category: cs.RO

TL;DR: Empart 是一个交互式工具，允许用户为网格的不同区域指定不同的简化容忍度，显著减少了凸部分的数量并提升了仿真性能。


<details>
  <summary>Details</summary>
Motivation: 简化复杂3D网格对机器人应用至关重要，但现有方法采用统一的误差容忍度，导致在非关键区域过度细节化或关键区域细节不足。

Method: 利用现有凸分解算法作为子程序，通过并行化框架处理区域特定约束，提供用户友好界面和可视化反馈。

Result: 在固定误差阈值下，相比V-HACD方法，Empart显著减少了凸部分数量，并将仿真时间减少了69%。

Conclusion: Empart展示了交互式、区域特定的网格简化在高效机器人应用中的价值。

Abstract: Simplifying complex 3D meshes is a crucial step in robotics applications to
enable efficient motion planning and physics simulation. Common methods, such
as approximate convex decomposition, represent a mesh as a collection of simple
parts, which are computationally inexpensive to simulate. However, existing
approaches apply a uniform error tolerance across the entire mesh, which can
result in a sub-optimal trade-off between accuracy and performance. For
instance, a robot grasping an object needs high-fidelity geometry in the
vicinity of the contact surfaces but can tolerate a coarser simplification
elsewhere. A uniform tolerance can lead to excessive detail in non-critical
areas or insufficient detail where it's needed most.
  To address this limitation, we introduce Empart, an interactive tool that
allows users to specify different simplification tolerances for selected
regions of a mesh. Our method leverages existing convex decomposition
algorithms as a sub-routine but uses a novel, parallelized framework to handle
region-specific constraints efficiently. Empart provides a user-friendly
interface with visual feedback on approximation error and simulation
performance, enabling designers to iteratively refine their decomposition. We
demonstrate that our approach significantly reduces the number of convex parts
compared to a state-of-the-art method (V-HACD) at a fixed error threshold,
leading to substantial speedups in simulation performance. For a robotic
pick-and-place task, Empart-generated collision meshes reduced the overall
simulation time by 69% compared to a uniform decomposition, highlighting the
value of interactive, region-specific simplification for performant robotics
applications.

</details>


### [38] [Multi-Robot Allocation for Information Gathering in Non-Uniform Spatiotemporal Environments](https://arxiv.org/abs/2509.22883)
*Kaleb Ben Naveed,Haejoon Lee,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出了一种两阶段多机器人场估计框架，用于非均匀时空环境中的场估计，解决了现有GP方法在空间和时间尺度上的局限性。


<details>
  <summary>Details</summary>
Motivation: 自主机器人被广泛用于估计时空变化的场（如风速、温度、气体浓度），但现有高斯过程方法通常假设全局尺度或忽略时间变化，导致不确定性估计不准确。

Method: 第一阶段使用变差函数驱动的规划器学习区域特定的空间尺度；第二阶段根据不确定性重新分配机器人，并随时间尺度细化更新采样。

Result: 方法在多种环境中评估，提供了空间尺度估计的收敛分析，并量化了与最佳分配序列的动态遗憾界限。

Conclusion: 提出的框架有效解决了非均匀时空场估计问题，提升了不确定性估计的准确性。

Abstract: Autonomous robots are increasingly deployed to estimate spatiotemporal fields
(e.g., wind, temperature, gas concentration) that vary across space and time.
We consider environments divided into non-overlapping regions with distinct
spatial and temporal dynamics, termed non-uniform spatiotemporal environments.
Gaussian Processes (GPs) can be used to estimate these fields. The GP model
depends on a kernel that encodes how the field co-varies in space and time,
with its spatial and temporal lengthscales defining the correlation. Hence,
when these lengthscales are incorrect or do not correspond to the actual field,
the estimates of uncertainty can be highly inaccurate. Existing GP methods
often assume one global lengthscale or update only periodically; some allow
spatial variation but ignore temporal changes. To address these limitations, we
propose a two-phase framework for multi-robot field estimation. Phase 1 uses a
variogram-driven planner to learn region-specific spatial lengthscales. Phase 2
employs an allocation strategy that reassigns robots based on the current
uncertainty, and updates sampling as temporal lengthscales are refined. For
encoding uncertainty, we utilize clarity, an information metric from our
earlier work. We evaluate the proposed method across diverse environments and
provide convergence analysis for spatial lengthscale estimation, along with
dynamic regret bounds quantifying the gap to the oracle's allocation sequence.

</details>


### [39] [Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM](https://arxiv.org/abs/2509.22910)
*Yanwei Du,Jing-Chen Peng,Patricio A. Vela*

Main category: cs.RO

TL;DR: Good Weights算法通过自适应整合航迹推算和视觉SLAM，提升了在纹理缺失或视觉退化环境中的定位准确性。


<details>
  <summary>Details</summary>
Motivation: 在缺乏纹理或视觉退化的环境中，视觉SLAM表现不佳，而航迹推算虽短期可用但长期不可靠。需要一种方法来结合两者的优势。

Method: Good Weights算法自适应调整航迹推算和视觉SLAM的权重，视觉信息强大时减少航迹推算的影响，反之亦然。

Result: 实验表明，Good Weights在数据集和实际部署中提升了视觉SLAM的性能和鲁棒性。

Conclusion: Good Weights为移动导航提供了一种实用解决方案，有效改善了视觉SLAM在复杂环境中的表现。

Abstract: Given that Visual SLAM relies on appearance cues for localization and scene
understanding, texture-less or visually degraded environments (e.g., plain
walls or low lighting) lead to poor pose estimation and track loss. However,
robots are typically equipped with sensors that provide some form of dead
reckoning odometry with reasonable short-time performance but unreliable
long-time performance. The Good Weights (GW) algorithm described here provides
a framework to adaptively integrate dead reckoning (DR) with passive visual
SLAM for continuous and accurate frame-level pose estimation. Importantly, it
describes how all modules in a comprehensive SLAM system must be modified to
incorporate DR into its design. Adaptive weighting increases DR influence when
visual tracking is unreliable and reduces when visual feature information is
strong, maintaining pose track without overreliance on DR. Good Weights yields
a practical solution for mobile navigation that improves visual SLAM
performance and robustness. Experiments on collected datasets and in real-world
deployment demonstrate the benefits of Good Weights.

</details>


### [40] [ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality](https://arxiv.org/abs/2509.22914)
*Rohan Walia,Yusheng Wang,Ralf Römer,Masahiro Nishio,Angela P. Schoellig,Jun Ota*

Main category: cs.RO

TL;DR: ARMimic是一个轻量级框架，仅使用消费级XR头显和固定摄像头实现机器人模仿学习的数据采集，减少演示时间50%，任务成功率提升11%。


<details>
  <summary>Details</summary>
Motivation: 传统机器人技能演示方法（如运动教学和远程操作）繁琐且硬件依赖高，限制了可扩展性和可用性。

Method: ARMimic结合手部跟踪、AR机器人叠加和实时深度感知，确保无碰撞且运动学可行的演示，并通过统一模仿学习管道处理人类和虚拟机器人轨迹。

Result: 在两个操纵任务（包括堆叠碗）中，ARMimic减少了50%的演示时间，任务成功率比基线ACT提高了11%。

Conclusion: ARMimic实现了安全、无缝且灵活的野外数据采集，为多样化现实场景中的机器人学习提供了潜力。

Abstract: Imitation learning is a powerful paradigm for robot skill acquisition, yet
conventional demonstration methods--such as kinesthetic teaching and
teleoperation--are cumbersome, hardware-heavy, and disruptive to workflows.
Recently, passive observation using extended reality (XR) headsets has shown
promise for egocentric demonstration collection, yet current approaches require
additional hardware, complex calibration, or constrained recording conditions
that limit scalability and usability. We present ARMimic, a novel framework
that overcomes these limitations with a lightweight and hardware-minimal setup
for scalable, robot-free data collection using only a consumer XR headset and a
stationary workplace camera. ARMimic integrates egocentric hand tracking,
augmented reality (AR) robot overlays, and real-time depth sensing to ensure
collision-aware, kinematically feasible demonstrations. A unified imitation
learning pipeline is at the core of our method, treating both human and virtual
robot trajectories as interchangeable, which enables policies that generalize
across different embodiments and environments. We validate ARMimic on two
manipulation tasks, including challenging long-horizon bowl stacking. In our
experiments, ARMimic reduces demonstration time by 50% compared to
teleoperation and improves task success by 11% over ACT, a state-of-the-art
baseline trained on teleoperated data. Our results demonstrate that ARMimic
enables safe, seamless, and in-the-wild data collection, offering great
potential for scalable robot learning in diverse real-world settings.

</details>


### [41] [DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes](https://arxiv.org/abs/2509.22937)
*Trent Weiss,Amar Kulkarni,Madhur Behl*

Main category: cs.RO

TL;DR: 论文提出了一种基于差分贝叶斯滤波框架的轨迹合成方法，用于解决自动驾驶赛车中的超车问题，避免了传统方法的简化假设，并在测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究背景是自动驾驶赛车中复杂的超车动作生成，尤其是避免碰撞和动态约束的挑战。

Method: 采用差分贝叶斯滤波框架，将轨迹合成问题建模为贝叶斯推断问题，无需依赖传统方法的简化假设。

Result: 在闭环测试中，该方法在87%的场景中成功超车，表现优于现有技术。

Conclusion: 该方法有效地解决了复杂赛道上的超车问题，为自动驾驶赛车提供了更可靠的轨迹合成方案。

Abstract: A significant challenge in autonomous racing is to generate overtaking
maneuvers. Racing agents must execute these maneuvers on complex racetracks
with little room for error. Optimization techniques and graph-based methods
have been proposed, but these methods often rely on oversimplified assumptions
for collision-avoidance and dynamic constraints. In this work, we present an
approach to trajectory synthesis based on an extension of the Differential
Bayesian Filtering framework. Our approach for collision-free trajectory
synthesis frames the problem as one of Bayesian Inference over the space of
Composite Bezier Curves. Our method is derivative-free, does not require a
spherical approximation of the vehicle footprint, linearization of constraints,
or simplifying upper bounds on collision avoidance. We conduct a closed-loop
analysis of DBF-MA and find it successfully overtakes an opponent in 87% of
tested scenarios, outperforming existing methods in autonomous overtaking.

</details>


### [42] [Hierarchical Control Design for Space Robots with Application to In-Orbit Servicing Missions](https://arxiv.org/abs/2509.22955)
*Pietro Bruschi*

Main category: cs.RO

TL;DR: 该论文提出了一种用于自主捕获太空翻滚物体的分层控制框架，结合了内环Lyapunov鲁棒控制和外环扩展逆运动学问题，提高了鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 太空中的在轨服务和主动碎片清除需要先进的机器人技术来捕获和不稳定非合作目标，为此需要解决多体动力学和液体晃动问题。

Method: 开发了一个模拟环境，包含追捕器的液体晃动动力学，并提出了一种结合Lyapunov鲁棒控制和扩展逆运动学的分层控制器。

Result: 仿真结果表明，该控制框架在鲁棒性和适应性上优于现有控制方案。

Conclusion: 该研究为太空机器人技术提供了更高效的控制方法，尤其在处理非合作目标时表现优异。

Abstract: In-Orbit Servicing and Active Debris Removal require advanced robotic
capabilities for capturing and detumbling uncooperative targets. This work
presents a hierarchical control framework for autonomous robotic capture of
tumbling objects in space. A simulation environment is developed, incorporating
sloshing dynamics of the chaser, a rarely studied effect in space robotics. The
proposed controller combines an inner Lyapunov-based robust control loop for
multi-body dynamics with an outer loop addressing an extended inverse
kinematics problem. Simulation results show improved robustness and
adaptability compared to existing control schemes.

</details>


### [43] [Robot Learning from Any Images](https://arxiv.org/abs/2509.22970)
*Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: RoLA是一个框架，能够将任意真实世界的图像转化为具有物理交互能力的机器人环境，无需额外硬件或数字资产。它通过单视图物理场景恢复和高效的视觉融合策略，实现了快速、大规模的可视化机器人数据生成，适用于多种应用场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统机器人数据生成方法需要额外硬件或数字资产的问题，RoLA旨在提供一个高效、低成本的数据生成框架，从而推动机器人学习的普及和发展。

Method: RoLA结合了单视图物理场景恢复方法和视觉融合策略，直接从单张图像生成物理交互环境。

Result: RoLA能够快速生成大量机器人演示数据，适用于多种应用场景，如机器人数据扩展、从互联网图像学习以及真实到仿真再到真实的系统。

Conclusion: RoLA为机器人数据生成提供了一种高效、低成本的新方法，具有广泛的应用潜力。

Abstract: We introduce RoLA, a framework that transforms any in-the-wild image into an
interactive, physics-enabled robotic environment. Unlike previous methods, RoLA
operates directly on a single image without requiring additional hardware or
digital assets. Our framework democratizes robotic data generation by producing
massive visuomotor robotic demonstrations within minutes from a wide range of
image sources, including camera captures, robotic datasets, and Internet
images. At its core, our approach combines a novel method for single-view
physical scene recovery with an efficient visual blending strategy for
photorealistic data collection. We demonstrate RoLA's versatility across
applications like scalable robotic data generation and augmentation, robot
learning from Internet images, and single-image real-to-sim-to-real systems for
manipulators and humanoids. Video results are available at
https://sihengz02.github.io/RoLA .

</details>


### [44] [Safe Task Space Synchronization with Time-Delayed Information](https://arxiv.org/abs/2509.22976)
*Rounak Bhattacharya,Vrithik R. Guthikonda,Ashwin P. Dani*

Main category: cs.RO

TL;DR: 本文设计了一种自适应控制器，用于机器人轨迹与人类轨迹在任务空间中的同步，考虑了通信延迟和未知运动学/动力学问题。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作任务中因传感器处理、网络延迟或计算限制导致的轨迹同步问题，同时确保安全性。

Method: 使用Barrier Lyapunov Function（BLF）限制机器人坐标，结合ICL自适应律估计未知运动学和梯度自适应律估计未知动力学。

Result: 通过Barrier Lyapunov-Krasovskii函数分析，证明同步和参数估计误差是半全局一致最终有界的（SGUUB）。仿真结果验证了控制器的有效性。

Conclusion: 设计的自适应控制器在存在时间延迟和安全性约束下，实现了高效的人机轨迹同步。

Abstract: In this paper, an adaptive controller is designed for the synchronization of
the trajectory of a robot with unknown kinematics and dynamics to that of the
current human trajectory in the task space using the delayed human trajectory
information. The communication time delay may be a result of various factors
that arise in human-robot collaboration tasks, such as sensor processing or
fusion to estimate trajectory/intent, network delays, or computational
limitations. The developed adaptive controller uses Barrier Lyapunov Function
(BLF) to constrain the Cartesian coordinates of the robot to ensure safety, an
ICL-based adaptive law to account for the unknown kinematics, and a
gradient-based adaptive law to estimate unknown dynamics. Barrier
Lyapunov-Krasovskii (LK) functionals are used for the stability analysis to
show that the synchronization and parameter estimation errors remain
semi-globally uniformly ultimately bounded (SGUUB). The simulation results
based on a human-robot synchronization scenario with time delay are provided to
demonstrate the effectiveness of the designed synchronization controller with
safety constraints.

</details>


### [45] [UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes](https://arxiv.org/abs/2509.23021)
*Xiao Hu,Qi Yin,Yangming Shi,Yang Ye*

Main category: cs.RO

TL;DR: UniPrototype框架通过共享运动原语，有效解决机器人学习中数据稀缺问题，提升学习效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 机器人学习中数据稀缺是一个主要挑战，而人类演示得益于丰富的运动捕捉数据和互联网资源。UniPrototype旨在通过知识转移弥补这一差距。

Method: 提出UniPrototype框架，包括软分配的组合原型发现机制、自适应原型选择策略，并通过仿真和实际机器人系统验证。

Result: 实验表明，UniPrototype成功将人类操作知识转移到机器人，显著提高了学习效率和任务性能。

Conclusion: UniPrototype为机器人学习中的数据稀缺问题提供了有效解决方案，具有广泛的应用潜力。

Abstract: Data scarcity remains a fundamental challenge in robot learning. While human
demonstrations benefit from abundant motion capture data and vast internet
resources, robotic manipulation suffers from limited training examples. To
bridge this gap between human and robot manipulation capabilities, we propose
UniPrototype, a novel framework that enables effective knowledge transfer from
human to robot domains via shared motion primitives. ur approach makes three
key contributions: (1) We introduce a compositional prototype discovery
mechanism with soft assignments, enabling multiple primitives to co-activate
and thus capture blended and hierarchical skills; (2) We propose an adaptive
prototype selection strategy that automatically adjusts the number of
prototypes to match task complexity, ensuring scalable and efficient
representation; (3) We demonstrate the effectiveness of our method through
extensive experiments in both simulation environments and real-world robotic
systems. Our results show that UniPrototype successfully transfers human
manipulation knowledge to robots, significantly improving learning efficiency
and task performance compared to existing approaches.The code and dataset will
be released upon acceptance at an anonymous repository.

</details>


### [46] [RAISE: A Robot-Assisted Selective Disassembly and Sorting System for End-of-Life Phones](https://arxiv.org/abs/2509.23048)
*Chang Liu,Badrinath Balasubramaniam,Neal Yancey,Michael Severson,Adam Shine,Philip Bove,Beiwen Li,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本研究提出了一种低成本、易部署的自动化拆解系统，用于高效处理废弃手机，解决传统人工拆解的低效率问题。


<details>
  <summary>Details</summary>
Motivation: 废弃手机因其高产量和短生命周期加剧了全球电子废物问题，传统人工拆解效率低下且成本高昂。

Method: 设计了由自适应切割系统、视觉引导机器人分拣系统和电池移除系统组成的自动化拆解系统。

Result: 系统每小时可处理120多部手机，平均拆解成功率达98.9%，并将高价值组件高效输送至下游处理环节。

Conclusion: 该系统为废弃手机拆解提供了可靠且可扩展的自动化解决方案，显著提升了经济效益。

Abstract: End-of-Life (EoL) phones significantly exacerbate global e-waste challenges
due to their high production volumes and short lifecycles. Disassembly is among
the most critical processes in EoL phone recycling. However, it relies heavily
on human labor due to product variability. Consequently, the manual process is
both labor-intensive and time-consuming. In this paper, we propose a low-cost,
easily deployable automated and selective disassembly and sorting system for
EoL phones, consisting of three subsystems: an adaptive cutting system, a
vision-based robotic sorting system, and a battery removal system. The system
can process over 120 phones per hour with an average disassembly success rate
of 98.9%, efficiently delivering selected high-value components to downstream
processing. It provides a reliable and scalable automated solution to the
pressing challenge of EoL phone disassembly. Additionally, the automated system
can enhance disassembly economics, converting a previously unprofitable process
into one that yields a net profit per unit weight of EoL phones.

</details>


### [47] [In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer](https://arxiv.org/abs/2509.23075)
*Soofiyan Atar,Daniel Huang,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 该论文提出了一种结合仿真训练和硬件演示学习的控制器，用于提升机器人手对铰链工具的操控能力，通过触觉和力反馈增强适应性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习和仿真到现实的方法在处理铰链机制时表现脆弱，主要由于复杂的动力学现象（如摩擦、间隙）未被充分建模。

Method: 结合仿真训练的基础策略和硬件演示学习的传感器驱动细化，利用触觉、力反馈和交叉注意力整合进行在线适应。

Result: 在真实世界的多种工具（如剪刀、手术工具）上验证了方法的有效性，实现了从仿真到硬件的稳健转移和对新工具的泛化。

Conclusion: 该方法减少了对精确物理建模的依赖，提升了铰链工具操控的鲁棒性和适应性。

Abstract: Reinforcement learning (RL) and sim-to-real transfer have advanced robotic
manipulation of rigid objects. Yet, policies remain brittle when applied to
articulated mechanisms due to contact-rich dynamics and under-modeled joint
phenomena such as friction, stiction, backlash, and clearances. We address this
challenge through dexterous in-hand manipulation of articulated tools using a
robotic hand with reduced articulation and kinematic redundancy relative to the
human hand. Our controller augments a simulation-trained base policy with a
sensor-driven refinement learned from hardware demonstrations, conditioning on
proprioception and target articulation states while fusing whole-hand tactile
and force feedback with the policy's internal action intent via
cross-attention-based integration. This design enables online adaptation to
instance-specific articulation properties, stabilizes contact interactions,
regulates internal forces, and coordinates coupled-link motion under
perturbations. We validate our approach across a diversity of real-world
examples, including scissors, pliers, minimally invasive surgical tools, and
staplers. We achieve robust transfer from simulation to hardware, improved
disturbance resilience, and generalization to previously unseen articulated
tools, thereby reducing reliance on precise physical modeling in contact-rich
settings.

</details>


### [48] [Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning](https://arxiv.org/abs/2509.23107)
*Yi Wang,Zeyu Xue,Mujie Liu,Tongqin Zhang,Yan Hu,Zhou Zhao,Chenguang Yang,Zhenyu Lu*

Main category: cs.RO

TL;DR: 论文提出了一种名为ST-OVSG的方法，通过结合时空动态和延迟标注的开放词汇场景图，解决了远程操作中的延迟导致的指令误解问题。实验表明，该方法在Replica基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 远程操作中的传输延迟会导致感知状态与操作意图不匹配，从而引发指令误解和执行错误。为了解决这一问题，研究团队开发了ST-OVSG方法。

Method: ST-OVSG结合了开放词汇3D对象表示和时空动态，并通过匈牙利算法实现时间域扩展。同时，嵌入延迟标签和任务导向子图过滤策略，以优化规划输入。

Result: 在Replica基准测试中，ST-OVSG的节点准确率达到74%，且在延迟鲁棒性实验中，LVLM规划器的成功率提升至70.5%。

Conclusion: ST-OVSG能够有效解决远程操作中的延迟问题，增强规划的鲁棒性，且无需微调即可泛化到新类别。

Abstract: Teleoperation via natural-language reduces operator workload and enhances
safety in high-risk or remote settings. However, in dynamic remote scenes,
transmission latency during bidirectional communication creates gaps between
remote perceived states and operator intent, leading to command
misunderstanding and incorrect execution. To mitigate this, we introduce the
Spatio-Temporal Open-Vocabulary Scene Graph (ST-OVSG), a representation that
enriches open-vocabulary perception with temporal dynamics and lightweight
latency annotations. ST-OVSG leverages LVLMs to construct open-vocabulary 3D
object representations, and extends them into the temporal domain via Hungarian
assignment with our temporal matching cost, yielding a unified spatio-temporal
scene graph. A latency tag is embedded to enable LVLM planners to
retrospectively query past scene states, thereby resolving local-remote state
mismatches caused by transmission delays. To further reduce redundancy and
highlight task-relevant cues, we propose a task-oriented subgraph filtering
strategy that produces compact inputs for the planner. ST-OVSG generalizes to
novel categories and enhances planning robustness against transmission latency
without requiring fine-tuning. Experiments show that our method achieves 74
percent node accuracy on the Replica benchmark, outperforming ConceptGraph.
Notably, in the latency-robustness experiment, the LVLM planner assisted by
ST-OVSG achieved a planning success rate of 70.5 percent.

</details>


### [49] [Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications](https://arxiv.org/abs/2509.23111)
*Chen Yizhe,Wang Qi,Hu Dongxiao,Jingzhe Fang,Liu Sichao,Zixin An,Hongliang Niu,Haoran Liu,Li Dong,Chuanfen Feng,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.RO

TL;DR: 这篇论文提出了一个工业级多模态干扰数据集，用于复杂环境下机器人感知与控制，解决了动态环境多传感器数据融合的挑战。


<details>
  <summary>Details</summary>
Motivation: 工业4.0应用中，动态环境干扰导致环境状态与机器人行为高度非线性耦合，现有机器人数据集难以有效表征多模态传感器数据融合的动态环境状态。

Method: 设计了包含大小、颜色和光照变化的多维干扰特征的数据集，采用高精度传感器同步采集视觉、扭矩和关节状态数据，并通过ROS实现微秒级时间同步和抗振动数据采集协议。

Result: 实验结果表明，该数据集提升了模型验证的鲁棒性，并在动态干扰环境中改善了机器人操作稳定性。

Conclusion: 该数据集为复杂环境下的机器人研究提供了真实且有代表性的数据支持，并已公开可用。

Abstract: In Industry 4.0 applications, dynamic environmental interference induces
highly nonlinear and strongly coupled interactions between the environmental
state and robotic behavior. Effectively representing dynamic environmental
states through multimodal sensor data fusion remains a critical challenge in
current robotic datasets. To address this, an industrial-grade multimodal
interference dataset is presented, designed for robotic perception and control
under complex conditions. The dataset integrates multi-dimensional interference
features including size, color, and lighting variations, and employs
high-precision sensors to synchronously collect visual, torque, and joint-state
measurements. Scenarios with geometric similarity exceeding 85\% and
standardized lighting gradients are included to ensure real-world
representativeness. Microsecond-level time-synchronization and
vibration-resistant data acquisition protocols, implemented via the Robot
Operating System (ROS), guarantee temporal and operational fidelity.
Experimental results demonstrate that the dataset enhances model validation
robustness and improves robotic operational stability in dynamic,
interference-rich environments. The dataset is publicly available
at:https://modelscope.cn/datasets/Liaoh_LAB/Liaohe-CobotMagic-PnP.

</details>


### [50] [FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task](https://arxiv.org/abs/2509.23112)
*Ryo Watanabe,Maxime Alvarez,Pablo Ferreiro,Pavel Savkin,Genki Sano*

Main category: cs.RO

TL;DR: 论文提出了一种多模态模仿学习策略，结合视觉和力/扭矩传感，提升机械臂在零售环境中的精确操作能力。


<details>
  <summary>Details</summary>
Motivation: 零售环境中机械臂在接触密集的边缘情况下仍需昂贵的人工遥控操作，特别是直立饮料瓶的精确操作，仅靠视觉提示往往不足。

Method: 采用多模态模仿学习策略，扩展了Action Chunking Transformer（ACT），结合图像、关节状态和力/扭矩传感，实现端到端学习。

Result: 实验证明，该方法在Pick-and-Reorient任务中优于基线，尤其在视觉受限的压制和放置阶段，力/扭矩信号显著提升了任务成功率。

Conclusion: 结合现代模仿学习架构与轻量级力/扭矩传感，为零售环境中扩展机械臂操作提供了实用路径。

Abstract: Manipulator robots are increasingly being deployed in retail environments,
yet contact rich edge cases still trigger costly human teleoperation. A
prominent example is upright lying beverage bottles, where purely visual cues
are often insufficient to resolve subtle contact events required for precise
manipulation. We present a multimodal Imitation Learning policy that augments
the Action Chunking Transformer with force and torque sensing, enabling
end-to-end learning over images, joint states, and forces and torques. Deployed
on Ghost, single-arm platform by Telexistence Inc, our approach improves
Pick-and-Reorient bottle task by detecting and exploiting contact transitions
during pressing and placement. Hardware experiments demonstrate greater task
success compared to baseline matching the observation space of ACT as an
ablation and experiments indicate that force and torque signals are beneficial
in the press and place phases where visual observability is limited, supporting
the use of interaction forces as a complementary modality for contact rich
skills. The results suggest a practical path to scaling retail manipulation by
combining modern imitation learning architectures with lightweight force and
torque sensing.

</details>


### [51] [EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation](https://arxiv.org/abs/2509.23118)
*Zeyi Li,Zhe Tang,Kyeong Soo Kim,Sihao Li,Jeremy S. Smith*

Main category: cs.RO

TL;DR: 本文提出了一种结合Wi-Fi RSSI指纹、LiDAR SLAM和IMU导航的新型室内定位框架，通过EKF融合多传感器数据，显著提升了定位精度，克服了单一方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi指纹定位精度不足，而LiDAR方案成本高且复杂。为了解决这些问题，需要一种既能提供高精度定位又易于部署的解决方案。

Method: 采用DNN进行Wi-Fi粗定位，结合IMU动态定位和Gmapping SLAM生成地图，最后通过EKF融合多传感器数据，抑制Wi-Fi噪声和IMU漂移。

Result: 实验表明，该框架的平均2D误差为0.2449至0.3781米，优于Wi-Fi指纹的1.3404米和LiDAR/IMU的0.6233至2.8803米。

Conclusion: 多传感器融合框架显著提升了定位稳定性和精度，适用于复杂室内环境。

Abstract: Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting
cannot meet the growing demand for accurate indoor localization and navigation
due to its lower accuracy, while solutions based on light detection and ranging
(LiDAR) can provide better localization performance but is limited by their
higher deployment cost and complexity. To address these issues, we propose a
novel indoor localization and navigation framework integrating Wi-Fi RSSI
fingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and
inertial measurement unit (IMU) navigation based on an extended Kalman filter
(EKF). Specifically, coarse localization by deep neural network (DNN)-based
Wi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a
Gmapping-based SLAM to generate an occupancy grid map and output high-frequency
attitude estimates, which is followed by EKF prediction-update integrating
sensor information while effectively suppressing Wi-Fi-induced noise and IMU
drift errors. Multi-group real-world experiments conducted on the IR building
at Xi'an Jiaotong-Liverpool University demonstrates that the proposed
multi-sensor fusion framework suppresses the instability caused by individual
approaches and thereby provides stable accuracy across all path configurations
with mean two-dimensional (2D) errors ranging from 0.2449 m to 0.3781 m. In
contrast, the mean 2D errors of Wi-Fi RSSI fingerprinting reach up to 1.3404 m
in areas with severe signal interference, and those of LiDAR/IMU localization
are between 0.6233 m and 2.8803 m due to cumulative drift.

</details>


### [52] [LAGEA: Language Guided Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.23155)
*Abdul Monaf Chowdhury,Akm Moshiur Rahman Mazumder,Rabeya Akter,Safaeid Hossain Arib*

Main category: cs.RO

TL;DR: LAGEA框架利用自然语言作为反馈信号，通过视觉语言模型（VLM）生成时间锚定的指导，优化强化学习效果，在Meta-World MT10任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操控模型缺乏从自身错误中学习的系统方法，研究自然语言是否能作为反馈信号帮助机器人诊断错误并修正行为。

Method: 提出LAGEA框架，利用VLM生成语言总结和时间锚定的反馈，并将其转化为有界的逐步奖励信号，结合自适应系数优化学习过程。

Result: 在Meta-World MT10基准测试中，LAGEA相比SOTA方法在随机目标和固定目标上平均成功率分别提升9.0%和5.3%，且收敛更快。

Conclusion: 研究表明结构化且时间锚定的语言反馈能有效帮助机器人自我反思并改进决策。

Abstract: Robotic manipulation benefits from foundation models that describe goals, but
today's agents still lack a principled way to learn from their own mistakes. We
ask whether natural language can serve as feedback, an error reasoning signal
that helps embodied agents diagnose what went wrong and correct course. We
introduce LAGEA (Language Guided Embodied Agents), a framework that turns
episodic, schema-constrained reflections from a vision language model (VLM)
into temporally grounded guidance for reinforcement learning. LAGEA summarizes
each attempt in concise language, localizes the decisive moments in the
trajectory, aligns feedback with visual state in a shared representation, and
converts goal progress and feedback agreement into bounded, step-wise shaping
rewardswhose influence is modulated by an adaptive, failure-aware coefficient.
This design yields dense signals early when exploration needs direction and
gracefully recedes as competence grows. On the Meta-World MT10 embodied
manipulation benchmark, LAGEA improves average success over the
state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed
goals, while converging faster. These results support our hypothesis: language,
when structured and grounded in time, is an effective mechanism for teaching
robots to self-reflect on mistakes and make better choices. Code will be
released soon.

</details>


### [53] [Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion](https://arxiv.org/abs/2509.23185)
*Ziyi Zhou,Qian Meng,Hadas Kress-Gazit,Ye Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种用于四足机器人在动态变化、未知地形上运动的集成规划框架，结合符号级控制器和混合整数凸规划（MICP）以实现高效步态规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式或计算密集型优化，限制了鲁棒性和适应性。

Method: 结合反应式合成和MICP步态规划，并通过符号修复机制减少计算开销。

Result: 框架能够识别缺失的运动技能并在安全关键环境中有效响应。

Conclusion: 提出的方法显著提升了四足机器人在复杂动态环境中的适应性和鲁棒性。

Abstract: We present an integrated planning framework for quadrupedal locomotion over
dynamically changing, unforeseen terrains. Existing methods often depend on
heuristics for real-time foothold selection-limiting robustness and
adaptability-or rely on computationally intensive trajectory optimization
across complex terrains and long horizons. In contrast, our approach combines
reactive synthesis for generating correct-by-construction symbolic-level
controllers with mixed-integer convex programming (MICP) for dynamic and
physically feasible footstep planning during each symbolic transition. To
reduce the reliance on costly MICP solves and accommodate specifications that
may be violated due to physical infeasibility, we adopt a symbolic repair
mechanism that selectively generates only the required symbolic transitions.
During execution, real-time MICP replanning based on actual terrain data,
combined with runtime symbolic repair and delay-aware coordination, enables
seamless bridging between offline synthesis and online operation. Through
extensive simulation and hardware experiments, we validate the framework's
ability to identify missing locomotion skills and respond effectively in
safety-critical environments, including scattered stepping stones and rebar
scenarios.

</details>


### [54] [CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation](https://arxiv.org/abs/2509.23203)
*Kai Yang,Tianlin Zhang,Zhengbo Wang,Zedong Chu,Xiaolong Wu,Yang Cai,Mu Xu*

Main category: cs.RO

TL;DR: CE-Nav是一个两阶段（模仿学习后强化学习）框架，通过解耦通用几何推理与特定形态的动态适应，实现了跨不同机器人形态的导航策略泛化，减少了对昂贵数据的需求。


<details>
  <summary>Details</summary>
Motivation: 解决跨机器人形态的通用导航策略问题是关键挑战，现有方法面临数据需求高、规划与控制紧密耦合及多模态决策问题。

Method: CE-Nav通过模仿学习训练一个形态无关的通用专家（VelFlow模型），再利用强化学习训练轻量级动态适应器，快速适应新机器人的动态特性。

Result: 在四足、双足和四旋翼机器人上的实验表明，CE-Nav性能优异且显著降低了适应成本，真实部署验证了其高效性和可扩展性。

Conclusion: CE-Nav是一个高效、可扩展的通用导航解决方案，成功解决了多机器人形态的导航策略泛化问题。

Abstract: Generalizing local navigation policies across diverse robot morphologies is a
critical challenge. Progress is often hindered by the need for costly and
embodiment-specific data, the tight coupling of planning and control, and the
"disastrous averaging" problem where deterministic models fail to capture
multi-modal decisions (e.g., turning left or right). We introduce CE-Nav, a
novel two-stage (IL-then-RL) framework that systematically decouples universal
geometric reasoning from embodiment-specific dynamic adaptation. First, we
train an embodiment-agnostic General Expert offline using imitation learning.
This expert, a conditional normalizing flow model named VelFlow, learns the
full distribution of kinematically-sound actions from a large-scale dataset
generated by a classical planner, completely avoiding real robot data and
resolving the multi-modality issue. Second, for a new robot, we freeze the
expert and use it as a guiding prior to train a lightweight, Dynamics-Aware
Refiner via online reinforcement learning. This refiner rapidly learns to
compensate for the target robot's specific dynamics and controller
imperfections with minimal environmental interaction. Extensive experiments on
quadrupeds, bipeds, and quadrotors show that CE-Nav achieves state-of-the-art
performance while drastically reducing adaptation cost. Successful real-world
deployments further validate our approach as an efficient and scalable solution
for building generalizable navigation systems.

</details>


### [55] [Simulated Annealing for Multi-Robot Ergodic Information Acquisition Using Graph-Based Discretization](https://arxiv.org/abs/2509.23214)
*Benjamin Wong,Aaron Weber,Mohamed M. Safwat,Santosh Devasia,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 论文提出了一种使用模拟退火算法生成目标采样分布的方法，以在多机器人团队中保持各区域相对不确定性一致，从而提高信息获取质量。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多机器人团队在未知噪声水平下如何动态调整采样分布，以实现一致的观测质量。

Method: 通过模拟退火算法，从均匀分布逐步过渡到估计的最优分布，利用Boltzmann分布和采样熵作为能量。

Result: 仿真结果表明，该方法在瞬时和渐进熵上均优于均匀采样和直接遍历搜索，并在TurtleBot群体系统中验证了物理适用性。

Conclusion: 该方法有效提升了多机器人团队在动态环境中的信息获取效率和一致性。

Abstract: One of the goals of active information acquisition using multi-robot teams is
to keep the relative uncertainty in each region at the same level to maintain
identical acquisition quality (e.g., consistent target detection) in all the
regions. To achieve this goal, ergodic coverage can be used to assign the
number of samples according to the quality of observation, i.e., sampling noise
levels. However, the noise levels are unknown to the robots. Although this
noise can be estimated from samples, the estimates are unreliable at first and
can generate fluctuating values. The main contribution of this paper is to use
simulated annealing to generate the target sampling distribution, starting from
uniform and gradually shifting to an estimated optimal distribution, by varying
the coldness parameter of a Boltzmann distribution with the estimated sampling
entropy as energy. Simulation results show a substantial improvement of both
transient and asymptotic entropy compared to both uniform and direct-ergodic
searches. Finally, a demonstration is performed with a TurtleBot swarm system
to validate the physical applicability of the algorithm.

</details>


### [56] [GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking](https://arxiv.org/abs/2509.23220)
*Ye Chen,Zichen Zhou,Jianyu Dou,Te Cui,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: GLUE是一种全局-局部统一编码框架，通过关键补丁跟踪解决复杂分布外环境下视觉表示学习的注意力分散问题，提升模仿学习策略的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在复杂分布外（OOD）环境中，全局视觉表示的注意力可能被干扰，导致策略性能下降。局部表示的任务相关性提供了一种解决方案。

Method: 提出GLUE框架，通过文本引导机制选择并跟踪关键补丁作为局部表示，融合全局和局部特征以生成低异质性局部特征。

Result: GLUE在仿真和真实环境中表现出色，分别超越最强基线17.6%、36.3%，在真实世界泛化任务中提升58.3%。

Conclusion: GLUE通过全局-局部特征融合有效对齐训练和测试分布，显著提升模仿学习策略的鲁棒性和性能。

Abstract: In recent years, visual representation learning has gained widespread
attention in robotic imitation learning. However, in complex
Out-of-Distribution(OOD) settings characterized by clutter and occlusion, the
attention of global visual representations can be diluted or interfered,
leading to degraded policy performance. The invariance of local representations
for task-relevant objects offers a solution. By efficiently utilizing these
local representations, training and testing data can be mapped to a more
similar feature space, thereby mitigating the covariate shift problem.
Accordingly, we propose GLUE, a global-local unified encoding framework for
imitation learning based on key-patch tracking. GLUE selects and tracks
key-patches as critical local representations by employing a text-guided
mechanism. It features a novel fusion framework where global patch features
query local patches to distill essential information, yielding fine-grained
local features with low heterogeneity relative to the global context. This
fused representation steers the robot's visual attention toward task-relevant
objects and preserves precise global context, which together align the training
and testing distributions into a similar and task-informative feature space,
ultimately enhancing the robustness of the imitation learning policy.
Experiments demonstrate that GLUE achieves strong performance across diverse
tasks in both simulation and real-world settings, outperforming the strongest
baseline by 17.6% in simulation, 36.3% in real-world environments, and 58.3% on
real-world generalization settings. The project website of GLUE is available at
https://GLUE666.github.io/.

</details>


### [57] [SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion](https://arxiv.org/abs/2509.23223)
*Aoqian Zhang,Zixuan Zhuang,Chunzheng Wang,Shuzhi Sam Ge,Fan Shi,Cheng Xiang*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人运动控制的切换策略框架，结合力顺应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人控制方法缺乏动物般的自适应和可调顺应性，易受扰动影响。

Method: 采用师生强化学习框架训练具有可调顺应性的策略，并结合基于捕获点的安全策略与可恢复性预测网络。

Result: 实现了四足机器人在严重外部扰动下的力顺应性和稳健安全性。

Conclusion: 该框架成功解决了现有方法在顺应性和安全性上的不足。

Abstract: Quadruped robots are designed to achieve agile locomotion by mimicking legged
animals. However, existing control methods for quadrupeds often lack one of the
key capabilities observed in animals: adaptive and adjustable compliance in
response to external disturbances. Most locomotion controllers do not provide
tunable compliance and tend to fail under large perturbations. In this work, we
propose a switched policy framework for compliant and safe quadruped
locomotion. First, we train a force compliant policy with adjustable compliance
levels using a teacher student reinforcement learning framework, eliminating
the need for explicit force sensing. Next, we develop a safe policy based on
the capture point concept to stabilize the robot when the compliant policy
fails. Finally, we introduce a recoverability network that predicts the
likelihood of failure and switches between the compliant and safe policies.
Together, this framework enables quadruped robots to achieve both force
compliance and robust safety when subjected to severe external disturbances.

</details>


### [58] [Leave No Observation Behind: Real-time Correction for VLA Action Chunks](https://arxiv.org/abs/2509.23224)
*Kohei Sendai,Maxime Alvarez,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: A2C2是一种轻量级的实时动作块校正模块，可提高VLA模型在实时控制中的反应性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型因动作块预测导致的推理延迟和长时任务反应性下降问题。

Method: 通过结合最新观测、基础动作、位置特征和基础策略特征，实时输出每步校正动作。

Result: 在动态Kinetix任务和LIBERO Spatial上，A2C2显著提升了成功率和鲁棒性。

Conclusion: A2C2是一种高效、即插即用的机制，适用于实时控制中的高容量动作块策略。

Abstract: To improve efficiency and temporal coherence, Vision-Language-Action (VLA)
models often predict action chunks; however, this action chunking harms
reactivity under inference delay and long horizons. We introduce Asynchronous
Action Chunk Correction (A2C2), which is a lightweight real-time chunk
correction head that runs every control step and adds a time-aware correction
to any off-the-shelf VLA's action chunk. The module combines the latest
observation, the predicted action from VLA (base action), a positional feature
that encodes the index of the base action within the chunk, and some features
from the base policy, then outputs a per-step correction. This preserves the
base model's competence while restoring closed-loop responsiveness. The
approach requires no retraining of the base policy and is orthogonal to
asynchronous execution schemes such as Real Time Chunking (RTC). On the dynamic
Kinetix task suite (12 tasks) and LIBERO Spatial, our method yields consistent
success rate improvements across increasing delays and execution horizons (+23%
point and +7% point respectively, compared to RTC), and also improves
robustness for long horizons even with zero injected delay. Since the
correction head is small and fast, there is minimal overhead compared to the
inference of large VLA models. These results indicate that A2C2 is an
effective, plug-in mechanism for deploying high-capacity chunking policies in
real-time control.

</details>


### [59] [Online Dynamic Goal Recognition in Gym Environments](https://arxiv.org/abs/2509.23244)
*Shamir Matan,Elhadad Osher,Nageris Ben,Mirsky Reuth*

Main category: cs.RO

TL;DR: 论文介绍了两个开源框架（gr-libs和gr-envs），旨在标准化和目标识别（GR）算法的开发、评估与比较，解决领域内因基准、领域和评估协议不一致导致的分裂问题。


<details>
  <summary>Details</summary>
Motivation: 当前GR领域存在基准、评估标准不统一的问题，影响了研究进展和算法比较。

Method: 提出两个互补的开源框架：gr-libs提供GR算法的模块化实现和评估工具，gr-envs提供适合目标导向行为的Gym兼容环境。

Result: 这两个框架为标准化的GR研究提供了可扩展和可重复的平台，支持动态和目标导向行为的分析。

Conclusion: 开源框架gr-libs和gr-envs为GR研究提供了统一平台，有助于推动领域发展。

Abstract: Goal Recognition (GR) is the task of inferring an agent's intended goal from
partial observations of its behavior, typically in an online and one-shot
setting. Despite recent advances in model-free GR, particularly in applications
such as human-robot interaction, surveillance, and assistive systems, the field
remains fragmented due to inconsistencies in benchmarks, domains, and
evaluation protocols.
  To address this, we introduce gr-libs
(https://github.com/MatanShamir1/gr_libs) and gr-envs
(https://github.com/MatanShamir1/gr_envs), two complementary open-source
frameworks that support the development, evaluation, and comparison of GR
algorithms in Gym-compatible environments. gr-libs includes modular
implementations of MDP-based GR baselines, diagnostic tools, and evaluation
utilities. gr-envs provides a curated suite of environments adapted for dynamic
and goal-directed behavior, along with wrappers that ensure compatibility with
standard reinforcement learning toolkits. Together, these libraries offer a
standardized, extensible, and reproducible platform for advancing GR research.
Both packages are open-source and available on GitHub and PyPI.

</details>


### [60] [Preventing Robotic Jailbreaking via Multimodal Domain Adaptation](https://arxiv.org/abs/2509.23281)
*Francesco Marchiori,Rohan Sinha,Christopher Agia,Alexander Robey,George J. Pappas,Mauro Conti,Marco Pavone*

Main category: cs.RO

TL;DR: 论文提出了J-DAPT框架，用于检测多模态越狱攻击，通过注意力融合和域适应提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs和VLMs在机器人环境中易受越狱攻击，数据驱动防御在机器人领域因数据集稀缺而泛化能力不足。

Method: J-DAPT通过注意力融合和多模态嵌入（文本和视觉），结合领域适配来提高检测能力。

Result: 评估表明J-DAPT在多个机器人应用中将检测准确率提升至近100％，且开销极小。

Conclusion: J-DAPT为机器人应用中的VLMs提供了实用的防御方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) are
increasingly deployed in robotic environments but remain vulnerable to
jailbreaking attacks that bypass safety mechanisms and drive unsafe or
physically harmful behaviors in the real world. Data-driven defenses such as
jailbreak classifiers show promise, yet they struggle to generalize in domains
where specialized datasets are scarce, limiting their effectiveness in robotics
and other safety-critical contexts. To address this gap, we introduce J-DAPT, a
lightweight framework for multimodal jailbreak detection through
attention-based fusion and domain adaptation. J-DAPT integrates textual and
visual embeddings to capture both semantic intent and environmental grounding,
while aligning general-purpose jailbreak datasets with domain-specific
reference data. Evaluations across autonomous driving, maritime robotics, and
quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100%
with minimal overhead. These results demonstrate that J-DAPT provides a
practical defense for securing VLMs in robotic applications. Additional
materials are made available at: https://j-dapt.github.io.

</details>


### [61] [A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier](https://arxiv.org/abs/2509.23288)
*Yafes Enes Şahiner,Esat Yusuf Gündoğdu,Volkan Sezer*

Main category: cs.RO

TL;DR: 本文提出了一种新型采样器，利用占用栅格地图确定性地识别狭窄通道环境，并增加这些区域的采样量，显著提高了路径规划的性能。


<details>
  <summary>Details</summary>
Motivation: 自主技术中的路径规划在狭窄通道环境中存在普遍问题，现有方法性能不佳。

Method: 提出一种新型采样器，通过占用栅格地图确定性地识别狭窄通道，并针对性增加采样量。

Result: 实验表明，该算法在规划时间和里程碑数量上优于基线采样器。

Conclusion: 该算法为狭窄通道环境下的路径规划提供了更高效的解决方案。

Abstract: Autonomous technology, which has become widespread today, appears in many
different configurations such as mobile robots, manipulators, and drones. One
of the most important tasks of these vehicles during autonomous operations is
path planning. In the literature, path planners are generally divided into two
categories: probabilistic and deterministic methods. In the analysis of
probabilistic methods, the common problem of almost all methods is observed in
narrow passage environments. In this paper, a novel sampler is proposed that
deterministically identifies narrow passage environments using occupancy grid
maps and accordingly increases the amount of sampling in these regions. The
codes of the algorithm is provided as open source. To evaluate the performance
of the algorithm, benchmark studies are conducted in three distinct categories:
specific and random simulation environments, and a real-world environment. As a
result, it is observed that our algorithm provides higher performance in
planning time and number of milestones compared to the baseline samplers.

</details>


### [62] [Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment](https://arxiv.org/abs/2509.23308)
*Jun Chen,Jiaqing Ma,Philip Dames*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的运动规划算法框架，整合前沿探索、覆盖保证和多目标追踪策略，优化非凸环境中机器人探索与追踪任务。


<details>
  <summary>Details</summary>
Motivation: 解决非凸环境中机器人同时探索、搜索和追踪目标的挑战，满足环境监测和救援等应用需求。

Method: 结合前沿探索策略、Lloyd算法覆盖保证策略和传感器多目标追踪策略。

Result: MATLAB仿真验证了算法的有效性和优越性。

Conclusion: 提出的框架能平衡探索中的覆盖搜索与高精度主动追踪，优于标准方法。

Abstract: In unknown non-convex environments, such as indoor and underground spaces,
deploying a fleet of robots to explore the surroundings while simultaneously
searching for and tracking targets of interest to maintain high-precision data
collection represents a fundamental challenge that urgently requires resolution
in applications such as environmental monitoring and rescue operations. Current
research has made significant progress in addressing environmental exploration,
information search, and target tracking problems, but has yet to establish a
framework for simultaneously optimizing these tasks in complex environments. In
this paper, we propose a novel motion planning algorithm framework that
integrates three control strategies: a frontier-based exploration strategy, a
guaranteed coverage strategy based on Lloyd's algorithm, and a sensor-based
multi-target tracking strategy. By incorporating these three strategies, the
proposed algorithm balances coverage search and high-precision active tracking
during exploration. Our approach is validated through a series of MATLAB
simulations, demonstrating validity and superiority over standard approaches.

</details>


### [63] [GUARD: Toward a Compromise between Traditional Control and Learning for Safe Robot Systems](https://arxiv.org/abs/2509.23312)
*Johannes A. Gaus,Junheon Yoon,Woo-Jeong Baek,Seungwon Choi,Suhan Park,Jaeheung Park*

Main category: cs.RO

TL;DR: GUARD框架结合传统控制与不确定性感知技术，通过主动学习和实时能力实现机器人安全避障。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法与学习算法之间的平衡问题，推动安全、高效且灵活的机器人应用发展。

Method: 结合反应式模型预测控制(RMPCC)和迭代最近点(ICP)算法，通过概率核优化技术实现实时不确定性来源识别。

Result: 实验证明GUARD性能优越，凸显其广泛应用的必要性。

Conclusion: GUARD成功解决了机器人安全性的模糊性问题，为未来的应用拓展提供了基础。

Abstract: This paper presents the framework \textbf{GUARD} (\textbf{G}uided robot
control via \textbf{U}ncertainty attribution and prob\textbf{A}bilistic kernel
optimization for \textbf{R}isk-aware \textbf{D}ecision making) that combines
traditional control with an uncertainty-aware perception technique using active
learning with real-time capability for safe robot collision avoidance. By doing
so, this manuscript addresses the central challenge in robotics of finding a
reasonable compromise between traditional methods and learning algorithms to
foster the development of safe, yet efficient and flexible applications. By
unifying a reactive model predictive countouring control (RMPCC) with an
Iterative Closest Point (ICP) algorithm that enables the attribution of
uncertainty sources online using active learning with real-time capability via
a probabilistic kernel optimization technique, \emph{GUARD} inherently handles
the existing ambiguity of the term \textit{safety} that exists in robotics
literature. Experimental studies indicate the high performance of \emph{GUARD},
thereby highlighting the relevance and need to broaden its applicability in
future.

</details>


### [64] [Space Robotics Bench: Robot Learning Beyond Earth](https://arxiv.org/abs/2509.23328)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: Space Robotics Bench是一个开源模拟框架，旨在通过模块化架构和大规模并行仿真环境支持机器人学习在太空领域的应用，解决数据稀缺和技术演示成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 太空探索需要能在极端外星环境下运行的自主系统，但机器人学习在该领域的应用因高成本和数据稀缺受到限制。

Method: 提出Space Robotics Bench框架，结合按需程序生成和大规模并行仿真环境，创建多样化的训练数据分布，并提供基准任务套件。

Result: 通过标准强化学习算法建立性能基线，揭示当前方法的局限性，验证框架能生成适用于现实世界的策略。

Conclusion: Space Robotics Bench为开发、评估和部署太空自主系统提供了宝贵资源。

Abstract: The growing ambition for space exploration demands robust autonomous systems
that can operate in unstructured environments under extreme extraterrestrial
conditions. The adoption of robot learning in this domain is severely hindered
by the prohibitive cost of technology demonstrations and the limited
availability of data. To bridge this gap, we introduce the Space Robotics
Bench, an open-source simulation framework for robot learning in space. It
offers a modular architecture that integrates on-demand procedural generation
with massively parallel simulation environments to support the creation of vast
and diverse training distributions for learning-based agents. To ground
research and enable direct comparison, the framework includes a comprehensive
suite of benchmark tasks that span a wide range of mission-relevant scenarios.
We establish performance baselines using standard reinforcement learning
algorithms and present a series of experimental case studies that investigate
key challenges in generalization, end-to-end learning, adaptive control, and
sim-to-real transfer. Our results reveal insights into the limitations of
current methods and demonstrate the utility of the framework in producing
policies capable of real-world operation. These contributions establish the
Space Robotics Bench as a valuable resource for developing, benchmarking, and
deploying the robust autonomous systems required for the final frontier.

</details>


### [65] [Robust Orientation Estimation with TRIAD-aided Manifold EKF](https://arxiv.org/abs/2509.23456)
*Arjun Sadananda,Ravi Banavar,Kavi Arya*

Main category: cs.RO

TL;DR: 论文提出了一种结合TRIAD算法和Manifold EKF的方法，以减少磁力计对俯仰和横滚轴姿态确定的干扰。


<details>
  <summary>Details</summary>
Motivation: 磁力计作为姿态确定的传感器容易受到校准和外部磁场的干扰，影响Manifold EKF的精度。TRIAD算法虽然次优，但在特定情况下可以有效减轻这种干扰。

Method: 通过将TRIAD算法的次优特性融入Manifold EKF中，减少磁力计读数在俯仰和横滚轴确定中的影响。

Result: 实验验证了该方法在减轻磁力计干扰方面的有效性。

Conclusion: 结合TRIAD的Manifold EKF方法能够有效提升姿态确定的鲁棒性。

Abstract: The manifold extended Kalman filter (Manifold EKF) has found extensive
application for attitude determination. Magnetometers employed as sensors for
such attitude determination are easily prone to disturbances by their
sensitivity to calibration and external magnetic fields. The TRIAD (Tri-Axial
Attitude Determination) algorithm is well known as a sub-optimal attitude
estimator. In this article, we incorporate this sub-optimal feature of the
TRIAD in mitigating the influence of the magnetometer reading in the pitch and
roll axis determination in the Manifold EKF algorithm. We substantiate our
results with experiments.

</details>


### [66] [Multi-Modal Manipulation via Multi-Modal Policy Consensus](https://arxiv.org/abs/2509.23468)
*Haonan Chen,Jiaming Xu,Hongyu Chen,Kaiwen Hong,Binghao Huang,Chaoqi Liu,Jiayuan Mao,Yunzhu Li,Yilun Du,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 论文提出了一种通过分解策略为多个扩散模型并利用路由网络动态整合多模态信息的创新方法，显著优于传统特征拼接方法，并在多模态推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中多模态信息整合的不足，传统特征拼接方法易受主导模态（如视觉）影响，且无法灵活处理新模态或缺失模态。

Method: 将策略分解为一组专门处理单个模态（如视觉或触觉）的扩散模型，并通过学习权重来动态组合各模态的贡献。

Result: 在仿真和真实世界的机器人操作任务中，该方法显著优于基线，展现出对物理扰动和传感器损坏的鲁棒性。

Conclusion: 该方法在多模态整合上具有优势，适用于复杂机器人操作任务，并能自适应不同模态的重要性。

Abstract: Effectively integrating diverse sensory modalities is crucial for robotic
manipulation. However, the typical approach of feature concatenation is often
suboptimal: dominant modalities such as vision can overwhelm sparse but
critical signals like touch in contact-rich tasks, and monolithic architectures
cannot flexibly incorporate new or missing modalities without retraining. Our
method factorizes the policy into a set of diffusion models, each specialized
for a single representation (e.g., vision or touch), and employs a router
network that learns consensus weights to adaptively combine their
contributions, enabling incremental of new representations. We evaluate our
approach on simulated manipulation tasks in {RLBench}, as well as real-world
tasks such as occluded object picking, in-hand spoon reorientation, and puzzle
insertion, where it significantly outperforms feature-concatenation baselines
on scenarios requiring multimodal reasoning. Our policy further demonstrates
robustness to physical perturbations and sensor corruption. We further conduct
perturbation-based importance analysis, which reveals adaptive shifts between
modalities.

</details>


### [67] [Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic](https://arxiv.org/abs/2509.23506)
*Dan BW Choe,Sundhar Vinodh Sangeetha,Steven Emanuel,Chih-Yuan Chiu,Samuel Coogan,Shreyas Kousik*

Main category: cs.RO

TL;DR: 该论文提出了一种分散式框架，通过自然语言和逻辑翻译实现异构机器人团队的无缝协作，显著优于传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在仓储等领域的广泛应用，异构机器人团队之间的协作需求增加，需要解决突发冲突。

Method: 采用基于大型语言模型的分散式框架，结合自然语言请求和信号时态逻辑翻译，通过混合整数线性规划解决问题。

Result: 实验表明，该方法显著优于选择最近可用机器人等启发式方法，且性能接近集中式基线。

Conclusion: 该框架为异构机器人团队的高效协作提供了一种轻量级且有效的解决方案。

Abstract: Increased robot deployment, such as in warehousing, has revealed a need for
seamless collaboration among heterogeneous robot teams to resolve unforeseen
conflicts. To address this challenge, we propose a novel decentralized
framework that enables robots to request and provide help. The process begins
when a robot detects a conflict and uses a Large Language Model (LLM) to decide
whether external assistance is required. If so, it crafts and broadcasts a
natural language (NL) help request. Potential helper robots reason over the
request and respond with offers of assistance, including information about the
effect on their ongoing tasks. Helper reasoning is implemented via an LLM
grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar,
ensuring syntactically valid NL-to-STL translations, which are then solved as a
Mixed Integer Linear Program (MILP). Finally, the requester robot selects a
helper by reasoning over the expected increase in system-level total task
completion time. We evaluated our framework through experiments comparing
different helper-selection strategies and found that considering multiple
offers allows the requester to minimize added makespan. Our approach
significantly outperforms heuristics such as selecting the nearest available
candidate helper robot, and achieves performance comparable to a centralized
"Oracle" baseline but without heavy information demands.

</details>


### [68] [Zero-shot Whole-Body Manipulation with a Large-Scale Soft Robotic Torso via Guided Reinforcement Learning](https://arxiv.org/abs/2509.23556)
*Curtis C. Johnson,Carlo Alessi,Egidio Falotico,Marc D. Killpack*

Main category: cs.RO

TL;DR: 该论文提出了一种高效的仿真方法，支持软机器人全身操控任务的快速仿真与控制，并通过零次模拟到现实的策略转移，在硬件平台上实现了88%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有软机器人在全身操控任务中存在动力学和运动学不确定性，仿真和控制面临挑战。论文旨在解决这些问题，展示高效仿真和学习策略的实际应用。

Method: 使用MuJoCo实现高速仿真（最高350倍实时速度），结合简单运动原语引导强化学习，优化全身操控策略。

Result: 在Baloo硬件平台上实现了88%的成功率，策略表现出反应行为（如重新抓取和扰动恢复），且在扰动下显示出过修正行为。

Conclusion: 论文首次展示了软机器人六自由度全身操控的实际应用，证明了高效仿真和学习策略的有效性，为零次模拟到现实的转移提供了成功案例。

Abstract: Whole-body manipulation is a powerful yet underexplored approach that enables
robots to interact with large, heavy, or awkward objects using more than just
their end-effectors. Soft robots, with their inherent passive compliance, are
particularly well-suited for such contact-rich manipulation tasks, but their
uncertainties in kinematics and dynamics pose significant challenges for
simulation and control. In this work, we address this challenge with a
simulation that can run up to 350x real time on a single thread in MuJoCo and
provide a detailed analysis of the critical tradeoffs between speed and
accuracy for this simulation. Using this framework, we demonstrate a successful
zero-shot sim-to-real transfer of a learned whole-body manipulation policy,
achieving an 88% success rate on the Baloo hardware platform. We show that
guiding RL with a simple motion primitive is critical to this success where
standard reward shaping methods struggled to produce a stable and successful
policy for whole-body manipulation. Furthermore, our analysis reveals that the
learned policy does not simply mimic the motion primitive. It exhibits
beneficial reactive behavior, such as re-grasping and perturbation recovery. We
analyze and contrast this learned policy against an open-loop baseline to show
that the policy can also exhibit aggressive over-corrections under
perturbation. To our knowledge, this is the first demonstration of forceful,
six-DoF whole-body manipulation using two continuum soft arms on a large-scale
platform (10 kg payloads), with zero-shot policy transfer.

</details>


### [69] [High Torque Density PCB Axial Flux Permanent Magnet Motor for Micro Robots](https://arxiv.org/abs/2509.23561)
*Jianren Wang,Jie Han,Abhinav Gupta,Deepak Pathak,Yang Zhang*

Main category: cs.RO

TL;DR: 微尺度轴向磁通永磁电机（AFPM）采用PCB绕组技术，实现高铜填充率，提升扭矩性能。


<details>
  <summary>Details</summary>
Motivation: 传统QDD驱动机器人需要高扭矩、低速度的电机，但微尺度下铜填充率不足限制了性能。

Method: 利用HDI技术制造的48层PCB绕组，实现45%铜填充率，设计并测试原型。

Result: 电机厚度仅5mm，直径19mm，性能通过实验验证。

Conclusion: PCB绕组技术解决了微尺度AFPM电机的性能瓶颈，为小型机器人提供高效驱动方案。

Abstract: Quasi-direct-drive (QDD) actuation is transforming legged and manipulator
robots by eliminating high-ratio gearboxes, yet it demands motors that deliver
very high torque at low speed within a thin, disc-shaped joint envelope.
Axial-flux permanent-magnet (AFPM) machines meet these geometric and torque
requirements, but scaling them below a 20mm outer diameter is hampered by poor
copper fill in conventional wound stators, inflating resistance and throttling
continuous torque. This paper introduces a micro-scale AFPM motor that
overcomes these limitations through printed-circuit-board (PCB) windings
fabricated with advanced IC-substrate high-density interconnect (HDI)
technology. The resulting 48-layer stator-formed by stacking four 12-layer HDI
modules-achieves a record 45\% copper fill in a package only 5mm thick and 19mm
in diameter. We perform comprehensive electromagnetic and thermal analyses to
inform the motor design, then fabricate a prototype whose performance
characteristics are experimentally verified.

</details>


### [70] [RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation](https://arxiv.org/abs/2509.23563)
*Seungchan Kim,Omar Alama,Dmytro Kurdydyk,John Keller,Nikhil Keetha,Wenshan Wang,Yonatan Bisk,Sebastian Scherer*

Main category: cs.RO

TL;DR: RAVEN是一个基于行为树的3D语义导航框架，用于无人机在非结构化户外环境中进行语义导航，通过结合长期规划和短期反应行为，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语义导航方法在户外环境中存在局限性，要么依赖短视的响应策略，要么无法适应实时部署需求。RAVEN旨在解决这些问题，提供一种能够在大型非结构化环境中高效导航的解决方案。

Method: RAVEN采用空间一致的语义体素射线地图作为持久记忆，结合短期体素搜索和长期射线搜索，并利用视觉语言模型提供辅助提示。这些组件通过行为树协调，实现自适应行为切换。

Result: RAVEN在10个逼真的户外仿真环境中进行了100个语义任务的测试，性能超过基线方法85.25%，并在实际无人机部署中验证了其可行性。

Conclusion: RAVEN通过创新的记忆框架和行为树协调机制，显著提升了无人机在户外环境中的语义导航能力，具有实际应用潜力。

Abstract: Aerial outdoor semantic navigation requires robots to explore large,
unstructured environments to locate target objects. Recent advances in semantic
navigation have demonstrated open-set object-goal navigation in indoor
settings, but these methods remain limited by constrained spatial ranges and
structured layouts, making them unsuitable for long-range outdoor search. While
outdoor semantic navigation approaches exist, they either rely on reactive
policies based on current observations, which tend to produce short-sighted
behaviors, or precompute scene graphs offline for navigation, limiting
adaptability to online deployment. We present RAVEN, a 3D memory-based,
behavior tree framework for aerial semantic navigation in unstructured outdoor
environments. It (1) uses a spatially consistent semantic voxel-ray map as
persistent memory, enabling long-horizon planning and avoiding purely reactive
behaviors, (2) combines short-range voxel search and long-range ray search to
scale to large environments, (3) leverages a large vision-language model to
suggest auxiliary cues, mitigating sparsity of outdoor targets. These
components are coordinated by a behavior tree, which adaptively switches
behaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor
simulation environments over 100 semantic tasks, encompassing single-object
search, multi-class, multi-instance navigation and sequential task changes.
Results show RAVEN outperforms baselines by 85.25% in simulation and
demonstrate its real-world applicability through deployment on an aerial robot
in outdoor field tests.

</details>


### [71] [GES-UniGrasp: A Two-Stage Dexterous Grasping Strategy With Geometry-Based Expert Selection](https://arxiv.org/abs/2509.23567)
*Fangting Xu,Jilin Zhu,Xiaoming Gu,Jianzhong Tang*

Main category: cs.RO

TL;DR: 提出了一种基于几何聚类的专家选择框架ContactGrasp，用于实现类人化抓取，表现出高成功率和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有强化学习方法抓取姿势不自然的问题，提升机器人抓取的自然性和适应性。

Method: 构建了一个包含773个对象的抓取数据集，并通过几何聚类和两阶段专家选择框架（GES）实现多样化抓取。

Result: 在训练集和测试集上分别达到99.4%和96.3%的成功率，展现了强泛化能力和高质量抓取。

Conclusion: ContactGrasp数据集结合GES框架能有效提升抓取的自然性和适应性，适用于多样化对象形状。

Abstract: Robust and human-like dexterous grasping of general objects is a critical
capability for advancing intelligent robotic manipulation in real-world
scenarios. However, existing reinforcement learning methods guided by grasp
priors often result in unnatural behaviors. In this work, we present
\textit{ContactGrasp}, a robotic dexterous pre-grasp and grasp dataset that
explicitly accounts for task-relevant wrist orientation and thumb-index
pinching coordination. The dataset covers 773 objects in 82 categories,
providing a rich foundation for training human-like grasp strategies. Building
upon this dataset, we perform geometry-based clustering to group objects by
shape, enabling a two-stage Geometry-based Expert Selection (GES) framework
that selects among specialized experts for grasping diverse object geometries,
thereby enhancing adaptability to diverse shapes and generalization across
categories. Our approach demonstrates natural grasp postures and achieves high
success rates of 99.4\% and 96.3\% on the train and test sets, respectively,
showcasing strong generalization and high-quality grasp execution.

</details>


### [72] [Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints](https://arxiv.org/abs/2509.23575)
*Jianshu Hu,Lidi Wang,Shujia Li,Yunpeng Jiang,Xiao Li,Paul Weng,Yutong Ban*

Main category: cs.RO

TL;DR: 提出了CLAP框架，通过任务分解、VLM微调3D关键点预测和3D感知表示，提升了3D操纵任务的泛化能力，在仿真和实际实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有分层策略在泛化新指令和环境变化时存在不足，CLAP旨在通过语言对齐和任务分解提升泛化能力。

Method: CLAP框架整合任务分解、VLM微调3D关键点预测和3D感知表示，以提高泛化能力。

Result: 在GemBench上，CLAP平均成功率比SOTA高12%，且仅需1/5的训练数据；真实实验中，仅10次演示训练即可泛化到新指令和环境。

Conclusion: CLAP在3D操纵任务中展现出优异的泛化性能，尤其是在样本效率上表现突出。

Abstract: Hierarchical coarse-to-fine policy, where a coarse branch predicts a region
of interest to guide a fine-grained action predictor, has demonstrated
significant potential in robotic 3D manipulation tasks by especially enhancing
sample efficiency and enabling more precise manipulation. However, even
augmented with pre-trained models, these hierarchical policies still suffer
from generalization issues. To enhance generalization to novel instructions and
environment variations, we propose Coarse-to-fine Language-Aligned manipulation
Policy (CLAP), a framework that integrates three key components: 1) task
decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware
representation. Through comprehensive experiments in simulation and on a real
robot, we demonstrate its superior generalization capability. Specifically, on
GemBench, a benchmark designed for evaluating generalization, our approach
achieves a 12\% higher average success rate than the SOTA method while using
only 1/5 of the training trajectories. In real-world experiments, our policy,
trained on only 10 demonstrations, successfully generalizes to novel
instructions and environments.

</details>


### [73] [Encoding Material Safety using Control Barrier Functions for Soft Actuator Control](https://arxiv.org/abs/2509.23623)
*Nicholas Pagliocca,Behrad Koohbor,Mitja Trkov*

Main category: cs.RO

TL;DR: 论文提出了基于应变能函数的软体机器人材料安全正式定义，并通过高阶控制屏障函数（HOCBF）实现安全控制。


<details>
  <summary>Details</summary>
Motivation: 随着软体机器人反馈控制的应用增多，亟需明确安全定义及其失效机制，以设计可证明安全的控制器。

Method: 利用应变能函数定义材料安全，通过HOCBF和二次规划反馈控制实现安全约束。

Result: 仿真验证了该方法能够有效执行材料安全规范。

Conclusion: 通过明确安全定义和控制方法，提升了软体机器人设计的可靠性。

Abstract: Until recently, the concept of soft robot safety was an informal notion,
often attributed solely to the fact that soft robots are less likely to damage
their operating environment than rigid robots. As the field moves toward
feedback control for practical applications, it becomes increasingly important
to define what safety means and to characterize how soft robots can become
unsafe. The unifying theme of soft robotics is to achieve useful functionality
through deformation. Consequently, limitations in constitutive model accuracy
and risks of material failure are inherent to all soft robots and pose a key
challenge in designing provably safe controllers. This work introduces a formal
definition of material safety based on strain energy functions and provides a
controller that enforces it. We characterize safe and unsafe sets of an
incompressible hyperelastic material and demonstrate that safety can be
enforced using a high-order control barrier function (HOCBF) with quadratic
program-based feedback control. As a case study, we consider a pressurized
hyperelastic tube with inertial effects, first-order viscous effects, and
full-state feedback. Simulation results verify that the proposed methodology
can enforce the material safety specification.

</details>


### [74] [KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion](https://arxiv.org/abs/2509.23650)
*Peizhuo Li,Hongyi Li,Yuxuan Ma,Linnan Chang,Xinrong Yang,Ruiqi Yu,Yifeng Zhang,Yuhong Cao,Qiuguo Zhu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出了一种名为KiVi的框架，通过结合本体感觉和视觉感知，使四足机器人在复杂环境中稳定移动。


<details>
  <summary>Details</summary>
Motivation: 解决视觉信息易受遮挡、反光和光照变化影响的问题，通过动物感测运动整合的灵感，提升机器人的适应性。

Method: KiVi框架分离本体感觉和视觉推理路径，利用本体感觉作为稳定基础，选择性结合视觉用于地形感知和避障。

Result: 实验表明，该方法使机器人能在多样地形中稳定移动，并对训练中未见过的视觉噪声和遮挡保持鲁棒性。

Conclusion: KiVi框架有效提升了四足机器人在真实世界环境中的稳定性和适应性。

Abstract: Vision-based locomotion has shown great promise in enabling legged robots to
perceive and adapt to complex environments. However, visual information is
inherently fragile, being vulnerable to occlusions, reflections, and lighting
changes, which often cause instability in locomotion. Inspired by animal
sensorimotor integration, we propose KiVi, a Kinesthetic-Visuospatial
integration framework, where kinesthetics encodes proprioceptive sensing of
body motion and visuospatial reasoning captures visual perception of
surrounding terrain. Specifically, KiVi separates these pathways, leveraging
proprioception as a stable backbone while selectively incorporating vision for
terrain awareness and obstacle avoidance. This modality-balanced, yet
integrative design, combined with memory-enhanced attention, allows the robot
to robustly interpret visual cues while maintaining fallback stability through
proprioception. Extensive experiments show that our method enables quadruped
robots to stably traverse diverse terrains and operate reliably in unstructured
outdoor environments, remaining robust to out-of-distribution (OOD) visual
noise and occlusion unseen during training, thereby highlighting its
effectiveness and applicability to real-world legged locomotion.

</details>


### [75] [HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot](https://arxiv.org/abs/2509.23651)
*Xinrong Yang,Peizhuo Li,Hongyi Li,Junkai Lu,Linnan Chang,Yuhong Cao,Yifeng Zhang,Ge Sun,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 该论文提出了一种名为HeLoM的层次化全身操纵框架，用于六足机器人在处理重量或形状不规则物体时实现高效的非抓取式推动。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在现实环境中移动或操纵与自身重量相当的物体，推动作为一种直接的且高效的非抓取式操纵策略，避免了复杂的抓取设计，但需要足够的操纵力和稳定性。

Method: HeLoM框架采用基于学习的层次化设计，高层规划推动行为和目标位姿，低层控制器维持运动稳定性并生成动态一致的关节动作，灵感来源于多足昆虫的协作策略。

Result: 框架在仿真中训练后直接部署到真实机器人上，无需额外微调，能够稳定推动不同尺寸和未知物理特性的箱子到目标位姿。

Conclusion: HeLoM框架通过协调多肢控制和动态接触力分配，成功实现了机器人高效且稳定的推动操作。

Abstract: Robots in real-world environments are often required to move/manipulate
objects comparable in weight to their own bodies. Compared to grasping and
carrying, pushing provides a more straightforward and efficient non-prehensile
manipulation strategy, avoiding complex grasp design while leveraging direct
contact to regulate an object's pose. Achieving effective pushing, however,
demands both sufficient manipulation forces and the ability to maintain
stability, which is particularly challenging when dealing with heavy or
irregular objects. To address these challenges, we propose HeLoM, a
learning-based hierarchical whole-body manipulation framework for a hexapod
robot that exploits coordinated multi-limb control. Inspired by the cooperative
strategies of multi-legged insects, our framework leverages redundant contact
points and high degrees of freedom to enable dynamic redistribution of contact
forces. HeLoM's high-level planner plans pushing behaviors and target object
poses, while its low-level controller maintains locomotion stability and
generates dynamically consistent joint actions. Our policies trained in
simulation are directly deployed on real robots without additional fine-tuning.
This design allows the robot to maintain balance while exerting continuous and
controllable pushing forces through coordinated foreleg interaction and
supportive hind-leg propulsion. We validate the effectiveness of HeLoM through
both simulation and real-world experiments. Results show that our framework can
stably push boxes of varying sizes and unknown physical properties to
designated goal poses in the real world.

</details>


### [76] [Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models](https://arxiv.org/abs/2509.23655)
*Rokas Bendikas,Daniel Dijkman,Markus Peschl,Sanjay Haresh,Pietro Mazzaglia*

Main category: cs.RO

TL;DR: Oat-VLA提出了一种基于对象中心化的视觉语言动作模型，通过减少视觉标记数量显著提升训练效率，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 适应预训练视觉语言模型（VLM）到机器人领域通常计算成本高，主要问题在于视觉输入的标记化方案。

Method: 提出了Oat-VLA，一种面向对象和机器人自身的视觉标记化方法，利用对象中心化表示学习的洞察。

Result: Oat-VLA能将视觉标记数量减少至极少，且收敛速度至少是OpenVLA的两倍，在LIBERO套件和现实任务中表现更优。

Conclusion: Oat-VLA通过高效的标记化方案显著降低了训练成本，同时保持了高性能，为机器人操作任务提供了更高效的方法。

Abstract: Vision-Language-Action (VLA) models offer a pivotal approach to learning
robotic manipulation at scale by repurposing large pre-trained
Vision-Language-Models (VLM) to output robotic actions. However, adapting VLMs
for robotic domains comes with an unnecessarily high computational cost, which
we attribute to the tokenization scheme of visual inputs. In this work, we aim
to enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric
Tokenization for VLAs. Building on the insights of object-centric
representation learning, our method introduces an inductive bias towards scene
objects and the agent's own visual information. As a result, we find that
Oat-VLA can drastically reduce the number of visual tokens to just a few tokens
without sacrificing performance. We reveal that Oat-VLA converges at least
twice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in
diverse real-world pick and place tasks.

</details>


### [77] [Certifiably Optimal State Estimation and Robot Calibration Using Trace-Constrained SDP](https://arxiv.org/abs/2509.23656)
*Liangting Wu,Roberto Tron*

Main category: cs.RO

TL;DR: 该论文提出了一种针对机器人学中非凸问题的凸松弛方法，通过半定规划（SDP）和固定迹约束实现全局最优解，并通过梯度细化程序进一步提升解的质量。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学中非凸问题的全局最优解需求，同时保证解的实用性和高效性。

Method: 使用固定迹约束的半定规划（SDP）方法，结合梯度细化程序，将松弛的解优化为低秩解。

Result: 该方法在PnP估计、手眼标定和双机器人系统标定等任务中表现出高效性和实用性。

Conclusion: 固定迹约束的SDP框架为机器人学任务提供了有效的解决方案，并具有广泛的适用性。

Abstract: Many nonconvex problems in robotics can be relaxed into convex formulations
via semidefinite programming (SDP), which offers the advantage of global
optimality. The practical quality of these solutions, however, critically
depends on achieving rank-1 matrices, a condition that typically requires
additional tightening. In this work, we focus on trace-constrained SDPs, where
the decision variables are positive semidefinite (PSD) matrices with fixed
trace values. These additional constraints not only capture important
structural properties but also facilitate first-order methods for recovering
rank-1 solutions. We introduce customized fixed-trace variables and constraints
to represent common robotic quantities such as rotations and translations,
which can be exactly recovered when the corresponding variables are rank-1. To
further improve practical performance, we develop a gradient-based refinement
procedure that projects relaxed SDP solutions toward rank-1, low-cost
candidates, which can then be certified for global optimality via the dual
problem. We demonstrate that many robotics tasks can be expressed within this
trace-constrained SDP framework, and showcase its effectiveness through
simulations in perspective-n-point (PnP) estimation, hand-eye calibration, and
dual-robot system calibration. To support broader use, we also introduce a
modular ``virtual robot'' abstraction that simplifies modeling across different
problem settings.

</details>


### [78] [MDCPP: Multi-robot Dynamic Coverage Path Planning for Workload Adaptation](https://arxiv.org/abs/2509.23705)
*Jun Chen,Mingjia Chen,Shinkyu Park*

Main category: cs.RO

TL;DR: 论文提出了一种新的多机器人动态覆盖路径规划（MDCPP）算法，通过动态调整机器人速度和工作负载分配，提高了覆盖任务的效率和均衡性。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设机器人速度固定，导致实际应用中工作负载不均和任务完成时间增加。

Method: MDCPP利用高斯混合模型估计工作负载，并通过容量受限的Voronoi图分配覆盖区域，还开发了分布式实现。

Result: 仿真结果显示，MDCPP在性能上优于现有算法，且通信范围对覆盖效率有显著影响。

Conclusion: MDCPP在动态任务分配和工作负载均衡方面表现出色，适合实际应用需求。

Abstract: Multi-robot Coverage Path Planning (MCPP) addresses the problem of computing
paths for multiple robots to effectively cover a large area of interest.
Conventional approaches to MCPP typically assume that robots move at fixed
velocities, which is often unrealistic in real-world applications where robots
must adapt their speeds based on the specific coverage tasks assigned to
them.Consequently, conventional approaches often lead to imbalanced workload
distribution among robots and increased completion time for coverage tasks. To
address this, we introduce a novel Multi-robot Dynamic Coverage Path Planning
(MDCPP) algorithm for complete coverage in two-dimensional environments. MDCPP
dynamically estimates each robot's remaining workload by approximating the
target distribution with Gaussian mixture models, and assigns coverage regions
using a capacity-constrained Voronoi diagram. We further develop a distributed
implementation of MDCPP for range-constrained robotic networks. Simulation
results validate the efficacy of MDCPP, showing qualitative improvements and
superior performance compared to an existing sweeping algorithm, and a
quantifiable impact of communication range on coverage efficiency.

</details>


### [79] [DA-MMP: Learning Coordinated and Accurate Throwing with Dynamics-Aware Motion Manifold Primitives](https://arxiv.org/abs/2509.23721)
*Chi Chu,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出了一种动态感知的运动生成框架DA-MMP，用于目标条件动态操纵，并在真实的环抛任务中验证其效果，表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手动设计动作参数或存在动态差距问题，限制了复杂任务中的表现。

Method: 扩展运动流形基元，学习高质量流形，并训练条件流匹配模型以生成考虑执行动态的轨迹。

Result: 在真实环境中实现高成功率，甚至超过人类专家表现，并能泛化到新目标。

Conclusion: DA-MMP成功学习了轨迹-动态映射，适用于动态操纵任务。

Abstract: Dynamic manipulation is a key capability for advancing robot performance,
enabling skills such as tossing. While recent learning-based approaches have
pushed the field forward, most methods still rely on manually designed action
parameterizations, limiting their ability to produce the highly coordinated
motions required in complex tasks. Motion planning can generate feasible
trajectories, but the dynamics gap-stemming from control inaccuracies, contact
uncertainties, and aerodynamic effects-often causes large deviations between
planned and executed trajectories. In this work, we propose Dynamics-Aware
Motion Manifold Primitives (DA-MMP), a motion generation framework for
goal-conditioned dynamic manipulation, and instantiate it on a challenging
real-world ring-tossing task. Our approach extends motion manifold primitives
to variable-length trajectories through a compact parametrization and learns a
high-quality manifold from a large-scale dataset of planned motions. Building
on this manifold, a conditional flow matching model is trained in the latent
space with a small set of real-world trials, enabling the generation of
throwing trajectories that account for execution dynamics. Experiments show
that our method can generate coordinated and smooth motion trajectories for the
ring-tossing task. In real-world evaluations, it achieves high success rates
and even surpasses the performance of trained human experts. Moreover, it
generalizes to novel targets beyond the training range, indicating that it
successfully learns the underlying trajectory-dynamics mapping.

</details>


### [80] [LocoFormer: Generalist Locomotion via Long-context Adaptation](https://arxiv.org/abs/2509.23745)
*Min Liu,Deepak Pathak,Ananye Agarwal*

Main category: cs.RO

TL;DR: LocoFormer是一个通用的全机器人运动控制模型，能够适应不同形态和动态变化的机器人，无需精确的动力学知识。


<details>
  <summary>Details</summary>
Motivation: 传统运动控制器需要针对特定机器人手动调优，限制了通用性。LocoFormer旨在解决这一问题，实现跨平台的鲁棒控制。

Method: 通过大规模强化学习训练，结合生成的多样化机器人和强领域随机化，同时扩展上下文长度以跨越任务边界。

Result: LocoFormer在多种机器人上表现鲁棒，能够应对重量变化和电机故障等干扰，并在极端情况下表现出跨任务的适应性学习。

Conclusion: LocoFormer的简单通用方法为未来训练机器人技能的基础模型提供了可能。

Abstract: Modern locomotion controllers are manually tuned for specific embodiments. We
present LocoFormer, a generalist omni-bodied locomotion model that can control
previously unseen legged and wheeled robots, even without precise knowledge of
their kinematics. LocoFormer is able to adapt to changes in morphology and
dynamics at test time. We find that two key choices enable adaptation. First,
we train massive scale RL on procedurally generated robots with aggressive
domain randomization. Second, in contrast to previous policies that are myopic
with short context lengths, we extend context by orders of magnitude to span
episode boundaries. We deploy the same LocoFormer to varied robots and show
robust control even with large disturbances such as weight change and motor
failures. In extreme scenarios, we see emergent adaptation across episodes,
LocoFormer learns from falls in early episodes to improve control strategies in
later ones. We believe that this simple, yet general recipe can be used to
train foundation models for other robotic skills in the future. Videos at
generalist-locomotion.github.io.

</details>


### [81] [Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse](https://arxiv.org/abs/2509.23778)
*Zeyuan Zhang,Chaoran Li,Shao Zhang,Ying Wen*

Main category: cs.RO

TL;DR: 本文提出了一种名为SePar的新方法，通过将多智能体路径规划问题转化为序列建模问题，利用Transformer范式实现隐式信息交换，显著降低了决策复杂度，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体拾取交付任务（MAPD）在多智能体路径规划（MAPF）基础上增加了复杂性，尤其是在具有狭窄通道和长走廊的仓库环境中，现有学习方法的性能受限。本文旨在解决这一问题。

Method: 将MAPF问题建模为序列问题，提出Sequential Pathfinder (SePar)方法，利用Transformer实现隐式信息交换，降低计算复杂度。

Result: SePar在多种MAPF任务中表现优于现有学习方法，并在未见环境中展现出良好的泛化能力。

Conclusion: 研究表明，序列建模方法在MAPD中具有优越性，并强调了在复杂地图（如仓库）中结合模仿学习的必要性。

Abstract: Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of
Multi-Agent Path Finding (MAPF), where agents are required to sequentially
complete tasks with fixed-location pickup and delivery demands. Although
learning-based methods have made progress in MAPD, they often perform poorly in
warehouse-like environments with narrow pathways and long corridors when
relying only on local observations for distributed decision-making.
Communication learning can alleviate the lack of global information but
introduce high computational complexity due to point-to-point communication. To
address this challenge, we formulate MAPF as a sequence modeling problem and
prove that path-finding policies under sequence modeling possess
order-invariant optimality, ensuring its effectiveness in MAPD. Building on
this, we propose the Sequential Pathfinder (SePar), which leverages the
Transformer paradigm to achieve implicit information exchange, reducing
decision-making complexity from exponential to linear while maintaining
efficiency and global awareness. Experiments demonstrate that SePar
consistently outperforms existing learning-based methods across various MAPF
tasks and their variants, and generalizes well to unseen environments.
Furthermore, we highlight the necessity of integrating imitation learning in
complex maps like warehouses.

</details>


### [82] [High-Precision Climbing Robot Localization Using Planar Array UWB/GPS/IMU/Barometer Integration](https://arxiv.org/abs/2509.23801)
*Shuning Zhang,Renjing Xu,Zhanchen Zhu,Xiangyu Chen,Yunheng Wang,Xu Jiang,Peibo Duan*

Main category: cs.RO

TL;DR: 本文提出了一种多传感器融合系统AMFA，用于复杂高海拔环境中攀爬机器人的高精度定位，通过UWB、GPS、IMU和气压计的数据融合与注意力机制，解决了GPS遮挡和UWB非视距问题，最终实验显示定位精度为0.48米。


<details>
  <summary>Details</summary>
Motivation: 解决复杂高海拔环境下单一传感器定位精度不足的问题，提升攀爬机器人的定位性能。

Method: 设计基于AMFA的多传感器融合架构，开发UWB与气压计的端到端神经网络模型，使用UKF优化轨迹。

Result: 实验结果显示定位精度达0.48米，最大误差为1.50米，优于GPS/INS-EKF等基线算法。

Conclusion: AMFA系统有效提升了攀爬机器人在复杂环境中的定位精度与鲁棒性。

Abstract: To address the need for high-precision localization of climbing robots in
complex high-altitude environments, this paper proposes a multi-sensor fusion
system that overcomes the limitations of single-sensor approaches. Firstly, the
localization scenarios and the problem model are analyzed. An integrated
architecture of Attention Mechanism-based Fusion Algorithm (AMFA) incorporating
planar array Ultra-Wideband (UWB), GPS, Inertial Measurement Unit (IMU), and
barometer is designed to handle challenges such as GPS occlusion and UWB
Non-Line-of-Sight (NLOS) problem. Then, End-to-end neural network inference
models for UWB and barometer are developed, along with a multimodal attention
mechanism for adaptive data fusion. An Unscented Kalman Filter (UKF) is applied
to refine the trajectory, improving accuracy and robustness. Finally,
real-world experiments show that the method achieves 0.48 m localization
accuracy and lower MAX error of 1.50 m, outperforming baseline algorithms such
as GPS/INS-EKF and demonstrating stronger robustness.

</details>


### [83] [Fostering Robots: A Governance-First Conceptual Framework for Domestic, Curriculum-Based Trajectory Collection](https://arxiv.org/abs/2509.23821)
*Federico Pablo-Marti,Carlos Mir Fernandez*

Main category: cs.RO

TL;DR: 提出了一个概念性、可实证测试的机器人培养框架，强调长期、精心设计的交互轨迹，并量化评估标准以符合欧盟治理标准。


<details>
  <summary>Details</summary>
Motivation: 旨在为家用机器人部署提供一种基于课程驱动和治理优先的长期互动模式，确保其高质量和可控性。

Method: 提出了一种量化轨迹质量的评估协议和指标，并通过低资源实证路线进行严格验证。

Result: 框架通过符合欧盟标准的治理标准，为未来试点研究提供了可行路径。

Conclusion: 该框架为家用机器人的部署提供了理论支持和实践指导，有望通过实证验证其效果。

Abstract: We propose a conceptual, empirically testable framework for Robot Fostering,
-a curriculum-driven, governance-first approach to domestic robot deployments,
emphasizing long-term, curated interaction trajectories. We formalize
trajectory quality with quantifiable metrics and evaluation protocols aligned
with EU-grade governance standards, delineating a low-resource empirical
roadmap to enable rigorous validation through future pilot studies.

</details>


### [84] [Control Your Robot: A Unified System for Robot Control and Policy Deployment](https://arxiv.org/abs/2509.23823)
*Tian Nian,Weijie Ke,Yao Mu,Tianxing Chen,Shaolong Zhu,Bingshan Hu*

Main category: cs.RO

TL;DR: Control Your Robot 是一个模块化、通用框架，解决了跨平台机器人控制中的硬件接口和数据格式不一致问题，通过标准化工作流程和统一API，支持高效数据收集和策略学习。


<details>
  <summary>Details</summary>
Motivation: 由于硬件接口、数据格式和控制范式的多样性，跨平台机器人控制存在工具链碎片化和部署速度慢的问题，需要一种统一的解决方案。

Method: 提出Control Your Robot框架，采用模块化设计、统一API和闭环架构，支持灵活机器人注册、双模式控制（遥操作和轨迹回放），以及多模态数据采集到推理的无缝集成。

Result: 在单臂和双臂系统上的实验表明，框架实现了高效、低延迟的数据收集，并有效支持模仿学习和视觉-语言-动作模型的策略学习。

Conclusion: Control Your Robot框架能够实现跨平台的可扩展和可复现的机器人学习，训练出的策略接近专家演示水平。

Abstract: Cross-platform robot control remains difficult because hardware interfaces,
data formats, and control paradigms vary widely, which fragments toolchains and
slows deployment. To address this, we present Control Your Robot, a modular,
general-purpose framework that unifies data collection and policy deployment
across diverse platforms. The system reduces fragmentation through a
standardized workflow with modular design, unified APIs, and a closed-loop
architecture. It supports flexible robot registration, dual-mode control with
teleoperation and trajectory playback, and seamless integration from multimodal
data acquisition to inference. Experiments on single-arm and dual-arm systems
show efficient, low-latency data collection and effective support for policy
learning with imitation learning and vision-language-action models. Policies
trained on data gathered by Control Your Robot match expert demonstrations
closely, indicating that the framework enables scalable and reproducible robot
learning across platforms.

</details>


### [85] [DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation](https://arxiv.org/abs/2509.23829)
*Kefei Zhu,Fengshuo Bai,YuanHao Xiang,Yishuai Cai,Xinglin Chen,Ruochong Li,Xingtao Wang,Hao Dong,Yaodong Yang,Xiaopeng Fan,Yuanpei Chen*

Main category: cs.RO

TL;DR: DexFlyWheel提出了一种可扩展的数据生成框架，通过自我改进循环不断丰富数据多样性，提升机器人灵活操作的能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据收集方法存在多样性不足或依赖人工的问题，限制了机器人灵活性操作的扩展性和泛化性。

Method: DexFlyWheel采用闭环流程，集成模仿学习、剩余强化学习、轨迹收集和数据增强，通过迭代循环扩展数据集。

Result: 实验结果表明，DexFlyWheel在四个任务中生成了2000多样本，策略在测试集上平均成功率为81.9%，并在真实世界中达到78.3%。

Conclusion: DexFlyWheel通过自我改进的飞轮效应显著提升了数据集多样性和策略泛化能力。

Abstract: Dexterous manipulation is critical for advancing robot capabilities in
real-world applications, yet diverse and high-quality datasets remain scarce.
Existing data collection methods either rely on human teleoperation or require
significant human engineering, or generate data with limited diversity, which
restricts their scalability and generalization. In this paper, we introduce
DexFlyWheel, a scalable data generation framework that employs a self-improving
cycle to continuously enrich data diversity. Starting from efficient seed
demonstrations warmup, DexFlyWheel expands the dataset through iterative
cycles. Each cycle follows a closed-loop pipeline that integrates Imitation
Learning (IL), residual Reinforcement Learning (RL), rollout trajectory
collection, and data augmentation. Specifically, IL extracts human-like
behaviors from demonstrations, and residual RL enhances policy generalization.
The learned policy is then used to generate trajectories in simulation, which
are further augmented across diverse environments and spatial configurations
before being fed back into the next cycle. Over successive iterations, a
self-improving data flywheel effect emerges, producing datasets that cover
diverse scenarios and thereby scaling policy performance. Experimental results
demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across
four challenging tasks. Policies trained on our dataset achieve an average
success rate of 81.9\% on the challenge test sets and successfully transfer to
the real world through digital twin, achieving a 78.3\% success rate on
dual-arm lift tasks.

</details>


### [86] [MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control](https://arxiv.org/abs/2509.23960)
*Manan Tayal,Aditya Singh,Shishir Kolathaya,Somil Bansal*

Main category: cs.RO

TL;DR: MAD-PINN是一个去中心化、基于物理信息的机器学习框架，用于解决多智能体状态约束最优控制问题，通过结合安全性和性能优化，在多智能体导航任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大规模多智能体系统中如何同时保证安全性和性能是一个关键挑战，现有方法如多智能体强化学习、安全过滤或模型预测控制存在局限性。

Method: 提出MAD-PINN框架，利用基于epigraph的重构方法结合物理信息神经网络，并通过去中心化训练和部署提升可扩展性。

Result: 实验表明，MAD-PINN在多智能体导航任务中实现了更优的安全性与性能权衡，且随智能体数量增加仍能保持高效。

Conclusion: MAD-PINN通过创新的去中心化和安全策略，显著提升了多智能体系统的安全性与性能。

Abstract: Co-optimizing safety and performance in large-scale multi-agent systems
remains a fundamental challenge. Existing approaches based on multi-agent
reinforcement learning (MARL), safety filtering, or Model Predictive Control
(MPC) either lack strict safety guarantees, suffer from conservatism, or fail
to scale effectively. We propose MAD-PINN, a decentralized physics-informed
machine learning framework for solving the multi-agent state-constrained
optimal control problem (MASC-OCP). Our method leverages an epigraph-based
reformulation of SC-OCP to simultaneously capture performance and safety, and
approximates its solution via a physics-informed neural network. Scalability is
achieved by training the SC-OCP value function on reduced-agent systems and
deploying them in a decentralized fashion, where each agent relies only on
local observations of its neighbours for decision-making. To further enhance
safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based
neighbour selection strategy to prioritize safety-critical interactions, and a
receding-horizon policy execution scheme that adapts to dynamic interactions
while reducing computational burden. Experiments on multi-agent navigation
tasks demonstrate that MAD-PINN achieves superior safety-performance
trade-offs, maintains scalability as the number of agents grows, and
consistently outperforms state-of-the-art baselines.

</details>


### [87] [Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras](https://arxiv.org/abs/2509.24094)
*Vignesh Ramanathan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Flash是一种轻量级的视觉地点识别（VPR）系统，通过亚毫秒级别的事件数据预测地点，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统的VPR方法依赖密集表示且需要大量事件数据，Flash旨在解决这些局限性。

Method: Flash利用活跃像素位置的特征，采用高效二进制帧和快速位运算进行相似性计算。

Result: 在室内和室外数据集上，Flash的Recall@1分别提升了11.33倍和5.92倍，并减少了定位延迟。

Conclusion: Flash首次实现了亚毫秒级别的VPR，显著提升了系统的响应速度和性能。

Abstract: Visual Place Recognition (VPR) enables systems to identify previously visited
locations within a map, a fundamental task for autonomous navigation. Prior
works have developed VPR solutions using event cameras, which asynchronously
measure per-pixel brightness changes with microsecond temporal resolution.
However, these approaches rely on dense representations of the inherently
sparse camera output and require tens to hundreds of milliseconds of event data
to predict a place. Here, we break this paradigm with Flash, a lightweight VPR
system that predicts places using sub-millisecond slices of event data. Our
method is based on the observation that active pixel locations provide strong
discriminative features for VPR. Flash encodes these active pixel locations
using efficient binary frames and computes similarities via fast bitwise
operations, which are then normalized based on the relative event activity in
the query and reference frames. Flash improves Recall@1 for sub-millisecond VPR
over existing baselines by 11.33x on the indoor QCR-Event-Dataset and 5.92x on
the 8 km Brisbane-Event-VPR dataset. Moreover, our approach reduces the
duration for which the robot must operate without awareness of its position, as
evidenced by a localization latency metric we term Time to Correct Match (TCM).
To the best of our knowledge, this is the first work to demonstrate
sub-millisecond VPR using event cameras.

</details>


### [88] [Ancestry Tree Clustering for Particle Filter Diversity Maintenance](https://arxiv.org/abs/2509.24124)
*Ilari Vallivaara,Bingnan Duan,Yinhuan Dong,Tughrul Arslan*

Main category: cs.RO

TL;DR: 提出了一种线性时间多样性维护的粒子滤波方法，通过基于祖先树拓扑的聚类防止早熟收敛。


<details>
  <summary>Details</summary>
Motivation: 解决多模态环境中粒子滤波的早熟收敛问题，同时保持估计的紧凑性。

Method: 基于祖先树拓扑聚类粒子，结合簇内适应度共享和保护未聚类粒子。

Result: 在多模态机器人仿真和真实室内环境中验证，性能优于多种多样性维护算法。

Conclusion: 该方法在不同领域和挑战性初始条件下表现出强鲁棒性，且对紧凑性影响小。

Abstract: We propose a method for linear-time diversity maintenance in particle
filtering. It clusters particles based on ancestry tree topology: closely
related particles in sufficiently large subtrees are grouped together. The main
idea is that the tree structure implicitly encodes similarity without the need
for spatial or other domain-specific metrics. This approach, when combined with
intra-cluster fitness sharing and the protection of particles not included in a
cluster, effectively prevents premature convergence in multimodal environments
while maintaining estimate compactness. We validate our approach in a
multimodal robotics simulation and a real-world multimodal indoor environment.
We compare the performance to several diversity maintenance algorithms from the
literature, including Deterministic Resampling and Particle Gaussian Mixtures.
Our algorithm achieves high success rates with little to no negative effect on
compactness, showing particular robustness to different domains and challenging
initial conditions.

</details>


### [89] [BOSfM: A View Planning Framework for Optimal 3D Reconstruction of Agricultural Scenes](https://arxiv.org/abs/2509.24126)
*Athanasios Bacharis,Konstantinos D. Polyzos,Georgios B. Giannakis,Nikolaos Papanikolopoulos*

Main category: cs.RO

TL;DR: 该论文提出了一种基于贝叶斯优化的视角规划框架，用于在噪声和泛化需求下高效确定最优相机位置，以实现3D环境重建。


<details>
  <summary>Details</summary>
Motivation: 主动视觉在农业任务中有广泛应用，但传统方法收集和处理大量图像效率低下，且易受噪声影响。论文旨在解决这些问题。

Method: 采用基于重建质量的优化方法，结合'structure-from-motion'技术，并通过贝叶斯优化高效求解相机最优位置。

Result: 模拟和真实农业场景的实验表明，该方法能高效估计最优相机位置，并准确重建3D环境，且泛化能力强。

Conclusion: 提出的视角规划框架在噪声环境下表现优异，能够适应未知的类似农业环境，无需重新优化或训练。

Abstract: Active vision (AV) has been in the spotlight of robotics research due to its
emergence in numerous applications including agricultural tasks such as
precision crop monitoring and autonomous harvesting to list a few. A major AV
problem that gained popularity is the 3D reconstruction of targeted
environments using 2D images from diverse viewpoints. While collecting and
processing a large number of arbitrarily captured 2D images can be arduous in
many practical scenarios, a more efficient solution involves optimizing the
placement of available cameras in 3D space to capture fewer, yet more
informative, images that provide sufficient visual information for effective
reconstruction of the environment of interest. This process termed as view
planning (VP), can be markedly challenged (i) by noise emerging in the location
of the cameras and/or in the extracted images, and (ii) by the need to
generalize well in other unknown similar agricultural environments without need
for re-optimizing or re-training. To cope with these challenges, the present
work presents a novel VP framework that considers a reconstruction
quality-based optimization formulation that relies on the notion of
`structure-from-motion' to reconstruct the 3D structure of the sought
environment from the selected 2D images. With no analytic expression of the
optimization function and with costly function evaluations, a Bayesian
optimization approach is proposed to efficiently carry out the VP process using
only a few function evaluations, while accounting for different noise cases.
Numerical tests on both simulated and real agricultural settings signify the
benefits of the advocated VP approach in efficiently estimating the optimal
camera placement to accurately reconstruct 3D environments of interest, and
generalize well on similar unknown environments.

</details>


### [90] [Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress](https://arxiv.org/abs/2509.24129)
*Priyanka Mandikal,Jiaheng Hu,Shivin Dass,Sagnik Majumder,Roberto Martín-Martín,Kristen Grauman*

Main category: cs.RO

TL;DR: SPARTA是一个统一的框架，用于处理对象状态变化的机器人操纵任务，如搅拌、涂抹或切片。它通过空间推进的视觉技能和密集奖励机制，显著提升了训练效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现实中的许多操纵任务涉及对象物理和视觉状态的渐进变化，而非简单的运动状态变化。现有方法未能统一处理此类任务，因此提出了SPARTA框架。

Method: SPARTA利用了对象状态变化的空间推进模式，通过感知可操作与已变化区域的视觉技能，生成结构化策略观察和密集奖励。提供基于强化学习和贪婪控制的两种策略变体。

Result: 在10种不同真实对象上的3个任务中，SPARTA显著优于稀疏奖励和视觉目标条件基线，展示了训练时间和准确性的提升。

Conclusion: SPARTA的成功表明，基于视觉表征的渐进感知方法是处理广泛对象状态操纵任务的有效基础。

Abstract: Most robot manipulation focuses on changing the kinematic state of objects:
picking, placing, opening, or rotating them. However, a wide range of
real-world manipulation tasks involve a different class of object state
change--such as mashing, spreading, or slicing--where the object's physical and
visual state evolve progressively without necessarily changing its position. We
present SPARTA, the first unified framework for the family of object state
change manipulation tasks. Our key insight is that these tasks share a common
structural pattern: they involve spatially-progressing, object-centric changes
that can be represented as regions transitioning from an actionable to a
transformed state. Building on this insight, SPARTA integrates spatially
progressing object change segmentation maps, a visual skill to perceive
actionable vs. transformed regions for specific object state change tasks, to
generate a) structured policy observations that strip away appearance
variability, and b) dense rewards that capture incremental progress over time.
These are leveraged in two SPARTA policy variants: reinforcement learning for
fine-grained control without demonstrations or simulation; and greedy control
for fast, lightweight deployment. We validate SPARTA on a real robot for three
challenging tasks across 10 diverse real-world objects, achieving significant
improvements in training time and accuracy over sparse rewards and visual
goal-conditioned baselines. Our results highlight progress-aware visual
representations as a versatile foundation for the broader family of object
state manipulation tasks. Project website:
https://vision.cs.utexas.edu/projects/sparta-robot

</details>


### [91] [A Novel Model for 3D Motion Planning for a Generalized Dubins Vehicle with Pitch and Yaw Rate Constraints](https://arxiv.org/abs/2509.24143)
*Deepak Prakash Kumar,Swaroop Darbha,Satyanarayana Gupta Manyam,David Casbeer*

Main category: cs.RO

TL;DR: 提出了一种新的建模方法和快速算法，用于固定翼无人机的3D运动规划，目标是构建满足运动约束的最短路径。


<details>
  <summary>Details</summary>
Motivation: 现有文献通常仅考虑部分车辆方向（如俯仰角和偏航角），并且使用单一控制输入，无法准确描述3D运动学问题。

Method: 使用车身附着的框架考虑完整的车辆方向（滚转、俯仰和偏航角），采用两个控制输入表示有界的俯仰和偏航速率，并通过旋转最小化框架和拼接最优Dubins路径构建路径。

Result: 数值模拟表明，该方法平均在10秒内生成可行路径，并且在大多数情况下路径比现有方法更短。

Conclusion: 该方法通过完整的方向描述和控制输入，显著提升了3D运动规划的准确性和效率。

Abstract: In this paper, we propose a new modeling approach and a fast algorithm for 3D
motion planning, applicable for fixed-wing unmanned aerial vehicles. The goal
is to construct the shortest path connecting given initial and final
configurations subject to motion constraints. Our work differs from existing
literature in two ways. First, we consider full vehicle orientation using a
body-attached frame, which includes roll, pitch, and yaw angles. However,
existing work uses only pitch and/or heading angle, which is insufficient to
uniquely determine orientation. Second, we use two control inputs to represent
bounded pitch and yaw rates, reflecting control by two separate actuators. In
contrast, most previous methods rely on a single input, such as path curvature,
which is insufficient for accurately modeling the vehicle's kinematics in 3D.
We use a rotation minimizing frame to describe the vehicle's configuration and
its evolution, and construct paths by concatenating optimal Dubins paths on
spherical, cylindrical, or planar surfaces. Numerical simulations show our
approach generates feasible paths within 10 seconds on average and yields
shorter paths than existing methods in most cases.

</details>


### [92] [Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation](https://arxiv.org/abs/2509.24160)
*Tomoyuki Kagaya,Subramanian Lakshmi,Yuxuan Lou,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: MTP框架利用成功的控制代码示例作为上下文指导，提升了LLM在机器人操纵中的适应性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在新环境中的适应性不足，依赖特定环境训练或固定提示，缺乏可迁移性和手动调整的需求。

Method: MTP通过生成初始计划、从代码记忆库检索相关示例并上下文适应目标环境，实现无需调整模型参数的重新规划。

Result: 在RLBench、CALVIN和物理机器人实验中，MTP相比固定提示和检索方法，显著提高了成功率和适应性。

Conclusion: MTP利用程序化知识增强LLM规划的鲁棒性，有效适应新环境并弥合仿真与现实的差距。

Abstract: Large language models (LLMs) are increasingly explored in robot manipulation,
but many existing methods struggle to adapt to new environments. Many systems
require either environment-specific policy training or depend on fixed prompts
and single-shot code generation, leading to limited transferability and manual
re-tuning. We introduce Memory Transfer Planning (MTP), a framework that
leverages successful control-code examples from different environments as
procedural knowledge, using them as in-context guidance for LLM-driven
planning. Specifically, MTP (i) generates an initial plan and code using LLMs,
(ii) retrieves relevant successful examples from a code memory, and (iii)
contextually adapts the retrieved code to the target setting for re-planning
without updating model parameters. We evaluate MTP on RLBench, CALVIN, and a
physical robot, demonstrating effectiveness beyond simulation. Across these
settings, MTP consistently improved success rate and adaptability compared with
fixed-prompt code generation, naive retrieval, and memory-free re-planning.
Furthermore, in hardware experiments, leveraging a memory constructed in
simulation proved effective. MTP provides a practical approach that exploits
procedural knowledge to realize robust LLM-based planning across diverse
robotic manipulation scenarios, enhancing adaptability to novel environments
and bridging simulation and real-world deployment.

</details>


### [93] [Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models](https://arxiv.org/abs/2509.24163)
*Wanming Yu,Adrian Röfer,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 论文提出利用多模态大语言模型（LLM）作为长期机器人堆叠任务的高层规划器，通过推理堆叠偏好（如重量、稳定性等）来改进任务完成效果。


<details>
  <summary>Details</summary>
Motivation: 现有预训练的LLM在需要物体物理属性的长期机器人任务中表现不足，如堆叠隐藏物体的容器。

Method: 使用多模态LLM作为高层规划器，输入多模态信息；创建自定义数据集（包含堆叠偏好）微调LLM，无需显式指令即可推理多偏好。

Result: 微调后的LLM在模拟和真实人形机器人上的堆叠任务表现优于仅提示调优的预训练LLM。

Conclusion: 多模态LLM结合自定义数据集微调，显著提升了长期堆叠任务的规划能力，验证了其在实际机器人应用中的有效性。

Abstract: Pretrained large language models (LLMs) can work as high-level robotic
planners by reasoning over abstract task descriptions and natural language
instructions, etc. However, they have shown a lack of knowledge and
effectiveness in planning long-horizon robotic manipulation tasks where the
physical properties of the objects are essential. An example is the stacking of
containers with hidden objects inside, which involves reasoning over hidden
physics properties such as weight and stability. To this end, this paper
proposes to use multimodal LLMs as high-level planners for such long-horizon
robotic stacking tasks. The LLM takes multimodal inputs for each object to
stack and infers the current best stacking sequence by reasoning over stacking
preferences. Furthermore, in order to enable the LLM to reason over multiple
preferences at the same time without giving explicit instructions, we propose
to create a custom dataset considering stacking preferences including weight,
stability, size, and footprint, to fine-tune the LLM. Compared to the
pretrained LLM with prompt tuning, we demonstrate the improved stacking
completion of the LLM fine-tuned with our custom dataset via large-scale
simulation evaluation. Furthermore, we showcase the effectiveness of the
proposed framework for the long-horizon stacking task on a real humanoid robot
in an online manner.

</details>


### [94] [Very High Frequency Interpolation for Direct Torque Control](https://arxiv.org/abs/2509.24175)
*Rafael Kourdis,Maciej Stępień,Jérôme Manhes,Nicolas Mansard,Steve Tonneau,Philippe Souères,Thomas Flayols*

Main category: cs.RO

TL;DR: 本文提出了一种在开源硬件上以高达40 kHz频率执行全身线性反馈的新方法，用于稳定扭矩控制器并支持非线性方案实时执行。


<details>
  <summary>Details</summary>
Motivation: 扭矩控制在机器人运动中具有敏捷性和鲁棒性，但实际部署常因不稳定性和硬件限制而受阻。

Method: 通过在开源硬件上实现高达40 kHz的全身线性反馈，并实时插值非线性方案（如逆动力学和学习扭矩策略）。

Result: 实验表明，稳定扭矩控制器并通过高频线性反馈可以有效释放扭矩控制机器人的潜力。

Conclusion: 本文的高频线性反馈是解锁扭矩控制机器人潜力的一种有效途径。

Abstract: Torque control enables agile and robust robot motion, but deployment is often
hindered by instability and hardware limits. Here, we present a novel solution
to execute whole-body linear feedback at up to 40 kHz on open-source hardware.
We use this to interpolate non-linear schemes during real-world execution, such
as inverse dynamics and learned torque policies. Our results show that by
stabilizing torque controllers, high-frequency linear feedback could be an
effective route towards unlocking the potential of torque-controlled robotics.

</details>


### [95] [ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning](https://arxiv.org/abs/2509.24219)
*Tomoyuki Kagaya,Subramanian Lakshmi,Anbang Ye,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: ViReSkill结合视觉重规划和技能记忆，通过反馈循环提升任务成功率，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs/VLMs在运动规划中缺乏几何和物理基础及执行不可靠的问题。

Method: 使用视觉重规划和技能记忆，失败时生成新动作序列，成功时存储为可重用技能。

Result: 在LIBERO、RLBench和实体机器人上任务成功率优于传统基线。

Conclusion: ViReSkill通过反馈循环实现自主连续学习，提升执行稳定性和任务成功率。

Abstract: Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL)
often adapt slowly to new tasks, whereas recent Large Language Models (LLMs)
and Vision-Language Models (VLMs) promise knowledge-rich planning from minimal
data. Deploying LLMs/VLMs for motion planning, however, faces two key
obstacles: (i) symbolic plans are rarely grounded in scene geometry and object
physics, and (ii) model outputs can vary for identical prompts, undermining
execution reliability. We propose ViReSkill, a framework that pairs
vision-grounded replanning with a skill memory for accumulation and reuse. When
a failure occurs, the replanner generates a new action sequence conditioned on
the current scene, tailored to the observed state. On success, the executed
plan is stored as a reusable skill and replayed in future encounters without
additional calls to LLMs/VLMs. This feedback loop enables autonomous continual
learning: each attempt immediately expands the skill set and stabilizes
subsequent executions. We evaluate ViReSkill on simulators such as LIBERO and
RLBench as well as on a physical robot. Across all settings, it consistently
outperforms conventional baselines in task success rate, demonstrating robust
sim-to-real generalization.

</details>


### [96] [Towards Tighter Convex Relaxation of Mixed-integer Programs: Leveraging Logic Network Flow for Task and Motion Planning](https://arxiv.org/abs/2509.24235)
*Xuan Lin,Jiming Ren,Yandong Luo,Weijun Xie,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种名为“Logic Network Flow”的基于优化的任务与运动规划框架，将时序逻辑规范融入混合整数程序中，提高了机器人规划的效率。


<details>
  <summary>Details</summary>
Motivation: 通过将时序谓词编码为网络流模型边缘的多面体约束，而非传统Logic Tree中的节点间约束，实现更高效的规划。

Method: 采用网络流模型的Fourier-Motzkin消除法，去除连续流变量同时保持凸松弛紧致性。

Result: 实验证明在车辆路径规划、多机器人协调和时序逻辑控制中，计算速度提升了多个数量级。

Conclusion: 该框架在动态环境条件下展示了实时重新规划能力，适用于实际机器人系统。

Abstract: This paper proposes an optimization-based task and motion planning framework,
named "Logic Network Flow", that integrates temporal logic specifications into
mixed-integer programs for efficient robot planning. Inspired by the
Graph-of-Convex-Sets formulation, temporal predicates are encoded as polyhedron
constraints on each edge of a network flow model, instead of as constraints
between nodes in traditional Logic Tree formulations. We further propose a
network-flow-based Fourier-Motzkin elimination procedure that removes
continuous flow variables while preserving convex relaxation tightness, leading
to provably tighter convex relaxations and fewer constraints than Logic Tree
formulations. For temporal logic motion planning with piecewise-affine dynamic
systems, comprehensive experiments across vehicle routing, multi-robot
coordination, and temporal logic control on dynamical systems using point mass
and linear inverted pendulum models demonstrate computational speedups of up to
several orders of magnitude. Hardware demonstrations with quadrupedal robots
validate real-time replanning capabilities under dynamically changing
environmental conditions. The project website is at
https://logicnetworkflow.github.io/.

</details>


### [97] [PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization](https://arxiv.org/abs/2509.24236)
*Siyan Dong,Zijun Wang,Lulu Cai,Yi Ma,Yanchao Yang*

Main category: cs.RO

TL;DR: 该论文提出了一种结合学习初始化和优化细化的方法，用于在相机不稳定运动时实现实时密集场景重建，解决了现有RGB-D SLAM系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决相机运动不稳定（如大视角变化、快速运动或突然抖动）时RGB-D SLAM系统的失效问题，平衡学习方法的鲁棒性和优化方法的高精度需求。

Method: 通过相机位姿回归网络预测相对位姿作为优化算法的初始值，再使用随机优化算法进一步对齐深度图像与场景几何。

Result: 实验表明该方法在挑战性基准上优于现有方法，同时在不稳定运动中和稳定序列上均表现良好，且实时运行。

Conclusion: 结合学习和优化的简单方法能同时实现鲁棒性和高精度，为密集重建提供了有效解决方案。

Abstract: Real-time dense scene reconstruction during unstable camera motions is
crucial for robotics, yet current RGB-D SLAM systems fail when cameras
experience large viewpoint changes, fast motions, or sudden shaking. Classical
optimization-based methods deliver high accuracy but fail with poor
initialization during large motions, while learning-based approaches provide
robustness but lack sufficient accuracy for dense reconstruction. We address
this challenge through a combination of learning-based initialization with
optimization-based refinement. Our method employs a camera pose regression
network to predict metric-aware relative poses from consecutive RGB-D frames,
which serve as reliable starting points for a randomized optimization algorithm
that further aligns depth images with the scene geometry. Extensive experiments
demonstrate promising results: our approach outperforms the best competitor on
challenging benchmarks, while maintaining comparable accuracy on stable motion
sequences. The system operates in real-time, showcasing that combining simple
and principled techniques can achieve both robustness for unstable motions and
accuracy for dense reconstruction. Project page:
https://github.com/siyandong/PROFusion.

</details>


### [98] [SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions](https://arxiv.org/abs/2509.24243)
*Jeongyong Yang,Seunghwan Jang,Soojean Han*

Main category: cs.RO

TL;DR: SafeFlowMatcher是一种结合流匹配（FM）和控制屏障函数（CBFs）的规划框架，通过两阶段预测-校正积分器实现实时高效和安全性保证。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于流匹配的生成规划器缺少正式安全性保证且可能在约束附近生成不完整路径的问题。

Method: 采用预测-校正（PC）积分器，预测阶段通过FM生成候选路径，校正阶段通过CBFs和二次规划最小扰动优化路径。

Result: 证明了屏障证书的有效性，确保了路径的安全性和收敛性，在迷宫导航和运动任务中表现优于基线方法。

Conclusion: SafeFlowMatcher提供了高效、平滑且安全的路径规划方案，并通过消融实验验证了PC积分器和屏障证书的关键作用。

Abstract: Generative planners based on flow matching (FM) can produce high-quality
paths in one or a few ODE steps, but their sampling dynamics offer no formal
safety guarantees and can yield incomplete paths near constraints. We present
SafeFlowMatcher, a planning framework that couples FM with control barrier
functions (CBFs) to achieve both real-time efficiency and certified safety.
SafeFlowMatcher uses a two-phase prediction-correction (PC) integrator: (i) a
prediction phase integrates the learned FM once (or a few steps) to obtain a
candidate path without intervention; (ii) a correction phase refines this path
with a vanishing time-scaled vector field and a CBF-based quadratic program
that minimally perturbs the vector field. We prove a barrier certificate for
the resulting flow system, establishing forward invariance of a robust safe set
and finite-time convergence to the safe set. By enforcing safety only on the
executed path (rather than on all intermediate latent paths), SafeFlowMatcher
avoids distributional drift and mitigates local trap problems. Across maze
navigation and locomotion benchmarks, SafeFlowMatcher attains faster, smoother,
and safer paths than diffusion- and FM-based baselines. Extensive ablations
corroborate the contributions of the PC integrator and the barrier certificate.

</details>


### [99] [Contextual Neural Moving Horizon Estimation for Robust Quadrotor Control in Varying Conditions](https://arxiv.org/abs/2509.24281)
*Kasra Torshizi,Chak Lam Shek,Khuzema Habib,Guangyao Shi,Pratap Tokekar,Troi Williams*

Main category: cs.RO

TL;DR: 提出了一种基于贝叶斯优化的自适应控制器方法，通过在特定环境上下文中收集数据，提高了四旋翼飞行器的轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统自适应控制器需要针对特定环境进行大量参数调整，缺乏灵活性和鲁棒性。机器学习方法虽有望解决这一问题，但收集所有环境数据不切实际。

Method: 通过贝叶斯优化和高斯过程选择关键环境上下文进行数据收集，动态调整神经网络参数，提出Contextual NeuroMHE方法。

Result: 实验表明，该方法在最大绝对位置误差上优于前方法20.3%，并通过少量精选上下文捕捉环境变化。

Conclusion: Contextual NeuroMHE显著提高了效率和泛化能力，适用于多变环境。

Abstract: Adaptive controllers on quadrotors typically rely on estimation of
disturbances to ensure robust trajectory tracking. Estimating disturbances
across diverse environmental contexts is challenging due to the inherent
variability and uncertainty in the real world. Such estimators require
extensive fine-tuning for a specific scenario, which makes them inflexible and
brittle to changing conditions. Machine-learning approaches, such as training a
neural network to tune the estimator's parameters, are promising. However,
collecting data across all possible environmental contexts is impossible. It is
also inefficient as the same estimator parameters could work for "nearby"
contexts. In this paper, we present a sequential decision making strategy that
decides which environmental contexts, using Bayesian Optimization with a
Gaussian Process, to collect data from in order to ensure robust performance
across a wide range of contexts. Our method, Contextual NeuroMHE, eliminates
the need for exhaustive training across all environments while maintaining
robust performance under different conditions. By enabling the neural network
to adapt its parameters dynamically, our method improves both efficiency and
generalization. Experimental results in various real-world settings demonstrate
that our approach outperforms the prior work by 20.3\% in terms of maximum
absolute position error and can capture the variations in the environment with
a few carefully chosen contexts.

</details>


### [100] [Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning](https://arxiv.org/abs/2509.24313)
*Korbinian Moller,Roland Stroop,Mattia Piccinini,Alexander Langmann,Johannes Betz*

Main category: cs.RO

TL;DR: 一种混合框架通过学习采样位置，提高自动驾驶中的运动规划效率，减少无效轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市场景中，传统均匀或启发式采样常产生大量不可行或不相关的轨迹，限制了规划效率。

Method: 结合强化学习（RL）和可解码的深度集合编码器世界模型（WM），指导采样并保持轨迹生成的解析性和可验证性。

Result: 在CommonRoad环境中，所需样本减少99%，运行时间缩短84%，同时保持规划质量和安全性。

Conclusion: 该方法显著提升了自动驾驶决策的效率和可靠性，适用于现实世界约束下的城市导航。

Abstract: Sampling-based motion planning is a well-established approach in autonomous
driving, valued for its modularity and analytical tractability. In complex
urban scenarios, however, uniform or heuristic sampling often produces many
infeasible or irrelevant trajectories. We address this limitation with a hybrid
framework that learns where to sample while keeping trajectory generation and
evaluation fully analytical and verifiable. A reinforcement learning (RL) agent
guides the sampling process toward regions of the action space likely to yield
feasible trajectories, while evaluation and final selection remains governed by
deterministic feasibility checks and cost functions. We couple the RL sampler
with a world model (WM) based on a decodable deep set encoder, enabling both
variable numbers of traffic participants and reconstructable latent
representations. The approach is evaluated in the CommonRoad simulation
environment, showing up to 99% fewer required samples and a runtime reduction
of up to 84% while maintaining planning quality in terms of success and
collision-free rates. These improvements lead to faster, more reliable
decision-making for autonomous vehicles in urban environments, achieving safer
and more responsive navigation under real-world constraints. Code and trained
artifacts are publicly available at:
https://github.com/TUM-AVS/Learning-to-Sample

</details>


### [101] [SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm](https://arxiv.org/abs/2509.24321)
*Yao Wang,Zhirui Sun,Wenzheng Chi,Baozhi Jia,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 本文提出SONAR方法，通过跨模态范式整合语义地图和视觉语言模型，以提高机器人导航的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖数据质量且泛化能力有限，或语义线索弱时表现不佳。SONAR旨在解决这些问题。

Method: 结合语义地图的目标预测模块和视觉语言模型的值映射模块，并集成多尺度语义地图与置信度地图以减少目标误检。

Result: 在MP3D数据集上，SONAR的成功率为38.4%，SPL为17.7%。

Conclusion: SONAR在未知环境中表现更鲁棒，有效平衡了泛化能力和场景适应性。

Abstract: Understanding human instructions and accomplishing Vision-Language Navigation
tasks in unknown environments is essential for robots. However, existing
modular approaches heavily rely on the quality of training data and often
exhibit poor generalization. Vision-Language Model based methods, while
demonstrating strong generalization capabilities, tend to perform
unsatisfactorily when semantic cues are weak. To address these issues, this
paper proposes SONAR, an aggregated reasoning approach through a cross modal
paradigm. The proposed method integrates a semantic map based target prediction
module with a Vision-Language Model based value map module, enabling more
robust navigation in unknown environments with varying levels of semantic cues,
and effectively balancing generalization ability with scene adaptability. In
terms of target localization, we propose a strategy that integrates multi-scale
semantic maps with confidence maps, aiming to mitigate false detections of
target objects. We conducted an evaluation of the SONAR within the Gazebo
simulator, leveraging the most challenging Matterport 3D (MP3D) dataset as the
experimental benchmark. Experimental results demonstrate that SONAR achieves a
success rate of 38.4% and an SPL of 17.7%.

</details>


### [102] [AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation](https://arxiv.org/abs/2509.24387)
*Xin Ding,Jianyu Wei,Yifan Yang,Shiqi Jiang,Qianxi Zhang,Hao Wu,Fucheng Jia,Liang Mi,Yuxuan Yan,Weijun Wang,Yunxin Liu,Zhibo Chen,Ting Cao*

Main category: cs.RO

TL;DR: AdaNav是一种基于不确定性的自适应推理框架，用于视觉语言导航（VLN），通过动态触发推理提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定步长的推理方法在VLN任务中表现不佳且计算冗余，需一种自适应机制来优化推理过程。

Method: 提出Uncertainty Adaptive Reasoning Block（UAR），利用动作熵作为策略先验，并结合启发式到强化学习的训练方法，动态触发推理。

Result: 仅用6K训练样本，AdaNav在多个数据集上显著优于闭源模型（R2R val-unseen提升20%，RxR-CE提升11.7%，真实场景提升11.4%）。

Conclusion: AdaNav通过自适应推理和高效训练方法，在数据有限的任务中实现了高性能导航。

Abstract: Vision Language Navigation (VLN) requires agents to follow natural language
instructions by grounding them in sequential visual observations over long
horizons. Explicit reasoning could enhance temporal consistency and perception
action alignment, but reasoning at fixed steps often leads to suboptimal
performance and unnecessary computation. To address this, we propose AdaNav, an
uncertainty-based adaptive reasoning framework for VLN. At its core is the
Uncertainty Adaptive Reasoning Block (UAR), a lightweight plugin that
dynamically triggers reasoning. We introduce Action Entropy as a policy prior
for UAR and progressively refine it through a Heuristics to RL training method,
enabling agents to learn difficulty aware reasoning policies under the strict
data limitations of embodied tasks. Results show that with only 6K training
samples, AdaNav achieves substantial gains over closed source models trained on
million scale data, improving success rate by 20% on R2R val-unseen, 11.7% on
RxR-CE, and 11.4% in real world scenes. The code is available at
https://github.com/xinding-sys/AdaNav.

</details>


### [103] [DynaMIC: Dynamic Multimodal In-Context Learning Enabled Embodied Robot Counterfactual Resistance Ability](https://arxiv.org/abs/2509.24413)
*Tianqiang Yan,Ziqiao Lin,Sicheng Wang,Tianwei Zhang,Zhenglong Sun*

Main category: cs.RO

TL;DR: 论文提出了DynaMIC框架，用于识别和反馈误导性指令（DCFs），以提高机器人任务执行的可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究发现，机器人严格遵循带有误导信息的指令可能导致任务错误和安全风险，但目前机器人研究对此关注不足。

Method: 引入DCFs概念，并提出DynaMIC框架，生成任务流程以识别DCFs并主动反馈给人类。

Result: 通过语义级实验和消融研究，验证了框架的有效性。

Conclusion: DynaMIC框架能增强机器人对潜在DCFs的敏感性，提升任务执行的可靠性。

Abstract: The emergence of large pre-trained models based on natural language has
breathed new life into robotics development. Extensive research has integrated
large models with robots, utilizing the powerful semantic understanding and
generation capabilities of large models to facilitate robot control through
natural language instructions gradually. However, we found that robots that
strictly adhere to human instructions, especially those containing misleading
information, may encounter errors during task execution, potentially leading to
safety hazards. This resembles the concept of counterfactuals in natural
language processing (NLP), which has not yet attracted much attention in
robotic research. In an effort to highlight this issue for future studies, this
paper introduced directive counterfactuals (DCFs) arising from misleading human
directives. We present DynaMIC, a framework for generating robot task flows to
identify DCFs and relay feedback to humans proactively. This capability can
help robots be sensitive to potential DCFs within a task, thus enhancing the
reliability of the execution process. We conducted semantic-level experiments
and ablation studies, showcasing the effectiveness of this framework.

</details>


### [104] [PhysiAgent: An Embodied Agent Framework in Physical World](https://arxiv.org/abs/2509.24524)
*Zhihao Wang,Jianxiong Li,Jinliang Zheng,Wencong Zhang,Dongxiu Liu,Yinan Zheng,Haoyi Niu,Junzhi Yu,Xianyuan Zhan*

Main category: cs.RO

TL;DR: PhysiAgent是一种新型的视觉-语言-动作（VLA）代理框架，通过引入监控、记忆和自我反思机制，解决了现有VLA模型在泛化和协作中的问题，显著提升了复杂任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型泛化能力有限，且与视觉-语言模型（VLM）的协作方式僵硬，导致执行效率低下。PhysiAgent旨在通过自主框架优化两者的协作。

Method: 提出PhysiAgent框架，整合监控、记忆、自我反思机制和轻量级工具包，基于VLA的实时反馈动态调整VLM的组件组织。

Result: 在复杂现实机器人任务中，PhysiAgent显著提升了任务解决性能，展示了VLM的有效自我调节和工具协作能力。

Conclusion: PhysiAgent为VLM和VLA的有效集成提供了实用方案，成功实现了在真实环境中的落地应用。

Abstract: Vision-Language-Action (VLA) models have achieved notable success but often
struggle with limited generalizations. To address this, integrating generalized
Vision-Language Models (VLMs) as assistants to VLAs has emerged as a popular
solution. However, current approaches often combine these models in rigid,
sequential structures: using VLMs primarily for high-level scene understanding
and task planning, and VLAs merely as executors of lower-level actions, leading
to ineffective collaboration and poor grounding challenges. In this paper, we
propose an embodied agent framework, PhysiAgent, tailored to operate
effectively in physical environments. By incorporating monitor, memory,
self-reflection mechanisms, and lightweight off-the-shelf toolboxes, PhysiAgent
offers an autonomous scaffolding framework to prompt VLMs to organize different
components based on real-time proficiency feedback from VLAs to maximally
exploit VLAs' capabilities. Experimental results demonstrate significant
improvements in task-solving performance on complex real-world robotic tasks,
showcasing effective self-regulation of VLMs, coherent tool collaboration, and
adaptive evolution of the framework during execution. PhysiAgent makes
practical and pioneering efforts to integrate VLMs and VLAs, effectively
grounding embodied agent frameworks in real-world settings.

</details>


### [105] [Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game](https://arxiv.org/abs/2509.24530)
*Giulia Pusceddu,Sara Mongile,Francesco Rea,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 研究探讨了利用博弈论研究人机混合群体中的合作与信任，通过改进的公共物品游戏（PGG）实验，评估不同机器人策略对人类合作倾向的影响。


<details>
  <summary>Details</summary>
Motivation: 探索机器人在促进人机交互中信任与凝聚力方面的作用，以期为开发能够促进人类与机器人合作的社交机器人提供见解。

Method: 采用改进的PGG实验，三名人类参与者与人形机器人iCub互动，测试不同机器人策略（如总是合作、总是搭便车、以牙还牙）对人类行为的影响。

Result: 初步分析显示，尽管参与者认为机器人慷慨，但他们仍倾向于不向公共池投资。

Conclusion: 研究为开发能够促进人机群体信任与合作的社交机器人提供了潜在价值。

Abstract: In this study, we explore the potential of Game Theory as a means to
investigate cooperation and trust in human-robot mixed groups. Particularly, we
introduce the Public Good Game (PGG), a model highlighting the tension between
individual self-interest and collective well-being. In this work, we present a
modified version of the PGG, where three human participants engage in the game
with the humanoid robot iCub to assess whether various robot game strategies
(e.g., always cooperate, always free ride, and tit-for-tat) can influence the
participants' inclination to cooperate. We test our setup during a pilot study
with nineteen participants. A preliminary analysis indicates that participants
prefer not to invest their money in the common pool, despite they perceive the
robot as generous. By conducting this research, we seek to gain valuable
insights into the role that robots can play in promoting trust and cohesion
during human-robot interactions within group contexts. The results of this
study may hold considerable potential for developing social robots capable of
fostering trust and cooperation within mixed human-robot groups.

</details>


### [106] [Unlocking the Potential of Soft Actor-Critic for Imitation Learning](https://arxiv.org/abs/2509.24539)
*Nayari Marie Lessa,Melya Boukheddimi,Frank Kirchner*

Main category: cs.RO

TL;DR: 本文提出了一种结合对抗运动先验（AMP）和离策略软行动者-批评者（SAC）算法的新型模仿学习框架，以提高仿生机器人运动的自然性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前基于近端策略优化（PPO）的模仿学习方法在样本效率和策略泛化性上存在不足，需要一种更高效且稳定的替代方案。

Method: 通过将AMP与SAC结合，利用回放驱动的学习和熵正则化探索，提高了数据效率和鲁棒性。

Result: 实验表明，AMP+SAC在多地形四足运动任务中表现出更高的模仿奖励和稳定的任务执行能力。

Conclusion: 离策略模仿学习框架在机器人运动生成中具有显著潜力。

Abstract: Learning-based methods have enabled robots to acquire bio-inspired movements
with increasing levels of naturalness and adaptability. Among these, Imitation
Learning (IL) has proven effective in transferring complex motion patterns from
animals to robotic systems. However, current state-of-the-art frameworks
predominantly rely on Proximal Policy Optimization (PPO), an on-policy
algorithm that prioritizes stability over sample efficiency and policy
generalization. This paper proposes a novel IL framework that combines
Adversarial Motion Priors (AMP) with the off-policy Soft Actor-Critic (SAC)
algorithm to overcome these limitations. This integration leverages
replay-driven learning and entropy-regularized exploration, enabling
naturalistic behavior and task execution, improving data efficiency and
robustness. We evaluate the proposed approach (AMP+SAC) on quadruped gaits
involving multiple reference motions and diverse terrains. Experimental results
demonstrate that the proposed framework not only maintains stable task
execution but also achieves higher imitation rewards compared to the widely
used AMP+PPO method. These findings highlight the potential of an off-policy IL
formulation for advancing motion generation in robotics.

</details>


### [107] [Prompting Robot Teams with Natural Language](https://arxiv.org/abs/2509.24575)
*Nicolas Pfitzer,Eduardo Sebastián,Ajay Shankar,Amanda Prorok*

Main category: cs.RO

TL;DR: 提出一种框架，利用自然语言提示多机器人团队执行高级任务，结合语言模型的推理能力和RNN、GNN实现分散协作。


<details>
  <summary>Details</summary>
Motivation: 利用语言模型的能力理解和分解人类意图表达，并将其应用于多机器人协作与决策中。

Method: 将任务表示为DFA，通过RNN编码任务逻辑，并用GNN控制策略分散执行任务。

Result: 在模拟和实际多机器人任务中验证了轻量级可解释模型的有效性。

Conclusion: 框架成功将语言模型的推理能力与多机器人分散协作结合，适用于顺序和协作任务。

Abstract: This paper presents a framework towards prompting multi-robot teams with
high-level tasks using natural language expressions. Our objective is to use
the reasoning capabilities demonstrated by recent language models in
understanding and decomposing human expressions of intent, and repurpose these
for multi-robot collaboration and decision-making. The key challenge is that an
individual's behavior in a collective can be hard to specify and interpret, and
must continuously adapt to actions from others. This necessitates a framework
that possesses the representational capacity required by the logic and
semantics of a task, and yet supports decentralized and interactive real-time
operation. We solve this dilemma by recognizing that a task can be represented
as a deterministic finite automaton (DFA), and that recurrent neural networks
(RNNs) can encode numerous automata. This allows us to distill the logic and
sequential decompositions of sub-tasks obtained from a language model into an
RNN, and align its internal states with the semantics of a given task. By
training a graph neural network (GNN) control policy that is conditioned on the
hidden states of the RNN and the language embeddings, our method enables robots
to execute task-relevant actions in a decentralized manner. We present
evaluations of this single light-weight interpretable model on various
simulated and real-world multi-robot tasks that require sequential and
collaborative behavior by the team -- sites.google.com/view/prompting-teams.

</details>


### [108] [U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation](https://arxiv.org/abs/2509.24579)
*Linzhi Wu,Aoran Mei,Xiyue Wang,Guo-Niu Zhu,Zhongxue Gan*

Main category: cs.RO

TL;DR: U-DiT Policy是一种新型的U形扩散变换器框架，结合了U-Net的多尺度特征融合优势和Transformers的全局上下文建模能力，显著提升了机器人视觉运动控制的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的DP-U方法在全局上下文建模和过度平滑伪影方面存在局限，需要一种更强大的方法来增强表示能力和策略表达能力。

Method: 提出U-DiT Policy框架，保留U-Net的多尺度特征融合，同时引入Transformers的全局上下文建模能力。

Result: 在仿真和真实机器人任务中，U-DiT分别比基线方法性能提升10%和22.5%，且在多变环境下表现出更强的鲁棒性和泛化能力。

Conclusion: U-DiT Policy作为一种新基础，为基于扩散的机器人操作提供了高效且实用的解决方案。

Abstract: Diffusion-based methods have been acknowledged as a powerful paradigm for
end-to-end visuomotor control in robotics. Most existing approaches adopt a
Diffusion Policy in U-Net architecture (DP-U), which, while effective, suffers
from limited global context modeling and over-smoothing artifacts. To address
these issues, we propose U-DiT Policy, a novel U-shaped Diffusion Transformer
framework. U-DiT preserves the multi-scale feature fusion advantages of U-Net
while integrating the global context modeling capability of Transformers,
thereby enhancing representational power and policy expressiveness. We evaluate
U-DiT extensively across both simulation and real-world robotic manipulation
tasks. In simulation, U-DiT achieves an average performance gain of 10\% over
baseline methods and surpasses Transformer-based diffusion policies (DP-T) that
use AdaLN blocks by 6\% under comparable parameter budgets. On real-world
robotic tasks, U-DiT demonstrates superior generalization and robustness,
achieving an average improvement of 22.5\% over DP-U. In addition, robustness
and generalization experiments under distractor and lighting variations further
highlight the advantages of U-DiT. These results highlight the effectiveness
and practical potential of U-DiT Policy as a new foundation for diffusion-based
robotic manipulation.

</details>


### [109] [PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control](https://arxiv.org/abs/2509.24591)
*Haozhuo Zhang,Michele Caprio,Jing Shao,Qiang Zhang,Jian Tang,Shanghang Zhang,Wei Pan*

Main category: cs.RO

TL;DR: PoseDiff是一种结合机器人状态估计与控制的扩散模型，通过单张RGB图像直接生成结构化状态（如3D关键点或关节角），无需多阶段流程或辅助模态。它还支持视频到动作的逆向动力学，生成流畅的长时程动作序列。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人感知与控制之间的集成问题，提出一种统一框架，以实现高效、准确的跨模块协同。

Method: 基于条件扩散模型，直接从视觉观测映射到机器人状态，并通过视频关键帧生成连续动作序列。

Result: 在DREAM数据集上达到领先的姿态估计精度和实时性能；在Libero-Object任务中显著提升成功率。

Conclusion: PoseDiff为具身AI提供了一种可扩展、精确且高效的感知与控制桥梁。

Abstract: We present PoseDiff, a conditional diffusion model that unifies robot state
estimation and control within a single framework. At its core, PoseDiff maps
raw visual observations into structured robot states-such as 3D keypoints or
joint angles-from a single RGB image, eliminating the need for multi-stage
pipelines or auxiliary modalities. Building upon this foundation, PoseDiff
extends naturally to video-to-action inverse dynamics: by conditioning on
sparse video keyframes generated by world models, it produces smooth and
continuous long-horizon action sequences through an overlap-averaging strategy.
This unified design enables scalable and efficient integration of perception
and control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy
and real-time performance for pose estimation. On Libero-Object manipulation
tasks, it substantially improves success rates over existing inverse dynamics
modules, even under strict offline settings. Together, these results show that
PoseDiff provides a scalable, accurate, and efficient bridge between
perception, planning, and control in embodied AI. The video visualization
results can be found on the project page:
https://haozhuo-zhang.github.io/PoseDiff-project-page/.

</details>


### [110] [CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations](https://arxiv.org/abs/2509.24661)
*Zhiyuan Wu,Rolandos Alexandros Potamias,Xuyang Zhang,Zhongqun Zhang,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: CEDex提出了一种新型跨形态灵巧抓取合成方法，通过结合人类抓取运动学和机器人运动学，实现高效的抓取生成和优化，并构建了大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在缺乏人类运动学理解或需大量人工数据收集方面的不足，以实现更通用的机器人操作。

Method: CEDex利用预训练的条件变分自编码器生成人类接触表示，通过拓扑合并和基于距离场的优化实现抓取合成。

Result: 构建了包含500K对象和20M抓取的大规模数据集，实验显示CEDex优于现有方法。

Conclusion: CEDex为跨形态抓取提供了高效解决方案，其数据集促进了抓取学习的多样性和质量。

Abstract: Cross-embodiment dexterous grasp synthesis refers to adaptively generating
and optimizing grasps for various robotic hands with different morphologies.
This capability is crucial for achieving versatile robotic manipulation in
diverse environments and requires substantial amounts of reliable and diverse
grasp data for effective model training and robust generalization. However,
existing approaches either rely on physics-based optimization that lacks
human-like kinematic understanding or require extensive manual data collection
processes that are limited to anthropomorphic structures. In this paper, we
propose CEDex, a novel cross-embodiment dexterous grasp synthesis method at
scale that bridges human grasping kinematics and robot kinematics by aligning
robot kinematic models with generated human-like contact representations. Given
an object's point cloud and an arbitrary robotic hand model, CEDex first
generates human-like contact representations using a Conditional Variational
Auto-encoder pretrained on human contact data. It then performs kinematic human
contact alignment through topological merging to consolidate multiple human
hand parts into unified robot components, followed by a signed distance
field-based grasp optimization with physics-aware constraints. Using CEDex, we
construct the largest cross-embodiment grasp dataset to date, comprising 500K
objects across four gripper types with 20M total grasps. Extensive experiments
show that CEDex outperforms state-of-the-art approaches and our dataset
benefits cross-embodiment grasp learning with high-quality diverse grasps.

</details>


### [111] [Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering](https://arxiv.org/abs/2509.24697)
*Evelyn D'Elia,Paolo Maria Viceconte,Lorenzo Rapetti,Diego Ferigo,Giulio Romualdi,Giuseppe L'Erario,Raffaello Camoriano,Daniele Pucci*

Main category: cs.RO

TL;DR: 通过结合物理先验和控制原理，改进人形机器人模仿学习的轨迹生成，提高真实性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 模仿学习虽能生成平滑轨迹，但受限于数据量且忽略物理规律，导致轨迹发散和滑动接触，影响稳定性。

Method: 采用双管齐下的学习策略：1）在监督模仿学习中引入物理先验；2）在推理时使用比例积分控制器减少漂移。

Result: 在ergoCub人形机器人上验证，显著提高了轨迹准确性和物理约束符合性，兼容多种控制器。

Conclusion: 结合物理知识和控制原理能有效提升机器人运动生成的稳定性和真实性。

Abstract: Recent trends in humanoid robot control have successfully employed imitation
learning to enable the learned generation of smooth, human-like trajectories
from human data. While these approaches make more realistic motions possible,
they are limited by the amount of available motion data, and do not incorporate
prior knowledge about the physical laws governing the system and its
interactions with the environment. Thus they may violate such laws, leading to
divergent trajectories and sliding contacts which limit real-world stability.
We address such limitations via a two-pronged learning strategy which leverages
the known physics of the system and fundamental control principles. First, we
encode physics priors during supervised imitation learning to promote
trajectory feasibility. Second, we minimize drift at inference time by applying
a proportional-integral controller directly to the generated output state. We
validate our method on various locomotion behaviors for the ergoCub humanoid
robot, where a physics-informed loss encourages zero contact foot velocity. Our
experiments demonstrate that the proposed approach is compatible with multiple
controllers on a real robot and significantly improves the accuracy and
physical constraint conformity of generated trajectories.

</details>


### [112] [LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers](https://arxiv.org/abs/2509.24706)
*Andreea Tulbure,Rene Zurbruegg,Timm Grigat,Marco Hutter*

Main category: cs.RO

TL;DR: LLM-Handover是一个结合大型语言模型推理和部分分割的新框架，用于优化机器人-人类交接任务中的抓取选择和执行。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人交接方法常忽视人类交接后的动作，限制了通用性，因此需要一种能根据任务上下文选择抓取的方法。

Method: 通过RGB-D图像和任务描述，系统推断相关物体部分并选择优化交接后使用性的抓取。

Result: 在零样本设置下，任务成功率83%，用户研究中86%的参与者偏好该方法。

Conclusion: LLM-Handover显著提升了交接任务的适应性和用户体验。

Abstract: Effective human-robot collaboration depends on task-oriented handovers, where
robots present objects in ways that support the partners intended use. However,
many existing approaches neglect the humans post-handover action, relying on
assumptions that limit generalizability. To address this gap, we propose
LLM-Handover, a novel framework that integrates large language model
(LLM)-based reasoning with part segmentation to enable context-aware grasp
selection and execution. Given an RGB-D image and a task description, our
system infers relevant object parts and selects grasps that optimize
post-handover usability. To support evaluation, we introduce a new dataset of
60 household objects spanning 12 categories, each annotated with detailed part
labels. We first demonstrate that our approach improves the performance of the
used state-of-the-art part segmentation method, in the context of robot-human
handovers. Next, we show that LLM-Handover achieves higher grasp success rates
and adapts better to post-handover task constraints. During hardware
experiments, we achieve a success rate of 83% in a zero-shot setting over
conventional and unconventional post-handover tasks. Finally, our user study
underlines that our method enables more intuitive, context-aware handovers,
with participants preferring it in 86% of cases.

</details>


### [113] [APREBot: Active Perception System for Reflexive Evasion Robot](https://arxiv.org/abs/2509.24733)
*Zihao Xu,Kuankuan Sima,Junhao Deng,Zixuan Zhuang,Chunzheng Wang,Ce Hao,Jin Song Dong*

Main category: cs.RO

TL;DR: APREBot是一种集成了LiDAR和摄像头的主动感知系统，旨在提高四足机器人在动态环境中的障碍物避障能力，通过实验验证其在安全性和效率上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在动态环境中实时感知的挑战，弥补单一传感器系统的局限性。

Method: 结合LiDAR的全向扫描和摄像头的主动聚焦，实现分层感知和反射性避障。

Result: 在仿真和实际实验中，APREBot表现出比现有基线更高的安全性和操作效率。

Conclusion: APREBot为安全关键场景下的四足机器人提供了可靠的自主感知解决方案。

Abstract: Reliable onboard perception is critical for quadruped robots navigating
dynamic environments, where obstacles can emerge from any direction under
strict reaction-time constraints. Single-sensor systems face inherent
limitations: LiDAR provides omnidirectional coverage but lacks rich texture
information, while cameras capture high-resolution detail but suffer from
restricted field of view. We introduce APREBot (Active Perception System for
Reflexive Evasion Robot), a novel framework that integrates reflexive evasion
with active hierarchical perception. APREBot strategically combines LiDAR-based
omnidirectional scanning with camera-based active focusing, achieving
comprehensive environmental awareness essential for agile obstacle avoidance in
quadruped robots. We validate APREBot through extensive sim-to-real experiments
on a quadruped platform, evaluating diverse obstacle types, trajectories, and
approach directions. Our results demonstrate substantial improvements over
state-of-the-art baselines in both safety metrics and operational efficiency,
highlighting APREBot's potential for dependable autonomy in safety-critical
scenarios. Videos are available at https://sites.google.com/view/aprebot/

</details>


### [114] [SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework](https://arxiv.org/abs/2509.24763)
*Xiangyi Meng,Delun Li,Zihao Mao,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: SSR-ZSON提出了一种空间语义相对零样本对象导航方法，通过平衡空间覆盖和语义密度，结合LLM全局引导机制，显著提高了导航效率。


<details>
  <summary>Details</summary>
Motivation: 解决零样本对象导航中因语义引导不足和空间记忆有限导致的低效探索和局部陷阱问题。

Method: 基于TARE分层探索框架，集成视点生成策略和LLM全局引导机制，优先高语义密度区域并评估语义关联。

Result: 在Matterport3D和Habitat-Matterport3D数据集上，SR提高了18.5%和11.2%，SPL提升了0.181和0.140。

Conclusion: SSR-ZSON通过创新的视点生成和语义关联评估，实现了实时高效导航，优于现有方法。

Abstract: Zero-shot object navigation in unknown environments presents significant
challenges, mainly due to two key limitations: insufficient semantic guidance
leads to inefficient exploration, while limited spatial memory resulting from
environmental structure causes entrapment in local regions. To address these
issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object
navigation method based on the TARE hierarchical exploration framework,
integrating a viewpoint generation strategy balancing spatial coverage and
semantic density with an LLM-based global guidance mechanism. The performance
improvement of the proposed method is due to two key innovations. First, the
viewpoint generation strategy prioritizes areas of high semantic density within
traversable sub-regions to maximize spatial coverage and minimize invalid
exploration. Second, coupled with an LLM-based global guidance mechanism, it
assesses semantic associations to direct navigation toward high-value spaces,
preventing local entrapment and ensuring efficient exploration. Deployed on
hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves
real-time operation and superior performance. On Matterport3D and
Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\% and
11.2\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140,
respectively, over state-of-the-art methods.

</details>


### [115] [IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks](https://arxiv.org/abs/2509.24768)
*Eric Hannus,Miika Malin,Tran Nguyen Le,Ville Kyrki*

Main category: cs.RO

TL;DR: IA-VLA框架通过利用大型视觉语言模型的强大语言理解能力，增强VLAs在处理复杂语言指令时的表现，特别是在视觉重复对象任务中。


<details>
  <summary>Details</summary>
Motivation: 现有VLAs受限于实时动作输出的需求，难以处理复杂的语言理解任务，如相对位置描述的指令。

Method: 引入IA-VLA框架，借助大型视觉语言模型生成上下文，增强VLA的输入。

Result: 实验表明，IA-VLA在处理视觉重复对象的任务时表现更优，尤其是在需要从演示中推导概念的复杂指令上。

Conclusion: IA-VLA通过结合大型语言模型的优势，显著提升了VLAs的复杂语言理解能力。

Abstract: Vision-language-action models (VLAs) have become an increasingly popular
approach for addressing robot manipulation problems in recent years. However,
such models need to output actions at a rate suitable for robot control, which
limits the size of the language model they can be based on, and consequently,
their language understanding capabilities. Manipulation tasks may require
complex language instructions, such as identifying target objects by their
relative positions, to specify human intention. Therefore, we introduce IA-VLA,
a framework that utilizes the extensive language understanding of a large
vision language model as a pre-processing stage to generate improved context to
augment the input of a VLA. We evaluate the framework on a set of semantically
complex tasks which have been underexplored in VLA literature, namely tasks
involving visual duplicates, i.e., visually indistinguishable objects. A
dataset of three types of scenes with duplicate objects is used to compare a
baseline VLA against two augmented variants. The experiments show that the VLA
benefits from the augmentation scheme, especially when faced with language
instructions that require the VLA to extrapolate from concepts it has seen in
the demonstrations. For the code, dataset, and videos, see
https://sites.google.com/view/ia-vla.

</details>


### [116] [Fidelity-Aware Data Composition for Robust Robot Generalization](https://arxiv.org/abs/2509.24797)
*Zizhao Tong,Di Chen,Sicheng Hu,Hongwei Fan,Liliang Chen,Guanghui Ren,Hao Tang,Hao Dong,Ling Shao*

Main category: cs.RO

TL;DR: 论文提出了CIFT框架，通过优化数据组合来解决机器人策略在分布外（OOD）场景下的泛化问题，结合信息保真度和视觉多样性，显著提升了泛化性能。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉同质数据集训练的通用机器人策略容易陷入捷径学习，导致分布外泛化能力不足。现有数据增强方法虽引入多样性，但忽略了信息保真度的重要性。

Method: 提出CIFT框架，基于信息保真度的代理指标优化数据组合，引入Decoherence Point概念识别训练稳定性变化，并提出MVAug生成因果解耦的数据增强方法。

Result: 应用CIFT后，策略架构（如$\pi_0$和Diffusion Policy）的OOD成功率提升超过54%。

Conclusion: 信息保真度感知的数据组合是开发鲁棒通用机器人的关键因素。

Abstract: Generalist robot policies trained on large-scale, visually homogeneous
datasets can be susceptible to shortcut learning, which impairs their
out-of-distribution (OOD) generalization. While generative data augmentation is
a common approach to introduce diversity, it presents a subtle challenge: data
composition. Naively mixing real and synthetic data can corrupt the learning
signal, as this process often prioritizes visual diversity at the expense of
information fidelity. This paper suggests that robust generalization depends on
principled, fidelity-aware data composition. We introduce Coherent Information
Fidelity Tuning (CIFT), a framework that treats data composition as an
optimization problem. CIFT uses a practical proxy for Information Fidelity
based on the feature-space geometry of a dataset. This enables the
identification of a phase transition, termed the Decoherence Point, where
training stability degrades. The framework includes a generative engine,
Multi-View Video Augmentation (MVAug), to synthesize a causally disentangled
data spectrum for this tuning process. Applying CIFT to policy architectures
such as $\pi_0$ and Diffusion Policy improves OOD success rates by over 54\%.
These results indicate that fidelity-aware composition, beyond data synthesis
alone, is an important component for developing robust, general-purpose robots.

</details>


### [117] [Towards Modular and Accessible AUV Systems](https://arxiv.org/abs/2509.24864)
*Mingxi Zhou,Farhang Naderi,Yuewei Fu,Tony Jacob,Lin Zhao,Manavi Panjnani,Chengzhi Yuan,William McConnell,Emir Cem Gezer*

Main category: cs.RO

TL;DR: 介绍了一种名为Marine Vehicle Packages (MVP)的新型开放模块化框架，用于自主水下航行器研究，兼具软硬件设计与实验验证。


<details>
  <summary>Details</summary>
Motivation: 为自主水下航行器研究提供高度定制化且易于构建的模块化框架。

Method: 设计了可扩展的硬件系统和模块化软件架构，集成了新功能如可调节推进器和高层图形用户界面。

Result: 通过仿真和实地实验验证了MVP的性能与兼容性。

Conclusion: MVP框架成功提升了自主水下航行器的定制化能力和研究效率。

Abstract: This paper reports the development of a new open-access modular framework,
called Marine Vehicle Packages (MVP), for Autonomous Underwater Vehicles. The
framework consists of both software and hardware designs allowing easy
construction of AUV for research with increased customizability and sufficient
payload capacity. This paper will present the scalable hardware system design
and the modular software design architecture. New features, such as articulated
thruster integration and high-level Graphic User Interface will be discussed.
Both simulation and field experiments results are shown to highlight the
performance and compatibility of the MVP.

</details>


### [118] [Finding an Initial Probe Pose in Teleoperated Robotic Echocardiography via 2D LiDAR-Based 3D Reconstruction](https://arxiv.org/abs/2509.24867)
*Mariadas Capsran Roshan,Edgar M Hidalgo,Mats Isaksson,Michelle Dunn,Jagannatha Charjee Pyaraka*

Main category: cs.RO

TL;DR: 本文提出一种基于机器人搭载的2D LiDAR技术，用于自动估计心脏超声探头初始位置的方法，以解决传统超声检查依赖操作者的问题。


<details>
  <summary>Details</summary>
Motivation: 心脏超声检查操作依赖性强且训练有素的技师资源有限，尤其在偏远地区。现有机器人辅助方法耗时增加，自动化非专家任务有望减轻负担。

Method: 采用机器人搭载的2D LiDAR重建胸部3D表面，通过校准和模板对齐自动估计探头初始位置。

Result: 校准精度RMS为1.8 mm，旋转误差低于0.2°。人体试验显示探头初始点误差20-30 mm，重复试验变异小于4 mm。

Conclusion: 该方法为自动化心脏超声提供可行方案，未来需进一步优化精度。

Abstract: Echocardiography is a key imaging modality for cardiac assessment but remains
highly operator-dependent, and access to trained sonographers is limited in
underserved settings. Teleoperated robotic echocardiography has been proposed
as a solution; however, clinical studies report longer examination times than
manual procedures, increasing diagnostic delays and operator workload.
Automating non-expert tasks, such as automatically moving the probe to an ideal
starting pose, offers a pathway to reduce this burden. Prior vision- and
depth-based approaches to estimate an initial probe pose are sensitive to
lighting, texture, and anatomical variability. We propose a robot-mounted 2D
LiDAR-based approach that reconstructs the chest surface in 3D and estimates
the initial probe pose automatically. To the best of our knowledge, this is the
first demonstration of robot-mounted 2D LiDAR used for 3D reconstruction of a
human body surface. Through plane-based extrinsic calibration, the
transformation between the LiDAR and robot base frames was estimated with an
overall root mean square (RMS) residual of 1.8 mm and rotational uncertainty
below 0.2{\deg}. The chest front surface, reconstructed from two linear LiDAR
sweeps, was aligned with non-rigid templates to identify an initial probe pose.
A mannequin-based study assessing reconstruction accuracy showed mean surface
errors of 2.78 +/- 0.21 mm. Human trials (N=5) evaluating the proposed approach
found probe initial points typically 20-30 mm from the clinically defined
initial point, while the variation across repeated trials on the same subject
was less than 4 mm.

</details>


### [119] [JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning](https://arxiv.org/abs/2509.24892)
*Shilong Ji,Yinuo Chen,Chuqi Wang,Jiayu Chen,Ruize Zhang,Feng Gao,Wenhao Tang,Shu'ang Yu,Sirui Xiang,Xinlei Chen,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: 论文提出JuggleRL，首个基于强化学习的空中杂技系统，通过学习闭环策略实现高效空中球杂技，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究无人机在不确定条件下执行精确且复杂交互任务的挑战，如空中球杂技。

Method: 利用强化学习在大规模仿真中训练策略，结合奖励函数设计和领域随机化以减小仿真与现实的差距。

Result: JuggleRL在真实实验中平均完成311次击球，最高达462次，远超基于模型的方法。

Conclusion: 强化学习能助力无人机在动态交互任务中实现稳定控制。

Abstract: Aerial robots interacting with objects must perform precise, contact-rich
maneuvers under uncertainty. In this paper, we study the problem of aerial ball
juggling using a quadrotor equipped with a racket, a task that demands accurate
timing, stable control, and continuous adaptation. We propose JuggleRL, the
first reinforcement learning-based system for aerial juggling. It learns
closed-loop policies in large-scale simulation using systematic calibration of
quadrotor and ball dynamics to reduce the sim-to-real gap. The training
incorporates reward shaping to encourage racket-centered hits and sustained
juggling, as well as domain randomization over ball position and coefficient of
restitution to enhance robustness and transferability. The learned policy
outputs mid-level commands executed by a low-level controller and is deployed
zero-shot on real hardware, where an enhanced perception module with a
lightweight communication protocol reduces delays in high-frequency state
estimation and ensures real-time control. Experiments show that JuggleRL
achieves an average of $311$ hits over $10$ consecutive trials in the real
world, with a maximum of $462$ hits observed, far exceeding a model-based
baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the
policy generalizes to unseen conditions, successfully juggling a lighter $5$ g
ball with an average of $145.9$ hits. This work demonstrates that reinforcement
learning can empower aerial robots with robust and stable control in dynamic
interaction tasks.

</details>


### [120] [DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits](https://arxiv.org/abs/2509.24903)
*Lantao Li,Kang Yang,Rui Song,Chen Sun*

Main category: cs.RO

TL;DR: DRCP框架通过跨模态协作感知和轻量级扩散优化模块，提升自动驾驶在动态环境中的感知鲁棒性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中因部分检测和噪声累积导致的下游检测精度不足问题。

Method: 融合Precise-Pyramid-Cross-Modality-Cross-Agent模块和Mask-Diffusion-Mask-Aggregation模块，优化特征融合与扩散。

Result: 在移动平台上实现实时性能，并在挑战性条件下显著提升鲁棒性。

Conclusion: DRCP为动态驾驶环境提供了一种高效且鲁棒的协作感知解决方案。

Abstract: Cooperative perception enabled by Vehicle-to-Everything communication has
shown great promise in enhancing situational awareness for autonomous vehicles
and other mobile robotic platforms. Despite recent advances in perception
backbones and multi-agent fusion, real-world deployments remain challenged by
hard detection cases, exemplified by partial detections and noise accumulation
which limit downstream detection accuracy. This work presents Diffusion on
Reinforced Cooperative Perception (DRCP), a real-time deployable framework
designed to address aforementioned issues in dynamic driving environments. DRCP
integrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent,
a cross-modal cooperative perception module that leverages
camera-intrinsic-aware angular partitioning for attention-based fusion and
adaptive convolution to better exploit external features; and (2)
Mask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement
module that encourages robustness against feature perturbations and aligns
bird's-eye-view features closer to the task-optimal manifold. The proposed
system achieves real-time performance on mobile platforms while significantly
improving robustness under challenging conditions. Code will be released in
late 2025.

</details>


### [121] [Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation](https://arxiv.org/abs/2509.24907)
*Thanh Long Nguyen,Duc Phu Nguyen,Thanh Thao Ton Nu,Quan Le,Thuan Hoang Tran,Manh Duong Phung*

Main category: cs.RO

TL;DR: 提出一种基于RGB-D相机和PCA的方法，用于识别人群交互以实现社交机器人的自然导航。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统常忽视社交线索，本文旨在填补这一空白，提升人机交互的流畅性。

Method: 利用RGB-D相机获取3D人体关键点和位置，通过PCA确定交互方向，并结合shoelace公式计算兴趣点和互动区域。

Result: 实验表明，该方法能有效识别不同场景下的群体交互，且处理速度快（4 ms/帧），易于集成到现有导航系统。

Conclusion: 该方法为社交机器人提供了高效的群体交互识别方案，适用于实际应用。

Abstract: {Recognizing human interactions is essential for social robots as it enables
them to navigate safely and naturally in shared environments. Conventional
robotic systems however often focus on obstacle avoidance, neglecting social
cues necessary for seamless human-robot interaction. To address this gap, we
propose a framework to recognize human group interactions for socially aware
navigation. Our method utilizes color and depth frames from a monocular RGB-D
camera to estimate 3D human keypoints and positions. Principal component
analysis (PCA) is then used to determine dominant interaction directions. The
shoelace formula is finally applied to compute interest points and engagement
areas. Extensive experiments have been conducted to evaluate the validity of
the proposed method. The results show that our method is capable of recognizing
group interactions across different scenarios with varying numbers of
individuals. It also achieves high-speed performance, processing each frame in
approximately 4 ms on a single-board computer used in robotic systems. The
method is implemented as a ROS 2 package making it simple to integrate into
existing navigation systems. Source code is available at
https://github.com/thanhlong103/social-interaction-detector

</details>


### [122] [From Code to Action: Hierarchical Learning of Diffusion-VLM Policies](https://arxiv.org/abs/2509.24917)
*Markus Peschl,Pietro Mazzaglia,Daniel Dijkman*

Main category: cs.RO

TL;DR: 该论文提出了一种分层框架，结合代码生成的视觉语言模型（VLM）和低级别扩散策略，以提高机器人模仿学习的泛化能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人模仿学习在复杂、长周期任务中泛化能力有限和数据稀缺的问题。

Method: 使用VLM分解任务描述为可执行子程序，并通过扩散策略模仿机器人行为，同时引入记忆机制处理非马尔可夫任务。

Result: 该方法实现了可解释的策略分解，提升泛化能力，并支持高级规划和低级控制的单独评估。

Conclusion: 分层框架和结构化监督是提高机器人模仿学习性能的有效方法。

Abstract: Imitation learning for robotic manipulation often suffers from limited
generalization and data scarcity, especially in complex, long-horizon tasks. In
this work, we introduce a hierarchical framework that leverages code-generating
vision-language models (VLMs) in combination with low-level diffusion policies
to effectively imitate and generalize robotic behavior. Our key insight is to
treat open-source robotic APIs not only as execution interfaces but also as
sources of structured supervision: the associated subtask functions - when
exposed - can serve as modular, semantically meaningful labels. We train a VLM
to decompose task descriptions into executable subroutines, which are then
grounded through a diffusion policy trained to imitate the corresponding robot
behavior. To handle the non-Markovian nature of both code execution and certain
real-world tasks, such as object swapping, our architecture incorporates a
memory mechanism that maintains subtask context across time. We find that this
design enables interpretable policy decomposition, improves generalization when
compared to flat policies and enables separate evaluation of high-level
planning and low-level control.

</details>


### [123] [CineWild: Balancing Art and Robotics for Ethical Wildlife Documentary Filmmaking](https://arxiv.org/abs/2509.24921)
*Pablo Pueyo,Fernando Caballero,Ana Cristina Murillo,Eduardo Montijano*

Main category: cs.RO

TL;DR: CineWild是一个结合机器人、摄影和伦理学的自主无人机框架，通过动态调整飞行路径和相机设置来平衡电影质量与动物福利。


<details>
  <summary>Details</summary>
Motivation: 无人机在纪录片制作中提供了独特视角，但也可能干扰野生动物。研究旨在解决这一伦理问题。

Method: 基于模型预测控制，CineWild采用自适应变焦、路径规划和低噪音机动来减少对动物的干扰。

Result: 通过模拟研究验证了系统的有效性，代码将在论文接受后公开。

Conclusion: CineWild展示了工程技术、视觉叙事和环境伦理的跨学科创新。

Abstract: Drones, or unmanned aerial vehicles (UAVs), have become powerful tools across
domains-from industry to the arts. In documentary filmmaking, they offer
dynamic, otherwise unreachable perspectives, transforming how stories are told.
Wildlife documentaries especially benefit, yet drones also raise ethical
concerns: the risk of disturbing the animals they aim to capture. This paper
introduces CineWild, an autonomous UAV framework that combines robotics,
cinematography, and ethics. Built on model predictive control, CineWild
dynamically adjusts flight paths and camera settings to balance cinematic
quality with animal welfare. Key features include adaptive zoom for filming
from acoustic and visual safe distances, path-planning that avoids an animal's
field of view, and smooth, low-noise maneuvers. CineWild exemplifies
interdisciplinary innovation-bridging engineering, visual storytelling, and
environmental ethics. We validate the system through simulation studies and
will release the code upon acceptance.

</details>


### [124] [Trajectory Prediction via Bayesian Intention Inference under Unknown Goals and Kinematics](https://arxiv.org/abs/2509.24928)
*Shunan Yin,Zehui Lu,Shaoshuai Mou*

Main category: cs.RO

TL;DR: 本文提出了一种自适应贝叶斯算法，用于通过意图推断实时预测目标轨迹，适用于意图和运动特性未知且可能变化的情况。


<details>
  <summary>Details</summary>
Motivation: 解决目标意图和运动特性未知且可能变化时，实时预测轨迹的挑战。

Method: 算法同时估计目标当前意图（马尔可夫潜在状态）和意图参数（描述目标遵循最短路径策略的程度），并通过采样机制生成概率预测。

Result: 实验证明该方法显著优于非自适应和部分自适应方法，实时运行频率达270 Hz。

Conclusion: 该算法无需训练或详细的先验知识，适用于多种机器人系统。

Abstract: This work introduces an adaptive Bayesian algorithm for real-time trajectory
prediction via intention inference, where a target's intentions and motion
characteristics are unknown and subject to change. The method concurrently
estimates two critical variables: the target's current intention, modeled as a
Markovian latent state, and an intention parameter that describes the target's
adherence to a shortest-path policy. By integrating this joint update
technique, the algorithm maintains robustness against abrupt intention shifts
and unknown motion dynamics. A sampling-based trajectory prediction mechanism
then exploits these adaptive estimates to generate probabilistic forecasts with
quantified uncertainty. We validate the framework through numerical
experiments: Ablation studies of two cases, and a 500-trial Monte Carlo
analysis; Hardware demonstrations on quadrotor and quadrupedal platforms.
Experimental results demonstrate that the proposed approach significantly
outperforms non-adaptive and partially adaptive methods. The method operates in
real time around 270 Hz without requiring training or detailed prior knowledge
of target behavior, showcasing its applicability in various robotic systems.

</details>


### [125] [World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](https://arxiv.org/abs/2509.24948)
*Junjin Xiao,Yandan Yang,Xinyuan Chang,Ronghan Chen,Feng Xiong,Mu Xu,Wei-Shi Zheng,Qing Zhang*

Main category: cs.RO

TL;DR: 论文提出World-Env框架，通过虚拟仿真改进VLA模型的数据稀缺问题，提高任务成功率和安全性。


<details>
  <summary>Details</summary>
Motivation: VLA模型依赖大规模演示数据且难以在现实环境中重置，尤其在高风险领域（如工业自动化）中存在局限，亟需解决方案。

Method: World-Env框架包含视频仿真器和VLM引导的反射器，通过虚拟仿真替代真实交互，实现高效安全的后训练。

Result: 实验表明，该方法仅需五个专家演示即可显著提升性能，有效克服数据低效和安全约束。

Conclusion: World-Env为资源受限环境中的VLA模型后训练提供了实用且可扩展的解决方案。

Abstract: Vision-Language-Action (VLA) models trained via imitation learning suffer
from significant performance degradation in data-scarce scenarios due to their
reliance on large-scale demonstration datasets. Although reinforcement learning
(RL)-based post-training has proven effective in addressing data scarcity, its
application to VLA models is hindered by the non-resettable nature of
real-world environments. This limitation is particularly critical in high-risk
domains such as industrial automation, where interactions often induce state
changes that are costly or infeasible to revert. Furthermore, existing VLA
approaches lack a reliable mechanism for detecting task completion, leading to
redundant actions that reduce overall task success rates. To address these
challenges, we propose World-Env, an RL-based post-training framework that
replaces physical interaction with a low-cost, world model-based virtual
simulator. World-Env consists of two key components: (1) a video-based world
simulator that generates temporally consistent future visual observations, and
(2) a vision-language model (VLM)-guided instant reflector that provides
continuous reward signals and predicts action termination. This simulated
environment enables VLA models to safely explore and generalize beyond their
initial imitation learning distribution. Our method achieves notable
performance gains with as few as five expert demonstrations per task.
Experiments on complex robotic manipulation tasks demonstrate that World-Env
effectively overcomes the data inefficiency, safety constraints, and
inefficient execution of conventional VLA models that rely on real-world
interaction, offering a practical and scalable solution for post-training in
resource-constrained settings.

</details>


### [126] [MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation](https://arxiv.org/abs/2509.24956)
*Jan Ole von Hartz,Lukas Schweizer,Joschka Boedecker,Abhinav Valada*

Main category: cs.RO

TL;DR: 提出了一种多流生成策略（MSG），通过推断时组合多个对象中心策略来提高泛化能力和样本效率，显著减少演示需求并提升性能。


<details>
  <summary>Details</summary>
Motivation: 生成式机器人策略（如Flow Matching）样本效率低，现有对象中心策略未能解决这一问题。

Method: 提出MSG框架，训练多个对象中心策略并在推断时组合，模型无关且仅需推断。

Result: 仅需5次演示即可学习高质量策略，减少95%演示需求，性能提升89%。

Conclusion: MSG有效提高样本效率和泛化能力，支持零样本对象实例迁移。

Abstract: Generative robot policies such as Flow Matching offer flexible, multi-modal
policy learning but are sample-inefficient. Although object-centric policies
improve sample efficiency, it does not resolve this limitation. In this work,
we propose Multi-Stream Generative Policy (MSG), an inference-time composition
framework that trains multiple object-centric policies and combines them at
inference to improve generalization and sample efficiency. MSG is
model-agnostic and inference-only, hence widely applicable to various
generative policies and training paradigms. We perform extensive experiments
both in simulation and on a real robot, demonstrating that our approach learns
high-quality generative policies from as few as five demonstrations, resulting
in a 95% reduction in demonstrations, and improves policy performance by 89
percent compared to single-stream approaches. Furthermore, we present
comprehensive ablation studies on various composition strategies and provide
practical recommendations for deployment. Finally, MSG enables zero-shot object
instance transfer. We make our code publicly available at
https://msg.cs.uni-freiburg.de.

</details>


### [127] [Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks](https://arxiv.org/abs/2509.24972)
*Vijja Wichitwechkarn,Emlyn Williams,Charles Fox,Ruchi Choudhary*

Main category: cs.RO

TL;DR: 提出了一种无需额外训练或标注的单次示范模仿学习方法，适用于多步和单步任务，性能优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单步任务表现良好，但在多步任务中仍需额外训练或标注，限制了应用范围。

Method: 基于单次示范的模仿学习方法，无需额外模型训练或手动标注。

Result: 多步任务平均成功率82.5%，单步任务90%，性能优于基线。

Conclusion: 该方法在多步和单步任务中均表现优异，计算高效。

Abstract: Recent advances in one-shot imitation learning have enabled robots to acquire
new manipulation skills from a single human demonstration. While existing
methods achieve strong performance on single-step tasks, they remain limited in
their ability to handle long-horizon, multi-step tasks without additional model
training or manual annotation. We propose a method that can be applied to this
setting provided a single demonstration without additional model training or
manual annotation. We evaluated our method on multi-step and single-step
manipulation tasks where our method achieves an average success rate of 82.5%
and 90%, respectively. Our method matches and exceeds the performance of the
baselines in both these cases. We also compare the performance and
computational efficiency of alternative pre-trained feature extractors within
our framework.

</details>


### [128] [Path Diffuser: Diffusion Model for Data-Driven Traffic Simulator](https://arxiv.org/abs/2509.24995)
*Da Saem Lee,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 论文提出了一种名为 Path Diffuser (PD) 的两阶段扩散模型，用于生成基于地图的车辆轨迹，解决了传统方法依赖历史数据的问题。


<details>
  <summary>Details</summary>
Motivation: 传统规则规划和基于学习的模拟器在生成多样化且真实的交通场景时存在局限性，尤其是在缺乏历史轨迹数据的情况下。

Method: PD 采用两阶段扩散模型，结合运动基元先验和 Frenet 帧候选轨迹，确保生成的轨迹符合道路规范。

Result: 在 Argoverse2 数据集上，PD 在分布指标、常识指标和道路合规性上显著优于基线方法。

Conclusion: Path Diffuser 提供了一种高效且通用的方法，能够在缺乏历史数据的情况下生成多样化和真实的交通场景。

Abstract: Simulating diverse and realistic traffic scenarios is critical for developing
and testing autonomous planning. Traditional rule-based planners lack diversity
and realism, while learning-based simulators often replay, forecast, or edit
scenarios using historical agent trajectories. However, they struggle to
generate new scenarios, limiting scalability and diversity due to their
reliance on fully annotated logs and historical data. Thus, a key challenge for
a learning-based simulator's performance is that it requires agents' past
trajectories and pose information in addition to map data, which might not be
available for all agents on the road.Without which, generated scenarios often
produce unrealistic trajectories that deviate from drivable areas, particularly
under out-of-distribution (OOD) map scenes (e.g., curved roads). To address
this, we propose Path Diffuser (PD): a two-stage, diffusion model for
generating agent pose initializations and their corresponding trajectories
conditioned on the map, free of any historical context of agents' trajectories.
Furthermore, PD incorporates a motion primitive-based prior, leveraging Frenet
frame candidate trajectories to enhance diversity while ensuring road-compliant
trajectory generation. We also explore various design choices for modeling
complex multi-agent interactions. We demonstrate the effectiveness of our
method through extensive experiments on the Argoverse2 Dataset and additionally
evaluate the generalizability of the approach on OOD map variants. Notably,
Path Diffuser outperforms the baseline methods by 1.92x on distribution
metrics, 1.14x on common-sense metrics, and 1.62x on road compliance from
adversarial benchmarks.

</details>


### [129] [AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation](https://arxiv.org/abs/2509.25032)
*Ryosuke Takanami,Petr Khrapchenkov,Shu Morikuni,Jumpei Arima,Yuta Takaba,Shunsuke Maeda,Takuya Okubo,Genki Sano,Satoshi Sekioka,Aoi Kadoya,Motonari Kambara,Naoya Nishiura,Haruto Suzuki,Takanori Yoshimoto,Koya Sakamoto,Shinnosuke Ono,Hu Yang,Daichi Yashima,Aoi Horo,Tomohiro Motoda,Kensuke Chiyoma,Hiroshi Ito,Koki Fukuda,Akihito Goto,Kazumi Morinaga,Yuya Ikeda,Riko Kawada,Masaki Yoshikawa,Norio Kosuge,Yuki Noguchi,Kei Ota,Tatsuya Matsushima,Yusuke Iwasawa,Yutaka Matsuo,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 论文提出了AIRoA MoMa数据集，填补了现有移动操作数据集的不足，包含多模态数据和分层注释，用于支持视觉-语言-动作模型的进阶研究。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化环境中执行自然语言指令仍面临挑战，需要大规模多模态数据集来支持鲁棒的移动操作任务。

Method: 通过收集同步的RGB图像、关节状态、六轴手腕力扭矩信号和机器人内部状态，并结合分层注释（子目标和原始动作），构建了一个大规模数据集。

Result: 数据集包含25,469个样本（约94小时数据），标准化为LeRobot v2.1格式，支持分层学习和错误分析。

Conclusion: AIRoA MoMa数据集为下一代视觉-语言-动作模型提供了关键基准，推动了移动操作领域的发展。

Abstract: As robots transition from controlled settings to unstructured human
environments, building generalist agents that can reliably follow natural
language instructions remains a central challenge. Progress in robust mobile
manipulation requires large-scale multimodal datasets that capture contact-rich
and long-horizon tasks, yet existing resources lack synchronized force-torque
sensing, hierarchical annotations, and explicit failure cases. We address this
gap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset
for mobile manipulation. It includes synchronized RGB images, joint states,
six-axis wrist force-torque signals, and internal robot states, together with a
novel two-layer annotation schema of sub-goals and primitive actions for
hierarchical learning and error analysis. The initial dataset comprises 25,469
episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is
fully standardized in the LeRobot v2.1 format. By uniquely integrating mobile
manipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa
provides a critical benchmark for advancing the next generation of
Vision-Language-Action models. The first version of our dataset is now
available at https://huggingface.co/datasets/airoa-org/airoa-moma .

</details>


### [130] [AgriCruiser: An Open Source Agriculture Robot for Over-the-row Navigation](https://arxiv.org/abs/2509.25056)
*Kenny Truong,Yongkyu Lee,Jason Irie,Shivam Kumar Panda,Shahab Ahmad,Md. Mukhlesur Rahman,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriCruiser是一款低成本、可快速适应不同作物和行布局的开源农业机器人，通过精准喷洒实现高效除草，减少作物损伤，并提供多功能农业应用基础。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、可重构的农业机器人，以实现高效杂草管理并减少作物损伤，同时为其他农业应用提供多功能平台。

Method: 设计了一个可调节轨道宽度和地面高度的机器人底盘，配备精准喷洒系统，并在不同地形上测试其移动性能。

Result: 单次机器人喷洒在12块亚麻田中杂草数量减少24至42倍，作物损伤更少，底盘成本约为5000至6000美元。

Conclusion: AgriCruiser展示了低成本可重构机器人在高效除草和多功能农业应用中的潜力，并提供开源设计以促进研究和采用。

Abstract: We present the AgriCruiser, an open-source over-the-row agricultural robot
developed for low-cost deployment and rapid adaptation across diverse crops and
row layouts. The chassis provides an adjustable track width of 1.42 m to 1.57
m, along with a ground clearance of 0.94 m. The AgriCruiser achieves compact
pivot turns with radii of 0.71 m to 0.79 m, enabling efficient headland
maneuvers. The platform is designed for the integration of the other
subsystems, and in this study, a precision spraying system was implemented to
assess its effectiveness in weed management. In twelve flax plots, a single
robotic spray pass reduced total weed populations (pigweed and Venice mallow)
by 24- to 42-fold compared to manual weeding in four flax plots, while also
causing less crop damage. Mobility experiments conducted on concrete, asphalt,
gravel, grass, and both wet and dry soil confirmed reliable traversal
consistent with torque sizing. The complete chassis can be constructed from
commodity T-slot extrusion with minimal machining, resulting in a bill of
materials costing approximately $5,000 - $6,000, which enables replication and
customization. The mentioned results demonstrate that low-cost, reconfigurable
over-the-row robots can achieve effective weed management with reduced crop
damage and labor requirements, while providing a versatile foundation for
phenotyping, sensing, and other agriculture applications. Design files and
implementation details are released to accelerate research and adoption of
modular agricultural robotics.

</details>


### [131] [Crop Spirals: Re-thinking the field layout for future robotic agriculture](https://arxiv.org/abs/2509.25091)
*Lakshan Lavan,Lanojithan Thiyagarasa,Udara Muthugala,Rajitha de Silva*

Main category: cs.RO

TL;DR: 论文提出了一种面向机器人的方形螺旋作物布局（替代传统的线性布局），结合新的导航技术，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 传统线性作物布局专为拖拉机设计，对机器人导航不利（如转弯困难、距离长、感知混淆）。

Method: 设计了机器人中心的方形螺旋布局及配套导航技术（DH-ResNet18、A*规划、MPC等）。

Result: 模拟显示，螺旋布局路径缩短28%、执行提速25%，多机器人协调效率提升33-37%。

Conclusion: 重新设计田间几何布局以适应自主农业，具有显著潜力。

Abstract: Conventional linear crop layouts, optimised for tractors, hinder robotic
navigation with tight turns, long travel distances, and perceptual aliasing. We
propose a robot-centric square spiral layout with a central tramline, enabling
simpler motion and more efficient coverage. To exploit this geometry, we
develop a navigation stack combining DH-ResNet18 waypoint regression,
pixel-to-odometry mapping, A* planning, and model predictive control (MPC). In
simulations, the spiral layout yields up to 28% shorter paths and about 25%
faster execution for waypoint-based tasks across 500 waypoints than linear
layouts, while full-field coverage performance is comparable to an optimised
linear U-turn strategy. Multi-robot studies demonstrate efficient coordination
on the spirals rule-constrained graph, with a greedy allocator achieving 33-37%
lower batch completion times than a Hungarian assignment under our setup. These
results highlight the potential of redesigning field geometry to better suit
autonomous agriculture.

</details>


### [132] [Curriculum Imitation Learning of Distributed Multi-Robot Policies](https://arxiv.org/abs/2509.25097)
*Jesús Roche,Eduardo Sebastián,Eduardo Montijano*

Main category: cs.RO

TL;DR: 研究通过模仿学习解决多机器人系统（MRS）长期协调困难的挑战，提出一种课程学习策略和感知估计方法，提高长期行为的准确性并增强策略对不确定性的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统的控制策略学习因长期协调和训练数据难获取而面临挑战，研究旨在克服这些限制。

Method: 采用课程学习策略逐步增加专家轨迹长度，并提出一种方法将全局演示转化为局部感知，结合物理信息生成分布式策略。

Result: 实验表明，课程学习提升了长期行为准确性，感知估计方法增强了策略对不确定性的鲁棒性。

Conclusion: 研究结合两种策略，能够通过学习全球演示生成鲁棒、分布式的控制器。

Abstract: Learning control policies for multi-robot systems (MRS) remains a major
challenge due to long-term coordination and the difficulty of obtaining
realistic training data. In this work, we address both limitations within an
imitation learning framework. First, we shift the typical role of Curriculum
Learning in MRS, from scalability with the number of robots, to focus on
improving long-term coordination. We propose a curriculum strategy that
gradually increases the length of expert trajectories during training,
stabilizing learning and enhancing the accuracy of long-term behaviors. Second,
we introduce a method to approximate the egocentric perception of each robot
using only third-person global state demonstrations. Our approach transforms
idealized trajectories into locally available observations by filtering
neighbors, converting reference frames, and simulating onboard sensor
variability. Both contributions are integrated into a physics-informed
technique to produce scalable, distributed policies from observations. We
conduct experiments across two tasks with varying team sizes and noise levels.
Results show that our curriculum improves long-term accuracy, while our
perceptual estimation method yields policies that are robust to realistic
uncertainty. Together, these strategies enable the learning of robust,
distributed controllers from global demonstrations, even in the absence of
expert actions or onboard measurements.

</details>


### [133] [Safe Planning in Unknown Environments using Conformalized Semantic Maps](https://arxiv.org/abs/2509.25124)
*David Smith Sundarsingh,Yifei Li,Tianji Tang,George J. Pappas,Nikolay Atanasov,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 论文研究了在未知环境中机器人如何解决语义规划问题，克服感知不确定性，提出了无需已知传感器模型的语义到达-避障任务规划方法。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，机器人需要完成语义到达-避障任务，但现有算法要么忽略感知不确定性，要么需要已知传感器模型。本文旨在填补这一空白。

Method: 使用保形预测方法动态量化语义地图中的不确定性，无需假设传感器模型或噪声分布，从而计算出满足用户定义概率的路径。

Result: 实验证明该方法在任务成功率上优于基线方法，且符合理论上的任务完成率。

Conclusion: 论文提出了一种无需传感器模型支持的语义规划方法，有效解决了未知环境中的语义到达-避障任务。

Abstract: This paper addresses semantic planning problems in unknown environments under
perceptual uncertainty. The environment contains multiple unknown semantically
labeled regions or objects, and the robot must reach desired locations while
maintaining class-dependent distances from them. We aim to compute robot paths
that complete such semantic reach-avoid tasks with user-defined probability
despite uncertain perception. Existing planning algorithms either ignore
perceptual uncertainty - thus lacking correctness guarantees - or assume known
sensor models and noise characteristics. In contrast, we present the first
planner for semantic reach-avoid tasks that achieves user-specified mission
completion rates without requiring any knowledge of sensor models or noise.
This is enabled by quantifying uncertainty in semantic maps - constructed
on-the-fly from perceptual measurements - using conformal prediction in a
model- and distribution-free manner. We validate our approach and the
theoretical mission completion rates through extensive experiments, showing
that it consistently outperforms baselines in mission success rates.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [134] [EEG-Based Framework for Reflexive and Perceptual Assessment in CLIS: Preliminary Study in Healthy Volunteers](https://arxiv.org/abs/2509.23524)
*Nicoli Leal,Rute Bettencourt,Urbano J. Nunes,Gabriel Pires*

Main category: q-bio.NC

TL;DR: 研究旨在开发神经生理报告，评估完全锁闭状态（CLIS）患者的认知能力，以支持BCI交互。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIS患者被认为有意识，但BCI通信效果有限，可能与执行功能、工作记忆和警觉性受损有关。

Method: 设计反射和感知层面的评估范式，基于MMN、SSAEP和SSVEP等神经反应。

Result: 初步测试表明，神经生理报告在健康参与者中可行。

Conclusion: 研究为CLIS患者的认知评估提供了潜在工具，支持BCI交互能力判断。

Abstract: Despite the general assumption that completely locked-in state (CLIS)
patients remain conscious and aware of their environment, the effectiveness of
brain-computer interfaces (BCIs) in facilitating communication has been
limited, as reported both in the literature and in our own findings. This
limitation is likely attributable to impairments in executive functions,
working memory, and vigilance, which appear to hinder the establishment of
reliable BCI-based communication. The main goal of this research is to develop
a neurophysiological report designed to support the evaluation of the cognitive
state of these individuals and determine their ability to interact with BCIs.
To achieve this, we designed a set of paradigms to assess CLIS patients at the
reflexive and perceptual levels, based on neural responses associated with
sensory and perceptual processing, including Mismatch Negativity (MMN), Steady
State Auditory Evoked Potential (SSAEP), and Steady State Visual Evoked
Potential (SSVEP). Pilot testing with five healthy participants demonstrates
the feasibility of generating a neurophysiological report for cognitive
assessment at both levels.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [135] [Eye-Tracking and BCI Integration for Assistive Communication in Locked-In Syndrome: Pilot Study with Healthy Participants](https://arxiv.org/abs/2509.23518)
*Ana Patrícia Pinto,Rute Bettencourt,Urbano J. Nunes,Gabriel Pires*

Main category: cs.HC

TL;DR: 本文提出了一种结合眼动追踪（ET）和脑电波（BCI）的混合BCI框架，旨在支持ALS患者从部分锁定状态（LIS）过渡到完全锁定状态（CLIS）时的沟通连续性。


<details>
  <summary>Details</summary>
Motivation: ALS患者随着病情发展会丧失眼动功能，导致ET系统失效。传统BCI可能因延迟使用而性能下降，因此需要一种结合ET和BCI的过渡方案。

Method: 研究提出了一种混合BCI框架，结合ET和P300 BCI，并开发了ET-BCI融合算法，通过实时处理数据增强用户意图检测。

Result: 五名健康参与者的初步测试表明，组合两种模态可保持高准确性，并为LIS到CLIS的过渡提供潜在改进方向。

Conclusion: 混合BCI框架有望维持ALS患者的沟通连续性，未来可扩展至临床研究以验证其有效性。

Abstract: Patients with Amyotrophic Lateral Sclerosis (ALS) progressively lose
voluntary motor control, often leading to a Locked-In State (LIS), or in severe
cases, a Completely Locked-in State (CLIS). Eye-tracking (ET) systems are
common communication tools in early LIS but become ineffective as oculomotor
function declines. EEG-based Brain-Computer Interfaces (BCIs) offer a
non-muscular communication alternative, but delayed adoption may reduce
performance due to diminished goal-directed thinking. This study presents a
preliminary hybrid BCI framework combining ET and BCI to support a gradual
transition between modalities. A group of five healthy participants tested a
modified P300-based BCI. Gaze and EEG data were processed in real time, and an
ET-BCI fusion algorithm was proposed to enhance detection of user intention.
Results indicate that combining both modalities may maintain high accuracy and
offers insights on how to potentially improve communication continuity for
patients transitioning from LIS to CLIS.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [136] [ELHPlan: Efficient Long-Horizon Task Planning for Multi-Agent Collaboration](https://arxiv.org/abs/2509.24230)
*Shaobin Ling,Yun Wang,Chenyou Fan,Tin Lun Lam,Junjie Hu*

Main category: cs.AI

TL;DR: ELHPlan提出了一种新的框架，通过动作链作为基本规划单元，平衡动态环境中的适应性与计算效率，显著降低了令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多机器人协作中适应性不足和计算成本高的问题。

Method: 引入动作链作为规划基础，采用周期性流程（构建、验证、优化、执行）来规划。

Result: 在基准测试中，ELHPlan达到相近任务成功率，令牌消耗仅为现有方法的24%。

Conclusion: ELHPlan为基于LLM的多智能体规划系统建立了新的效率-效果前沿。

Abstract: Large Language Models (LLMs) enable intelligent multi-robot collaboration but
face fundamental trade-offs: declarative methods lack adaptability in dynamic
environments, while iterative methods incur prohibitive computational costs
that scale poorly with team size and task complexity. In this paper, we propose
ELHPlan, a novel framework that introduces Action Chains--sequences of actions
explicitly bound to sub-goal intentions--as the fundamental planning primitive.
ELHPlan operates via a cyclical process: 1) constructing intention-bound action
sequences, 2) proactively validating for conflicts and feasibility, 3) refining
issues through targeted mechanisms, and 4) executing validated actions. This
design balances adaptability and efficiency by providing sufficient planning
horizons while avoiding expensive full re-planning. We further propose
comprehensive efficiency metrics, including token consumption and planning
time, to more holistically evaluate multi-agent collaboration. Our experiments
on benchmark TDW-MAT and C-WAH demonstrate that ELHPlan achieves comparable
task success rates while consuming only 24% of the tokens required by
state-of-the-art methods. Our research establishes a new
efficiency-effectiveness frontier for LLM-based multi-agent planning systems.

</details>


### [137] [Training Agents Inside of Scalable World Models](https://arxiv.org/abs/2509.24527)
*Danijar Hafner,Wilson Yan,Timothy Lillicrap*

Main category: cs.AI

TL;DR: Dreamer 4是一种通过强化学习在快速准确的世界模型中训练的智能代理，显著提升了复杂环境中物体交互的预测能力，并在Minecraft中实现了纯离线数据获取钻石的突破。


<details>
  <summary>Details</summary>
Motivation: 解决以往世界模型无法准确预测复杂环境中物体交互的问题，提出一种不需要环境交互的智能代理训练方法，适用于实际场景如机器人学。

Method: 使用高效的Transformer架构和捷径目标，构建快速准确的世界模型，通过少量数据学习动作条件，并利用多样化无标签视频进行训练。

Result: Dreamer 4在Minecraft中大幅超越之前的世界模型，实现了纯离线数据下获取钻石的任务，展示了其高效的预测和训练能力。

Conclusion: Dreamer 4为想象训练提供了可扩展的解决方案，标志着智能代理发展的新一步。

Abstract: World models learn general knowledge from videos and simulate experience for
training behaviors in imagination, offering a path towards intelligent agents.
However, previous world models have been unable to accurately predict object
interactions in complex environments. We introduce Dreamer 4, a scalable agent
that learns to solve control tasks by reinforcement learning inside of a fast
and accurate world model. In the complex video game Minecraft, the world model
accurately predicts object interactions and game mechanics, outperforming
previous world models by a large margin. The world model achieves real-time
interactive inference on a single GPU through a shortcut forcing objective and
an efficient transformer architecture. Moreover, the world model learns general
action conditioning from only a small amount of data, allowing it to extract
the majority of its knowledge from diverse unlabeled videos. We propose the
challenge of obtaining diamonds in Minecraft from only offline data, aligning
with practical applications such as robotics where learning from environment
interaction can be unsafe and slow. This task requires choosing sequences of
over 20,000 mouse and keyboard actions from raw pixels. By learning behaviors
in imagination, Dreamer 4 is the first agent to obtain diamonds in Minecraft
purely from offline data, without environment interaction. Our work provides a
scalable recipe for imagination training, marking a step towards intelligent
agents.

</details>


### [138] [When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?](https://arxiv.org/abs/2509.24927)
*An Guo,Shuoxiao Zhang,Enyi Tang,Xinyu Gao,Haomin Pang,Haoxiang Tian,Yanzhou Mu,Wu Wen,Chunrong Fang,Zhenyu Chen*

Main category: cs.AI

TL;DR: 论文通过实证研究分析了V2X协同感知系统的六大常见错误模式，并评估了关键组件的性能，揭示了系统潜在风险和脆弱性。


<details>
  <summary>Details</summary>
Motivation: 解决单车感知系统在远距离感知和遮挡问题上的局限性，并探讨协同感知系统错误类型及其原因。

Method: 通过大规模研究识别和分析六种常见错误模式，并系统评估协同感知系统的关键组件。

Result: 发现LiDAR协同配置性能最佳，V2I和V2V在不同融合方案下表现不同；系统对通信干扰不够鲁棒，错误可能导致更多驾驶违规。

Conclusion: 研究揭示了协同感知系统的潜在风险和脆弱性，有助于推动系统设计和修复。

Abstract: With the tremendous advancement of deep learning and communication
technology, Vehicle-to-Everything (V2X) cooperative perception has the
potential to address limitations in sensing distant objects and occlusion for a
single-agent perception system. V2X cooperative perception systems are software
systems characterized by diverse sensor types and cooperative agents, varying
fusion schemes, and operation under different communication conditions.
Therefore, their complex composition gives rise to numerous operational
challenges. Furthermore, when cooperative perception systems produce erroneous
predictions, the types of errors and their underlying causes remain
insufficiently explored. To bridge this gap, we take an initial step by
conducting an empirical study of V2X cooperative perception. To systematically
evaluate the impact of cooperative perception on the ego vehicle's perception
performance, we identify and analyze six prevalent error patterns in
cooperative perception systems. We further conduct a systematic evaluation of
the critical components of these systems through our large-scale study and
identify the following key findings: (1) The LiDAR-based cooperation
configuration exhibits the highest perception performance; (2)
Vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communication
exhibit distinct cooperative perception performance under different fusion
schemes; (3) Increased cooperative perception errors may result in a higher
frequency of driving violations; (4) Cooperative perception systems are not
robust against communication interference when running online. Our results
reveal potential risks and vulnerabilities in critical components of
cooperative perception systems. We hope that our findings can better promote
the design and repair of cooperative perception systems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [139] [AI-Assisted Music Production: A User Study on Text-to-Music Models](https://arxiv.org/abs/2509.23364)
*Francesca Ronchini,Luca Comanducci,Simone Marcucci,Fabio Antonacci*

Main category: eess.AS

TL;DR: 论文研究了文本到音乐（TTM）模型对音乐制作的影响，通过用户研究和案例分析揭示了其在创意工作流程中的潜力和挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨TTM模型如何实际融入音乐制作工作流程，填补现有研究的空白。

Method: 采用用户研究，参与者使用结合TTM和源分离模型的工具制作音乐，并进行半结构化访谈和主题分析。

Result: 揭示了TTM模型在音乐制作中的潜力，以及实际集成中的关键挑战和伦理问题。

Conclusion: TTM模型具有变革音乐制作的潜力，但需解决实际应用中的挑战和伦理问题。

Abstract: Text-to-music models have revolutionized the creative landscape, offering new
possibilities for music creation. Yet their integration into musicians
workflows remains underexplored. This paper presents a case study on how TTM
models impact music production, based on a user study of their effect on
producers creative workflows. Participants produce tracks using a custom tool
combining TTM and source separation models. Semi-structured interviews and
thematic analysis reveal key challenges, opportunities, and ethical
considerations. The findings offer insights into the transformative potential
of TTMs in music production, as well as challenges in their real-world
integration.

</details>


### [140] [AudioFuse: Unified Spectral-Temporal Learning via a Hybrid ViT-1D CNN Architecture for Robust Phonocardiogram Classification](https://arxiv.org/abs/2509.23454)
*Md. Saiful Bari Siddiqui,Utsab Saha*

Main category: eess.AS

TL;DR: AudioFuse结合2D频谱图和1D波形两种互补表示，通过宽浅ViT和浅层CNN减轻过拟合风险，在PCG分类中取得优秀性能，展示了强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生物医学音频信号（如PCG）的频谱和时域信息均具诊断价值，但传统2D频谱图会丢失相位信息和时间精度。

Method: 提出AudioFuse，集成宽浅ViT处理频谱图和浅层1D CNN处理波形，通过互补表示减轻过拟合风险。

Result: 在PhysioNet 2016数据集上，ROC-AUC达0.8608，超越单模态基线；在PASCAL数据集上表现稳健（ROC-AUC 0.7181）。

Conclusion: 融合互补表示提供强归纳偏置，无需大规模预训练即可构建高效、泛化性强的分类器。

Abstract: Biomedical audio signals, such as phonocardiograms (PCG), are inherently
rhythmic and contain diagnostic information in both their spectral (tonal) and
temporal domains. Standard 2D spectrograms provide rich spectral features but
compromise the phase information and temporal precision of the 1D waveform. We
propose AudioFuse, an architecture that simultaneously learns from both
complementary representations to classify PCGs. To mitigate the overfitting
risk common in fusion models, we integrate a custom, wide-and-shallow Vision
Transformer (ViT) for spectrograms with a shallow 1D CNN for raw waveforms. On
the PhysioNet 2016 dataset, AudioFuse achieves a state-of-the-art competitive
ROC-AUC of 0.8608 when trained from scratch, outperforming its spectrogram
(0.8066) and waveform (0.8223) baselines. Moreover, it demonstrates superior
robustness to domain shift on the challenging PASCAL dataset, maintaining an
ROC-AUC of 0.7181 while the spectrogram baseline collapses (0.4873). Fusing
complementary representations thus provides a strong inductive bias, enabling
the creation of efficient, generalizable classifiers without requiring
large-scale pre-training.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [141] [A quantitative analysis of intraventricular bioimpedance in an in vivo pilot study with contextual pressure measurements](https://arxiv.org/abs/2509.23785)
*Fabian Flürenbrock,Christian T. Stoeck,Markus F. Oertel,Miriam Weisskopf,Melanie N. Zeilinger,Marianne Schmid Daners,Leonie Korn*

Main category: physics.med-ph

TL;DR: 本文开发了一种用于脑室内生物阻抗（BI）监测的系统，并在大型动物模型中验证了其有效性。该系统能够反映脑脊液（CSF）动力学和脑血流动力学，有望为脑积水的临床管理提供更全面的监测手段。


<details>
  <summary>Details</summary>
Motivation: 脑积水的临床管理中，持续监测脑脊液（CSF）体积仍是一个未解决的需求。尽管生物阻抗（BI）已被提出作为潜在的CSF体积标志物，但先前研究仅限于模拟、体外模型和小动物实验。

Method: 研究开发了一种脑室内BI测量系统，先在体外模拟生理CSF动力学的机电测试台上验证，随后在大型动物模型中进行体内实验，并与CSF和血压监测同步进行。

Result: 时间序列分析揭示了与心率和呼吸周期相关的生理BI波形成分。此外，通过鞘内注射人工CSF诱导CSF体积变化时，BI变化与CSF和血压变化相关。

Conclusion: 这是首次在大型动物模型中证明BI能够反映CSF动力学和脑血流动力学，未来结合颅内压和CSF引流监测，有望为脑积水治疗提供更全面的监测和控制手段。

Abstract: Hydrocephalus is a neurological condition characterized by disturbed
cerebrospinal fluid (CSF) dynamics and is typically treated with shunt systems
that drain excessive CSF out of the ventricular system. Continuous monitoring
of ventricular CSF volume, however, remains a major unmet need in the clinical
management of this condition. While intraventricular bioimpedance (BI) has been
proposed as a potential marker of CSF volume, prior investigations have been
limited to simulations, in vitro phantoms, and small animal models. This work
presents the development of a measurement system for intraventricular BI and
its evaluation in a large animal model. The measurement system was first
validated in vitro using a mechatronic test bench replicating physiological CSF
dynamics and subsequently applied in an in vivo pilot study with concurrent CSF
and blood pressure monitoring. Time series analysis of the recorded signals
revealed physiological BI waveform components linked to the cardiac and
respiratory cycles. In addition, changes in BI following CSF volume alterations
induced through intrathecal bolus infusions of artificial CSF were observed and
found to be correlated to changes in CSF and blood pressures. These results
provide the first in vivo evidence in a large animal model that BI reflects CSF
dynamics as well as cerebral hemodynamics. Complementing intracranial pressure
and CSF drainage measurements in smart shunt systems with BI could enable more
comprehensive patient monitoring and physiologically informed control of
hydrocephalus therapy.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [142] [S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network](https://arxiv.org/abs/2509.23442)
*Md. Saiful Bari Siddiqui,Mohammed Imamul Hassan Bhuiyan*

Main category: eess.IV

TL;DR: 论文提出了一种名为S$^3$F-Net的双分支框架，通过同时学习空间和频域表示来解决CNN在医疗图像分析中的局限性，显著提高了准确性并展示了通用性。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络（CNN）在医疗图像分析中专注于空间特征，但忽略了频域信息，无法捕捉全局模式。为了解决这一问题，作者提出了同时学习空间和频域表示的双分支框架。

Method: S$^3$F-Net结合了深度空间CNN和浅层频域编码器SpectraNet，后者通过SpectralFilter层直接对图像的傅里叶谱进行高效计算，实现全局感受野。

Result: 在四个不同模态的医疗图像数据集上，S$^3$F-Net显著优于仅使用空间的基线模型，最高准确率提升5.13%，并在BRISC2025数据集上达到98.76%的SOTA性能。

Conclusion: 双域学习是一种强大且通用的医疗图像分析范式，能够根据输入病理动态调整对空间和频域信息的依赖。

Abstract: Convolutional Neural Networks have become a cornerstone of medical image
analysis due to their proficiency in learning hierarchical spatial features.
However, this focus on a single domain is inefficient at capturing global,
holistic patterns and fails to explicitly model an image's frequency-domain
characteristics. To address these challenges, we propose the Spatial-Spectral
Summarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns
from both spatial and spectral representations simultaneously. The S$^3$F-Net
performs a fusion of a deep spatial CNN with our proposed shallow spectral
encoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,
which leverages the Convolution Theorem by applying a bank of learnable filters
directly to an image's full Fourier spectrum via a computation-efficient
element-wise multiplication. This allows the SpectralFilter layer to attain a
global receptive field instantaneously, with its output being distilled by a
lightweight summarizer network. We evaluate S$^3$F-Net across four medical
imaging datasets spanning different modalities to validate its efficacy and
generalizability. Our framework consistently and significantly outperforms its
strong spatial-only baseline in all cases, with accuracy improvements of up to
5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive
accuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs
better on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%
accuracy, surpassing many top-performing, much deeper models. Our
explainability analysis also reveals that the S$^3$F-Net learns to dynamically
adjust its reliance on each branch based on the input pathology. These results
verify that our dual-domain approach is a powerful and generalizable paradigm
for medical image analysis.

</details>


### [143] [Foundation Model-Based Adaptive Semantic Image Transmission for Dynamic Wireless Environments](https://arxiv.org/abs/2509.23590)
*Fangyu Liu,Peiwen Jiang,Wenjin Wang,Chao-Kai Wen,Shi Jin,Jun Zhang*

Main category: eess.IV

TL;DR: 本文提出了一种基于基础模型的自适应语义图像传输系统，用于动态无线环境。该系统通过分解图像为语义分割图和压缩表示，结合任务感知的资源分配和条件扩散模型，提升了传输的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了语义组件对下游任务的重要性差异，且未充分利用无线领域知识，导致在动态信道条件下鲁棒性不足。

Method: 系统将图像分解为语义分割图和压缩表示，采用任务自适应预编码机制分配资源，并使用条件扩散模型构建信道估计知识图和接收端图像重建。

Result: 在BDD100K数据集上的仿真结果表明，该方法在感知质量、任务准确性和传输效率上优于现有方法。

Conclusion: 结合任务感知语义分解、场景自适应信道估计和扩散重构，显著提升了动态无线环境中的语义传输效果。

Abstract: Foundation model-based semantic transmission has recently shown great
potential in wireless image communication. However, existing methods exhibit
two major limitations: (i) they overlook the varying importance of semantic
components for specific downstream tasks, and (ii) they insufficiently exploit
wireless domain knowledge, resulting in limited robustness under dynamic
channel conditions. To overcome these challenges, this paper proposes a
foundation model-based adaptive semantic image transmission system for dynamic
wireless environments, such as autonomous driving. The proposed system
decomposes each image into a semantic segmentation map and a compressed
representation, enabling task-aware prioritization of critical objects and
fine-grained textures. A task-adaptive precoding mechanism then allocates radio
resources according to the semantic importance of extracted features. To ensure
accurate channel information for precoding, a channel estimation knowledge map
(CEKM) is constructed using a conditional diffusion model that integrates user
position, velocity, and sparse channel samples to train scenario-specific
lightweight estimators. At the receiver, a conditional diffusion model
reconstructs high-quality images from the received semantic features, ensuring
robustness against channel impairments and partial data loss. Simulation
results on the BDD100K dataset with multi-scenario channels generated by
QuaDRiGa demonstrate that the proposed method outperforms existing approaches
in terms of perceptual quality (SSIM, LPIPS, FID), task-specific accuracy
(IoU), and transmission efficiency. These results highlight the effectiveness
of integrating task-aware semantic decomposition, scenario-adaptive channel
estimation, and diffusion-based reconstruction for robust semantic transmission
in dynamic wireless environments.

</details>


### [144] [Motion Informed Needle Segmentation in Ultrasound Images](https://arxiv.org/abs/2312.01239)
*Raghavv Goel,Cecilia Morales,Manpreet Singh,Artur Dubrawski,John Galeotti,Howie Choset*

Main category: eess.IV

TL;DR: 该论文提出了一种结合经典卡尔曼滤波技术与数据驱动学习的针分割新方法，在2D超声图像中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决超声图像中由于伪影、噪声和针遮挡导致的针分割难题，尤其是在数据有限的场景下。

Method: 采用混合方法，结合卡尔曼滤波技术和CNN，设计了可学习的滤波器和兼容框架。

Result: 新方法在针尖位置误差上减少15%，长度误差减少8%，性能优于现有技术。

Conclusion: 该方法首次实现了可学习滤波器的针分割，显著提升了性能。

Abstract: Segmenting a moving needle in ultrasound images is challenging due to the
presence of artifacts, noise, and needle occlusion. This task becomes even more
demanding in scenarios where data availability is limited. In this paper, we
present a novel approach for needle segmentation for 2D ultrasound that
combines classical Kalman Filter (KF) techniques with data-driven learning,
incorporating both needle features and needle motion. Our method offers three
key contributions. First, we propose a compatible framework that seamlessly
integrates into commonly used encoder-decoder style architectures. Second, we
demonstrate superior performance compared to recent state-of-the-art needle
segmentation models using our novel convolutional neural network (CNN) based
KF-inspired block, achieving a 15\% reduction in pixel-wise needle tip error
and an 8\% reduction in length error. Third, to our knowledge we are the first
to implement a learnable filter to incorporate non-linear needle motion for
improving needle segmentation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [145] [Integrated Communication and Control for Energy-Efficient UAV Swarms: A Multi-Agent Reinforcement Learning Approach](https://arxiv.org/abs/2509.23905)
*Tianjiao Sun,Ningyan Guo,Haozhe Gu,Yanyan Peng,Zhiyong Feng*

Main category: cs.LG

TL;DR: 本文提出了一种集成通信和控制协同设计的机制，通过多智能体强化学习框架优化无人机群的能量效率和通信质量，在复杂地理环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 无人机群在基础设施不足的环境中提供临时通信覆盖，但复杂地理环境导致无线信道动态变化，影响通信质量和可靠性。

Method: 提出了一种集成通信和控制协同设计机制，利用多智能体强化学习框架和新型算法MAHPPO-AM优化资源分配和3D轨迹控制。

Result: 实验结果表明，该方法在能源消耗减少25%的同时，公平指数达到0.99，优于基线方法。

Conclusion: 该方法显著提升了无人机群在复杂环境中的通信质量和能源效率，为临时通信场景提供了可靠解决方案。

Abstract: The deployment of unmanned aerial vehicle (UAV) swarm-assisted communication
networks has become an increasingly vital approach for remediating coverage
limitations in infrastructure-deficient environments, with especially pressing
applications in temporary scenarios, such as emergency rescue, military and
security operations, and remote area coverage. However, complex geographic
environments lead to unpredictable and highly dynamic wireless channel
conditions, resulting in frequent interruptions of air-to-ground (A2G) links
that severely constrain the reliability and quality of service in UAV
swarm-assisted mobile communications. To improve the quality of UAV
swarm-assisted communications in complex geographic environments, we propose an
integrated communication and control co-design mechanism. Given the stringent
energy constraints inherent in UAV swarms, our proposed mechanism is designed
to optimize energy efficiency while maintaining an equilibrium between
equitable communication rates for mobile ground users (GUs) and UAV energy
expenditure. We formulate the joint resource allocation and 3D trajectory
control problem as a Markov decision process (MDP), and develop a multi-agent
reinforcement learning (MARL) framework to enable real-time coordinated actions
across the UAV swarm. To optimize the action policy of UAV swarms, we propose a
novel multi-agent hybrid proximal policy optimization with action masking
(MAHPPO-AM) algorithm, specifically designed to handle complex hybrid action
spaces. The algorithm incorporates action masking to enforce hard constraints
in high-dimensional action spaces. Experimental results demonstrate that our
approach achieves a fairness index of 0.99 while reducing energy consumption by
up to 25% compared to baseline methods.

</details>


### [146] [PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM](https://arxiv.org/abs/2509.24085)
*Ju-Hyung Lee,Yanqing Lu,Klaus Doppler*

Main category: cs.LG

TL;DR: PEARL是一种用于D2D通信的合作跨层优化框架，利用设备状态指导WA参数选择，并通过KL微调实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决单设备LLM的局限性，通过合作优化提升D2D通信的效率与能耗表现。

Method: 采用上下文感知奖励和KL微调，提出PEARL和PEARL-Lite两种轻量级变体。

Result: PEARL在合成场景中表现优于基线方法，能耗降低16%，PEARL-Lite实现20ms内的推理。

Conclusion: LLMs在设备间合作控制和能效优化中具有实际应用价值。

Abstract: We present PEARL (Peer-Enhanced Adaptive Radio via On-Device LLM), a
framework for cooperative cross-layer optimization in device-to-device (D2D)
communication. Building on our previous work on single-device on-device LLMs,
PEARL extends the paradigm by leveraging both publisher and subscriber states
to guide Wi-Fi Aware (WA) parameter selection. A context-aware reward, which
normalizes latency by application tolerances and modulates energy by device
battery states, provides richer supervision for KL-based finetuning. We study
two lightweight variants: PEARL (Head + Low-Rank Adaptation (LoRA)) achieves
the best overall performance, while PEARL-Lite (Head-only) delivers sub-20 ms
inference at near-identical objective scores. Across synthetic scenarios
grounded in real measurements, PEARL improves objective scores over heuristic
and compact model baselines and reduces energy by up to 16% in cooperative
low-battery cases. These results demonstrate that peer-aware context,
reward-aligned training, and head-based efficiency make LLMs practical for
always-on, on-device cross-layer control.

</details>


### [147] [CURA: Size Isnt All You Need -- A Compact Universal Architecture for On-Device Intelligence](https://arxiv.org/abs/2509.24601)
*Jae-Bum Seo,Muhammad Salman,Lismer Andres Caceres-Najarro*

Main category: cs.LG

TL;DR: CURA是一种受模拟音频信号处理电路启发的架构，解决了现有设备AI在紧凑性和泛化性上的不足，适用于多领域任务。


<details>
  <summary>Details</summary>
Motivation: 现有设备AI架构在紧凑性和泛化性上存在局限，无法适应多任务需求。

Method: 提出CURA架构，基于模拟音频信号处理电路，实现紧凑、轻量化的多领域任务解决方案。

Result: CURA在紧凑性（参数减少2500倍）、泛化性（跨领域性能一致）和复杂模式识别（误差更低）上表现优异。

Conclusion: CURA为资源受限环境提供了一种高效、通用的AI架构解决方案。

Abstract: Existing on-device AI architectures for resource-constrained environments
face two critical limitations: they lack compactness, with parameter
requirements scaling proportionally to task complexity, and they exhibit poor
generalizability, performing effectively only on specific application domains
(e.g., models designed for regression tasks cannot adapt to natural language
processing (NLP) applications). In this paper, we propose CURA, an architecture
inspired by analog audio signal processing circuits that provides a compact and
lightweight solution for diverse machine learning tasks across multiple
domains. Our architecture offers three key advantages over existing approaches:
(1) Compactness: it requires significantly fewer parameters regardless of task
complexity; (2) Generalizability: it adapts seamlessly across regression,
classification, complex NLP, and computer vision tasks; and (3) Complex pattern
recognition: it can capture intricate data patterns while maintaining extremely
low model complexity. We evaluated CURA across diverse datasets and domains.
For compactness, it achieved equivalent accuracy using up to 2,500 times fewer
parameters compared to baseline models. For generalizability, it demonstrated
consistent performance across four NLP benchmarks and one computer vision
dataset, nearly matching specialized existing models (achieving F1-scores up to
90%). Lastly, it delivers superior forecasting accuracy for complex patterns,
achieving 1.6 times lower mean absolute error and 2.1 times lower mean squared
error than competing models.

</details>


### [148] [Clebsch-Gordan Transformer: Fast and Global Equivariant Attention](https://arxiv.org/abs/2509.24093)
*Owen Lewis Howell,Linfeng Zhao,Xupeng Zhu,Yaoyao Qian,Haojie Huang,Lingfeng Sun,Wil Thomason,Robert Platt,Robin Walters*

Main category: cs.LG

TL;DR: 论文提出了Clebsch-Gordan Transformer，通过新颖的Clebsch-Gordon卷积在SO(3)不可约表示上实现高效的全局注意力机制，解决了现有等变Transformer的局限性。


<details>
  <summary>Details</summary>
Motivation: 全局注意力机制在Transformer中至关重要，但其计算成本与标记数量呈平方关系。同时，等变模型在物理、生化等领域表现优异，但计算需求高。现有等变Transformer仅支持低阶等变特征和局部上下文窗口，限制了其表达能力。

Method: 提出Clebsch-Gordan Transformer，利用Clebsch-Gordon卷积在SO(3)不可约表示上实现高效的全局注意力，支持高阶等变特征，计算复杂度为O(N log N)。此外，通过权重共享或数据增强实现可选的标记置换等变性。

Result: 在多个基准测试（如n-body模拟、QM9、ModelNet点云分类和机器人抓取数据集）中，该方法在GPU内存占用、速度和准确性上均优于现有等变Transformer。

Conclusion: Clebsch-Gordan Transformer为高阶等变特征建模提供了高效的全局注意力机制，显著提升了性能和效率。

Abstract: The global attention mechanism is one of the keys to the success of
transformer architecture, but it incurs quadratic computational costs in
relation to the number of tokens. On the other hand, equivariant models, which
leverage the underlying geometric structures of problem instance, often achieve
superior accuracy in physical, biochemical, computer vision, and robotic tasks,
at the cost of additional compute requirements. As a result, existing
equivariant transformers only support low-order equivariant features and local
context windows, limiting their expressiveness and performance. This work
proposes Clebsch-Gordan Transformer, achieving efficient global attention by a
novel Clebsch-Gordon Convolution on $\SO(3)$ irreducible representations. Our
method enables equivariant modeling of features at all orders while achieving
${O}(N \log N)$ input token complexity. Additionally, the proposed method
scales well with high-order irreducible features, by exploiting the sparsity of
the Clebsch-Gordon matrix. Lastly, we also incorporate optional token
permutation equivariance through either weight sharing or data augmentation. We
benchmark our method on a diverse set of benchmarks including n-body
simulation, QM9, ModelNet point cloud classification and a robotic grasping
dataset, showing clear gains over existing equivariant transformers in GPU
memory size, speed, and accuracy.

</details>


### [149] [Discrete Variational Autoencoding via Policy Search](https://arxiv.org/abs/2509.24716)
*Michael Drolet,Firas Al-Hafez,Aditya Bhatt,Jan Peters,Oleg Arenz*

Main category: cs.LG

TL;DR: 论文提出了一种训练离散变分自编码器（VAE）的新框架，通过利用非参数编码器的自然梯度更新参数编码器，无需重参数化，显著提升了高维数据重构的性能。


<details>
  <summary>Details</summary>
Motivation: 传统离散VAE由于离散随机变量的不可微性，通常依赖近似方法或高方差的无梯度方法，导致在高维任务（如图像重构）中效果有限。本文旨在解决这一问题。

Method: 结合策略搜索中的技术，提出了一种无需重参数化的训练框架，利用非参数编码器的自然梯度更新参数编码器，并采用自动步长调整和基于变压器的编码器。

Result: 该方法在ImageNet等挑战性数据集上表现优异，重构高维数据时优于传统近似方法和基于量化的离散自编码器，FID得分提升了20%。

Conclusion: 提出的方法有效解决了离散VAE在高维任务中的性能瓶颈，展示了自然梯度和非参数编码器结合的优势，为未来研究方向提供了新思路。

Abstract: Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit
efficiency and can be modeled with autoregressive discrete distributions,
enabling parameter-efficient multimodal search with transformers. However,
discrete random variables do not allow for exact differentiable
parameterization; therefore, discrete VAEs typically rely on approximations,
such as Gumbel-Softmax reparameterization or straight-through gradient
estimates, or employ high-variance gradient-free methods such as REINFORCE that
have had limited success on high-dimensional tasks such as image
reconstruction. Inspired by popular techniques in policy search, we propose a
training framework for discrete VAEs that leverages the natural gradient of a
non-parametric encoder to update the parametric encoder without requiring
reparameterization. Our method, combined with automatic step size adaptation
and a transformer-based encoder, scales to challenging datasets such as
ImageNet and outperforms both approximate reparameterization methods and
quantization-based discrete autoencoders in reconstructing high-dimensional
data from compact latent spaces, achieving a 20% improvement on FID Score for
ImageNet 256.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [150] [Performance Analysis of Zero-Forcing Beamforming Strategies for the Uplink of an MU-MIMO System with Multi-Antenna Users](https://arxiv.org/abs/2509.23921)
*João Paulo P. G. Marques,Catherine Rosenberg*

Main category: cs.NI

TL;DR: 本文评估了OFDMA-based MU-MIMO系统中三种ZF波束成形策略的性能，并提出了一种基于贪婪搜索的高效启发式方法。结果显示，在不同场景下，BD和CTR1可以替代更复杂的CTRF。


<details>
  <summary>Details</summary>
Motivation: 研究OFDMA-based MU-MIMO系统中ZF波束成形策略的性能，特别是在上行链路资源管理中由于功率管理的挑战性需求。

Method: 提出了一种基于贪婪搜索的启发式方法，用于在时间槽内进行流集选择，同时考虑了公平性、调制编码方案和资源管理过程。

Result: 在农村宏场景中，BD或CTR1可以在用户数量较少或较多时替代CTRF；在城市宏场景中，CTR1性能接近CTRF。系统参数对ZF策略影响显著，且BD在简单功率管理方案下性能下降更多。

Conclusion: ZF策略的性能因场景和用户数量而异，BD和CTR1在某些情况下可以替代CTRF，但系统参数和功率管理方案的影响不容忽视。

Abstract: We conduct a comprehensive evaluation of the performance of the uplink of
OFDMA-based MU-MIMO systems with multi-antenna users, for three Zero-Forcing
(ZF) Beamforming (BF) strategies: Coordinated-Transmit-Receive-1 (CTR1), where
only the strongest data stream is enabled per scheduled user; Block
Diagonalization (BD), where all possible streams are enabled per scheduled
user; Coordinated-Transmit-Receive-Flexible (CTRF), which allows a flexible
stream allocation per user. The Radio Resource Management (RRM) of the uplink
of all OFDMA-based systems must be done over an entire Time-Slot (TS) due to
power management, making it challenging. To enable this study, we propose an
efficient heuristic based on greedy-up searches for stream-sets that provides
feasible solutions. It operates over the TS and considers fairness, practical
Modulation and Coding Schemes and all RRM processes. The results show that, for
Rural Macro scenarios, BD (resp. CTR1) could replace the more complex CTRF if
the number of users is small (resp. large), while for Urban Macro scenarios,
CTR1 emerges as an alternative to CTRF due to its similar performance. We also
show that the system parameters can substantially impact the performance of the
ZF strategies and that BD performance is more impaired with a simpler power
management scheme than CTR1 and CTRF.

</details>


### [151] [Experimental Study of Magnetic Near-Field Microstrip Electronic Probe for PCB EMC Emission Measurement](https://arxiv.org/abs/2509.24944)
*Hongchuan Jia,Fayu Wan,Vladimir Mordachev,Jérôme Rossignol,Glauco Fontagalland,Nour Murad,Blaise Ravelo*

Main category: cs.NI

TL;DR: 本文研究了用于印刷电路板(PCB)辐射的磁近场(NF)扫描实验系统，介绍了电磁NF扫描仪的设计、安装和校准过程，并通过实验和仿真验证了其功能。


<details>
  <summary>Details</summary>
Motivation: 开发和验证一种用于6G无线通信PCB电磁兼容性(EMC)辐射发射的磁NF扫描仪。

Method: 设计和安装电磁NF扫描仪，使用微带磁NF探头，遵循IEC 61967-1标准进行校准，并通过仿真和实验验证其功能。

Result: 扫描仪在0.1GHz至3GHz范围内验证了校准过程，并对非标准传输线DUT进行了实验，讨论了2GHz和3GHz下的磁NF扫描图。

Conclusion: 该NF扫描仪适用于6G无线通信PCB的EMC辐射发射测试，但仍需进一步开发。

Abstract: An experimental study on magnetic near-field (NF) scanning of printed circuit
board (PCB) emission radiation is developed in this paper. The design and
installation of the electromagnetic (EM) NF scanner is introduced. The test bed
of magnetic NF emission in the microwave frequency range is described. The
methodology of the microstrip magnetic NF probe is discussed. The probe
calibration process was performed following the IEC 61967-1 NF scanning
standard. The NF scanner functioning is tested with passive microstrip circuit
square loop probe and device under test (DUT) PCB radiation in the test plan
positioned at 1-mm above the ground plane. Based on the standard test with
I-shape 50-$\Omega$ transmission line (TL), the calibration process of radiated
magnetic field was validated by comparison between HFSS__ simulation and
experimentation in very wideband frequency from 0.1-GHz to 3-GHz. Then, a
nonstandard TL based DUT was experimented. Accordingly, the cartographies of
scanned magnetic NF at two different test frequencies, 2 GHz and 3 GHz, are
discussed. The NF scanner is under development for targeting the EMC radiated
emission of PCB dedicated to operate in 6G wireless communication.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [152] [From Static to Dynamic: a Survey of Topology-Aware Perception in Autonomous Driving](https://arxiv.org/abs/2509.23641)
*Yixiao Chen,Ruining Yang,Xin Chen,Jia He,Dongliang Xu,Yue Yao*

Main category: cs.CV

TL;DR: 这篇综述探讨了自动驾驶中拓扑感知感知的四个研究方向，强调了从静态地图到动态感知的范式转变。


<details>
  <summary>Details</summary>
Motivation: 传统静态地图成本高、更新难且泛化能力受限，因此需要转向实时、动态的传感器驱动感知方法。

Method: 系统回顾了四个核心方向：矢量化地图构建、拓扑结构建模、先验知识融合和基于语言模型的感知。

Result: 这些方法共同推动了更适应性强、可扩展性高且可解释的自动驾驶系统。

Conclusion: 动态感知范式为自动驾驶的未来发展提供了更具适应性和扩展性的解决方案。

Abstract: The key to achieving autonomous driving lies in topology-aware perception,
the structured understanding of the driving environment with an emphasis on
lane topology and road semantics. This survey systematically reviews four core
research directions under this theme: vectorized map construction, topological
structure modeling, prior knowledge fusion, and language model-based
perception. Across these directions, we observe a unifying trend: a paradigm
shift from static, pre-built maps to dynamic, sensor-driven perception.
Specifically, traditional static maps have provided semantic context for
autonomous systems. However, they are costly to construct, difficult to update
in real time, and lack generalization across regions, limiting their
scalability. In contrast, dynamic representations leverage on-board sensor data
for real-time map construction and topology reasoning. Each of the four
research directions contributes to this shift through compact spatial modeling,
semantic relational reasoning, robust domain knowledge integration, and
multimodal scene understanding powered by pre-trained language models.
Together, they pave the way for more adaptive, scalable, and explainable
autonomous driving systems.

</details>


### [153] [Color-Pair Guided Robust Zero-Shot 6D Pose Estimation and Tracking of Cluttered Objects on Edge Devices](https://arxiv.org/abs/2509.23647)
*Xingjian Yang,Ashis G. Banerjee*

Main category: cs.CV

TL;DR: 论文提出了一个统一的框架，用于在边缘设备上高效执行6D姿态估计，结合了稳健的初始估计模块和快速的运动跟踪器，通过共享的照明不变特征表示实现高精度和实时性。


<details>
  <summary>Details</summary>
Motivation: 针对在挑战性光照条件下实现新颖物体的6D姿态估计的困难，以及初始姿态估计与实时跟踪之间的权衡问题。

Method: 采用共享的照明不变颜色对特征表示，分别用于初始估计和跟踪阶段，以实现稳健的初始姿态估计和高效的运动跟踪。

Result: 在基准数据集上的实验表明，该方法在姿态估计精度和高保真跟踪方面均表现出色，尤其是在突发姿态变化情况下。

Conclusion: 该框架通过统一的特征表示有效地解决了光照挑战和实时性问题，为6D姿态估计提供了高效且稳健的解决方案。

Abstract: Robust 6D pose estimation of novel objects under challenging illumination
remains a significant challenge, often requiring a trade-off between accurate
initial pose estimation and efficient real-time tracking. We present a unified
framework explicitly designed for efficient execution on edge devices, which
synergizes a robust initial estimation module with a fast motion-based tracker.
The key to our approach is a shared, lighting-invariant color-pair feature
representation that forms a consistent foundation for both stages. For initial
estimation, this feature facilitates robust registration between the live RGB-D
view and the object's 3D mesh. For tracking, the same feature logic validates
temporal correspondences, enabling a lightweight model to reliably regress the
object's motion. Extensive experiments on benchmark datasets demonstrate that
our integrated approach is both effective and robust, providing competitive
pose estimation accuracy while maintaining high-fidelity tracking even through
abrupt pose changes.

</details>


### [154] [FastViDAR: Real-Time Omnidirectional Depth Estimation via Alternative Hierarchical Attention](https://arxiv.org/abs/2509.23733)
*Hangtian Zhao,Xiang Chen,Yizhe Li,Qianhao Wang,Haibo Lu,Fei Gao*

Main category: cs.CV

TL;DR: FastViDAR是一个新颖框架，通过四个鱼眼摄像头生成360度深度图，并采用AHA机制和ERP融合方法提升效率。


<details>
  <summary>Details</summary>
Motivation: 提出FastViDAR旨在高效融合多视角深度信息，实现实时360度深度估计。

Method: 引入AHA机制进行跨视角特征融合，并通过ERP投影方法整合多视角深度估计。

Result: 在HM3D和2D3D-S数据集上表现出色，实时性达20 FPS。

Conclusion: FastViDAR在实时性和准确性上均表现优异，适合嵌入式硬件应用。

Abstract: In this paper we propose FastViDAR, a novel framework that takes four fisheye
camera inputs and produces a full $360^\circ$ depth map along with per-camera
depth, fusion depth, and confidence estimates. Our main contributions are: (1)
We introduce Alternative Hierarchical Attention (AHA) mechanism that
efficiently fuses features across views through separate intra-frame and
inter-frame windowed self-attention, achieving cross-view feature mixing with
reduced overhead. (2) We propose a novel ERP fusion approach that projects
multi-view depth estimates to a shared equirectangular coordinate system to
obtain the final fusion depth. (3) We generate ERP image-depth pairs using HM3D
and 2D3D-S datasets for comprehensive evaluation, demonstrating competitive
zero-shot performance on real datasets while achieving up to 20 FPS on NVIDIA
Orin NX embedded hardware. Project page:
\href{https://3f7dfc.github.io/FastVidar/}{https://3f7dfc.github.io/FastVidar/}

</details>


### [155] [GRS-SLAM3R: Real-Time Dense SLAM with Gated Recurrent State](https://arxiv.org/abs/2509.23737)
*Guole Shen,Tianchen Deng,Yanbo Wang,Yongtao Chen,Yilin Shen,Jiuming Liu,Jingchuan Wang*

Main category: cs.CV

TL;DR: GRS-SLAM3R是一种端到端的SLAM框架，通过RGB图像实现密集场景重建和姿态估计，无需先验场景或相机参数知识。


<details>
  <summary>Details</summary>
Motivation: 现有DUSt3R方法仅依赖图像对估计点图，忽略了空间记忆和全局一致性，因此提出一种支持序列输入和全局坐标系的方法。

Method: 使用潜在状态存储空间记忆，设计基于Transformer的门控更新模块，并采用子图分割和局部对齐技术实现全局一致性。

Result: 在多个数据集上验证，实现了更高的重建精度并保持实时性能。

Conclusion: GRS-SLAM3R显著提升了密集SLAM的性能和一致性。

Abstract: DUSt3R-based end-to-end scene reconstruction has recently shown promising
results in dense visual SLAM. However, most existing methods only use image
pairs to estimate pointmaps, overlooking spatial memory and global
consistency.To this end, we introduce GRS-SLAM3R, an end-to-end SLAM framework
for dense scene reconstruction and pose estimation from RGB images without any
prior knowledge of the scene or camera parameters. Unlike existing DUSt3R-based
frameworks, which operate on all image pairs and predict per-pair point maps in
local coordinate frames, our method supports sequentialized input and
incrementally estimates metric-scale point clouds in the global coordinate. In
order to improve consistent spatial correlation, we use a latent state for
spatial memory and design a transformer-based gated update module to reset and
update the spatial memory that continuously aggregates and tracks relevant 3D
information across frames. Furthermore, we partition the scene into submaps,
apply local alignment within each submap, and register all submaps into a
common world frame using relative constraints, producing a globally consistent
map. Experiments on various datasets show that our framework achieves superior
reconstruction accuracy while maintaining real-time performance.

</details>


### [156] [DriveE2E: Closed-Loop Benchmark for End-to-End Autonomous Driving through Real-to-Simulation](https://arxiv.org/abs/2509.23922)
*Haibao Yu,Wenxian Yang,Ruiyang Hao,Chuanye Wang,Jiaru Zhong,Ping Luo,Zaiqing Nie*

Main category: cs.CV

TL;DR: 该论文提出了一个基于CARLA模拟器的闭环评估框架，通过整合真实世界交通场景和基础设施合作，提高了自动驾驶模型评估的逼真度和挑战性。


<details>
  <summary>Details</summary>
Motivation: 当前的CARLA模拟器闭环评估依赖于手动配置的交通场景，与现实世界存在差异，无法准确反映实际驾驶性能。

Method: 提取800个动态交通场景并创建15个真实交叉路口的静态数字孪生资产，整合进CARLA模拟器。

Result: 数字孪生准确复制了真实世界的交通和环境特征，提供了更逼真的模拟环境。

Conclusion: 该框架为端到端自动驾驶模型提供了更贴近现实的闭环评估基准。

Abstract: Closed-loop evaluation is increasingly critical for end-to-end autonomous
driving. Current closed-loop benchmarks using the CARLA simulator rely on
manually configured traffic scenarios, which can diverge from real-world
conditions, limiting their ability to reflect actual driving performance. To
address these limitations, we introduce a simple yet challenging closed-loop
evaluation framework that closely integrates real-world driving scenarios into
the CARLA simulator with infrastructure cooperation. Our approach involves
extracting 800 dynamic traffic scenarios selected from a comprehensive 100-hour
video dataset captured by high-mounted infrastructure sensors, and creating
static digital twin assets for 15 real-world intersections with consistent
visual appearance. These digital twins accurately replicate the traffic and
environmental characteristics of their real-world counterparts, enabling more
realistic simulations in CARLA. This evaluation is challenging due to the
diversity of driving behaviors, locations, weather conditions, and times of day
at complex urban intersections. In addition, we provide a comprehensive
closed-loop benchmark for evaluating end-to-end autonomous driving models.
Project URL:
\href{https://github.com/AIR-THU/DriveE2E}{https://github.com/AIR-THU/DriveE2E}.

</details>


### [157] [Advancing Multi-agent Traffic Simulation via R1-Style Reinforcement Fine-Tuning](https://arxiv.org/abs/2509.23993)
*Muleilan Pei,Shaoshuai Shi,Shaojie Shen*

Main category: cs.CV

TL;DR: SMART-R1提出了一种新型R1风格强化微调范式，通过度量导向的策略优化和交替训练策略，提升多智能体交通行为模拟的真实性，并在实验中取得了领先表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据驱动模拟器中训练与测试间分布偏移的问题，以提升自动驾驶技术在未见过环境中的泛化能力。

Method: 采用R1风格强化微调范式，结合度量导向策略优化和SFT-RFT-SFT交替训练策略。

Result: 在WOMD数据集上验证有效，并在WOSAC挑战中取得0.7858的总体真实度得分，排名第一。

Conclusion: SMART-R1通过简单而强大的训练框架，显著提升了基础模型的性能，推动了自动驾驶技术的发展。

Abstract: Scalable and realistic simulation of multi-agent traffic behavior is critical
for advancing autonomous driving technologies. Although existing data-driven
simulators have made significant strides in this domain, they predominantly
rely on supervised learning to align simulated distributions with real-world
driving scenarios. A persistent challenge, however, lies in the distributional
shift that arises between training and testing, which often undermines model
generalization in unseen environments. To address this limitation, we propose
SMART-R1, a novel R1-style reinforcement fine-tuning paradigm tailored for
next-token prediction models to better align agent behavior with human
preferences and evaluation metrics. Our approach introduces a metric-oriented
policy optimization algorithm to improve distribution alignment and an
iterative "SFT-RFT-SFT" training strategy that alternates between Supervised
Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) to maximize performance
gains. Extensive experiments on the large-scale Waymo Open Motion Dataset
(WOMD) validate the effectiveness of this simple yet powerful R1-style training
framework in enhancing foundation models. The results on the Waymo Open Sim
Agents Challenge (WOSAC) showcase that SMART-R1 achieves state-of-the-art
performance with an overall realism meta score of 0.7858, ranking first on the
leaderboard at the time of submission.

</details>


### [158] [Gaze Estimation for Human-Robot Interaction: Analysis Using the NICO Platform](https://arxiv.org/abs/2509.24001)
*Matej Palider,Omar Eldardeer,Viktor Kocur*

Main category: cs.CV

TL;DR: 论文评估了人机交互共享工作空间场景中的视线估计方法，介绍了新数据集并测试了四种先进模型，发现实际应用中误差较大，提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估当前视线估计方法在人机交互共享工作空间中的实际效果，揭示其局限性。

Method: 使用NICO机器人平台收集新数据集，并测试四种先进的视线估计模型。

Result: 角度误差接近通用基准，但实际工作空间中最佳中位误差为16.48厘米。

Conclusion: 讨论了当前方法的局限性，提出了优化视线估计在人机交互中应用的建议。

Abstract: This paper evaluates the current gaze estimation methods within an HRI
context of a shared workspace scenario. We introduce a new, annotated dataset
collected with the NICO robotic platform. We evaluate four state-of-the-art
gaze estimation models. The evaluation shows that the angular errors are close
to those reported on general-purpose benchmarks. However, when expressed in
terms of distance in the shared workspace the best median error is 16.48 cm
quantifying the practical limitations of current methods. We conclude by
discussing these limitations and offering recommendations on how to best
integrate gaze estimation as a modality in HRI systems.

</details>


### [159] [FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation](https://arxiv.org/abs/2509.24241)
*Seungwook Kim,Seunghyeon Lee,Minsu Cho*

Main category: cs.CV

TL;DR: 论文提出了两种无需训练的推理时间技术，通过充分利用动作参数在扩散模型中生成更真实的机器人视频，显著提升了动作一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 生成基于明确动作轨迹的真实机器人视频是构建有效世界模型和机器人基础模型的关键步骤。

Method: 提出了两种方法：动态调制引导强度的动作缩放分类器自由引导，以及调整初始采样噪声分布的动作缩放噪声截断。

Result: 在真实机器人操作数据集上的实验显示，这些技术显著改善了动作一致性和视觉质量。

Conclusion: 这些方法为扩散模型中的机器人视频生成提供了更强的可控性和对齐性。

Abstract: Generating realistic robot videos from explicit action trajectories is a
critical step toward building effective world models and robotics foundation
models. We introduce two training-free, inference-time techniques that fully
exploit explicit action parameters in diffusion-based robot video generation.
Instead of treating action vectors as passive conditioning signals, our methods
actively incorporate them to guide both the classifier-free guidance process
and the initialization of Gaussian latents. First, action-scaled
classifier-free guidance dynamically modulates guidance strength in proportion
to action magnitude, enhancing controllability over motion intensity. Second,
action-scaled noise truncation adjusts the distribution of initially sampled
noise to better align with the desired motion dynamics. Experiments on real
robot manipulation datasets demonstrate that these techniques significantly
improve action coherence and visual quality across diverse robot environments.

</details>


### [160] [SCOPE: Semantic Conditioning for Sim2Real Category-Level Object Pose Estimation in Robotics](https://arxiv.org/abs/2509.24572)
*Peter Hönig,Stefan Thalhammer,Jean-Baptiste Weibel,Matthias Hirschmanner,Markus Vincze*

Main category: cs.CV

TL;DR: SCOPE 是一种基于扩散的类别级物体姿态估计模型，利用 DINOv2 特征作为连续语义先验，无需离散类别标签，显著减少 Sim2Real 差距，并在未知类别中实现高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在开放环境中，机器人会遇到未知物体，需要语义理解以泛化到已知类别及之外，因此需要一种无需类别标签的姿态估计方法。

Method: 结合 DINOv2 特征、逼真训练数据及点法线噪声模型，通过交叉注意力注入连续语义先验，学习跨物体实例的规范化坐标系统。

Result: SCOPE 在合成训练的类别级姿态估计中优于现有方法，5°5cm 指标提升 31.9%；在未知类别物体抓取中成功率高达 100%。

Conclusion: SCOPE 通过连续语义先验显著提升了姿态估计的泛化能力，适用于未知物体的操作任务。

Abstract: Object manipulation requires accurate object pose estimation. In open
environments, robots encounter unknown objects, which requires semantic
understanding in order to generalize both to known categories and beyond. To
resolve this challenge, we present SCOPE, a diffusion-based category-level
object pose estimation model that eliminates the need for discrete category
labels by leveraging DINOv2 features as continuous semantic priors. By
combining these DINOv2 features with photorealistic training data and a noise
model for point normals, we reduce the Sim2Real gap in category-level object
pose estimation. Furthermore, injecting the continuous semantic priors via
cross-attention enables SCOPE to learn canonicalized object coordinate systems
across object instances beyond the distribution of known categories. SCOPE
outperforms the current state of the art in synthetically trained
category-level object pose estimation, achieving a relative improvement of
31.9\% on the 5$^\circ$5cm metric. Additional experiments on two instance-level
datasets demonstrate generalization beyond known object categories, enabling
grasping of unseen objects from unknown categories with a success rate of up to
100\%. Code available: https://github.com/hoenigpeter/scope.

</details>


### [161] [Evaluation of Polarimetric Fusion for Semantic Segmentation in Aquatic Environments](https://arxiv.org/abs/2509.24731)
*Luis F. W. Batista,Tom Bourbon,Cedric Pradalier*

Main category: cs.CV

TL;DR: 该论文研究了利用偏振成像技术改进水上漂浮碎片的分割效果，通过基准测试发现偏振线索能提升分割精度，但也增加了计算负担。


<details>
  <summary>Details</summary>
Motivation: 水上漂浮物体的语义分割常受水面反光和户外光照变化的干扰，偏振成像技术有望解决这一问题。

Method: 在公开数据集PoTATO上测试了最先进的融合网络，并与传统的单图像基线模型进行比较。

Result: 偏振线索能恢复低对比度物体并抑制反射导致的误检，提升了平均IoU并降低了轮廓误差，但也增加了计算负担。

Conclusion: 通过提供可复现的基准测试和公开代码，帮助研究者判断偏振相机是否适合其应用，并推动相关研究。

Abstract: Accurate segmentation of floating debris on water is often compromised by
surface glare and changing outdoor illumination. Polarimetric imaging offers a
single-sensor route to mitigate water-surface glare that disrupts semantic
segmentation of floating objects. We benchmark state-of-the-art fusion networks
on PoTATO, a public dataset of polarimetric images of plastic bottles in inland
waterways, and compare their performance with single-image baselines using
traditional models. Our results indicate that polarimetric cues help recover
low-contrast objects and suppress reflection-induced false positives, raising
mean IoU and lowering contour error relative to RGB inputs. These sharper masks
come at a cost: the additional channels enlarge the models increasing the
computational load and introducing the risk of new false positives. By
providing a reproducible, diagnostic benchmark and publicly available code, we
hope to help researchers choose if polarized cameras are suitable for their
applications and to accelerate related research.

</details>


### [162] [ThermalGen: Style-Disentangled Flow-Based Generative Models for RGB-to-Thermal Image Translation](https://arxiv.org/abs/2509.24878)
*Jiuhong Xiao,Roshan Nayak,Ning Zhang,Daniel Tortei,Giuseppe Loianno*

Main category: cs.CV

TL;DR: ThermalGen提出了一种基于流的RGB-T图像翻译模型，通过RGB图像条件架构和风格解耦机制，解决了RGB-热图像对的稀缺问题，并在多数据集上表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于同步和校准的RGB-热图像对的稀缺性，RGB-T图像翻译成为解决这一问题的关键。

Method: 提出ThermalGen，一种基于流的生成模型，结合RGB图像条件架构和风格解耦机制，并使用多个公开和新数据集进行训练。

Result: ThermalGen在多个RGB-T基准测试中表现优于现有的GAN和扩散方法，能够合成反映不同视角、传感器特性和环境条件的热图像。

Conclusion: ThermalGen是首个能够合成多样化热图像的RGB-T翻译模型，解决了数据稀缺问题，展示了优异的性能。

Abstract: Paired RGB-thermal data is crucial for visual-thermal sensor fusion and
cross-modality tasks, including important applications such as multi-modal
image alignment and retrieval. However, the scarcity of synchronized and
calibrated RGB-thermal image pairs presents a major obstacle to progress in
these areas. To overcome this challenge, RGB-to-Thermal (RGB-T) image
translation has emerged as a promising solution, enabling the synthesis of
thermal images from abundant RGB datasets for training purposes. In this study,
we propose ThermalGen, an adaptive flow-based generative model for RGB-T image
translation, incorporating an RGB image conditioning architecture and a
style-disentangled mechanism. To support large-scale training, we curated eight
public satellite-aerial, aerial, and ground RGB-T paired datasets, and
introduced three new large-scale satellite-aerial RGB-T datasets--DJI-day,
Bosonplus-day, and Bosonplus-night--captured across diverse times, sensor
types, and geographic regions. Extensive evaluations across multiple RGB-T
benchmarks demonstrate that ThermalGen achieves comparable or superior
translation performance compared to existing GAN-based and diffusion-based
methods. To our knowledge, ThermalGen is the first RGB-T image translation
model capable of synthesizing thermal images that reflect significant
variations in viewpoints, sensor characteristics, and environmental conditions.
Project page: http://xjh19971.github.io/ThermalGen

</details>


### [163] [Fast Feature Field ($\text{F}^3$): A Predictive Representation of Events](https://arxiv.org/abs/2509.25146)
*Richeek Das,Kostas Daniilidis,Pratik Chaudhari*

Main category: cs.CV

TL;DR: 本文提出了Fast Feature Field（F3），一种从事件相机数据中构建表示的方法，通过学习预测未来事件来保留场景结构和运动信息。F3高效、鲁棒，并在多种任务中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据具有稀疏性和噪声敏感性，需要一种高效且鲁棒的表示方法来支持多种下游任务。

Method: F3结合多分辨率哈希编码和深度集合技术，将事件数据表示为连续时空体积的多通道图像。

Result: F3在光流估计、语义分割和单目深度估计等任务中达到了最先进水平，适用于不同环境和传感器。

Conclusion: F3是一种高效、鲁棒的表示方法，适用于事件相机的广泛应用场景。

Abstract: This paper develops a mathematical argument and algorithms for building
representations of data from event-based cameras, that we call Fast Feature
Field ($\text{F}^3$). We learn this representation by predicting future events
from past events and show that it preserves scene structure and motion
information. $\text{F}^3$ exploits the sparsity of event data and is robust to
noise and variations in event rates. It can be computed efficiently using ideas
from multi-resolution hash encoding and deep sets - achieving 120 Hz at HD and
440 Hz at VGA resolutions. $\text{F}^3$ represents events within a contiguous
spatiotemporal volume as a multi-channel image, enabling a range of downstream
tasks. We obtain state-of-the-art performance on optical flow estimation,
semantic segmentation, and monocular metric depth estimation, on data from
three robotic platforms (a car, a quadruped robot and a flying platform),
across different lighting conditions (daytime, nighttime), environments
(indoors, outdoors, urban, as well as off-road) and dynamic vision sensors
(resolutions and event rates). Our implementations can predict these tasks at
25-75 Hz at HD resolution.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [164] [Safety-Critical Input-Constrained Nonlinear Intercept Guidance in Multiple Engagement Zones](https://arxiv.org/abs/2509.25053)
*Praveen Kumar Ranjan,Abhinav Sinha,Yongcan Cao*

Main category: eess.SY

TL;DR: 本文提出了一种输入受限的非线性制导律，用于解决在有多名防御者的竞争环境中拦截静止目标的问题。通过几何方法定义了防御者的威胁区域，并通过切换策略和光滑最小函数处理多重威胁，同时考虑了输入饱和问题。


<details>
  <summary>Details</summary>
Motivation: 在竞争环境中拦截目标时，传统方法依赖于防御者策略的显式知识或保守的安全条件。本文旨在通过几何方法更灵活地定义威胁区域，并提出一种动态切换策略以应对多防御者情况。

Method: 通过几何方法定义防御者的威胁区域（接触区域），在靠近区域时采用排斥安全机动，远离时采用追踪机动。使用光滑最小函数聚合多重威胁，并将输入饱和嵌入非完整车辆动力学中。

Result: 数值模拟表明，该方法能够在多种初始条件下避开威胁区域并成功拦截目标。

Conclusion: 本文提出的制导律通过几何威胁定义和动态切换策略，有效解决了多防御者环境中的目标拦截问题，兼顾了安全性和控制稳定性。

Abstract: This paper presents an input-constrained nonlinear guidance law to address
the problem of intercepting a stationary target in contested environments with
multiple defending agents. Contrary to prior approaches that rely on explicit
knowledge of defender strategies or utilize conservative safety conditions
based on a defender's range, our work characterizes defender threats
geometrically through engagement zones that delineate inevitable interception
regions. Outside these engagement zones, the interceptor remains invulnerable.
The proposed guidance law switches between a repulsive safety maneuver near
these zones and a pursuit maneuver outside their influence. To deal with
multiple engagement zones, we employ a smooth minimum function
(log-sum-exponent approximation) that aggregates threats from all the zones
while prioritizing the most critical threats. Input saturation is modeled and
embedded in the non-holonomic vehicle dynamics so the controller respects
actuator limits while maintaining stability. Numerical simulations with several
defenders demonstrate the proposed method's ability to avoid engagement zones
and achieve interception across diverse initial conditions.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [165] [RIS- and Multi-Snapshot-Enabled SISO 3D Position and Velocity Estimation With Single Base Station](https://arxiv.org/abs/2509.23274)
*Yirun Wang,Yongqing Wang,Yuyao Shen,Gongpu Wang,Chintha Tellambura*

Main category: cs.IT

TL;DR: 论文提出了一种结合RIS和多快照的两阶段方法，实现了在单基站SISO系统中的3D位置和速度联合估计，并通过仿真验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决单RIS或多快照单独使用时无法实现3D-JPVE的问题，论文探索了RIS与多快照的结合使用。

Method: 开发了两阶段方法：第一阶段通过张量分解将3D-JADE问题拆解为两个子问题；第二阶段通过线性方程和迭代优化实现3D-JPVE。

Result: 提出的方法在统计上接近CRLB精度，且主动RIS的性能优于被动RIS。

Conclusion: 论文证明了结合RIS和多快照的方法在实际系统中的可行性，并提供了高效的低复杂度实现。

Abstract: Reconfigurable intelligent surface (RIS) panels can act as cost-effective
anchors for radio localization, complementing conventional base station (BS)
anchors. This paper investigates joint three-dimensional position and velocity
estimation (3D-JPVE) in single-input single-output (SISO) systems with only one
BS available. We first theoretically show that 3D-JPVE is infeasible when
relying solely on a single RIS or on multiple snapshots alone. To address this,
we propose combining RIS deployment with multi-snapshot utilization to enable
realizable 3D-JPVE. A two-stage method is developed for multi-snapshot channel
parameter estimation, comprising a tensor-based coarse estimation step followed
by a maximum likelihood refinement step. In particular, we introduce a
third-order tensor formulation to decompose the challenging 3D joint
angle-of-departure and Doppler shift estimation (3D-JADE) into two tractable
subproblems, which are jointly solved via a low-complexity alternating
optimization approach. Building on the channel parameter estimates, we further
design a two-stage low-complexity method for optimal 3D-JPVE: coarse estimation
is obtained from differential measurements through linear equations, and the
preliminary results are refined iteratively using the original measurements.
Moreover, we derive the closed-form Cramer-Rao lower bound (CRLB) and show that
the proposed 3D-JPVE method approaches CRLB-level accuracy. Simulation results
confirm the statistical efficiency of the proposed estimators and demonstrate
substantial 3D-JPVE performance gains when deploying active RIS compared to
passive RIS.

</details>


### [166] [Prediction-Powered Communication with Distortion Guarantees](https://arxiv.org/abs/2509.24373)
*Matteo Zecchin,Unnikrishnan Kunnath Ganesan,Giuseppe Durisi,Petar Popovski,Osvaldo Simeone*

Main category: cs.IT

TL;DR: 本文研究了6G无线系统中的预测驱动通信，提出两种零延迟压缩算法，利用在线共形预测保证失真约束，实验验证了其在语义文本压缩中的高效性。


<details>
  <summary>Details</summary>
Motivation: 随着6G和智能设备的发展，需要重新思考传统信息理论，转向语义和任务导向的通信模式。

Method: 提出了两种零延迟压缩算法，结合在线共形预测，适用于无差错和丢包反馈信道，保证失真约束。

Result: 实验表明，相比现有方法，新算法显著降低了比特率，同时严格满足失真保证。

Conclusion: 提出的方法在语义任务中展现了高效性和可靠性，为6G通信提供了新思路。

Abstract: The development of 6G wireless systems is taking place alongside the
development of increasingly intelligent wireless devices and network nodes. The
changing technological landscape is motivating a rethinking of classical
Shannon information theory that emphasizes semantic and task-oriented
paradigms. In this paper, we study a prediction-powered communication setting,
in which devices, equipped with artificial intelligence (AI)-based predictors,
communicate under zero-delay constraints with strict distortion guarantees. Two
classes of distortion measures are considered: (i) outage-based metrics,
suitable for tasks tolerating occasional packet losses, such as real-time
control or monitoring; and (ii) bounded distortion metrics, relevant to
semantic-rich tasks like text or video transmission. We propose two zero-delay
compression algorithms leveraging online conformal prediction to provide
per-sequence guarantees on the distortion of reconstructed sequences over
error-free and packet-erasure channels with feedback. For erasure channels, we
introduce a doubly-adaptive conformal update to compensate for channel-induced
errors and derive sufficient conditions on erasure statistics to ensure
distortion constraints. Experiments on semantic text compression validate the
approach, showing significant bit rate reductions while strictly meeting
distortion guarantees compared to state-of-the-art prediction-powered
compression methods.

</details>


### [167] [Energy-Efficient Movable Antennas: Mechanical Power Modeling and Performance Optimization](https://arxiv.org/abs/2509.24433)
*Xin Wei,Weidong Mei,Xuan Huang,Zhi Chen,Boyu Ning*

Main category: cs.IT

TL;DR: 论文研究了移动天线(MAs)在通信性能优化中的能效问题，提出了一种基于步进电机的功耗模型，并通过创新的优化算法解决了多移动天线系统的能效最大化问题。


<details>
  <summary>Details</summary>
Motivation: 移动天线(MAs)通过局部天线移动提供了额外的空间自由度，但机械功耗问题使其能效优化比固定天线(FPA)系统更为关键。

Method: 建立了步进电机驱动的多移动天线系统的功耗模型，提出了两层优化框架（Dinkelbach算法和内层优化），并在多用户场景下使用了交替优化(AO)算法。

Result: 数值结果显示，尽管机械功耗增加，所提算法在能效上优于传统FPA系统和其他现有基准。

Conclusion: 研究发现，通过合理优化移动天线的位置、速度和波束成形，可以有效提升能效，证明了移动天线系统在实际应用中的潜力。

Abstract: Movable antennas (MAs) offer additional spatial degrees of freedom (DoFs) to
enhance communication performance through local antenna movement. However, to
achieve accurate and fast antenna movement, MA drivers entail non-negligible
mechanical power consumption, rendering energy efficiency (EE) optimization
more critical compared to conventional fixed-position antenna (FPA) systems. To
address this issue, we develop a fundamental power consumption model for
stepper motor-driven multi-MA systems based on electric motor theory. Based on
this model, we formulate an EE maximization problem from a multi-MA base
station (BS) to multiple single-FPA users. We aim to jointly optimize the MAs'
positions, moving speeds, and the BS's transmit precoding matrix subject to
collision-avoidance constraints during the multi-MA movements. However, this
problem is difficult to solve. To tackle this challenge, we first reveal that
the collision-avoidance constraints can always be relaxed without loss of
optimality by properly renumbering the MA indices. For the resulting relaxed
problem, we first consider a simplified single-user setup and uncover a hidden
monotonicity of the EE performance with respect to the MAs' moving speeds. To
solve the remaining optimization problem, we develop a two-layer optimization
framework. In the inner layer, the Dinkelbach algorithm is employed to derive
the optimal beamforming solution for any given MA positions. In the outer
layer, a sequential update algorithm is proposed to iteratively refine the MA
positions based on the optimal values obtained from the inner layer. Next, we
proceed to the general multi-user case and propose an alternating optimization
(AO) algorithm. Numerical results demonstrate that despite the additional
mechanical power consumption, the proposed algorithms can outperform both
conventional FPA systems and other existing EE maximization benchmarks

</details>


### [168] [Capacity Achieving Design for Hybrid Beamforming in Millimeter Wave Massive MIMO Systems](https://arxiv.org/abs/2509.25067)
*Rohollah Vahdani,S. Mohammad Razavizadeh*

Main category: cs.IT

TL;DR: 本文提出了一种新颖的混合波束成形矩阵联合设计方法，通过优化发射信号的协方差矩阵来最大化下行链路的总速率容量。


<details>
  <summary>Details</summary>
Motivation: 当前混合波束成形设计中，预编码和组合矩阵仅依赖于信道信息，忽略了发射信号协方差矩阵的结构。因此，本文旨在解决这一缺陷。

Method: 利用广播信道（BC）和多址信道（MAC）之间的对偶关系，优化发射信号的协方差矩阵，以解决非凸问题。

Result: 通过多种场景（如点对点MIMO、多用户MISO和MU-MIMO）的模拟，验证了所提方法的优越性。

Conclusion: 本文方法在毫米波系统中优化波束成形方面表现出高效性和多功能性。

Abstract: Hybrid digital and analog beamforming is a highly effective technique for
implementing beamforming methods in millimeter wave (mmWave) systems. It
provides a viable solution to replace the complex fully digital beamforming
techniques. However, the current design of precoding and combining matrices in
hybrid beamforming solely relies on the channel information, neglecting the
crucial consideration of the structure of covariance matrices of the transmit
signals. In this paper, we present a novel approach for the joint design of
hybrid beamforming matrices at the transmitter and receiver. This approach is
centered around the optimization of the covariance matrix of the transmitted
signals. Our goal is to maximize the downlink sum rate capacity of the system
by achieving an optimal design of the transmit covariance matrix. We tackle the
non-convex nature of this problem by leveraging the dual relationship between
the broadcast channel (BC) and the multiple access channel (MAC). Through
extensive simulations in various scenarios, including point-to-point
multi-input multi-output (MIMO), multi-user (MU) multi-input single-output
(MISO), and MU-MIMO, we demonstrate the superiority of our proposed method over
traditional designs. These results highlight the effectiveness and versatility
of our approach in optimizing beamforming for mmWave systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [169] [SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where](https://arxiv.org/abs/2509.23852)
*Yiheng Huang,Junran Peng,Silei Shen,Jingwei Yang,ZeJi Wei,ChenCheng Bai,Yonghao He,Wei Sui,Muyi Sun,Yan Liu,Xu-Cheng Yin,Man Zhang,Zhaoxiang Zhang,Chuanchen Luo*

Main category: cs.GR

TL;DR: 本文提出了一种全栈解决方案，结合音频、语言和空间数据生成对话手势，解决了现有方法在交互时机和空间意图上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖描述性语言或音频生成手势，缺乏交互时机和空间意图的刻画，限制了其在机器人或游戏动画中的应用。

Method: 首先建立了一种独特的数据收集方法，同时捕捉高精度人体运动和空间意图；然后开发了由音频、语言和空间数据驱动的生成模型，并设计了专门的评估指标。

Result: 解决方案在人形机器人上部署，实现了丰富且上下文感知的物理交互。

Conclusion: 该方法显著提升了对话手势生成的交互性和空间准确性，具有广泛的应用潜力。

Abstract: The accompanying actions and gestures in dialogue are often closely linked to
interactions with the environment, such as looking toward the interlocutor or
using gestures to point to the described target at appropriate moments. Speech
and semantics guide the production of gestures by determining their timing
(WHEN) and style (HOW), while the spatial locations of interactive objects
dictate their directional execution (WHERE). Existing approaches either rely
solely on descriptive language to generate motions or utilize audio to produce
non-interactive gestures, thereby lacking the characterization of interactive
timing and spatial intent. This significantly limits the applicability of
conversational gesture generation, whether in robotics or in the fields of game
and animation production. To address this gap, we present a full-stack
solution. We first established a unique data collection method to
simultaneously capture high-precision human motion and spatial intent. We then
developed a generation model driven by audio, language, and spatial data,
alongside dedicated metrics for evaluating interaction timing and spatial
accuracy. Finally, we deployed the solution on a humanoid robot, enabling rich,
context-aware physical interactions.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [170] [A Generative Model for Controllable Feature Heterophily in Graphs](https://arxiv.org/abs/2509.23230)
*Haoyu Wang,Renyuan Ma,Gonzalo Mateos,Luana Ruiz*

Main category: stat.ML

TL;DR: 提出了一种生成图信号的框架，可显式控制特征异质性，通过理论和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 图学习方法中特征异质性是关键属性，但目前缺乏对其显式控制的生成模型。

Method: 结合Lipschitz图元随机图生成器和通过拉普拉斯矩阵平滑谱函数过滤的高斯节点特征。

Result: 建立了理论保证，包括经验异质性评分的收敛性和异质性测量的确定性函数化。

Conclusion: 框架通过图元和滤波器的交互提供可调的异质性控制机制，实验验证了其精确性。

Abstract: We introduce a principled generative framework for graph signals that enables
explicit control of feature heterophily, a key property underlying the
effectiveness of graph learning methods. Our model combines a Lipschitz
graphon-based random graph generator with Gaussian node features filtered
through a smooth spectral function of the rescaled Laplacian. We establish new
theoretical guarantees: (i) a concentration result for the empirical
heterophily score; and (ii) almost-sure convergence of the feature heterophily
measure to a deterministic functional of the graphon degree profile, based on a
graphon-limit law for polynomial averages of Laplacian eigenvalues. These
results elucidate how the interplay between the graphon and the filter governs
the limiting level of feature heterophily, providing a tunable mechanism for
data modeling and generation. We validate the theory through experiments
demonstrating precise control of homophily across graph families and spectral
filters.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [171] [Systematic Alias Sampling: an efficient and low-variance way to sample from a discrete distribution](https://arxiv.org/abs/2509.24089)
*Ilari Vallivaara,Katja Poikselkä,Pauli Rikula,Juha Röning*

Main category: cs.DS

TL;DR: 提出了一种结合Alias方法和系统采样技术的高效离散分布采样方法，显著提升了粒子滤波中的重采样速度。


<details>
  <summary>Details</summary>
Motivation: 现有的离散分布采样方法（如二进制搜索或逆变换法）效率较低，无法满足实时需求，特别是在机器人运动模型等应用中。

Method: 结合Alias方法和系统采样技术，实现了高效的离散分布采样，速度比传统方法快一个数量级。

Result: 实验表明，该方法在采样速度和拟合优度统计上均优于传统多项式采样。

Conclusion: 该方法为粒子滤波等领域提供了一种高效且通用的离散分布采样解决方案。

Abstract: In this paper we combine the Alias method with the concept of systematic
sampling, a method commonly used in particle filters for efficient low-variance
resampling. The proposed method allows very fast sampling from a discrete
distribution: drawing k samples is up to an order of magnitude faster than
binary search from the cumulative distribution function (cdf) or inversion
methods used in many libraries. The produced empirical distribution function is
evaluated using a modified Cram\'er-Von Mises goodness-of-fit statistic,
showing that the method compares very favourably to multinomial sampling. As
continuous distributions can often be approximated with discrete ones, the
proposed method can be used as a very general way to efficiently produce random
samples for particle filter proposal distributions, e.g. for motion models in
robotics.

</details>
