{"id": "2601.11713", "pdf": "https://arxiv.org/pdf/2601.11713", "abs": "https://arxiv.org/abs/2601.11713", "authors": ["Rodney Martinez Alonso", "Cel Thys", "Cedric Dehos", "Yuneisy Esthela Garcia Guzman", "Sofie Pollin"], "title": "Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.NI"], "comment": "This preprint was submitted to The 2026 EuCNC & 6G Summit", "summary": "This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. We present the design of an end-to-end wireless autoencoder architecture that jointly optimizes the transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By exploiting the orthogonality and self-inverse properties of Walsh functions, the system distributes and learns to encode bit-words across parallel Walsh branches. Through analytical modeling and simulation, we characterize how 5G CPOFDM interference maps into the Walsh domain and identify optimal ratios of transmission frequencies and sampling rate where the end-to-end autoencoder achieves the highest rejection. Experimental results show that the proposed autoencoder achieves up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) for the same baseline channel noise, i.e., baseline Signal-to-Noise-Ratio (SNR) without the interference."}
{"id": "2601.11720", "pdf": "https://arxiv.org/pdf/2601.11720", "abs": "https://arxiv.org/abs/2601.11720", "authors": ["Hasan M. Boudi", "Taissir Y. Elganimi"], "title": "Sparsity Realization in User-Side Multilayer RIS", "categories": ["eess.SP"], "comment": null, "summary": "User-side reconfigurable intelligent surface (US-RIS)-aided communication has recently emerged as a promising solution to overcome the high hardware cost and physical size limitations of large-scale user side antenna arrays. This letter proposes, for the first time, a framework that realizes sparsity in multilayer US-RIS using two strategies, namely element-wise sparsity and geometric sparsity. The element-wise approach distributes a limited number of active elements irregularly across multiple layers, thereby exploiting additional spatial degrees of freedom and boosting the achievable rate. For further performance enhancement, a novel foldable RIS architecture leveraging geometric sparsity is proposed, achieving additional gains by optimizing the folding topology of its multilayer structure. Simulation results show that the proposed sparse architectures provide consistently higher achievable rates than existing designs."}
{"id": "2601.11734", "pdf": "https://arxiv.org/pdf/2601.11734", "abs": "https://arxiv.org/abs/2601.11734", "authors": ["Hao Guo", "Ruoyu Sun", "Amir Hossein Fahim Raouf", "Rahil Gandotra", "Jiayu Mao", "Mark Poletti"], "title": "LarS-Net: A Large-Scale Framework for Network-Level Spectrum Sensing", "categories": ["eess.SP"], "comment": "7 pages, 5 figures, this paper is under review at an IEEE conference", "summary": "As the demand of wireless communication continues to rise, the radio spectrum (a finite resource) requires increasingly efficient utilization. This trend is driving the evolution from static, stand-alone spectrum allocation toward spectrum sharing and dynamic spectrum sharing. A critical element of this transition is spectrum sensing, which facilitates informed decision-making in shared environments. Previous studies on spectrum sensing and cognitive radio have been largely limited to individual sensors or small sensor groups. In this work, a large-scale spectrum sensing network (LarS-Net) is designed in a cost-effective manner. Spectrum sensors are either co-located with base stations (BSs) to share the tower, backhaul, and power infrastructure, or integrated directly into BSs as a new feature leveraging active BS antenna systems. As an example incumbent system, fixed service microwave link operating in the lower-7 GHz band is investigated. This band is a primary candidate for 6G, being considered by the WRC-23, ITU, and FCC. Based on Monte Carlo simulations, we determine the minimum subset of BSs equipped with sensing capability to guarantee a target incumbent detection probability. The simulations account for various sensor antenna configurations, propagation channel models, and duty cycles for both incumbent transmissions and sensing operations. Building on this framework, we introduce three network-level sensing performance metrics: Emission Detection Probability (EDP), Temporal Detection Probability (TDP), and Temporal Mis-detection Probability (TMP), which jointly capture spatial coverage, temporal detectability, and multi-node diversity effects. Using these metrics, we analyze the impact of LarS-Net inter-site distance, noise uncertainty, and sensing duty-cycle on large-scale sensing performance."}
{"id": "2601.11741", "pdf": "https://arxiv.org/pdf/2601.11741", "abs": "https://arxiv.org/abs/2601.11741", "authors": ["Oliver Kirkpatrick", "Santiago Ozafrain", "Christopher Gilliam", "Beth Jelfs"], "title": "MIMO Array Calibration in Non-stationary Channels with Residual Surfaces and Slepian Spherical Harmonics", "categories": ["eess.SP"], "comment": "5 pages, 3 figures, 1 table", "summary": "The fundamental mechanism driving MIMO beamforming is the relative phases of signals departing the transmit array and arriving at the receive array. If a propagation channel affects all transmitted signals equally, the relative phases are a function of the directions of departure and arrival, as well as the transmit and receive hardware. In a non-stationary channel, the amplitudes and phases of arriving signals may vary significantly over time, making it infeasible to directly measure the influence of hardware. In this paper, we present a calibration method for achieving indirect measurement and compensation of hardware influences in non-stationary channels. Our method characterizes the patterns of array elements relative to a reference element and estimates these relative patterns, termed residual surfaces, using a Slepian spherical harmonic basis. Using simulations, we demonstrate that our calibration method achieves beamforming gains that closely match theoretical optimums. Our results also show a reduction in the error in estimating the target direction, lower side lobes, and improve null-steering capabilities."}
{"id": "2601.11801", "pdf": "https://arxiv.org/pdf/2601.11801", "abs": "https://arxiv.org/abs/2601.11801", "authors": ["Nitish Sontakke", "K. Niranjan Kumar", "Sehoon Ha"], "title": "RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study."}
{"id": "2601.11742", "pdf": "https://arxiv.org/pdf/2601.11742", "abs": "https://arxiv.org/abs/2601.11742", "authors": ["Jiayu Mao", "Ruoyu Sun", "Mark Poletti", "Rahil Gandotra", "Hao Guo", "Aylin Yener"], "title": "AI-Driven Spectrum Occupancy Prediction Using Real-World Spectrum Measurements", "categories": ["eess.SP"], "comment": "8 pages, 7 figures. This paper is under review at an IEEE conference", "summary": "Spectrum occupancy prediction is a critical enabler for real-time and proactive dynamic spectrum sharing (DSS), as it can provide short-term channel availability information to support more efficient spectrum access decisions in wireless communication systems. Instead of relying on open-source datasets or simulated data, commonly used in the literature, this paper investigates short-horizon spectrum occupancy prediction using mid-band, 24X7 real-world spectrum measurement data collected in the United States. We construct a multi-band channel occupancy dataset through analyzing 61 days of empirical data and formulate a next-minute channel occupancy prediction task across all frequency channels. This study focuses on AI-driven prediction methods, including Random Forest, Extreme Gradient Boosting (XGBoost), and a Long Short-Term Memory (LSTM) network, and compares their performance against a conventional Markov chain-based statistical baseline. Numerical results show that learning-based methods outperform the statistical baseline on dynamic channels, particularly under fixed false-alarm constraints. These results demonstrate the effectiveness of AI-driven spectrum occupancy prediction, indicating that lightweight learning models can effectively support future deployment-oriented DSS systems."}
{"id": "2601.11802", "pdf": "https://arxiv.org/pdf/2601.11802", "abs": "https://arxiv.org/abs/2601.11802", "authors": ["Suguru Sato", "Jinaykumar Patel", "Kamesh Subbarao"], "title": "Optimal Thruster Configuration for 6-DOF Control of a Small Satellite", "categories": ["cs.RO", "eess.SY"], "comment": "19 pages, 9 figures", "summary": "With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved."}
{"id": "2601.11748", "pdf": "https://arxiv.org/pdf/2601.11748", "abs": "https://arxiv.org/abs/2601.11748", "authors": ["Rahil Gandotra", "Ruoyu Sun", "Mark Poletti", "Jiayu Mao", "Hao Guo"], "title": "Automated Spectrum Sensing and Analysis Framework", "categories": ["eess.SP"], "comment": "This paper is under review at an IEEE conference", "summary": "Spectrum sensing and analysis is crucial for a variety of reasons, including regulatory compliance, interference detection and mitigation, and spectrum resource planning and optimization. Effective, real-time spectrum analysis remains a challenge, stemming from the need to analyse an increasingly complex and dynamic environment with limited resources. The vast amount of data generated from sensing the spectrum at multiple sites requires sophisticated data analysis and processing techniques, which can be technically demanding and expensive. This paper presents a novel, holistic framework developed and deployed at multiple locations across the USA for spectrum analysis and describes the different parts of the end-to-end pipeline. The details of each of the modules of the pipeline, data collection and pre-processing at remote locations, transfer to a centralized location, post-processing analysis, visualization, and long-term storage, are reported. The motivation behind this work is to develop a robust spectrum analysis framework that can help gain greater insights into the spectrum usage across the country and augment additional use cases such as dynamic spectrum sharing."}
{"id": "2601.11832", "pdf": "https://arxiv.org/pdf/2601.11832", "abs": "https://arxiv.org/abs/2601.11832", "authors": ["Suguru Sato", "Kamesh Subbarao"], "title": "Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles", "categories": ["cs.RO", "eess.SY"], "comment": "18 pages, 15 figures", "summary": "This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications."}
{"id": "2601.11844", "pdf": "https://arxiv.org/pdf/2601.11844", "abs": "https://arxiv.org/abs/2601.11844", "authors": ["Yue Bi", "Michèle Wigger"], "title": "Necessity of Cooperative Transmissions for Wireless MapReduce", "categories": ["eess.SP", "cs.IT"], "comment": null, "summary": "The paper presents an improved upper bound (achievability result) on the optimal tradeoff between Normalized Delivery Time (NDT) and computation load for distributed computing MapReduce systems in certain ranges of the parameters. The upper bound is based on interference alignment combined with zero-forcing. The paper further provides a lower bound (converse) on the optimal NDT-computation tradeoff that can be achieved when IVAs are partitioned into sub-IVAs, and these sub-IVAs are then transmitted (in an arbitrary form) by a single node, without cooperation among nodes. For appropriate linear functions (e.g., XORs), such non-cooperative schemes can achieve some of the best NDT-computation tradeoff points so far obtained in the literature. However, as our lower bound shows, any non-cooperative scheme achieves a worse NDT-computation tradeoff than our new proposed scheme for certain parameters, thus proving the necessity of cooperative schemes like zero-forcing to attain the optimal NDT-computation tradeoff."}
{"id": "2601.11876", "pdf": "https://arxiv.org/pdf/2601.11876", "abs": "https://arxiv.org/abs/2601.11876", "authors": ["Christopher Kao", "Akhil Pathapati", "James Davis"], "title": "AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal", "categories": ["cs.RO", "cs.AI", "cs.CV", "eess.SY"], "comment": "Published in IEEE/SICE SII 2025", "summary": "There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution."}
{"id": "2601.11869", "pdf": "https://arxiv.org/pdf/2601.11869", "abs": "https://arxiv.org/abs/2601.11869", "authors": ["Zekun Hong", "Shinya Sugiura", "Chao Xu", "Lajos Hanzo"], "title": "Delay-Doppler-Domain Channel Estimation and Reduced-Complexity Detection of Faster-than-Nyquist Signaling Aided OTFS", "categories": ["eess.SP"], "comment": "16 pages, 18 figures, 3 tables", "summary": "We conceive a novel channel estimation and data detection scheme for OTFS-modulated faster-than-Nyquist (FTN) transmission over doubly selective fading channels, aiming for enhancing the spectral efficiency and Doppler resilience. The delay-Doppler (DD) domain's input-output relationship of OTFS-FTN signaling is derived by employing a root-raised cosine (RRC) shaping filter. More specifically, we design our DD-domain channel estimator for FTN-based pilot transmission, where the pilot symbol interval is lower than that defined by the classic Nyquist criterion. Moreover, we propose a reduced-complexity linear minimum mean square error equalizer, supporting noise whitening, where the FTN-induced inter-symbol interference (ISI) matrix is approximated by a sparse one. Our performance results demonstrate that the proposed OTFS-FTN scheme is capable of enhancing the achievable information rate, while attaining a comparable BER performance to both that of its Nyquist-based OTFS counterpart and to other FTN transmission schemes, which employ the same RRC shaping filter."}
{"id": "2601.11906", "pdf": "https://arxiv.org/pdf/2601.11906", "abs": "https://arxiv.org/abs/2601.11906", "authors": ["Jose Cuaran", "Kendall Koe", "Aditya Potnis", "Naveen Kumar Uppalapati", "Girish Chowdhary"], "title": "Visual-Language-Guided Task Planning for Horticultural Robots", "categories": ["cs.RO"], "comment": "14 pages, 4 figures", "summary": "Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics."}
{"id": "2601.11878", "pdf": "https://arxiv.org/pdf/2601.11878", "abs": "https://arxiv.org/abs/2601.11878", "authors": ["Xi Peng"], "title": "Accelerated MR Elastography Using Learned Neural Network Representation", "categories": ["eess.SP", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "To develop a deep-learning method for achieving fast high-resolution MR elastography from highly undersampled data without the need of high-quality training dataset. We first framed the deep neural network representation as a nonlinear extension of the linear subspace model, then used it to represent and reconstruct MRE image repetitions from undersampled k-space data. The network weights were learned using a multi-level k-space consistent loss in a self-supervised manner. To further enhance reconstruction quality, phase-contrast specific magnitude and phase priors were incorporated, including the similarity of anatomical structures and smoothness of wave-induced harmonic displacement. Experiments were conducted using both 3D gradient-echo spiral and multi-slice spin-echo spiral MRE datasets. Compared to the conventional linear subspace-based approaches, the nonlinear network representation method was able to produce superior image reconstruction with suppressed noise and artifacts from a single in-plane spiral arm per MRE repetition (e.g., total R=10), yielding comparable stiffness estimation to the fully sampled data. This work demonstrated the feasibility of using deep network representations to model and reconstruct MRE images from highly-undersampled data, a nonlinear extension of the subspace-based approaches."}
{"id": "2601.12012", "pdf": "https://arxiv.org/pdf/2601.12012", "abs": "https://arxiv.org/abs/2601.12012", "authors": ["Zhaoyang Jacopo Hu", "Alex Ranne", "Alaa Eldin Abdelaal", "Kiran Bhattacharyya", "Etienne Burdet", "Allison M. Okamura", "Ferdinando Rodriguez y Baena"], "title": "Model selection and real-time skill assessment for suturing in robotic surgery", "categories": ["cs.RO"], "comment": null, "summary": "Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization."}
{"id": "2601.11894", "pdf": "https://arxiv.org/pdf/2601.11894", "abs": "https://arxiv.org/abs/2601.11894", "authors": ["Haotian Liu", "Zhiqing Wei", "Yucong Du", "Jiachen Wei", "Xingwang Li", "Zhiyong Feng"], "title": "Beyond Target-Level: ISAC-Enabled Event-Level Sensing for Behavioral Intention Prediction", "categories": ["eess.SP"], "comment": "5 pages, 5 figures, 1 table, and 15 references. Reviewed by IEEE WCL", "summary": "Integrated Sensing and Communication (ISAC) holds great promise for enabling event-level sensing, such as behavioral intention prediction (BIP) in autonomous driving, particularly under non-line-of-sight (NLoS) or adverse weather conditions where conventional sensors degrade. However, as a key instance of event-level sensing, ISAC-based BIP remains unexplored. To address this gap, we propose an ISAC-enabled BIP framework and validate its feasibility and effectiveness through extensive simulations. Our framework achieves robust performance in safety-critical scenarios, improving the F1-score by 11.4% over sensor-based baselines in adverse weather, thereby demonstrating ISAC's potential for intelligent event-level sensing."}
{"id": "2601.12116", "pdf": "https://arxiv.org/pdf/2601.12116", "abs": "https://arxiv.org/abs/2601.12116", "authors": ["Hang Xu", "Yizhou Chen", "Dongjie Yu", "Yi Ren", "Jia PanI"], "title": "BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies", "categories": ["cs.RO"], "comment": "Accepted by IEEE Transactions on Automation Science and Engineering 2025", "summary": "Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus."}
{"id": "2601.11938", "pdf": "https://arxiv.org/pdf/2601.11938", "abs": "https://arxiv.org/abs/2601.11938", "authors": ["Sebastian Ratto", "Huy Trinh", "Ahmed N. Sayed", "Abdelrahman Elbadrawy", "Arien Sligar", "George Shaker"], "title": "Radar-Based Fall Detection for Assisted Living: A Digital-Twin Representation Case Study", "categories": ["eess.SP"], "comment": "6 pages, 8 figures", "summary": "Obtaining data on high-impact falls from older adults is ethically difficult, yet these rare events cause many fall-related health problems. As a result, most radar-based fall detectors are trained on staged falls from young volunteers, and representation choices are rarely tested against the radar signals from dangerous falls. This paper uses a frequency-modulated continuous-wave (FMCW) radar digital twin as a single simulated room testbed to study how representation choice affects fall/non-fall discrimination. From the same simulated range-Doppler sequence, Doppler-time spectrograms, three-channel per-receiver spectrogram stacks, and time-pooled range-Doppler maps (RDMs) are derived and fed to an identical compact CNN under matched training on a balanced fall/non-fall dataset. In this twin, temporal spectrograms reach 98-99% test accuracy with similar precision and recall for both classes, while static RDMs reach 89.4% and show more variable training despite using the same backbone. A qualitative comparison between synthetic and measured fall spectrograms suggests that the twin captures gross Doppler-time structure, but amplitude histograms reveal differences in the distributions of amplitude values consistent with receiver processing not modeled in the twin. Because the twin omits noise and hardware impairments and is only qualitatively compared to a single measured example, these results provide representation-level guidance under controlled synthetic conditions rather than ready-to-use clinical performance in real settings."}
{"id": "2601.12122", "pdf": "https://arxiv.org/pdf/2601.12122", "abs": "https://arxiv.org/abs/2601.12122", "authors": ["Jose Cuaran", "Naveen K. Upalapati", "Girish Chowdhary"], "title": "Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting", "categories": ["cs.RO"], "comment": "9 pages, 4 figures", "summary": "Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics."}
{"id": "2601.11971", "pdf": "https://arxiv.org/pdf/2601.11971", "abs": "https://arxiv.org/abs/2601.11971", "authors": ["Duc Viet Nguyen", "Haiquan Zhao", "Jinhui Hu", "Xiaoli Li"], "title": "Robust distributed extended Kalman filter based on adaptive multi-kernel mixture maximum correntropy for non-Gaussian systems", "categories": ["eess.SP"], "comment": "15 pages, 16 figures,", "summary": "As one of the most advanced variants in the correntropy family, the multi-kernel correntropy criterion demonstrates superior accuracy in handling non-Gaussian noise, particularly with multimodal distributions. However, current approaches suffer from key limitations-namely, reliance on a single type of sensitive Gaussian kernel and the manual selection of free parameters. To address these issues and further boost robustness, this paper introduces the concept of multi-kernel mixture correntropy (MKMC), along with its key properties. MKMC employs a flexible kernel function composed of a mixture of two Students t-Cauchy functions with adjustable (non-zero) means. Building on this criterion within multi-sensor networks, we propose a robust distributed extended Kalman filter-AMKMMC-RDEKF based on adaptive multi-kernel mixture maximum correntropy. To reduce communication overhead, a consensus averaging strategy is incorporated. Furthermore, an adaptive mechanism is introduced to mitigate the impact of manually tuned free parameters. At the same time, the computational complexity and convergence ability of the proposed algorithm are analyzed. The effectiveness of the proposed algorithm is validated through challenging scenarios involving power system and land vehicle state estimation."}
{"id": "2601.12143", "pdf": "https://arxiv.org/pdf/2601.12143", "abs": "https://arxiv.org/abs/2601.12143", "authors": ["Devin Hunter", "Chinwendu Enyioha"], "title": "Neural Process-Based Reactive Controller for Autonomous Racing", "categories": ["cs.RO"], "comment": "6 pages, 4 figures", "summary": "Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction."}
{"id": "2601.12110", "pdf": "https://arxiv.org/pdf/2601.12110", "abs": "https://arxiv.org/abs/2601.12110", "authors": ["David. Casillas-Pérez", "Daniel. Merino-Pérez", "Silvia. Jiménez-Fernández", "J. Antonio. Portilla-Figueras", "Sancho. Salcedo-Sanz"], "title": "Extended Weighted ABG: A Robust Non-Linear ABG-Based Approach for Optimal Combination of ABG Path-Loss Propagation Models", "categories": ["eess.SP"], "comment": null, "summary": "This paper proposes a robust non-linear generalized path-loss propagation model, the Extended Weighted ABG (EWABG), which efficiently allows generating a path-loss propagation model by combining several available path-loss datasets (from measurements campaigns) and other previously proposed state-of-the-art 5G path-loss propagation models. The EWABG model works by integrating individual path-loss models into one single model in the least-squares sense, allowing to extend knowledge from frequencies and distances covered by path-loss datasets or path-loss propagation models. The proposed EWABG model is the first non-linear extension of the common ABG-based approach, which surpasses the non-uniformity problem between the low and high 5G frequencies (as most measurements campaigns have taken place in low frequencies). The EWABG also addresses the problem of removing outlier measurements, a step not included in previous propagation path-loss models. In this case, we have compared the most recent techniques for avoiding outliers, and we have adopted the Theil-Sen method, due to its strong robustness demonstrated in the experiments carried out. In addition, the proposed model specifically considers non-linear attenuation by atmospheric gases, in order to improve its estimations. The good performance of the proposed EWABG model has been tested and compared against recent 5G propagation path-loss models including the ABG and WABG models. The exhaustive experimentation carried out includes the 5G non-line-of-sight environment in different 5G scenarios, UMiSC, UMiOS and UMa. The proposed EWABG obtains the best accuracy, specially in noisy environments with outliers, reporting negligible increment error rates (with respect to the non-outliers situation), lower than 1%, compared to the ABG and WABG."}
{"id": "2601.12169", "pdf": "https://arxiv.org/pdf/2601.12169", "abs": "https://arxiv.org/abs/2601.12169", "authors": ["Samuel A. Moore", "Easop Lee", "Boyuan Chen"], "title": "Learning Legged MPC with Smooth Neural Surrogates", "categories": ["cs.RO"], "comment": null, "summary": "Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains."}
{"id": "2601.12171", "pdf": "https://arxiv.org/pdf/2601.12171", "abs": "https://arxiv.org/abs/2601.12171", "authors": ["Jeffrey W. Utley", "Gregery T. Buzzard", "Charles A. Bouman", "Matthew R. Kemnetz"], "title": "Boiling flow estimation for aero-optic phase screen generation", "categories": ["eess.SP"], "comment": "Submitted to the Unconventional Imaging, Sensing, and Adaptive Optics special session of Optical Engineering", "summary": "Aero-optic effects due to turbulence can reduce the effectiveness of transmitting light waves to a distant target. Methods to compensate for turbulence typically rely on realistic turbulence data, which can be generated by i) experiment, ii) high-fidelity CFD, iii) low-fidelity CFD, and iv) autoregressive methods. However, each of these methods has significant drawbacks, including monetary and/or computational expense, limited quantity, inaccurate statistics, and overall complexity. In contrast, the boiling flow algorithm is a simple, computationally efficient model that can generate atmospheric phase screen data with only a handful of parameters. However, boiling flow has not been widely used in aero-optic applications, at least in part because some of these parameters, such as r0, are not clearly defined for aero-optic data. In this paper, we demonstrate a method to use the boiling flow algorithm to generate arbitrary length synthetic data to match the statistics of measured aero-optic data. Importantly, we modify the standard boiling flow method to generate anisotropic phase screens. While this model does not fully capture all statistics, it can be used to generate data that matches the temporal power spectrum or the anisotropic 2D structure function, with the ability to trade fidelity to one for fidelity to the other."}
{"id": "2601.12244", "pdf": "https://arxiv.org/pdf/2601.12244", "abs": "https://arxiv.org/abs/2601.12244", "authors": ["Shyalan Ramesh", "Scott Mann", "Alex Stumpf"], "title": "A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics", "categories": ["cs.RO", "cs.NE"], "comment": "Published as part of the Special Issue: Wide Application of Marine Robotic Systems, in the Journal of Marine Science and Engineering", "summary": "The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems."}
{"id": "2601.12278", "pdf": "https://arxiv.org/pdf/2601.12278", "abs": "https://arxiv.org/abs/2601.12278", "authors": ["Yingquan Li", "Jiajie Xu", "Bodhibrata Mukhopadhyay", "Mohamed-Slim Alouini"], "title": "Low-Complexity RSS-based Underwater Localization with Unknown Transmit Power", "categories": ["eess.SP"], "comment": null, "summary": "Underwater wireless sensor networks (UWSNs) have received significant attention due to their various applications, with underwater target localization playing a vital role in enhancing network performance. Given the challenges and high costs associated with UWSN deployments, Received Signal Strength (RSS)-based localization offers a viable solution due to its minimal hardware requirements and cost-effectiveness. In this paper, we assign distance-based weights to RSS measurements, providing higher reliability to closer anchor nodes. Using the weighted RSS measurements and generalized trust region subproblem (GTRS), we propose the GTRS-based localization technique with Unknown Transmit Power (GUTP), which can be solved by a simple bisection method. Unlike conventional localization methods that require prior knowledge of the target node's transmit power, GUTP jointly estimates both the location and transmit power of the target node, broadening its practical use. Additionally, we derive the Cramer-Rao lower bounds (CRLBs) for RSS-based underwater localization with known and unknown transmit power, respectively. Extensive simulations demonstrate that GUTP achieves enhanced accuracy and significantly lower computational complexity in estimating the target node's location and transmit power compared to existing semidefinite programming (SDP)-based techniques."}
{"id": "2601.12277", "pdf": "https://arxiv.org/pdf/2601.12277", "abs": "https://arxiv.org/abs/2601.12277", "authors": ["Wangtian Shen", "Ziyang Meng", "Jinming Ma", "Mingliang Zhou", "Diyun Xiang"], "title": "An Efficient and Multi-Modal Navigation System with One-Step World Model", "categories": ["cs.RO"], "comment": null, "summary": "Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines."}
{"id": "2601.12281", "pdf": "https://arxiv.org/pdf/2601.12281", "abs": "https://arxiv.org/abs/2601.12281", "authors": ["Lingyi Zhu", "Zhongxiang Wei", "Fan Liu", "Jianjun Wu", "Xiao-Wei Tang", "Christos Masouros", "Shanpu Shen"], "title": "Overcoming BS Down-Tilt for Air-Ground ISAC Coverage: Antenna Design, Beamforming and User Scheduling", "categories": ["eess.SP"], "comment": null, "summary": "Integrated sensing and communication holds great promise for low-altitude economy applications. However, conventional downtilted base stations primarily provide sectorized forward lobes for ground services, failing to sense air targets due to backward blind zones. In this paper, a novel antenna structure is proposed to enable air-ground beam steering, facilitating simultaneous full-space sensing and communication (S&C). Specifically, instead of inserting a reflector behind the antenna array for backlobe mitigation, an omni-steering plate is introduced to collaborate with the active array for omnidirectional beamforming. Building on this hardware innovation, sum S&C mutual information (MI) is maximized, jointly optimizing user scheduling, passive coefficients of the omni-steering plate, and beamforming of the active array. The problem is decomposed into two subproblems: one for optimizing passive coefficients via Riemannian gradient on the manifold, and the other for optimizing user scheduling and active array beamforming. Exploiting relationships among S&C MI, data decoding MMSE, and parameter estimation MMSE, the original subproblem is equivalently transformed into a sum weighted MMSE problem, rigorously established via the Lagrangian and first-order optimality conditions. Simulations show that the proposed algorithm outperforms baselines in sum-MI and MSE, while providing 360 sensing coverage. Beampattern analysis further demonstrates effective user scheduling and accurate target alignment."}
{"id": "2601.12291", "pdf": "https://arxiv.org/pdf/2601.12291", "abs": "https://arxiv.org/abs/2601.12291", "authors": ["Jianhao Jiao", "Changkun Liu", "Jingwen Yu", "Boyi Liu", "Qianyi Zhang", "Yue Wang", "Dimitrios Kanoulas"], "title": "OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization", "categories": ["cs.RO", "cs.CV"], "comment": "21 pages, 20 figures", "summary": "Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page."}
{"id": "2601.12403", "pdf": "https://arxiv.org/pdf/2601.12403", "abs": "https://arxiv.org/abs/2601.12403", "authors": ["Shu Cai", "Ya-Feng Liu", "Jun Zhan", "Qi Zhang"], "title": "RIS-Enhanced Information-Decoupled Symbiotic Radio Over Broadcasting Signals", "categories": ["eess.SP"], "comment": "Accepted to ICASSP 2026. ©2026 IEEE. Personal use of this material is permitted", "summary": "This paper studies a reconfigurable intelligent surface (RIS)-enhanced decoupled symbiotic radio (SR) system in which a primary transmitter delivers common data to multiple primary receivers (PRs), while a RIS-based backscatter device sends secondary data to a backscatter receiver (BRx). Unlike conventional SR, the BRx performs energy detection and never decodes the primary signal, thereby removing ambiguity and preventing exposure of the primary payload to unintended receivers. In this paper, we formulate the problem as the minimization of the transmit power subject to a common broadcast rate constraint across all PRs and a bit error rate (BER) constraint at the BRx. The problem is nonconvex due to the unit-modulus RIS constraint and coupled quadratic forms. Leveraging a rate-balanced reformulation and a monotonic BER ratio characterization, we develop a low-complexity penalty-based block coordinate descent algorithm with closed-form updates. Numerical results show fast convergence of the proposed algorithm and reduced power consumption of the considered RIS-enhanced information-decoupled SR system over conventional SR baselines."}
{"id": "2601.12353", "pdf": "https://arxiv.org/pdf/2601.12353", "abs": "https://arxiv.org/abs/2601.12353", "authors": ["Jie Wang", "Peng Du", "Yiyuan Zhang", "Zhexin Xie", "Cecilia Laschi"], "title": "From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots", "categories": ["cs.RO"], "comment": "Provisional accepted by Bioinspiration & Biomimetics", "summary": "Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots."}
{"id": "2601.12433", "pdf": "https://arxiv.org/pdf/2601.12433", "abs": "https://arxiv.org/abs/2601.12433", "authors": ["Amanda Nyholm", "Yessica Arellano", "Jinyu Liu", "Damian Krakowiak", "Pierluigi Salvo Rossi"], "title": "Temporal Data and Short-Time Averages Improve Multiphase Mass Flow Metering", "categories": ["eess.SP", "cs.LG"], "comment": "9 pages, 6 figures", "summary": "Reliable flow measurements are essential in many industries, but current instruments often fail to accurately estimate multiphase flows, which are frequently encountered in real-world operations. Combining machine learning (ML) algorithms with accurate single-phase flowmeters has therefore received extensive research attention in recent years. The Coriolis mass flowmeter is a widely used single-phase meter that provides direct mass flow measurements, which ML models can be trained to correct, thereby reducing measurement errors in multiphase conditions. This paper demonstrates that preserving temporal information significantly improves model performance in such scenarios. We compare a multilayer perceptron, a windowed multilayer perceptron, and a convolutional neural network (CNN) on three-phase air-water-oil flow data from 342 experiments. Whereas prior work typically compresses each experiment into a single averaged sample, we instead compute short-time averages from within each experiment and train models that preserve temporal information at several downsampling intervals. The CNN performed best at 0.25 Hz with approximately 95 % of relative errors below 13 %, a normalized root mean squared error of 0.03, and a mean absolute percentage error of approximately 4.3 %, clearly outperforming the best single-averaged model and demonstrating that short-time averaging within individual experiments is preferable. Results are consistent across multiple data splits and random seeds, demonstrating robustness."}
{"id": "2601.12377", "pdf": "https://arxiv.org/pdf/2601.12377", "abs": "https://arxiv.org/abs/2601.12377", "authors": ["Haobo Xi", "Shiyong Zhang", "Qianli Dong", "Yunze Tong", "Songyang Wu", "Jing Yuan", "Xuebo Zhang"], "title": "R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry", "categories": ["cs.RO"], "comment": null, "summary": "This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub."}
{"id": "2601.12482", "pdf": "https://arxiv.org/pdf/2601.12482", "abs": "https://arxiv.org/abs/2601.12482", "authors": ["Minhua Ding", "Prathapasinghe Dharmawansa", "Italo Atzeni", "Antti Tölli"], "title": "The Effect of Noise Correlation on MMSE Channel Estimation in One-Bit Quantized Systems", "categories": ["eess.SP"], "comment": null, "summary": "This paper analyzes the impact of spatially correlated additive noise on the minimum mean-square error (MMSE) estimation of multiple-input multiple-output (MIMO) channels from one-bit quantized observations. Although additive noise can be correlated in practical scenarios, e.g., due to jamming, clutter, or other external disturbances, the effect of such correlation on the MMSE channel estimator in this setting remains unexplored in prior work. Against this backdrop, we derive a novel analytical expression for the general MIMO MMSE channel estimator, which is inherently nonlinear in one-bit observations, and accommodates arbitrary channel and noise correlation structures. To further characterize the impact of noise correlation, we subsequently specialize the general MMSE expression to certain tractable multi antenna configurations in which both the channel and the noise assume single-parameter constant correlation structures. Our analyses reveal nontrivial, noise-correlation-induced scenarios in which the estimator remains linear despite non-zero channel and noise correlation parameters. Moreover, the results indicate that, at low-to-medium signal-to-noise ratio, noise correlation improves the MMSE performance when channels are uncorrelated, but degrades performance when channels are strongly correlated."}
{"id": "2601.12395", "pdf": "https://arxiv.org/pdf/2601.12395", "abs": "https://arxiv.org/abs/2601.12395", "authors": ["Chao Wang", "Anna Belardinelli", "Michael Gienger"], "title": "VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research", "categories": ["cs.RO", "cs.HC"], "comment": "7 pages, 4 figures", "summary": "Touch-rich human-robot interaction (HRI) is difficult to study: building and programming physical robots is costly and slow, while VR-based robot prototypes often remove physical contact or break the tight coupling between an agent's body and the user's felt touch. We present VR2VR, a co-located dual VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body gestures, head and gaze behaviors, and facial expressions are mapped from the operator's tracked motion and face signals. Because the operator is physically co-present and calibrated into the same coordinate frame, the operator can also physically touch the participant, enabling the participant to perceive robot touch aligned with the robot's hands; finger and hand motion are mapped to the robot using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb teleoperation, our VR2VR system supports experimental control by retargeting or selectively enabling nonverbal channels (e.g., head only vs. head+eyes vs. head+eyes+facial expressions) while keeping physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate the platform through a touch-based Wizard-of-Oz HRI study, illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, touch-centric robot behaviors."}
{"id": "2601.12562", "pdf": "https://arxiv.org/pdf/2601.12562", "abs": "https://arxiv.org/abs/2601.12562", "authors": ["Maaz Qureshi", "Mohammad Omid Bagheri", "Abdelrahman Elbadrawy", "William Melek", "George Shaker"], "title": "Automated Angular Received-Power Characterization of Embedded mmWave Transmitters Using Geometry-Calibrated Spatial Sampling", "categories": ["eess.SP", "eess.SY"], "comment": null, "summary": "This paper presents an automated measurement methodology for angular received-power characterization of embedded millimeter-wave transmitters using geometry-calibrated spatial sampling. Characterization of integrated mmWave transmitters remains challenging due to limited angular coverage and alignment variability in conventional probe-station techniques, as well as the impracticality of anechoic-chamber testing for platform-mounted active modules. To address these challenges, we introduce RAPTAR, an autonomous measurement system for angular received-power acquisition under realistic installation constraints. A collaborative robot executes geometry-calibrated, collision-aware hemispherical trajectories while carrying a calibrated receive probe, enabling controlled and repeatable spatial positioning around a fixed device under test. A spectrum-analyzer-based receiver chain acquires amplitude-only received power as a function of angle and distance following quasi-static pose stabilization. The proposed framework enables repeatable angular received-power mapping and power-domain comparison against idealized free-space references derived from full-wave simulation. Experimental results for a 60-GHz radar module demonstrate a mean absolute received-power error below 2 dB relative to simulation-derived references and a 36.5 % reduction in error compared to manual probe-station measurements, attributed primarily to reduced alignment variability and consistent spatial sampling. The proposed method eliminates the need for coherent field measurements and near-field transformations, enabling practical power-domain characterization of embedded mmWave modules. It is well suited for angular validation in real-world platforms where conventional anechoic measurements are impractical."}
{"id": "2601.12397", "pdf": "https://arxiv.org/pdf/2601.12397", "abs": "https://arxiv.org/abs/2601.12397", "authors": ["Wangtian Shen", "Jinming Ma", "Mingliang Zhou", "Ziyang Meng"], "title": "Learning Diverse Skills for Behavior Models with Mixture of Experts", "categories": ["cs.RO"], "comment": null, "summary": "Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM."}
{"id": "2601.12629", "pdf": "https://arxiv.org/pdf/2601.12629", "abs": "https://arxiv.org/abs/2601.12629", "authors": ["Mohammad Omid Bagheri", "Justin Chow", "Josh Visser", "Veronica Leong", "George Shaker"], "title": "Millimeter-Wave Multi-Radar Tracking System Enabled by a Modified GRIN Luneburg Lens for Real-Time Healthcare Monitoring", "categories": ["eess.SP"], "comment": null, "summary": "Multi-beam radar sensing systems are emerging as powerful tools for non-contact motion tracking and vital-sign monitoring in healthcare environments. This paper presents the design and experimental validation of a synchronized millimeter-wave multi-radar tracking system enhanced by a modified spherical gradient-index (GRIN) Luneburg lens. Five commercial FMCW radar modules operating in the 58--63 GHz band are arranged in a semi-circular configuration around the lens, whose tailored refractive-index profile accommodates bistatic radar modules with co-located transmit (TX) and receive (RX) antennas. The resulting architecture generates multiple fixed high-gain beams with improved angular resolution and minimal mutual interference. Each radar operates independently but is temporally synchronized through a centralized Python-based acquisition framework to enable parallel data collection and low-latency motion tracking. A 10-cm-diameter 3D-printed prototype demonstrates a measured gain enhancement of approximately 12 dB for each module, corresponding to a substantial improvement in detection range. Full-wave simulations and measurements confirm effective non-contact, privacy-preserving short-range human-motion detection across five 28-degree sectors, providing 140-degree total angular coverage. Fall-detection experiments further validate reliable wide-angle performance and continuous spatial tracking. The proposed system offers a compact, low-cost, and scalable platform for millimeter-wave sensing in ambient healthcare and smart-environment applications."}
{"id": "2601.12428", "pdf": "https://arxiv.org/pdf/2601.12428", "abs": "https://arxiv.org/abs/2601.12428", "authors": ["Baorui Peng", "Wenyao Zhang", "Liang Xu", "Zekun Qi", "Jiazhao Zhang", "Hongsi Liu", "Wenjun Zeng", "Xin Jin"], "title": "ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods."}
{"id": "2601.12659", "pdf": "https://arxiv.org/pdf/2601.12659", "abs": "https://arxiv.org/abs/2601.12659", "authors": ["Ruiqi Wang", "Essra M. Ghoura", "Omar Alhussein", "Yuzhi Yang", "Yuhang Sheng", "Jing Ren", "Shizhong Xu", "Sami Muhaidat"], "title": "Two-Layer Reinforcement Learning-Assisted Joint Beamforming and Trajectory Optimization for Multi-UAV Downlink Communications", "categories": ["eess.SP"], "comment": null, "summary": "Unmanned aerial vehicles (UAVs) are pivotal for future 6G non-terrestrial networks, yet their high mobility creates a complex coupled optimization problem for beamforming and trajectory design. Existing numerical methods suffer from prohibitive latency, while standard deep learning often ignores dynamic interference topology, limiting scalability. To address these issues, this paper proposes a hierarchically decoupled framework synergizing graph neural networks (GNNs) with multi-agent reinforcement learning. Specifically, on the short timescale, we develop a topology-aware GNN beamformer by incorporating GraphNorm. By modeling the dynamic UAV-user association as a time-varying heterogeneous graph, this method explicitly extracts interference patterns to achieve sub-millisecond inference. On the long timescale, trajectory planning is modeled as a decentralized partially observable Markov decision process and solved via the multi-agent proximal policy optimization algorithm under the centralized training with decentralized execution paradigm, facilitating cooperative behaviors. Extensive simulation results demonstrate that the proposed framework significantly outperforms state-of-the-art optimization heuristics and deep learning baselines in terms of system sum rate, convergence speed, and generalization capability."}
{"id": "2601.12463", "pdf": "https://arxiv.org/pdf/2601.12463", "abs": "https://arxiv.org/abs/2601.12463", "authors": ["Zi Cong Guo", "James R. Forbes", "Timothy D. Barfoot"], "title": "KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter", "categories": ["cs.RO"], "comment": "Submitted to RA-L. 9 pages, 9 figures, 1 table. Note: version submitted to RA-L did not include the Appendix section present in this arXiv version", "summary": "We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration."}
{"id": "2601.12663", "pdf": "https://arxiv.org/pdf/2601.12663", "abs": "https://arxiv.org/abs/2601.12663", "authors": ["Yan-Chen Chen", "Wei-Yu Chiu", "Qun-Yu Wang", "Jing-Wei Chen", "Hao-Ting Zhao"], "title": "Energy-Efficient Prediction in Textile Manufacturing: Enhancing Accuracy and Data Efficiency With Ensemble Deep Transfer Learning", "categories": ["eess.SP", "cs.LG"], "comment": "26 pages, 11 figures", "summary": "Traditional textile factories consume substantial energy, making energy-efficient production optimization crucial for sustainability and cost reduction. Meanwhile, deep neural networks (DNNs), which are effective for factory output prediction and operational optimization, require extensive historical data, posing challenges due to high sensor deployment and data collection costs. To address this, we propose Ensemble Deep Transfer Learning (EDTL), a novel framework that enhances prediction accuracy and data efficiency by integrating transfer learning with an ensemble strategy and a feature alignment layer. EDTL pretrains DNN models on data-rich production lines (source domain) and adapts them to data-limited lines (target domain), reducing dependency on large datasets. Experiments on real-world textile factory datasets show that EDTL improves prediction accuracy by 5.66% and enhances model robustness by 3.96% compared to conventional DNNs, particularly in data-limited scenarios (20%-40% data availability). This research contributes to energy-efficient textile manufacturing by enabling accurate predictions with fewer data requirements, providing a scalable and cost-effective solution for smart production systems."}
{"id": "2601.12479", "pdf": "https://arxiv.org/pdf/2601.12479", "abs": "https://arxiv.org/abs/2601.12479", "authors": ["Miquel Kegeleirs", "Lorenzo Garattoni", "Gianpiero Francesca", "Mauro Birattari"], "title": "Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions", "categories": ["cs.RO"], "comment": null, "summary": "We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study."}
{"id": "2601.12708", "pdf": "https://arxiv.org/pdf/2601.12708", "abs": "https://arxiv.org/abs/2601.12708", "authors": ["Yuxi Zhao", "Vicente Casares-Giner", "Vicent Pla", "Luis Guijarro", "Iztok Humar", "Yi Zhong", "Xiaohu Ge"], "title": "Energy-Based Cell Association in Nonuniform Renewable Energy-Powered Cellular Networks: Analysis and Optimization of Carbon Efficiency", "categories": ["eess.SP"], "comment": null, "summary": "The increasing global push for carbon reduction highlights the importance of integrating renewable energy into the supply chain of cellular networks. However, due to the stochastic nature of renewable energy generation and the uneven load distribution across base stations, the utilization rate of renewable energy remains low. To address these challenges, this paper investigates the trade-off between carbon emissions and downlink throughput in cellular networks, offering insights into optimizing both network performance and sustainability. The renewable energy state of base station batteries and the number of occupied channels are modeled as a quasi-birth-death process. We construct models for the probability of channel blocking, average successful transmission probability for users, downlink throughput, carbon emissions, and carbon efficiency based on stochastic geometry. Based on these analyses, an energy-based cell association scheme is proposed to optimize the carbon efficiency of cellular networks. The results show that, compared to the closest cell association scheme, the energy-based cell association scheme is capable of reducing the carbon emissions of the network by 13.0% and improving the carbon efficiency by 11.3%."}
{"id": "2601.12523", "pdf": "https://arxiv.org/pdf/2601.12523", "abs": "https://arxiv.org/abs/2601.12523", "authors": ["Cem Suulker", "Muhie Al Haimus", "Thomas Mack", "Mohammad Sheikhsofla", "Neri Niccolò Dei", "Reza Kashef", "Hadi Sadati", "Federica Barontini", "Fanny Ficuciello", "Alberto Arezzo", "Bruno Siciliano", "Sebastien Ourselin", "Kaspar Althoefer"], "title": "Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands", "categories": ["cs.RO"], "comment": null, "summary": "Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy."}
{"id": "2601.12725", "pdf": "https://arxiv.org/pdf/2601.12725", "abs": "https://arxiv.org/abs/2601.12725", "authors": ["Chaedam Son", "Si-Hyeon Lee"], "title": "Robust Beamforming and Time Allocation for Time-Division Cell-Free Near-Field ISAC", "categories": ["eess.SP"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In this paper, we propose a time-division near-field integrated sensing and communication (ISAC) framework for cell-free multiple-input multiple-output (MIMO), where sensing and downlink communication are separated in time. During the sensing phase, user locations are estimated and used to construct location-aware channels, which are then exploited in the subsequent communication phase. By explicitly modeling the coupling between sensing-induced localization errors and channel-estimation errors, we capture the tradeoff between sensing accuracy and communication throughput. Based on this model, we jointly optimize the time-allocation ratio, sensing covariance matrix, and robust downlink beamforming under imperfect channel state information (CSI). The resulting non-convex problem is addressed via a semidefinite programming (SDP)-based reformulation within an alternating-optimization framework. To further reduce computational complexity, we also propose two low-complexity suboptimal designs: an error-ignorant scheme and a maximum ratio transmission (MRT)-based scheme. Simulation results show that the proposed scheme significantly improves localization accuracy over far-field and monostatic setups, thereby reducing channel estimation errors and ultimately enhancing the achievable rate. Moreover, the error-ignorant scheme performs well under stringent sensing requirements, whereas the MRT-based scheme remains robust over a wide range of sensing requirements by adapting the time-allocation ratio, albeit with some beamforming loss."}
{"id": "2601.12701", "pdf": "https://arxiv.org/pdf/2601.12701", "abs": "https://arxiv.org/abs/2601.12701", "authors": ["Yunpeng Lyu", "Chao Cao", "Ji Zhang", "Howie Choset", "Zhongqiang Ren"], "title": "RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments", "categories": ["cs.RO", "cs.CG"], "comment": null, "summary": "Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods."}
{"id": "2601.12788", "pdf": "https://arxiv.org/pdf/2601.12788", "abs": "https://arxiv.org/abs/2601.12788", "authors": ["Kaihe Wang", "Ran Yang", "Lipeng Zhu", "Rongyan Xi", "Yue Xiu", "Zhongpei Zhang"], "title": "Movable Antenna Enhanced MIMO Communications with Spatial Modulation", "categories": ["eess.SP"], "comment": null, "summary": "Movable antenna (MA) has demonstrated great potential in enhancing wireless communication performance. In this paper, we investigate an MA-enabled multiple-input multiple-output (MIMO) communication system with spatial modulation (SM), which improves communication performance by utilizing flexible MA placement while reducing the cost of RF chains. To this end, we propose a joint transceiver design framework aimed at minimizing the bit error rate (BER) based on the maximum minimum distance (MMD) criterion. To address the intractable problem, we develop an efficient iterative algorithm based on alternating optimization (AO) and successive convex approximation (SCA) techniques. Simulation results demonstrate that the proposed algorithm achieves rapid convergence performance and significantly outperforms the existing benchmark schemes."}
{"id": "2601.12742", "pdf": "https://arxiv.org/pdf/2601.12742", "abs": "https://arxiv.org/abs/2601.12742", "authors": ["Xuecheng Chen", "Zongzhuo Liu", "Jianfa Ma", "Bang Du", "Tiantian Zhang", "Xueqian Wang", "Boyu Zhou"], "title": "AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication."}
{"id": "2601.12827", "pdf": "https://arxiv.org/pdf/2601.12827", "abs": "https://arxiv.org/abs/2601.12827", "authors": ["Haotian Wang", "Dan Wang", "Xiaodong Xu", "Chuan Huang", "Hao Chen", "Nan Ma"], "title": "Integrated Sensing and Semantic Communication with Adaptive Source-Channel Coding", "categories": ["eess.SP"], "comment": null, "summary": "Semantic communication has emerged as a new paradigm to facilitate the performance of integrated sensing and communication systems in 6G. However, most of the existing works mainly focus on sensing data compression to reduce the subsequent communication overheads, without considering the integrated transmission framework for both the SemCom and sensing tasks. This paper proposes an adaptive source-channel coding and beamforming design framework for integrated sensing and SemCom systems by jointly optimizing the coding rate for SemCom task and the transmit beamforming for both the SemCom and sensing tasks. Specifically, an end-to-end semantic distortion function is approximated by deriving an upper bound composing of source and channel coding induced components, and then a hybrid Cramér-Rao bound (HCRB) is also derived for target position under imperfect time synchronization. To facilitate the joint optimization, a distortion minimization problem is formulated by considering the HCRB threshold, channel uses, and power budget. Subsequently, an alternative optimization algorithm composed of successive convex approximation and fractional programming is proposed to address this problem by decoupling it into two subproblems for coding rate and beamforming designs, respectively. Simulation results demonstrate that our proposed scheme outperforms the conventional deep joint source-channel coding -water filling-zero forcing benchmark."}
{"id": "2601.12790", "pdf": "https://arxiv.org/pdf/2601.12790", "abs": "https://arxiv.org/abs/2601.12790", "authors": ["Yang Zhang", "Jianming Ma", "Liyun Yan", "Zhanxiang Cao", "Yazhou Zhang", "Haoyang Li", "Yue Gao"], "title": "FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation", "categories": ["cs.RO"], "comment": "12 pages, 11 figures", "summary": "Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments."}
{"id": "2601.12867", "pdf": "https://arxiv.org/pdf/2601.12867", "abs": "https://arxiv.org/abs/2601.12867", "authors": ["Zixiang Han", "Hanning Wang", "Shiwen Tang", "Yujie Zhang"], "title": "Angular Sensing by Highly Reconfigurable Pixel Antennas with Joint Radiating Aperture and Feeding Ports Reconfiguration", "categories": ["eess.SP", "cs.IT"], "comment": null, "summary": "Angular sensing capability is realized using highly reconfigurable pixel antenna (HRPA) with joint radiating aperture and feeding ports reconfiguration. Pixel antennas represent a general class of reconfigurable antenna designs in which the radiating surface, regardless of its shape or size, is divided into sub-wavelength elements called pixels. Each pixel is connected to its neighboring elements through radio frequency switches. By controlling pixel connections, the pixel antenna topology can be flexibly adjusted so that the resulting radiation pattern can be reconfigured. However, conventional pixel antennas have only a single, fixed-position feeding port, which is not efficient for angular sensing. Therefore, in this work, we further extend the reconfigurability of pixel antennas by introducing the HRPA, which enables both geometry control of the pixel antenna and switching of its feeding ports. The model of the proposed HRPA, including both circuit and radiation parameters, is derived. A codebook is then defined, consisting of pixel connection states and feeding port positions for each sensing area. Based on this codebook, an efficient optimization approach is developed to minimize the Cram\\acute{\\mathrm{\\mathbf{e}}}r-Rao lower bound (CRLB) and obtain the optimal HRPA geometries for angular sensing within a given area. Numerical results show that the HRPA reduces the angle estimation error by more than 50% across the full three-dimensional sphere when compared with a conventional uniform planar array of the same size. This demonstrates the effectiveness of the proposed approach and highlights the potential of HRPA for integrated sensing and communication systems."}
{"id": "2601.12796", "pdf": "https://arxiv.org/pdf/2601.12796", "abs": "https://arxiv.org/abs/2601.12796", "authors": ["Changwei Jing", "Jai Krishna Bandi", "Jianglong Ye", "Yan Duan", "Pieter Abbeel", "Xiaolong Wang", "Sha Yi"], "title": "Contact-Aware Neural Dynamics", "categories": ["cs.RO"], "comment": "8 pages", "summary": "High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment."}
{"id": "2601.12924", "pdf": "https://arxiv.org/pdf/2601.12924", "abs": "https://arxiv.org/abs/2601.12924", "authors": ["Ruopeng Xu", "Songling Zhang", "Zhaohui Yang", "Mingzhe Chen", "Zhaoyang Zhang", "Kai-Kit Wong"], "title": "Fluid Antenna Relay (FAR)-assisted Communication with Hybrid Relaying Scheme Selection", "categories": ["eess.SP"], "comment": null, "summary": "In this paper, we investigate a fluid antenna relay (FAR)-assisted communication system with hybrid relaying scheme selection. By leveraging statistical channel state information (CSI) and distribution characteristics of fluid antenna system (FAS), we approximate the outage probability (OP) with different relaying schemes utilizing a Gaussian copula-based method. Each relay node follows the OP-minimized principle to choose the forwarding schemes. To reduce self-interference and avoid multi-user interference, half-duplex relays and frequency division multiple access schemes are considered, respectively. On this basis, we formulate a sum-rate maximization problem to mitigate the rate loss introduced by the half-duplex mode. To solve this problem, we first transform the original nonconvex problem into a power control optimization problem by obtaining the closed form of bandwidth allocation and substituting it into the original problem. Then, we solve the power control optimization problem with a low complexity method. Simulation results verify the effectiveness of our proposed algorithm to improve the sum rate of the system."}
{"id": "2601.12799", "pdf": "https://arxiv.org/pdf/2601.12799", "abs": "https://arxiv.org/abs/2601.12799", "authors": ["Peng Li", "Zihan Zhuang", "Yangfan Gao", "Yi Dong", "Sixian Li", "Changhao Jiang", "Shihan Dou", "Zhiheng Xi", "Enyu Zhou", "Jixuan Huang", "Hui Li", "Jingjing Gong", "Xingjun Ma", "Tao Gui", "Zuxuan Wu", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Xipeng Qiu"], "title": "FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions", "categories": ["cs.RO", "cs.CL", "cs.CV"], "comment": "Project Page: https://openmoss.github.io/FRoM-W1", "summary": "Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence."}
{"id": "2601.12963", "pdf": "https://arxiv.org/pdf/2601.12963", "abs": "https://arxiv.org/abs/2601.12963", "authors": ["Mauro Marchese", "Musa Furkan Keskin", "Pietro Savazzi", "Henk Wymeersch"], "title": "Monostatic ISAC Without Full Buffers: Revisiting Spatial Trade-Offs Under Bursty Traffic", "categories": ["eess.SP"], "comment": "Presented at 6th IEEE International Symposium on Joint Communication and Sensing (JC&S) 2026", "summary": "This work investigates the spatial trade-offs arising from the design of the transmit beamformer in a monostatic integrated sensing and communication (ISAC) base station (BS) under bursty traffic, a crucial aspect necessitated by the integration of communication and sensing functionalities in next-generation wireless systems. In this setting, the BS does not always have data available for transmission. This study compares different ISAC policies and reveals the presence of multiple effects influencing ISAC performance: signal-to-noise ratio (SNR) boosting of data-aided strategies compared to pilot-based ones, saturation of the probability of detection in data-aided strategies due to the non-full-buffer assumption, and, finally, directional masking of sensing targets due to the relative position between target and user. Simulation results demonstrate varying impact of these effects on ISAC trade-offs under different operating conditions, thus guiding the design of efficient ISAC transmission strategies."}
{"id": "2601.12894", "pdf": "https://arxiv.org/pdf/2601.12894", "abs": "https://arxiv.org/abs/2601.12894", "authors": ["Kangye Ji", "Yuan Meng", "Zhou Jianbo", "Ye Li", "Hanyun Cui", "Zhi Wang"], "title": "Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\\textit{static}$ schedules that fail to adapt to the $\\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\\underline{\\textbf{S}}$parse $\\underline{\\textbf{A}}$ction$\\underline{\\textbf{G}}$en ($\\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/."}
{"id": "2601.12970", "pdf": "https://arxiv.org/pdf/2601.12970", "abs": "https://arxiv.org/abs/2601.12970", "authors": ["Mauro Marchese", "Musa Furkan Keskin", "Henk Wymeersch", "Pietro Savazzi"], "title": "6G OFDM Communications with High Mobility Transceivers and Scatterers via Angle-Domain Processing and Deep Learning", "categories": ["eess.SP"], "comment": "Accepted for presentation at IEEE International Conference on Communications (ICC) 2026", "summary": "High-mobility communications, which are crucial for next-generation wireless systems, cause the orthogonal frequency division multiplexing (OFDM) waveform to suffer from strong intercarrier interference (ICI) due to the Doppler effect. In this work, we propose a novel receiver architecture for OFDM that leverages the angular domain to separate multipaths. A block-type pilot is sent to estimate direction-of-arrivals (DoAs), propagation delays, and channel gains of the multipaths. Subsequently, a decision-directed (DD) approach is employed to estimate and iteratively refine the Dopplers. Two different approaches are investigated to provide initial Doppler estimates: an error vector magnitude (EVM)-based method and a deep learning (DL)-based method. Simulation results reveal that the DL-based approach allows for constant bit error rate (BER) performance up to the maximum 6G speed of 1000 km/h."}
{"id": "2601.12901", "pdf": "https://arxiv.org/pdf/2601.12901", "abs": "https://arxiv.org/abs/2601.12901", "authors": ["Hongchen Li", "Tianyu Li", "Jiazhi Yang", "Haochen Tian", "Caojun Wang", "Lei Shi", "Mingyang Shang", "Zengrong Lin", "Gaoqiang Wu", "Zhihui Hao", "Xianpeng Lang", "Jia Hu", "Hongyang Li"], "title": "PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning", "categories": ["cs.RO"], "comment": null, "summary": "Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process."}
{"id": "2601.12982", "pdf": "https://arxiv.org/pdf/2601.12982", "abs": "https://arxiv.org/abs/2601.12982", "authors": ["Alexandros I. Papadopoulos", "Maria Anna Pistela", "Dimitrios Tyrovolas", "Antonios Lalas", "Konstantinos Votis", "Sotiris Ioannidis", "George K. Karagiannidis", "Christos Liaskos"], "title": "Physics-Aware RIS Codebook Compilation for Near-Field Beam Focusing under Mutual Coupling and Specular Reflections", "categories": ["eess.SP", "cs.NI"], "comment": "Accepted for presentation in IEEE International Conference on Communications (IEEE ICC 2026)", "summary": "Next-generation wireless networks are envisioned to achieve reliable, low-latency connectivity within environments characterized by strong multipath and severe channel variability. Programmable wireless environments (PWEs) address this challenge by enabling deterministic control of electromagnetic (EM) propagation through software-defined reconfigurable intelligent surfaces (RISs). However, effectively configuring RISs in real time remains a major bottleneck, particularly under near-field conditions where mutual coupling and specular reflections alter the intended response. To overcome this limitation, this paper introduces MATCH, a physics-based codebook compilation algorithm that explicitly accounts for the EM coupling among RIS unit cells and the reflective interactions with surrounding structures, ensuring that the resulting codebooks remain consistent with the physical characteristics of the environment. Finally, MATCH is evaluated under a full-wave simulation framework incorporating mutual coupling and secondary reflections, demonstrating its ability to concentrate scattered energy within the focal region, confirming that physics-consistent, codebook-based optimization constitutes an effective approach for practical and efficient RIS configuration."}
{"id": "2601.12918", "pdf": "https://arxiv.org/pdf/2601.12918", "abs": "https://arxiv.org/abs/2601.12918", "authors": ["Dharmendra Sharma", "Peeyush Thakur", "Sandeep Gupta", "Narendra Kumar Dhar", "Laxmidhar Behera"], "title": "Dynamic Hand Gesture Recognition for Robot Manipulator Tasks", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology."}
{"id": "2601.13001", "pdf": "https://arxiv.org/pdf/2601.13001", "abs": "https://arxiv.org/abs/2601.13001", "authors": ["Wenrui Yu", "Jaron Skovsted Gundersen", "Richard Heusdens", "Qiongxiu Li"], "title": "When Is Distributed Nonlinear Aggregation Private? Optimality and Information-Theoretical Bounds", "categories": ["eess.SP", "cs.IT"], "comment": null, "summary": "Nonlinear aggregation is central to modern distributed systems, yet its privacy behavior is far less understood than that of linear aggregation. Unlike linear aggregation where mature mechanisms can often suppress information leakage, nonlinear operators impose inherent structural limits on what privacy guarantees are theoretically achievable when the aggregate must be computed exactly. This paper develops a unified information-theoretic framework to characterize privacy leakage in distributed nonlinear aggregation under a joint adversary that combines passive (honest-but-curious) corruption and eavesdropping over communication channels.\n  We cover two broad classes of nonlinear aggregates: order-based operators (maximum/minimum and top-$K$) and robust aggregation (median/quantiles and trimmed mean). We first derive fundamental lower bounds on leakage that hold without sacrificing accuracy, thereby identifying the minimum unavoidable information revealed by the computation and the transcript. We then propose simple yet effective privacy-preserving distributed algorithms, and show that with appropriate randomized initialization and parameter choices, our proposed approaches can attach the derived optimal bounds for the considered operators. Extensive experiments validate the tightness of the bounds and demonstrate that network topology and key algorithmic parameters (including the stepsize) govern the observed leakage in line with the theoretical analysis, yielding actionable guidelines for privacy-preserving nonlinear aggregation."}
{"id": "2601.12925", "pdf": "https://arxiv.org/pdf/2601.12925", "abs": "https://arxiv.org/abs/2601.12925", "authors": ["Weize Xie", "Yi Ding", "Ying He", "Leilei Wang", "Binwen Bai", "Zheyi Zhao", "Chenyang Wang", "F. Richard Yu"], "title": "ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks."}
{"id": "2601.13065", "pdf": "https://arxiv.org/pdf/2601.13065", "abs": "https://arxiv.org/abs/2601.13065", "authors": ["Davide Bergamasco", "Federico Clazzer", "Paolo Casari"], "title": "OTFS-IDMA: An Unsourced Multiple Access Scheme for Doubly-Dispersive Channels", "categories": ["eess.SP"], "comment": "6 pages, 5 figures", "summary": "We present an unsourced multiple access (UMAC) scheme tailored to high-mobility wireless channels. The proposed construction is based on orthogonal time frequency space (OTFS) modulation and sparse interleaver division multiple access (IDMA) in the delay-Doppler (DD) domain. The receiver runs a compressive-sensing joint activity-detection and channel estimation process followed by a single-user decoder which harnesses multipath diversity via the maximal-ratio combining (MRC) principle. Numerical results show the potential of DD-based uncoordinated schemes in the presence of double selectivity, while remarking the design tradeoffs and remaining challenges introduced by the proposed design."}
{"id": "2601.12939", "pdf": "https://arxiv.org/pdf/2601.12939", "abs": "https://arxiv.org/abs/2601.12939", "authors": ["Kaleem Arshid", "Ali Krayani", "Lucio Marcenaro", "David Martin Gomez", "Carlo Regazzoni"], "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design", "categories": ["cs.RO", "cs.AI", "eess.SP"], "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'", "summary": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control."}
{"id": "2601.13157", "pdf": "https://arxiv.org/pdf/2601.13157", "abs": "https://arxiv.org/abs/2601.13157", "authors": ["Hang Zou", "Bohao Wang", "Yu Tian", "Lina Bariah", "Chongwen Huang", "Samson Lasaulce", "Mérouane Debbah"], "title": "Seeing Radio: From Zero RF Priors to Explainable Modulation Recognition with Vision Language Models", "categories": ["eess.SP"], "comment": null, "summary": "The rise of vision language models (VLMs) paves a new path for radio frequency (RF) perception. Rather than designing task-specific neural receivers, we ask if VLMs can learn to recognize modulations when RF waveforms are expressed as images. In this work, we find that they can. In specific, in this paper, we introduce a practical pipeline for converting complex IQ streams into visually interpretable inputs, hence, enabling general-purpose VLMs to classify modulation schemes without changing their underlying design. Building on this, we construct an RF visual question answering (VQA) benchmark framework that covers 57 classes across major families of analog/digital modulations with three complementary image modes, namely, (i) short \\emph{time-series} IQ segments represented as real/imaginary traces, (ii) magnitude-only \\emph{spectrograms}, and (iii) \\emph{joint} representations that pair spectrograms with a synchronized time-series waveforms. We design uniform zero-shot and few-shot prompts for both class-level and family-level evaluations. Our finetuned VLMs with these images achieve competitive accuracy of $90\\%$ compared to $10\\%$ of the base models. Furthermore, the fine-tuned VLMs show robust performance under noise and demonstrate high generalization performance to unseen modulation types, without relying on RF-domain priors or specialized architectures. The obtained results show that combining RF-to-image conversion with promptable VLMs provides a scalable and practical foundation for RF-aware AI systems in future 6G networks."}
{"id": "2601.12952", "pdf": "https://arxiv.org/pdf/2601.12952", "abs": "https://arxiv.org/abs/2601.12952", "authors": ["Shibo Shao", "Dong Zhou", "Guanghui Sun", "Liwen Zhang", "Mingxuan Jiang"], "title": "Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration", "categories": ["cs.RO", "eess.SY"], "comment": "6 figures, 4 tables. Focus on 6-DOF spacecraft rendezvous and docking control using imitation learning-based control method", "summary": "Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD."}
{"id": "2601.13201", "pdf": "https://arxiv.org/pdf/2601.13201", "abs": "https://arxiv.org/abs/2601.13201", "authors": ["Konstantinos D. Katsanos", "George C. Alexandropoulos"], "title": "Decentralized Cooperative Beamforming for BDRIS-Assisted Cell-Free MIMO OFDM Systems", "categories": ["eess.SP", "cs.ET", "cs.IT"], "comment": "13 pages, 6 figures, submitted to an IEEE Transactions journal", "summary": "In this paper, a wideband cell-free multi-stream multi-user Multiple-Input Multiple-Output (MIMO) Orthogonal Frequency Division Multiplexing (OFDM) system is considered operating within a smart wireless environment enabled by multiple Beyond Diagonal Reconfigurable Intelligent Surfaces (BDRISs). A novel decentralized active and passive beamforming framework, robust to imperfect channel state availability and with minimal cooperation among the system's multiple Base Stations (BSs) for deciding the final configurations of the shared BDRISs, is proposed, which aims to substantially reduce the overhead inherent in centralized solutions necessitating a central processing unit of high computational power. By considering a Dynamic Group-Connected (DGC) BDRIS architecture with frequency-selective responses per unit element, we formulate the system's sum-rate maximization problem with respect to the tunable capacitances and permutation matrices of the BDRISs as well as the precoding matrices of the BSs, which is solved via successive concave approximation and alternating projections as well as consensus-based updates for the BDRISs' design. Through extensive simulation results, it is showcased that the proposed robust decentralized cooperative approach with diverse BDRIS architectures outperforms non-cooperation benchmarks. It is also demonstrated that the considered DGC BDRIS architecture is able to provide sum-rate performance gains sufficiently close to the more complex fully-connected BDRIS structure."}
{"id": "2601.12993", "pdf": "https://arxiv.org/pdf/2601.12993", "abs": "https://arxiv.org/abs/2601.12993", "authors": ["Hao Luo", "Ye Wang", "Wanpeng Zhang", "Sipeng Zheng", "Ziheng Xi", "Chaoyi Xu", "Haiweng Xu", "Haoqi Yuan", "Chi Zhang", "Yiqing Wang", "Yicheng Feng", "Zongqing Lu"], "title": "Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization", "categories": ["cs.RO"], "comment": "44 pages", "summary": "We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal \"mother tongue\" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms."}
{"id": "2601.13204", "pdf": "https://arxiv.org/pdf/2601.13204", "abs": "https://arxiv.org/abs/2601.13204", "authors": ["Yanfeng Zhang", "Xi'an Fan", "Jinkai Zheng", "Xiaoye Jing", "Weiwei Yang", "Xu Zhu"], "title": "Hierarchical Sparse Vector Transmission for Ultra Reliable and Low Latency Communications", "categories": ["eess.SP", "cs.IT", "eess.IV"], "comment": null, "summary": "Sparse vector transmission (SVT) is a promising candidate technology for achieving ultra-reliable low-latency communication (URLLC). In this paper, a hierarchical SVT scheme is proposed for multi-user URLLC scenarios. The hierarchical SVT scheme partitions the transmitted bits into common and private parts. The common information is conveyed by the indices of non-zero sections in a sparse vector, while each user's private information is embedded into non-zero blocks with specific block lengths. At the receiver, the common bits are first recovered from the detected non-zero sections, followed by user-specific private bits decoding based on the corresponding non-zero block indices. Simulation results show the proposed scheme outperforms state-of-the-art SVT schemes in terms of block error rate."}
{"id": "2601.13042", "pdf": "https://arxiv.org/pdf/2601.13042", "abs": "https://arxiv.org/abs/2601.13042", "authors": ["Yijun Zhou", "Muhan Hou", "Kim Baraka"], "title": "Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks", "categories": ["cs.RO"], "comment": "5 pages, 5 figures. Accepted in HRI'26 (Late-Breaking Reports track) in 12 Jan, 2026", "summary": "Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap."}
{"id": "2601.13205", "pdf": "https://arxiv.org/pdf/2601.13205", "abs": "https://arxiv.org/abs/2601.13205", "authors": ["Kadyrzhan Tortayev", "Oliver Falkenberg Damborg", "Jònas À Hàlvmørk Joensen", "Jonas Pedesk", "Yifa Li", "Fengchun Zhang", "Zeliang An", "Yubo Wang", "Ming Shen"], "title": "Co-Channel Interference Mitigation Using Deep Learning for Drone-Based Large-Scale Antenna Measurements", "categories": ["eess.SP"], "comment": null, "summary": "Unmanned aerial vehicles (UAVs) enable efficient in-situ radiation characterization of large-aperture antennas directly in their deployment environments. In such measurements, a continuous-wave (CW) probe tone is commonly transmitted to characterize the antenna response. However, active co-channel emissions from neighboring antennas often introduce severe in-band interference, where classical FFT-based estimators fail to accurately estimate the CW tone amplitude when the signal-to-interference ratios (SIR) falls below -10 dB. This paper proposes a lightweight deep convolutional neural network (DC-CNN) that estimates the amplitude of the CW tone. The model is trained and evaluated on real 5~GHz measurement bursts spanning an effective SIR range of --33.3 dB to +46.7 dB. Despite its compact size (<20k parameters), the proposed DC-CNN achieves a mean absolute error (MAE) of 7% over the full range, with <1 dB error for SIR >= -30 dB. This robustness and efficiency make DC-CNN suitable for deployment on embedded UAV platforms for interference-resilient antenna pattern characterization."}
{"id": "2601.13088", "pdf": "https://arxiv.org/pdf/2601.13088", "abs": "https://arxiv.org/abs/2601.13088", "authors": ["Harry Huang", "Talia Xu", "Marco Zúñiga Zamalloa"], "title": "Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.\n  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.\n  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system."}
{"id": "2601.13289", "pdf": "https://arxiv.org/pdf/2601.13289", "abs": "https://arxiv.org/abs/2601.13289", "authors": ["Ruhul Amin Khalil", "Asiya Jehangir", "Hanane Lamaazi", "Sadaf Rubab", "Nasir Saeed"], "title": "Semantic Communication in Underwater IoT Networks for Meaning-Driven Connectivity", "categories": ["eess.SP"], "comment": "25 pages, 3 figures and 8 tables", "summary": "The Internet of Underwater Things (IoUT) is revolutionizing marine sensing and environmental monitoring, as well as subaquatic exploration, which are enabled by interconnected and intelligent subsystems. Nevertheless, underwater communication is constrained by narrow bandwidth, high latency, and strict energy constraints, which are the source of efficiency problems in traditional data-centric networks. To tackle these problematic issues, this work provides a survey of recent advances in Semantic Communication (SC) for IoUT, a novel communication paradigm that seeks to harness not raw symbol information but rather its meaning and/or contextual significance. In this paper, we investigate the emerging advanced AI-powered frameworks, including large language models (LLMs), diffusion-based generative encoders, and federated learning (FL), that bridge semantic compression with context-aware prioritization and robust information reconstruction over noisy underwater channels. Hybrid acoustic-optical-RF architectures and edge-intelligent semantic encoders are also considered enablers of sustainable, adaptive operations. Examples in underwater archaeology, marine ecology, and autonomous underwater vehicles (AUVs) coordination are provided as a relief to illustrate the merits of meaning-driven connectivity. The paper concludes with some recommendations, including semantic representations standardization, cross-domain interpolation, and privacy-support schemes. These issues must be addressed in the future before trustworthy SC-enabled IoUT systems can be developed for underwater communication."}
{"id": "2601.13096", "pdf": "https://arxiv.org/pdf/2601.13096", "abs": "https://arxiv.org/abs/2601.13096", "authors": ["Muhayy Ud Din", "Waseem Akram", "Ahsan B. Bakht", "Irfan Hussain"], "title": "LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System", "categories": ["cs.RO", "cs.CV"], "comment": "submitted in AEJ", "summary": "Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection"}
{"id": "2601.13418", "pdf": "https://arxiv.org/pdf/2601.13418", "abs": "https://arxiv.org/abs/2601.13418", "authors": ["Sambrama Hegde", "Venkata Srirama Rohit Kantheti", "Liang C Chu", "Erik Blasch", "Shih-Chun Lin"], "title": "Autonomous Self-Healing UAV Swarms for Robust 6G Non-Terrestrial Networks", "categories": ["eess.SP"], "comment": null, "summary": "Recent years have seen an increased interest in the use of Non-terrestrial networks (NTNs), especially the unmanned aerial vehicles (UAVs) to provide cost-effective global connectivity in next-generation wireless networks. We introduce a resilient, adaptive, self-healing network design (RASHND) to optimize signal quality under dynamic interference and adversarial conditions. RASHND leverages inter-node communication and an intelligent algorithm selection process, incorporating combining techniques like distributed-Maximal Ratio Combining (d-MRC), distributed-Linear Minimum Mean Squared Error Estimation(d-LMMSE), and Selection Combining (SC). These algorithms are selected to improve performance by adapting to changing network conditions. To evaluate the effectiveness of the proposed RASHND solutions, a software-defined radio (SDR)-based hardware testbed afforded initial testing and evaluations. Additionally, we present results from UAV tests conducted on the AERPAW testbed to validate our solutions in real-world scenarios. The results demonstrate that RASHND significantly enhances the reliability and interference resilience of UAV networks, making them well-suited for critical communications."}
{"id": "2601.13177", "pdf": "https://arxiv.org/pdf/2601.13177", "abs": "https://arxiv.org/abs/2601.13177", "authors": ["Behnam Moradkhani", "Raghav Sankaranarayanan", "Pejman Kheradmand", "Harshith Jella", "Nicholas Ahn", "Ajmal Zemmar", "Yash Chitalia"], "title": "Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation", "categories": ["cs.RO"], "comment": "8 pages, 9 figures", "summary": "Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management."}
{"id": "2601.13470", "pdf": "https://arxiv.org/pdf/2601.13470", "abs": "https://arxiv.org/abs/2601.13470", "authors": ["Gabriel Avanzi Ubiali", "José Carlos Marinello Filho", "Taufik Abrão"], "title": "Joint Subarray Selection, User Scheduling, and Pilot Assignment for XL-MIMO", "categories": ["eess.SP"], "comment": "31 pages, 5 figures, full paper", "summary": "Extra-large scale MIMO (XL-MIMO) is a key technology for meeting sixth-generation (6G) requirements for high-rate connectivity and uniform quality of service (QoS); however, its deployment is challenged by the prohibitive complexity of resource management based on instantaneous channel state information (CSI). To address this intractability, this work derives novel closed-form deterministic signal-to-interference-plus-noise ratio (SINR) expressions for both centralized and distributed uplink operations. Valid for Rician fading channels with minimum mean square error (MMSE) receive combining and MMSE channel estimation, these expressions depend exclusively on long-term channel statistics, providing a tractable alternative to computationally expensive instantaneous CSI-driven optimization. Building on these results, we develop statistical-CSI-based algorithms for joint subarray selection, users scheduling, and pilot assignment, leveraging the derived SINR approximations to maximize the minimum spectral efficiency (SE) among scheduled users while preserving computational tractability. The proposed framework exploits the spatial sparsity of user equipment (UE) visibility regions (VRs) to enable more aggressive pilot reuse than is possible in conventional massive MIMO. Numerical results validate the high accuracy of the derived SINR approximations and demonstrate that the proposed algorithms significantly enhance fairness and throughput in crowded scenarios."}
{"id": "2601.13196", "pdf": "https://arxiv.org/pdf/2601.13196", "abs": "https://arxiv.org/abs/2601.13196", "authors": ["Jacob Swindell", "Marija Popović", "Riccardo Polvara"], "title": "Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations", "categories": ["cs.RO"], "comment": null, "summary": "Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping."}
{"id": "2601.13549", "pdf": "https://arxiv.org/pdf/2601.13549", "abs": "https://arxiv.org/abs/2601.13549", "authors": ["Chao Zhou", "Changsheng You", "Cong Zhou", "Chengwen Xing", "Jianhua Zhang"], "title": "Near-field Physical Layer Security: Robust Beamforming under Location Uncertainty", "categories": ["eess.SP", "cs.IT"], "comment": "13 pages, 11 figures, submitted to IEEE for possible publication", "summary": "In this paper, we study robust beamforming design for near-field physical-layer-security (PLS) systems, where a base station (BS) equipped with an extremely large-scale array (XL-array) serves multiple near-field legitimate users (Bobs) in the presence of multiple near-field eavesdroppers (Eves). Unlike existing works that mostly assume perfect channel state information (CSI) or location information of Eves, we consider a more practical and challenging scenario, where the locations of Bobs are perfectly known, while only imperfect location information of Eves is available at the BS. We first formulate a robust optimization problem to maximize the sum-rate of Bobs while guaranteeing a worst-case limit on the eavesdropping rate under location uncertainty. By transforming Cartesian position errors into the polar domain, we reveal an important near-field angular-error amplification effect: for the same location error, the closer the Eve, the larger the angle error, severely degrading the performance of conventional robust beamforming methods based on imperfect channel state information. To address this issue, we first establish the conditions for which the first-order Taylor approximation of the near-field channel steering vector under location uncertainty is largely accurate. Then, we propose a two-stage robust beamforming method, which first partitions the uncertainty region into multiple fan-shaped sub-regions, followed by the second stage to formulate and solve a refined linear-matrix-inequality (LMI)-based robust beamforming optimization problem. In addition, the proposed method is further extended to scenarios with multiple Bobs and multiple Eves. Finally, numerical results validate that the proposed method achieves a superior trade-off between rate performance and secrecy robustness, hence significantly outperforming existing benchmarks under Eve location uncertainty."}
{"id": "2601.13232", "pdf": "https://arxiv.org/pdf/2601.13232", "abs": "https://arxiv.org/abs/2601.13232", "authors": ["Kourosh Darvish", "Arjun Sohal", "Abhijoy Mandal", "Hatem Fakhruldeen", "Nikola Radulov", "Zhengxue Zhou", "Satheeshkumar Veeramani", "Joshua Choi", "Sijie Han", "Brayden Zhang", "Jeeyeoun Chae", "Alex Wright", "Yijie Wang", "Hossein Darvish", "Yuchi Zhao", "Gary Tom", "Han Hao", "Miroslav Bogdanovic", "Gabriella Pizzuto", "Andrew I. Cooper", "Alán Aspuru-Guzik", "Florian Shkurti", "Animesh Garg"], "title": "MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation", "categories": ["cs.RO"], "comment": "Darvish, K., Sohal, A., Mandal, A. et al. MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation. Nat Comput Sci (2025)", "summary": "Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ ."}
{"id": "2601.13593", "pdf": "https://arxiv.org/pdf/2601.13593", "abs": "https://arxiv.org/abs/2601.13593", "authors": ["Aswin Jose", "Roeland P. J. E. Decorte", "Laurent Locquet"], "title": "Instant Preliminary Cardiac Analysis from Smartphone Auscultation: A Real-World Canine Heart Sound Dataset and Evaluation", "categories": ["eess.SP"], "comment": null, "summary": "This study presents a real-world canine heart sound dataset and evaluates SoNUS version 3.2.x, a machine learning algorithm for preliminary cardiac analysis using smartphone microphone recordings. More than one hundred recordings were collected from dogs across four continents, with thirty eight recordings annotated by board certified veterinary cardiologists for quantitative evaluation. SoNUS version 3.2.x employs a multi-stage fallback architecture with quality-aware filtering to ensure reliable output under variable recording conditions. The primary sixty second model achieved mean and median heart rate accuracies of ninety one point six three percent and ninety four point nine five percent, while a fast model optimized for thirty to forty second recordings achieved mean and median accuracies of eighty eight point eight six percent and ninety two point nine eight percent. These results demonstrate the feasibility of extracting clinically relevant cardiac information from opportunistic smartphone recordings, supporting scalable preliminary assessment and telehealth applications in veterinary cardiology."}
{"id": "2601.13250", "pdf": "https://arxiv.org/pdf/2601.13250", "abs": "https://arxiv.org/abs/2601.13250", "authors": ["Ante Marić", "Giammarco Caroleo", "Alessandro Albini", "Julius Jankowski", "Perla Maiolino", "Sylvain Calinon"], "title": "Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation", "categories": ["cs.RO"], "comment": null, "summary": "Tactile sensing provides a promising sensing modality for object pose estimation in manipulation settings where visual information is limited due to occlusion or environmental effects. However, efficiently leveraging tactile data for estimation remains a challenge due to partial observability, with single observations corresponding to multiple possible contact configurations. This limits conventional estimation approaches largely tailored to vision. We propose to address these challenges by learning an inverse tactile sensor model using denoising diffusion. The model is conditioned on tactile observations from a distributed tactile sensor and trained in simulation using a geometric sensor model based on signed distance fields. Contact constraints are enforced during inference through single-step projection using distance and gradient information from the signed distance field. For online pose estimation, we integrate the inverse model with a particle filter through a proposal scheme that combines generated hypotheses with particles from the prior belief. Our approach is validated in simulated and real-world planar pose estimation settings, without access to visual data or tight initial pose priors. We further evaluate robustness to unmodeled contact and sensor dynamics for pose tracking in a box-pushing scenario. Compared to local sampling baselines, the inverse sensor model improves sampling efficiency and estimation accuracy while preserving multimodal beliefs across objects with varying tactile discriminability."}
{"id": "2601.13635", "pdf": "https://arxiv.org/pdf/2601.13635", "abs": "https://arxiv.org/abs/2601.13635", "authors": ["Emin Akpinar", "Emir Aslandogan", "Burak Ahmet Ozden", "Haci Ilhan", "Erdogan Aydin"], "title": "Deep Learning-Enabled Signal Detection for MIMO-OTFS-Based 6G and Future Wireless Networks", "categories": ["eess.SP"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Orthogonal time frequency space (OTFS) modulation stands out as a promising waveform for sixth generation (6G) and beyond wireless communication systems, offering superior performance over conventional methods, particularly in high-mobility scenarios and dispersive channel conditions. Recent research has demonstrated that the reduced computational complexity of deep learning (DL)-based signal detection (SD) methods constitutes a compelling alternative to conventional techniques. In this study, low-complexity DL-based SD methods are proposed for a multiple-input multiple-output (MIMO)-OTFS system and examined under Nakagami-$m$ channel conditions. The symbols obtained from the receiver antennas are combined using maximum ratio combining (MRC) and detected with the help of a DL-based detector implemented with multi-layer perceptron (MLP), convolutional neural network (CNN), and residual network (ResNet). Complexity analysis reveals that the MLP architecture offers significantly lower computational complexity compared to CNN, ResNet, and classical methods such as maximum likelihood detection (MLD). Furthermore, numerical analyses have shown that the proposed DL-based detectors, despite their low complexity, achieve comparable bit error rate (BER) performance to that of a high-performance MLD under various system conditions."}
{"id": "2601.13252", "pdf": "https://arxiv.org/pdf/2601.13252", "abs": "https://arxiv.org/abs/2601.13252", "authors": ["Mahmud S. Zango", "Jianglin Lan"], "title": "Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints", "categories": ["cs.RO", "eess.SY"], "comment": "28 pages, 5 figures, 1 table. Review article", "summary": "Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging \"Edge AI\" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the \"Sim-to-Real\" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments."}
{"id": "2601.13680", "pdf": "https://arxiv.org/pdf/2601.13680", "abs": "https://arxiv.org/abs/2601.13680", "authors": ["Shama Siddiqui", "Anwar Ahmed Khan", "Nicola Marchetti"], "title": "TSN-IoT: A Two-Stage NOMA-Enabled Framework for Prioritized Traffic Handling in Dense IoT Networks", "categories": ["eess.SP"], "comment": null, "summary": "With the growing applications of the Internet of Things (IoT), a major challenge is to ensure continuous connectivity while providing prioritized access. In dense IoT scenarios, synchronization may be disrupted either by the movement of nodes away from base stations or by the unavailability of reliable Global Navigation Satellite System (GNSS) signals, which can be affected by physical obstructions, multipath fading, or environmental interference, such as such as walls, buildings, moving objects, or electromagnetic noise from surrounding devices. In such contexts, distributed synchronization through Non-Orthogonal Multiple Access (NOMA) offers a promising solution, as it enables simultaneous transmission to multiple users with different power levels, supporting efficient synchronization while minimizing the signaling overhead. Moreover, NOMA also plays a vital role for dynamic priority management in dense and heterogeneous IoT environments. In this article, we proposed a Two-Stage NOMA-Enabled Framework \"TSN-IoT\" that integrates the mechanisms of conventional Precision Time Protocol (PTP) based synchronization, distributed synchronization and data transmission. The framework is designed as a four-tier architecture that facilitates prioritized data delivery from sensor nodes to the central base station. We demonstrated the performance of \"TSN-IoT\" through a healthcare use case, where intermittent connectivity and varying data priority levels present key challenges for reliable communication. Synchronization speed and end-to-end delay were evaluated through a series of simulations implemented in Python. Results show that, compared to priority-based Orthogonal Frequency Division Multiple Access (OFDMA), TSN-IoT achieves significantly better performance by offering improved synchronization opportunities and enabling parallel transmissions over the same sub-carrier."}
{"id": "2601.13361", "pdf": "https://arxiv.org/pdf/2601.13361", "abs": "https://arxiv.org/abs/2601.13361", "authors": ["Pranay Meshram", "Charuvahan Adhivarahan", "Ehsan Tarkesh Esfahani", "Souma Chowdhury", "Chen Wang", "Karthik Dantu"], "title": "CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments", "categories": ["cs.RO"], "comment": "Under review for an IEEE conference", "summary": "Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration."}
{"id": "2601.13827", "pdf": "https://arxiv.org/pdf/2601.13827", "abs": "https://arxiv.org/abs/2601.13827", "authors": ["Yongqiang Zhang", "Qurrat-Ul-Ain Nadeem"], "title": "Channel Estimation in MIMO Systems Using Flow Matching Models", "categories": ["eess.SP"], "comment": "6 pages, 3 figures, accepted by IEEE International Conference on Communications (ICC) 2026", "summary": "Multiple-input multiple-output (MIMO) systems require efficient and accurate channel estimation with low pilot overhead to unlock their full potential for high spectral and energy efficiency. While deep generative models have emerged as a powerful foundation for the channel estimation task, the existing approaches using diffusion-based and score-based models suffer from high computational runtime due to their stochastic and many-step iterative sampling. In this paper, we introduce a flow matching-based channel estimator to overcome this limitation. The proposed channel estimator is based on a deep neural network trained to learn the velocity field of wireless channels, which we then integrate into a plug-and-play proximal gradient descent (PnP-PGD) framework. Simulation results reveal that our formulated approach consistently outperforms existing state-of-the-art (SOTA) generative model-based estimators, achieves up to 49 times faster inference at test time, and reduces up to 20 times peak graphics processing unit (GPU) memory usage. Our code and models are publicly available to support reproducible research."}
{"id": "2601.13389", "pdf": "https://arxiv.org/pdf/2601.13389", "abs": "https://arxiv.org/abs/2601.13389", "authors": ["Zhaohui Liang", "Chengyuan Ma", "Keke Long", "Xiaopeng Li"], "title": "Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections", "categories": ["cs.RO"], "comment": null, "summary": "Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability."}
{"id": "2601.13877", "pdf": "https://arxiv.org/pdf/2601.13877", "abs": "https://arxiv.org/abs/2601.13877", "authors": ["Ignacio Santamaria", "Mohammad Soleymani", "Eduard Jorswieck", "Jesus Gutierrez", "Carlos Beltran"], "title": "Riemannian optimization on the manifold of unitary and symmetric matrices with application to BD-RIS-assisted systems", "categories": ["eess.SP"], "comment": "5 pages, 2 figures", "summary": "In this paper, we rigorously characterize for the first time the manifold of unitary and symmetric matrices, deriving its tangent space and its geodesics. The resulting parameterization of the geodesics (through a real and symmetric matrix) allows us to derive a new Riemannian manifold optimization (MO) algorithm whose most remarkable feature is that it does not need to set any adaptation parameter. We apply the proposed MO algorithm to maximize the achievable rate in a multiple-input multiple-output (MIMO) system assisted by a beyond-diagonal reconfigurable intelligent surface (BD-RIS), illustrating the method's performance through simulations. The MO algorithm achieves a significant reduction in computational cost compared to previous alternatives based on Takagi decomposition, while retaining global convergence to a stationary point of the cost function."}
{"id": "2601.13451", "pdf": "https://arxiv.org/pdf/2601.13451", "abs": "https://arxiv.org/abs/2601.13451", "authors": ["Reza Ahmadvand", "Sarah Safura Sharif", "Yaser Mike Banad"], "title": "Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments."}
{"id": "2601.13934", "pdf": "https://arxiv.org/pdf/2601.13934", "abs": "https://arxiv.org/abs/2601.13934", "authors": ["Phuong Nam Tran", "Nhan Thanh Nguyen", "Hien Quoc Ngo", "Markku Juntti"], "title": "Deep Reinforcement Learning-Based Dynamic Resource Allocation in Cell-Free Massive MIMO", "categories": ["eess.SP"], "comment": null, "summary": "In this paper, we consider power allocation and antenna activation of cell-free massive multiple-input multiple-output (CFmMIMO) systems. We first derive closed-form expressions for the system spectral efficiency (SE) and energy efficiency (EE) as functions of the power allocation coefficients and the number of active antennas at the access points (APs). Then, we aim to enhance the EE through jointly optimizing antenna activation and power control. This task leads to a non-convex and mixed-integer design problem with high-dimensional design variables. To address this, we propose a novel DRL-based framework, in which the agent learns to map large-scale fading coefficients to AP activation ratio, antenna coefficient, and power coefficient. These coefficients are then employed to determine the number of active antennas per AP and the power factors assigned to users based on closed-form expressions. By optimizing these parameters instead of directly controlling antenna selection and power allocation, the proposed method transforms the intractable optimization into a low-dimensional learning task. Our extensive simulations demonstrate the efficiency and scalability of the proposed scheme. Specifically, in a CFmMIMO system with 40 APs and 20 users, it achieves a 50% EE improvement and 3350 times run time reduction compared to the conventional sequential convex approximation method."}
{"id": "2601.13529", "pdf": "https://arxiv.org/pdf/2601.13529", "abs": "https://arxiv.org/abs/2601.13529", "authors": ["Pejman Kheradmand", "Kent K. Yamamoto", "Emma Webster", "Keith Sowards", "Gianna Hatheway", "Katharine L. Jackson", "Sabino Zani", "Julie A. Raffi", "Diandra N. Ayala-Peacock", "Scott R. Silva", "Joanna Deaton Bertram", "Yash Chitalia"], "title": "The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study", "categories": ["cs.RO"], "comment": null, "summary": "Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets."}
{"id": "2601.13962", "pdf": "https://arxiv.org/pdf/2601.13962", "abs": "https://arxiv.org/abs/2601.13962", "authors": ["Eike Osmers", "Dorothea Kolossa"], "title": "Optimal Calibration of the endpoint-corrected Hilbert Transform", "categories": ["eess.SP", "eess.SY", "q-bio.NC", "stat.ME"], "comment": null, "summary": "Accurate, low-latency estimates of the instantaneous phase of oscillations are essential for closed-loop sensing and actuation, including (but not limited to) phase-locked neurostimulation and other real-time applications. The endpoint-corrected Hilbert transform (ecHT) reduces boundary artefacts of the Hilbert transform by applying a causal narrow-band filter to the analytic spectrum. This improves the phase estimate at the most recent sample. Despite its widespread empirical use, the systematic endpoint distortions of ecHT have lacked a principled, closed-form analysis. In this study, we derive the ecHT endpoint operator analytically and demonstrate that its output can be decomposed into a desired positive-frequency term (a deterministic complex gain that induces a calibratable amplitude/phase bias) and a residual leakage term setting an irreducible variance floor. This yields (i) an explicit characterisation and bounds for endpoint phase/amplitude error, (ii) a mean-squared-error-optimal scalar calibration (c-ecHT), and (iii) practical design rules relating window length, bandwidth/order, and centre-frequency mismatch to residual bias via an endpoint group delay. The resulting calibrated ecHT achieves near-zero mean phase error and remains computationally compatible with real-time pipelines. Code and analyses are provided at https://github.com/eosmers/cecHT."}
{"id": "2601.13556", "pdf": "https://arxiv.org/pdf/2601.13556", "abs": "https://arxiv.org/abs/2601.13556", "authors": ["Jianan Wang", "Siyang Zhang", "Bin Li", "Juan Chen", "Jingtao Qi", "Zhuo Zhang", "Chen Qian"], "title": "LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI", "categories": ["cs.RO"], "comment": "19 pages, 15 figures, 6 tables", "summary": "Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%."}
{"id": "2601.13997", "pdf": "https://arxiv.org/pdf/2601.13997", "abs": "https://arxiv.org/abs/2601.13997", "authors": ["Xuehan Wang", "Jinhong Yuan", "Jintao Wang", "Kehan Huang"], "title": "Achieving Full Multipath Diversity by Random Constellation Rotation: a Theoretical Perspective", "categories": ["eess.SP", "cs.IT"], "comment": "10 pages, 5 figures. This paper has been accepted for publication in IEEE TSP", "summary": "Diversity is an essential concept associated with communication reliability in multipath channels since it determines the slope of bit error rate performance in the medium to high signal-to-noise ratio regions. However, most of the existing analytical frameworks were developed for specific modulation schemes while the efficient validation of full multipath diversity for general modulation schemes remains an open problem. To fill this research gap, we propose to utilize random constellation rotation to ease the conditions for full-diversity modulation designs. For linearly precoded cyclic-prefix orthogonal frequency division multiplexing (OFDM) systems, we prove that maximum multipath diversity can be attained as long as the spread matrix does not have zero entries, which is a sufficient but easily satisfied condition. Furthermore, we derive the sufficient and necessary condition for general modulation schemes, whose verification can be divided into validation tasks for each column of the modulation matrix. Based on the proposed conditions, maximum diversity order can be attained with the probability of 1 by enabling a randomly generated rotation pattern for both time and doubly dispersive channels. The theoretical analysis in this paper also demonstrates that the diversity evaluation can be concentrated on the pairwise error probability when the number of error symbols is one, which reduces the complexity of diversity-driven design and performance analysis for novel modulation schemes significantly in both time and doubly dispersive channels. Finally, numerical results for various modulation schemes confirm that the theoretical analysis holds in both time and doubly dispersive channels. Furthermore, when employing practical detectors, the random constellation rotation technique consistently enhance the transmission reliability for both coded and uncoded systems."}
{"id": "2601.13574", "pdf": "https://arxiv.org/pdf/2601.13574", "abs": "https://arxiv.org/abs/2601.13574", "authors": ["Guanyu Xu", "Jiaqi Wang", "Dezhong Tong", "Xiaonan Huang"], "title": "Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction", "categories": ["cs.RO"], "comment": "13 pages, 7 figures", "summary": "Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems."}
{"id": "2601.14080", "pdf": "https://arxiv.org/pdf/2601.14080", "abs": "https://arxiv.org/abs/2601.14080", "authors": ["Alexander Ihlow", "Marius Schmidt", "Carsten Andrich", "Reiner S. Thomä"], "title": "Background Subtraction with Drift Correction for Bistatic Radar Reflectivity Measurements", "categories": ["eess.SP"], "comment": "20th European Conference on Antennas and Propagation (EuCAP 2026)", "summary": "Fundamental research on bistatic radar reflectivity is highly relevant, e.g., to the upcoming mobile communication standard 6G, which includes integrated sensing and communication (ISAC). We introduce a model for correcting instrumentation drift during bistatic radar measurements in anechoic chambers. Usually, background subtraction is applied with the goal to yield the target reflection signal as best as possible while coherently subtracting all signals which were present in both the foreground and background measurement. However, even slight incoherences between the foreground and background measurement process deteriorate the result. We analyze these effects in real measurements in the frequency range 2-18 GHz, taken with the Bistatic Radar (BIRA) measurement facility at TU Ilmenau. Applying our proposed drift correction model, we demonstrate up to 40 dB improvement for the removal of direct line-of-sight antenna crosstalk over the state of the art."}
{"id": "2601.13639", "pdf": "https://arxiv.org/pdf/2601.13639", "abs": "https://arxiv.org/abs/2601.13639", "authors": ["Deyun Qin", "Zezhi Liu", "Hanqian Luo", "Xiao Liang", "Yongchun Fang"], "title": "A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint", "categories": ["cs.RO"], "comment": null, "summary": "Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework."}
{"id": "2601.14220", "pdf": "https://arxiv.org/pdf/2601.14220", "abs": "https://arxiv.org/abs/2601.14220", "authors": ["Wenyi Yan", "Zeyuan Li", "Lu Gan", "Honqing Liu", "Guoquan Li"], "title": "Bit-Efficient Quantisation for Two-Channel Modulo-Sampling Systems", "categories": ["eess.SP"], "comment": null, "summary": "Two-channel modulo analog-to-digital converters (ADCs) enable high-dynamic-range signal sensing at the Nyquist rate per channel, but existing designs quantise both channel outputs independently, incurring redundant bitrate costs. This paper proposes a bit-efficient quantisation scheme that exploits the integer-valued structure of inter-channel differences, transmitting one quantised channel output together with a compact difference index. We prove that this approach requires only 1-2 bits per signal sample overhead relative to conventional ADCs, despite operating with a much smaller per-channel dynamic range. Simulations confirm the theoretical error bounds and bitrate analysis, while hardware experiments demonstrate substantial bitrate savings compared with existing modulo sampling schemes, while maintaining comparable reconstruction accuracy. These results highlight a practical path towards high-resolution, bandwidth-efficient modulo ADCs for bitrate-constrained systems."}
{"id": "2601.13657", "pdf": "https://arxiv.org/pdf/2601.13657", "abs": "https://arxiv.org/abs/2601.13657", "authors": ["Myong-Yol Choi", "Hankyoul Ko", "Hanse Cho", "Changseung Kim", "Seunghwan Kim", "Jaemin Seo", "Hyondong Oh"], "title": "Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization."}
{"id": "2601.14233", "pdf": "https://arxiv.org/pdf/2601.14233", "abs": "https://arxiv.org/abs/2601.14233", "authors": ["Yekta Demirci", "Guillaume Mantelet", "Stephane Martel", "Jean-Francois Frigon", "Gunes Karabulut Kurt"], "title": "Burst Aware Forecasting of User Traffic Demand in LEO Satellite Networks", "categories": ["eess.SP"], "comment": "Accepted by IEEE International Conference on Communications (ICC) 2026", "summary": "In Low Earth Orbit (LEO) satellite networks, Beam Hopping (BH) technology enables the efficient utilization of limited radio resources by adapting to varying user demands and link conditions. Effective BH planning requires prior knowledge of upcoming traffic at the time of scheduling, making forecasting an important sub-task. Forecasting becomes particularly critical under heavy load conditions where an unexpected demand burst combined with link degradation may cause buffer overflows and packet loss. To address this challenge, we propose a burst aware forecasting solution. This challenge may arise in a wide range of wireless networks; therefore, the proposed solution is broadly applicable to settings characterized by bursty traffic patterns where accurate demand forecasting is essential. Our approach introduces three key enhancements to a transformer architecture: (i) a distance from the last burst embedding to capture burst proximity, (ii) two additional linear layers in the decoder to forecast both upcoming bursts and their relative impact, and (iii) use of an asymmetric cost function during model training to better capture burst dynamics. Empirical evaluations in an Earth-fixed cell under high-traffic demand scenario demonstrate that the proposed model reduces prediction error by up to 94% at a one-step horizon and maintains the ability to accurately capture bursts even near the end of longer prediction horizons following Mean Square Error (MSE) metric."}
{"id": "2601.13732", "pdf": "https://arxiv.org/pdf/2601.13732", "abs": "https://arxiv.org/abs/2601.13732", "authors": ["Andreas Wiedholz", "Rafael Paintner", "Julian Gleißner", "Alwin Hoffmann", "Tobias Huber"], "title": "SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation", "categories": ["cs.RO"], "comment": null, "summary": "The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison."}
{"id": "2601.14244", "pdf": "https://arxiv.org/pdf/2601.14244", "abs": "https://arxiv.org/abs/2601.14244", "authors": ["Qing Zhang", "Adham Sakhnini", "Robbert Beerten", "Haoqiu Xiong", "Zhuangzhuang Cui", "Yang Miao", "Sofie Pollin"], "title": "Robust Localization in OFDM-Based Massive MIMO through Phase Offset Calibration", "categories": ["eess.SP"], "comment": "Accepted to IEEE International Symposium on Joint Communications & Sensing (JC&S) 2026; recipient of the Best Student Paper Award", "summary": "Accurate localization in Orthogonal Frequency Division Multiplexing (OFDM)-based massive Multiple-Input Multiple-Output (MIMO) systems depends critically on phase coherence across subcarriers and antennas. However, practical systems suffer from frequency-dependent and (spatial) antenna-dependent phase offsets, degrading localization accuracy. This paper analytically studies the impact of phase incoherence on localization performance under a static User Equipment (UE) and Line-of-Sight (LoS) scenario. We use two complementary tools. First, we derive the Cramér-Rao Lower Bound (CRLB) to quantify the theoretical limits under phase offsets. Then, we develop a Spatial Ambiguity Function (SAF)-based model to characterize ambiguity patterns. Simulation results reveal that spatial phase offsets severely degrade localization performance, while frequency phase offsets have a minor effect in the considered system configuration. To address this, we propose a robust Channel State Information (CSI) calibration framework and validate it using real-world measurements from a practical massive MIMO testbed. The experimental results confirm that the proposed calibration framework significantly improves the localization Root Mean Squared Error (RMSE) from 5 m to 1.2 cm, aligning well with the theoretical predictions."}
{"id": "2601.13737", "pdf": "https://arxiv.org/pdf/2601.13737", "abs": "https://arxiv.org/abs/2601.13737", "authors": ["Joon Lee", "Jeongyoon Han", "Doyoung Kim", "Seokhwan Jeong"], "title": "RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure", "categories": ["cs.RO", "eess.SY"], "comment": "Soft Robotics", "summary": "This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications."}
{"id": "2601.11694", "pdf": "https://arxiv.org/pdf/2601.11694", "abs": "https://arxiv.org/abs/2601.11694", "authors": ["Xinjue Wang", "Xiuheng Wang", "Esa Ollila", "Sergiy A. Vorobyov"], "title": "Anisotropic Tensor Deconvolution of Hyperspectral Images", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "comment": "To appear in ICASSP 2026", "summary": "Hyperspectral image (HSI) deconvolution is a challenging ill-posed inverse problem, made difficult by the data's high dimensionality.We propose a parameter-parsimonious framework based on a low-rank Canonical Polyadic Decomposition (CPD) of the entire latent HSI $\\mathbf{\\mathcal{X}} \\in \\mathbb{R}^{P\\times Q \\times N}$.This approach recasts the problem from recovering a large-scale image with $PQN$ variables to estimating the CPD factors with $(P+Q+N)R$ variables.This model also enables a structure-aware, anisotropic Total Variation (TV) regularization applied only to the spatial factors, preserving the smooth spectral signatures.An efficient algorithm based on the Proximal Alternating Linearized Minimization (PALM) framework is developed to solve the resulting non-convex optimization problem.Experiments confirm the model's efficiency, showing a numerous parameter reduction of over two orders of magnitude and a compelling trade-off between model compactness and reconstruction accuracy."}
{"id": "2601.13777", "pdf": "https://arxiv.org/pdf/2601.13777", "abs": "https://arxiv.org/abs/2601.13777", "authors": ["Zvi Chapnik", "Yizhar Or", "Shai Revzen"], "title": "Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System", "categories": ["cs.RO"], "comment": null, "summary": "Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available."}
{"id": "2601.11768", "pdf": "https://arxiv.org/pdf/2601.11768", "abs": "https://arxiv.org/abs/2601.11768", "authors": ["Venkat Suprabath Bitra", "Homayoon Beigi"], "title": "Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "eess.SP"], "comment": "12 pages, 6 figures, 3 tables, and an appendix, Accepted for publication at ICPRAM 2026 in Marbella, Spain, on March 2, 2026", "summary": "Reliable fundamental frequency (F 0) and voicing estimation is essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. We propose a lightweight, fully self-supervised framework for joint F 0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, we introduce an EM-style iterative reweighting scheme that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, our method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization."}
{"id": "2601.13801", "pdf": "https://arxiv.org/pdf/2601.13801", "abs": "https://arxiv.org/abs/2601.13801", "authors": ["Yuhua Jin", "Nikita Kuzmin", "Georgii Demianchuk", "Mariya Lezina", "Fawad Mehboob", "Issatay Tokmurziyev", "Miguel Altamirano Cabrera", "Muhammad Ahsan Mustafa", "Dzmitry Tsetserukou"], "title": "HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction", "categories": ["cs.RO"], "comment": "This paper has been accepted for publication at LBR HRI 2026 conference", "summary": "Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction."}
{"id": "2601.11929", "pdf": "https://arxiv.org/pdf/2601.11929", "abs": "https://arxiv.org/abs/2601.11929", "authors": ["Sebastian Ratto", "Ahmed N. Sayed", "Neda Rojhani", "Arien P. Sligar", "Jose R. Rosas-Bustos", "Saasha Joshi", "Luke C. G. Govia", "Omar M. Ramahi", "George Shaker"], "title": "Indoor Occupancy Classification using a Compact Hybrid Quantum-Classical Model Enabled by a Physics-Informed Radar Digital Twin", "categories": ["quant-ph", "eess.SP"], "comment": "22 pages, 18 figures", "summary": "Indoor occupancy classification enables privacy-preserving monitoring in settings such as remote elder care, where presence information helps triage alarms without cameras or wearables. Radar suits this role by sensing motion through occlusions and in darkness. Modern deep-learning pipelines are the standard for interpreting radar returns effectively; however, they are often parameter-heavy and sensitive at low signal-to-noise ratios (SNR), motivating compact alternatives like Hybrid Quantum Neural Networks (HQNNs). A two-qubit HQNN is benchmarked against convolutional neural networks (CNNs) using a physics-informed 60GHz digital twin and real radar measurements under matched training protocols. In clean conditions, the HQNN achieves high accuracy (99.7% synthetic; 97.0% real) with up to 170x fewer parameters (0.066M). Its parameter efficiency is shown to be structural, as an ablation of the parameterized quantum circuit (PQC) causes sharp performance drops on real data (to 68.5% and 31.5% for the control heads). A domain-dependent sensitivity emerges under additive-noise evaluation, where the HQNN begins recovery earlier in synthetic data while CNNs recover more steeply and peak higher on real measurements. In label-fraction ablations, CNNs prove more sample-efficient on real Range-Doppler Maps (RDMs), with the performance gap being most pronounced (at 50% labels, BA 0.89-0.99 vs. HQNN 0.75). On synthetic data, this gap narrows significantly, largely vanishing by the 50% label mark. Overall, the HQNN's value lies in parameter efficiency and a compact inductive bias that shapes its distinct sensitivity profile; this work establishes a rigorous baseline for hybrid quantum models in privacy-preserving radar occupancy sensing."}
{"id": "2601.13809", "pdf": "https://arxiv.org/pdf/2601.13809", "abs": "https://arxiv.org/abs/2601.13809", "authors": ["Fawad Mehboob", "Monijesu James", "Amir Habel", "Jeffrin Sam", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "DroneVLA: VLA based Aerial Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations."}
{"id": "2601.12662", "pdf": "https://arxiv.org/pdf/2601.12662", "abs": "https://arxiv.org/abs/2601.12662", "authors": ["Xingran Chen", "Navid NaderiAlizadeh", "Alejandro Ribeiro", "Shirin Saeedi Bidokhti"], "title": "Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity."}
{"id": "2601.13813", "pdf": "https://arxiv.org/pdf/2601.13813", "abs": "https://arxiv.org/abs/2601.13813", "authors": ["Timofei Kozlov", "Artem Trandofilov", "Georgii Gazaryan", "Issatay Tokmurziyev", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "GuideTouch: An Obstacle Avoidance Device for Visually Impaired", "categories": ["cs.RO", "cs.HC"], "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation."}
{"id": "2601.12939", "pdf": "https://arxiv.org/pdf/2601.12939", "abs": "https://arxiv.org/abs/2601.12939", "authors": ["Kaleem Arshid", "Ali Krayani", "Lucio Marcenaro", "David Martin Gomez", "Carlo Regazzoni"], "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design", "categories": ["cs.RO", "cs.AI", "eess.SP"], "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'", "summary": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control."}
{"id": "2601.13945", "pdf": "https://arxiv.org/pdf/2601.13945", "abs": "https://arxiv.org/abs/2601.13945", "authors": ["Yixuan Deng", "Tongrun Wu", "Donghao Wu", "Zeyu Wei", "Jiayuan Wang", "Zhenglong Sun", "Yuqing Tang", "Xiaoqiang Ji"], "title": "Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems."}
{"id": "2601.13174", "pdf": "https://arxiv.org/pdf/2601.13174", "abs": "https://arxiv.org/abs/2601.13174", "authors": ["Maryam Salamatmoghadasi", "Amir Mehrabian", "Halim Yanikomeroglu", "Georges Kaddoum"], "title": "QoS-Aware Energy Optimization via Cell Switching in Heterogeneous Networks", "categories": ["eess.SY", "eess.SP"], "comment": null, "summary": "The growing demand for mobile data services in dense urban areas has intensified the need for energy-efficient radio access networks (RANs) in future 6G systems. In this context, one promising strategy is cell switching (CS), which dynamically deactivates underutilized small base stations (SBSs) to reduce power consumption. However, while previous research explored CS primarily based on traffic load, ensuring user quality of service (QoS) under realistic channel conditions remains a challenge. In this paper, we propose a novel optimization-driven CS framework that jointly minimizes network power consumption and guarantees user QoS by enforcing a minimum received power threshold as part of offloading decisions. In contrast to prior load-based or learning-based approaches, our method explicitly integrates channel-aware information into the CS process, thus ensuring reliable service quality for offloaded users. Furthermore, flexibility of the proposed framework enables operators to adapt system behavior between energy-saving and QoS-preserving modes by tuning a single design parameter. Simulation results demonstrate that the proposed approach achieves up to 30% power savings as compared to baseline methods while fully maintaining QoS under diverse network conditions. Scalability and robustness of the proposed method in realistic heterogeneous networks (HetNets) further highlight its potential as a practical solution for sustainable 6G deployments."}
{"id": "2601.13979", "pdf": "https://arxiv.org/pdf/2601.13979", "abs": "https://arxiv.org/abs/2601.13979", "authors": ["Raffaele Mazza", "Ciro Natale", "Pietro Falco"], "title": "Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects."}
{"id": "2601.13214", "pdf": "https://arxiv.org/pdf/2601.13214", "abs": "https://arxiv.org/abs/2601.13214", "authors": ["Zheyu Wu", "Junjie Ma", "Ya-Feng Liu", "Bruno Clerckx"], "title": "An AMP-Based Asymptotic Analysis For Nonlinear One-Bit Precoding", "categories": ["cs.IT", "eess.SP"], "comment": "5 pages, 2 figures, accepted by ICASSP2026", "summary": "This paper focuses on the asymptotic analysis of a class of nonlinear one-bit precoding schemes under Rayleigh fading channels. The considered scheme employs a convex-relaxation-then-quantization (CRQ) approach to the well-known minimum mean square error (MMSE) model, which includes the classical one-bit precoder SQUID as a special case. To analyze its asymptotic behavior, we develop a novel analytical framework based on approximate message passing (AMP). We show that, the statistical properties of the considered scheme can be asymptotically characterized by a scalar ``signal plus Gaussian noise'' model. Based on this, we further derive a closed-form expression for the symbol error probability (SEP) in the large-system limit, which quantitatively characterizes the impact of both system and model parameters on SEP performance. Simulation results validate our analysis and also demonstrate that performance gains over SQUID can be achieved by appropriately tuning the parameters involved in the considered model."}
{"id": "2601.14000", "pdf": "https://arxiv.org/pdf/2601.14000", "abs": "https://arxiv.org/abs/2601.14000", "authors": ["Junwoo Chang", "Joseph Park", "Roberto Horowitz", "Jongmin Lee", "Jongeun Choi"], "title": "Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior", "categories": ["cs.RO", "cs.LG"], "comment": "14 pages, 6 figures", "summary": "Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline."}
{"id": "2601.13320", "pdf": "https://arxiv.org/pdf/2601.13320", "abs": "https://arxiv.org/abs/2601.13320", "authors": ["Yasin Demir", "Nur Hüseyin Kaplan", "Sefa Kucuk", "Nagihan Severoglu"], "title": "RetinexGuI: Retinex-Guided Iterative Illumination Estimation Method for Low Light Images", "categories": ["eess.IV", "eess.SP"], "comment": null, "summary": "In recent years, there has been a growing interest in low-light image enhancement (LLIE) due to its importance for critical downstream tasks. Current Retinex-based methods and learning-based approaches have shown significant LLIE performance. However, computational complexity and dependencies on large training datasets often limit their applicability in real-time applications. We introduce RetinexGuI, a novel and effective Retinex-guided LLIE framework to overcome these limitations. The proposed method first separates the input image into illumination and reflection layers, and iteratively refines the illumination while keeping the reflectance component unchanged. With its simplified formulation and computational complexity of $\\mathcal{O}(N)$, our RetinexGuI demonstrates impressive enhancement performance across three public datasets, indicating strong potential for large-scale applications. Furthermore, it opens promising directions for theoretical analysis and integration with deep learning approaches. The source code will be made publicly available at https://github.com/etuspars/RetinexGuI once the paper is accepted."}
{"id": "2601.14091", "pdf": "https://arxiv.org/pdf/2601.14091", "abs": "https://arxiv.org/abs/2601.14091", "authors": ["Hossein Naderi", "Alireza Shojaei", "Lifu Huang", "Philip Agee", "Kereshmeh Afsari", "Abiola Akanmu"], "title": "Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction."}
{"id": "2601.13386", "pdf": "https://arxiv.org/pdf/2601.13386", "abs": "https://arxiv.org/abs/2601.13386", "authors": ["Changxu Zhang", "Zhaoze Wang", "Tai Fei", "Christopher Grimm", "Yi Jin", "Claas Tebruegge", "Ernst Warsitz", "Markus Gardill"], "title": "Leveraging Transformer Decoder for Automotive Radar Object Detection", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines."}
{"id": "2601.14104", "pdf": "https://arxiv.org/pdf/2601.14104", "abs": "https://arxiv.org/abs/2601.14104", "authors": ["Tairan Huang", "Qingqing Ye", "Yulin Jin", "Jiawei Lian", "Yi Wang", "Haibo Hu"], "title": "Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material."}
{"id": "2601.13436", "pdf": "https://arxiv.org/pdf/2601.13436", "abs": "https://arxiv.org/abs/2601.13436", "authors": ["Szabolcs Szentpéteri", "Balázs Csanád Csáji"], "title": "Distribution-Free Confidence Ellipsoids for Ridge Regression with PAC Bounds", "categories": ["stat.ML", "cs.LG", "eess.SP", "eess.SY", "math.ST"], "comment": null, "summary": "Linearly parametrized models are widely used in control and signal processing, with the least-squares (LS) estimate being the archetypical solution. When the input is insufficiently exciting, the LS problem may be unsolvable or numerically unstable. This issue can be resolved through regularization, typically with ridge regression. Although regularized estimators reduce the variance error, it remains important to quantify their estimation uncertainty. A possible approach for linear regression is to construct confidence ellipsoids with the Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm. The SPS EOA builds non-asymptotic confidence ellipsoids under the assumption that the noises are independent and symmetric about zero. This paper introduces an extension of the SPS EOA algorithm to ridge regression, and derives probably approximately correct (PAC) upper bounds for the resulting region sizes. Compared with previous analyses, our result explicitly show how the regularization parameter affects the region sizes, and provide tighter bounds under weaker excitation assumptions. Finally, the practical effect of regularization is also demonstrated via simulation experiments."}
{"id": "2601.14128", "pdf": "https://arxiv.org/pdf/2601.14128", "abs": "https://arxiv.org/abs/2601.14128", "authors": ["Shoujie Li", "Changqing Guo", "Junhao Gong", "Chenxin Liang", "Wenhua Ding", "Wenbo Ding"], "title": "SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media", "categories": ["cs.RO"], "comment": "Accepted by IEEE Transactions on Robotics", "summary": "Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance."}
{"id": "2601.13629", "pdf": "https://arxiv.org/pdf/2601.13629", "abs": "https://arxiv.org/abs/2601.13629", "authors": ["Ziqian Wang", "Xianjun Xia", "Chuanzeng Huang", "Lei Xie"], "title": "S$^2$Voice: Style-Aware Autoregressive Modeling with Enhanced Conditioning for Singing Style Conversion", "categories": ["eess.AS", "eess.SP"], "comment": "accepted to ICASSP 2026", "summary": "We present S$^2$Voice, the winning system of the Singing Voice Conversion Challenge (SVCC) 2025 for both the in-domain and zero-shot singing style conversion tracks. Built on the strong two-stage Vevo baseline, S$^2$Voice advances style control and robustness through several contributions. First, we integrate style embeddings into the autoregressive large language model (AR LLM) via a FiLM-style layer-norm conditioning and a style-aware cross-attention for enhanced fine-grained style modeling. Second, we introduce a global speaker embedding into the flow-matching transformer to improve timbre similarity. Third, we curate a large, high-quality singing corpus via an automated pipeline for web harvesting, vocal separation, and transcript refinement. Finally, we employ a multi-stage training strategy combining supervised fine-tuning (SFT) and direct preference optimization (DPO). Subjective listening tests confirm our system's superior performance: leading in style similarity and singer similarity for Task 1, and across naturalness, style similarity, and singer similarity for Task 2. Ablation studies demonstrate the effectiveness of our contributions in enhancing style fidelity, timbre preservation, and generalization. Audio samples are available~\\footnote{https://honee-w.github.io/SVC-Challenge-Demo/}."}
{"id": "2601.14133", "pdf": "https://arxiv.org/pdf/2601.14133", "abs": "https://arxiv.org/abs/2601.14133", "authors": ["Bin Yu", "Shijie Lian", "Xiaopeng Lin", "Yuliang Wei", "Zhaolong Shen", "Changti Wu", "Yuzhuo Miao", "Xinming Wang", "Bailing Wang", "Cong Huang", "Kai Chen"], "title": "TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers", "categories": ["cs.RO", "cs.CV"], "comment": "GitHub: https://github.com/ZGC-EmbodyAI/TwinBrainVLA", "summary": "Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to \"catastrophic forgetting\" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen \"Left Brain\", which retains robust general visual reasoning, with a trainable \"Right Brain\", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity."}
{"id": "2601.13641", "pdf": "https://arxiv.org/pdf/2601.13641", "abs": "https://arxiv.org/abs/2601.13641", "authors": ["Shuvayan Banerjee", "Radhendushka Srivastava", "James Saunderson", "Ajit Rajwade"], "title": "Correction of Pooling Matrix Mis-specifications in Compressed Sensing Based Group Testing", "categories": ["stat.AP", "eess.SP"], "comment": null, "summary": "Compressed sensing, which involves the reconstruction of sparse signals from an under-determined linear system, has been recently used to solve problems in group testing. In a public health context, group testing aims to determine the health status values of p subjects from n<<p pooled tests, where a pool is defined as a mixture of small, equal-volume portions of the samples of a subset of subjects. This approach saves on the number of tests administered in pandemics or other resource-constrained scenarios. In practical group testing in time-constrained situations, a technician can inadvertently make a small number of errors during pool preparation, which leads to errors in the pooling matrix, which we term `model mismatch errors' (MMEs). This poses difficulties while determining health status values of the participating subjects from the results on n<<p pooled tests. In this paper, we present an algorithm to correct the MMEs in the pooled tests directly from the pooled results and the available (inaccurate) pooling matrix. Our approach then reconstructs the signal vector from the corrected pooling matrix, in order to determine the health status of the subjects. We further provide theoretical guarantees for the correction of the MMEs and the reconstruction error from the corrected pooling matrix. We also provide several supporting numerical results."}
{"id": "2601.11543", "pdf": "https://arxiv.org/pdf/2601.11543", "abs": "https://arxiv.org/abs/2601.11543", "authors": ["Berfin Ataman", "Rodrigo Gallardo", "Qilmeg Doudatcz"], "title": "Affective Translation: Material and Virtual Embodiments of Kinetic Textile Robots", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "This study presents a comparative framework for evaluating emotional engagement with textile soft robots and their augmented-reality (AR) counterparts. Four robotic sculptures were developed, each embodying nature-inspired dynamic behaviors such as breathing and gradual deformation. Using a between-subjects design, two independent groups, one experiencing the physical installations and one engaging with their virtual (AR) twins, follow identical protocols and complete the same self-assessment survey on affective and perceptual responses. This approach minimizes carryover and novelty effects while enabling a direct comparison of sensations such as calmness, curiosity, and discomfort across modalities. The analysis explores how motion, form, and material behavior shape emotional interpretation in physical versus digital contexts, informing the design of hybrid systems that evoke meaningful, emotionally legible interactions between humans, robots, and digital twins."}
{"id": "2601.13838", "pdf": "https://arxiv.org/pdf/2601.13838", "abs": "https://arxiv.org/abs/2601.13838", "authors": ["Jiunn-Tsair Chen"], "title": "A Predictive and Preventive Digital Twin Framework for Indoor Wireless Networks", "categories": ["cs.NI", "eess.SP"], "comment": "44 pages, 21 figures", "summary": "Wi-Fi networks increasingly suffer from performance degradation caused by contention-based channel access, dense deployments, and largely self-managed operation among mutually interfering access points (APs). In this paper, we propose a Digital Twin (DT) framework that captures the essential spatial and temporal characteristics of wireless channels and traffic patterns, enabling the prediction of likely future network scenarios while respecting physical constraints. Leveraging this predictive capability, we introduce two analytically derived performance upper bounds-one based on Shannon capacity and the other on latency behavior under CSMA-CA (Carrier Sense Multiple Access with Collision Avoidance)-that can be evaluated efficiently without time-consuming network simulations. By applying importance sampling to DT-generated scenarios, potentially risky network conditions can be identified within large stochastic scenario spaces. These same performance bounds are then used to proactively guide a gradient-based search for improved network configurations, with the objective of avoiding imminent performance degradation rather than pursuing globally optimal but fragile solutions. Simulation results demonstrate that the proposed approach can successfully predict time-dependent network congestion and mitigate it in advance, highlighting its potential for predictive and preventive Wi-Fi network management."}
{"id": "2601.11617", "pdf": "https://arxiv.org/pdf/2601.11617", "abs": "https://arxiv.org/abs/2601.11617", "authors": ["Xu Wang", "Boyao Han", "Xiaojun Chen", "Ying Liu", "Ruihui Li"], "title": "PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM", "categories": ["cs.CV", "cs.GR", "cs.RO"], "comment": null, "summary": "Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics."}
{"id": "2601.13849", "pdf": "https://arxiv.org/pdf/2601.13849", "abs": "https://arxiv.org/abs/2601.13849", "authors": ["Ziyi Yang", "Li Rao", "Zhengding Luo", "Dongyuan Shi", "Qirui Huang", "Woon-Seng Gan"], "title": "Co-Initialization of Control Filter and Secondary Path via Meta-Learning for Active Noise Control", "categories": ["eess.AS", "cs.LG", "eess.SP"], "comment": null, "summary": "Active noise control (ANC) must adapt quickly when the acoustic environment changes, yet early performance is largely dictated by initialization. We address this with a Model-Agnostic Meta-Learning (MAML) co-initialization that jointly sets the control filter and the secondary-path model for FxLMS-based ANC while keeping the runtime algorithm unchanged. The initializer is pre-trained on a small set of measured paths using short two-phase inner loops that mimic identification followed by residual-noise reduction, and is applied by simply setting the learned initial coefficients. In an online secondary path modeling FxLMS testbed, it yields lower early-stage error, shorter time-to-target, reduced auxiliary-noise energy, and faster recovery after path changes than a baseline without re-initialization. The method provides a simple fast start for feedforward ANC under environment changes, requiring a small set of paths to pre-train."}
{"id": "2601.11665", "pdf": "https://arxiv.org/pdf/2601.11665", "abs": "https://arxiv.org/abs/2601.11665", "authors": ["Amir Farzin Nikkhah", "Dong Chen", "Bradford Campbell", "Somayeh Asadi", "Arsalan Heydarian"], "title": "UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted for publication at the International Conference on Construction Engineering and Management (I3CE 2025)", "summary": "Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections."}
{"id": "2601.13926", "pdf": "https://arxiv.org/pdf/2601.13926", "abs": "https://arxiv.org/abs/2601.13926", "authors": ["Peter Golenderov", "Yaroslav Matushenko", "Anastasia Tushina", "Michal Barodkin"], "title": "SCG With Your Phone: Diagnosis of Rhythmic Spectrum Disorders in Field Conditions", "categories": ["q-bio.QM", "cs.LG", "eess.SP"], "comment": null, "summary": "Aortic valve opening (AO) events are crucial for detecting frequency and rhythm disorders, especially in real-world settings where seismocardiography (SCG) signals collected via consumer smartphones are subject to noise, motion artifacts, and variability caused by device heterogeneity. In this work, we present a robust deep-learning framework for SCG segmentation and rhythm analysis using accelerometer recordings obtained with consumer smartphones. We develop an enhanced U-Net v3 architecture that integrates multi-scale convolutions, residual connections, and attention gates, enabling reliable segmentation of noisy SCG signals. A dedicated post-processing pipeline converts probability masks into precise AO timestamps, whereas a novel adaptive 3D-to-1D projection method ensures robustness to arbitrary smartphone orientation. Experimental results demonstrate that the proposed method achieves consistently high accuracy and robustness across various device types and unsupervised data-collection conditions. Our approach enables practical, low-cost, and automated cardiac-rhythm monitoring using everyday mobile devices, paving the way for scalable, field-deployable cardiovascular assessment and future multimodal diagnostic systems."}
{"id": "2601.11794", "pdf": "https://arxiv.org/pdf/2601.11794", "abs": "https://arxiv.org/abs/2601.11794", "authors": ["Abdelrahman Ramadan", "Zahra Dorbeigi Namaghi", "Emily Taylor", "Lucas Edwards", "Xan Giuliani", "David S. McLagan", "Sidney Givigi", "Melissa Greeff"], "title": "Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing", "categories": ["cs.LG", "cs.CV", "cs.RO"], "comment": null, "summary": "Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\\% smoothness improvement and 90.7\\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\\% negative outputs. The lean variant outperforms wide (+5.6\\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware."}
{"id": "2601.14202", "pdf": "https://arxiv.org/pdf/2601.14202", "abs": "https://arxiv.org/abs/2601.14202", "authors": ["Mohamed Nomeir", "Sennur Ulukus"], "title": "Storage-Rate Trade-off in A-XPIR", "categories": ["cs.IT", "cs.CR", "cs.NI", "eess.SP"], "comment": null, "summary": "We consider the storage problem in an asymmetric $X$-secure private information retrieval (A-XPIR) setting. The A-XPIR setting considers the $X$-secure PIR problem (XPIR) when a given arbitrary set of servers is communicating. We focus on the trade-off region between the average storage at the servers and the average download cost. In the case of $N=4$ servers and two non-overlapping sets of communicating servers with $K=2$ messages, we characterize the achievable region and show that the three main inequalities compared to the no-security case collapse to two inequalities in the asymmetric security case. In the general case, we derive bounds that need to be satisfied for the general achievable region for an arbitrary number of servers and messages. In addition, we provide the storage and retrieval scheme for the case of $N=4$ servers with $K=2$ messages and two non-overlapping sets of communicating servers, such that the messages are not replicated (in the sense of a coded version of each symbol) and at the same time achieve the optimal achievable rate for the case of replication. Finally, we derive the exact capacity for the case of asymmetric security and asymmetric collusion for $N=4$ servers, with the communication links $\\{1,2\\}$ and $\\{3,4\\}$, which splits the servers into two groups, i.e., $g=2$, and with the collusion links $\\{1,3\\}$, $\\{2,4\\}$, as $C=\\frac{1}{3}$. More generally, we derive a capacity result for a certain family of asymmetric collusion and asymmetric security cases."}
{"id": "2601.11807", "pdf": "https://arxiv.org/pdf/2601.11807", "abs": "https://arxiv.org/abs/2601.11807", "authors": ["Pijuan Yu", "Anzu Kawazoe", "Alexis Urquhart", "Thomas K. Ferris", "M. Cynthia Hipwell", "Rebecca F. Friesen"], "title": "A Hybrid Soft Haptic Display for Rendering Lump Stiffness in Remote Palpation", "categories": ["cs.HC", "cs.RO"], "comment": "Paper manuscript has been accepted by 2026 IEEE Haptics Symposium", "summary": "Remote palpation enables noninvasive tissue examination in telemedicine, yet current tactile displays often lack the fidelity to convey both large-scale forces and fine spatial details. This study introduces a hybrid fingertip display comprising a rigid platform and a $4\\times4$ soft pneumatic tactile display (4.93 mm displacement and 1.175 N per single pneumatic chamber) to render a hard lump beneath soft tissue. This study compares three rendering strategies: a Platform-Only baseline that renders the total interaction force; a Hybrid A (Position + Force Feedback) strategy that adds a dynamic, real-time soft spatial cue; and a Hybrid B (Position + Preloaded Stiffness Feedback) strategy that provides a constant, pre-calculated soft spatial cue.\n  In a 12-participant lump detection study, both hybrid methods dramatically improved accuracy over the Platform-Only baseline (from 50\\% to over 95\\%). While the Hybrid B was highlighted qualitatively for realism, its event-based averaging is expected to increase interaction latency in real-time operation. This suggests a trade-off between perceived lump realism and real-time responsiveness, such that rendering choices that enhance realism may conflict with those that minimize latency."}
{"id": "2601.12084", "pdf": "https://arxiv.org/pdf/2601.12084", "abs": "https://arxiv.org/abs/2601.12084", "authors": ["Shiye Cao", "Jiwon Moon", "Yifan Xu", "Anqi Liu", "Chien-Ming Huang"], "title": "Reframing Conversational Design in HRI: Deliberate Design with AI Scaffolds", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Large language models (LLMs) have enabled conversational robots to move beyond constrained dialogue toward free-form interaction. However, without context-specific adaptation, generic LLM outputs can be ineffective or inappropriate. This adaptation is often attempted through prompt engineering, which is non-intuitive and tedious. Moreover, predominant design practice in HRI relies on impression-based, trial-and-error refinement without structured methods or tools, making the process inefficient and inconsistent. To address this, we present the AI-Aided Conversation Engine (ACE), a system that supports the deliberate design of human-robot conversations. ACE contributes three key innovations: 1) an LLM-powered voice agent that scaffolds initial prompt creation to overcome the \"blank page problem,\" 2) an annotation interface that enables the collection of granular and grounded feedback on conversational transcripts, and 3) using LLMs to translate user feedback into prompt refinements. We evaluated ACE through two user studies, examining both designs' experience and end users' interactions with robots designed using ACE. Results show that ACE facilitates the creation of robot behavior prompts with greater clarity and specificity, and that the prompts generated with ACE lead to higher-quality human-robot conversational interactions."}
{"id": "2601.12089", "pdf": "https://arxiv.org/pdf/2601.12089", "abs": "https://arxiv.org/abs/2601.12089", "authors": ["Erwan Tanguy-Legac", "Tommaso Belvedere", "Gianluca Corsini", "Marco Tognon", "Marcello Traiola"], "title": "Domain-specific Hardware Acceleration for Model Predictive Path Integral Control", "categories": ["cs.AR", "cs.RO"], "comment": "7 pages, 11 figures", "summary": "Accurately controlling a robotic system in real time is a challenging problem. To address this, the robotics community has adopted various algorithms, such as Model Predictive Control (MPC) and Model Predictive Path Integral (MPPI) control. The first is difficult to implement on non-linear systems such as unmanned aerial vehicles, whilst the second requires a heavy computational load. GPUs have been successfully used to accelerate MPPI implementations; however, their power consumption is often excessive for autonomous or unmanned targets, especially when battery-powered. On the other hand, custom designs, often implemented on FPGAs, have been proposed to accelerate robotic algorithms while consuming considerably less energy than their GPU (or CPU) implementation. However, no MPPI custom accelerator has been proposed so far. In this work, we present a hardware accelerator for MPPI control and simulate its execution. Results show that the MPPI custom accelerator allows more accurate trajectories than GPU-based MPPI implementations."}
{"id": "2601.12142", "pdf": "https://arxiv.org/pdf/2601.12142", "abs": "https://arxiv.org/abs/2601.12142", "authors": ["Ziang Guo", "Feng Yang", "Xuefeng Zhang", "Jiaqi Guo", "Kun Zhao", "Peng Lu", "Zufeng Zhang", "Sifa Zheng"], "title": "Listen, Look, Drive: Coupling Audio Instructions for User-aware VLA-based Autonomous Driving", "categories": ["eess.AS", "cs.MM", "cs.RO"], "comment": "Accepted by IV", "summary": "Vision Language Action (VLA) models promise an open-vocabulary interface that can translate perceptual ambiguity into semantically grounded driving decisions, yet they still treat language as a static prior fixed at inference time. As a result, the model must infer continuously shifting objectives from pixels alone, yielding delayed or overly conservative maneuvers. We argue that effective VLAs for autonomous driving need an online channel in which users can influence driving with specific intentions. To this end, we present EchoVLA, a user-aware VLA that couples camera streams with in situ audio instructions. We augment the nuScenes dataset with temporally aligned, intent-specific speech commands generated by converting ego-motion descriptions into synthetic audios. Further, we compose emotional speech-trajectory pairs into a multimodal Chain-of-Thought (CoT) for fine-tuning a Multimodal Large Model (MLM) based on Qwen2.5-Omni. Specifically, we synthesize the audio-augmented dataset with different emotion types paired with corresponding driving behaviors, leveraging the emotional cues embedded in tone, pitch, and speech tempo to reflect varying user states, such as urgent or hesitant intentions, thus enabling our EchoVLA to interpret not only the semantic content but also the emotional context of audio commands for more nuanced and emotionally adaptive driving behavior. In open-loop benchmarks, our approach reduces the average L2 error by $59.4\\%$ and the collision rate by $74.4\\%$ compared to the baseline of vision-only perception. More experiments on nuScenes dataset validate that EchoVLA not only steers the trajectory through audio instructions, but also modulates driving behavior in response to the emotions detected in the user's speech."}
{"id": "2601.12358", "pdf": "https://arxiv.org/pdf/2601.12358", "abs": "https://arxiv.org/abs/2601.12358", "authors": ["Omar Y. Goba", "Ahmed Y. Gado", "Catherine M. Elias", "Ahmed Hussein"], "title": "From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios."}
{"id": "2601.12367", "pdf": "https://arxiv.org/pdf/2601.12367", "abs": "https://arxiv.org/abs/2601.12367", "authors": ["Hana E. Elmalah", "Catherine M. Elias"], "title": "User-to-Vehicle Interaction in Smart Mobility: The GO-DRiVeS Autonomous Ride-Sharing Application", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "This paper introduces the GO-DRiVeS application, an on demand ride sharing and requesting mobile application tailored specifically to save long walks and challenges which are time consuming and tiring especially during hot days or when carrying heavy items, faced by university students and staff. The GO-DRiVeS application was developed following the Agile methodology for its flexibility. In addition to, using the mobile application system architecture and client-server architecture. GO-DRiVeS was implemented using React Native (Expo) for the frontend, Node.js and Express for the backend, and MongoDB as the database; based on a detailed analyses to the existing transportation application, comparing their frameworks and identifying their essential functionalities. GO-DRiVeS supports core features like user registration, ride requesting and real-time tracking.In addition to handling multiple requests at the same time in a first come first serve manner. The application was developed based on these features, and the results were conducted in the form of multiple experiments that demonstrated stable behavior in handling the requests, as presented in the Methodology and Results chapters."}
{"id": "2601.12373", "pdf": "https://arxiv.org/pdf/2601.12373", "abs": "https://arxiv.org/abs/2601.12373", "authors": ["Amro Khaled", "Farah Khaled", "Omar Riad", "Catherine M. Elias"], "title": "CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology", "categories": ["cs.CV", "cs.HC", "cs.RO"], "comment": null, "summary": "In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture."}
{"id": "2601.12729", "pdf": "https://arxiv.org/pdf/2601.12729", "abs": "https://arxiv.org/abs/2601.12729", "authors": ["Hanyu Zhu", "Zhihao Zhan", "Yuhang Ming", "Liang Li", "Dibo Hou", "Javier Civera", "Wanzeng Kong"], "title": "DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition", "categories": ["cs.CV", "cs.RO"], "comment": "10 pages, 4 figures, 5 tables", "summary": "One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes."}
{"id": "2601.12830", "pdf": "https://arxiv.org/pdf/2601.12830", "abs": "https://arxiv.org/abs/2601.12830", "authors": ["Om Mishra", "Jayesh Patil", "Sathwik Narkedimilli", "G Srikantha Sharma", "Ananda S", "Manjunath K Vanahalli"], "title": "From Design to Deorbit: A Solar-Electric Autonomous Module for Multi-Debris Remediation", "categories": ["cs.DC", "cs.RO"], "comment": "6 pages, 13 Figures, 2 tables", "summary": "The escalating accumulation of orbital debris threatens the sustainability of space operations, necessitating active removal solutions that overcome the limitations of current fuel-dependent methods. To address this, this study introduces a novel remediation architecture that integrates a mechanical clamping system for secure capture with a high-efficiency, solar-powered NASA Evolutionary Xenon Thruster (NEXT) and autonomous navigation protocols. High-fidelity simulations validate the architecture's capabilities, demonstrating a successful retrograde deorbit from 800 km to 100 km, <10m position Root Mean Square Errors (RMSE) via radar-based Extended Kalman Filter (EKF) navigation, and a 93\\% data delivery efficiency within 1 second using Delay/Disruption Tolerant Network (DTN) protocols. This approach significantly advances orbital management by establishing a benchmark for renewable solar propulsion that minimizes reliance on conventional fuels and extends mission longevity for multi-target removal."}
{"id": "2601.13338", "pdf": "https://arxiv.org/pdf/2601.13338", "abs": "https://arxiv.org/abs/2601.13338", "authors": ["Ziyi Liu", "Xinyi Wang", "Shao-Kang Hsia", "Chenfei Zhu", "Zhengze Zhu", "Xiyun Hu", "Anastasia Kouvaras Ostrowski", "Karthik Ramani"], "title": "Towards Natural Language Environment: Understanding Seamless Natural-Language-Based Human-Multi-Robot Interactions", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "As multiple robots are expected to coexist in future households, natural language is increasingly envisioned as a primary medium for human-robot and robot-robot communication. This paper introduces the concept of a Natural Language Environment (NLE), defined as an interaction space in which humans and multiple heterogeneous robots coordinate primarily through natural language.\n  Rather than proposing a deployable system, this work aims to explore the design space of such environments. We first synthesize prior work on language-based human-robot interaction to derive a preliminary design space for NLEs. We then conduct a role-playing study in virtual reality to investigate how people conceptualize, negotiate, and coordinate human-multi-robot interactions within this imagined environment.\n  Based on qualitative and quantitative analysis, we refine the preliminary design space and derive design implications that highlight key tensions and opportunities around task coordination dominance, robot autonomy, and robot personality in Natural Language Environments."}
{"id": "2601.13494", "pdf": "https://arxiv.org/pdf/2601.13494", "abs": "https://arxiv.org/abs/2601.13494", "authors": ["Swapnil Guragain", "Gokarna Sharma"], "title": "Learning-Augmented Online TRP on a Line", "categories": ["cs.DS", "cs.RO"], "comment": "8 pages, 5 figures, 3 tables, and 2 pseudocodes", "summary": "We study the online traveling repairperson problem on a line within the recently proposed learning-augmented framework, which provides predictions on the requests to be served via machine learning. In the original model (with no predictions), there is a stream of requests released over time along the line. The goal is to minimize the sum (or average) of the completion times of the requests. In the original model, the state-of-the-art competitive ratio lower bound is $1+\\sqrt{2} > 2.414$ for any deterministic algorithm and the state-of-the-art competitive ratio upper bound is 4 for a deterministic algorithm. Our prediction model involves predicted positions, possibly error-prone, of each request in the stream known a priori but the arrival times of requests are not known until their arrival. We first establish a 3-competitive lower bound which extends to the original model. We then design a deterministic algorithm that is $(2+\\sqrt{3})\\approx 3.732$-competitive when predictions are perfect. With imperfect predictions (maximum error $δ> 0$), we show that our deterministic algorithm becomes $\\min\\{3.732+4δ,4\\}$-competitive, knowing $δ$. To the best of our knowledge, these are the first results for online traveling repairperson problem in the learning-augmented framework."}
{"id": "2601.13565", "pdf": "https://arxiv.org/pdf/2601.13565", "abs": "https://arxiv.org/abs/2601.13565", "authors": ["Yu Qin", "Shimeng Fan", "Fan Yang", "Zixuan Xue", "Zijie Mai", "Wenrui Chen", "Kailun Yang", "Zhiyong Li"], "title": "Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": "The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP", "summary": "Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP."}
{"id": "2601.13976", "pdf": "https://arxiv.org/pdf/2601.13976", "abs": "https://arxiv.org/abs/2601.13976", "authors": ["Jing Zuo", "Lingzhou Mu", "Fan Jiang", "Chengcheng Ma", "Mu Xu", "Yonggang Qi"], "title": "FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods."}
{"id": "2601.14234", "pdf": "https://arxiv.org/pdf/2601.14234", "abs": "https://arxiv.org/abs/2601.14234", "authors": ["Qiyang Li", "Sergey Levine"], "title": "Q-learning with Adjoint Matching", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": "32 pages, 8 figures, 7 tables", "summary": "We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL."}
