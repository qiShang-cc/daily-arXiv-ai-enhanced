<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 23]
- [cs.RO](#cs.RO) [Total: 48]
- [cs.LG](#cs.LG) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]
- [astro-ph.IM](#astro-ph.IM) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 10]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.GR](#cs.GR) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Developing a Framework to Simulate Quantitative Ultrasound Flow and Tissue Motion for Ultrafast Doppler Ultrasound](https://arxiv.org/abs/2509.05464)
*Qiang Fu,Changhui Li*

Main category: eess.SP

TL;DR: 3D-FQFlow是一个开源框架，用于在真实的血管和运动条件下定量验证超快功率多普勒成像（uPDI），提供了可重复的标准用于微血管成像研究。


<details>
  <summary>Details</summary>
Motivation: 现有uPDI缺乏能够模拟三维定量血流和组织运动的工具，尤其是在接近真实条件下。

Method: 集成了基于L系统的血管生成器、SimVascular CFD血流动力学模拟、支持用户定义或临床数据驱动的组织运动模拟器、优化的PFILED超声模拟器、预计算矩阵重建器和定量分析器。

Result: 展示了四种运动模式对SVD分解的显著影响，成功实现了兔肾脏（SSIM=0.951）、生成血管（SSIM=0.902）和临床肺动脉（SSIM=0.850）的三维成像，GPU加速使得100帧3D-uPDI生成速度提升18.8倍。

Conclusion: 3D-FQFlow为首个开源框架，为uPDI在真实条件下的定量验证提供了可重复标准。

Abstract: Ultrafast power Doppler imaging (uPDI) has made significant progress and
become an important imaging method for both research and clinical
implementations. While, it lacks simulation tools that can perform
three-dimensional (3D) quantitative flow with tissue motion close to realistic
conditions. In this study, we explore to construct an open-source framework,
named 3D-Fully Quantitative Flow (3D-FQFlow), to provide quantitative modeling
of 3D vascular flow with tissue motion and uPDI imaging. The framework
integrates a L-system-based vascular generator with SimVascular CFD for
hemodynamics, a tissue motion simulator supporting user-defined or
clinical-data-driven condition, an optimized PFILED ultrasound simulator, a
precomputed-matrix-based reconstructor, and a quantitative analyzer
(MSE/PSNR/SSIM). Results demonstrate distinct influences of four motion
patterns on SVD decomposition; successful 3D imaging of rabbit kidney (SSIM =
0.951), generated vasculature (SSIM = 0.902), and clinical pulmonary arteries
(SSIM = 0.850); and GPU acceleration permitting 1-million-scatterer simulation
in 4,117 seconds with 18.8* speedup for 100-frame 3D-uPDI generation. 3D-FQFlow
establishes the first open-source framework for quantitative validation of uPDI
under realistic vascular and motion conditions, creating a reproducible
standard for microvascular imaging research
(https://github.com/FortuneOU/3D-FQFlow).

</details>


### [2] [Time-Modulated Intelligent Reflecting Surfaces for Integrated Sensing, Communication and Security: A Generative AI Design Framework](https://arxiv.org/abs/2509.05565)
*Zhihao Tao,Athina Petropulu,H. Vincent Poor*

Main category: eess.SP

TL;DR: 提出了一种基于GFlowNet的TM-IRS设计方法，用于ISAC系统的物理层安全保护，通过在合法用户方向保持数据完整性，同时在其它方向扰乱数据，同时兼顾感知和通信性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决ISAC系统中可能存在的窃听目标问题，同时保证合法用户的通信安全，同时兼顾感知性能的优化。

Method: 利用GFlowNet框架学习TM-IRS的配置策略，建模为确定性MDP，通过深度神经网络参量化，采样高奖励的TM-IRS参数集。

Result: 实验证明了该方法在同时集成感知、通信和安全方面的有效性，相较于穷举搜索更具采样效率和鲁棒性。

Conclusion: GFlowNet框架成功解决了TM-IRS设计中的高维参数优化问题，为ISAC系统提供了高效的物理层安全解决方案。

Abstract: We propose a novel approach to achieve physical layer security for integrated
sensing and communication (ISAC) systems operating in the presence of targets
that may be eavesdroppers. The system is aided by a time-modulated intelligent
reflecting surface (TM-IRS), which is configured to preserve the integrity of
the transmitted data at one or more legitimate communication users (CUs) while
making them appear scrambled in all other directions. The TM-IRS design
leverages a generative flow network (GFlowNet) framework to learn a stochastic
policy that samples high-performing TM-IRS configurations from a vast discrete
parameter space. Specifically, we begin by formulating the achievable sum rate
for the legitimate CUs and the beampattern gain toward the target direction,
based on which we construct reward functions for GFlowNets that jointly capture
both communication and sensing performance. The TM-IRS design is modeled as a
deterministic Markov decision process (MDP), where each terminal state
corresponds to a complete configuration of TM-IRS parameters. GFlowNets,
parametrized by deep neural networks are employed to learn a stochastic policy
that samples TM-IRS parameter sets with probability proportional to their
associated reward. Experimental results demonstrate the effectiveness of the
proposed GFlowNet-based method in integrating sensing, communication and
security simultaneously, and also exhibit significant sampling efficiency as
compared to the exhaustive combinatorial search and enhanced robustness against
the rule-based TM-IRS design method.

</details>


### [3] [Power-Measurement-Based Channel Estimation for Beyond Diagonal RIS](https://arxiv.org/abs/2509.05639)
*Yijie Liu,Weidong Mei,He Sun,Dong Wang,Peilan Wang*

Main category: eess.SP

TL;DR: 提出一种基于单层神经网络的BD-RIS信道估计方法，仅利用用户终端接收功率测量，减少系统开销并兼容现有协议。


<details>
  <summary>Details</summary>
Motivation: 解决BD-RIS信道估计中依赖专用导频信号导致系统开销大且与现有协议不兼容的问题。

Method: 利用单层神经网络结构，将接收信号功率表达为类似神经网络的权重形式，通过反向传播从功率测量中恢复信道状态信息。

Result: 数值结果表明，该方法在小归一化均方误差（NMSE）方面表现良好，尤其在训练反射次数多时效果更佳。

Conclusion: 该方法为BD-RIS信道估计提供了高效且兼容现有协议的解决方案，显著提升了无线通信性能。

Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS), with its
enhanced degrees of freedom compared to conventional RIS, has demonstrated
notable potential for enhancing wireless communication performance. However, a
key challenge in employing BD-RIS lies in accurately acquiring its channel
state information (CSI) with both the base station (BS) and users. Existing
BD-RIS channel estimation methods rely mainly on dedicated pilot signals, which
increase system overhead and may be incompatible with current communication
protocols. To overcome these limitations, this letter proposes a new
single-layer neural network (NN)-enabled channel estimation method utilizing
only the easily accessible received power measurements at user terminals. In
particular, we show that the received signal power can be expressed in a form
similar to a single-layer NN, where the weights represent the BD-RIS's CSI.
This structure enables the recovery of CSI using the backward propagation,
based on power measurements collected under varying training reflection
coefficients. Numerical results show that our proposed method can achieve a
small normalized mean square error (NMSE), particularly when the number of
training reflections is large.

</details>


### [4] [Full-Angle Ray Antenna Array and Omnicell Wireless Communication System](https://arxiv.org/abs/2509.05677)
*Xuancheng Zhu,Zhiwen Zhou,Yong Zeng*

Main category: eess.SP

TL;DR: 论文提出了一种全角度射线天线阵列（RAA）架构及基于该架构的omnicell无线通信新范式，旨在降低硬件成本、提高波束成形增益并实现全方向均匀角分辨率，从而减少用户间干扰并提升成本效率。


<details>
  <summary>Details</summary>
Motivation: 传统多天线架构（如ULA和UCA）在硬件成本和波束成形增益上存在局限，RAA作为一种新型架构，通过简单线性阵列排列和全角度扩展，有望解决这些问题并推动无线通信系统的革新。

Method: 提出全角度RAA架构，扩展其方向角度至全角度域，并设计基于该架构的omnicell无线通信系统。通过分析和数值结果，对比其与传统的ULA/UCA扇区化系统在关键性能指标上的差异。

Result: 全角度RAA的omnicell系统在空间分辨率和通信速率上优于传统扇区化系统，同时显著降低用户间干扰并提升成本效率。

Conclusion: 全角度RAA架构及其omnicell系统为无线通信提供了更具成本效益和高性能的解决方案，有望替代传统扇区化系统。

Abstract: Ray antenna array (RAA) was recently proposed as a novel multi-antenna
architecture that arranges multiple massive cheap antenna elements into simple
uniform linear arrays (sULAs) with different orientations. Compared with
traditional architectures like hybrid analog/digital beamforming with uniform
linear array (ULA) and uniform circular array (UCA), RAA has several promising
advantages such as significantly reduced hardware cost, higher beamforming
gains and the ability of providing uniform angular resolution for all
directions. In this paper, we propose a full-angle RAA architecture and an
innovative omnicell wireless communication paradigm enabled by full-angle RAA.
The proposed full-angle RAA expands RAA's orientation angle to the full angle
domain, such that the RAA's advantages can be exploited to all directions. This
further enables the new concept of omnicell wireless communication system, with
the base station equipped by full-angle RAA and deployed at the center of each
cell. Compared to the conventional cell sectoring wireless communication
system, the proposed omnicell system is expected to not only significantly
reduce the inter-user interference, but also improve the cost efficiency.
Extensive analytical and numerical results are provided to compare those key
performance indicators such as the spatial resolution and the communication
rate of the proposed full-angle RAA based omnicell wireless communication
system against the conventional ULA/UCA-based cell sectoring systems.

</details>


### [5] [Affine Filter Bank Modulation (AFBM): A Novel 6G ISAC Waveform with Low PAPR and OOBE](https://arxiv.org/abs/2509.05683)
*Kuranage Roche Rayan Ranasinghe,Henrique L. Senger,Gustavo P. Gonçalves,Hyeon Seok Rou,Bruno S. Chang,Giuseppe Thadeu Freitas de Abreu,Didier Le Ruyet*

Main category: eess.SP

TL;DR: 提出了一种名为AFBM的波形，结合FBMC理论和AFDM，具备低PAPR和OOBE特性，适用于6G ISAC。通过GaBP算法实现可靠通信，EM-PDA框架实现精准感知，综合性能优于传统AFDM。


<details>
  <summary>Details</summary>
Motivation: 为6G中的集成感知与通信（ISAC）设计一种高效波形，克服传统波形的功率和带宽限制。

Method: 基于FBMC和AFDM理论设计AFBM波形，采用GaBP算法和EM-PDA框架分别优化通信和感知性能。

Result: AFBM具有低PAPR和OOBE，通信和感知性能均优于传统AFDM。

Conclusion: AFBM是一种有前景的下一代无线波形，适合6G ISAC应用。

Abstract: We propose the affine filter bank modulation (AFBM) waveform for enhanced
integrated sensing and communications (ISAC) in sixth generation (6G), designed
by drawing on concepts from classical filter bank multicarrier modulation
(FBMC) theory and recent advances in chirp-domain waveforms, particularly
affine frequency division multiplexing (AFDM). Specifically, AFBM exhibits
several desirable properties, with emphasis on its remarkably low
peak-to-average power ratio (PAPR) and reduced out-of-band emission (OOBE) when
benchmarked against the conventional AFDM waveform under doubly-dispersive (DD)
channel conditions. In the communications setting, reliable symbol detection is
achieved using a tailored low-complexity Gaussian belief propagation
(GaBP)-based algorithm, while in the sensing setting, a range and velocity
estimation approach is developed that integrates an expectation maximization
(EM)-assisted probabilistic data association (PDA) framework to accurately
identify surrounding targets. The highlighted performance and benefits of AFBM
are validated through analytical and numerical evaluations, including
conventional metrics such as ambiguity function (AF), bit error rate (BER), and
root mean square error (RMSE), consolidating its position as a promising
waveform for next-generation wireless systems.

</details>


### [6] [Resource Allocation and Beamforming in FIM-Assisted BS and STAR-BD-RIS-Aided NOMA: A Meta-Learning Approach](https://arxiv.org/abs/2509.05692)
*Armin Farhadi,Maryam Cheraghy,Qingqing Wu,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 该论文提出了一种基于柔性智能超表面（FIM）的无线通信系统，结合了STAR-BD-RIS和NOMA技术，并通过Meta-SAC算法实现能效最大化。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过FIM和STAR-BD-RIS技术提升通信系统的能量效率，解决传统方法的局限性。

Method: 采用多天线FIM辅助基站，结合双扇区BD-RIS，并提出了Meta-SAC算法进行联合优化。

Result: 仿真结果表明，Meta-SAC算法优于Meta-DDPG，FIM辅助设计显著提升了能效。

Conclusion: FIM与STAR-BD-RIS的结合，加上Meta-SAC算法的优化能力，为未来无线通信系统的能效提升提供了有效解决方案。

Abstract: This study explores a flexible intelligent metasurface (FIM)-based wireless
communication system that integrates simultaneously transmitting and reflecting
beyond diagonal reconfigurable intelligent surfaces (STAR-BD-RIS) with
non-orthogonal multiple access (NOMA). The system features a multi-antenna
FIM-assisted base station (BS) aided by dual-sector BD-RIS. The FIM consists of
cost-effective radiating elements that can independently emit signals and
dynamically adjust their vertical positions ("morphing"). The goal is to
maximize energy efficiency by jointly optimizing BS beamforming, the
STAR-BD-RIS matrix, NOMA constraints, and the FIM surface shape under power
limits. Due to the problem's non-convexity, a meta-soft actor-critic (Meta-SAC)
algorithm is proposed for adaptive optimization. Simulation results show that
Meta-SAC outperforms the Meta-DDPG algorithm, and FIM-assisted designs yield
substantial energy efficiency gains over benchmark schemes.

</details>


### [7] [Optimal Anchor Deployment and Topology Design for Large-Scale AUV Navigation](https://arxiv.org/abs/2509.05903)
*Wei Huang,Junpeng Lu,Tianhe Xu,Jianxu Shu,Hao Zhang,Kaitao Meng,Yanan Wu*

Main category: eess.SP

TL;DR: 论文研究了海底声学锚点的最优部署拓扑，以提升AUV导航性能，分析了大规模水下导航系统的部署模式，并推导了锚点对导航性能的影响规律。


<details>
  <summary>Details</summary>
Motivation: 由于水下设备部署稀疏且成本高，无法像地面节点一样实现全覆盖，因此需要研究最优部署拓扑以提高AUV导航质量。

Method: 分析了可能的部署模式，提出拓扑优化方法，并推导了锚点对导航性能的量化规律。

Result: 通过实验验证了优化性能，展示了高概率到达目的地的服务区域覆盖条件。

Conclusion: 研究为水下锚点部署提供了优化方法，显著提升了AUV导航性能。

Abstract: Seafloor acoustic anchors are an important component of AUV navigation,
providing absolute updates that correct inertial dead-reckoning. Unlike
terrestrial positioning systems, the deployment of underwater anchor nodes is
usually sparse due to the uneven distribution of underwater users, as well as
the high economic cost and difficult maintenance of underwater equipment. These
anchor nodes lack satellite coverage and cannot form ubiquitous backhaul as
terrestrial nodes do. In this paper, we investigate the optimal anchor
deployment topology to provide high-quality AUV navigation and positioning
services. We first analyze the possible deployment mode in large-scale
underwater navigation system, and formulate a topology optimization for
underwater anchor node deployment. Then, we derive a scaling law about the
influence of anchors in each cluster on the navigation performance within a
given area and demonstrate a service area coverage condition with a high
probability of reaching the destination. Finally, the optimization performance
is evaluated through experimental results.

</details>


### [8] [Active noise cancellation in ultra-low field MRI: distinct strategies for different channels](https://arxiv.org/abs/2509.05955)
*Jiali He,Sheng Shen,Jiamin Wu,Xiaohan Kong,Yamei Dai,Liang Tan,Zheng Xu*

Main category: eess.SP

TL;DR: 分析了永磁低场MRI系统中通道特异性干扰路径，提出了一种双重抑制策略，显著降低了电磁干扰并提高了图像质量。


<details>
  <summary>Details</summary>
Motivation: 研究超低场MRI系统中不同通道对电磁干扰的非均匀响应，以解决干扰问题并优化图像质量。

Method: 通过前端空间域逆场重建和后端通道自适应主动噪声消除相结合的双重抑制策略来降低干扰。

Result: 实验表明该方法能减少80%以上的干扰，提高信噪比一致性24%。

Conclusion: 揭示了电磁干扰的通道依赖性，并为未来阵列线圈系统的噪声抑制提供了理论和实践指导。

Abstract: Ultra-low field magnetic resonance imaging(ULF-MRI) systems operating in open
environments are highly susceptible to composite electromagnetic
interference(EMI). Different imaging channels respond non-uniformly to EMI
owing to their distinct coupling characteristics. Here, we investigate
channel-specific interference pathways in a permanent-magnet-based low-field
MRI system and show that saddle coils are intrinsically more vulnerable to
transverse EMI components than solenoidal coils. To mitigate these
heterogeneous coupling effects, we propose a dual-stage suppression strategy
that combines front-end spatial-domain inverse field reconstruction with
back-end channel-adaptive active noise cancellation. Experiments demonstrate
that this approach suppresses EMI by more than 80%, substantially improves
inter-channel signal-to-noise ratio(SNR) consistency, and enhances the
fused-image SNR by 24%. These findings elucidate the channel-dependent nature
of EMI coupling and establish targeted mitigation strategies, providing both a
theoretical basis and practical guidance for noise suppression in future
array-coil ULF-MRI systems.

</details>


### [9] [The Case for a DNANF 1Pb/s Trans-Atlantic Submarine Cable](https://arxiv.org/abs/2509.05959)
*Pierluigi Poggiolini,Francesco Poletti*

Main category: eess.SP

TL;DR: 低损耗空心光纤的进展可能实现跨大西洋海底电缆，支持单方向1 Pb/s速率和200km跨距。


<details>
  <summary>Details</summary>
Motivation: 探索空心光纤技术在高速长距离通信中的应用潜力。

Method: 利用双向传输和空心光纤的低损耗特性。

Result: 理论上可实现1 Pb/s每方向和200km跨距的通信。

Conclusion: 空心光纤有望大幅提升跨洋通信性能和效率。

Abstract: The recent progress in low-loss hollow-core fibers allows to speculate on the
possibility of building a transatlantic submarine cable that can achieve the
goal of 1 Pb/s per direction, leveraging bidirectional transmission, and at the
same time drastically increase span length, theoretically to 200km.

</details>


### [10] [DeepStream: Prototyping Deep Joint Source-Channel Coding for Real-Time Multimedia Transmissions](https://arxiv.org/abs/2509.05971)
*Kaiyi Chi,Yinghui He,Qianqian Yang,Zhiping Jiang,Yuanchao Shu,Zhiqin Wang,Jun Luo,Jiming Chen*

Main category: eess.SP

TL;DR: DeepStream是一种基于深度学习的联合源信道编码技术，通过OFDM技术实现高效媒体传输，并在低信噪比环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有DeepJSCC研究多停留在数值模拟，缺乏实际验证，DeepStream旨在解决这一问题。

Method: 开发了特征到符号映射和交叉子载波预编码方法，并提出了渐进编码策略以适应不同服务质量需求。

Result: DeepStream在10 dB SNR下，图像传输PSNR达35 dB，视频流MS-SSIM达20 dB，表现优于标准方案。

Conclusion: DeepStream验证了DeepJSCC在现实中的可行性，并在效率和鲁棒性上表现突出。

Abstract: Deep learning-based joint source-channel coding (DeepJSCC) has emerged as a
promising technique in 6G for enhancing the efficiency and reliability of data
transmission across diverse modalities, particularly in low signal-to-noise
ratio (SNR) environments. This advantage is realized by leveraging powerful
neural networks to learn an optimal end-to-end mapping from the source data
directly to the transmit symbol sequence, eliminating the need for separate
source coding, channel coding, and modulation. Although numerous efforts have
been made towards efficient DeepJSCC, they have largely stayed at numerical
simulations that can be far from practice, leaving the real-world viability of
DeepJSCC largely unverified. To this end, we prototype DeepStream upon
orthogonal frequency division multiplexing (OFDM) technology to offer efficient
and robust DeepJSCC for multimedia transmission. In conforming to OFDM, we
develop both a feature-to-symbol mapping method and a cross-subcarrier
precoding method to improve the subcarrier independence and reduce
peak-to-average power ratio. To reduce system complexity and enable flexibility
in accommodating varying quality of service requirements, we further propose a
progressive coding strategy that adjusts the compression ratio based on latency
with minimal performance loss. We implement DeepStream for real-time image
transmission and video streaming using software-defined radio. Extensive
evaluations verify that DeepStream outperforms both the standard scheme and the
direct deployment scheme. Particularly, at an SNR of 10 dB, DeepStream achieves
a PSNR of 35 dB for image transmission and an MS-SSIM of 20 dB for video
streaming, whereas the standard scheme fails to recover meaningful information.

</details>


### [11] [3D-Image Reconstruction using MIMO-SAR FMCW Radar](https://arxiv.org/abs/2509.05977)
*Ayush Jha,Dhanireddy Chandrika,Chandra Sekhar Seelamantula,Chetan Singh Thakur*

Main category: eess.SP

TL;DR: 提出了一种基于虚拟MIMO FMCW雷达和SAR技术的高分辨率3D毫米波雷达成像算法。


<details>
  <summary>Details</summary>
Motivation: 传统SAR算法仅提取二维信息，限制了3D场景重建的潜力，因此需要新的方法来实现高分辨率3D成像。

Method: 结合虚拟MIMO FMCW雷达和SAR技术，开发了一种快速的时域重建算法。

Result: 实现了毫米波频率下的高分辨率3D雷达成像。

Conclusion: 该算法为先进的雷达成像应用开辟了新的可能性。

Abstract: With the advancement of millimeter-wave radar technology, Synthetic Aperture
Radar (SAR) imaging at millimeter-wave frequencies has gained significant
attention in both academic research and industrial applications. However,
traditional SAR imaging algorithms primarily focus on extracting
two-dimensional information from detected targets, which limits their potential
for 3D scene reconstruction. In this work, we demonstrated a fast time-domain
reconstruction algorithm for achieving high-resolution 3D radar imaging at
millimeter-wave (mmWave) frequencies. This approach leverages a combination of
virtual Multiple Input Multiple Output (MIMO) Frequency Modulated Continuous
Wave (FMCW) radar with the precision of Synthetic Aperture Radar (SAR)
technique, setting the stage for a new era of advanced radar imaging
applications.

</details>


### [12] [Quantum Radar for ISAC: Sum-Rate Optimization](https://arxiv.org/abs/2509.06070)
*Abdulmohsen Alsaui,Neel Kanth Kundu,Hyundong Shin,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 这篇论文提出了一种集成量子传感与经典通信（IQSCC）的新框架，通过在基站中嵌入量子照明雷达，同时支持全双工经典通信和量子增强目标检测，优化了传输功率和波束形成向量的联合问题，并在低信噪比环境下展示了量子优势。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统ISAC架构中雷达系统在低信号功率和高噪声条件下的局限性，本文提出结合量子雷达技术，以提升频谱效率和硬件融合无线网络的性能。

Method: 论文采用了一种基于和速率最大化的优化框架，结合雷达感知约束，使用逐次凸逼近技术解决了非凸联合优化问题，并推导了经典和量子雷达协议的性能界限。

Result: 仿真结果表明，所提出的IQSCC系统在满足感知需求的同时，比传统ISAC基线实现了更高的通信吞吐量。

Conclusion: IQSCC框架成功整合了量子传感和经典通信，展示了在低信噪比条件下的量子优势，为未来无线网络提供了新的设计思路。

Abstract: Integrated sensing and communication (ISAC) is emerging as a key enabler for
spectrum-efficient and hardware-converged wireless networks. However, classical
radar systems within ISAC architectures face fundamental limitations under low
signal power and high-noise conditions. This paper proposes a novel framework
that embeds quantum illumination radar into a base station to simultaneously
support full-duplex classical communication and quantum-enhanced target
detection. The resulting integrated quantum sensing and classical communication
(IQSCC) system is optimized via a sum-rate maximization formulation subject to
radar sensing constraints. The non-convex joint optimization of transmit power
and beamforming vectors is tackled using the successive convex approximation
technique. Furthermore, we derive performance bounds for classical and quantum
radar protocols under the statistical detection theory, highlighting the
quantum advantage in low signal-to-interference-plus-noise ratio regimes.
Simulation results demonstrate that the proposed IQSCC system achieves a higher
communication throughput than the conventional ISAC baseline while satisfying
the sensing requirement.

</details>


### [13] [Pinching Antenna System (PASS) Enhanced Covert Communications: Against Warden via Sensing](https://arxiv.org/abs/2509.06170)
*Hao Jiang,Zhaolin Wang,Yuanwei Liu,Arumugam Nallanathan,Zhiguo Ding*

Main category: eess.SP

TL;DR: 提出一种基于压接天线系统的感知辅助隐蔽通信网络，通过动态调整天线位置增强隐蔽性，结合感知功能追踪恶意监听者，并通过EKF和DRL优化设计，性能优于传统MIMO系统。


<details>
  <summary>Details</summary>
Motivation: 传统MIMO系统隐蔽性有限，需要动态调整天线位置并追踪监听者以提升隐蔽通信的性能和安全性。

Method: 提出EKF追踪监听者运动，联合设计波束成形、人工噪声和压接天线位置，通过子空间方法和DRL分别优化。

Result: EKF能低复杂度精确追踪监听者；提出的方案优于贪婪和搜索基准；压接天线系统比传统MIMO性能更优。

Conclusion: 动态天线和感知辅助设计有效提升隐蔽通信性能，展示了压接天线系统在新自由度下的优势。

Abstract: A sensing-aided covert communication network empowered by pinching antenna
systems (PASS) is proposed in this work. Unlike conventional fixed-position
MIMO arrays, PASS dynamically reconfigures its pinching antennas (PAs) closer
to the legitimate user, substantially enhancing covertness. To further secure
the adversary's channel state information (CSI), a sensing function is
leveraged to track the malicious warden's movements. In particular, this paper
first proposes an extended Kalman filter (EKF) based approach to fulfilling the
tracking function. Building on this, a covert communication problem is
formulated with a joint design of beamforming, artificial noise (AN) signals,
and the position of PAs. Then, the beamforming and AN design subproblems are
resolved jointly with a subspace approach, while the PA position optimization
subproblem is handled by a deep reinforcement learning (DRL) approach by
treating the evolution of the warden's mobility status as a temporally
corrected process. Numerical results are presented and demonstrate that: i) the
EKF approach can accurately track the warden's CSI with low complexity, ii) the
effectiveness of the proposed solution is verified by its outperformance over
the greedy and searching-based benchmarks, and iii) with new design degrees of
freedom (DoFs), the performance of PASS is superior to the conventional
fully-digital MIMO systems.

</details>


### [14] [Human Body Weight Estimation Through Music-Induced Bed Vibrations](https://arxiv.org/abs/2509.06257)
*Yuyan Wu,Jiale Zhang,Moon Lee,Cherrelle Smith,Xinyi Li,Ankur Senapati,Pei Zhang,Hae Young Noh*

Main category: eess.SP

TL;DR: MelodyBedScale是一种利用音乐引起的床振动来快速、非侵入性地估算患者体重的系统，适用于急救医疗场景。


<details>
  <summary>Details</summary>
Motivation: 在急救医疗中，快速准确的体重估算对治疗决策至关重要，但传统方法（如体重秤或长度测量）往往不实用或不准确。

Method: 系统通过振动传感器捕捉床振动信号，结合特定频率的音乐和物理信息神经网络，进行体重回归分析。

Result: 在11名参与者中，MelodyBedScale的平均绝对误差为1.55公斤，适用于不同类型床铺。

Conclusion: MelodyBedScale是一种可行且高效的急救体重估算解决方案。

Abstract: Rapid and accurate body weight estimation is critical in emergency medical
care, as it directly influences treatment decisions, such as drug dosing,
defibrillation energy selection, and fluid resuscitation. Traditional methods
such as stand-on scales, length-based tapes, or transfer-based weighing scales
are often impractical for immobilized patients, inaccurate, or labor-intensive
and time-consuming. This paper introduces MelodyBedScale, a non-intrusive and
rapid on-bed weight estimation system that leverages bed vibration induced by
music. The core insight is that body weight affects the vibration transfer
function of the bed-body system, which is captured using vibration sensors
placed on opposite sides of the bed. First, we identify weight-sensitive
frequency bands and compose clinically acceptable soft, natural music with high
signal energy in these frequency bands. This music is then played through a
speaker mounted on the bed to induce bed vibrations. Additionally, to
efficiently capture the complex weight-vibration relationship with limited data
and enhance generalizability to unseen individuals and weights, we
theoretically analyze the weight-vibration relationship and integrate the
results into the activation functions of the neural network for
physics-informed weight regression. We evaluated MelodyBedScale on both wooden
and steel beds across 11 participants, achieving a mean absolute error of up to
1.55 kg.

</details>


### [15] [Optimal Distortion-Aware Multi-User Power Allocation for Massive MIMO Networks](https://arxiv.org/abs/2509.06491)
*Siddarth Marwaha,Pawel Kryszkiewicz,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 本文提出了一种针对功率放大器（PA）非线性失真的最优功率分配策略，显著提升了大规模MIMO系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的无线发射前端存在非线性行为（如PA信号削波），但许多资源分配方案简化了这一点，导致结果不准确或性能下降。

Method: 基于软限制PA模型和小尺度瑞利衰落信道，推导了宽带信噪失真比（SNDR），并将问题分解为非凸总功率分配和凸功率分布问题。

Result: 仿真结果显示，相比忽略失真的方案，其和速率显著提升（64天线基站提升4倍，512天线基站提升50%）。

Conclusion: 提出的算法有效解决了PA非线性失真问题，为大规模MIMO系统提供了性能优化方案。

Abstract: Real-world wireless transmitter front-ends exhibit certain nonlinear
behavior, e.g., signal clipping by a Power Amplifier (PA). Although many
resource allocation solutions do not consider this for simplicity, it leads to
inaccurate results or a reduced number of degrees of freedom, not achieving the
global performance. In this work, we propose an optimal PA distortion-aware
power allocation strategy in a downlink orthogonal frequency division multiplex
(OFDM) based massive multiple-input multiple-output (M-MIMO) system. Assuming a
soft-limiter PA model, where the transmission occurs under small-scale
independent and identically distributed (i.i.d) Rayleigh fading channel, we
derive the wideband signal-to-noise-and-distortion ratio (SNDR) and formulate
the power allocation problem. Most interestingly, the distortion introduced by
the PA leads to an SNDR-efficient operating point without explicit transmit
power constraints. While the optimization problem is non-convex, we decouple it
into a non-convex total power allocation problem and a convex power
distribution problem among the users (UEs). We propose an alternating
optimization algorithm to find the optimum solution. Our simulation results
show significant sum-rate gains over existing distortion-neglecting solutions,
e.g., a median 4 times increase and a median 50\% increase for a 64-antenna and
512-antenna base station serving 60 users, respectively.

</details>


### [16] [Synesthesia of Machines (SoM)-Aided LiDAR Point Cloud Transmission for Collaborative Perception](https://arxiv.org/abs/2509.06506)
*Ensong Liu,Rongqing Zhang,Xiang Cheng,Jian Tang*

Main category: eess.SP

TL;DR: 论文提出了一种高效的LiDAR点云传输系统LPC-FT，通过密度保持的深度压缩方法和自注意力机制提升传输效率与鲁棒性，支持多智能体的协作感知。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR点云数据传输效率低和鲁棒性不足的问题，以支持多智能体的协作感知。

Method: 采用密度保持的深度点云压缩方法编码点云，设计基于自注意力的信道编码模块和基于交叉注意力的特征融合模块，利用非线性激活层和迁移学习优化训练。

Result: LPC-FT在Chamfer Distance上降低30%，PSNR提升1.9 dB，优于传统方法和现有深度学习压缩技术。

Conclusion: LPC-FT在重建性能和信道变化鲁棒性方面表现优异，适用于协作感知任务。

Abstract: Collaborative perception enables more accurate and comprehensive scene
understanding by learning how to share information between agents, with LiDAR
point clouds providing essential precise spatial data. Due to the substantial
data volume generated by LiDAR sensors, efficient point cloud transmission is
essential for low-latency multi-agent collaboration. In this work, we propose
an efficient, robust and applicable LiDAR point cloud transmission system via
the Synesthesia of Machines (SoM), termed LiDAR Point Cloud Feature
Transmission (LPC-FT), to support collaborative perception among multiple
agents. Specifically, we employ a density-preserving deep point cloud
compression method that encodes the complete point cloud into a downsampled
efficient representation. To mitigate the effects of the wireless channel, we
design a channel encoder module based on self-attention to enhance LiDAR point
cloud features and a feature fusion module based on cross-attention to
integrate features from transceivers. Furthermore, we utilize the nonlinear
activation layer and transfer learning to improve the training of deep neural
networks in the presence the digital channel noise. Experimental results
demonstrate that the proposed LPC-FT is more robust and effective than
traditional octree-based compression followed by channel coding, and
outperforms state-of-the-art deep learning-based compression techniques and
existing semantic communication methods, reducing the Chamfer Distance by 30%
and improving the PSNR by 1.9 dB on average. Owing to its superior
reconstruction performance and robustness against channel variations, LPC-FT is
expected to support collaborative perception tasks.

</details>


### [17] [Integrated Detection and Tracking Based on Radar Range-Doppler Feature](https://arxiv.org/abs/2509.06569)
*Chenyu Zhang,Yuanhang Wu,Xiaoxi Ma,Wei Yi*

Main category: eess.SP

TL;DR: 雷达检测与跟踪的联合方法InDT，通过特征提取和跟踪器优化提升性能，并在实验中验证效果。


<details>
  <summary>Details</summary>
Motivation: 当前雷达检测与跟踪方法存在信号潜力利用不足、复杂场景刻画不足和跟踪信息有限的问题。

Method: 提出InDT方法，结合雷达特征提取网络和跟踪器优化，利用RD矩阵特征增强检测与数据关联。

Result: 在模拟数据和公开数据集上验证了方法的有效性。

Conclusion: InDT方法通过联合优化检测与跟踪，显著提升了雷达系统的性能。

Abstract: Detection and tracking are the basic tasks of radar systems. Current joint
detection tracking methods, which focus on dynamically adjusting detection
thresholds from tracking results, still present challenges in fully utilizing
the potential of radar signals. These are mainly reflected in the limited
capacity of the constant false-alarm rate model to accurately represent
information, the insufficient depiction of complex scenes, and the limited
information acquired by the tracker. We introduce the Integrated Detection and
Tracking based on radar feature (InDT) method, which comprises a network
architecture for radar signal detection and a tracker that leverages detection
assistance. The InDT detector extracts feature information from each
Range-Doppler (RD) matrix and then returns the target position through the
feature enhancement module and the detection head. The InDT tracker adaptively
updates the measurement noise covariance of the Kalman filter based on
detection confidence. The similarity of target RD features is measured by
cosine distance, which enhances the data association process by combining
location and feature information. Finally, the efficacy of the proposed method
was validated through testing on both simulated data and publicly available
datasets.

</details>


### [18] [Towards In-Air Ultrasonic QR Codes: Deep Learning for Classification of Passive Reflector Constellations](https://arxiv.org/abs/2509.06615)
*Wouter Jansen,Jan Steckel*

Main category: eess.SP

TL;DR: 本文提出了一种多标签卷积神经网络（CNN），用于从单次3D声纳测量中同时识别多个紧密排列的反射器，并通过自适应波束成形技术隔离单个反射器，验证了这种方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 在视觉传感器失效的环境中，声纳提供了一种可靠的替代方案。然而，现有研究仅能分类单个声学地标，本文旨在通过引入反射器星座作为编码标签，提高信息容量。

Method: 使用多标签CNN同时识别多个反射器，并探索自适应波束成形与空转向技术以隔离单个反射器进行分类。

Result: 初步实验证明了方法的可行性，能够解码复杂的声学模式。

Conclusion: 本文展示了提高声学地标系统信息熵的潜力，并讨论了实验结果的局限性及未来发展方向。

Abstract: In environments where visual sensors falter, in-air sonar provides a reliable
alternative for autonomous systems. While previous research has successfully
classified individual acoustic landmarks, this paper takes a step towards
increasing information capacity by introducing reflector constellations as
encoded tags. Our primary contribution is a multi-label Convolutional Neural
Network (CNN) designed to simultaneously identify multiple, closely spaced
reflectors from a single in-air 3D sonar measurement. Our initial findings on a
small dataset confirm the feasibility of this approach, validating the ability
to decode these complex acoustic patterns. Secondly, we investigated using
adaptive beamforming with null-steering to isolate individual reflectors for
single-label classification. Finally, we discuss the experimental results and
limitations, offering key insights and future directions for developing
acoustic landmark systems with significantly increased information entropy and
their accurate and robust detection and classification.

</details>


### [19] [Near-Threshold Voltage Massive MIMO Computing](https://arxiv.org/abs/2509.06651)
*Mikael Rinkinen,Mehdi Safarpour,Shahriar Shahabuddin,Olli Silven,Lauri Koskinen*

Main category: eess.SP

TL;DR: 论文探讨了如何通过算法容错（ABFT）提升大规模MIMO系统的可靠性，并结合近阈值计算（NTC）降低功耗，实验证明该方法可节约36%的功耗且计算开销仅为3%。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统虽能提升频谱效率，但高功耗问题限制了其应用。近阈值计算（NTC）虽能降低能耗，但易受工艺、电压和温度（PVT）影响导致计算错误。本文旨在通过ABFT解决NTC的可靠性问题。

Method: 提出了一种改进的矩阵运算牛顿迭代MIMO算法，无缝集成ABFT以检测计算错误，无需硬件修改，纯软件实现。

Result: 实验结果表明，在大规模问题中，该方法相比基线可节约36%的功耗，计算开销仅为3%。

Conclusion: 结合ABFT与NTC是实现高效节能且鲁棒的大规模MIMO处理器的可行路径。

Abstract: Massive MIMO systems have the potential to significantly enhance spectral
efficiency, yet their widespread integration is hindered by the high power
consumption of the underlying computations. This paper explores the
applicability and effectiveness of Algorithm-Based Fault Tolerance (ABFT) for
massive MIMO signal processing to tackle the reliability challenge of Near
Threshold Computing (NTC). We propose modifying matrix arithmetic Newton
iteration MIMO algorithm to seamlessly integrate ABFT to detect any
computational errors by inspecting the final result. The overhead from ABFT
depends largely on the matrix dimensions, which in this context are dictated by
the number of user equipments involved in the computation. NTC is a promising
strategy for reducing the energy consumption in digital circuits by operating
transistors at extremely reduced voltages. However, NTC is highly susceptible
to variations in Process, Voltage, and Temperature (PVT) which can lead to
increased error rates in computations. Traditional techniques for enabling NTC,
such as dynamic voltage and frequency scaling guided by circuit level timing
error detection methods, introduce considerable hardware complexity and are
difficult to implement at high clock frequencies. In this context ABFT has
emerged as a lightweight error detection method tailored for matrix operations
without requiring any modifications on circuit-level and can be implemented
purely in software.A MIMO accelerator was implemented on a reconfigurable
hardware platform. Experimental results demonstrate that for sufficiently large
problem sizes, the proposed method achieves a 36% power saving compared to
baseline, with only an average of 3% computational overhead, at default clock
frequency. These results indicate that combining ABFT with near-threshold
operation provides a viable path toward energy-efficient and robust massive
MIMO processors.

</details>


### [20] [SE and EE Tradeoff in Active STAR-RIS Assisted Systems With Hardware Impairments](https://arxiv.org/abs/2509.06662)
*Ao Huang,Xidong Mu,Li Guo,Guangyu Zhu*

Main category: eess.SP

TL;DR: 论文研究了在硬件损伤的情况下，如何通过联合优化基站和STAR-RIS的波束成形，实现频谱效率（SE）和能量效率（EE）的最优权衡。


<details>
  <summary>Details</summary>
Motivation: 在硬件损伤（HWIs）的现实条件下，优化STAR-RIS辅助通信系统的资源效率，以实现频谱效率和能量效率的平衡。

Method: 采用二次变换法处理分数目标函数，并开发交替优化算法迭代更新基站和STAR-RIS的波束成形系数。

Result: 仿真结果显示，所提方案在硬件损伤下优于其他基线方案，并分析了不同发射功率预算下SE-EE区域的变化。

Conclusion: 该方案在硬件损伤条件下能够有效优化资源效率，为STAR-RIS辅助系统的性能提升提供了可行方法。

Abstract: This paper investigates the problem of resource efficiency maximization in an
active simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS) assisted communication system under practical transceiver
hardware impairments (HWIs). We aim to obtain an optimal tradeoff between
system spectral efficiency (SE) and energy efficiency (EE), by jointly
optimizing the base station (BS) transmit beamforming and the active STAR-RIS
beamforming. To tackle the challenges in the fractional objective function, we
begin by applying the quadratic transformation method to simplify it into a
manageable form. An alternating optimization-based algorithm is then developed
to iteratively update the BS and STAR-RIS beamforming coefficients. Simulation
results demonstrate that the proposed scheme performs better than other
baseline schemes in the presence of HWIs. Moreover, the variation of the
achievable SE-EE region with different transmit power budgets is analyzed.

</details>


### [21] [ISAC Imaging by Channel State Information using Ray Tracing for Next Generation 6G](https://arxiv.org/abs/2509.06672)
*Ahmad Bazzi,Mingjun Ying,Ojas Kanhere,Theodore S. Rappaport,Marwa Chafii*

Main category: eess.SP

TL;DR: 该论文提出了一种基于CSI多径分量的ISAC成像框架，通过两段反射点优化算法精确重建物体几何形状，并在6.75 GHz频段上首次实现多跳ISAC成像。


<details>
  <summary>Details</summary>
Motivation: 6G无线系统中，ISAC技术通过共享硬件和频谱实现连接和环境映射的需求日益增长，尤其是在多跳反射场景下，精确的几何重构是一项重要且具有挑战性的任务。

Method: 利用校准的NYURay射线追踪器获取CSI、TX和RX位置信息，通过提取多径分量并将其角度和时延信息融合为等效反射点，进一步采用两段反射点优化算法独立估计路径长度以实现精确重构。

Result: 实验证明该框架能准确重建物体表面、边缘和曲线特征。

Conclusion: 该研究首次在6.75 GHz频段展示了多跳ISAC成像的有效性。

Abstract: Integrated sensing and communications (ISAC) is emerging as a cornerstone
technology for sixth generation (6G) wireless systems, unifying connectivity
and environmental mapping through shared hardware, spectrum, and waveforms. The
following paper presents an ISAC imaging framework utilizing channel state
information (CSI) per-path components, transmitter (TX) positions, and receiver
(RX) positions obtained from the calibrated NYURay ray tracer at 6.75 GHz in
the upper mid-band. Our work shows how each resolvable multipath component can
be extracted from CSI estimation and cast into an equivalent three-dimensional
reflection point by fusing its angle and delay information, which is useful and
challenging for multi-bounce reflections. The primary contribution of the paper
is the two-segment reflection point optimization algorithm, which independently
estimates the path lengths from the TX position and RX position to an
equivalent reflection point (ERP) on the object surface, thus enabling precise
geometric reconstruction. Subsequently, we aggregate the ERPs derived from
multiple pairs of TX and RX positions, generating dense three dimensional point
clouds representing the objects in the channel. Experimental results validate
that the proposed ISAC imaging framework accurately reconstructs object
surfaces, edges, and curved features. To the best of our knowledge, this paper
provides the first demonstration of multi bounce ISAC imaging using wireless
ray tracing at 6.75 GHz.

</details>


### [22] [RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator](https://arxiv.org/abs/2509.06751)
*Weicheng Gao*

Main category: eess.SP

TL;DR: 提出了一种基于模型的FMCW雷达HAR模拟器，用于生成高保真数据以支持算法开发。


<details>
  <summary>Details</summary>
Motivation: 雷达HAR需要多样化和高保真的数据集，但获取这些数据具有挑战性。

Method: 开发了包含13散射体运动学模型的模拟器，模拟12种活动，并通过STFT和FSST生成RTM和DTM。

Result: 模拟器成功生成了高保真且独特的微多普勒特征，适用于算法设计。

Conclusion: 该模拟器为雷达HAR提供了一种有价值的工具，代码已开源。

Abstract: Radar-based human activity recognition (HAR) is a pivotal research area for
applications requiring non-invasive monitoring. However, the acquisition of
diverse and high-fidelity radar datasets for robust algorithm development
remains a significant challenge. To overcome this bottleneck, a model-based
frequency-modulated continuous wave (FMCW) radar HAR simulator is developed.
The simulator integrates an anthropometrically scaled $13$-scatterer kinematic
model to simulate $12$ distinct activities. The FMCW radar echo model is
employed, which incorporates dynamic radar cross-section (RCS), free-space or
through-the-wall propagation, and a calibrated noise floor to ensure signal
fidelity. The simulated raw data is then processed through a complete pipeline,
including moving target indication (MTI), bulk Doppler compensation, and
Savitzky-Golay denoising, culminating in the generation of high-resolution
range-time map (RTM) and Doppler-time maps (DTMs) via both short-time Fourier
transform (STFT) and Fourier synchrosqueezed transform (FSST). Finally, a novel
neural network method is proposed to validate the effectiveness of the radar
HAR. Numerical experiments demonstrate that the simulator successfully
generates high-fidelity and distinct micro-Doppler signature, which provides a
valuable tool for radar HAR algorithm design and validation. The installer of
this simulator is released at:
\href{https://github.com/JoeyBGOfficial/RadHARSimulatorV1-Model-Based-FMCW-Radar-Human-Activity-Recognition-Simulator}{Github/JoeyBGOfficial/RadHARSimulatorV1}.

</details>


### [23] [Green Learning for STAR-RIS mmWave Systems with Implicit CSI](https://arxiv.org/abs/2509.06820)
*Yu-Hsiang Huang,Po-Heng Chou,Wan-Jen Huang,Walid Saad,C. -C. Jay Kuo*

Main category: eess.SP

TL;DR: 提出了一种基于绿色学习（GL）的预编码框架，用于STAR-RIS辅助的毫米波MIMO广播系统，无需显式CSI估计，显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 未来6G网络强调环境可持续性，通过广播传输架构提高频谱效率并减少冗余传输和功耗。

Method: 采用GL框架，结合Saab、RFT和XGBoost技术，直接利用上行导频信号预测STAR-RIS系数和发射预编码器。

Result: 仿真表明，GL在频谱效率上接近传统方法，但计算量减少四个数量级。

Conclusion: GL框架适合资源受限的实时广播场景，具有较高的部署潜力。

Abstract: In this paper, a green learning (GL)-based precoding framework is proposed
for simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS)-aided millimeter-wave (mmWave) MIMO broadcasting systems.
Motivated by the growing emphasis on environmental sustainability in future 6G
networks, this work adopts a broadcasting transmission architecture for
scenarios where multiple users share identical information, improving spectral
efficiency and reducing redundant transmissions and power consumption.
Different from conventional optimization methods, such as block coordinate
descent (BCD) that require perfect channel state information (CSI) and
iterative computation, the proposed GL framework operates directly on received
uplink pilot signals without explicit CSI estimation. Unlike deep learning (DL)
approaches that require CSI-based labels for training, the proposed GL approach
also avoids deep neural networks and backpropagation, leading to a more
lightweight design. Although the proposed GL framework is trained with
supervision generated by BCD under full CSI, inference is performed in a fully
CSI-free manner. The proposed GL integrates subspace approximation with
adjusted bias (Saab), relevant feature test (RFT)-based supervised feature
selection, and eXtreme gradient boosting (XGBoost)-based decision learning to
jointly predict the STAR-RIS coefficients and transmit precoder. Simulation
results show that the proposed GL approach achieves competitive spectral
efficiency compared to BCD and DL-based models, while reducing floating-point
operations (FLOPs) by over four orders of magnitude. These advantages make the
proposed GL approach highly suitable for real-time deployment in energy- and
hardware-constrained broadcasting scenarios.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [24] [ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory](https://arxiv.org/abs/2509.05314)
*Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Shanghang Zhang*

Main category: cs.RO

TL;DR: ManipDreamer3D提出了一种新型框架，用于从输入图像和文本指令生成3D感知的机器人操作视频，结合3D轨迹规划和轨迹到视频的扩散模型，显著减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作领域数据稀缺问题，现有方法依赖2D轨迹导致3D空间模糊性。

Method: 结合3D轨迹规划和重建的3D占用图，使用轨迹到视频的扩散模型生成视频。

Result: 实验结果表明视觉质量优于现有方法，生成具有自主规划3D轨迹的视频。

Conclusion: ManipDreamer3D有效解决了3D空间模糊性问题，为机器人操作视频生成提供了新方案。

Abstract: Data scarcity continues to be a major challenge in the field of robotic
manipulation. Although diffusion models provide a promising solution for
generating robotic manipulation videos, existing methods largely depend on 2D
trajectories, which inherently face issues with 3D spatial ambiguity. In this
work, we present a novel framework named ManipDreamer3D for generating
plausible 3D-aware robotic manipulation videos from the input image and the
text instruction. Our method combines 3D trajectory planning with a
reconstructed 3D occupancy map created from a third-person perspective, along
with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D
first reconstructs the 3D occupancy representation from the input image and
then computes an optimized 3D end-effector trajectory, minimizing path length
while avoiding collisions. Next, we employ a latent editing technique to create
video sequences from the initial image latent and the optimized 3D trajectory.
This process conditions our specially trained trajectory-to-video diffusion
model to produce robotic pick-and-place videos. Our method generates robotic
videos with autonomously planned plausible 3D trajectories, significantly
reducing human intervention requirements. Experimental results demonstrate
superior visual quality compared to existing methods.

</details>


### [25] [Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles](https://arxiv.org/abs/2509.05315)
*Petros Loukas,David Bassir,Savvas Chatzichristofis,Angelos Amanatiadis*

Main category: cs.RO

TL;DR: 论文评估了大型语言模型（LLMs）在自动驾驶车辆中作为异常检测器的潜力，尤其是在当前自动驾驶系统失败的边缘案例中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，其在多领域的应用潜力逐渐显现。然而，目前对其在自动驾驶中的评估主要局限于合成数据集或缺乏真实场景的地面真实数据，无法准确衡量其在现有感知与规划算法中的表现。

Method: 提出了一种结合开放词汇目标检测、提示工程和大型语言模型上下文推理的架构，并在真实世界的边缘案例中对几种前沿模型进行了评估。

Result: 研究提供了定性比较结果，并讨论了LLMs作为自动驾驶车辆异常检测器的潜在应用。

Conclusion: 该工作展示了LLMs在自动驾驶领域的实际应用潜力，尤其是在处理复杂边缘案例时，但仍需进一步研究以优化其性能。

Abstract: The rapid evolution of large language models (LLMs) has pushed their
boundaries to many applications in various domains. Recently, the research
community has started to evaluate their potential adoption in autonomous
vehicles and especially as complementary modules in the perception and planning
software stacks. However, their evaluation is limited in synthetic datasets or
manually driving datasets without the ground truth knowledge and more
precisely, how the current perception and planning algorithms would perform in
the cases under evaluation. For this reason, this work evaluates LLMs on
real-world edge cases where current autonomous vehicles have been proven to
fail. The proposed architecture consists of an open vocabulary object detector
coupled with prompt engineering and large language model contextual reasoning.
We evaluate several state-of-the-art models against real edge cases and provide
qualitative comparison results along with a discussion on the findings for the
potential application of LLMs as anomaly detectors in autonomous vehicles.

</details>


### [26] [Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks](https://arxiv.org/abs/2509.05338)
*Atsushi Masumori,Norihiro Maruyama,Itsuki Doi,johnsmith,Hiroki Sato,Takashi Ikegami*

Main category: cs.RO

TL;DR: Plantbot是一种混合生命形式，通过大型语言模型（LLM）模块网络将植物与移动机器人连接起来，利用自然语言实现生物与人工领域的无缝交互。


<details>
  <summary>Details</summary>
Motivation: 通过结合生物和机器人元素，探索LLM作为混合界面的潜力，实现自主响应环境的新型人工生命模型。

Method: 采用异步运行的LLM模块（感知、视觉、对话、行动）进行自然语言通信，将多模态数据转化为语言消息以协调系统行为。

Result: Plantbot能够将植物状态转化为机器人动作，表现出自主适应性。

Conclusion: 该方法为生物和人工系统的新型交互提供了可能性，展示了LLM在人工生命领域的应用潜力。

Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a
mobile robot through a network of large language model (LLM) modules. Each
module - responsible for sensing, vision, dialogue, or action - operates
asynchronously and communicates via natural language, enabling seamless
interaction across biological and artificial domains. This architecture
leverages the capacity of LLMs to serve as hybrid interfaces, where natural
language functions as a universal protocol, translating multimodal data (soil
moisture, temperature, visual context) into linguistic messages that coordinate
system behaviors. The integrated network transforms plant states into robotic
actions, installing normativity essential for agency within the sensor-motor
loop. By combining biological and robotic elements through LLM-mediated
communication, Plantbot behaves as an embodied, adaptive agent capable of
responding autonomously to environmental conditions. This approach suggests
possibilities for a new model of artificial life, where decentralized, LLM
modules coordination enable novel interactions between biological and
artificial systems.

</details>


### [27] [INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing](https://arxiv.org/abs/2509.05345)
*Jiasheng Qu,Zhuo Huang,Dezhao Guo,Hailin Sun,Aoran Lyu,Chengkai Dai,Yeung Yam,Guoxin Fang*

Main category: cs.RO

TL;DR: 提出了一种基于隐式神经场（INFs）的多轴3D打印通用计算框架，统一了工具路径生成和全局无碰撞运动规划的各个阶段。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统3D打印方法在工具路径优化和碰撞处理上的局限性，提出了一种高效的统一框架。

Method: 使用隐式距离场表示模型，将打印目标（如无支撑打印和表面质量）编码到隐式引导场的优化中，并通过连续的四元数场联合优化打印序列和多轴运动。

Result: 与基于显式表示的方法相比，INF-3DP实现了速度上两个数量级的提升，并显著减少了路径点到表面的误差。

Conclusion: 该框架在多轴3D打印中表现出高效性和通用性，适用于复杂模型的物理制造。

Abstract: We introduce a general, scalable computational framework for multi-axis 3D
printing based on implicit neural fields (INFs) that unifies all stages of
toolpath generation and global collision-free motion planning. In our pipeline,
input models are represented as signed distance fields, with fabrication
objectives such as support-free printing, surface finish quality, and extrusion
control being directly encoded in the optimization of an implicit guidance
field. This unified approach enables toolpath optimization across both surface
and interior domains, allowing shell and infill paths to be generated via
implicit field interpolation. The printing sequence and multi-axis motion are
then jointly optimized over a continuous quaternion field. Our continuous
formulation constructs the evolving printing object as a time-varying SDF,
supporting differentiable global collision handling throughout INF-based motion
planning. Compared to explicit-representation-based methods, INF-3DP achieves
up to two orders of magnitude speedup and significantly reduces
waypoint-to-surface error. We validate our framework on diverse, complex models
and demonstrate its efficiency with physical fabrication experiments using a
robot-assisted multi-axis system.

</details>


### [28] [Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation](https://arxiv.org/abs/2509.05355)
*Ahmed R. Sadik,Muhammad Ashfaq,Niko Mäkitalo,Tommi Mikkonen*

Main category: cs.RO

TL;DR: 提出了一种基于大语言模型的自适应无人机群架构，用于动态选择最优架构（集中式、分层式或整体式），以应对灾难响应任务中的动态环境挑战。


<details>
  <summary>Details</summary>
Motivation: 传统固定架构难以适应动态不可预测的环境，导致能源消耗和连接效率低下。

Method: 利用大语言模型根据任务复杂性、群规模和通信稳定性等实时参数，动态选择最优架构。

Result: 模拟实验表明，自适应架构在可扩展性、能源效率和连接性上优于传统静态模型。

Conclusion: 该方法为现实灾难响应场景提供了可扩展、适应性强且稳健的解决方案。

Abstract: The deployment of autonomous drone swarms in disaster response missions
necessitates the development of flexible, scalable, and robust coordination
systems. Traditional fixed architectures struggle to cope with dynamic and
unpredictable environments, leading to inefficiencies in energy consumption and
connectivity. This paper addresses this gap by proposing an adaptive
architecture for drone swarms, leveraging a Large Language Model to dynamically
select the optimal architecture as centralized, hierarchical, or holonic based
on real time mission parameters such as task complexity, swarm size, and
communication stability. Our system addresses the challenges of scalability,
adaptability, and robustness,ensuring efficient energy consumption and
maintaining connectivity under varying conditions. Extensive simulations
demonstrate that our adaptive architecture outperforms traditional static
models in terms of scalability, energy efficiency, and connectivity. These
results highlight the potential of our approach to provide a scalable,
adaptable, and resilient solution for real world disaster response scenarios.

</details>


### [29] [Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning](https://arxiv.org/abs/2509.05356)
*Justus Huebotter,Pablo Lanillos,Marcel van Gerven,Serge Thill*

Main category: cs.RO

TL;DR: 该论文展示了如何在连续环境中训练全脉冲神经网络（SNNs）以实现机器人手臂的多自由度控制，并验证了其在高维运动任务中的可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管在分类任务中训练SNNs取得了进展，但在连续运动控制领域的应用仍然有限。本文旨在填补这一空白。

Method: 结合漏电积分点火（LIF）动力学和替代梯度，提出了一种预测控制框架，同时优化动态预测的前向模型和目标导向动作的策略网络。

Result: 在2D平面到达任务和6自由度机器人仿真中，SNNs表现稳定并能实现精确的扭矩控制。消融实验揭示了初始化、可学习时间常数和正则化的重要性。

Conclusion: 虽然SNNs可以实现稳定有效的控制，但其对超参数设置高度敏感，强调了设计选择的重要性。

Abstract: Despite recent progress in training spiking neural networks (SNNs) for
classification, their application to continuous motor control remains limited.
Here, we demonstrate that fully spiking architectures can be trained end-to-end
to control robotic arms with multiple degrees of freedom in continuous
environments. Our predictive-control framework combines Leaky
Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a
forward model for dynamics prediction and a policy network for goal-directed
action. We evaluate this approach on both a planar 2D reaching task and a
simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve
stable training and accurate torque control, establishing their viability for
high-dimensional motor tasks. An extensive ablation study highlights the role
of initialization, learnable time constants, and regularization in shaping
training dynamics. We conclude that while stable and effective control can be
achieved, recurrent spiking networks remain highly sensitive to hyperparameter
settings, underscoring the importance of principled design choices.

</details>


### [30] [Long-Horizon Visual Imitation Learning via Plan and Code Reflection](https://arxiv.org/abs/2509.05368)
*Quan Chen,Chenrui Shi,Qi Chen,Yuwei Wu,Zhi Gao,Xintong Zhang,Rui Gao,Kun Wu,Yunde Jia*

Main category: cs.RO

TL;DR: 提出了一种新框架，包含两个反思模块，用于提升计划和代码生成，解决了视觉模仿学习中长时程和复杂动作序列的挑战。


<details>
  <summary>Details</summary>
Motivation: 长时程演示中的复杂动作序列对视觉模仿学习带来挑战，尤其是动作的时间关系和对象的空间关系。

Method: 框架包含计划生成模块和代码生成模块，分别通过反思模块验证和改进，确保计划和代码的质量。

Result: 实验表明，新框架在LongVILBench基准测试中表现优异，优于现有方法。

Conclusion: 该方法通过反思机制有效提升了长时程视觉模仿学习的性能，为相关研究提供了新基准。

Abstract: Learning from long-horizon demonstrations with complex action sequences
presents significant challenges for visual imitation learning, particularly in
understanding temporal relationships of actions and spatial relationships
between objects. In this paper, we propose a new agent framework that
incorporates two dedicated reflection modules to enhance both plan and code
generation. The plan generation module produces an initial action sequence,
which is then verified by the plan reflection module to ensure temporal
coherence and spatial alignment with the demonstration video. The code
generation module translates the plan into executable code, while the code
reflection module verifies and refines the generated code to ensure correctness
and consistency with the generated plan. These two reflection modules jointly
enable the agent to detect and correct errors in both the plan generation and
code generation, improving performance in tasks with intricate temporal and
spatial dependencies. To support systematic evaluation, we introduce
LongVILBench, a benchmark comprising 300 human demonstrations with action
sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial
complexity across multiple task types. Experimental results demonstrate that
existing methods perform poorly on this benchmark, whereas our new framework
establishes a strong baseline for long-horizon visual imitation learning.

</details>


### [31] [Evaluating Magic Leap 2 Tool Tracking for AR Sensor Guidance in Industrial Inspections](https://arxiv.org/abs/2509.05391)
*Christian Masuhr,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.RO

TL;DR: 本文通过系统评估Magic Leap 2控制器在AR硬件中的跟踪性能，填补了公共基准测试的空白，为工业应用提供了定量基线和方法论。


<details>
  <summary>Details</summary>
Motivation: 商业AR硬件的严格评估至关重要，但目前现代头戴显示器（HMD）的工具跟踪公共基准有限。

Method: 使用机器人手臂和光学跟踪系统作为基准，评估静态和动态性能，包括实际应用场景中的路径。

Result: 定量分析了ML2控制器的准确性和重复性，并提出了一种可转移的评估方法。

Conclusion: 研究结果为评估控制器在工业AR引导任务中的适用性提供了基础。

Abstract: Rigorous evaluation of commercial Augmented Reality (AR) hardware is crucial,
yet public benchmarks for tool tracking on modern Head-Mounted Displays (HMDs)
are limited. This paper addresses this gap by systematically assessing the
Magic Leap 2 (ML2) controllers tracking performance. Using a robotic arm for
repeatable motion (EN ISO 9283) and an optical tracking system as ground truth,
our protocol evaluates static and dynamic performance under various conditions,
including realistic paths from a hydrogen leak inspection use case. The results
provide a quantitative baseline of the ML2 controller's accuracy and
repeatability and present a robust, transferable evaluation methodology. The
findings provide a basis to assess the controllers suitability for the
inspection use case and similar industrial sensor-based AR guidance tasks.

</details>


### [32] [RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/abs/2509.05397)
*Matthew Lai,Keegan Go,Zhibin Li,Torsten Kroger,Stefan Schaal,Kelsey Allen,Jonathan Scholz*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习和图神经网络的自动化任务与运动规划框架，成功应用于多机器人协作场景。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂环境下难以高效解决多机器人的任务分配、调度和运动规划问题，需要人工干预。

Method: 采用图神经网络策略，通过强化学习生成多机器人轨迹，解决任务分配、调度和运动规划。

Result: 框架在模拟环境中训练后，能够零样本泛化到新场景，提高了规划速度和适应性。

Conclusion: 该方法在多机器人协作中表现出高效性和适应性，适用于动态任务场景。

Abstract: Modern robotic manufacturing requires collision-free coordination of multiple
robots to complete numerous tasks in shared, obstacle-rich workspaces. Although
individual tasks may be simple in isolation, automated joint task allocation,
scheduling, and motion planning under spatio-temporal constraints remain
computationally intractable for classical methods at real-world scales.
Existing multi-arm systems deployed in the industry rely on human intuition and
experience to design feasible trajectories manually in a labor-intensive
process. To address this challenge, we propose a reinforcement learning (RL)
framework to achieve automated task and motion planning, tested in an
obstacle-rich environment with eight robots performing 40 reaching tasks in a
shared workspace, where any robot can perform any task in any order. Our
approach builds on a graph neural network (GNN) policy trained via RL on
procedurally-generated environments with diverse obstacle layouts, robot
configurations, and task distributions. It employs a graph representation of
scenes and a graph policy neural network trained through reinforcement learning
to generate trajectories of multiple robots, jointly solving the sub-problems
of task allocation, scheduling, and motion planning. Trained on large randomly
generated task sets in simulation, our policy generalizes zero-shot to unseen
settings with varying robot placements, obstacle geometries, and task poses. We
further demonstrate that the high-speed capability of our solution enables its
use in workcell layout optimization, improving solution times. The speed and
scalability of our planner also open the door to new capabilities such as
fault-tolerant planning and online perception-based re-planning, where rapid
adaptation to dynamic task sets is required.

</details>


### [33] [HapMorph: A Pneumatic Framework for Multi-Dimensional Haptic Property Rendering](https://arxiv.org/abs/2509.05433)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: HapMorph是一种气动框架，通过对抗性织物气动执行器（AFPAs）实现物体尺寸和刚度的连续同步调制，适用于可穿戴设备，展示了多维度触觉渲染的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有触觉界面通常只能渲染几何特征或机械属性，难以同时在可穿戴设备中实现多种物理属性的调制。

Method: 采用AFPAs技术，通过双腔压力调节实现尺寸和刚度的解耦控制，并进行系统表征和用户感知研究。

Result: 原型实现了50至104 mm的尺寸变化、4.7 N/mm的刚度调制，用户能以89.4%准确率区分9种状态。

Conclusion: HapMorph展示了对抗性气动原理在多维度触觉界面中的潜力，适用于实际可穿戴应用。

Abstract: Haptic interfaces that can simultaneously modulate multiple physical
properties remain a fundamental challenge in human-robot interaction. Existing
systems typically allow the rendering of either geometric features or
mechanical properties, but rarely both, within wearable form factors. Here, we
introduce HapMorph, a pneumatic framework that enables continuous, simultaneous
modulation of object size and stiffness through antagonistic fabric-based
pneumatic actuators (AFPAs). We implemented a HapMorph protoytpe designed for
hands interaction achieving size variation from 50 to 104 mm, stiffness
modulation up to 4.7 N/mm and mass of the wearable parts of just 21 g. Through
systematic characterization, we demonstrate decoupled control of size and
stiffness properties via dual-chamber pressure regulation. Human perception
studies with 10 participants reveal that users can distinguish nine discrete
states across three size categories and three stiffness levels with 89.4%
accuracy and 6.7 s average response time. We further demonstrate extended
architectures that combine AFPAs with complementary pneumatic structures to
enable shape or geometry morphing with concurrent stiffness control. Our
results establish antagonistic pneumatic principle as a pathway toward
next-generation haptic interfaces, capable of multi-dimensiona rendering
properties within practical wearable constraints.

</details>


### [34] [Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation](https://arxiv.org/abs/2509.05475)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 论文提出了一种基于模型强化学习的框架，用于解决月球环境中的自主挖掘问题，通过动态调制刚度和阻尼以及视觉反馈提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决月球环境中因复杂颗粒介质交互和多样化工具需求导致的自主挖掘难题。

Method: 使用并行化模拟和高保真粒子物理结合强化学习，通过动态调整刚度和阻尼实现自适应策略。

Result: 实验表明，工具多样性训练和视觉反馈显著提升了任务成功率和系统泛化能力。

Conclusion: 该方法为未来太空任务所需的自主系统开发提供了可靠方法论。

Abstract: Autonomous regolith excavation is a cornerstone of in-situ resource
utilization for a sustained human presence beyond Earth. However, this task is
fundamentally hindered by the complex interaction dynamics of granular media
and the operational need for robots to use diverse tools. To address these
challenges, this work introduces a framework where a model-based reinforcement
learning agent learns within a parallelized simulation. This environment
leverages high-fidelity particle physics and procedural generation to create a
vast distribution of both lunar terrains and excavation tool geometries. To
master this diversity, the agent learns an adaptive interaction strategy by
dynamically modulating its own stiffness and damping at each control step
through operational space control. Our experiments demonstrate that training
with a procedural distribution of tools is critical for generalization and
enables the development of sophisticated tool-aware behavior. Furthermore, we
show that augmenting the agent with visual feedback significantly improves task
success. These results represent a validated methodology for developing the
robust and versatile autonomous systems required for the foundational tasks of
future space missions.

</details>


### [35] [Microrobot Vascular Parkour: Analytic Geometry-based Path Planning with Real-time Dynamic Obstacle Avoidance](https://arxiv.org/abs/2509.05500)
*Yanda Yang,Max Sokolich,Fatma Ceren Kirmizitas,Sambeeta Das,Andreas A. Malikopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种实时路径规划框架，结合全局规划器和局部控制器，用于在密集动态障碍物中导航微机器人，实现了高效且可靠的避障和目标到达。


<details>
  <summary>Details</summary>
Motivation: 在血管环境中，微机器人的导航面临密集动态障碍物的挑战，需要高效的路径规划方法以实现微创治疗和靶向药物递送。

Method: 该方法结合了全局几何规划器（AGP）和两种反应式局部控制器（基于规则和强化学习），通过实时成像估计位置并计算无碰撞路径。

Result: 仿真和实验表明，AGP在路径长度和规划速度上优于WA*, PSO和RRT，且平均每帧规划时间为40毫秒，满足实时控制需求。

Conclusion: 该框架显著提升了微机器人在血管环境中的自主导航能力，为靶向治疗提供了可靠的技术支持。

Abstract: Autonomous microrobots in blood vessels could enable minimally invasive
therapies, but navigation is challenged by dense, moving obstacles. We propose
a real-time path planning framework that couples an analytic geometry global
planner (AGP) with two reactive local escape controllers, one based on rules
and one based on reinforcement learning, to handle sudden moving obstacles.
Using real-time imaging, the system estimates the positions of the microrobot,
obstacles, and targets and computes collision-free motions. In simulation, AGP
yields shorter paths and faster planning than weighted A* (WA*), particle swarm
optimization (PSO), and rapidly exploring random trees (RRT), while maintaining
feasibility and determinism. We extend AGP from 2D to 3D without loss of speed.
In both simulations and experiments, the combined global planner and local
controllers reliably avoid moving obstacles and reach targets. The average
planning time is 40 ms per frame, compatible with 25 fps image acquisition and
real-time closed-loop control. These results advance autonomous microrobot
navigation and targeted drug delivery in vascular environments.

</details>


### [36] [TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs](https://arxiv.org/abs/2509.05547)
*Ziling Chen,Yeo Jung Yoon,Rolando Bautista-Montesano,Zhen Zhao,Ajay Mandlekar,John Liu*

Main category: cs.RO

TL;DR: TeleopLab是一个移动设备遥操作系统，旨在通过机器人臂和智能手机界面为学生提供远程实验室体验，显著提高了任务效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决远程教育中实际设备互动的高成本和非直观性问题，提供更高效和可扩展的STEM学习平台。

Method: 系统包括机器人臂、自适应夹具、摄像头、智能手机界面和视频通话软件，并通过用户研究评估性能、观点、可用性和工作量。

Result: 任务完成时间减少46.1%，学生观点改善，工作量可管理（38.2），可用性高（73.8）。

Conclusion: TeleopLab成功连接了实体实验室与远程教育，是一种高效且可扩展的远程学习解决方案。

Abstract: Teleoperation offers a promising solution for enabling hands-on learning in
remote education, particularly in environments requiring interaction with
real-world equipment. However, such remote experiences can be costly or
non-intuitive. To address these challenges, we present TeleopLab, a mobile
device teleoperation system that allows students to control a robotic arm and
operate lab equipment. TeleopLab comprises a robotic arm, an adaptive gripper,
cameras, lab equipment for a diverse range of applications, a user interface
accessible through smartphones, and video call software. We conducted a user
study, focusing on task performance, students' perspectives toward the system,
usability, and workload assessment. Our results demonstrate a 46.1% reduction
in task completion time as users gained familiarity with the system.
Quantitative feedback highlighted improvements in students' perspectives after
using the system, while NASA TLX and SUS assessments indicated a manageable
workload of 38.2 and a positive usability of 73.8. TeleopLab successfully
bridges the gap between physical labs and remote education, offering a scalable
and effective platform for remote STEM learning.

</details>


### [37] [Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids](https://arxiv.org/abs/2509.05581)
*Arturo Flores Alvarez,Fatemeh Zargarbashi,Havel Liu,Shiqi Wang,Liam Edwards,Jessica Anz,Alex Xu,Fan Shi,Stelian Coros,Dennis W. Hong*

Main category: cs.RO

TL;DR: 研究者利用强化学习和对抗运动先验（AMP）技术，为娱乐人形机器人Cosmo设计了一种既能保持自然动作又能确保稳定性的运动系统。该方法通过定制化的领域随机化和奖励机制，实现了从仿真到现实的迁移，成功应对了Cosmo因设计美学带来的独特挑战。


<details>
  <summary>Details</summary>
Motivation: 娱乐机器人的设计通常注重美学，例如Cosmo的大头部和防护外壳，这些设计限制了运动能力并增加了控制难度。研究旨在通过学习方法克服这些限制，实现功能与美学的平衡。

Method: 采用了基于强化学习的对抗运动先验（AMP）技术，结合定制化的领域随机化和奖励机制，确保动作自然且稳定，同时保护硬件安全。

Result: 实验表明，尽管Cosmo的质量分布极端且运动受限，AMP仍能生成稳定的站立和行走行为。

Conclusion: 基于学习的方法能有效适应美学驱动的设计约束，为功能性与美学兼具的机器人提供了可行方向。

Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a
custom-built humanoid robot designed for entertainment applications. Unlike
traditional humanoids, entertainment robots present unique challenges due to
aesthetic-driven design choices. Cosmo embodies these with a disproportionately
large head (16% of total mass), limited sensing, and protective shells that
considerably restrict movement. To address these challenges, we apply
Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking
movements while maintaining physical stability. We develop tailored domain
randomization techniques and specialized reward structures to ensure safe
sim-to-real, protecting valuable hardware components during deployment. Our
experiments demonstrate that AMP generates stable standing and walking
behaviors despite Cosmo's extreme mass distribution and movement constraints.
These results establish a promising direction for robots that balance aesthetic
appeal with functional performance, suggesting that learning-based methods can
effectively adapt to aesthetic-driven design constraints.

</details>


### [38] [MonoGlass3D: Monocular 3D Glass Detection with Plane Regression and Adaptive Feature Fusion](https://arxiv.org/abs/2509.05599)
*Kai Zhang,Guoyang Zhao,Jianxing Shi,Bonan Liu,Weiqing Qi,Jun Ma*

Main category: cs.RO

TL;DR: 论文提出了一种名为MonoGlass3D的新方法，用于单目3D玻璃检测，并引入了一个包含多样化玻璃配置的新数据集。


<details>
  <summary>Details</summary>
Motivation: 玻璃的光学特性使传统传感器难以准确检测其表面，缺乏真实世界数据集也阻碍了研究进展。

Method: 提出自适应特征融合模块以捕捉上下文信息，并设计了平面回归流水线以利用玻璃的平面几何特性。

Result: 实验表明，该方法在玻璃分割和单目玻璃深度估计中优于现有技术。

Conclusion: 结合几何和上下文线索对透明表面理解具有显著优势。

Abstract: Detecting and localizing glass in 3D environments poses significant
challenges for visual perception systems, as the optical properties of glass
often hinder conventional sensors from accurately distinguishing glass
surfaces. The lack of real-world datasets focused on glass objects further
impedes progress in this field. To address this issue, we introduce a new
dataset featuring a wide range of glass configurations with precise 3D
annotations, collected from distinct real-world scenarios. On the basis of this
dataset, we propose MonoGlass3D, a novel approach tailored for monocular 3D
glass detection across diverse environments. To overcome the challenges posed
by the ambiguous appearance and context diversity of glass, we propose an
adaptive feature fusion module that empowers the network to effectively capture
contextual information in varying conditions. Additionally, to exploit the
distinct planar geometry of glass surfaces, we present a plane regression
pipeline, which enables seamless integration of geometric properties within our
framework. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches in both glass segmentation and monocular glass
depth estimation. Our results highlight the advantages of combining geometric
and contextual cues for transparent surface understanding.

</details>


### [39] [Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation](https://arxiv.org/abs/2509.05672)
*Juho Kalliokoski,Evan G. Center,Steven M. LaValle,Timo Ojala,Basak Sakcak*

Main category: cs.RO

TL;DR: 研究了共享控制方法在远程机器人导航中的表现，发现其效率与控制切换相当，但未能显著降低用户工作负担。


<details>
  <summary>Details</summary>
Motivation: 远程机器人导航的效率与直观性仍然是挑战，研究者旨在探索共享控制方法是否能提升用户体验。

Method: 开发并评估了共享控制方法，用户可影响路径生成，同时与控制切换方法（用户切换直接和自动控制）进行对比。

Result: 共享控制未降低导航效率，但未显著减轻用户工作负担。

Conclusion: 需进一步研究影响用户偏好和性能的因素。

Abstract: Telepresence robots enable users to interact with remote environments, but
efficient and intuitive navigation remains a challenge. In this work, we
developed and evaluated a shared control method, in which the robot navigates
autonomously while allowing users to affect the path generation to better suit
their needs. We compared this with control switching, where users toggle
between direct and automated control. We hypothesized that shared control would
maintain efficiency comparable to control switching while potentially reducing
user workload. The results of two consecutive user studies (each with final
sample of n=20) showed that shared control does not degrade navigation
efficiency, but did not show a significant reduction in task load compared to
control switching. Further research is needed to explore the underlying factors
that influence user preference and performance in these control systems.

</details>


### [40] [A*-PRM: A Dynamic Weight-Based Probabilistic Roadmap Algorithm](https://arxiv.org/abs/2509.05701)
*Siyuan Wang,Shuyi Zhang,Zhen Tian,Yuheng Yao,Gongsen Wang,Yu Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种结合动态权重的混合路径规划算法A-star PRM，通过嵌入A-Star算法的曼哈顿距离启发式到PRM的随机采样中，实现了路径质量与计算效率的平衡。实验表明该方法在路径长度、稳定性和计算效率上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 提升自主导航系统的环境适应能力，特别是在复杂障碍分布场景中。

Method: 结合A-Star算法的启发式与PRM的随机采样，采用分层采样策略和动态连接机制。

Result: 在1000个采样顶点下，路径长度比PRM缩短42.3%；在3000个顶点下，路径长度减少0.94%，计算时间增长仅为PRM的10%。

Conclusion: A-star PRM在路径质量、稳定性和计算效率方面优于现有混合算法，尤其适用于狭窄通道和动态障碍场景。

Abstract: Robot path planning is a fundamental challenge in enhancing the environmental
adaptability of autonomous navigation systems. This paper presents a hybrid
path planning algorithm, A-star PRM, which incorporates dynamic weights. By
embedding the Manhattan distance heuristic of the A-star algorithm into the
random sampling process of PRM, the algorithm achieves a balanced optimization
of path quality and computational efficiency. The approach uses a hierarchical
sampling strategy and a dynamic connection mechanism, greatly improving
adaptability to complex obstacle distributions. Experiments show that under a
baseline configuration with one thousand sampled vertices, the path length of
A-star PRM is 1073.23 plus or minus 14.8 meters and is 42.3 percent shorter
than that of PRM with p value less than 0.01. With high-density sampling using
three thousand vertices, the path length is reduced by 0.94 percent, 1036.61
meters compared with 1046.42 meters, while the increase in computational time
is cut to about one tenth of the PRM increase, 71 percent compared with 785
percent. These results confirm the comprehensive advantages of A-star PRM in
path quality, stability, and computational efficiency. Compared with existing
hybrid algorithms, the proposed method shows clear benefits, especially in
narrow channels and scenarios with dynamic obstacles.

</details>


### [41] [Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723)
*Liansheng Wang,Xinke Zhang,Chenhui Li,Dongjiao He,Yihan Pan,Jianjun Yi*

Main category: cs.RO

TL;DR: Super-LIO是一种高效的LiDAR-惯性里程计系统，通过紧凑的八叉体素地图结构和启发式KNN策略，显著提升了计算效率和准确性，适用于资源受限的平台。


<details>
  <summary>Details</summary>
Motivation: 由于计算和内存限制，LiDAR-惯性里程计在资源受限平台上的部署存在挑战。Super-LIO旨在提供高性能和高精度的解决方案，适用于无人机和移动自主系统。

Method: Super-LIO采用称为OctVox的紧凑八叉体素地图结构，限制每个体素为八个融合子体素，实现严格的点密度控制和增量去噪。此外，设计了启发式KNN策略（HKNN），利用空间局部性加速对应搜索。

Result: 在X86和ARM平台上测试表明，Super-LIO比现有技术快73%，同时保持高精度和低CPU资源消耗。测试覆盖了30多个公开和自采数据集。

Conclusion: Super-LIO通过高效的地图设计和搜索策略，提供了高性能、高精度的LiDAR-惯性里程计解决方案，支持多种传感器和平台，并开源实现。

Abstract: LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous
systems, yet its deployment on resource-constrained platforms remains
challenging due to computational and memory limitations. We propose Super-LIO,
a robust LIO system that demands both high performance and accuracy, ideal for
applications such as aerial robots and mobile autonomous systems. At the core
of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that
limits each voxel to eight fused subvoxels, enabling strict point density
control and incremental denoising during map updates. This design enables a
simple yet efficient and accurate map structure, which can be easily integrated
into existing LIO frameworks. Additionally, Super-LIO designs a
heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search
by leveraging spatial locality, further reducing runtime overhead. We evaluated
the proposed system using four publicly available datasets and several
self-collected datasets, totaling more than 30 sequences. Extensive testing on
both X86 and ARM platforms confirms that Super-LIO offers superior efficiency
and robustness, while maintaining competitive accuracy. Super-LIO processes
each frame approximately 73% faster than SOTA, while consuming less CPU
resources. The system is fully open-source and plug-and-play compatible with a
wide range of LiDAR sensors and platforms. The implementation is available at:
https://github.com/Liansheng-Wang/Super-LIO.git

</details>


### [42] [Scenario-based Decision-making Using Game Theory for Interactive Autonomous Driving: A Survey](https://arxiv.org/abs/2509.05777)
*Zhihao Lin,Zhen Tian*

Main category: cs.RO

TL;DR: 该论文探讨了基于游戏的交互式驾驶模拟在道路运输决策算法中的应用，总结了最新进展和面临的挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过游戏技术与先进学习框架的结合，提升驾驶决策模型在多样化场景中的适应性和性能。

Method: 通过系统性综述和比较不同场景下的游戏化驾驶方法，评估其算法机制和对决策性能的影响。

Result: 研究发现这些模型在复杂驾驶场景中优于传统模拟方法，但仍需改进。

Conclusion: 论文指出当前方法的局限性，并提出了未来研究的潜在方向以实现更高效的驾驶决策。

Abstract: Game-based interactive driving simulations have emerged as versatile
platforms for advancing decision-making algorithms in road transport mobility.
While these environments offer safe, scalable, and engaging settings for
testing driving strategies, ensuring both realism and robust performance amid
dynamic and diverse scenarios remains a significant challenge. Recently, the
integration of game-based techniques with advanced learning frameworks has
enabled the development of adaptive decision-making models that effectively
manage the complexities inherent in varied driving conditions. These models
outperform traditional simulation methods, especially when addressing
scenario-specific challenges, ranging from obstacle avoidance on highways and
precise maneuvering during on-ramp merging to navigation in roundabouts,
unsignalized intersections, and even the high-speed demands of autonomous
racing. Despite numerous innovations in game-based interactive driving, a
systematic review comparing these approaches across different scenarios is
still missing. This survey provides a comprehensive evaluation of game-based
interactive driving methods by summarizing recent advancements and inherent
roadway features in each scenario. Furthermore, the reviewed algorithms are
critically assessed based on their adaptation of the standard game model and an
analysis of their specific mechanisms to understand their impact on
decision-making performance. Finally, the survey discusses the limitations of
current approaches and outlines promising directions for future research.

</details>


### [43] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: 论文提出了一种基于事件的视觉-惯性系统时空校准方法eKalibr-Inertial，利用圆网格板实现高精度校准，并通过开源代码推动研究。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动估计等领域具有优势，但需要精确的时空校准以实现最优的视觉-惯性融合。

Method: 基于eKalibr系列方法，通过严格的初始化和连续时间批量优化，校准事件相机与惯性传感器的时空参数。

Result: 实验表明，eKalibr-Inertial能够实现高精度的事件相机-惯性传感器时空校准。

Conclusion: eKalibr-Inertial为事件相机-惯性系统提供了有效的校准工具，并开源以促进研究。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [44] [ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction](https://arxiv.org/abs/2509.06031)
*Junhui Huang,Yuhe Gong,Changsheng Li,Xingguang Duan,Luis Figueredo*

Main category: cs.RO

TL;DR: ZLATTE是一个无需学习的、几何感知的框架，通过语言驱动重塑人机交互中的轨迹，利用视觉语言模型和大型语言模型将指令转化为几何与运动学约束，并通过优化实现安全、平滑的轨迹修改。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于学习方法在人机交互中轨迹修改的局限性，提供更安全、平滑且可解释的解决方案。

Method: 结合视觉语言模型和大型语言模型，将自然语言指令转化为几何与运动学约束，并通过潜在场优化和多智能体策略实现轨迹修改。

Result: 仿真和实际实验表明，ZLATTE比现有方法更能实现平滑、安全且可解释的轨迹修改。

Conclusion: ZLATTE无需学习，框架简单且高效，适用于复杂语言指令下的轨迹优化任务。

Abstract: We present ZLATTE, a geometry-aware, learning-free framework for
language-driven trajectory reshaping in human-robot interaction. Unlike prior
learning-based methods, ZLATTE leverages Vision-Language Models to register
objects as geometric primitives and employs a Large Language Model to translate
natural language instructions into explicit geometric and kinematic
constraints. These constraints are integrated into a potential field
optimization to adapt initial trajectories while preserving feasibility and
safety. A multi-agent strategy further enhances robustness under complex or
conflicting commands. Simulation and real-world experiments demonstrate that
ZLATTE achieves smoother, safer, and more interpretable trajectory
modifications compared to state-of-the-art baselines.

</details>


### [45] [Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness](https://arxiv.org/abs/2509.06048)
*Yi Dong,Yangjun Liu,Jinjun Duan,Yang Li,Zhendong Dai*

Main category: cs.RO

TL;DR: 该论文提出了一个机器人操作框架，用于解决鞋类产品这种不规则形状和可变形物品的成对包装问题，通过语义关键点视觉模块和多种重定向方法，实现了高效包装。


<details>
  <summary>Details</summary>
Motivation: 随着仓储和物流行业的快速发展，商品包装问题受到学界和工业界关注。鞋类产品因其不规则形状和可变形特性成为典型代表，但现有研究未考虑不同初始状态的影响。

Method: 研究提出包含感知模块、重定向规划和包装规划的机器人操作框架，基于语义关键点的视觉模块提取几何特征，并结合多种重定向方法和任务规划器完成包装。

Result: 真实实验验证了方法的鲁棒性和包装策略的有效性，适用于多种鞋类。

Conclusion: 研究展示了语义关键点表示方法的潜力，为可变形物体的重定向和多物体操作提供了新视角。

Abstract: With the rapid development of the warehousing and logistics industries, the
packing of goods has gradually attracted the attention of academia and
industry. The packing of footwear products is a typical representative
paired-item packing task involving irregular shapes and deformable objects.
Although studies on shoe packing have been conducted, different initial states
due to the irregular shapes of shoes and standard packing placement poses have
not been considered. This study proposes a robotic manipulation framework,
including a perception module, reorientation planners, and a packing planner,
that can complete the packing of pairs of shoes in any initial state. First, to
adapt to the large intraclass variations due to the state, shape, and
deformation of the shoe, we propose a vision module based on semantic
keypoints, which can also infer more information such as size, state, pose, and
manipulation points by combining geometric features. Subsequently, we not only
proposed primitive-based reorientation methods for different states of a single
deformable shoe but also proposed a fast reorientation method for the top state
using box edge contact and gravity, which further improved the efficiency of
reorientation. Finally, based on the perception module and reorientation
methods, we propose a task planner for shoe pair packing in any initial state
to provide an optimal packing strategy. Real-world experiments were conducted
to verify the robustness of the reorientation methods and the effectiveness of
the packing strategy for various types of shoes. In this study, we highlight
the potential of semantic keypoint representation methods, introduce new
perspectives on the reorientation of 3D deformable objects and multi-object
manipulation, and provide a reference for paired object packing.

</details>


### [46] [Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain](https://arxiv.org/abs/2509.06061)
*Faiza Babakano,Ahmed Fahmin,Bojie Shen,Muhammad Aamir Cheema,Isma Farah Siddiqui*

Main category: cs.RO

TL;DR: 该论文提出了OMEPP问题，旨在解决AMR在途中拾取物体时的能量高效路径规划问题，并提出了一种基于PCPD的并发搜索算法，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: AMR在户外复杂地形中运行时，拾取物体的行为会因载重变化显著影响能量消耗，现有研究忽略了这一实际场景。

Method: 论文首先提出基于Z star算法的基线方法，随后引入了并发PCPD搜索算法，利用Payload-Constrained Path Database优化搜索过程。

Result: 实验表明，并发PCPD搜索算法在接近最优解的同时，计算速度比基线方法快1-2个数量级。

Conclusion: PCPD方法有效解决了AMR在拾取物体时的能量高效路径规划问题，并在实际应用中展现了高性能。

Abstract: Autonomous Mobile Robots (AMRs) operate on battery power, making energy
efficiency a critical consideration, particularly in outdoor environments where
terrain variations affect energy consumption. While prior research has
primarily focused on computing energy-efficient paths from a source to a
destination, these approaches often overlook practical scenarios where a robot
needs to pick up an object en route - an action that can significantly impact
energy consumption due to changes in payload. This paper introduces the
Object-Pickup Minimum Energy Path Problem (OMEPP), which addresses
energy-efficient route planning for AMRs required to pick up an object from one
of many possible locations and deliver it to a destination. To address OMEPP,
we first introduce a baseline algorithm that employs the Z star algorithm, a
variant of A star tailored for energy-efficient routing, to iteratively visit
each pickup point. While this approach guarantees optimality, it suffers from
high computational cost due to repeated searches at each pickup location. To
mitigate this inefficiency, we propose a concurrent PCPD search that manages
multiple Z star searches simultaneously across all pickup points. Central to
our solution is the Payload-Constrained Path Database (PCPD), an extension of
the Compressed Path Database (CPD) that incorporates payload constraints. We
demonstrate that PCPD significantly reduces branching factors during search,
improving overall performance. Although the concurrent PCPD search may produce
slightly suboptimal solutions, extensive experiments on real-world datasets
show it achieves near-optimal performance while being one to two orders of
magnitude faster than the baseline algorithm.

</details>


### [47] [Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots](https://arxiv.org/abs/2509.06115)
*Runjiao Bao,Lin Zhang,Tianwei Niu,Haoyu Yuan,Shoukun Wang*

Main category: cs.RO

TL;DR: 提出了一种扩展的Hybrid A*框架，用于四轮独立转向（4WIS）机器人的多模态路径规划，解决了现有方法未能充分利用4WIS多模态能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法通常假设单一运动模式，无法充分利用4WIS系统多模态的机动性优势。

Method: 扩展Hybrid A*框架至四维状态空间，设计多模态Reeds-Shepp曲线、改进启发式函数以考虑模式切换成本，并引入智能模式选择的终端连接策略。

Result: 在复杂环境中显著提升了4WIS机器人的路径规划性能。

Conclusion: 该方法成功实现了多模态运动的无缝集成，提高了机器人在复杂环境中的灵活性和适应性。

Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a
rich set of motion modes, such as Ackermann steering, lateral steering, and
parallel movement, offering superior maneuverability in constrained
environments. However, existing path planning methods generally assume a single
kinematic model and thus fail to fully exploit the multi-modal capabilities of
4WIS platforms. To address this limitation, we propose an extended Hybrid A*
framework that operates in a four-dimensional state space incorporating both
spatial states and motion modes. Within this framework, we design multi-modal
Reeds-Shepp curves tailored to the distinct kinematic constraints of each
motion mode, develop an enhanced heuristic function that accounts for
mode-switching costs, and introduce a terminal connection strategy with
intelligent mode selection to ensure smooth transitions between different
steering patterns. The proposed planner enables seamless integration of
multiple motion modalities within a single path, significantly improving
flexibility and adaptability in complex environments. Results demonstrate
significantly improved planning performance for 4WIS robots in complex
environments.

</details>


### [48] [A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications](https://arxiv.org/abs/2509.06119)
*Shiqi Xu,Lihao Zhang,Yuyang Du,Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 本文提出了一种混合TDMA/CSMA协议，解决了在高负载机器人通信中CSMA导致的延迟和碰撞问题，显著提升了任务关键流量的实时性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于机器人应用（如制造、医疗和自动驾驶）对实时控制的需求日益增长，CSMA在高负载下表现不佳，导致任务关键命令无法按时到达，影响性能和安全性。

Method: 提出了一种兼容IEEE 802.11的混合TDMA/CSMA协议，结合了TDMA的确定性时隙调度和CSMA的灵活性，通过精确的时间同步、动态TDMA分配和信标-NAV保护实现低延迟和无碰撞通信。

Result: 实验表明，相比CSMA基线，该协议将任务关键流量的错过截止期错误减少了93%，轨迹跟踪误差降低了90%，同时非关键流量的吞吐量变化保持在±2%以内。

Conclusion: 所提出的混合协议在高负载机器人通信中显著提升了任务关键流量的实时性和稳定性，同时保持了非关键流量的性能。

Abstract: Recent progress in robotics has underscored the demand for real-time control
in applications such as manufacturing, healthcare, and autonomous systems,
where the timely delivery of mission-critical commands under heterogeneous
robotic traffic is paramount for operational efficacy and safety. In these
scenarios, mission-critical traffic follows a strict deadline-constrained
communication pattern: commands must arrive within defined QoS deadlines,
otherwise late arrivals can degrade performance or destabilize control loops.In
this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted
in robotic communications,suffers severe degradation under high robot traffic
loads, with contention-induced collisions and delays disrupting the on-time
arrival of mission-critical packets. To address this problem, we propose an
IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's
deterministic slot scheduling with CSMA's adaptability for heterogeneous robot
traffic.The protocol achieves collision-free, low-latency mission-critical
command delivery and IEEE 802.11 compatibility through the synergistic
integration of sub-microsecond PTP-based slot synchronization-essential for
establishing precise timing for TDMA, a three-session superframe with dynamic
TDMA allocation for structured and adaptable traffic management,and beacon-NAV
protection to preemptively secure these critical communication sessions from
interference. Emulation experiments on real-time SDR testbed and Robot
Operating System (ROS) simulation show that the proposed protocol reduces
missed-deadline errors by 93% compared to the CSMA baseline. In high-speed
robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)
trajectory error by up to 90% compared with a CSMA baseline, all while
maintaining throughput for non-critical traffic within +-2%.

</details>


### [49] [Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)](https://arxiv.org/abs/2509.06191)
*Yifei Ren,Edward Johns*

Main category: cs.RO

TL;DR: 3D生成模型通过单次真实演示的数据集增强，实现多方向策略学习，减少演示需求，并在多项任务中表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 探索3D生成模型在机器人任务中的应用潜力，通过增强数据集减少真实演示的需求。

Method: 利用3D生成模型从单次真实演示中生成想象数据集，并学习多方向策略。

Result: 机器人能在远离演示初始状态下完成任务，显著减少策略学习所需的演示次数，并在多项任务中表现优异。

Conclusion: 3D生成模型为机器人策略学习提供了高效的数据增强方法，提升了任务的泛化能力。

Abstract: Recent 3D generative models, which are capable of generating full object
shapes from just a few images, now open up new opportunities in robotics. In
this work, we show that 3D generative models can be used to augment a dataset
from a single real-world demonstration, after which an omnidirectional policy
can be learned within this imagined dataset. We found that this enables a robot
to perform a task when initialised from states very far from those observed
during the demonstration, including starting from the opposite side of the
object relative to the real-world demonstration, significantly reducing the
number of demonstrations required for policy learning. Through several
real-world experiments across tasks such as grasping objects, opening a drawer,
and placing trash into a bin, we study these omnidirectional policies by
investigating the effect of various design choices on policy behaviour, and we
show superior performance to recent baselines which use alternative methods for
data augmentation.

</details>


### [50] [Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control](https://arxiv.org/abs/2509.06201)
*Jun Yamada,Adithyavairavan Murali,Ajay Mandlekar,Clemens Eppner,Ingmar Posner,Balakumar Sundaralingam*

Main category: cs.RO

TL;DR: Grasp-MPC是一种闭环6自由度视觉抓取策略，旨在在杂乱环境中对新物体进行稳健和反应迅速的抓取，效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决在非结构化环境中多样化物体抓取的挑战，尤其是开环方法在杂乱环境中的局限性以及闭环方法在泛化能力上的不足。

Method: 结合大规模合成数据训练的价值函数，并在MPC框架中部署，融合避碰和平滑执行的额外成本项。

Result: 在仿真和真实世界的嘈杂条件下，抓取成功率分别提高了32.6%和33.3%。

Conclusion: Grasp-MPC在杂乱环境中对新物体的抓取表现出显著的稳健性和高效性。

Abstract: Grasping of diverse objects in unstructured environments remains a
significant challenge. Open-loop grasping methods, effective in controlled
settings, struggle in cluttered environments. Grasp prediction errors and
object pose changes during grasping are the main causes of failure. In
contrast, closed-loop methods address these challenges in simplified settings
(e.g., single object on a table) on a limited set of objects, with no path to
generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping
policy designed for robust and reactive grasping of novel objects in cluttered
environments. Grasp-MPC incorporates a value function, trained on visual
observations from a large-scale synthetic dataset of 2 million grasp
trajectories that include successful and failed attempts. We deploy this
learned value function in an MPC framework in combination with other cost terms
that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC
on FetchBench and real-world settings across diverse environments. Grasp-MPC
improves grasp success rates by up to 32.6% in simulation and 33.3% in
real-world noisy conditions, outperforming open-loop, diffusion policy,
transformer policy, and IQL approaches. Videos and more at
http://grasp-mpc.github.io.

</details>


### [51] [O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.06233)
*Tongxuan Tian,Xuhui Kang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 该论文提出了一个基于单样本学习的3D物体间交互能力（affordance）学习方法，结合视觉基础模型和点云数据表示，显著提升了机器人操作中对新颖物体和类别的泛化能力，并通过与大型语言模型（LLMs）的结合增强了任务约束功能的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于单物体交互能力的预测，忽视了现实中多数交互涉及物体对的关系。本文旨在解决数据有限条件下物体间交互能力的映射问题。

Method: 结合视觉基础模型的语义特征与点云数据的几何理解能力，设计了一个单样本学习框架，并进一步整合3D交互能力表示与LLMs，用于机器人操作任务。

Result: 实验表明，该方法（O$^3$Afford）在3D物体间交互能力映射和机器人操作任务中，在准确性和泛化能力上显著优于基线方法。

Conclusion: 该方法不仅提升了机器人对物体交互的理解能力，还为LLMs的任务推理提供了更丰富的信息，具有较强的实用性和扩展性。

Abstract: Grounding object affordance is fundamental to robotic manipulation as it
establishes the critical link between perception and action among interacting
objects. However, prior works predominantly focus on predicting single-object
affordance, overlooking the fact that most real-world interactions involve
relationships between pairs of objects. In this work, we address the challenge
of object-to-object affordance grounding under limited data contraints.
Inspired by recent advances in few-shot learning with 2D vision foundation
models, we propose a novel one-shot 3D object-to-object affordance learning
approach for robotic manipulation. Semantic features from vision foundation
models combined with point cloud representation for geometric understanding
enable our one-shot learning pipeline to generalize effectively to novel
objects and categories. We further integrate our 3D affordance representation
with large language models (LLMs) for robotics manipulation, significantly
enhancing LLMs' capability to comprehend and reason about object interactions
when generating task-specific constraint functions. Our experiments on 3D
object-to-object affordance grounding and robotic manipulation demonstrate that
our O$^3$Afford significantly outperforms existing baselines in terms of both
accuracy and generalization capability.

</details>


### [52] [DCReg: Decoupled Characterization for Efficient Degenerate LiDAR Registration](https://arxiv.org/abs/2509.06285)
*Xiangcheng Hu,Xieyuanli Chen,Mingkai Jia,Jin Wu,Ping Tan,Steven L. Waslander*

Main category: cs.RO

TL;DR: DCReg 是一个解决 LiDAR 点云配准中几何退化或狭窄环境下问题的框架，通过检测、分析和缓解退化问题，显著提升了配准精度和效率。


<details>
  <summary>Details</summary>
Motivation: 在几何退化或狭窄环境中，LiDAR 点云配准问题变得病态，导致解不稳定和精度下降，现有方法未能有效解决这一问题。

Method: DCReg 通过 Schur 补分解解耦旋转和平移子空间，定量表征退化方向，并设计选择性稳定策略，使用预条件共轭梯度法优化。

Result: 实验表明，DCReg 在定位准确性上提升了 20%-50%，运算速度提高了 5-100 倍。

Conclusion: DCReg 提供了一个系统化的解决方案，显著改善了病态环境下的点云配准性能。

Abstract: LiDAR point cloud registration is fundamental to robotic perception and
navigation. However, in geometrically degenerate or narrow environments,
registration problems become ill-conditioned, leading to unstable solutions and
degraded accuracy. While existing approaches attempt to handle these issues,
they fail to address the core challenge: accurately detection, interpret, and
resolve this ill-conditioning, leading to missed detections or corrupted
solutions. In this study, we introduce DCReg, a principled framework that
systematically addresses the ill-conditioned registration problems through
three integrated innovations. First, DCReg achieves reliable ill-conditioning
detection by employing a Schur complement decomposition to the hessian matrix.
This technique decouples the registration problem into clean rotational and
translational subspaces, eliminating coupling effects that mask degeneracy
patterns in conventional analyses. Second, within these cleanly subspaces, we
develop quantitative characterization techniques that establish explicit
mappings between mathematical eigenspaces and physical motion directions,
providing actionable insights about which specific motions lack constraints.
Finally, leveraging this clean subspace, we design a targeted mitigation
strategy: a novel preconditioner that selectively stabilizes only the
identified ill-conditioned directions while preserving all well-constrained
information in observable space. This enables efficient and robust optimization
via the Preconditioned Conjugate Gradient method with a single physical
interpretable parameter. Extensive experiments demonstrate DCReg achieves at
least 20% - 50% improvement in localization accuracy and 5-100 times speedup
over state-of-the-art methods across diverse environments. Our implementation
will be available at https://github.com/JokerJohn/DCReg.

</details>


### [53] [Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion](https://arxiv.org/abs/2509.06296)
*Francisco Affonso,Felipe Andrade G. Tommaselli,Juliano Negri,Vivian S. Medeiros,Mateus V. Gasparino,Girish Chowdhary,Marcelo Becker*

Main category: cs.RO

TL;DR: 传统RL控制器数据效率低，本文提出基于模型的强化学习框架，通过合成数据提升四足机器人运动的样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于强化学习的运动控制器样本效率低的问题。

Method: 采用基于模型的强化学习（MBRL）框架，结合Dyna-Style方法生成合成数据，并通过策略更新迭代逐步整合这些数据。

Result: 实验验证显示，合成数据不仅能模拟更长的rollout，还能提升策略回报并降低方差，同时减少实际模拟步骤的需求。

Conclusion: 该方法能有效提升样本效率，并广泛应用于多种运动命令的跟踪。

Abstract: Traditional RL-based locomotion controllers often suffer from low data
efficiency, requiring extensive interaction to achieve robust performance. We
present a model-based reinforcement learning (MBRL) framework that improves
sample efficiency for quadrupedal locomotion by appending synthetic data to the
end of standard rollouts in PPO-based controllers, following the Dyna-Style
paradigm. A predictive model, trained alongside the policy, generates
short-horizon synthetic transitions that are gradually integrated using a
scheduling strategy based on the policy update iterations. Through an ablation
study, we identified a strong correlation between sample efficiency and rollout
length, which guided the design of our experiments. We validated our approach
in simulation on the Unitree Go1 robot and showed that replacing part of the
simulated steps with synthetic ones not only mimics extended rollouts but also
improves policy return and reduces variance. Finally, we demonstrate that this
improvement transfers to the ability to track a wide range of locomotion
commands using fewer simulated steps.

</details>


### [54] [Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots](https://arxiv.org/abs/2509.06342)
*Filip Bjelonic,Fabian Tischhauser,Marco Hutter*

Main category: cs.RO

TL;DR: 该论文提出了一种结合仿真到现实强化学习与物理基础能量模型的框架，提升了腿式机器人的能效和鲁棒性，并在多个平台上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高腿式机器人在真实环境中的实用性和能效，解决仿真控制器在现实中失效的问题，并简化复杂的奖励设计。

Method: 结合仿真到现实强化学习与基于永磁同步电机的物理能量模型，采用简化的四项奖励函数和能量损失公式。

Result: 在多个平台上验证了方法的有效性，实现了ANYmal整体运输成本降低32%（值为1.27）。

Conclusion: 提出的框架显著提升了腿式机器人的能效和鲁棒性，且无需复杂的参数随机化。

Abstract: Legged robots must achieve both robust locomotion and energy efficiency to be
practical in real-world environments. Yet controllers trained in simulation
often fail to transfer reliably, and most existing approaches neglect
actuator-specific energy losses or depend on complex, hand-tuned reward
formulations. We propose a framework that integrates sim-to-real reinforcement
learning with a physics-grounded energy model for permanent magnet synchronous
motors. The framework requires a minimal parameter set to capture the
simulation-to-reality gap and employs a compact four-term reward with a
first-principle-based energetic loss formulation that balances electrical and
mechanical dissipation. We evaluate and validate the approach through a
bottom-up dynamic parameter identification study, spanning actuators,
full-robot in-air trajectories and on-ground locomotion. The framework is
tested on three primary platforms and deployed on ten additional robots,
demonstrating reliable policy transfer without randomization of dynamic
parameters. Our method improves energetic efficiency over state-of-the-art
methods, achieving a 32 percent reduction in the full Cost of Transport of
ANYmal (value 1.27). All code, models, and datasets will be released.

</details>


### [55] [Adaptive Evolution Factor Risk Ellipse Framework for Reliable and Safe Autonomous Driving](https://arxiv.org/abs/2509.06375)
*Fujiang Yuan,Zhen Tian,Yangfan He,Guojian Zou,Chunhong Yuan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 论文提出了一种名为ERPF的动态风险评估方法，结合Risk-Ellipse和自适应Evolution Factor，通过MPC框架实现自动驾驶的平滑、高效和无碰撞导航。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如博弈论或鲁棒控制）保守或计算量大，而基于学习的方法需要大量数据且解释性差。RPF方法轻量但静态，无法适应动态交通。为解决这些问题，提出了ERPF。

Method: 提出Evolutionary Risk Potential Field (ERPF)，结合Risk-Ellipse和自适应Evolution Factor（基于TTC和TWH），并与MPC框架集成。

Result: 实验表明，ERPF-MPC在复杂交互驾驶场景中表现优越，轨迹更平滑、速度更高且无碰撞。

Conclusion: ERPF-MPC为复杂交互驾驶环境提供了鲁棒且自适应的解决方案。

Abstract: In recent years, ensuring safety, efficiency, and comfort in interactive
autonomous driving has become a critical challenge. Traditional model-based
techniques, such as game-theoretic methods and robust control, are often overly
conservative or computationally intensive. Conversely, learning-based
approaches typically require extensive training data and frequently exhibit
limited interpretability and generalizability. Simpler strategies, such as Risk
Potential Fields (RPF), provide lightweight alternatives with minimal data
demands but are inherently static and struggle to adapt effectively to dynamic
traffic conditions. To overcome these limitations, we propose the Evolutionary
Risk Potential Field (ERPF), a novel approach that dynamically updates risk
assessments in dynamical scenarios based on historical obstacle proximity data.
We introduce a Risk-Ellipse construct that combines longitudinal reach and
lateral uncertainty into a unified spatial temporal collision envelope.
Additionally, we define an adaptive Evolution Factor metric, computed through
sigmoid normalization of Time to Collision (TTC) and Time-Window-of-Hazard
(TWH), which dynamically adjusts the dimensions of the ellipse axes in real
time. This adaptive risk metric is integrated seamlessly into a Model
Predictive Control (MPC) framework, enabling autonomous vehicles to proactively
address complex interactive driving scenarios in terms of uncertain driving of
surrounding vehicles. Comprehensive comparative experiments demonstrate that
our ERPF-MPC approach consistently achieves smoother trajectories, higher
average speeds, and collision-free navigation, offering a robust and adaptive
solution suitable for complex interactive driving environments.

</details>


### [56] [Safety Meets Speed: Accelerated Neural MPC with Safety Guarantees and No Retraining](https://arxiv.org/abs/2509.06404)
*Kaikai Wang,Tianxun Li,Liang Xu,Qinglei Hu,Keyou You*

Main category: cs.RO

TL;DR: BAN-MPC框架结合神经网络的快速计算与MPC的约束处理能力，通过CBF确保安全性，减少计算复杂度。实验显示其比传统MPC快200倍，适合嵌入式应用。


<details>
  <summary>Details</summary>
Motivation: 解决传统MPC在实时执行时计算资源消耗大的问题，同时确保严格的安全性。

Method: 提出BAN-MPC，结合神经网络与MPC，使用CBF替代欧氏距离，并通过神经价值函数减少在线计算。

Result: 在Jetson Nano上，BAN-MPC比传统MPC快200倍，控制误差低于5%，适应参数变化。

Conclusion: BAN-MPC是一种高效的嵌入式MPC替代方案，适合实时安全控制。

Abstract: While Model Predictive Control (MPC) enforces safety via constraints, its
real-time execution can exceed embedded compute budgets. We propose a
Barrier-integrated Adaptive Neural Model Predictive Control (BAN-MPC) framework
that synergizes neural networks' fast computation with MPC's
constraint-handling capability. To ensure strict safety, we replace traditional
Euclidean distance with Control Barrier Functions (CBFs) for collision
avoidance. We integrate an offline-learned neural value function into the
optimization objective of a Short-horizon MPC, substantially reducing online
computational complexity. Additionally, we use a second neural network to learn
the sensitivity of the value function to system parameters, and adaptively
adjust the neural value function based on this neural sensitivity when model
parameters change, eliminating the need for retraining and reducing offline
computation costs. The hardware in-the-loop (HIL) experiments on Jetson Nano
show that BAN-MPC solves 200 times faster than traditional MPC, enabling
collision-free navigation with control error below 5\% under model parameter
variations within 15\%, making it an effective embedded MPC alternative.

</details>


### [57] [Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation](https://arxiv.org/abs/2509.06433)
*Ian Page,Pierre Susbielle,Olivier Aycard,Pierre-Brice Wieber*

Main category: cs.RO

TL;DR: 提出了一种基于高斯分割SLAM的高效GPU集成方法，显著提升了未知环境中的远程遥控效率。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，高效远程遥控需要快速理解环境布局，传统在线地图方法因计算成本高导致性能不佳。

Method: 结合高斯分割SLAM与现有在线地图系统，采用模块化GPU集成，实现高效且逼真的3D地图生成。

Result: 实验显示，该系统提高了决策速度和环境交互准确性，提升了遥控效率。

Conclusion: 该系统通过实时逼真地图生成，有效提升了未知环境中的遥控性能。

Abstract: Achieving efficient remote teleoperation is particularly challenging in
unknown environments, as the teleoperator must rapidly build an understanding
of the site's layout. Online 3D mapping is a proven strategy to tackle this
challenge, as it enables the teleoperator to progressively explore the site
from multiple perspectives. However, traditional online map-based teleoperation
systems struggle to generate visually accurate 3D maps in real-time due to the
high computational cost involved, leading to poor teleoperation performances.
In this work, we propose a solution to improve teleoperation efficiency in
unknown environments. Our approach proposes a novel, modular and efficient
GPU-based integration between recent advancement in gaussian splatting SLAM and
existing online map-based teleoperation systems. We compare the proposed
solution against state-of-the-art teleoperation systems and validate its
performances through real-world experiments using an aerial vehicle. The
results show significant improvements in decision-making speed and more
accurate interaction with the environment, leading to greater teleoperation
efficiency. In doing so, our system enhances remote teleoperation by seamlessly
integrating photorealistic mapping generation with real-time performances,
enabling effective teleoperation in unfamiliar environments.

</details>


### [58] [Interactive Shaping of Granular Media Using Reinforcement Learning](https://arxiv.org/abs/2509.06469)
*Benedikt Kreis,Malte Mosbach,Anny Ripke,Muhammad Ehsan Ullah,Sven Behnke,Maren Bennewitz*

Main category: cs.RO

TL;DR: 摘要描述了如何利用强化学习框架训练机器人手臂操纵颗粒介质（如沙子），以克服传统方法在高维配置空间和复杂动态中的挑战，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 颗粒介质的自主操纵在建筑、挖掘和增材制造中至关重要，但其高维配置空间和复杂动态使传统方法难以应对，需探索更高效的策略。

Method: 采用强化学习框架，通过机器人手臂（配备立方体末端执行器和立体相机）学习操纵颗粒介质的目标结构，强调紧凑观测和简洁奖励设计的重要性。

Result: 实验结果表明，该方法在训练视觉策略和实际部署中优于两种基线方法，并通过消融研究验证了设计选择。

Conclusion: 强化学习框架为颗粒介质的操纵提供了有效解决方案，尤其在视觉策略训练和实际应用中表现出色。

Abstract: Autonomous manipulation of granular media, such as sand, is crucial for
applications in construction, excavation, and additive manufacturing. However,
shaping granular materials presents unique challenges due to their
high-dimensional configuration space and complex dynamics, where traditional
rule-based approaches struggle without extensive engineering efforts.
Reinforcement learning (RL) offers a promising alternative by enabling agents
to learn adaptive manipulation strategies through trial and error. In this
work, we present an RL framework that enables a robotic arm with a cubic
end-effector and a stereo camera to shape granular media into desired target
structures. We show the importance of compact observations and concise reward
formulations for the large configuration space, validating our design choices
with an ablation study. Our results demonstrate the effectiveness of the
proposed approach for the training of visual policies that manipulate granular
media including their real-world deployment, outperforming two baseline
approaches.

</details>


### [59] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 论文提出了一种基于事件驱动的通信机制（ED-CBBA），以减少多机器人任务分配中的通信负担，同时保持CBBA的性能和收敛性。


<details>
  <summary>Details</summary>
Motivation: 在多无人机监视和搜救等场景中，高效的任务分配算法至关重要，但CBBA的连续通信需求可能导致网络拥塞和数据包丢失。

Method: 引入了事件驱动的通信机制，减少不必要的通信，同时确保任务分配的收敛性和性能。

Result: 理论证明ED-CBBA与CBBA具有相同的解质量，实验显示消息传输减少了52%。

Conclusion: ED-CBBA在减少通信负担的同时，保持了CBBA的性能，适用于资源受限的多机器人系统。

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [60] [Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization](https://arxiv.org/abs/2509.06582)
*Carlos A. Pinheiro de Sousa,Niklas Gröne,Mathias Günther,Oliver Deussen*

Main category: cs.RO

TL;DR: 提出了一种多用户VR共位框架，结合运动捕捉与SLAM跟踪，实现低延迟、高帧率的同步虚拟环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖外部跟踪（导致延迟）或一次性标定（无法纠正漂移）的问题。

Method: 结合HMD SLAM跟踪与外部源实时对齐，支持设备间实时姿态共享。

Result: 框架在空间准确性、舒适度、可扩展性和鲁棒性上优于现有共位VR方案。

Conclusion: 该框架为多用户自然交互提供了高效且灵活的解决方案。

Abstract: We introduce a multi-user VR co-location framework that synchronizes users
within a shared virtual environment aligned to physical space. Our approach
combines a motion capture system with SLAM-based inside-out tracking to deliver
smooth, high-framerate, low-latency performance. Previous methods either rely
on continuous external tracking, which introduces latency and jitter, or on
one-time calibration, which cannot correct drift over time. In contrast, our
approach combines the responsiveness of local HMD SLAM tracking with the
flexibility to realign to an external source when needed. It also supports
real-time pose sharing across devices, ensuring consistent spatial alignment
and engagement between users. Our evaluation demonstrates that our framework
achieves the spatial accuracy required for natural multi-user interaction while
offering improved comfort, scalability, and robustness over existing co-located
VR solutions.

</details>


### [61] [A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling](https://arxiv.org/abs/2509.06593)
*Meher V. R. Malladi,Tiziano Guadagnino,Luca Lobefaro,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 提出了一种不依赖传感器特定建模的鲁棒激光雷达-惯性里程计系统，简化了IMU集成并结合扫描到地图的LiDAR注册方法，提升了里程计性能，并在多种数据集上验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器人导航中精确的里程计是关键组件，但现有方法通常依赖传感器特定建模，限制了其泛化能力。需要一种适用于不同传感器和场景的鲁棒里程计方案。

Method: 采用简化的IMU集成运动模型，直接通过扫描到地图的方式注册LiDAR数据，并提出新的LiDAR注册正则化方法。

Result: 在多种数据集上验证了方法的鲁棒性，能够以相同配置适应不同传感器和场景，显著提升里程计性能。

Conclusion: 提出的方法无需传感器特定建模，具有高鲁棒性和泛化能力，已开源以促进进一步研究和应用。

Abstract: Accurate odometry is a critical component in a robotic navigation stack, and
subsequent modules such as planning and control often rely on an estimate of
the robot's motion. Sensor-based odometry approaches should be robust across
sensor types and deployable in different target domains, from solid-state
LiDARs mounted on cars in urban-driving scenarios to spinning LiDARs on
handheld packages used in unstructured natural environments. In this paper, we
propose a robust LiDAR-inertial odometry system that does not rely on
sensor-specific modeling. Sensor fusion techniques for LiDAR and inertial
measurement unit (IMU) data typically integrate IMU data iteratively in a
Kalman filter or use pre-integration in a factor graph framework, combined with
LiDAR scan matching often exploiting some form of feature extraction. We
propose an alternative strategy that only requires a simplified motion model
for IMU integration and directly registers LiDAR scans in a scan-to-map
approach. Our approach allows us to impose a novel regularization on the LiDAR
registration, improving the overall odometry performance. We detail extensive
experiments on a number of datasets covering a wide array of commonly used
robotic sensors and platforms. We show that our approach works with the exact
same configuration in all these scenarios, demonstrating its robustness. We
have open-sourced our implementation so that the community can build further on
our work and use it in their navigation stacks.

</details>


### [62] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: LiHRA是一个新颖的数据集，旨在支持人机交互（HRI）场景中自动化、学习型或经典风险监测（RM）方法的开发，填补了高质量数据集缺乏的空白。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人在工业环境中的普及，对可靠安全系统的需求增加，但缺乏捕捉真实人机互动的高质量数据集阻碍了发展。

Method: LiHRA提供了多模态数据集，结合3D LiDAR点云、人体关键点和机器人关节状态，记录了协作任务的完整空间和动态上下文。

Result: 数据集包含4,431个标记点云，覆盖六种HRI场景，支持训练和基准测试，并提出了一种基于上下文信息的RM方法。

Conclusion: LiHRA为实时风险监测和自适应安全策略提供了重要基础，推动了人机工作空间中的安全研究。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>


### [63] [T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation](https://arxiv.org/abs/2509.06644)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 该论文提出了一种名为T-araVLN的方法，通过翻译模块提升农业机器人对复杂指令的理解能力，显著提高了导航性能。


<details>
  <summary>Details</summary>
Motivation: 当前农业机器人依赖人工操作或固定轨道移动，AgriVLN方法虽能处理简单指令，但对复杂指令理解不足。

Method: 提出T-araVLN方法，通过指令翻译模块将原始指令优化为更精确的版本。

Result: 在A2A基准测试中，SR从0.47提升到0.63，NE从2.91m降至2.28m，性能显著提升。

Conclusion: T-araVLN在农业机器人视觉语言导航领域实现了最先进的性能。

Abstract: Agricultural robotic agents have been becoming powerful helpers in a wide
range of agricultural tasks, nevertheless, still heavily rely on manual
operation or untransportable railway for movement. The AgriVLN method and the
A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the
agricultural domain, enabling agents navigate to the target position following
the natural language instructions. AgriVLN effectively understands the simple
instructions, however, often misunderstands the complicated instructions. To
bridge this gap, we propose the method of Translator for Agricultural Robotic
Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction
Translator module translates the original instruction to be both refined and
precise. Being evaluated on the A2A benchmark, our T-araVLN effectively
improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating
the state-of-the-art performance in the agricultural domain. Code:
https://github.com/AlexTraveling/T-araVLN.

</details>


### [64] [An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields](https://arxiv.org/abs/2509.06682)
*Sajad Ahmadi,Mohammadreza Davoodi,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 提出了一种用于动态农业环境的自适应覆盖控制方法，通过无人机实时检测障碍物和地形变化，指导地面车辆动态调整路径。


<details>
  <summary>Details</summary>
Motivation: 传统覆盖控制方法假设静态环境，无法应对农业场景中移动障碍物和复杂地形的挑战。

Method: 结合无人机观测实时更新加权有向图模型，采用Voronoi分区、自适应边权分配和基于成本的路径优化。

Result: 仿真结果显示方法能有效优化路径规划，降低移动成本，并在动态障碍和泥泞地形中保持覆盖效果。

Conclusion: 该方法为动态农业环境中的车辆覆盖控制提供了高效解决方案。

Abstract: This paper presents an adaptive coverage control method for a fleet of
off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic
(time-varying) agricultural environments. Traditional coverage control
approaches often assume static conditions, making them unsuitable for
real-world farming scenarios where obstacles, such as moving machinery and
uneven terrains, create continuous challenges. To address this, we propose a
real-time path planning framework that integrates Unmanned Aerial Vehicles
(UAVs) for obstacle detection and terrain assessment, allowing UGVs to
dynamically adjust their coverage paths. The environment is modeled as a
weighted directed graph, where the edge weights are continuously updated based
on the UAV observations to reflect obstacle motion and terrain variations. The
proposed approach incorporates Voronoi-based partitioning, adaptive edge weight
assignment, and cost-based path optimization to enhance navigation efficiency.
Simulation results demonstrate the effectiveness of the proposed method in
improving path planning, reducing traversal costs, and maintaining robust
coverage in the presence of dynamic obstacles and muddy terrains.

</details>


### [65] [Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways](https://arxiv.org/abs/2509.06687)
*Sajad Ahmadi,Hossein Nejatbakhsh Esfahani,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出了一种结合鲁棒模型预测控制（RMPC）和控制屏障函数（CBFs）的新型运动规划方法，用于自动水面船舶（ASVs）在内陆水道的安全导航。


<details>
  <summary>Details</summary>
Motivation: 内陆水道中的自动导航可以缓解交通拥堵和减少排放，但现有方法在狭窄水道和高密度交通环境下缺乏鲁棒性和精确性。

Method: 采用RMPC和CBFs的结合方法，将水道边界和障碍物作为安全约束纳入控制设计框架。

Result: 仿真结果表明，该方法在复杂水道环境下能有效避免碰撞并实现鲁棒导航，安全性和适应性优于现有技术。

Conclusion: 所提出的方法在自动水面船舶的安全导航中表现出显著的性能提升，适用于复杂的内陆水道环境。

Abstract: Deploying self-navigating surface vessels in inland waterways offers a
sustainable alternative to reduce road traffic congestion and emissions.
However, navigating confined waterways presents unique challenges, including
narrow channels, higher traffic density, and hydrodynamic disturbances.
Existing methods for autonomous vessel navigation often lack the robustness or
precision required for such environments. This paper presents a new motion
planning approach for Automated Surface Vessels (ASVs) using Robust Model
Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By
incorporating channel borders and obstacles as safety constraints within the
control design framework, the proposed method ensures both collision avoidance
and robust navigation on complex waterways. Simulation results demonstrate the
efficacy of the proposed method in safely guiding ASVs under realistic
conditions, highlighting its improved safety and adaptability compared to the
state-of-the-art.

</details>


### [66] [Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](https://arxiv.org/abs/2509.06768)
*Oluwadamilola Sotomi,Devika Kodi,Kiruthiga Chandra Shekar,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文提出了一种多模态异常检测与缓解系统，结合视觉语言模型和大语言模型，实时识别和应对动态环境中的异常情况。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，自主机器人需识别并报告异常以确保安全性和操作连续性。

Method: 系统融合视觉语言模型和大语言模型，将危险和冲突状态纳入机器人决策框架，触发特定缓解策略。

Result: 用户研究（n=30）显示，系统异常检测准确率达91.2%，响应延迟低。

Conclusion: 该系统通过主动检测和自动缓解机制，有效提升了机器人在动态环境中的安全性和操作能力。

Abstract: Autonomous robots operating in dynamic environments should identify and
report anomalies. Embodying proactive mitigation improves safety and
operational continuity. This paper presents a multimodal anomaly detection and
mitigation system that integrates vision-language models and large language
models to identify and report hazardous situations and conflicts in real-time.
The proposed system enables robots to perceive, interpret, report, and if
possible respond to urban and environmental anomalies through proactive
detection mechanisms and automated mitigation actions. A key contribution in
this paper is the integration of Hazardous and Conflict states into the robot's
decision-making framework, where each anomaly type can trigger specific
mitigation strategies. User studies (n = 30) demonstrated the effectiveness of
the system in anomaly detection with 91.2% prediction accuracy and relatively
low latency response times using edge-ai architecture.

</details>


### [67] [CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](https://arxiv.org/abs/2509.06819)
*Daniel San José Pro,Oliver Hausdörfer,Ralf Römer,Maximilian Dösch,Martin Schuck,Angela P. Schöllig*

Main category: cs.RO

TL;DR: CRISP 是一个轻量级的 C++ 实现，支持 ROS2 控制标准，用于实现平滑的 Cartesian 和关节空间控制，适用于学习型控制器和远程操作。


<details>
  <summary>Details</summary>
Motivation: 解决学习型控制器生成的低频或不连续状态变化问题，需要低级控制器实现平滑参考跟踪和接触交互的兼容性。

Method: 开发了 CRISP，兼容 ROS2 控制标准，支持 Python 和 Gymnasium 接口，统一了数据记录和策略部署流程。

Result: 在 Franka Robotics FR3 硬件和 Kuka IIWA14 与 Kinova Gen3 仿真中验证，实现了快速集成和高性能。

Conclusion: CRISP 提供了学习型方法在 ROS2 兼容机械臂上的快速应用，降低了实验门槛。

Abstract: Learning-based controllers, such as diffusion policies and vision-language
action models, often generate low-frequency or discontinuous robot state
changes. Achieving smooth reference tracking requires a low-level controller
that converts high-level targets commands into joint torques, enabling
compliant behavior during contact interactions. We present CRISP, a lightweight
C++ implementation of compliant Cartesian and joint-space controllers for the
ROS2 control standard, designed for seamless integration with high-level
learning-based policies as well as teleoperation. The controllers are
compatible with any manipulator that exposes a joint-torque interface. Through
our Python and Gymnasium interfaces, CRISP provides a unified pipeline for
recording data from hardware and simulation and deploying high-level
learning-based policies seamlessly, facilitating rapid experimentation. The
system has been validated on hardware with the Franka Robotics FR3 and in
simulation with the Kuka IIWA14 and Kinova Gen3. Designed for rapid
integration, flexible deployment, and real-time performance, our implementation
provides a unified pipeline for data collection and policy execution, lowering
the barrier to applying learning-based methods on ROS2-compatible manipulators.
Detailed documentation is available at the project website -
https://utiasDSL.github.io/crisp_controllers.

</details>


### [68] [Dynamic Modeling and Efficient Data-Driven Optimal Control for Micro Autonomous Surface Vehicles](https://arxiv.org/abs/2509.06882)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种结合物理驱动模型和数据驱动最优控制的框架，用于提升微型自主水面车辆（MicroASV）在复杂环境中的精确控制能力。


<details>
  <summary>Details</summary>
Motivation: 微型自主水面车辆在狭窄或浅水区域的应用潜力巨大，但由于非线性水动力建模困难和环境干扰敏感性问题，其精确控制仍具挑战性。

Method: 论文提出了一种基于物理驱动的动力学模型，并结合数据驱动的最优控制框架，利用弱公式化的在线模型学习方法实时优化模型。

Result: 仿真结果表明，该方法显著提高了轨迹跟踪的准确性和鲁棒性，即使面对未知负载和外部干扰。

Conclusion: 数据驱动的在线学习最优控制为MicroASV的性能提升提供了有效途径，有望推动更可靠和精确的自主操作。

Abstract: Micro Autonomous Surface Vehicles (MicroASVs) offer significant potential for
operations in confined or shallow waters and swarm robotics applications.
However, achieving precise and robust control at such small scales remains
highly challenging, mainly due to the complexity of modeling nonlinear
hydrodynamic forces and the increased sensitivity to self-motion effects and
environmental disturbances, including waves and boundary effects in confined
spaces. This paper presents a physics-driven dynamics model for an
over-actuated MicroASV and introduces a data-driven optimal control framework
that leverages a weak formulation-based online model learning method. Our
approach continuously refines the physics-driven model in real time, enabling
adaptive control that adjusts to changing system parameters. Simulation results
demonstrate that the proposed method substantially enhances trajectory tracking
accuracy and robustness, even under unknown payloads and external disturbances.
These findings highlight the potential of data-driven online learning-based
optimal control to improve MicroASV performance, paving the way for more
reliable and precise autonomous surface vehicle operations.

</details>


### [69] [LLaDA-VLA: Vision Language Diffusion Action Models](https://arxiv.org/abs/2509.06932)
*Yuqing Wen,Hebei Li,Kefan Gu,Yucheng Zhao,Tiancai Wang,Xiaoyan Sun*

Main category: cs.RO

TL;DR: LLaDA-VLA是一个基于预训练扩散视觉语言模型的首个视觉-语言-扩散-动作模型，用于机器人操作。


<details>
  <summary>Details</summary>
Motivation: 利用扩散模型在文本生成和多模态应用中的竞争性能，探索其在机器人策略学习中的应用。

Method: 引入了局部特殊令牌分类策略和分层动作结构化解码策略，以适配机器人领域。

Result: LLaDA-VLA在模拟和真实机器人实验中显著优于现有方法。

Conclusion: 该方法成功地将扩散模型应用于机器人操作领域，展示了其潜力。

Abstract: The rapid progress of auto-regressive vision-language models (VLMs) has
inspired growing interest in vision-language-action models (VLA) for robotic
manipulation. Recently, masked diffusion models, a paradigm distinct from
autoregressive models, have begun to demonstrate competitive performance in
text generation and multimodal applications, leading to the development of a
series of diffusion-based VLMs (d-VLMs). However, leveraging such models for
robot policy learning remains largely unexplored. In this work, we present
LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon
pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to
robotic domain, we introduce two key designs: (1) a localized special-token
classification strategy that replaces full-vocabulary classification with
special action token classification, reducing adaptation difficulty; (2) a
hierarchical action-structured decoding strategy that decodes action sequences
hierarchically considering the dependencies within and across actions.
Extensive experiments demonstrate that LLaDA-VLA significantly outperforms
state-of-the-art VLAs on both simulation and real-world robots.

</details>


### [70] [F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](https://arxiv.org/abs/2509.06951)
*Qi Lv,Weijie Kong,Hao Li,Jia Zeng,Zherui Qiu,Delin Qu,Haoming Song,Qizhi Chen,Xiang Deng,Jiangmiao Pang*

Main category: cs.RO

TL;DR: F1是一个预训练的视觉语言动作（VLA）框架，通过集成视觉前瞻生成到决策流程中，解决了动态视觉环境中语言条件任务的执行问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型多为反应式状态到动作的映射，导致短视行为和动态场景中的鲁棒性差，F1旨在解决这一问题。

Method: F1采用混合Transformer架构，包含感知、前瞻生成和控制模块，通过目标条件视觉前瞻预测机制实现规划。

Result: F1在现实任务和仿真基准测试中优于现有方法，显著提升了任务成功率和泛化能力。

Conclusion: F1通过视觉前瞻预测和模块化训练，显著提高了在动态环境中的决策能力和鲁棒性。

Abstract: Executing language-conditioned tasks in dynamic visual environments remains a
central challenge in embodied AI. Existing Vision-Language-Action (VLA) models
predominantly adopt reactive state-to-action mappings, often leading to
short-sighted behaviors and poor robustness in dynamic scenes. In this paper,
we introduce F1, a pretrained VLA framework which integrates the visual
foresight generation into decision-making pipeline. F1 adopts a
Mixture-of-Transformer architecture with dedicated modules for perception,
foresight generation, and control, thereby bridging understanding, generation,
and actions. At its core, F1 employs a next-scale prediction mechanism to
synthesize goal-conditioned visual foresight as explicit planning targets. By
forecasting plausible future visual states, F1 reformulates action generation
as a foresight-guided inverse dynamics problem, enabling actions that
implicitly achieve visual goals. To endow F1 with robust and generalizable
capabilities, we propose a three-stage training recipe on an extensive dataset
comprising over 330k trajectories across 136 diverse tasks. This training
scheme enhances modular reasoning and equips the model with transferable visual
foresight, which is critical for complex and dynamic environments. Extensive
evaluations on real-world tasks and simulation benchmarks demonstrate F1
consistently outperforms existing approaches, achieving substantial gains in
both task success rate and generalization ability.

</details>


### [71] [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](https://arxiv.org/abs/2509.06953)
*Jiahui Yang,Jason Jingzhou Liu,Yulong Li,Youssef Khaky,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: DRP是一种视觉运动神经运动策略，专为在动态环境中生成反应性运动而设计，结合了预训练和微调技术，显著提升了成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决动态、部分可观察环境中机器人操作器生成无碰撞运动的难题，传统方法在动态场景中效率低下，而现有神经策略在复杂环境中泛化能力不足。

Method: 提出DRP，基于点云输入，核心是预训练的IMPACT模型，结合迭代师生微调和动态障碍物避免模块DCP-RMP。

Result: 在模拟和真实环境中，DRP在成功率和泛化能力上优于现有经典和神经方法。

Conclusion: DRP展示了在复杂动态环境中高效生成反应性运动的潜力，为机器人运动规划提供了新思路。

Abstract: Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [72] [Graph Neural Networks for Resource Allocation in Interference-limited Multi-Channel Wireless Networks with QoS Constraints](https://arxiv.org/abs/2509.06395)
*Lili Chen,Changyang She,Jingge Zhu,Jamie Evans*

Main category: cs.LG

TL;DR: 论文提出了一种结合GNN和拉格朗日优化的框架JCPGNN-M，用于满足无线网络中的QoS约束，其性能与eWMMSE相当但计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法难以保证QoS约束的理论收敛性，且计算复杂度高。

Method: 扩展WMMSE算法到多通道设置（eWMMSE），并开发基于GNN和拉格朗日优化的JCPGNN-M算法。

Result: JCPGNN-M在性能上与eWMMSE相当，同时提高了推理速度和泛化能力。

Conclusion: 该研究为未来无线网络中约束资源分配提供了可扩展且理论可靠的方法。

Abstract: Meeting minimum data rate constraints is a significant challenge in wireless
communication systems, particularly as network complexity grows. Traditional
deep learning approaches often address these constraints by incorporating
penalty terms into the loss function and tuning hyperparameters empirically.
However, this heuristic treatment offers no theoretical convergence guarantees
and frequently fails to satisfy QoS requirements in practical scenarios.
Building upon the structure of the WMMSE algorithm, we first extend it to a
multi-channel setting with QoS constraints, resulting in the enhanced WMMSE
(eWMMSE) algorithm, which is provably convergent to a locally optimal solution
when the problem is feasible. To further reduce computational complexity and
improve scalability, we develop a GNN-based algorithm, JCPGNN-M, capable of
supporting simultaneous multi-channel allocation per user. To overcome the
limitations of traditional deep learning methods, we propose a principled
framework that integrates GNN with a Lagrangian-based primal-dual optimization
method. By training the GNN within the Lagrangian framework, we ensure
satisfaction of QoS constraints and convergence to a stationary point.
Extensive simulations demonstrate that JCPGNN-M matches the performance of
eWMMSE while offering significant gains in inference speed, generalization to
larger networks, and robustness under imperfect channel state information. This
work presents a scalable and theoretically grounded solution for constrained
resource allocation in future wireless networks.

</details>


### [73] [Information-Theoretic Bounds and Task-Centric Learning Complexity for Real-World Dynamic Nonlinear Systems](https://arxiv.org/abs/2509.06599)
*Sri Satish Krishna Chaitanya Bulusu,Mikko Sillanpää*

Main category: cs.LG

TL;DR: 论文提出了一种基于结构化分解、方差分析和任务中心复杂度界限的理论框架，用于解决动态非线性系统中的静动态耦合问题，并提出了行为不确定性原则。


<details>
  <summary>Details</summary>
Motivation: 动态非线性系统中静动态效应的耦合带来失真，传统数据驱动建模面临重大挑战。

Method: 采用结构化分解、方差分析、任务中心复杂度界限，并引入方向性下界和内存有限性指标。

Result: 提出了行为不确定性原则，验证了静动态失真无法同时最小化，并建立了函数方差与学习复杂度的联系。

Conclusion: 该框架为复杂动态非线性系统建模提供了理论基础，解释了结构化残差学习的经验优势。

Abstract: Dynamic nonlinear systems exhibit distortions arising from coupled static and
dynamic effects. Their intertwined nature poses major challenges for
data-driven modeling. This paper presents a theoretical framework grounded in
structured decomposition, variance analysis, and task-centric complexity
bounds.
  The framework employs a directional lower bound on interactions between
measurable system components, extending orthogonality in inner product spaces
to structurally asymmetric settings. This bound supports variance inequalities
for decomposed systems. Key behavioral indicators are introduced along with a
memory finiteness index. A rigorous power-based condition establishes a
measurable link between finite memory in realizable systems and the First Law
of Thermodynamics. This offers a more foundational perspective than classical
bounds based on the Second Law.
  Building on this foundation, we formulate a `Behavioral Uncertainty
Principle,' demonstrating that static and dynamic distortions cannot be
minimized simultaneously. We identify that real-world systems seem to resist
complete deterministic decomposition due to entangled static and dynamic
effects. We also present two general-purpose theorems linking function variance
to mean-squared Lipschitz continuity and learning complexity. This yields a
model-agnostic, task-aware complexity metric, showing that lower-variance
components are inherently easier to learn.
  These insights explain the empirical benefits of structured residual
learning, including improved generalization, reduced parameter count, and lower
training cost, as previously observed in power amplifier linearization
experiments. The framework is broadly applicable and offers a scalable,
theoretically grounded approach to modeling complex dynamic nonlinear systems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [74] [Time-domain sound field estimation using kernel ridge regression](https://arxiv.org/abs/2509.05720)
*Jesper Brunnström,Martin Bo Møller,Jan Østergaard,Shoichi Koyama,Toon van Waterschoot,Marc Moonen*

Main category: eess.AS

TL;DR: 该论文将基于核岭回归的声场估计方法扩展到离散时间声场，提供了时域声场估计，并利用时域数据加权和方向性加权来提升估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅限于单频声场，限制了数据和先验知识的利用。本文将方法扩展到时域声场，以解决更广泛的声场估计问题。

Method: 提出了一种基于核岭回归的时域声场估计方法，通过时域数据加权和方向性加权结合物理可实现性约束，提升估计性能。

Result: 实验表明，时域数据加权和方向性加权结合能有效提升声场估计性能，并适用于更广泛的声场估计问题。

Conclusion: 本文方法扩展了核岭回归的应用范围，为考虑时域响应的声场估计问题提供了有效解决方案。

Abstract: Sound field estimation methods based on kernel ridge regression have proven
effective, allowing for strict enforcement of physical properties, in addition
to the inclusion of prior knowledge such as directionality of the sound field.
These methods have been formulated for single-frequency sound fields,
restricting the types of data and prior knowledge that can be used. In this
paper, the kernel ridge regression approach is generalized to consider
discrete-time sound fields. The proposed method provides time-domain sound
field estimates that can be computed in closed form, are guaranteed to be
physically realizable, and for which time-domain properties of the sound fields
can be exploited to improve estimation performance. Exploiting prior
information on the time-domain behaviour of room impulse responses, the
estimation performance of the proposed method is shown to be improved using a
time-domain data weighting, demonstrating the usefulness of the proposed
approach. It is further shown using both simulated and real data that the
time-domain data weighting can be combined with a directional weighting,
exploiting prior knowledge of both spatial and temporal properties of the room
impulse responses. The theoretical framework of the proposed method enables
solving a broader class of sound field estimation problems using kernel ridge
regression where it would be required to consider the time-domain response
rather than the frequency-domain response of each frequency separately.

</details>


### [75] [Integrating Spatial and Semantic Embeddings for Stereo Sound Event Localization in Videos](https://arxiv.org/abs/2509.06598)
*Davide Berghi,Philip J. B. Jackson*

Main category: eess.AS

TL;DR: 本文提出了一种结合语义信息的多模态方法，用于立体声事件定位与检测任务（3D SELD），通过预训练模型提升性能，并在竞赛中取得了第二名。


<details>
  <summary>Details</summary>
Motivation: 传统的SELD方法依赖多通道输入，受限于数据规模，无法充分利用大规模预训练。本文旨在通过引入语义信息（音频和视觉的预训练模型）来提升性能。

Method: 采用预训练的CLAP（音频）和OWL-ViT（视觉）模型，结合改进的Conformer模块（Cross-Modal Conformer）进行多模态融合。通过数据增强和模型集成进一步优化。

Result: 在DCASE2025 Task3 Stereo SELD数据集上取得第二名，验证了方法的有效性。

Conclusion: 结合预训练模型和多模态融合的方法有效提升了3D SELD任务的性能，未来将探索模块贡献和架构优化。

Abstract: In this study, we address the multimodal task of stereo sound event
localization and detection with source distance estimation (3D SELD) in regular
video content. 3D SELD is a complex task that combines temporal event
classification with spatial localization, requiring reasoning across spatial,
temporal, and semantic dimensions. The last is arguably the most challenging to
model. Traditional SELD approaches typically rely on multichannel input,
limiting their capacity to benefit from large-scale pre-training due to data
constraints. To overcome this, we enhance a standard SELD architecture with
semantic information by integrating pre-trained, contrastive language-aligned
models: CLAP for audio and OWL-ViT for visual inputs. These embeddings are
incorporated into a modified Conformer module tailored for multimodal fusion,
which we refer to as the Cross-Modal Conformer. We perform an ablation study on
the development set of the DCASE2025 Task3 Stereo SELD Dataset to assess the
individual contributions of the language-aligned models and benchmark against
the DCASE Task 3 baseline systems. Additionally, we detail the curation process
of large synthetic audio and audio-visual datasets used for model pre-training.
These datasets were further expanded through left-right channel swapping
augmentation. Our approach, combining extensive pre-training, model ensembling,
and visual post-processing, achieved second rank in the DCASE 2025 Challenge
Task 3 (Track B), underscoring the effectiveness of our method. Future work
will explore the modality-specific contributions and architectural refinements.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [76] [Stereovision Image Processing for Planetary Navigation Maps with Semi-Global Matching and Superpixel Segmentation](https://arxiv.org/abs/2509.05645)
*Yan-Shan Lu,Miguel Arana-Catania,Saurabh Upadhyay,Leonard Felicetti*

Main category: astro-ph.IM

TL;DR: 论文提出了一种结合半全局匹配（SGM）和超像素优化的方法，用于改善火星地形建模中的深度图精度，解决了传统块匹配在低纹理和遮挡区域的不足。


<details>
  <summary>Details</summary>
Motivation: 火星探索需要高精度地形模型以保障探测车安全导航，传统块匹配方法在低纹理和遮挡区域表现不佳，因此需要更高效且上下文感知的方法。

Method: 采用半全局匹配（SGM）结合超像素优化，平衡效率与精度，并通过上下文分割提升深度推理的一致性。

Result: 在三个数据集上验证，显示地形结构一致性提升，岩石后的间隙减少，细节捕捉更准确，适用于火星自主导航。

Conclusion: 该方法为未来行星探索任务提供了一条完整的建模流程，显著改善了深度图的精度和一致性。

Abstract: Mars exploration requires precise and reliable terrain models to ensure safe
rover navigation across its unpredictable and often hazardous landscapes.
Stereoscopic vision serves a critical role in the rover's perception, allowing
scene reconstruction by generating precise depth maps through stereo matching.
State-of-the-art Martian planetary exploration uses traditional local
block-matching, aggregates cost over square windows, and refines disparities
via smoothness constraints. However, this method often struggles with
low-texture images, occlusion, and repetitive patterns because it considers
only limited neighbouring pixels and lacks a wider understanding of scene
context. This paper uses Semi-Global Matching (SGM) with superpixel-based
refinement to mitigate the inherent block artefacts and recover lost details.
The approach balances the efficiency and accuracy of SGM and adds context-aware
segmentation to support more coherent depth inference. The proposed method has
been evaluated in three datasets with successful results: In a Mars analogue,
the terrain maps obtained show improved structural consistency, particularly in
sloped or occlusion-prone regions. Large gaps behind rocks, which are common in
raw disparity outputs, are reduced, and surface details like small rocks and
edges are captured more accurately. Another two datasets, evaluated to test the
method's general robustness and adaptability, show more precise disparity maps
and more consistent terrain models, better suited for the demands of autonomous
navigation on Mars, and competitive accuracy across both non-occluded and
full-image error metrics. This paper outlines the entire terrain modelling
process, from finding corresponding features to generating the final 2D
navigation maps, offering a complete pipeline suitable for integration in
future planetary exploration missions.

</details>


### [77] [Advancing Resource Extraction Systems in Martian Volcanic Terrain: Rover Design, Power Consumption and Hazard Analysis](https://arxiv.org/abs/2509.06103)
*Divij Gupta,Arkajit Aich*

Main category: astro-ph.IM

TL;DR: 论文提出了一种在火星火山地形中利用原位资源（ISRU）的方案，研究了火山地形的复杂性和环境危险，并提出了工程策略，包括斜坡稳定方法和地形自适应漫游车设计。


<details>
  <summary>Details</summary>
Motivation: 为了解决在火星火山地区进行采矿任务的复杂地质和环境挑战，研究旨在设计一种能够适应极端环境且具备高度自主性的采矿系统。

Method: 研究提出了斜坡稳定方法（如阶梯化和锚定钻机）和地形自适应漫游车设计，结合太阳能和核能供电，并进行道路与轨道运输基础设施的比较分析。

Result: 结果表明，任务成功依赖于机械韧性、环境适应能力和操作自主性的结合，确保了在火星最具挑战性的地质环境中可持续获取资源。

Conclusion: 研究验证了提出的采矿方案在火星火山地形中的可行性，强调了多技术集成的必要性。

Abstract: This study proposes a schematic plan for in-situ resource utilization (ISRU)
in Martian volcanic terrains. The work investigated the complexity of volcanic
terrains and Martian environmental hazards and suggested comprehensive
engineering strategies to overcome the odds and establish a successful mining
program in Martian volcanic regions. Slope stabilization methods - such as
terracing and anchored drilling rigs - with terrain-adaptive rovers capable of
autonomous operations on steep unstable slopes has been suggested as feasible
solutions to navigate the complex geological terrains of Martian volcanoes. The
mid range rover design with a mass of approximately 2.1 t, proposed here for
mining operations, incorporates a six-wheel rocker-bogie suspension,
anchoring-enabled drilling arm, dust-mitigation solar arrays, and advanced
sensing systems for hazard detection and navigation. A comparative analysis
regarding choice of roads and rails for building transport infrastructure has
also been performed. We have also looked into the energy requirement of the
rover to work under extreme environmental conditions of Mars and suggested a
combination of solar and nuclear power to account for the huge energy
requirements of sustained operations on Mars. The results demonstrate that
mission success in these environments depends on integrating mechanical
resilience, environmental adaptability, and operational autonomy, enabling
sustainable access to resources in one of Mars' most geologically challenging
settings.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [78] [Distributed Automatic Generation Control subject to Ramp-Rate-Limits: Anytime Feasibility and Uniform Network-Connectivity](https://arxiv.org/abs/2509.06588)
*Mohammadreza Doostmohammadian,Hamid R. Rabiee*

Main category: eess.SY

TL;DR: 本文研究了基于信息共享网络的发电机组自动生成控制，提出了一种多智能体系统优化方法，解决了现有线性/非线性优化方案中忽略的爬坡率限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有优化方案常忽略发电机组的爬坡率限制，导致实际中无法完全遵循优化算法的功率分配，影响收敛性和可行性。

Method: 通过分布式信息共识算法，结合爬坡率限制、功率限制和供需平衡约束，确保算法在每次迭代中都满足可行性。

Result: 提出的方案在保证实时供需平衡的同时，支持通信链路失效的容忍性，并通过引入内部符号非线性提高了收敛速度。

Conclusion: 该方法有效解决了爬坡率限制问题，提升了优化算法的实用性和收敛性。

Abstract: This paper considers automatic generation control over an information-sharing
network of communicating generators as a multi-agent system. The optimization
solution is distributed among the agents based on information consensus
algorithms, while addressing the generators' ramp-rate-limits (RRL). This is
typically ignored in the existing linear/nonlinear optimization solutions but
they exist in real-time power generation scenarios. Without addressing the RRL,
the generators cannot follow the assigned rate of generating power by the
optimization algorithm; therefore, the existing solutions may not necessarily
converge to the exact optimal cost or may lose feasibility in practice. The
proposed solution in this work addresses the ramp-rate-limit constraint along
with the box constraint (limits on the generated powers) and the
coupling-constraint (generation-demand balance) at all iteration times of the
algorithm. The latter is referred to as the anytime feasibility and implies
that at every termination point of the algorithm, the balance between the
demand and generated power holds. To improve the convergence rate of the
algorithm we further consider internal signum-based nonlinearity. We also show
that our solution can tolerate communication link removal. This follows from
the uniform-connectivity assumption on the communication network.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [79] [Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory](https://arxiv.org/abs/2509.05337)
*Younggeol Cho,Gokhan Solak,Olivia Nocentini,Marta Lorenzini,Andrea Fortuna,Arash Ajoudani*

Main category: cs.CV

TL;DR: 本文提出了一种结合动态图神经网络（DGNN）和长短期记忆网络（LSTM）的混合模型，用于预测人体跌倒状态，并通过实时骨骼特征输入实现高精度早期检测。


<details>
  <summary>Details</summary>
Motivation: 人类跌倒的检测与预防是辅助机器人系统的关键部分，但目前对跌倒前的预测及稳定性与即将跌倒之间的过渡状态分析尚未充分探索。

Method: 采用DGNN作为分类器区分稳定、过渡和跌倒三种步态状态，LSTM网络预测后续时间步的人体运动，实现早期跌倒检测。模型基于OUMVLP-Pose和URFD数据集训练验证。

Result: 模型在预测误差和识别准确性上优于仅依赖DGNN的模型和文献中的其他模型，表明解耦预测和分类任务能提升性能。

Conclusion: 该方法不仅提高了跌倒预测的准确性，还能监测过渡状态，为高级辅助系统提供有价值的洞察。

Abstract: Detecting and preventing falls in humans is a critical component of assistive
robotic systems. While significant progress has been made in detecting falls,
the prediction of falls before they happen, and analysis of the transient state
between stability and an impending fall remain unexplored. In this paper, we
propose a anticipatory fall detection method that utilizes a hybrid model
combining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory
(LSTM) networks that decoupled the motion prediction and gait classification
tasks to anticipate falls with high accuracy. Our approach employs real-time
skeletal features extracted from video sequences as input for the proposed
model. The DGNN acts as a classifier, distinguishing between three gait states:
stable, transient, and fall. The LSTM-based network then predicts human
movement in subsequent time steps, enabling early detection of falls. The
proposed model was trained and validated using the OUMVLP-Pose and URFD
datasets, demonstrating superior performance in terms of prediction error and
recognition accuracy compared to models relying solely on DGNN and models from
literature. The results indicate that decoupling prediction and classification
improves performance compared to addressing the unified problem using only the
DGNN. Furthermore, our method allows for the monitoring of the transient state,
offering valuable insights that could enhance the functionality of advanced
assistance systems.

</details>


### [80] [Quaternion Approximation Networks for Enhanced Image Classification and Oriented Object Detection](https://arxiv.org/abs/2509.05512)
*Bryce Grant,Peng Wang*

Main category: cs.CV

TL;DR: QUAN是一种新型深度学习框架，利用四元数代数实现旋转等变的图像分类和目标检测，通过实数运算近似四元数卷积，提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决旋转等变任务中传统方法的局限性，QUAN通过四元数代数提供更高效的几何特征处理方案。

Method: 采用Hamilton乘积分解实现四元数卷积的实数近似，引入IQBN稳定训练，并扩展了空间注意力机制。

Result: 在分类和检测任务中，QUAN在精度、参数效率和收敛速度上优于传统方法，并在四元数CNN中达到SOTA。

Conclusion: QUAN在资源受限的机器人系统中具有部署潜力，适合需要旋转感知的应用场景。

Abstract: This paper introduces Quaternion Approximate Networks (QUAN), a novel deep
learning framework that leverages quaternion algebra for rotation equivariant
image classification and object detection. Unlike conventional quaternion
neural networks attempting to operate entirely in the quaternion domain, QUAN
approximates quaternion convolution through Hamilton product decomposition
using real-valued operations. This approach preserves geometric properties
while enabling efficient implementation with custom CUDA kernels. We introduce
Independent Quaternion Batch Normalization (IQBN) for training stability and
extend quaternion operations to spatial attention mechanisms. QUAN is evaluated
on image classification (CIFAR-10/100, ImageNet), object detection (COCO,
DOTA), and robotic perception tasks. In classification tasks, QUAN achieves
higher accuracy with fewer parameters and faster convergence compared to
existing convolution and quaternion-based models. For objection detection, QUAN
demonstrates improved parameter efficiency and rotation handling over standard
Convolutional Neural Networks (CNNs) while establishing the SOTA for quaternion
CNNs in this downstream task. These results highlight its potential for
deployment in resource-constrained robotic systems requiring rotation-aware
perception and application in other domains.

</details>


### [81] [OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation](https://arxiv.org/abs/2509.05513)
*Ahad Jawaid,Yu Xiang*

Main category: cs.CV

TL;DR: OpenEgo是一个多模态的自我中心操作数据集，提供了标准化的手部姿势注释和意图对齐的动作基元，以支持从自我中心视频学习的可重复研究。


<details>
  <summary>Details</summary>
Motivation: 现有的自我中心视频数据集通常缺乏细粒度、时间定位的动作描述或灵巧的手部注释，OpenEgo旨在解决这一问题。

Method: OpenEgo整合了六个公共数据集，统一手部姿势布局并提供描述性、带时间戳的动作基元，用于训练语言条件模仿学习策略。

Result: 数据集包含1107小时的视频，覆盖290个操作任务和600多个环境，验证了其效用。

Conclusion: OpenEgo降低了从自我中心视频学习灵巧操作的障碍，并支持愿景-语言-动作学习的可重复研究。

Abstract: Egocentric human videos provide scalable demonstrations for imitation
learning, but existing corpora often lack either fine-grained, temporally
localized action descriptions or dexterous hand annotations. We introduce
OpenEgo, a multimodal egocentric manipulation dataset with standardized
hand-pose annotations and intention-aligned action primitives. OpenEgo totals
1107 hours across six public datasets, covering 290 manipulation tasks in 600+
environments. We unify hand-pose layouts and provide descriptive, timestamped
action primitives. To validate its utility, we train language-conditioned
imitation-learning policies to predict dexterous hand trajectories. OpenEgo is
designed to lower the barrier to learning dexterous manipulation from
egocentric video and to support reproducible research in vision-language-action
learning. All resources and instructions will be released at
www.openegocentric.com.

</details>


### [82] [SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning](https://arxiv.org/abs/2509.05614)
*Hanzhen Wang,Jiaming Xu,Jiayi Pan,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: 论文提出了一种名为SpecPrune-VLA的训练无关方法，通过结合局部和全局信息进行两级剪枝，显著提升计算效率且几乎不影响任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉-语言-动作（VLA）模型中仅利用局部信息剪枝令牌，导致成功率下降和速度提升有限。作者观察到连续动作间的高相似性，提出结合局部和全局信息以优化剪枝。

Method: SpecPrune-VLA采用两级剪枝：静态（动作级别，基于全局历史和局部上下文）和动态（层级别，基于层重要性）。此外，轻量级动作感知控制器根据动作类型（粗/细粒度）调整剪枝强度。

Result: 在LIBERO数据集上，SpecPrune-VLA在NVIDIA A800和RTX 3090上的速度分别提升至OpenVLA-OFT的1.46倍和1.57倍，成功率损失可忽略。

Conclusion: 结合局部和全局信息的剪枝策略显著提升了VLA模型的计算效率，同时保持了任务成功率。

Abstract: Pruning accelerates compute-bound models by reducing computation. Recently
applied to Vision-Language-Action (VLA) models, existing methods prune tokens
using only local info from current action, ignoring global context from prior
actions, causing >20% success rate drop and limited speedup. We observe high
similarity across consecutive actions and propose leveraging both local
(current) and global (past) info for smarter token selection. We introduce
SpecPrune-VLA, a training-free method with two-level pruning and heuristic
control: (1) Static pruning at action level: uses global history and local
context to reduce visual tokens per action; (2) Dynamic pruning at layer level:
prunes tokens per layer based on layer-specific importance; (3) Lightweight
action-aware controller: classifies actions as coarse/fine-grained (by speed),
adjusting pruning aggressiveness since fine-grained actions are
pruning-sensitive. Experiments on LIBERO show SpecPrune-VLA achieves 1.46 times
speedup on NVIDIA A800 and 1.57 times on NVIDIA GeForce RTX 3090 vs.
OpenVLA-OFT, with negligible success rate loss.

</details>


### [83] [LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction](https://arxiv.org/abs/2509.05728)
*Niels Balemans,Ali Anwar,Jan Steckel,Siegfried Mercelis*

Main category: cs.CV

TL;DR: 该论文扩展了LiDAR-BIND框架，引入时间一致性机制，提升多模态传感器融合的时空一致性，优化下游SLAM性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态传感器（雷达、声纳）与LiDAR融合时的时间一致性问题，以提升SLAM的鲁棒性和性能。

Method: 提出三种机制：(i)时间嵌入相似性对齐连续潜在空间，(ii)运动对齐变换损失匹配预测与LiDAR真值位移，(iii)专用时间模块实现窗口时间融合。

Result: 实验显示在雷达/声纳到LiDAR的翻译任务中，时空一致性显著提升，降低了绝对轨迹误差，提高了SLAM的占用图精度。

Conclusion: LiDAR-BIND-T在保持即插即用多模态融合的同时，显著增强了时间稳定性，提升了SLAM的鲁棒性和性能。

Abstract: This paper extends LiDAR-BIND, a modular multi-modal fusion framework that
binds heterogeneous sensors (radar, sonar) to a LiDAR-defined latent space,
with mechanisms that explicitly enforce temporal consistency. We introduce
three contributions: (i) temporal embedding similarity that aligns consecutive
latents, (ii) a motion-aligned transformation loss that matches displacement
between predictions and ground truth LiDAR, and (iii) windows temporal fusion
using a specialised temporal module. We further update the model architecture
to better preserve spatial structure. Evaluations on radar/sonar-to-LiDAR
translation demonstrate improved temporal and spatial coherence, yielding lower
absolute trajectory error and better occupancy map accuracy in
Cartographer-based SLAM (Simultaneous Localisation and Mapping). We propose
different metrics based on the Fr\'echet Video Motion Distance (FVMD) and a
correlation-peak distance metric providing practical temporal quality
indicators to evaluate SLAM performance. The proposed temporal LiDAR-BIND, or
LiDAR-BIND-T, maintains plug-and-play modality fusion while substantially
enhancing temporal stability, resulting in improved robustness and performance
for downstream SLAM.

</details>


### [84] [InterAct: A Large-Scale Dataset of Dynamic, Expressive and Interactive Activities between Two People in Daily Scenarios](https://arxiv.org/abs/2509.05747)
*Leo Ho,Yinghao Huang,Dafei Qin,Mingyi Shi,Wangpok Tse,Wei Liu,Junichi Yamagishi,Taku Komura*

Main category: cs.CV

TL;DR: 论文提出了一种新方法，用于准确捕捉日常场景中两个人之间的动态交互行为，并发布了多模态数据集InterAct。


<details>
  <summary>Details</summary>
Motivation: 解决现有研究中仅关注单人行为或静态交互的问题，目标是建模动态、语义一致的长时间交互。

Method: 提出了基于扩散的层次回归方法，从语音输入估计交互式面部表情和身体动作，并设计了微调机制以提高唇部准确性。

Result: 发布了包含241个动态序列的InterAct数据集，展示了多样化的复杂交互模式，并验证了方法的有效性。

Conclusion: 该方法为动态交互行为研究提供了新工具和数据支持，代码和数据已开源。

Abstract: We address the problem of accurate capture of interactive behaviors between
two people in daily scenarios. Most previous works either only consider one
person or solely focus on conversational gestures of two people, assuming the
body orientation and/or position of each actor are constant or barely change
over each interaction. In contrast, we propose to simultaneously model two
people's activities, and target objective-driven, dynamic, and semantically
consistent interactions which often span longer duration and cover bigger
space. To this end, we capture a new multi-modal dataset dubbed InterAct, which
is composed of 241 motion sequences where two people perform a realistic and
coherent scenario for one minute or longer over a complete interaction. For
each sequence, two actors are assigned different roles and emotion labels, and
collaborate to finish one task or conduct a common interaction activity. The
audios, body motions, and facial expressions of both persons are captured.
InterAct contains diverse and complex motions of individuals and interesting
and relatively long-term interaction patterns barely seen before. We also
demonstrate a simple yet effective diffusion-based method that estimates
interactive face expressions and body motions of two people from speech inputs.
Our method regresses the body motions in a hierarchical manner, and we also
propose a novel fine-tuning mechanism to improve the lip accuracy of facial
expressions. To facilitate further research, the data and code is made
available at https://hku-cg.github.io/interact/ .

</details>


### [85] [Multi-Modal Camera-Based Detection of Vulnerable Road Users](https://arxiv.org/abs/2509.06333)
*Penelope Brown,Julie Stephany Berrio Perez,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 论文提出了一种融合RGB和热红外成像的多模态检测框架，用于提升弱势道路使用者（VRUs）的检测效果。


<details>
  <summary>Details</summary>
Motivation: 弱势道路使用者（如行人、骑行者和摩托车手）在全球交通死亡中占比超过一半，但在光线不足、恶劣天气和不平衡数据集下检测仍然具有挑战性。

Method: 使用微调的YOLOv8模型集成RGB和热红外成像，训练数据包括KITTI、BDD100K和Teledyne FLIR数据集，采用类别重新加权和轻度增强提升少数类性能和鲁棒性。实验表明，640像素分辨率和部分主干冻结优化了准确性和效率，类别加权损失提高了稀有VRUs的召回率。

Result: 热红外模型实现了最高精度，RGB到热红外的数据增强提升了召回率，展示了多模态检测在提升交叉路口VRU安全性方面的潜力。

Conclusion: 多模态检测框架通过结合RGB和热红外成像，显著提升了VRUs检测的准确性和召回率，有望改善交通安全。

Abstract: Vulnerable road users (VRUs) such as pedestrians, cyclists, and motorcyclists
represent more than half of global traffic deaths, yet their detection remains
challenging in poor lighting, adverse weather, and unbalanced data sets. This
paper presents a multimodal detection framework that integrates RGB and thermal
infrared imaging with a fine-tuned YOLOv8 model. Training leveraged KITTI,
BDD100K, and Teledyne FLIR datasets, with class re-weighting and light
augmentations to improve minority-class performance and robustness, experiments
show that 640-pixel resolution and partial backbone freezing optimise accuracy
and efficiency, while class-weighted losses enhance recall for rare VRUs.
Results highlight that thermal models achieve the highest precision, and
RGB-to-thermal augmentation boosts recall, demonstrating the potential of
multimodal detection to improve VRU safety at intersections.

</details>


### [86] [Investigating Location-Regularised Self-Supervised Feature Learning for Seafloor Visual Imagery](https://arxiv.org/abs/2509.06660)
*Cailei Liang,Adrian Bodenmann,Emma J Curtis,Samuel Simmons,Kazunori Nagano,Stan Brown,Adam Riese,Blair Thornton*

Main category: cs.CV

TL;DR: 研究了位置元数据在不同自监督学习（SSL）策略中对海床图像分类的影响，结果表明位置正则化能显著提升性能，尤其是在低维潜在表示中。


<details>
  <summary>Details</summary>
Motivation: 提高海床视觉图像的高通量解释效率，探索位置元数据在自监督学习中的作用。

Method: 评估了六种SSL框架（包括CNN和ViT模型）在三种海床图像数据集上的表现，分析了位置正则化的效果。

Result: 位置正则化平均提升了CNN和ViT的F1分数，尤其是在低维潜在表示中；高维ViT表现出强泛化能力。

Conclusion: 位置元数据对SSL正则化有价值，特别是低维表示；高维ViT在海床图像分析中表现出优异的泛化性能。

Abstract: High-throughput interpretation of robotically gathered seafloor visual
imagery can increase the efficiency of marine monitoring and exploration.
Although recent research has suggested that location metadata can enhance
self-supervised feature learning (SSL), its benefits across different SSL
strategies, models and seafloor image datasets are underexplored. This study
evaluates the impact of location-based regularisation on six state-of-the-art
SSL frameworks, which include Convolutional Neural Network (CNN) and Vision
Transformer (ViT) models with varying latent-space dimensionality. Evaluation
across three diverse seafloor image datasets finds that location-regularisation
consistently improves downstream classification performance over standard SSL,
with average F1-score gains of $4.9 \pm 4.0%$ for CNNs and $6.3 \pm 8.9%$ for
ViTs, respectively. While CNNs pretrained on generic datasets benefit from
high-dimensional latent representations, dataset-optimised SSL achieves similar
performance across the high (512) and low (128) dimensional latent
representations. Location-regularised SSL improves CNN performance over
pre-trained models by $2.7 \pm 2.7%$ and $10.1 \pm 9.4%$ for high and
low-dimensional latent representations, respectively. For ViTs,
high-dimensionality benefits both pre-trained and dataset-optimised SSL.
Although location-regularisation improves SSL performance compared to standard
SSL methods, pre-trained ViTs show strong generalisation, matching the
best-performing location-regularised SSL with F1-scores of $0.795 \pm 0.075$
and $0.795 \pm 0.077$, respectively. The findings highlight the value of
location metadata for SSL regularisation, particularly when using
low-dimensional latent representations, and demonstrate strong generalisation
of high-dimensional ViTs for seafloor image analysis.

</details>


### [87] [Online Clustering of Seafloor Imagery for Interpretation during Long-Term AUV Operations](https://arxiv.org/abs/2509.06678)
*Cailei Liang,Adrian Bodenmann,Sam Fenton,Blair Thornton*

Main category: cs.CV

TL;DR: 该论文提出了一种在线聚类框架（OCF），用于实时无监督解析海底图像，适用于自适应任务和高效通信。实验表明，OCF在三个数据集上表现最佳，F1分数达0.68，且计算时间稳定。


<details>
  <summary>Details</summary>
Motivation: 随着长续航和海底驻留AUV的发展，需要实时解析海底图像以支持自适应任务和优化通信效率。传统方法依赖完整数据集和人工标注，无法满足实时需求。

Method: 提出OCF框架，通过代表性样本动态捕捉特征分布，支持实时聚类，无需重新处理历史数据，并实现了动态簇合并与分裂。

Result: OCF在三个数据集上平均F1分数为0.68，计算时间随数据量增加保持稳定，优于其他在线聚类方法。

Conclusion: OCF适用于长期自主海洋探索，能高效生成数据摘要并支持路径规划，具有鲁棒性和扩展性。

Abstract: As long-endurance and seafloor-resident AUVs become more capable, there is an
increasing need for extended, real-time interpretation of seafloor imagery to
enable adaptive missions and optimise communication efficiency. Although
offline image analysis methods are well established, they rely on access to
complete datasets and human-labelled examples to manage the strong influence of
environmental and operational conditions on seafloor image
appearance-requirements that cannot be met in real-time settings. To address
this, we introduce an online clustering framework (OCF) capable of interpreting
seafloor imagery without supervision, which is designed to operate in real-time
on continuous data streams in a scalable, adaptive, and self-consistent manner.
The method enables the efficient review and consolidation of common patterns
across the entire data history in constant time by identifying and maintaining
a set of representative samples that capture the evolving feature distribution,
supporting dynamic cluster merging and splitting without reprocessing the full
image history. We evaluate the framework on three diverse seafloor image
datasets, analysing the impact of different representative sampling strategies
on both clustering accuracy and computational cost. The OCF achieves the
highest average F1 score of 0.68 across the three datasets among all
comparative online clustering approaches, with a standard deviation of 3%
across three distinct survey trajectories, demonstrating its superior
clustering capability and robustness to trajectory variation. In addition, it
maintains consistently lower and bounded computational time as the data volume
increases. These properties are beneficial for generating survey data summaries
and supporting informative path planning in long-term, persistent autonomous
marine exploration.

</details>


### [88] [Event Spectroscopy: Event-based Multispectral and Depth Sensing using Structured Light](https://arxiv.org/abs/2509.06741)
*Christian Geckeler,Niklas Neugebauer,Manasi Muglikar,Davide Scaramuzza,Stefano Mintchev*

Main category: cs.CV

TL;DR: 提出了一种新型事件光谱系统，用于无人机在森林环境中实现高分辨率、低延迟的深度重建和多光谱成像。


<details>
  <summary>Details</summary>
Motivation: 解决传统传感方法在森林环境中存在的延迟、深度分辨率差和对环境光依赖性强的问题。

Method: 通过调制结构化光的波长，同时进行深度重建和多光谱成像，覆盖650 nm至850 nm波段。

Result: 实验显示深度重建误差降低60%，光谱精度与商用设备相当，深度数据辅助材料分类精度提升30%。

Conclusion: 该系统为无人机在复杂自然环境中的轻量、集成和鲁棒感知与数据收集提供了可行性。

Abstract: Uncrewed aerial vehicles (UAVs) are increasingly deployed in forest
environments for tasks such as environmental monitoring and search and rescue,
which require safe navigation through dense foliage and precise data
collection. Traditional sensing approaches, including passive multispectral and
RGB imaging, suffer from latency, poor depth resolution, and strong dependence
on ambient light - especially under forest canopies. In this work, we present a
novel event spectroscopy system that simultaneously enables high-resolution,
low-latency depth reconstruction and multispectral imaging using a single
sensor. Depth is reconstructed using structured light, and by modulating the
wavelength of the projected structured light, our system captures spectral
information in controlled bands between 650 nm and 850 nm. We demonstrate up to
$60\%$ improvement in RMSE over commercial depth sensors and validate the
spectral accuracy against a reference spectrometer and commercial multispectral
cameras, demonstrating comparable performance. A portable version limited to
RGB (3 wavelengths) is used to collect real-world depth and spectral data from
a Masoala Rainforest. We demonstrate the use of this prototype for color image
reconstruction and material differentiation between leaves and branches using
spectral and depth data. Our results show that adding depth (available at no
extra effort with our setup) to material differentiation improves the accuracy
by over $30\%$ compared to color-only method. Our system, tested in both lab
and real-world rainforest environments, shows strong performance in depth
estimation, RGB reconstruction, and material differentiation - paving the way
for lightweight, integrated, and robust UAV perception and data collection in
complex natural environments.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [89] [Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster](https://arxiv.org/abs/2509.06426)
*Pembe Gizem Özdil,Chuanfang Ning,Jasper S. Phelps,Sibo Wang-Chen,Guy Elisha,Alexander Blanke,Auke Ijspeert,Pavan Ramdya*

Main category: q-bio.NC

TL;DR: 该论文首次提出了果蝇腿部的3D数据驱动肌肉骨骼模型，结合OpenSim和MuJoCo模拟环境，用于研究电机控制并预测肌肉协同作用。


<details>
  <summary>Details</summary>
Motivation: 尽管果蝇的中枢神经系统、肌肉和外骨骼已近完全重建，但缺乏基于解剖和物理的腿部肌肉模型，这些模型是连接运动神经元活动和关节运动的桥梁。

Method: 利用高分辨率X射线扫描和多标本数据，构建Hill型肌肉模型，并结合3D姿态估计数据实现肌肉驱动的行为重放。在MuJoCo中训练模仿学习策略。

Result: 模型成功预测了多种行为中的肌肉协同作用，并验证了被动关节特性对学习速度的影响。

Conclusion: 该模型为研究果蝇的电机控制提供了新工具，揭示了生物力学在复杂肢体运动中的作用，并可应用于人工代理的自然运动生成。

Abstract: Computational models are critical to advance our understanding of how neural,
biomechanical, and physical systems interact to orchestrate animal behaviors.
Despite the availability of near-complete reconstructions of the Drosophila
melanogaster central nervous system, musculature, and exoskeleton, anatomically
and physically grounded models of fly leg muscles are still missing. These
models provide an indispensable bridge between motor neuron activity and joint
movements. Here, we introduce the first 3D, data-driven musculoskeletal model
of Drosophila legs, implemented in both OpenSim and MuJoCo simulation
environments. Our model incorporates a Hill-type muscle representation based on
high-resolution X-ray scans from multiple fixed specimens. We present a
pipeline for constructing muscle models using morphological imaging data and
for optimizing unknown muscle parameters specific to the fly. We then combine
our musculoskeletal models with detailed 3D pose estimation data from behaving
flies to achieve muscle-actuated behavioral replay in OpenSim. Simulations of
muscle activity across diverse walking and grooming behaviors predict
coordinated muscle synergies that can be tested experimentally. Furthermore, by
training imitation learning policies in MuJoCo, we test the effect of different
passive joint properties on learning speed and find that damping and stiffness
facilitate learning. Overall, our model enables the investigation of motor
control in an experimentally tractable model organism, providing insights into
how biomechanics contribute to generation of complex limb movements. Moreover,
our model can be used to control embodied artificial agents to generate
naturalistic and compliant locomotion in simulated environments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [90] [MAPF-HD: Multi-Agent Path Finding in High-Density Environments](https://arxiv.org/abs/2509.06374)
*Hiroya Makino,Seigo Ito*

Main category: cs.MA

TL;DR: 论文提出了一种高密度环境下的多智能体路径规划框架（MAPF-HD），通过PHANS方法解决了传统整数线性规划（ILP）方法计算时间长的问题，显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 在高密度环境中（如自动化仓库），传统ILP方法因计算时间长而不实用，需要一种更高效的路径规划方法。

Method: 提出了PHANS方法，通过启发式交换智能体与空位位置，逐步优化路径。

Result: PHANS方法在大规模环境中（超过700个单元）能在几秒至几十秒内解决问题，显著快于ILP方法。

Conclusion: PHANS方法高效实用，适用于仓库物流、交通管理等现实应用。

Abstract: Multi-agent path finding (MAPF) involves planning efficient paths for
multiple agents to move simultaneously while avoiding collisions. In typical
warehouse environments, agents are often sparsely distributed along aisles.
However, increasing the agent density can improve space efficiency. When the
agent density is high, we must optimize the paths not only for goal-assigned
agents but also for those obstructing them. This study proposes a novel MAPF
framework for high-density environments (MAPF-HD). Several studies have
explored MAPF in similar settings using integer linear programming (ILP).
However, ILP-based methods require substantial computation time to optimize all
agent paths simultaneously. Even in small grid-based environments with fewer
than $100$ cells, these computations can incur tens to hundreds of seconds.
These high computational costs render these methods impractical for large-scale
applications such as automated warehouses and valet parking. To address these
limitations, we introduce the phased null-agent swapping (PHANS) method. PHANS
employs a heuristic approach to incrementally swap positions between agents and
empty vertices. This method solves the MAPF-HD problem within seconds to tens
of seconds, even in large environments containing more than $700$ cells. The
proposed method can potentially improve efficiency in various real-world
applications such as warehouse logistics, traffic management, or crowd control.
Code is available at https://github.com/ToyotaCRDL/MAPF-in-High-Density-Envs.

</details>


### [91] [Nanobot Algorithms for Treatment of Diffuse Cancer](https://arxiv.org/abs/2509.06893)
*Noble Harasha,Nancy Lynch*

Main category: cs.MA

TL;DR: 研究探讨了‘纳米机器人’在多处癌症扩散情况下通过协调投放药物来治疗的效果，提出了三种算法（KM、KMA、KMAR），其中KMAR表现最佳，具有强适应性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 纳米机器人因其尺度小和精准性，有望实现更有效且毒性更低的靶向药物递送。本研究旨在解决多处扩散癌症的治疗问题。

Method: 提出了一种数学模型描述纳米机器人和胶体环境行为，并基于实验设计了三种算法：KM（自然信号跟随）、KMA（增强信号）、KMAR（抑制信号）。

Result: KM在信号弱时治疗速度慢；KMA速度提升但成功率下降；KMAR在所有癌症模式下表现优异。

Conclusion: KMAR算法在适应性和治疗成功率上表现出色，为扩散癌症治疗提供了可靠方案。

Abstract: Motile nanosized particles, or "nanobots", promise more effective and less
toxic targeted drug delivery because of their unique scale and precision. We
consider the case in which the cancer is "diffuse", dispersed such that there
are multiple distinct cancer sites. We investigate the problem of a swarm of
nanobots locating these sites and treating them by dropping drug payloads at
the sites. To improve the success of the treatment, the drug payloads must be
allocated between sites according to their "demands"; this requires extra
nanobot coordination. We present a mathematical model of the behavior of the
nanobot agents and of their colloidal environment. This includes a movement
model for agents based upon experimental findings from actual nanoparticles in
which bots noisily ascend and descend chemical gradients. We present three
algorithms: The first algorithm, called KM, is the most representative of
reality, with agents simply following naturally existing chemical signals that
surround each cancer site. The second algorithm, KMA, includes an additional
chemical payload which amplifies the existing natural signals. The third
algorithm, KMAR, includes another additional chemical payload which counteracts
the other signals, instead inducing negative chemotaxis in agents such that
they are repelled from sites that are already sufficiently treated. We present
simulation results for all algorithms across different types of cancer
arrangements. For KM, we show that the treatment is generally successful unless
the natural chemical signals are weak, in which case the treatment progresses
too slowly. For KMA, we demonstrate a significant improvement in treatment
speed but a drop in eventual success, except for concentrated cancer patterns.
For KMAR, our results show great performance across all types of cancer
patterns, demonstrating robustness and adaptability.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [92] ["It was Tragic": Exploring the Impact of a Robot's Shutdown](https://arxiv.org/abs/2509.06934)
*Agam Oberlender,Hadas Erel*

Main category: cs.HC

TL;DR: 研究表明，人们倾向于将机器人视为社交实体，即使是未设计用于社交互动的机器人。实验发现，机器人的关机动作会影响其感知和评价。


<details>
  <summary>Details</summary>
Motivation: 探讨人们对机器人关机动作的社交解读及其对机器人感知的影响。

Method: 参与者与机器人互动后，分别在两种条件下关闭机器人：一种是直接关机，另一种是模仿'睡觉'的动作关机。

Result: 直接关机的动作被负面解读为'死亡'，而模仿睡觉的动作则被中性解读为'睡觉'，后者提高了好感度、智能感和生命力感知。

Conclusion: 设计机器人关机动作时应考虑人们的社交感知倾向，以提升用户体验。

Abstract: It is well established that people perceive robots as social entities, even
when they are not designed for social interaction. We evaluated whether the
social interpretation of robotic gestures should also be considered when
turning off a robot. In the experiment, participants engaged in a brief
preliminary neutral interaction while a robotic arm showed interest in their
actions. At the end of the task, participants were asked to turn off the
robotic arm under two conditions: (1) a Non-designed condition, where all of
the robot's engines were immediately and simultaneously turned off, as robots
typically shut down; (2) a Designed condition, where the robot's engines
gradually folded inward in a motion resembling "falling asleep." Our findings
revealed that all participants anthropomorphized the robot's movement when it
was turned off. In the Non-designed condition, most participants interpreted
the robot's turn-off movement negatively, as if the robot had "died." In the
Designed condition, most participants interpreted it more neutrally, stating
that the robot "went to sleep." The robot's turn-off movement also impacted its
perception, leading to higher likeability, perceived intelligence, and animacy
in the Designed condition. We conclude that the impact of common edge
interactions, such as turning off a robot, should be carefully designed while
considering people's automatic tendency to perceive robots as social entities.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [93] [Beyond Diagonal IRS Aided OFDM: Rate Maximization under Frequency-Dependent Reflection](https://arxiv.org/abs/2509.06378)
*Ye Yuan,Shuowen Zhang*

Main category: cs.IT

TL;DR: 本文研究了基于超对角智能反射面(BD-IRS)的宽带正交频分复用(OFDM)系统，探讨了BD-IRS反射矩阵在不同子载波间的耦合效应，并提出了一种联合优化算法以提高系统性能。


<details>
  <summary>Details</summary>
Motivation: BD-IRS的反射矩阵在实际电路结构中依赖于电路参数和工作频率，导致不同子载波间的反射矩阵耦合，增加了设计难度。研究旨在解决这一问题并优化系统性能。

Method: 通过建模BD-IRS反射矩阵与可调电容矩阵的关系，采用交替优化和逐次凸逼近算法，联合优化可调电容矩阵和OFDM子载波的功率分配。

Result: 数值仿真表明，所提出的算法在提升系统可达速率方面优于基准设计。

Conclusion: BD-IRS在多子载波耦合环境下能通过联合优化显著提升OFDM系统性能。

Abstract: This paper studies a broadband orthogonal frequency division multiplexing
(OFDM) system aided by a beyond diagonal intelligent reflecting surface
(BD-IRS), where inter-connections exist among different elements such that the
reflection matrix can exhibit a beyond diagonal structure. Under practical
circuit structures, the reflection matrix of the BD-IRS is generally dependent
on the circuit parameters (e.g., capacitance matrix for all tunable capacitors)
as well as the operating frequency, which leads to couplings among the BD-IRS
reflection matrices over different sub-carriers and consequently new challenges
in the BD-IRS design. Motivated by this, we first model the relationship
between the BD-IRS reflection matrices over different sub-carriers and the
tunable capacitance matrix, and then formulate the joint optimization problem
of the tunable capacitance matrix and power allocation over OFDM sub-carriers
to maximize the achievable rate of the OFDM system. Despite the non-convexity
of the problem, we propose an effective algorithm for finding a high-quality
feasible solution via leveraging alternating optimization and successive convex
approximation. Numerical results show the superiority of our proposed design
over benchmark designs.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [94] [Cumplimiento del Reglamento (UE) 2024/1689 en robótica y sistemas autónomos: una revisión sistemática de la literatura](https://arxiv.org/abs/2509.05380)
*Yoana Pita Lorenzo*

Main category: cs.CY

TL;DR: 系统文献综述分析了自主机器人系统中符合欧盟2024/1689法规的现状，重点关注网络安全框架和方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估当前自主机器人系统在网络安全方面的合规性，特别是针对欧盟2024/1689法规的要求。

Method: 采用PRISMA协议，从IEEE Xplore、ACM DL、Scopus和Web of Science的243条初始记录中筛选了22项研究进行分析。

Result: 研究发现部分合规性进展主要体现在风险管理和加密通信上，但在可解释性模块、实时人工监督和知识库可追溯性方面仍存在显著不足。40%的解决方案明确解决透明度要求，30%实施故障干预机制。

Conclusion: 研究总结认为，整合风险管理、监督和持续审计的模块化方法对于实现自主机器人系统中的AI法案要求至关重要。

Abstract: This systematic literature review analyzes the current state of compliance
with Regulation (EU) 2024/1689 in autonomous robotic systems, focusing on
cybersecurity frameworks and methodologies. Using the PRISMA protocol, 22
studies were selected from 243 initial records across IEEE Xplore, ACM DL,
Scopus, and Web of Science. Findings reveal partial regulatory alignment: while
progress has been made in risk management and encrypted communications,
significant gaps persist in explainability modules, real-time human oversight,
and knowledge base traceability. Only 40% of reviewed solutions explicitly
address transparency requirements, and 30% implement failure intervention
mechanisms. The study concludes that modular approaches integrating risk,
supervision, and continuous auditing are essential to meet the AI Act mandates
in autonomous robotics.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [95] [Distributed Link Sparsification for Scalable Scheduling Using Graph Neural Networks (Journal Version)](https://arxiv.org/abs/2509.05447)
*Zhongyuan Zhao,Gunjan Verma,Ananthram Swami,Santiago Segarra*

Main category: cs.NI

TL;DR: 该论文提出了一种利用图神经网络（GNN）的分布式链路稀疏化方案，以减少高密度无线网络的信令开销，同时保持网络容量。


<details>
  <summary>Details</summary>
Motivation: 在高密度无线网络中，分布式链路调度算法的信令开销会导致拥塞、能耗增加和射频足迹扩展等问题，因此需要一种解决方案。

Method: 作者提出了一种离线无监督学习算法，训练GNN模块以根据流量统计和网络拓扑调整链路竞争阈值，减少不必要的调度竞争。

Result: 在模拟的500链路无线多跳网络中，该方法有效缓解了拥塞并减少了射频足迹，适用于四种不同的分布式链路调度协议。

Conclusion: 该方案为高密度无线网络提供了一种有效的链路稀疏化方法，平衡了开销减少与网络性能的关系。

Abstract: In wireless networks characterized by dense connectivity, the significant
signaling overhead generated by distributed link scheduling algorithms can
exacerbate issues like congestion, energy consumption, and radio footprint
expansion. To mitigate these challenges, we propose a distributed link
sparsification scheme employing graph neural networks (GNNs) to reduce
scheduling overhead for delay-tolerant traffic while maintaining network
capacity. A GNN module is trained to adjust contention thresholds for
individual links based on traffic statistics and network topology, enabling
links to withdraw from scheduling contention when they are unlikely to succeed.
Our approach is facilitated by a novel offline constrained {unsupervised}
learning algorithm capable of balancing two competing objectives: minimizing
scheduling overhead while ensuring that total utility meets the required level.
In simulated wireless multi-hop networks with up to 500 links, our link
sparsification technique effectively alleviates network congestion and reduces
radio footprints across four distinct distributed link scheduling protocols.

</details>


### [96] [BatStation: Toward In-Situ Radar Sensing on 5G Base Stations with Zero-Shot Template Generation](https://arxiv.org/abs/2509.06898)
*Zhihui Gao,Zhecun Liu,Tingjun Chen*

Main category: cs.NI

TL;DR: BatStation是一个轻量级雷达感知框架，集成于5G基站中，利用上行资源网格提取雷达信号，支持实时雷达检测、分类和定位。


<details>
  <summary>Details</summary>
Motivation: 现有雷达信号与5G信号共存需要高效的频谱共享，利用密集部署的5G基站进行雷达感知可实现广域覆盖和实时反馈。

Method: 通过雷达信号分离、资源网格重塑和零样本模板关联三个组件实现雷达信号提取和感知。

Result: 在真实5G流量下，BatStation表现出色，检测概率达97.02%，分类准确率97%，运行时延仅为0.11/0.94 ms。

Conclusion: BatStation是一种高效、轻量级的雷达感知解决方案，适用于5G网络的实时需求。

Abstract: The coexistence between incumbent radar signals and commercial 5G signals
necessitates a versatile and ubiquitous radar sensing for efficient and
adaptive spectrum sharing. In this context, leveraging the densely deployed 5G
base stations (BS) for radar sensing is particularly promising, offering both
wide coverage and immediate feedback to 5G scheduling. However, the targeting
radar signals are superimposed with concurrent 5G uplink transmissions received
by the BS, and practical deployment also demands a lightweight, portable radar
sensing model. This paper presents BatStation, a lightweight, in-situ radar
sensing framework seamlessly integrated into 5G BSs. BatStation leverages
uplink resource grids to extract radar signals through three key components:
(i) radar signal separation to cancel concurrent 5G transmissions and reveal
the radar signals, (ii) resource grid reshaping to align time-frequency
resolution with radar pulse characteristics, and (iii) zero-shot template
correlation based on a portable model trained purely on synthetic data that
supports detection, classification, and localization of radar pulses without
fine-tuning using experimental data. We implement BatStation on a
software-defined radio (SDR) testbed and evaluate its performance with real 5G
traffic in the CBRS band. Results show robust performance across diverse radar
types, achieving detection probabilities of 97.02% (PUCCH) and 79.23% (PUSCH),
classification accuracy up to 97.00%, and median localization errors of
2.68-6.20 MHz (frequency) and 24.6-32.4 microseconds (time). Notably,
BatStation achieves this performance with a runtime latency of only 0.11/0.94
ms on GPU/CPU, meeting the real-time requirement of 5G networks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [97] [OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision](https://arxiv.org/abs/2509.05578)
*Ruixun Liu,Lingyu Kong,Derun Li,Hang Zhao*

Main category: cs.AI

TL;DR: OccVLA是一个新颖的多模态框架，通过3D占据表示增强空间理解，无需显式3D输入即可实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在3D空间理解方面存在不足，尤其在自动驾驶领域，主要面临3D表示构建和空间细节丢失的挑战。

Method: 提出OccVLA框架，将3D占据表示作为预测输出和监督信号，直接从2D视觉输入学习精细空间结构。

Result: 在nuScenes基准测试中表现优异，轨迹规划和3D视觉问答任务均达到领先水平。

Conclusion: OccVLA为自动驾驶提供了一种高效、可扩展且完全基于视觉的解决方案。

Abstract: Multimodal large language models (MLLMs) have shown strong vision-language
reasoning abilities but still lack robust 3D spatial understanding, which is
critical for autonomous driving. This limitation stems from two key challenges:
(1) the difficulty of constructing accessible yet effective 3D representations
without expensive manual annotations, and (2) the loss of fine-grained spatial
details in VLMs due to the absence of large-scale 3D vision-language
pretraining. To address these challenges, we propose OccVLA, a novel framework
that integrates 3D occupancy representations into a unified multimodal
reasoning process. Unlike prior approaches that rely on explicit 3D inputs,
OccVLA treats dense 3D occupancy as both a predictive output and a supervisory
signal, enabling the model to learn fine-grained spatial structures directly
from 2D visual inputs. The occupancy predictions are regarded as implicit
reasoning processes and can be skipped during inference without performance
degradation, thereby adding no extra computational overhead. OccVLA achieves
state-of-the-art results on the nuScenes benchmark for trajectory planning and
demonstrates superior performance on 3D visual question-answering tasks,
offering a scalable, interpretable, and fully vision-based solution for
autonomous driving.

</details>


### [98] [VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction](https://arxiv.org/abs/2509.06736)
*Jie Yang,Jiajun Chen,Zhangyue Yin,Shuo Chen,Yuxin Wang,Yiran Guo,Yuan Li,Yining Zheng,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 论文提出了VehicleWorld环境及State-based Function Call（SFC）方法，解决了传统函数调用在智能汽车座舱中效率低的问题，显著提升了执行准确性和延迟。


<details>
  <summary>Details</summary>
Motivation: 智能汽车座舱的复杂性要求高效的API代理协调，传统方法因无状态导致效率低下和错误恢复能力差。

Method: 通过VehicleWorld（包含30模块、250 API和680属性）提出SFC方法，明确系统状态并直接实现状态转换。

Result: 实验表明，SFC显著优于传统方法，执行准确性更高且延迟更低。

Conclusion: SFC为智能汽车座舱提供了更高效的环境控制方法，代码已开源。

Abstract: Intelligent vehicle cockpits present unique challenges for API Agents,
requiring coordination across tightly-coupled subsystems that exceed typical
task environments' complexity. Traditional Function Calling (FC) approaches
operate statelessly, requiring multiple exploratory calls to build
environmental awareness before execution, leading to inefficiency and limited
error recovery. We introduce VehicleWorld, the first comprehensive environment
for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties
with fully executable implementations that provide real-time state information
during agent execution. This environment enables precise evaluation of vehicle
agent behaviors across diverse, challenging scenarios. Through systematic
analysis, we discovered that direct state prediction outperforms function
calling for environmental control. Building on this insight, we propose
State-based Function Call (SFC), a novel approach that maintains explicit
system state awareness and implements direct state transitions to achieve
target conditions. Experimental results demonstrate that SFC significantly
outperforms traditional FC approaches, achieving superior execution accuracy
and reduced latency. We have made all implementation code publicly available on
Github https://github.com/OpenMOSS/VehicleWorld.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [99] [Programming tension in 3D printed networks inspired by spiderwebs](https://arxiv.org/abs/2509.05855)
*Thijs Masmeijer,Caleb Swain,Jeff Hill,Ed Habtour*

Main category: cs.GR

TL;DR: 提出了一种直接3D打印带编程张力梯度结构的算法，解决了传统制造中的张力分布不准问题。


<details>
  <summary>Details</summary>
Motivation: 传统制造方法中，张力网络的张力梯度难以精确控制，导致形状和稳定性问题。

Method: 通过力密度法定义网络和张力梯度，优化顶点位置并将直线元素转换为弧线，分解为可打印路径。

Result: 实验验证显示张力梯度准确，应变误差小于1%，适用于多种复杂结构。

Conclusion: 该算法可实现紧凑的集成电缆网络，为医疗器械等领域提供新应用。

Abstract: Each element in tensioned structural networks -- such as tensegrity,
architectural fabrics, or medical braces/meshes -- requires a specific tension
level to achieve and maintain the desired shape, stability, and compliance.
These structures are challenging to manufacture, 3D print, or assemble because
flattening the network during fabrication introduces multiplicative
inaccuracies in the network's final tension gradients. This study overcomes
this challenge by offering a fabrication algorithm for direct 3D printing of
such networks with programmed tension gradients, an approach analogous to the
spinning of spiderwebs. The algorithm: (i) defines the desired network and
prescribes its tension gradients using the force density method; (ii) converts
the network into an unstretched counterpart by numerically optimizing vertex
locations toward target element lengths and converting straight elements into
arcs to resolve any remaining error; and (iii) decomposes the network into
printable toolpaths; Optional additional steps are: (iv) flattening curved 2D
networks or 3D networks to ensure 3D printing compatibility; and (v)
automatically resolving any unwanted crossings introduced by the flattening
process. The proposed method is experimentally validated using 2D unit cells of
viscoelastic filaments, where accurate tension gradients are achieved with an
average element strain error of less than 1.0\%. The method remains effective
for networks with element minimum length and maximum stress of 5.8 mm and 7.3
MPa, respectively. The method is used to demonstrate the fabrication of three
complex cases: a flat spiderweb, a curved mesh, and a tensegrity system. The
programmable tension gradient algorithm can be utilized to produce compact,
integrated cable networks, enabling novel applications such as moment-exerting
structures in medical braces and splints.

</details>
