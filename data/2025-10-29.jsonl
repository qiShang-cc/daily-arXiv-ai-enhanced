{"id": "2510.23780", "pdf": "https://arxiv.org/pdf/2510.23780", "abs": "https://arxiv.org/abs/2510.23780", "authors": ["Omran Abbas", "Abdullah Zayat", "Loıc Markley", "Anas Chaaban"], "title": "Nonlinear Stacked Intelligent Surfaces for Wireless Systems", "categories": ["eess.SP"], "comment": "9 pages, 4 figures", "summary": "Stacked intelligent surfaces (SIS) are a promising technology for\nnext-generation wireless systems, offering an opportunity to enhance\ncommunication performance with low power consumption. Typically, an SIS is\nmodelled as a surface that imparts phase shifts on impinging electromagnetic\nsignals to achieve desired communication objectives. However, this mode of\noperation results in a linear SIS, which limits its applicability to linear\noperations. To unlock further SIS potential, we propose a nonlinear SIS that\ncan mimic the behaviour of nonlinear neural networks. We discuss the\nfeasibility and potential of this idea and propose a nonlinear SIS unit cell\nwith a step-like response. To evaluate the system-level performance of\nnonlinear SIS, we present a case study where SIS structures are optimized to\nminimize the symbol error rate (SER) in an MIMO system with SIS deployed at\nboth the transmitter and receiver sides using only statistical channel\ninformation. We demonstrate that a nonlinear SIS can improve communication\nreliability compared to a linear SIS by forming complex signal patterns across\nthe SIS surface, which provide higher diversity against noise disturbances,\nwhile still allowing the receiver to discern these patterns. Finally, we\noutline several potential applications of nonlinear SIS in wireless\ncommunication scenarios."}
{"id": "2510.23832", "pdf": "https://arxiv.org/pdf/2510.23832", "abs": "https://arxiv.org/abs/2510.23832", "authors": ["Evan Allen", "Karim Said", "Robert Calderbank", "Lingjia Liu"], "title": "Communication in a Fractional World: MIMO MC-OTFS Precoder Prediction", "categories": ["eess.SP"], "comment": null, "summary": "As 6G technologies advance, international bodies and regulatory agencies are\nintensifying efforts to extend seamless connectivity especially for\nhigh-mobility scenarios such as Mobile Ad-Hoc Networks (\\textit{MANETs}) types\nsuch as Vehicular Ad-Hoc Networks (\\textit{VANETs}) and Flying Ad-Hoc Networks\n(\\textit{FANETs}). For these environments to be considered for long term\nadoption and use they must support Multiple-Input-Multiple- (MIMO) technology,\nrapidly fluctuating channel conditions in these environments place a heavy\nburden on traditional time-frequency CSI feedback schemes required for MIMO\nprecoding. This motivates a shift toward delay-Doppler representations like\nthose employed by Orthogonal Time-Frequency Space(OTFS) modulation, which\noffers greater stability under mobility. We derive an expression for the\nvariation over time in the OTFS I/O relationship. We then use this to create a\nphysics informed complex exponential basis expansion model prediction framework\nthat maximizes the usefulness of outdated Channel State Information (CSI) in\nthe presence of integer and fractional delay-Doppler channels and facilitates\nhigh mobility MIMO communication."}
{"id": "2510.23837", "pdf": "https://arxiv.org/pdf/2510.23837", "abs": "https://arxiv.org/abs/2510.23837", "authors": ["Ali Amhaz", "Shreya Khisa", "Mohamed Elhattab", "Chadi Assi", "Sanaa Sharafeddine"], "title": "Coordinated Multipoint Transmission in Pinching Antenna Systems", "categories": ["eess.SP"], "comment": null, "summary": "We study a coordinated multi-point (CoMP) transmission where two base\nstations (BSs), each supported by a pinching antenna system (PASS), are\ndeployed to jointly serve communication users under spatial division multiple\naccess (SDMA) technology. Pinching Antenna technology was introduced as a\npromising solution to overcome the large-scale fading that has been shown to be\nan impediment in multiple-input multiple-output (MIMO) systems. To realize the\nadvantages of this technology in CoMP systems, which suffer from an upperbound\nrate limitation when traditional uniform linear arrays (ULAs) are adopted, we\nformulate an optimization problem with the aim of maximizing the achievable sum\nrate by jointly determining the transmit beamforming vectors and pinching\nlocations on the waveguides while respecting the quality of service (QoS)\nrequirements of users. This problem is inherently non-convex due to the strong\ncoupling among its decision parameters, making it challenging to solve using\ntraditional optimization methods. Thus, we utilize a gradient-based\nmeta-learning (GML) strategy specifically designed for large-scale optimization\ntasks. Finally, numerical analysis demonstrates the effectiveness of the\nproposed GML approach, achieving 92 percent of the optimal solution, and the\nsuperiority of the solution presented compared to other benchmarks. In\naddition, it achieves a higher upper bound on the achievable rate compared to\nconventional CoMP systems."}
{"id": "2510.23844", "pdf": "https://arxiv.org/pdf/2510.23844", "abs": "https://arxiv.org/abs/2510.23844", "authors": ["Cameron M. Pike", "Brad Oney", "Gabriel Hepner", "Animesh Yadav"], "title": "Accurate Prediction of Nonlinear Distortion of Multi-Carrier Signals", "categories": ["eess.SP"], "comment": "7 Pages, 7 figures, 6 pages, 6 figures, accepted for publication in\n  IEEE TCAS-II", "summary": "Nonlinearities in power amplifiers adversely affect multi-carrier modulation\ntechniques. Accurate prediction of nonlinear distortion is essential for making\ndesign trade-offs between output power and network throughput. We use the\nseries form of the characteristic function (ch.f.) method to predict distortion\nspectra for sparse multi-carrier transmissions. This method results in\nefficient calculations of individual signal and distortion components. The\nmethod is validated both theoretically and practically. Theoretical validation\nis performed by modeling the signal as a bandpass Gaussian process that is hard\nlimited, and it is shown that the series ch.f. method produces results that are\nidentical with the classical Price's theorem. Practical validation is shown by\nconsidering an orthogonal frequency division multiplexing (OFDM) signal with a\nfragmented spectrum which is then applied to an amplifier driven into\ncompression for which application of Price's theorem is difficult, and the\npredicted output spectrum corroborates laboratory measurements. Part of the\ncomputational efficiency is realized in that the nonlinearity can be expressed\nas the fast Fourier transform (FFT) of samples of its forward scattering\nparameter (i.e., S21) or transconductance function (including AM-PM effects),\nand distortion contributions of the signal can be expressed as numerical\nautoconvolutions of the clean spectrum. Signal-to-distortion ratio (SDR) can be\neasily computed and parameterized across variables of interest, such as\noverdrive level."}
{"id": "2510.23763", "pdf": "https://arxiv.org/pdf/2510.23763", "abs": "https://arxiv.org/abs/2510.23763", "authors": ["Siyin Wang", "Jinlan Fu", "Feihong Liu", "Xinzhe He", "Huangxuan Wu", "Junhao Shi", "Kexin Huang", "Zhaoye Fei", "Jingjing Gong", "Zuxuan Wu", "Yugang Jiang", "See-Kiong Ng", "Tat-Seng Chua", "Xipeng Qiu"], "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "categories": ["cs.RO", "cs.CL", "cs.CV"], "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid\nprogress in Vision-Language-Action (VLA) models for robotic manipulation.\nAlthough effective in many scenarios, current approaches largely rely on\nexplicit instructions, whereas in real-world interactions, humans rarely issue\ninstructions directly. Effective collaboration requires robots to infer user\nintentions proactively. In this work, we introduce cross-modal contextual\ninstructions, a new setting where intent is derived from spoken dialogue,\nenvironmental sounds, and visual cues rather than explicit commands. To address\nthis new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor\nframework based on end-to-end omni-modal LLMs that unifies intention\nrecognition, interaction confirmation, and action execution. RoboOmni fuses\nauditory and visual signals spatiotemporally for robust intention recognition,\nwhile supporting direct speech interaction. To address the absence of training\ndata for proactive intention recognition in robotic manipulation, we build\nOmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640\nbackgrounds, and six contextual instruction types. Experiments in simulation\nand real-world settings show that RoboOmni surpasses text- and ASR-based\nbaselines in success rate, inference speed, intention recognition, and\nproactive assistance."}
{"id": "2510.23892", "pdf": "https://arxiv.org/pdf/2510.23892", "abs": "https://arxiv.org/abs/2510.23892", "authors": ["Kebin Contreras", "Emmanuel Martinez", "Brayan Monroy", "Sebastian Ardila", "Cristian Ramirez", "Mariana Caicedo", "Hans Garcia", "Tatiana Gelvez-Barrera", "Juan Poveda-Jaramillo", "Henry Arguello", "Jorge Bacca"], "title": "Learning-based Spectral Regression for Cocoa Bean Physicochemical Property Prediction", "categories": ["eess.SP"], "comment": null, "summary": "Cocoa bean quality assessment is essential for ensuring compliance with\ncommercial standards, protecting consumer health, and increasing the market\nvalue of the cocoa product. The quality assessment estimates key\nphysicochemical properties, such as fermentation level, moisture content,\npolyphenol concentration, and cadmium content, among others. This assessment\nhas traditionally relied on the accurate estimation of these properties via\nvisual or sensory evaluation, jointly with laboratory-based physicochemical\nanalyses, which are often time-consuming, destructive, and difficult to scale.\nThis creates the need for rapid, reliable, and noninvasive alternatives.\nSpectroscopy, particularly in the visible and near-infrared ranges, offers a\nnon-invasive alternative by capturing the molecular signatures associated with\nthese properties. Therefore, this work introduces a scalable methodology for\nevaluating the quality of cocoa beans by predicting key physicochemical\nproperties from the spectral signatures of cocoa beans. This approach utilizes\na conveyor belt system integrated with a VIS-NIR spectrometer, coupled with\nlearning-based regression models. Furthermore, a dataset is built using cocoa\nbean batches from Santander, Colombia. Ground-truth reference values were\nobtained through standardized laboratory analyses and following commercial\ncocoa quality regulations. To further evaluate the proposed methodology's\ngeneralization, performance is tested on samples collected from other Colombian\nregions and from Cusco, Peru. Experimental results show that the proposed\nmodels achieved R2 scores exceeding 0.98 across all physicochemical properties,\nand reached 0.96 accuracy on geographically independent samples. This\nnon-destructive approach represents a suitable and scalable alternative to\nconventional laboratory methods for quality assessment across the cocoa\nproduction chain."}
{"id": "2510.23860", "pdf": "https://arxiv.org/pdf/2510.23860", "abs": "https://arxiv.org/abs/2510.23860", "authors": ["Hyung Chan Cho", "Go-Eum Cha", "Yanfu Liu", "Sooyeon Jeong"], "title": "Motivating Students' Self-study with Goal Reminder and Emotional Support", "categories": ["cs.RO"], "comment": "RO-MAN 2025 accepted paper", "summary": "While the efficacy of social robots in supporting people in learning tasks\nhas been extensively investigated, their potential impact in assisting students\nin self-studying contexts has not been investigated much. This study explores\nhow a social robot can act as a peer study companion for college students\nduring self-study tasks by delivering task-oriented goal reminder and positive\nemotional support. We conducted an exploratory Wizard-of-Oz study to explore\nhow these robotic support behaviors impacted students' perceived focus,\nproductivity, and engagement in comparison to a robot that only provided\nphysical presence (control). Our study results suggest that participants in the\ngoal reminder and the emotional support conditions reported greater ease of\nuse, with the goal reminder condition additionally showing a higher willingness\nto use the robot in future study sessions. Participants' satisfaction with the\nrobot was correlated with their perception of the robot as a social other, and\nthis perception was found to be a predictor for their level of goal achievement\nin the self-study task. These findings highlight the potential of socially\nassistive robots to support self-study through both functional and emotional\nengagement."}
{"id": "2510.23900", "pdf": "https://arxiv.org/pdf/2510.23900", "abs": "https://arxiv.org/abs/2510.23900", "authors": ["Kuan-Po Chiu", "Sumit Roy"], "title": "LEO Downlink Channel Model Revisited: Scattering Geometry-Inspired Derivation", "categories": ["eess.SP"], "comment": "Accepted to Globecom 2025", "summary": "This paper presents a new derivation of LEO-to-ground receiver channel model\nto address a clear gap in the prior art: the lack of an appropriate geometry\naware characterization of non LOS (NLOS) link model represented by the power\nspectral density (PSD). Specifically, the main contribution is a coherent\nderivation of the PSD from 1st principles that is able to reproduce results in\nprior art and explain the causal relationship of main PSD features to the\npropagation geometry parameters."}
{"id": "2510.23902", "pdf": "https://arxiv.org/pdf/2510.23902", "abs": "https://arxiv.org/abs/2510.23902", "authors": ["Jans Solano", "Diego Quiroz"], "title": "Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped", "categories": ["cs.RO"], "comment": "Accepted at the IROS 2025 Workshop on Wheeled-Legged Robots", "summary": "Wheeled-legged robots combine the efficiency of wheels with the obstacle\nnegotiation of legs, yet many state-of-the-art systems rely on costly actuators\nand sensors, and fall-recovery is seldom integrated, especially for\nwheeled-legged morphologies. This work presents a recovery-aware\nvisual-inertial navigation system on a low-cost wheeled quadruped. The proposed\nsystem leverages vision-based perception from a depth camera and deep\nreinforcement learning policies for robust locomotion and autonomous recovery\nfrom falls across diverse terrains. Simulation experiments show agile mobility\nwith low-torque actuators over irregular terrain and reliably recover from\nexternal perturbations and self-induced failures. We further show goal directed\nnavigation in structured indoor spaces with low-cost perception. Overall, this\napproach lowers the barrier to deploying autonomous navigation and robust\nlocomotion policies in budget-constrained robotic platforms."}
{"id": "2510.23905", "pdf": "https://arxiv.org/pdf/2510.23905", "abs": "https://arxiv.org/abs/2510.23905", "authors": ["Yiming Zhang", "Vikram Krishnamurthy", "Shashwat Jain"], "title": "Inferring Group Intent as a Cooperative Game. An NLP-based Framework for Trajectory Analysis using Graph Transformer Neural Network", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "This paper studies group target trajectory intent as the outcome of a\ncooperative game where the complex-spatio trajectories are modeled using an\nNLP-based generative model. In our framework, the group intent is specified by\nthe characteristic function of a cooperative game, and allocations for players\nin the cooperative game are specified by either the core, the Shapley value, or\nthe nucleolus. The resulting allocations induce probability distributions that\ngovern the coordinated spatio-temporal trajectories of the targets that reflect\nthe group's underlying intent. We address two key questions: (1) How can the\nintent of a group trajectory be optimally formalized as the characteristic\nfunction of a cooperative game? (2) How can such intent be inferred from noisy\nobservations of the targets? To answer the first question, we introduce a\nFisher-information-based characteristic function of the cooperative game, which\nyields probability distributions that generate coordinated spatio-temporal\npatterns. As a generative model for these patterns, we develop an NLP-based\ngenerative model built on formal grammar, enabling the creation of realistic\nmulti-target trajectory data. To answer the second question, we train a Graph\nTransformer Neural Network (GTNN) to infer group trajectory intent-expressed as\nthe characteristic function of the cooperative game-from observational data\nwith high accuracy. The self-attention function of the GTNN depends on the\ntrack estimates. Thus, the formulation and algorithms provide a multi-layer\napproach that spans target tracking (Bayesian signal processing) and the GTNN\n(for group intent inference)."}
{"id": "2510.23928", "pdf": "https://arxiv.org/pdf/2510.23928", "abs": "https://arxiv.org/abs/2510.23928", "authors": ["Raman Jha", "Yang Zhou", "Giuseppe Loianno"], "title": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "categories": ["cs.RO", "cs.CV"], "comment": "Under Review for ROBOVIS 2026", "summary": "In this paper, we propose an adaptive keyframe selection method for improved\n3D scene reconstruction in dynamic environments. The proposed method integrates\ntwo complementary modules: an error-based selection module utilizing\nphotometric and structural similarity (SSIM) errors, and a momentum-based\nupdate module that dynamically adjusts keyframe selection thresholds according\nto scene motion dynamics. By dynamically curating the most informative frames,\nour approach addresses a key data bottleneck in real-time perception. This\nallows for the creation of high-quality 3D world representations from a\ncompressed data stream, a critical step towards scalable robot learning and\ndeployment in complex, dynamic environments. Experimental results demonstrate\nsignificant improvements over traditional static keyframe selection strategies,\nsuch as fixed temporal intervals or uniform frame skipping. These findings\nhighlight a meaningful advancement toward adaptive perception systems that can\ndynamically respond to complex and evolving visual scenes. We evaluate our\nproposed adaptive keyframe selection module on two recent state-of-the-art 3D\nreconstruction networks, Spann3r and CUT3R, and observe consistent improvements\nin reconstruction quality across both frameworks. Furthermore, an extensive\nablation study confirms the effectiveness of each individual component in our\nmethod, underlining their contribution to the overall performance gains."}
{"id": "2510.23908", "pdf": "https://arxiv.org/pdf/2510.23908", "abs": "https://arxiv.org/abs/2510.23908", "authors": ["M. T. Hassan", "D. Zelenchuk", "M. A. B. Abbasi"], "title": "Machine Learning-Driven User Localization in RIS-Assisted Wireless Systems", "categories": ["eess.SP", "cs.ET"], "comment": null, "summary": "The sixth generation (6G) targets ultra reliable, low latency (URLLC) gigabit\nconnectivity in mmWave bands, where directional channels require precise beam\nalignment. Reconfigurable intelligent surfaces (RIS) reshape wave propagation\nand extend coverage, but they enlarge the beam search space at the base\nstation, making exhaustive sweeps inefficient due to control overhead and\nlatency. We propose an ML based user localization framework for RIS assisted\ncommunication at 27 GHz. A 20x20 RIS reflects signals from a core network\nconnected base station and sweeps beams across the 0-90 degree elevation plane,\ndivided into four angular sectors. We build a dataset by recording received\nsignal power (Pr in dBm) across user locations and train multiple regressors,\nincluding decision tree (DT), support vector regressor (SVR), k nearest\nneighbor (KNN), XGBoost, gradient boosting, and random forest. In operation, an\nunknown user in the same plane measures four received power values (one per\nsector) and reports them to the pretrained RIS controller, which predicts the\nuser's angular position in real time. Evaluation using mean absolute error\n(MAE), root mean squared error (RMSE), and R squared (R2) shows high accuracy.\nThe DT model achieves an MAE of 4.8 degrees with R2 = 0.96, while other models\nreach 70 to 86 percent. Predicted radiation patterns, including main lobe\nalignment between 52 and 55 degrees, closely track ground truth. The framework\nreduces beam probing, enables faster alignment, and lowers latency for RIS\nassisted 6G networks."}
{"id": "2510.23954", "pdf": "https://arxiv.org/pdf/2510.23954", "abs": "https://arxiv.org/abs/2510.23954", "authors": ["Pejman Kheradmand", "Behnam Moradkhani", "Raghavasimhan Sankaranarayanan", "Kent K. Yamamoto", "Tanner J. Zachem", "Patrick J. Codd", "Yash Chitalia", "Pierre E. Dupont"], "title": "A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons", "categories": ["cs.RO"], "comment": null, "summary": "Tendon-actuated concentric tube mechanisms combine the advantages of\ntendon-driven continuum robots and concentric tube robots while addressing\ntheir respective limitations. They overcome the restricted degrees of freedom\noften seen in tendon-driven designs, and mitigate issues such as snapping\ninstability associated with concentric tube robots. However, a complete and\ngeneral mechanical model for these systems remains an open problem. In this\nwork, we propose a Cosserat rod-based framework for modeling the general case\nof $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \\{1,\n\\ldots, n\\}$. The model allows each tube to twist and elongate while enforcing\na shared centerline for bending. We validate the proposed framework through\nexperiments with two-tube and three tube assemblies under various tendon\nrouting configurations, achieving tip prediction errors $<4\\%$ of the robot's\ntotal length. We further demonstrate the model's generality by applying it to\nexisting robots in the field, where maximum tip deviations remain around $5\\%$\nof the total length. This model provides a foundation for accurate shape\nestimation and control of advanced tendon-actuated concentric tube robots."}
{"id": "2510.24017", "pdf": "https://arxiv.org/pdf/2510.24017", "abs": "https://arxiv.org/abs/2510.24017", "authors": ["Brian Skoglind", "Travis Roberts", "Sourabh Karmakar", "Cameron Turner", "Laine Mears"], "title": "Localized Acoustic-Event Measurement Probe: Connector Confirmation Utilizing Acoustic Signatures", "categories": ["eess.SP"], "comment": null, "summary": "Modern consumer products are full of interconnected electrical and electronic\nmodules to fulfill direct and indirect needs. In an automated assembly line\nstill, most of these interconnections are required to be done manually due to\nthe large variety of connector types, connector positions, and the soft,\nflexible nature of their structures. The manual connection points are the\nsource of partial or completely loose connections. Sometimes connections are\nmissed due to the application of unequal mating forces and natural human\nfatigue. Subsequently, these defects can lead to unexpected downtime and\nexpensive rework. For successful connection detection, past approaches such as\nvision verification, Augmented Reality, or circuit parameter-based measurements\nhave shown limited ability to detect the correct connection state. Though most\nconnections emit a specific noise for successful mating, the acoustic-based\nverification system for electrical connection confirmation has not been\nextensively researched. The main discouraging reason for such research is the\ntypically low signal-to-noise ratio (SNR) between the sound of a pair of\nelectrical connector mating and the diverse soundscape of the plant. In this\nstudy, the authors investigated increasing the SNR between the electrical\nconnector mating sound and the plant soundscape to improve connection success\ndetection by employing a physical system for background noise mitigation and\nthe successful met noise signature amplification algorithm. The solution is\nover 75% effective at detecting and classifying connection state. The solution\nhas been constructed without any modification to the existing manual\ninterconnection process."}
{"id": "2510.23963", "pdf": "https://arxiv.org/pdf/2510.23963", "abs": "https://arxiv.org/abs/2510.23963", "authors": ["Hiroki Ishikawa", "Kyosuke Ishibashi", "Ko Yamamoto"], "title": "Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a soft robot finger capable of adaptive-twist deformation\nto grasp objects by wrapping them. For a soft hand to grasp and pick-up one\nobject from densely contained multiple objects, a soft finger requires the\nadaptive-twist deformation function in both in-plane and out-of-plane\ndirections. The function allows the finger to be inserted deeply into a limited\ngap among objects. Once inserted, the soft finger requires appropriate control\nof grasping force normal to contact surface, thereby maintaining the twisted\ndeformation. In this paper, we refer to this type of grasping as grasping by\nwrapping. To achieve these two functions by a single actuation source, we\npropose a variable stiffness mechanism that can adaptively change the stiffness\nas the pressure is higher. We conduct a finite element analysis (FEA) on the\nproposed mechanism and determine its design parameter based on the FEA result.\nUsing the developed soft finger, we report basic experimental results and\ndemonstrations on grasping various objects."}
{"id": "2510.24058", "pdf": "https://arxiv.org/pdf/2510.24058", "abs": "https://arxiv.org/abs/2510.24058", "authors": ["Zihan Zhao", "Masood Mortazavi", "Ning Yan"], "title": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to Low-Cost Sensors for Stress Monitoring", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "Accepted as a finders paper at ML4H 2025", "summary": "Electrodermal activity (EDA), the primary signal for stress detection,\nrequires costly hardware often unavailable in real-world wearables. In this\npaper, we propose PULSE, a framework that utilizes EDA exclusively during\nself-supervised pretraining, while enabling inference without EDA but with more\nreadily available modalities such as ECG, BVP, ACC, and TEMP. Our approach\nseparates encoder outputs into shared and private embeddings. We align shared\nembeddings across modalities and fuse them into a modality-invariant\nrepresentation. The private embeddings carry modality-specific information to\nsupport the reconstruction objective. Pretraining is followed by knowledge\ntransfer where a frozen EDA teacher transfers sympathetic-arousal\nrepresentations into student encoders. On WESAD, our method achieves strong\nstress-detection performance, showing that representations of privileged EDA\ncan be transferred to low-cost sensors to improve accuracy while reducing\nhardware cost."}
{"id": "2510.23988", "pdf": "https://arxiv.org/pdf/2510.23988", "abs": "https://arxiv.org/abs/2510.23988", "authors": ["Phuc Nguyen Xuan", "Thanh Nguyen Canh", "Huu-Hung Nguyen", "Nak Young Chong", "Xiem HoangVan"], "title": "A Survey on Collaborative SLAM with 3D Gaussian Splatting", "categories": ["cs.RO"], "comment": null, "summary": "This survey comprehensively reviews the evolving field of multi-robot\ncollaborative Simultaneous Localization and Mapping (SLAM) using 3D Gaussian\nSplatting (3DGS). As an explicit scene representation, 3DGS has enabled\nunprecedented real-time, high-fidelity rendering, ideal for robotics. However,\nits use in multi-robot systems introduces significant challenges in maintaining\nglobal consistency, managing communication, and fusing data from heterogeneous\nsources. We systematically categorize approaches by their architecture --\ncentralized, distributed -- and analyze core components like multi-agent\nconsistency and alignment, communication-efficient, Gaussian representation,\nsemantic distillation, fusion and pose optimization, and real-time scalability.\nIn addition, a summary of critical datasets and evaluation metrics is provided\nto contextualize performance. Finally, we identify key open challenges and\nchart future research directions, including lifelong mapping, semantic\nassociation and mapping, multi-model for robustness, and bridging the Sim2Real\ngap."}
{"id": "2510.24185", "pdf": "https://arxiv.org/pdf/2510.24185", "abs": "https://arxiv.org/abs/2510.24185", "authors": ["Kwadwo Mensah Obeng Afrane", "Yang Miao", "André B. J. Kokkeler"], "title": "Performance Analysis of Sub-band Full-duplex Cell-free Massive MIMO JCAS Systems", "categories": ["eess.SP"], "comment": null, "summary": "In-band Full-duplex joint communication and sensing systems require self\ninterference cancellation as well as decoupling of the mutual interference\nbetween UL communication signals and radar echoes. We present sub-band\nfull-duplex as an alternative duplexing scheme to achieve simultaneous uplink\ncommunication and target parameter estimation in a cell-free massive MIMO\nsystem. Sub-band full-duplex allows uplink and downlink transmissions\nsimultaneously on non-overlapping frequency resources via explicitly defined\nuplink and downlink sub-bands in each timeslot. Thus, we propose a sub-band\nfull-duplex cell-free massive MIMO system with active downlink sensing on\ndownlink sub-bands and uplink communication on uplink sub-band. In the proposed\nsystem, the target illumination signal is transmitted on the downlink (radar)\nsub-band whereas uplink users transmit on the uplink (communication) sub-band.\nBy assuming efficient suppression of inter-sub-band interference between radar\nand communication sub-bands, uplink communication and radar signals can be\nefficiently processed without mutual interference. We show that each AP can\nestimate sensing parameters with high accuracy in SBFD cell-free massive MIMO\nJCAS systems."}
{"id": "2510.23997", "pdf": "https://arxiv.org/pdf/2510.23997", "abs": "https://arxiv.org/abs/2510.23997", "authors": ["Stanley Wu", "Mohamad H. Danesh", "Simon Li", "Hanna Yurchyk", "Amin Abyaneh", "Anas El Houssaini", "David Meger", "Hsiu-Chin Lin"], "title": "VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion", "categories": ["cs.RO", "I.2.9"], "comment": "Accepted in IEEE Robotics and Automation Letters (RAL), 2025. 8\n  pages, 9 figures", "summary": "Recent advancements in legged robot locomotion have facilitated traversal\nover increasingly complex terrains. Despite this progress, many existing\napproaches rely on end-to-end deep reinforcement learning (DRL), which poses\nlimitations in terms of safety and interpretability, especially when\ngeneralizing to novel terrains. To overcome these challenges, we introduce\nVOCALoco, a modular skill-selection framework that dynamically adapts\nlocomotion strategies based on perceptual input. Given a set of pre-trained\nlocomotion policies, VOCALoco evaluates their viability and energy-consumption\nby predicting both the safety of execution and the anticipated cost of\ntransport over a fixed planning horizon. This joint assessment enables the\nselection of policies that are both safe and energy-efficient, given the\nobserved local terrain. We evaluate our approach on staircase locomotion tasks,\ndemonstrating its performance in both simulated and real-world scenarios using\na quadrupedal robot. Empirical results show that VOCALoco achieves improved\nrobustness and safety during stair ascent and descent compared to a\nconventional end-to-end DRL policy"}
{"id": "2510.24193", "pdf": "https://arxiv.org/pdf/2510.24193", "abs": "https://arxiv.org/abs/2510.24193", "authors": ["Tailai Wen", "Da Ke", "Xiang Wang", "Zhitao Huang"], "title": "Dual-Domain Constraints: Designing Covert and Efficient Adversarial Examples for Secure Communication", "categories": ["eess.SP"], "comment": null, "summary": "The advancements in Automatic Modulation Classification (AMC) have propelled\nthe development of signal sensing and identification technologies in\nnon-cooperative communication scenarios but also enable eavesdroppers to\neffectively intercept user signals in wireless communication environments. To\nprotect user privacy in communication links, we have optimized the adversarial\nexample generation model and introduced a novel framework for generating\nadversarial perturbations for transmitted signals. This framework implements\ndual-domain constraints in both the time and frequency domains, ensuring that\nthe adversarial perturbation cannot be filtered out. Comparative experiments\nconfirm the superiority of the proposed method and the concealment of the\nadversarial examples it generates."}
{"id": "2510.24029", "pdf": "https://arxiv.org/pdf/2510.24029", "abs": "https://arxiv.org/abs/2510.24029", "authors": ["Andrew Gerstenslager", "Bekarys Dukenbaev", "Ali A. Minai"], "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "q-bio.NC", "I.2.9; I.2.6"], "comment": "8 pages, 9 figures, Presented at the 2025 International Joint\n  Conference on Neural Networks, Rome, July 2025", "summary": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of\nvertebrates that encode environmental boundaries at specific distances and\nallocentric directions, playing a central role in forming place fields in the\nhippocampus. Most computational BVC models are restricted to two-dimensional\n(2D) environments, making them prone to spatial ambiguities in the presence of\nhorizontal symmetries in the environment. To address this limitation, we\nincorporate vertical angular sensitivity into the BVC framework, thereby\nenabling robust boundary detection in three dimensions, and leading to\nsignificantly more accurate spatial localization in a biologically-inspired\nrobot model.\n  The proposed model processes LiDAR data to capture vertical contours, thereby\ndisambiguating locations that would be indistinguishable under a purely 2D\nrepresentation. Experimental results show that in environments with minimal\nvertical variation, the proposed 3D model matches the performance of a 2D\nbaseline; yet, as 3D complexity increases, it yields substantially more\ndistinct place fields and markedly reduces spatial aliasing. These findings\nshow that adding a vertical dimension to BVC-based localization can\nsignificantly enhance navigation and mapping in real-world 3D spaces while\nretaining performance parity in simpler, near-planar scenarios."}
{"id": "2510.24223", "pdf": "https://arxiv.org/pdf/2510.24223", "abs": "https://arxiv.org/abs/2510.24223", "authors": ["Mahmut Kemal Ercan", "Alireza Pourafzal", "Musa Furkan Keskin", "Sinan Gezici", "Henk Wymeersch"], "title": "Pilot Distortion Design for ToA Obfuscation in Uplink OFDM Communication", "categories": ["eess.SP"], "comment": "The document consists of 6 pages and features 4 figures. Submitted to\n  IEEE WCNC 2026", "summary": "We study uplink orthogonal frequency-division multiplexing (OFDM) pilot\ndistortion to deliberately obfuscate time-of-arrival (ToA) estimation at a\nsingle base station while preserving communication performance. We design a\ncomplex per-subcarrier distortion vector that increases sidelobes of the\nmismatched ambiguity function (MAF) relative to its mainlobe, using two\nobjectives: the sidelobe-to-peak level ratio and the integrated sidelobe level.\nThe design is subject to a transmit-power budget and a proximity\n(dissimilarity) constraint around the communication-optimal pilot.\nCommunication impact is quantied by a capacity-motivated lower bound obtained\nfrom the linear minimum mean-squared error error covariance with a mismatched\nchannel estimate. The resulting generalized fractional program is solved with\nDinkelbach's transform and a difference-of-convex update that yields a\nclosed-form Karush-Kuhn-Tucker step. Simulations on a single-input\nsingle-output OFDM link show that the optimized distortions raise MAF sidelobes\nand degrade delay estimation, as validated by a mismatched maximum-likelihood\nToA estimator, while incurring only marginal capacity loss over a broad\nsignal-to-noise ratio range. The method requires no protocol changes or\nartificial path injection and provides a signal-level mechanism to control ToA\nobservability under communication constraints."}
{"id": "2510.24052", "pdf": "https://arxiv.org/pdf/2510.24052", "abs": "https://arxiv.org/abs/2510.24052", "authors": ["Jongsuk Kim", "Jaeyoung Lee", "Gyojin Han", "Dongjae Lee", "Minki Jeong", "Junmo Kim"], "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recent advancements in deep learning and the availability of high-quality\nreal-world driving datasets have propelled end-to-end autonomous driving.\nDespite this progress, relying solely on real-world data limits the variety of\ndriving scenarios for training. Synthetic scenario generation has emerged as a\npromising solution to enrich the diversity of training data; however, its\napplication within E2E AD models remains largely unexplored. This is primarily\ndue to the absence of a designated ego vehicle and the associated sensor\ninputs, such as camera or LiDAR, typically provided in real-world scenarios. To\naddress this gap, we introduce SynAD, the first framework designed to enhance\nreal-world E2E AD models using synthetic data. Our method designates the agent\nwith the most comprehensive driving information as the ego vehicle in a\nmulti-agent synthetic scenario. We further project path-level scenarios onto\nmaps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view\nfeatures without relying on sensor inputs. Finally, we devise a training\nstrategy that effectively integrates these map-based synthetic data with real\ndriving data. Experimental results demonstrate that SynAD effectively\nintegrates all components and notably enhances safety performance. By bridging\nsynthetic scenario generation and E2E AD, SynAD paves the way for more\ncomprehensive and robust autonomous driving models."}
{"id": "2510.24243", "pdf": "https://arxiv.org/pdf/2510.24243", "abs": "https://arxiv.org/abs/2510.24243", "authors": ["Duc Nguyen Dao", "Haibin Zhang", "Andre B. J. Kokkeler", "Yang Miao"], "title": "Joint Beamforming for Multi-user Multi-target FD ISAC System: A Hybrid GRQ-GA Approach", "categories": ["eess.SP"], "comment": "6 pages, 4 figures", "summary": "In this paper, we consider a full-duplex (FD) Integrated Sensing and\nCommunication (ISAC) system, in which the base station (BS) performs downlink\nand uplink communications with multiple users while simultaneously sensing\nmultiple targets. In the scope of this work, we assume a narrowband and static\nscenario, aiming to focus on the beamforming and power allocation strategies.\nWe propose a joint beamforming strategy for designing transmit and receive\nbeamformer vectors at the BS. The optimization problem aims to maximize the\ncommunication sum-rate, which is critical for ensuring high-quality service to\nusers, while also maintaining accurate sensing performance for detection tasks\nand adhering to maximum power constraints for efficient resource usage. The\noptimal receive beamformers are first derived using a closed-form Generalized\nRayleigh Quotient (GRQ) solution, reducing the variables to be optimized. Then,\nthe remaining problem is solved using floating-point Genetic Algorithms (GA).\nThe numerical results show that the proposed GA-based solution demonstrates up\nto a 98% enhancement in sum-rate compared to a baseline half-duplex ISAC system\nand provides better performance than a benchmark algorithm from the literature.\nAdditionally, it offers insights into sensing performance effects on beam\npatterns as well as communicationsensing trade-offs in multi-target scenarios."}
{"id": "2510.24055", "pdf": "https://arxiv.org/pdf/2510.24055", "abs": "https://arxiv.org/abs/2510.24055", "authors": ["Xiucheng Zhang", "Yang Jiang", "Hongwei Qing", "Jiashuo Bai"], "title": "Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "8 pages", "summary": "Perceptual ambiguity and task conflict limit multitask robotic manipulation\nvia imitation learning. We propose a framework combining a Language-Conditioned\nVisual Representation (LCVR) module and a Language-conditioned\nMixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual\nambiguities by grounding visual features with language instructions, enabling\ndifferentiation between visually similar tasks. To mitigate task conflict,\nLMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal\naction distributions, stabilized by gradient modulation. On real-robot\nbenchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion\nPolicy (DP) success rates by 33.75% and 25%, respectively. The full framework\nachieves a 79% average success, outperforming the advanced baseline by 21%. Our\nwork shows that combining semantic grounding and expert specialization enables\nrobust, efficient multi-task manipulation"}
{"id": "2510.24255", "pdf": "https://arxiv.org/pdf/2510.24255", "abs": "https://arxiv.org/abs/2510.24255", "authors": ["Jihao Luo", "Zesong Fei", "Xinyi Wang", "Le Zhao", "Yuanhao Cui", "Guangxu Zhu", "Dusit Niyato"], "title": "Trajectory Design for UAV-Based Low-Altitude Wireless Networks in Unknown Environments: A Digital Twin-Assisted TD3 Approach", "categories": ["eess.SP", "cs.AI"], "comment": "13 pages, 11 figures", "summary": "Unmanned aerial vehicles (UAVs) are emerging as key enablers for low-altitude\nwireless network (LAWN), particularly when terrestrial networks are\nunavailable. In such scenarios, the environmental topology is typically\nunknown; hence, designing efficient and safe UAV trajectories is essential yet\nchallenging. To address this, we propose a digital twin (DT)-assisted training\nand deployment framework. In this framework, the UAV transmits integrated\nsensing and communication signals to provide communication services to ground\nusers, while simultaneously collecting echoes that are uploaded to the DT\nserver to progressively construct virtual environments (VEs). These VEs\naccelerate model training and are continuously updated with real-time UAV\nsensing data during deployment, supporting decision-making and enhancing flight\nsafety. Based on this framework, we further develop a trajectory design scheme\nthat integrates simulated annealing for efficient user scheduling with the\ntwin-delayed deep deterministic policy gradient algorithm for continuous\ntrajectory design, aiming to minimize mission completion time while ensuring\nobstacle avoidance. Simulation results demonstrate that the proposed approach\nachieves faster convergence, higher flight safety, and shorter mission\ncompletion time compared with baseline methods, providing a robust and\nefficient solution for LAWN deployment in unknown environments."}
{"id": "2510.24067", "pdf": "https://arxiv.org/pdf/2510.24067", "abs": "https://arxiv.org/abs/2510.24067", "authors": ["Tianyi Ding", "Ronghao Zheng", "Senlin Zhang", "Meiqin Liu"], "title": "Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition", "categories": ["cs.RO"], "comment": null, "summary": "This work addresses the collaborative multi-robot autonomous online\nexploration problem, particularly focusing on distributed exploration planning\nfor dynamically balanced exploration area partition and task allocation among a\nteam of mobile robots operating in obstacle-dense non-convex environments.\n  We present a novel topological map structure that simultaneously\ncharacterizes both spatial connectivity and global exploration completeness of\nthe environment. The topological map is updated incrementally to utilize known\nspatial information for updating reachable spaces, while exploration targets\nare planned in a receding horizon fashion under global coverage guidance.\n  A distributed weighted topological graph Voronoi algorithm is introduced\nimplementing balanced graph space partitions of the fused topological maps.\nTheoretical guarantees are provided for distributed consensus convergence and\nequitable graph space partitions with constant bounds.\n  A local planner optimizes the visitation sequence of exploration targets\nwithin the balanced partitioned graph space to minimize travel distance, while\ngenerating safe, smooth, and dynamically feasible motion trajectories.\n  Comprehensive benchmarking against state-of-the-art methods demonstrates\nsignificant improvements in exploration efficiency, completeness, and workload\nbalance across the robot team."}
{"id": "2510.24287", "pdf": "https://arxiv.org/pdf/2510.24287", "abs": "https://arxiv.org/abs/2510.24287", "authors": ["Richard Koebe", "Noah Saibel", "Juan Miguel Lopez Alcaraz", "Simon Schäfer", "Nils Strodthoff"], "title": "Towards actionable hypotension prediction -- predicting catecholamine therapy initiation in the intensive care unit", "categories": ["eess.SP", "cs.LG"], "comment": "27 pages, 8 figures, source code under\n  https://github.com/AI4HealthUOL/actionable-hypotension", "summary": "Hypotension in critically ill ICU patients is common and life-threatening.\nEscalation to catecholamine therapy marks a key management step, with both\nundertreatment and overtreatment posing risks. Most machine learning (ML)\nmodels predict hypotension using fixed MAP thresholds or MAP forecasting,\noverlooking the clinical decision behind treatment escalation. Predicting\ncatecholamine initiation, the start of vasoactive or inotropic agent\nadministration offers a more clinically actionable target reflecting real\ndecision-making. Using the MIMIC-III database, we modeled catecholamine\ninitiation as a binary event within a 15-minute prediction window. Input\nfeatures included statistical descriptors from a two-hour sliding MAP context\nwindow, along with demographics, biometrics, comorbidities, and ongoing\ntreatments. An Extreme Gradient Boosting (XGBoost) model was trained and\ninterpreted via SHapley Additive exPlanations (SHAP). The model achieved an\nAUROC of 0.822 (0.813-0.830), outperforming the hypotension baseline (MAP < 65,\nAUROC 0.686 [0.675-0.699]). SHAP analysis highlighted recent MAP values, MAP\ntrends, and ongoing treatments (e.g., sedatives, electrolytes) as dominant\npredictors. Subgroup analysis showed higher performance in males, younger\npatients (<53 years), those with higher BMI (>32), and patients without\ncomorbidities or concurrent medications. Predicting catecholamine initiation\nbased on MAP dynamics, treatment context, and patient characteristics supports\nthe critical decision of when to escalate therapy, shifting focus from\nthreshold-based alarms to actionable decision support. This approach is\nfeasible across a broad ICU cohort under natural event imbalance. Future work\nshould enrich temporal and physiological context, extend label definitions to\ninclude therapy escalation, and benchmark against existing hypotension\nprediction systems."}
{"id": "2510.24069", "pdf": "https://arxiv.org/pdf/2510.24069", "abs": "https://arxiv.org/abs/2510.24069", "authors": ["Sangmin Kim", "Hajun Kim", "Gijeong Kim", "Min-Gyu Kim", "Hae-Won Park"], "title": "Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition", "categories": ["cs.RO"], "comment": "8 pages, 4 figures, IEEE ROBOTICS AND AUTOMATION LETTERS. PREPRINT\n  VERSION. ACCEPTED OCTOBER, 2025", "summary": "To generate reliable motion for legged robots through trajectory\noptimization, it is crucial to simultaneously compute the robot's path and\ncontact sequence, as well as accurately consider the dynamics in the problem\nformulation. In this paper, we present a phase-based trajectory optimization\nthat ensures the feasibility of translational dynamics and friction cone\nconstraints throughout the entire trajectory. Specifically, our approach\nleverages the superposition properties of linear differential equations to\ndecouple the translational dynamics for each contact point, which operates\nunder different phase sequences. Furthermore, we utilize the differentiation\nmatrix of B{\\'e}zier polynomials to derive an analytical relationship between\nthe robot's position and force, thereby ensuring the consistent satisfaction of\ntranslational dynamics. Additionally, by exploiting the convex closure property\nof B{\\'e}zier polynomials, our method ensures compliance with friction cone\nconstraints. Using the aforementioned approach, the proposed trajectory\noptimization framework can generate dynamically reliable motions with various\ngait sequences for legged robots. We validate our framework using a quadruped\nrobot model, focusing on the feasibility of dynamics and motion generation."}
{"id": "2510.24350", "pdf": "https://arxiv.org/pdf/2510.24350", "abs": "https://arxiv.org/abs/2510.24350", "authors": ["Yiming Zhu", "Zhuhong Zhu", "Xiaodong Xu", "Hongwei Hou", "Wenjin Wang", "Rui Ding"], "title": "Achieving Constant-Envelope Waveform in CP-OFDMA Framework", "categories": ["eess.SP"], "comment": "This work will be submitted to the IEEE for possible publication", "summary": "OFDM is widely adopted in modern wireless communication systems, but its\npower efficiency is limited by high envelope fluctuations. Although various\nhigh power-efficiency waveforms have been proposed, most are incompatible with\nthe CP-OFDMA framework and remain ineffective in multi-user downlink\ntransmissions. To address this issue, we propose a constant-envelope (CE)\nwaveform design, which enables low-complexity transceiver architectures while\nmaintaining full compatibility with the prevailing CP-OFDMA framework.\nSpecifically, we start from a general CE FDMA signal model and develop a\nCP-OFDMA-compatible waveform implementation structure, followed by the design\nof an optimized CE-constrained pulse-shaping filter to suppress out-of-band\nemissions. To tackle channel estimation challenge under non-flat\nfrequency-domain pilots induced by CE modulation, we optimize the time-domain\nbinary pilot sequence to achieve frequency-domain CE properties, and then\npropose a multi-stage method combining delay-domain denoising with power delay\nprofile estimation to facilitate reduced-dimension LMMSE estimation.\nSubsequently, we design a low-complexity maximum ratio combining-aided LMMSE\nequalizer by exploiting the periodicity and conjugate symmetry of the CE\nreceived signals. To mitigate the downlink peak-to-average power ratio increase\ncaused by FDMA, we further develop a multi-user downlink CE transmission scheme\nincluding multiple access mechanism, downlink control information design, and\ncorresponding system-level implementation, which ensures compatibility with the\nNew Radio standard. Numerical results demonstrate that the proposed scheme\nachieves bit error rate performance close to the ideal case while significantly\nreducing transceiver complexity compared to existing CE waveform solutions."}
{"id": "2510.24108", "pdf": "https://arxiv.org/pdf/2510.24108", "abs": "https://arxiv.org/abs/2510.24108", "authors": ["Zhenxin Li", "Wenhao Yao", "Zi Wang", "Xinglong Sun", "Jingde Chen", "Nadine Chang", "Maying Shen", "Jingyu Song", "Zuxuan Wu", "Shiyi Lan", "Jose M. Alvarez"], "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "End-to-end autonomous driving maps raw sensor inputs directly into\nego-vehicle trajectories to avoid cascading errors from perception modules and\nto leverage rich semantic cues. Existing frameworks largely rely on Imitation\nLearning (IL), which can be limited by sub-optimal expert demonstrations and\ncovariate shift during deployment. On the other hand, Reinforcement Learning\n(RL) has recently shown potential in scaling up with simulations, but is\ntypically confined to low-dimensional symbolic inputs (e.g. 3D objects and\nmaps), falling short of full end-to-end learning from raw sensor data. We\nintroduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory\nScoring), a framework that combines the strengths of both worlds: sensor inputs\nwithout losing information and RL training for robust planning. To the best of\nour knowledge, ZTRS is the first framework that eliminates IL entirely by only\nlearning from rewards while operating directly on high-dimensional sensor data.\nZTRS utilizes offline reinforcement learning with our proposed Exhaustive\nPolicy Optimization (EPO), a variant of policy gradient tailored for enumerable\nactions and rewards. ZTRS demonstrates strong performance across three\nbenchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop\nplanning in challenging real-world and synthetic scenarios), and HUGSIM\n(simulated closed-loop driving). Specifically, ZTRS achieves the\nstate-of-the-art result on Navhard and outperforms IL-based baselines on\nHUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS."}
{"id": "2510.24400", "pdf": "https://arxiv.org/pdf/2510.24400", "abs": "https://arxiv.org/abs/2510.24400", "authors": ["Francisco Díaz-Ruiz", "Francisco J. Martín-Vega", "José Antonio Cortés", "Gerardo Gómez", "Mari Carmen Aguayo-Torres"], "title": "Deep Learning-Based CSI Prediction Framework for Channel Aging Mitigation in TDD 5G Systems", "categories": ["eess.SP"], "comment": null, "summary": "Time division duplexing (TDD) has become the dominant duplexing mode in 5G\nand beyond due to its ability to exploit channel reciprocity for efficient\ndownlink channel state information (CSI) acquisition. However, channel aging\ncaused by user mobility and processing delays degrades the accuracy of CSI,\nleading to suboptimal link adaptation and loss of performance. To address this\nissue, we propose a learning-based CSI prediction framework that leverages\ntemporal correlations in wireless channels to forecast future signal to\ninterference plus noise ratio (SINR) values. The prediction operates in the\neffective SINR domain, obtained via exponential effective SINR mapping (EESM),\nensuring full compatibility with existing 5G standards without requiring\ncontinuous pilot signaling. Two models are considered: a fully connected deep\nneural network (DNN) and an long short-term memory (LSTM)-based network. The\nsimulation results show that the LSTM predictor achieves an improvement of up\nto 2 dB in normalized mean squared error (NMSE) and a gain of up to 1.2 Mbps\nthroughput over a baseline without prediction under moderate Doppler\nconditions. These results confirm the potential of lightweight AI-based CSI\nprediction to effectively mitigate channel aging and enhance link adaptation in\nTDD 5G systems."}
{"id": "2510.24109", "pdf": "https://arxiv.org/pdf/2510.24109", "abs": "https://arxiv.org/abs/2510.24109", "authors": ["Wenbin Ding", "Jun Chen", "Mingjia Chen", "Fei Xie", "Qi Mao", "Philip Dames"], "title": "PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI", "categories": ["cs.RO"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has marked a\nsignificant breakthrough in Artificial Intelligence (AI), ushering in a new era\nof Human-centered Artificial Intelligence (HAI). HAI aims to better serve human\nwelfare and needs, thereby placing higher demands on the intelligence level of\nrobots, particularly in aspects such as natural language interaction, complex\ntask planning, and execution. Intelligent agents powered by LLMs have opened up\nnew pathways for realizing HAI. However, existing LLM-based embodied agents\noften lack the ability to plan and execute complex natural language control\ntasks online. This paper explores the implementation of intelligent robotic\nmanipulating agents based on Vision-Language Models (VLMs) in the physical\nworld. We propose a novel embodied agent framework for robots, which comprises\na human-robot voice interaction module, a vision-language agent module and an\naction execution module. The vision-language agent itself includes a\nvision-based task planner, a natural language instruction converter, and a task\nperformance feedback evaluator. Experimental results demonstrate that our agent\nachieves a 28\\% higher average task success rate in both simulated and real\nenvironments compared to approaches relying solely on LLM+CLIP, significantly\nimproving the execution success rate of high-level natural language instruction\ntasks."}
{"id": "2510.24495", "pdf": "https://arxiv.org/pdf/2510.24495", "abs": "https://arxiv.org/abs/2510.24495", "authors": ["Yuzhi Yang", "Sen Yan", "Weijie Zhou", "Brahim Mefgouda", "Ridong Li", "Zhaoyang Zhang", "Mérouane Debbah"], "title": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel Estimation to AI-Native 6G Receivers", "categories": ["eess.SP", "cs.AI"], "comment": "Submitted for potential publication in IEEE Wireless Communications", "summary": "With the development of artificial intelligence (AI) techniques, implementing\nAI-based techniques to improve wireless transceivers becomes an emerging\nresearch topic. Within this context, AI-based channel characterization and\nestimation become the focus since these methods have not been solved by\ntraditional methods very well and have become the bottleneck of transceiver\nefficiency in large-scale orthogonal frequency division multiplexing (OFDM)\nsystems. Specifically, by formulating channel estimation as a generative AI\nproblem, generative AI methods such as diffusion models (DMs) can efficiently\ndeal with rough initial estimations and have great potential to cooperate with\ntraditional signal processing methods. This paper focuses on the transceiver\ndesign of OFDM systems based on DMs, provides an illustration of the potential\nof DMs in wireless transceivers, and points out the related research directions\nbrought by DMs. We also provide a proof-of-concept case study of further\nadapting DMs for better wireless receiver performance."}
{"id": "2510.24118", "pdf": "https://arxiv.org/pdf/2510.24118", "abs": "https://arxiv.org/abs/2510.24118", "authors": ["Haotian Zhou", "Xiaole Wang", "He Li", "Fusheng Sun", "Shengyu Guo", "Guolei Qi", "Jianghuan Xu", "Huijing Zhao"], "title": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Navigating to a designated goal using visual information is a fundamental\ncapability for intelligent robots. Most classical visual navigation methods are\nrestricted to single-goal, single-modality, and closed set goal settings. To\naddress the practical demands of multi-modal, open-vocabulary goal queries and\nmulti-goal visual navigation, we propose LagMemo, a navigation system that\nleverages a language 3D Gaussian Splatting memory. During exploration, LagMemo\nconstructs a unified 3D language memory. With incoming task goals, the system\nqueries the memory, predicts candidate goal locations, and integrates a local\nperception-based verification mechanism to dynamically match and validate goals\nduring navigation. For fair and rigorous evaluation, we curate GOAT-Core, a\nhigh-quality core split distilled from GOAT-Bench tailored to multi-modal\nopen-vocabulary multi-goal visual navigation. Experimental results show that\nLagMemo's memory module enables effective multi-modal open-vocabulary goal\nlocalization, and that LagMemo outperforms state-of-the-art methods in\nmulti-goal visual navigation. Project page:\nhttps://weekgoodday.github.io/lagmemo"}
{"id": "2510.24512", "pdf": "https://arxiv.org/pdf/2510.24512", "abs": "https://arxiv.org/abs/2510.24512", "authors": ["Magnus Heimpel", "Irena Hajnsek", "Othmar Frey"], "title": "Quality Coefficients for Interferometric Phase Linking", "categories": ["eess.SP", "physics.geo-ph", "stat.AP"], "comment": null, "summary": "In multi-temporal InSAR, phase linking refers to the estimation of a\nsingle-reference interferometric phase history from the information contained\nin the coherence matrix of a distributed scatterer. Since the phase information\nin the coherence matrix is typically inconsistent, the extent to which the\nestimated phase history captures it must be assessed to exclude unreliable\npixels from further processing. We introduce three quality criteria in the form\nof coefficients, for threshold-based pixel selection: a coefficient based on\nclosure phase that quantifies the internal consistency of the phase information\nin the coherence matrix; a goodness-of-fit coefficient that quantifies how well\na resulting phase history estimate approximates the phase information according\nto the characteristic optimization model of a given phase linking method; and\nan ambiguity coefficient that compares the goodness of fit of the original\nestimate with that of an orthogonal alternative. We formulate the phase linking\nmethods and these criteria within a unified mathematical framework and discuss\ncomputational and algorithmic aspects. Unlike existing goodness-of-fit\nindicators, the proposed coefficients are normalized to the unit interval with\nexplicit noise-floor correction, improving interpretability across stacks of\ndifferent size. Experiments on TerraSAR-X data over Visp, Switzerland, indicate\nthat the closure phase coefficient effectively pre-screens stable areas, the\ngoodness-of-fit coefficient aligns with and systematically generalizes\nestablished quality indicators, and the ambiguity coefficient flags solutions\nthat fit well but are unstable. Together, the coefficients enable systematic\npixel selection and quality control in the interferometric processing of\ndistributed scatterers."}
{"id": "2510.24194", "pdf": "https://arxiv.org/pdf/2510.24194", "abs": "https://arxiv.org/abs/2510.24194", "authors": ["Ev Zisselman", "Mirco Mutti", "Shelly Francis-Meretzki", "Elisei Shafer", "Aviv Tamar"], "title": "Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Behavioral cloning is a simple yet effective technique for learning\nsequential decision-making from demonstrations. Recently, it has gained\nprominence as the core of foundation models for the physical world, where\nachieving generalization requires countless demonstrations of a multitude of\ntasks. Typically, a human expert with full information on the task demonstrates\na (nearly) optimal behavior. In this paper, we propose to hide some of the\ntask's information from the demonstrator. This ``blindfolded'' expert is\ncompelled to employ non-trivial exploration to solve the task. We show that\ncloning the blindfolded expert generalizes better to unseen tasks than its\nfully-informed counterpart. We conduct experiments of real-world robot peg\ninsertion tasks with (limited) human demonstrations, alongside videogames from\nthe Procgen benchmark. Additionally, we support our findings with theoretical\nanalysis, which confirms that the generalization error scales with\n$\\sqrt{I/m}$, where $I$ measures the amount of task information available to\nthe demonstrator, and $m$ is the number of demonstrated tasks. Both theory and\npractice indicate that cloning blindfolded experts generalizes better with\nfewer demonstrated tasks. Project page with videos and code:\nhttps://sites.google.com/view/blindfoldedexperts/home"}
{"id": "2510.24569", "pdf": "https://arxiv.org/pdf/2510.24569", "abs": "https://arxiv.org/abs/2510.24569", "authors": ["Ashkan Jafari Fesharaki", "Yasser Mestrah", "Yi Ma", "Rahim Tafazolli", "Ibrahim Hemadeh", "Mohammad Heggo", "Arman Shojaeifard", "Javier Lorca Hernando", "Alain Mourad"], "title": "Advanced Closed-Loop Method with Limited Feedback for ISAC", "categories": ["eess.SP"], "comment": null, "summary": "6G wireless networks are poised to seamlessly integrate communication,\ncomputing, localization, and sensing functionalities, ensuring high reliability\nand trustworthiness. This paper introduces Smart Sensing Feedback (SSF), a\nlimited-feedback framework designed to enhance sensing capabilities while\nmaintaining communication performance. SSF adapts the concept of retransmission\nfrom communication to sensing. Specifically, we focus on downlink (DL) bistatic\nsensing, where the User Equipment (UE) performs measurements from reflected\nsensing signals and provides feedback to the network (NW). In sensing services,\nUE reporting can vary significantly due to dynamic factors such as target\ncharacteristics, environmental conditions, and UE status. Our results\ndemonstrate that SSF significantly improves sensing quality while preserving\ncommunication efficiency. Additionally, it enhances key performance metrics\nsuch as probability of detection, latency, and power consumption. These\nimprovements underscore SSF's ability to deliver robust, low-overhead feedback\nand adaptability to support a wide range of ISAC applications."}
{"id": "2510.24257", "pdf": "https://arxiv.org/pdf/2510.24257", "abs": "https://arxiv.org/abs/2510.24257", "authors": ["Ziqi Ma", "Changda Tian", "Yue Gao"], "title": "Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors", "categories": ["cs.RO"], "comment": null, "summary": "In recent years, there has been growing interest in developing robots and\nautonomous systems that can interact with human in a more natural and intuitive\nway. One of the key challenges in achieving this goal is to enable these\nsystems to manipulate objects and tools in a manner that is similar to that of\nhumans. In this paper, we propose a novel approach for learning human-style\nmanipulation skills by using adversarial motion priors, which we name HMAMP.\nThe approach leverages adversarial networks to model the complex dynamics of\ntool and object manipulation, as well as the aim of the manipulation task. The\ndiscriminator is trained using a combination of real-world data and simulation\ndata executed by the agent, which is designed to train a policy that generates\nrealistic motion trajectories that match the statistical properties of human\nmotion. We evaluated HMAMP on one challenging manipulation task: hammering, and\nthe results indicate that HMAMP is capable of learning human-style manipulation\nskills that outperform current baseline methods. Additionally, we demonstrate\nthat HMAMP has potential for real-world applications by performing real robot\narm hammering tasks. In general, HMAMP represents a significant step towards\ndeveloping robots and autonomous systems that can interact with humans in a\nmore natural and intuitive way, by learning to manipulate tools and objects in\na manner similar to how humans do."}
{"id": "2510.24597", "pdf": "https://arxiv.org/pdf/2510.24597", "abs": "https://arxiv.org/abs/2510.24597", "authors": ["Longpan Wang", "Zhuoran Zhang", "Zhenyuan Li", "Xuetao Gan", "Xudong Bai", "Wen Chen", "Qingqing Wu"], "title": "Multifunctional Wideband Digital Metasurface for Secure Electromagnetic Manipulation in S-Band", "categories": ["eess.SP"], "comment": null, "summary": "Digital metasurfaces have attracted significant attention in recent years due\nto their ability to manipulate electromagnetic (EM) waves for secure sensing\nand communication. However, most reported metasurfaces operate at relatively\nhigh frequencies, primarily due to the constraints imposed by the physical\nscale of the dielectric substrate, thus limiting their full-wave system\napplications. In this work, a wideband digital reflective metasurface is\npresented for capable of dynamically controlling EM waves, with multifunctional\napplications in the lower-frequency S-band. The metasurface is composed of\nelectronically reconfigurable meta-atoms with wideband characteristics, and\ndesigned by using trapezoidal and M-shaped patches connected by a pin diode.\nSimulation results show that the proposed digital metasurface could achieve\nwideband 1-bit phase quantization with a stable phase difference within 180\ndegree +/- 25 degree and small reflection loss below 0.6 dB from 2.72 to 3.25\nGHz. To validate the proposed design, a 20x20-unit metasurface array was\ndesigned, simulated and fabricated. By dynamically adjusting the coding\nsequence, the metasurface could enable multi-mode orbital angular momentum\n(OAM) beam generation, dynamic beam scanning, and precise direction finding.\nThese capabilities support secure sensing and secure communications through\nhigh-resolution target detection and anti-jamming beam steering, as well as\nphysical-layer security. The proposed wideband metasurface may serve as an\neffective candidate for enhancing spectral efficiency and security performance\nin radar and wireless systems."}
{"id": "2510.24261", "pdf": "https://arxiv.org/pdf/2510.24261", "abs": "https://arxiv.org/abs/2510.24261", "authors": ["Jingyi Tian", "Le Wang", "Sanping Zhou", "Sen Wang", "Jiayi Li", "Gang Hua"], "title": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Accepted to NeurIPS 2025", "summary": "Learning generalizable robotic manipulation policies remains a key challenge\ndue to the scarcity of diverse real-world training data. While recent\napproaches have attempted to mitigate this through self-supervised\nrepresentation learning, most either rely on 2D vision pretraining paradigms\nsuch as masked image modeling, which primarily focus on static semantics or\nscene geometry, or utilize large-scale video prediction models that emphasize\n2D dynamics, thus failing to jointly learn the geometry, semantics, and\ndynamics required for effective manipulation. In this paper, we present\nDynaRend, a representation learning framework that learns 3D-aware and\ndynamics-informed triplane features via masked reconstruction and future\nprediction using differentiable volumetric rendering. By pretraining on\nmulti-view RGB-D video data, DynaRend jointly captures spatial geometry, future\ndynamics, and task semantics in a unified triplane representation. The learned\nrepresentations can be effectively transferred to downstream robotic\nmanipulation tasks via action value map prediction. We evaluate DynaRend on two\nchallenging benchmarks, RLBench and Colosseum, as well as in real-world robotic\nexperiments, demonstrating substantial improvements in policy success rate,\ngeneralization to environmental perturbations, and real-world applicability\nacross diverse manipulation tasks."}
{"id": "2510.16620", "pdf": "https://arxiv.org/pdf/2510.16620", "abs": "https://arxiv.org/abs/2510.16620", "authors": ["Yingyao Zhou", "Natasha Devroye", "Onur Günlü"], "title": "Feedback Lunch: Deep Feedback Codes for Wiretap Channels", "categories": ["cs.IT", "cs.AI", "cs.CR", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "We consider reversely-degraded wiretap channels, for which the secrecy\ncapacity is zero if there is no channel feedback. This work focuses on a seeded\nmodular code design for the Gaussian wiretap channel with channel output\nfeedback, combining universal hash functions for security and learned\nfeedback-based codes for reliability to achieve positive secrecy rates. We\nstudy the trade-off between communication reliability and information leakage,\nillustrating that feedback enables agreeing on a secret key shared between\nlegitimate parties, overcoming the security advantage of the wiretapper. Our\nfindings also motivate code designs for sensing-assisted secure communication,\nto be used in next-generation integrated sensing and communication methods."}
{"id": "2510.24315", "pdf": "https://arxiv.org/pdf/2510.24315", "abs": "https://arxiv.org/abs/2510.24315", "authors": ["Baozhe Zhang", "Xinwei Chen", "Qingcheng Chen", "Chao Xu", "Fei Gao", "Yanjun Cao"], "title": "Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation", "categories": ["cs.RO"], "comment": null, "summary": "CoNi-MPC provides an efficient framework for UAV control in air-ground\ncooperative tasks by relying exclusively on relative states, eliminating the\nneed for global state estimation. However, its lack of environmental\ninformation poses significant challenges for obstacle avoidance. To address\nthis issue, we propose a novel obstacle avoidance algorithm, Cooperative\nNon-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for\nUAV-UGV cooperative scenarios without reliance on global state estimation or\nobstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data\nfrom the UAV to generate a modulation matrix, which directly adjusts the\nquadrotor's velocity to achieve obstacle avoidance. This modulation-based\nmethod enables real-time generation of collision-free trajectories within the\nUGV's non-inertial frame, significantly reducing computational demands (less\nthan 5 ms per iteration) while maintaining safety in dynamic and unpredictable\nenvironments. The key contributions of this work include: (1) a\nmodulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV\ncooperation in non-inertial frames without global states; (2) rapid, real-time\ntrajectory generation based solely on single-frame LiDAR data, removing the\nneed for obstacle modeling or prediction; and (3) adaptability to both static\nand dynamic environments, thus extending applicability to featureless or\nunknown scenarios."}
{"id": "2510.23819", "pdf": "https://arxiv.org/pdf/2510.23819", "abs": "https://arxiv.org/abs/2510.23819", "authors": ["Avishka Herath", "Malith Jayalath", "Kumudu Kaushalya", "Sanjana Kapukotuwa", "Chathuni Wijegunawardena", "Pahan Mendis", "Kithmin Wickremasinghe", "Duminda Samarasinghe", "Wageesha N. Manamperi", "Chamira U. S. Edussooriya"], "title": "A Simultaneous ECG-PCG Acquisition System with Real-Time Burst-Adaptive Noise Cancellation", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": "Paper submitted to IEEE International Symposium on Circuits and\n  Systems (ISCAS) 2026", "summary": "Cardiac auscultation is an essential clinical skill, requiring excellent\nhearing to distinguish subtle differences in timing and pitch of heart sounds.\nHowever, diagnosing solely from these sounds is often challenging due to\ninterference from surrounding noise, and the information may be limited.\nExisting solutions that adaptively cancel external noise are either not\nreal-time or are computationally intensive, making them unsuitable for\nimplementation in a portable system. This work proposes an end-to-end system\nwith a real-time adaptive noise cancellation pipeline integrated into a device\nthat simultaneously acquires electrocardiogram (ECG) and phonocardiogram (PCG)\nsignals. The performance of the system is validated using real-world hospital\nnoise datasets and recordings captured with the dual-modality device. For PCG\nand ECG signals recorded from the device in noisy hospital settings, the\nproposed algorithms achieved signal-to-noise ratio improvements of 37.01 dB and\n30.32 dB, respectively. These results demonstrate the systems effectiveness in\nenabling reliable and accessible cardiac screening, including noisy hospital\nenvironments typical of resource-constrained settings."}
{"id": "2510.24335", "pdf": "https://arxiv.org/pdf/2510.24335", "abs": "https://arxiv.org/abs/2510.24335", "authors": ["Mingyu Jeong", "Eunsung Kim", "Sehun Park", "Andrew Jaeyong Choi"], "title": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "categories": ["cs.RO", "cs.CV"], "comment": "9 pages, 10 figures", "summary": "We present NVSim, a framework that automatically constructs large-scale,\nnavigable indoor simulators from only common image sequences, overcoming the\ncost and scalability limitations of traditional 3D scanning. Our approach\nadapts 3D Gaussian Splatting to address visual artifacts on sparsely observed\nfloors a common issue in robotic traversal data. We introduce Floor-Aware\nGaussian Splatting to ensure a clean, navigable ground plane, and a novel\nmesh-free traversability checking algorithm that constructs a topological graph\nby directly analyzing rendered views. We demonstrate our system's ability to\ngenerate valid, large-scale navigation graphs from real-world data. A video\ndemonstration is avilable at https://youtu.be/tTiIQt6nXC8"}
{"id": "2510.23847", "pdf": "https://arxiv.org/pdf/2510.23847", "abs": "https://arxiv.org/abs/2510.23847", "authors": ["Joel Poncha Lemayian", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "title": "EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet", "categories": ["cs.CR", "eess.SP"], "comment": "Under review for publication", "summary": "Cryptocurrency blockchain networks safeguard digital assets using\ncryptographic keys, with wallets playing a critical role in generating,\nstoring, and managing these keys. Wallets, typically categorized as hot and\ncold, offer varying degrees of security and convenience. However, they are\ngenerally software-based applications running on microcontrollers.\nConsequently, they are vulnerable to malware and side-channel attacks, allowing\nperpetrators to extract private keys by targeting critical algorithms, such as\nECC, which processes private keys to generate public keys and authorize\ntransactions. To address these issues, this work presents EthVault, the first\nhardware architecture for an Ethereum hierarchically deterministic cold wallet,\nfeaturing hardware implementations of key algorithms for secure key generation.\nAlso, an ECC architecture resilient to side-channel and timing attacks is\nproposed. Moreover, an architecture of the child key derivation function, a\nfundamental component of cryptocurrency wallets, is proposed. The design\nminimizes resource usage, meeting market demand for small, portable\ncryptocurrency wallets. FPGA implementation results validate the feasibility of\nthe proposed approach. The ECC architecture exhibits uniform execution behavior\nacross varying inputs, while the complete design utilizes only 27%, 7%, and 6%\nof LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+\nFPGA."}
{"id": "2510.24457", "pdf": "https://arxiv.org/pdf/2510.24457", "abs": "https://arxiv.org/abs/2510.24457", "authors": ["Jorge Vicente-Martinez", "Edgar Ramirez-Laboreo"], "title": "Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "8 pages, 11 figures", "summary": "This paper presents an optimal trajectory generation method for 3D overhead\ncranes by leveraging differential flatness. This framework enables the direct\ninclusion of complex physical and dynamic constraints, such as nonlinear\nfriction and collision avoidance for both payload and rope. Our approach allows\nfor aggressive movements by constraining payload swing only at the final point.\nA comparative simulation study validates our approach, demonstrating that\nneglecting dry friction leads to actuator saturation and collisions. The\nresults show that friction modeling is a fundamental requirement for fast and\nsafe crane trajectories."}
{"id": "2510.23937", "pdf": "https://arxiv.org/pdf/2510.23937", "abs": "https://arxiv.org/abs/2510.23937", "authors": ["Yuancheng Luo"], "title": "Optimized Loudspeaker Panning for Adaptive Sound-Field Correction and Non-stationary Listening Areas", "categories": ["cs.SD", "eess.AS", "eess.SP", "math.OC"], "comment": null, "summary": "Surround sound systems commonly distribute loudspeakers along standardized\nlayouts for multichannel audio reproduction. However in less controlled\nenvironments, practical layouts vary in loudspeaker quantity, placement, and\nlistening locations / areas. Deviations from standard layouts introduce\nsound-field errors that degrade acoustic timbre, imaging, and clarity of audio\ncontent reproduction. This work introduces both Bayesian loudspeaker\nnormalization and content panning optimization methods for sound-field\ncorrection. Conjugate prior distributions over loudspeaker-listener directions\nupdate estimated layouts for non-stationary listening locations; digital\nfilters adapt loudspeaker acoustic responses to a common reference target at\nthe estimated listening area without acoustic measurements. Frequency-domain\npanning coefficients are then optimized via sensitivity / efficiency objectives\nsubject to spatial, electrical, and acoustic domain constraints; normalized and\npanned loudspeakers form virtual loudspeakers in standardized layouts for\naccurate multichannel reproduction. Experiments investigate robustness of\nBayesian adaptation, and panning optimizations in practical applications."}
{"id": "2510.24508", "pdf": "https://arxiv.org/pdf/2510.24508", "abs": "https://arxiv.org/abs/2510.24508", "authors": ["Haoying Li", "Yifan Peng", "Junfeng Wu"], "title": "Supervisory Measurement-Guided Noise Covariance Estimation", "categories": ["cs.RO"], "comment": null, "summary": "Reliable state estimation hinges on accurate specification of sensor noise\ncovariances, which weigh heterogeneous measurements. In practice, these\ncovariances are difficult to identify due to environmental variability,\nfront-end preprocessing, and other reasons. We address this by formulating\nnoise covariance estimation as a bilevel optimization that, from a Bayesian\nperspective, factorizes the joint likelihood of so-called odometry and\nsupervisory measurements, thereby balancing information utilization with\ncomputational efficiency. The factorization converts the nested Bayesian\ndependency into a chain structure, enabling efficient parallel computation: at\nthe lower level, an invariant extended Kalman filter with state augmentation\nestimates trajectories, while a derivative filter computes analytical gradients\nin parallel for upper-level gradient updates. The upper level refines the\ncovariance to guide the lower-level estimation. Experiments on synthetic and\nreal-world datasets show that our method achieves higher efficiency over\nexisting baselines."}
{"id": "2510.24215", "pdf": "https://arxiv.org/pdf/2510.24215", "abs": "https://arxiv.org/abs/2510.24215", "authors": ["Vishal Halder", "Alexandre Reiffers-Masson", "Abdeldjalil Aïssa-El-Bey", "Gugan Thoppe"], "title": "What Can Be Recovered Under Sparse Adversarial Corruption? Assumption-Free Theory for Linear Measurements", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ be an arbitrary, known matrix\nand $\\mathbf{e}$ a $q$-sparse adversarial vector. Given $\\mathbf{y} =\n\\mathbf{A} x^* + \\mathbf{e}$ and $q$, we seek the smallest set containing\n$x^*$-hence the one conveying maximal information about $x^*$-that is uniformly\nrecoverable from $\\mathbf{y}$ without knowing $\\mathbf{e}$. While exact\nrecovery of $x^*$ via strong (and often impractical) structural assumptions on\n$\\mathbf{A}$ or $x^*$ (for example, restricted isometry, sparsity) is well\nstudied, recoverability for arbitrary $\\mathbf{A}$ and $x^*$ remains open. Our\nmain result shows that the best that one can hope to recover is $x^* +\n\\ker(\\mathbf{U})$, where $\\mathbf{U}$ is the unique projection matrix onto the\nintersection of rowspaces of all possible submatrices of $\\mathbf{A}$ obtained\nby deleting $2q$ rows. Moreover, we prove that every $x$ that minimizes the\n$\\ell_0$-norm of $\\mathbf{y} - \\mathbf{A} x$ lies in $x^* + \\ker(\\mathbf{U})$,\nwhich then gives a constructive approach to recover this set."}
{"id": "2510.24515", "pdf": "https://arxiv.org/pdf/2510.24515", "abs": "https://arxiv.org/abs/2510.24515", "authors": ["Malintha Fernando", "Petter Ögren", "Silun Zhang"], "title": "Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems", "categories": ["cs.RO"], "comment": "Submitted to IEEE Robotics and Automation Letters", "summary": "The Team Orienteering Problem (TOP) generalizes many real-world multi-robot\nscheduling and routing tasks that occur in autonomous mobility, aerial\nlogistics, and surveillance applications. While many flavors of the TOP exist\nfor planning in multi-robot systems, they assume that all the robots cooperate\ntoward a single objective; thus, they do not extend to settings where the\nrobots compete in reward-scarce environments. We propose Stochastic\nPrize-Collecting Games (SPCG) as an extension of the TOP to plan in the\npresence of self-interested robots operating on a graph, under energy\nconstraints and stochastic transitions. A theoretical study on complete and\nstar graphs establishes that there is a unique pure Nash equilibrium in SPCGs\nthat coincides with the optimal routing solution of an equivalent TOP given a\nrank-based conflict resolution rule. This work proposes two algorithms: Ordinal\nRank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in\ntemporarily-formed local neighborhoods during the games' stages, and Fictitious\nOrdinal Response Learning (FORL) to obtain best-response policies against one's\nsenior-rank opponents. Empirical evaluations conducted on road networks and\nsynthetic graphs under both dynamic and stationary prize distributions show\nthat 1) the state-aliasing induced by OR-conditioning enables learning policies\nthat scale more efficiently to large team sizes than those trained with the\nglobal index, and 2) Policies trained with FORL generalize better to imbalanced\nprize distributions than those with other multi-agent training methods.\nFinally, the learned policies in the SPCG achieved between 87% and 95%\noptimality compared to an equivalent TOP solution obtained by mixed-integer\nlinear programming."}
{"id": "2510.24614", "pdf": "https://arxiv.org/pdf/2510.24614", "abs": "https://arxiv.org/abs/2510.24614", "authors": ["James Josep Perry", "Pablo Garcia-Conde Ortiz", "George Konstantinou", "Cornelie Vergouwen", "Edlyn Santha Kumaran", "Morteza Moradi"], "title": "Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures", "categories": ["cs.LG", "cs.CE", "eess.SP"], "comment": null, "summary": "Health indicators (HIs) are central to diagnosing and prognosing the\ncondition of aerospace composite structures, enabling efficient maintenance and\noperational safety. However, extracting reliable HIs remains challenging due to\nvariability in material properties, stochastic damage evolution, and diverse\ndamage modes. Manufacturing defects (e.g., disbonds) and in-service incidents\n(e.g., bird strikes) further complicate this process. This study presents a\ncomprehensive data-driven framework that learns HIs via two learning approaches\nintegrated with multi-domain signal processing. Because ground-truth HIs are\nunavailable, a semi-supervised and an unsupervised approach are proposed: (i) a\ndiversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach\naugmented with continuous auxiliary labels used as hypothetical damage proxies,\nwhich overcomes the limitation of prior binary labels that only distinguish\nhealthy and failed states while neglecting intermediate degradation, and (ii) a\ndegradation-trend-constrained variational autoencoder (DTC-VAE), in which the\nmonotonicity criterion is embedded via an explicit trend constraint. Guided\nwaves with multiple excitation frequencies are used to monitor single-stiffener\ncomposite structures under fatigue loading. Time, frequency, and time-frequency\nrepresentations are explored, and per-frequency HIs are fused via unsupervised\nensemble learning to mitigate frequency dependence and reduce variance. Using\nfast Fourier transform features, the augmented Diversity-DeepSAD model achieved\n81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%\nperformance, outperforming existing baselines."}
{"id": "2510.24533", "pdf": "https://arxiv.org/pdf/2510.24533", "abs": "https://arxiv.org/abs/2510.24533", "authors": ["Yuan Shen", "Yuze Hong", "Guangyang Zeng", "Tengfei Zhang", "Pui Yi Chui", "Ziyang Hong", "Junfeng Wu"], "title": "GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots", "categories": ["cs.RO"], "comment": null, "summary": "Accurate visual inertial simultaneous localization and mapping (VI SLAM) for\nunderwater robots remains a significant challenge due to frequent visual\ndegeneracy and insufficient inertial measurement unit (IMU) motion excitation.\nIn this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system\ndesigned to address these issues. By leveraging the stereo camera's direct\ndepth estimation ability, we eliminate the need to estimate scale during IMU\ninitialization, enabling stable operation even under low acceleration dynamics.\nWith precise gravity initialization, we decouple the pitch and roll from the\npose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point\n(PnP) problem for pose tracking. This allows the use of a minimal 3-point\nsolver, which significantly reduces computational time to reject outliers\nwithin a Random Sample Consensus framework. We further propose a\nbias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the\nrelative pose converges to the true value as the feature number increases. To\nhandle dynamic motion, we refine the full 6-DOF pose while jointly estimating\nthe IMU covariance, enabling adaptive weighting of the gravity prior. Extensive\nexperiments on simulated and real-world data demonstrate that GeVI-SLAM\nachieves higher accuracy and greater stability compared to state-of-the-art\nmethods."}
{"id": "2510.24554", "pdf": "https://arxiv.org/pdf/2510.24554", "abs": "https://arxiv.org/abs/2510.24554", "authors": ["Vignesh Kottayam Viswanathan", "Yifan Bai", "Scott Fredriksson", "Sumeet Satpute", "Christoforos Kanellakis", "George Nikolakopoulos"], "title": "An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments", "categories": ["cs.RO"], "comment": "Submitted for ICRA 2026", "summary": "In this work, we present a hierarchical framework designed to support robotic\ninspection under environment uncertainty. By leveraging a known environment\nmodel, existing methods plan and safely track inspection routes to visit points\nof interest. However, discrepancies between the model and actual site\nconditions, caused by either natural or human activities, can alter the surface\nmorphology or introduce path obstructions. To address this challenge, the\nproposed framework divides the inspection task into: (a) generating the initial\nglobal view-plan for region of interests based on a historical map and (b)\nlocal view replanning to adapt to the current morphology of the inspection\nscene. The proposed hierarchy preserves global coverage objectives while\nenabling reactive adaptation to the local surface morphology. This enables the\nlocal autonomy to remain robust against environment uncertainty and complete\nthe inspection tasks. We validate the approach through deployments in\nreal-world subterranean mines using quadrupedal robot."}
{"id": "2510.24571", "pdf": "https://arxiv.org/pdf/2510.24571", "abs": "https://arxiv.org/abs/2510.24571", "authors": ["Hongxu Zhao", "Guangyang Zeng", "Yunling Shao", "Tengfei Zhang", "Junfeng Wu"], "title": "Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots", "categories": ["cs.RO"], "comment": null, "summary": "The calibration of extrinsic parameters and clock offsets between sensors for\nhigh-accuracy performance in underwater SLAM systems remains insufficiently\nexplored. Existing methods for Doppler Velocity Log (DVL) calibration are\neither constrained to specific sensor configurations or rely on oversimplified\nassumptions, and none jointly estimate translational extrinsics and time\noffsets. We propose a Unified Iterative Calibration (UIC) framework for general\nDVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a\nGaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC\nalternates between efficient GP-based motion state updates and gradient-based\ncalibration variable updates, supported by a provably statistically consistent\nsequential initialization scheme. The proposed UIC can be applied to IMU,\ncameras and other modalities as co-sensors. We release an open-source\nDVL-camera calibration toolbox. Beyond underwater applications, several aspects\nof UIC-such as the integration of GP priors for MAP-based calibration and the\ndesign of provably reliable initialization procedures-are broadly applicable to\nother multi-sensor calibration problems. Finally, simulations and real-world\ntests validate our approach."}
{"id": "2510.24584", "pdf": "https://arxiv.org/pdf/2510.24584", "abs": "https://arxiv.org/abs/2510.24584", "authors": ["Jørgen Anker Olsen", "Lars Rønhaug Pettersen", "Kostas Alexis"], "title": "Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning", "categories": ["cs.RO"], "comment": "8 pages", "summary": "This paper presents a curriculum-based reinforcement learning framework for\ntraining precise and high-performance jumping policies for the robot `Olympus'.\nSeparate policies are developed for vertical and horizontal jumps, leveraging a\nsimple yet effective strategy. First, we densify the inherently sparse jumping\nreward using the laws of projectile motion. Next, a reference state\ninitialization scheme is employed to accelerate the exploration of dynamic\njumping behaviors without reliance on reference trajectories. We also present a\nwalking policy that, when combined with the jumping policies, unlocks versatile\nand dynamic locomotion capabilities. Comprehensive testing validates walking on\nvaried terrain surfaces and jumping performance that exceeds previous works,\neffectively crossing the Sim2Real gap. Experimental validation demonstrates\nhorizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to\n1.0 m. Additionally, we show that with only minor modifications, the proposed\nmethod can be used to learn omnidirectional jumping."}
{"id": "2510.24623", "pdf": "https://arxiv.org/pdf/2510.24623", "abs": "https://arxiv.org/abs/2510.24623", "authors": ["Nicolai Steinke", "Daniel Goehring"], "title": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline\ndesigned to localize a mobile robot in large-scale outdoor environments using\nprior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing\non the perceived ground area and utilizes the place recognition network R2D2,\nor alternatively, the non-learning approach Scale-Invariant Feature Transform\n(SIFT), to identify and select keypoints for BEV image map registration. Our\nresults demonstrate that GroundLoc outperforms state-of-the-art methods on the\nSemanticKITTI and HeLiPR datasets across various sensors. In the multi-session\nlocalization evaluation, GroundLoc reaches an Average Trajectory Error (ATE)\nwell below 50 cm on all Ouster OS2 128 sequences while meeting online runtime\nrequirements. The system supports various sensor models, as evidenced by\nevaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II,\nand Livox Avia sensors. The prior maps are stored as 2D raster image maps,\nwhich can be created from a single drive and require only 4 MB of storage per\nsquare kilometer. The source code is available at\nhttps://github.com/dcmlr/groundloc."}
{"id": "2510.24671", "pdf": "https://arxiv.org/pdf/2510.24671", "abs": "https://arxiv.org/abs/2510.24671", "authors": ["Li Li", "Tobias Brinkmann", "Till Temmen", "Markus Eisenbarth", "Jakob Andert"], "title": "Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "With the increasing integration of intelligent driving functions into\nserial-produced vehicles, ensuring their functionality and robustness poses\ngreater challenges. Compared to traditional road testing, scenario-based\nvirtual testing offers significant advantages in terms of time and cost\nefficiency, reproducibility, and exploration of edge cases. We propose a\nTransformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for\ngenerating multi-agent traffic scenarios in roundabouts, which are\ncharacterized by high vehicle dynamics and complex layouts, yet remain\nrelatively underexplored in current research. The results show that the\nproposed model can accurately reconstruct original scenarios and generate\nrealistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators\n(KPIs) are employed to evaluate the interactive behavior in the generated\nscenarios. Analysis of the latent space reveals partial disentanglement, with\nseveral latent dimensions exhibiting distinct and interpretable effects on\nscenario attributes such as vehicle entry timing, exit timing, and velocity\nprofiles. The results demonstrate the model's capability to generate scenarios\nfor the validation of intelligent driving functions involving multi-agent\ninteractions, as well as to augment data for their development and iterative\nimprovement."}
{"id": "2510.24676", "pdf": "https://arxiv.org/pdf/2510.24676", "abs": "https://arxiv.org/abs/2510.24676", "authors": ["Jiaxuan Zhang", "Yuquan Leng", "Yixuan Guo", "Chenglong Fu"], "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "6 pages, conference", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or\ncomplex terrain remains challenging. This study addresses this issue by using\nan inertial sensor on the sound ankle to guide obstacle-crossing movements. A\ngenetic algorithm computes the optimal neural network structure to predict the\nrequired angles of the thigh and knee joints. A gait progression prediction\nalgorithm determines the actuation angle index for the prosthetic knee motor,\nultimately defining the necessary thigh and knee angles and gait progression.\nResults show that when the standard deviation of Gaussian noise added to the\nthigh angle data is less than 1, the method can effectively eliminate noise\ninterference, achieving 100\\% accuracy in gait phase estimation under 150 Hz,\nwith thigh angle prediction error being 8.71\\% and knee angle prediction error\nbeing 6.78\\%. These findings demonstrate the method's ability to accurately\npredict gait progression and joint angles, offering significant practical value\nfor obstacle negotiation in powered transfemoral prosthetics."}
{"id": "2510.24680", "pdf": "https://arxiv.org/pdf/2510.24680", "abs": "https://arxiv.org/abs/2510.24680", "authors": ["Zishuo Wang", "Joel Loo", "David Hsu"], "title": "Fare: Failure Resilience in Learned Visual Navigation Control", "categories": ["cs.RO"], "comment": null, "summary": "While imitation learning (IL) enables effective visual navigation, IL\npolicies are prone to unpredictable failures in out-of-distribution (OOD)\nscenarios. We advance the notion of failure-resilient policies, which not only\ndetect failures but also recover from them automatically. Failure recognition\nthat identifies the factors causing failure is key to informing recovery: e.g.\npinpointing image regions triggering failure detections can provide cues to\nguide recovery. We present Fare, a framework to construct failure-resilient IL\npolicies, embedding OOD-detection and recognition in them without using\nexplicit failure data, and pairing them with recovery heuristics. Real-world\nexperiments show that Fare enables failure recovery across two different policy\narchitectures, enabling robust long-range navigation in complex environments."}
{"id": "2510.24683", "pdf": "https://arxiv.org/pdf/2510.24683", "abs": "https://arxiv.org/abs/2510.24683", "authors": ["Caleb Escobedo", "Nataliya Nechyporenko", "Shreyas Kadekodi", "Alessandro Roncone"], "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers", "categories": ["cs.RO"], "comment": null, "summary": "Real-time control is an essential aspect of safe robot operation in the real\nworld with dynamic objects. We present a framework for the analysis of\nobject-aware controllers, methods for altering a robot's motion to anticipate\nand avoid possible collisions. This framework is focused on three design\nconsiderations: kinematics, motion profiles, and virtual constraints.\nAdditionally, the analysis in this work relies on verification of robot\nbehaviors using fundamental robot-obstacle experimental scenarios. To showcase\nthe effectiveness of our method we compare three representative object-aware\ncontrollers. The comparison uses metrics originating from the design\nconsiderations. From the analysis, we find that the design of object-aware\ncontrollers often lacks kinematic considerations, continuity of control points,\nand stability in movement profiles. We conclude that this framework can be used\nin the future to design, compare, and benchmark obstacle avoidance methods."}
{"id": "2510.24692", "pdf": "https://arxiv.org/pdf/2510.24692", "abs": "https://arxiv.org/abs/2510.24692", "authors": ["Jun Wang", "Ziyang Zhou", "Ardalan Kahak", "Suyi Li"], "title": "Embodying Physical Computing into Soft Robots", "categories": ["cs.RO"], "comment": null, "summary": "Softening and onboarding computers and controllers is one of the final\nfrontiers in soft robotics towards their robustness and intelligence for\neveryday use. In this regard, embodying soft and physical computing presents\nexciting potential. Physical computing seeks to encode inputs into a mechanical\ncomputing kernel and leverage the internal interactions among this kernel's\nconstituent elements to compute the output. Moreover, such input-to-output\nevolution can be re-programmable. This perspective paper proposes a framework\nfor embodying physical computing into soft robots and discusses three unique\nstrategies in the literature: analog oscillators, physical reservoir computing,\nand physical algorithmic computing. These embodied computers enable the soft\nrobot to perform complex behaviors that would otherwise require CMOS-based\nelectronics -- including coordinated locomotion with obstacle avoidance,\npayload weight and orientation classification, and programmable operation based\non logical rules. This paper will detail the working principles of these\nembodied physical computing methods, survey the current state-of-the-art, and\npresent a perspective for future development."}
{"id": "2510.23615", "pdf": "https://arxiv.org/pdf/2510.23615", "abs": "https://arxiv.org/abs/2510.23615", "authors": ["Nishant Doshi"], "title": "Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning", "categories": ["cs.MA", "cs.RO"], "comment": null, "summary": "This paper presents an approach for accelerated learning of optimal plans for\na given task represented using Linear Temporal Logic (LTL) in multi-agent\nsystems. Given a set of options (temporally abstract actions) available to each\nagent, we convert the task specification into the corresponding Buchi Automaton\nand proceed with a model-free approach which collects transition samples and\nconstructs a product Semi Markov Decision Process (SMDP) on-the-fly.\nValue-based Reinforcement Learning algorithms can then be used to synthesize a\ncorrect-by-design controller without learning the underlying transition model\nof the multi-agent system. The exponential sample complexity due to multiple\nagents is dealt with using a novel reward shaping approach. We test the\nproposed algorithm in a deterministic gridworld simulation for different tasks\nand find that the reward shaping results in significant reduction in\nconvergence times. We also infer that using options becomes increasing more\nrelevant as the state and action space increases in multi-agent systems."}
{"id": "2510.23895", "pdf": "https://arxiv.org/pdf/2510.23895", "abs": "https://arxiv.org/abs/2510.23895", "authors": ["Hoora Sobhani", "Hyoseung Kim"], "title": "Modeling and Scheduling of Fusion Patterns in Autonomous Driving Systems (Extended Version)", "categories": ["eess.SY", "cs.OS", "cs.RO", "cs.SY"], "comment": null, "summary": "In Autonomous Driving Systems (ADS), Directed Acyclic Graphs (DAGs) are\nwidely used to model complex data dependencies and inter-task communication.\nHowever, existing DAG scheduling approaches oversimplify data fusion tasks by\nassuming fixed triggering mechanisms, failing to capture the diverse fusion\npatterns found in real-world ADS software stacks. In this paper, we propose a\nsystematic framework for analyzing various fusion patterns and their\nperformance implications in ADS. Our framework models three distinct fusion\ntask types: timer-triggered, wait-for-all, and immediate fusion, which\ncomprehensively represent real-world fusion behaviors. Our Integer Linear\nProgramming (ILP)-based approach enables an optimization of multiple real-time\nperformance metrics, including reaction time, time disparity, age of\ninformation, and response time, while generating deterministic offline\nschedules directly applicable to real platforms. Evaluation using real-world\nADS case studies, Raspberry Pi implementation, and randomly generated DAGs\ndemonstrates that our framework handles diverse fusion patterns beyond the\nscope of existing work, and achieves substantial performance improvements in\ncomparable scenarios."}
{"id": "2510.23899", "pdf": "https://arxiv.org/pdf/2510.23899", "abs": "https://arxiv.org/abs/2510.23899", "authors": ["Maria G. Mendoza", "Addison Kalanther", "Daniel Bostwick", "Emma Stephan", "Chinmay Maheshwari", "Shankar Sastry"], "title": "Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments", "categories": ["cs.MA", "cs.RO"], "comment": "Accepted to IEEE Global Humanitarian Technology Conference (GHTC\n  2025). 8 pages, 4 figures", "summary": "Autonomous drone technology holds significant promise for enhancing search\nand rescue operations during evacuations by guiding humans toward safety and\nsupporting broader emergency response efforts. However, their application in\ndynamic, real-time evacuation support remains limited. Existing models often\noverlook the psychological and emotional complexity of human behavior under\nextreme stress. In real-world fire scenarios, evacuees frequently deviate from\ndesignated safe routes due to panic and uncertainty. To address these\nchallenges, this paper presents a multi-agent coordination framework in which\nautonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time\nby locating, intercepting, and guiding them to safety under uncertain\nconditions. We model the problem as a Partially Observable Markov Decision\nProcess (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)\nand a low-level rescuer (LLR), coordinate through shared observations and\ncomplementary capabilities. Human behavior is captured using an agent-based\nmodel grounded in empirical psychology, where panic dynamically affects\ndecision-making and movement in response to environmental stimuli. The\nenvironment features stochastic fire spread, unknown evacuee locations, and\nlimited visibility, requiring UAVs to plan over long horizons to search for\nhumans and adapt in real-time. Our framework employs the Proximal Policy\nOptimization (PPO) algorithm with recurrent policies to enable robust\ndecision-making in partially observable settings. Simulation results\ndemonstrate that the UAV team can rapidly locate and intercept evacuees,\nsignificantly reducing the time required for them to reach safety compared to\nscenarios without UAV assistance."}
{"id": "2510.24095", "pdf": "https://arxiv.org/pdf/2510.24095", "abs": "https://arxiv.org/abs/2510.24095", "authors": ["Vedant Gupta", "Haotian Fu", "Calvin Luo", "Yiding Jiang", "George Konidaris"], "title": "Learning Parameterized Skills from Demonstrations", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Neurips 2025", "summary": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location."}
{"id": "2510.24161", "pdf": "https://arxiv.org/pdf/2510.24161", "abs": "https://arxiv.org/abs/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "categories": ["cs.AI", "cs.MM", "cs.RO"], "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks."}
{"id": "2510.24259", "pdf": "https://arxiv.org/pdf/2510.24259", "abs": "https://arxiv.org/abs/2510.24259", "authors": ["Ziqi Ma", "Sao Mai Nguyen", "Philippe Xu"], "title": "Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?", "categories": ["cs.CL", "cs.RO"], "comment": null, "summary": "Emergent symbolic representations are critical for enabling developmental\nlearning agents to plan and generalize across tasks. In this work, we\ninvestigate whether large language models (LLMs) can translate human natural\nlanguage instructions into the internal symbolic representations that emerge\nduring hierarchical reinforcement learning. We apply a structured evaluation\nframework to measure the translation performance of commonly seen LLMs -- GPT,\nClaude, Deepseek and Grok -- across different internal symbolic partitions\ngenerated by a hierarchical reinforcement learning algorithm in the Ant Maze\nand Ant Fall environments. Our findings reveal that although LLMs demonstrate\nsome ability to translate natural language into a symbolic representation of\nthe environment dynamics, their performance is highly sensitive to partition\ngranularity and task complexity. The results expose limitations in current LLMs\ncapacity for representation alignment, highlighting the need for further\nresearch on robust alignment between language and internal agent\nrepresentations."}
{"id": "2510.24399", "pdf": "https://arxiv.org/pdf/2510.24399", "abs": "https://arxiv.org/abs/2510.24399", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "title": "GenTrack: A New Generation of Multi-Object Tracking", "categories": ["cs.CV", "cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper introduces a novel multi-object tracking (MOT) method, dubbed\nGenTrack, whose main contributions include: a hybrid tracking approach\nemploying both stochastic and deterministic manners to robustly handle unknown\nand time-varying numbers of targets, particularly in maintaining target\nidentity (ID) consistency and managing nonlinear dynamics, leveraging particle\nswarm optimization (PSO) with some proposed fitness measures to guide\nstochastic particles toward their target distribution modes, enabling effective\ntracking even with weak and noisy object detectors, integration of social\ninteractions among targets to enhance PSO-guided particles as well as improve\ncontinuous updates of both strong (matched) and weak (unmatched) tracks,\nthereby reducing ID switches and track loss, especially during occlusions, a\nGenTrack-based redefined visual MOT baseline incorporating a comprehensive\nstate and observation model based on space consistency, appearance, detection\nconfidence, track penalties, and social scores for systematic and efficient\ntarget updates, and the first-ever publicly available source-code reference\nimplementation with minimal dependencies, featuring three variants, including\nGenTrack Basic, PSO, and PSO-Social, facilitating flexible reimplementation.\nExperimental results have shown that GenTrack provides superior performance on\nstandard benchmarks and real-world scenarios compared to state-of-the-art\ntrackers, with integrated implementations of baselines for fair comparison.\nPotential directions for future work are also discussed. The source-code\nreference implementations of both the proposed method and compared-trackers are\nprovided on GitHub: https://github.com/SDU-VelKoTek/GenTrack"}
{"id": "2510.24410", "pdf": "https://arxiv.org/pdf/2510.24410", "abs": "https://arxiv.org/abs/2510.24410", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "title": "A Hybrid Approach for Visual Multi-Object Tracking", "categories": ["cs.CV", "cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper proposes a visual multi-object tracking method that jointly\nemploys stochastic and deterministic mechanisms to ensure identifier\nconsistency for unknown and time-varying target numbers under nonlinear\ndynamics. A stochastic particle filter addresses nonlinear dynamics and\nnon-Gaussian noise, with support from particle swarm optimization (PSO) to\nguide particles toward state distribution modes and mitigate divergence through\nproposed fitness measures incorporating motion consistency, appearance\nsimilarity, and social-interaction cues with neighboring targets. Deterministic\nassociation further enforces identifier consistency via a proposed cost matrix\nincorporating spatial consistency between particles and current detections,\ndetection confidences, and track penalties. Subsequently, a novel scheme is\nproposed for the smooth updating of target states while preserving their\nidentities, particularly for weak tracks during interactions with other targets\nand prolonged occlusions. Moreover, velocity regression over past states\nprovides trend-seed velocities, enhancing particle sampling and state updates.\nThe proposed tracker is designed to operate flexibly for both pre-recorded\nvideos and camera live streams, where future frames are unavailable.\nExperimental results confirm superior performance compared to state-of-the-art\ntrackers. The source-code reference implementations of both the proposed method\nand compared-trackers are provided on GitHub:\nhttps://github.com/SDU-VelKoTek/GenTrack2"}
{"id": "2510.24461", "pdf": "https://arxiv.org/pdf/2510.24461", "abs": "https://arxiv.org/abs/2510.24461", "authors": ["Korneel Van den Berghe", "Stein Stroobants", "Vijay Janapa Reddi", "G. C. H. E. de Croon"], "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Neuromorphic computing systems are set to revolutionize energy-constrained\nrobotics by achieving orders-of-magnitude efficiency gains, while enabling\nnative temporal processing. Spiking Neural Networks (SNNs) represent a\npromising algorithmic approach for these systems, yet their application to\ncomplex control tasks faces two critical challenges: (1) the non-differentiable\nnature of spiking neurons necessitates surrogate gradients with unclear\noptimization properties, and (2) the stateful dynamics of SNNs require training\non sequences, which in reinforcement learning (RL) is hindered by limited\nsequence lengths during early training, preventing the network from bridging\nits warm-up period.\n  We address these challenges by systematically analyzing surrogate gradient\nslope settings, showing that shallower slopes increase gradient magnitude in\ndeeper layers but reduce alignment with true gradients. In supervised learning,\nwe find no clear preference for fixed or scheduled slopes. The effect is much\nmore pronounced in RL settings, where shallower slopes or scheduled slopes lead\nto a 2.1x improvement in both training and final deployed performance. Next, we\npropose a novel training approach that leverages a privileged guiding policy to\nbootstrap the learning process, while still exploiting online environment\ninteractions with the spiking policy. Combining our method with an adaptive\nslope schedule for a real-world drone position control task, we achieve an\naverage return of 400 points, substantially outperforming prior techniques,\nincluding Behavioral Cloning and TD3BC, which achieve at most --200 points\nunder the same conditions. This work advances both the theoretical\nunderstanding of surrogate gradient learning in SNNs and practical training\nmethodologies for neuromorphic controllers demonstrated in real-world robotic\nsystems."}
{"id": "2510.24482", "pdf": "https://arxiv.org/pdf/2510.24482", "abs": "https://arxiv.org/abs/2510.24482", "authors": ["Klemens Iten", "Lenart Treven", "Bhavya Sukhija", "Florian Dörfler", "Andreas Krause"], "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "26 pages, 6 figures, 6 tables", "summary": "Reinforcement learning algorithms are typically designed for discrete-time\ndynamics, even though the underlying real-world control systems are often\ncontinuous in time. In this paper, we study the problem of continuous-time\nreinforcement learning, where the unknown system dynamics are represented using\nnonlinear ordinary differential equations (ODEs). We leverage probabilistic\nmodels, such as Gaussian processes and Bayesian neural networks, to learn an\nuncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily\nmaximizes a weighted sum of the extrinsic reward and model epistemic\nuncertainty. This yields a scalable and sample-efficient approach to\ncontinuous-time model-based RL. We show that COMBRL achieves sublinear regret\nin the reward-driven setting, and in the unsupervised RL setting (i.e., without\nextrinsic rewards), we provide a sample complexity bound. In our experiments,\nwe evaluate COMBRL in both standard and unsupervised RL settings and\ndemonstrate that it scales better, is more sample-efficient than prior methods,\nand outperforms baselines across several deep RL tasks."}
