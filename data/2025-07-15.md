<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 24]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.IT](#cs.IT) [Total: 5]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [LNN-powered Fluid Antenna Multiple Access](https://arxiv.org/abs/2507.08821)
*Pedro D. Alvim,Hugerles S. Silva,Ugo S. Dias,Osamah S. Badarneh,Felipe A. P. Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 将流体天线系统的端口选择问题首次建模为多标签分类任务，采用液态神经网络预测最佳端口，并通过超参数优化改进网络架构，降低中断概率。


<details>
  <summary>Details</summary>
Motivation: 通过优化流体天线系统的端口选择，提高信号与干扰加噪声比，以在多接入场景中获得更好的性能。

Method: 将端口选择问题作为多标签分类任务处理，利用液态神经网络（LNNs）预测最佳端口，并结合α-μ衰落模型和超参数优化改进网络架构。

Result: 提出的方法比现有方法表现更优，具有更低的中断概率值。

Conclusion: 液态神经网络结合超参数优化在流体天线系统中能有效提升端口选择的性能。

Abstract: Fluid antenna systems represent an innovative approach in wireless
communication, recently applied in multiple access to optimize the
signal-to-interference-plus-noise ratio through port selection. This letter
frames the port selection problem as a multi-label classification task for the
first time, improving best-port selection with limited port observations. We
address this challenge by leveraging liquid neural networks (LNNs) to predict
the optimal port under emerging fluid antenna multiple access scenarios
alongside a more general $\alpha$-$\mu$ fading model. We also apply
hyperparameter optimization to refine LNN architectures for different
observation scenarios. Our approach yields lower outage probability values than
existing methods.

</details>


### [2] [Fundamental limits via CRB of semi-blind channel estimation in Massive MIMO systems](https://arxiv.org/abs/2507.08950)
*Xue Zhang,Abla Kammoun,Mohamed-Slim Alouini*

Main category: eess.SP

TL;DR: 研究了大规模MIMO系统中半盲信道估计的确定性及随机Cramér-Rao边界（CRB）的渐近行为，发现当传输块长度增长且训练序列长度同步增长时，CRB可无限减小；但若训练序列数与用户数成比例，则误差有下界。


<details>
  <summary>Details</summary>
Motivation: 探索大规模MIMO系统中半盲信道估计的性能极限，揭示CRB在不同渐近条件下的行为，为减少训练序列数量提供理论支持。

Method: 推导并分析了CRB在多种渐近条件下的数学表达式，包括天线数、用户数、训练序列长度和传输块长度的增长关系。

Result: 当传输块和训练序列长度同步增长且用户数固定时，CRB可无限减小；但若训练序列数与用户数成比例，则误差存在非零下界。数值结果验证了半盲估计的优势。

Conclusion: 半盲信道估计在特定条件下可显著降低训练序列需求，但需权衡用户数增长带来的误差下界问题。

Abstract: This paper investigates the asymptotic behavior of the deterministic and
stochastic Cram\'er-Rao Bounds (CRB) for semi-blind channel estimation in
massive multiple-input multiple-output (MIMO) systems. We derive and analyze
mathematically tractable expressions for both metrics under various asymptotic
regimes, which govern the growth rates of the number of antennas, the number of
users, the training sequence length, and the transmission block length. Unlike
the existing work, our results show that the CRB can be made arbitrarily small
as the transmission block length increases, but only when the training sequence
length grows at the same rate and the number of users remains fixed. However,
if the number of training sequences remains proportional to the number of
users, the channel estimation error is always lower-bounded by a non-vanishing
constant. Numerical results are presented to support our findings and
demonstrate the advantages of semi-blind channel estimation in reducing the
required number of training sequences.

</details>


### [3] [Domain Adaptation-Enabled Realistic Map-Based Channel Estimation for MIMO-OFDM](https://arxiv.org/abs/2507.08974)
*Thien Hieu Hoang,Tri Nhu Do,Georges Kaddoum*

Main category: eess.SP

TL;DR: 提出了一种新的领域自适应方法，用于解决无线通信中信道估计的动态环境问题，通过仿真训练和领域适应技术实现高性能模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法在动态环境中表现不佳，而机器学习方法缺乏跨数据集的泛化能力，因此需要一种新方法来解决这些问题。

Method: 提出了一个信道估计流程，结合仿真训练和领域适应技术，以减少实际数据需求。

Result: 即使在真实信道信息有限的情况下，该方法仍能实现稳健的性能。

Conclusion: 该方法有效提升了信道估计在动态环境中的性能，具有实际应用潜力。

Abstract: Accurate channel estimation is crucial for the improvement of signal
processing performance in wireless communications. However, traditional
model-based methods frequently experience difficulties in dynamic environments.
Similarly, alternative machine-learning approaches typically lack
generalization across different datasets due to variations in channel
characteristics. To address this issue, in this study, we propose a novel
domain adaptation approach to bridge the gap between the quasi-static channel
model (QSCM) and the map-based channel model (MBCM). Specifically, we first
proposed a channel estimation pipeline that takes into account realistic
channel simulation to train our foundation model. Then, we proposed domain
adaptation methods to address the estimation problem. Using simulation-based
training to reduce data requirements for effective application in practical
wireless environments, we find that the proposed strategy enables robust model
performance, even with limited true channel information.

</details>


### [4] [Hypergraph Overlapping Community Detection for Brain Networks](https://arxiv.org/abs/2507.08999)
*Duc Vu,Selin Aviyente*

Main category: eess.SP

TL;DR: 该论文提出了一种基于超图的方法来捕捉大脑区域间的高阶依赖关系，并引入了谱聚类算法来检测重叠社区结构。


<details>
  <summary>Details</summary>
Motivation: 传统功能连接网络只能量化大脑区域间的成对关系，忽略了多区域间的高阶依赖关系。因此，需要一种新的方法来表示和分析这些高阶关系。

Method: 论文首先为每个被试构建超图以捕捉高阶依赖关系，然后提出了一种基于谱聚类的算法检测超图中的重叠社区结构，并在多个被试中确定共识社区结构。

Result: 方法被应用于Human Connectome Project的静息态fMRI数据，成功总结了健康年轻人群体中的重叠社区结构。

Conclusion: 该研究为脑功能超网络中的社区检测提供了一种新的有效方法，能够更好地表征大脑区域间的高阶关系。

Abstract: Functional magnetic resonance imaging (fMRI) has been commonly used to
construct functional connectivity networks (FCNs) of the human brain. TFCNs are
primarily limited to quantifying pairwise relationships between ROIs ignoring
higher order dependencies between multiple brain regions. Recently, hypergraph
construction methods from fMRI time series data have been proposed to
characterize the high-order relations among multiple ROIs. While there have
been multiple methods for constructing hypergraphs from fMRI time series, the
question of how to characterize the topology of these hypergraphs remains open.
In this paper, we make two key contributions to the field of community
detection in brain hypernetworks. First, we construct a hypergraph for each
subject capturing high order dependencies between regions. Second, we introduce
a spectral clustering based approach on hypergraphs to detect overlapping
community structure. Finally, the proposed method is implemented to detect the
consensus community structure across multiple subjects. The proposed method is
applied to resting state fMRI data from Human Connectome Project to summarize
the overlapping community structure across a group of healthy young adults.

</details>


### [5] [Time-Varying Offset Estimation for Clock-Asynchronous Bistatic ISAC Systems](https://arxiv.org/abs/2507.09215)
*Yi Wang,Keke Zu,Luping Xiang,Martin Haardt,Kun Yang*

Main category: eess.SP

TL;DR: 论文提出了一种针对时钟异步的双基地ISAC系统的时间变化偏移估计（TVOE）框架，通过动态跟踪和修正定时偏移和载波频率偏移，显著提高了目标感知性能。


<details>
  <summary>Details</summary>
Motivation: 双基地集成感知与通信（ISAC）在下一代通信网络（如B5G/6G）中具有重要应用潜力，但远距离收发信机间的时钟异步性导致定时和载波频率偏移，传统同步方法在无人机场景下不可靠。

Method: 提出TVOE框架，利用视距路径（LoS）的几何特性，通过状态空间建模和扩展卡尔曼滤波（EKF）实时联合估计偏移，并修正非视距（NLoS）组件的定时偏差。

Result: 仿真结果表明，TVOE方法将估计精度提高了60%。

Conclusion: TVOE框架为时钟异步双基地ISAC系统提供了一种高效且无需额外基础设施的同步解决方案，显著提升了感知性能。

Abstract: The bistatic Integrated Sensing and Communication (ISAC) is poised to become
a key application for next generation communication networks (e.g., B5G/6G),
providing simultaneous sensing and communication services with minimal changes
to existing network infrastructure and hardware. However, a significant
challenge in bistatic cooperative sensing is clock asynchronism, arising from
the use of different clocks at far separated transmitters and receivers. This
asynchrony leads to Timing Offsets (TOs) and Carrier Frequency Offsets (CFOs),
potentially causing sensing ambiguity. Traditional synchronization methods
typically rely on static reference links or GNSS-based timing sources, both of
which are often unreliable or unavailable in UAVbased bistatic ISAC scenarios.
To overcome these limitations, we propose a Time-Varying Offset Estimation
(TVOE) framework tailored for clock-asynchronous bistatic ISAC systems, which
leverages the geometrically predictable characteristics of the Line-of-Sight
(LoS) path to enable robust, infrastructure-free
  synchronization. The framework treats the LoS delay and the Doppler shift as
dynamic observations and models their evolution as a hidden stochastic process.
A state-space formulation is developed to jointly estimate TO and CFO via an
Extended Kalman Filter (EKF), enabling real-time tracking of clock offsets
across successive frames. Furthermore, the estimated offsets are subsequently
applied to correct the timing misalignment of all Non-Line-of-Sight (NLoS)
components, thereby enhancing the high-resolution target sensing performance.
Extensive simulation results demonstrate that the proposed TVOE method improves
the estimation accuracy by 60%.

</details>


### [6] [Image Super-Resolution-Based Signal Enhancement in Bistatic ISAC](https://arxiv.org/abs/2507.09218)
*Yi Wang,Keke Zu,Luping Xiang,Martin Haardt,Chaochao Wang,Xianchao Zhang,Kun Yang*

Main category: eess.SP

TL;DR: 本文提出了一种基于图像超分辨率的信号增强框架（ISR-SE），用于改善双基地集成感知与通信（ISAC）系统中的信号识别与恢复能力，解决了复杂环境中信号弱化的问题。


<details>
  <summary>Details</summary>
Motivation: 双基地ISAC技术在下一代通信网络中潜力巨大，但由于复杂环境中的高反射损耗导致信号弱化，传统自适应滤波方法难以适应多样化的网络拓扑，因此需要更高效的信号增强方法。

Method: 首先通过短时傅里叶变换（STFT）将接收信号转换为频谱图，并将其映射为RGB图像；随后设计了一种结合UNet和扩散模型的去噪网络，以提升低信噪比条件下的信号质量。

Result: 提出的ISR-SE框架显著提升了信号的识别和恢复能力，特别是在低信噪比环境中。

Conclusion: ISR-SE框架为解决双基地ISAC系统中的信号弱化问题提供了有效方案，为下一代通信网络的感知与通信集成技术奠定了基础。

Abstract: Bistatic Integrated Sensing and Communication (ISAC) is poised to become a
cornerstone technology in next-generation communication networks, such as
Beyond 5G (B5G) and 6G, by enabling the concurrent execution of sensing and
communication functions without requiring significant modifications to existing
infrastructure. Despite its promising potential, a major challenge in bistatic
cooperative sensing lies in the degradation of sensing accuracy, primarily
caused by the inherently weak received signals resulting from high reflection
losses in complex environments. Traditional methods have predominantly relied
on adaptive filtering techniques to enhance the Signal-to-Noise Ratio (SNR) by
dynamically adjusting the filter coefficients. However, these methods often
struggle to adapt effectively to the increasingly complex and diverse network
topologies. To address these challenges, we propose a novel Image
Super-Resolution-based Signal Enhancement (ISR-SE) framework that significantly
improves the recognition and recovery capabilities of ISAC signals.
Specifically, we first perform a time-frequency analysis by applying the
Short-Time Fourier Transform (STFT) to the received signals, generating
spectrograms that capture the frequency, magnitude, and phase components. These
components are then mapped into RGB images, where each channel represents one
of the extracted features, enabling a more intuitive and informative
visualization of the signal structure. To enhance these RGB images, we design
an improved denoising network that combines the strengths of the UNet
architecture and diffusion models. This hybrid architecture leverages UNet's
multi-scale feature extraction and the generative capacity of diffusion models
to perform effective image denoising, thereby improving the quality and clarity
of signal representations under low-SNR conditions.

</details>


### [7] [Deep Learning for sub-THz Radio Unit Selection using sub-10 GHz Channel Information and Inferred Device Beamforming](https://arxiv.org/abs/2507.09244)
*Nishant Gupta,Muris Sarajlic,Erik G. Larsson*

Main category: eess.SP

TL;DR: 论文提出了一种利用深度学习从sub-10 GHz信道特性推断合适sub-THz RU的方法，解决了UE不共享IBBC信息时的RU选择问题。


<details>
  <summary>Details</summary>
Motivation: 6G应用中sub-THz RU的密集部署带来了高功耗和开销，需要一种高效方法解决RU选择问题。

Method: 通过深度学习从sub-10 GHz信道特性推断sub-THz RU候选，考虑UE的IBBC信息。

Result: 仿真结果表明方法有效，同时揭示了忽视UE方向对系统性能的负面影响。

Conclusion: 深度学习可有效优化sub-THz RU选择，IBBC信息对系统性能至关重要。

Abstract: The dense and distributed deployment of sub-THz radio units (RUs) alongside
sub-10 GHz access point (AP) is a promising approach to provide high data rate
and reliable coverage for future 6G applications. However, beam search or RU
selection for the sub-THz RUs incurs significant overhead and high power
consumption. To address this, we introduce a method that leverages deep
learning to infer a suitable sub-THz RU candidate from a set of sub-THz RUs
using the sub-10 GHz channel characteristics. A novel aspect of this work is
the consideration of inter-band beam configuration (IBBC), defined as the
broadside angle between the low-band and high-band antenna patterns of the user
equipment (UE). Since IBBC indicates the beamforming information or UE's
orientation, it is typically not shared with the network as a part of
signalling. Therefore, we propose a solution strategy to infer a suitable
sub-THz RU even when UEs do not share their IBBC information. Simulation
results illustrate the performance of the inferred sub-THz RU and highlights
the detrimental impact of neglecting UE orientation on the systems performance.

</details>


### [8] [Matched Filtering-Based Channel Estimation for AFDM Systems in Doubly Selective Channels](https://arxiv.org/abs/2507.09268)
*Xiangjun Li,Zilong Liu,Zhengchun Zhou,Pingzhi Fan*

Main category: eess.SP

TL;DR: 论文提出了一种增强型AFDM波形，通过考虑延迟-多普勒耦合相位，研究了匹配滤波辅助信道估计方法，解决了路径模糊问题并降低了复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂双选择性信道中AFDM系统的信道估计问题，尤其是路径模糊导致的性能下降，同时降低计算复杂度。

Method: 提出基于匹配滤波的信道估计方案，采用新型导频排列，利用DAFT域中路径的可分离性和近似正交性，并结合广义斐波那契搜索减少冗余计算。

Result: 仿真结果表明，所提方案在通信性能和复杂度方面具有显著优势。

Conclusion: 增强型AFDM在复杂信道中表现优异，匹配滤波辅助信道估计方案有效提升了性能并降低了复杂度。

Abstract: Affine frequency division multiplexing (AFDM) has recently emerged as an
excellent backward-compatible 6G waveform. In this paper, an enhanced AFDM is
proposed whereby the delay-Doppler (DD) coupling phase is considered.
Specifically, we study matched filtering (MF) assisted channel estimation (CE)
for AFDM systems in complex doubly selective channels. By deriving the complete
input-output relationship, the inter-chirp-carrier interference,
signal-to-interference-plus-noise ratio (SINR), and the effective SINR loss of
AFDM, are investigated in discrete affine Fourier transform (DAFT) domain.
Further, we look into the path ambiguity problem and show that it may lead to
severe performance deterioration in fractional-delay fractional-Doppler
channels. To address such a problem, we introduce an MF assisted CE scheme
building upon a novel pilot arrangement across two consecutive AFDM
transmissions. This allows us to sequentially estimate the parameters of each
path by exploiting the separability and approximate orthogonality of different
paths in the DAFT domain, thus leading to significantly reduced complexity.
Furthermore, based on generalized Fibonacci search (GFS), an MF-GFS scheme is
proposed to avoid significantly redundant computation, which can be extended to
typical wide-band systems. Extensive simulation results indicate that the
proposed schemes offer superior advantages in terms of their improved
communication performance and lower complexity.

</details>


### [9] [Free-running vs. Synchronous: Single-Photon Lidar for High-flux 3D Imaging](https://arxiv.org/abs/2507.09386)
*Ruangrawee Kitichotkul,Shashwath Bharadwaj,Joshua Rapp,Yanting Ma,Alexander Mehta,Vivek K Goyal*

Main category: eess.SP

TL;DR: 提出一种高效的联合最大似然估计器和正则化框架，用于提升自由运行单光子激光雷达的性能。


<details>
  <summary>Details</summary>
Motivation: 自由运行单光子激光雷达（SPL）因减少直方图失真而具优势，但现有解决方案有限，本文旨在提升其精度。

Method: 开发了一种基于直方图的高效联合最大似然估计器，用于估计信号通量、背景通量和深度，并结合学习的点云评分模型作为先验的正则化框架。

Result: 仿真和实验表明，自由运行SPL在相同条件下比同步SPL估计误差更低，正则化进一步提高了精度。

Conclusion: 自由运行SPL结合提出的方法能显著提升性能，且优于同步SPL。

Abstract: Conventional wisdom suggests that single-photon lidar (SPL) should operate in
low-light conditions to minimize dead-time effects. Many methods have been
developed to mitigate these effects in synchronous SPL systems. However,
solutions for free-running SPL remain limited despite the advantage of reduced
histogram distortion from dead times. To improve the accuracy of free-running
SPL, we propose a computationally efficient joint maximum likelihood estimator
of the signal flux, the background flux, and the depth using only histograms,
along with a complementary regularization framework that incorporates a learned
point cloud score model as a prior. Simulations and experiments demonstrate
that free-running SPL yields lower estimation errors than its synchronous
counterpart under identical conditions, with our regularization further
improving accuracy.

</details>


### [10] [Lightweight Graph Neural Networks for Enhanced 5G NR Channel Estimation](https://arxiv.org/abs/2507.09408)
*Sajedeh Norouzi,Mostafa Rahmani,Yi Chu,Torsten Braun,Kaushik Chowdhury,Alister Burr*

Main category: eess.SP

TL;DR: 本文提出了一种轻量级图神经网络GraphNet，用于5G NR系统的信道估计，性能优于传统方法，特别是在高动态环境中。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法在动态环境中复杂性和适应性不足，需要更高效的解决方案。

Method: 利用图神经网络GNN架构，降低计算开销并捕捉关键特征。

Result: GraphNet在高动态环境中显著优于ChannelNet，且在计算资源有限的情况下表现优异。

Conclusion: GraphNet为5G NR提供了一种高效、可扩展的信道估计解决方案。

Abstract: Effective channel estimation CE is critical for optimizing the performance of
5G New Radio NR systems particularly in dynamic environments where traditional
methods struggle with complexity and adaptability This paper introduces
GraphNet a novel lightweight Graph Neural Network GNNbased estimator designed
to enhance CE in 5G NR Our proposed method utilizes a GNN architecture that
minimizes computational overhead while capturing essential features necessary
for accurate CE We evaluate GraphNet across various channel conditions from
slowvarying to highly dynamic environments and compare its performance to
ChannelNet a wellknown deep learningbased CE method GraphNet not only matches
ChannelNets performance in stable conditions but significantly outperforms it
in highvariation scenarios particularly in terms of Block Error Rate It also
includes builtin noise estimation that enhances robustness in challenging
channel conditions Furthermore its significantly lighter computational
footprint makes GraphNet highly suitable for realtime deployment especially on
edge devices with limited computational resources By underscoring the potential
of GNNs to transform CE processes GraphNet offers a scalable and robust
solution that aligns with the evolving demands of 5G technologies highlighting
its efficiency and performance as a nextgeneration solution for wireless
communication systems

</details>


### [11] [An Enregy Efficient Design of Hybrid NOMA Based on Hybrid SIC with Power Adaptation](https://arxiv.org/abs/2507.09458)
*Wang Ning,Zhang Chenyu,Sun Yanshi,Min Minghui,Liu Yuanwei,Li Shiyin*

Main category: eess.SP

TL;DR: 该论文提出了一种结合混合干扰消除（HSIC）和功率适配（PA）的H-NOMA方案，显著提高了无线通信系统的能效和数据速率。


<details>
  <summary>Details</summary>
Motivation: 为了进一步释放H-NOMA的潜力，提升无线通信系统的性能。

Method: 联合采用混合干扰消除（HSIC）和功率适配（PA）技术。

Result: 在高信噪比下，H-NOMA方案能以更高概率实现比纯OMA更高的数据速率和更低的能耗。

Conclusion: 所提方案在能效和数据速率方面表现优异，适合高信噪比场景。

Abstract: Recently, hybrid non-orthogonal multiple access (H-NOMA) technology, which
effectively utilizes both NOMA and orthogonal multiple access (OMA)
technologies through flexible resource allocation in a single transmission, has
demonstrated immense potential for enhancing the performance of wireless
communication systems. To further release the potential of HNOMA, this paper
proposes a novel design of H-NOMA which jointly incorporates hybrid successive
interference cancellation (HSIC) and power adaptation (PA) in the NOMA
transmission phase. To reveal the potential of the proposed HSIC-PA aided
H-NOMA scheme, closed-form expression for the probability of the event that
H-NOMA can achieve a higher data rate than pure OMA by consuming less energy is
rigorously derived. Furthermore, the asymptotic analysis demonstrates that the
probability of the proposed H-NOMA scheme approaches 1 in the high
signal-to-noise ratio (SNR) regime without any constraints on either users'
target rates or transmit power ratios. This represents a significant
improvement over conventional H-NOMA schemes, which require specific
restrictive conditions to achieve probability 1 at high SNRs as shown in
existing work. The above observation indicates that with less energy
consumption, the proposed HSIC-PA aided H-NOMA can achieve a higher data rate
than pure OMA with probability 1 at high SNRs, and hence a higher energy
efficiency. Finally, numerical results are provided to verify the accuracy of
the analysis and also demonstrate the superior performance of the proposed
H-NOMA scheme.

</details>


### [12] [Reframing SAR Target Recognition as Visual Reasoning: A Chain-of-Thought Dataset with Multimodal LLMs](https://arxiv.org/abs/2507.09535)
*Chaoran Li,Xingguo Xu,Siyuan Mu*

Main category: eess.SP

TL;DR: 该研究提出利用多模态大语言模型（如GPT-4o）进行SAR图像目标识别，通过引入链式思维推理提升分类效果，并构建新数据集验证模型可行性。


<details>
  <summary>Details</summary>
Motivation: 针对SAR图像识别中传统方法的局限性（如弱纹理、高噪声、模糊边界），研究探索了多模态推理的新思路。

Method: 基于GPT-4o的多模态大语言模型，结合候选类别和链式思维推理（CoT），对SAR图像进行目标分类。构建了新数据集，包含原始SAR图像、标注、候选标签及GPT生成的CoT推理链。

Result: 实验表明模型在多数场景下能生成逻辑连贯且可解释的推理，但也揭示了其局限性。通过失败案例分析提供了详细的行为洞察。

Conclusion: 研究证实了多模态大语言模型在SAR分析中的可行性，为未来SAR视觉推理研究奠定了基础。

Abstract: In the context of Synthetic Aperture Radar (SAR) image recognition,
traditional methods often struggle with the intrinsic limitations of SAR data,
such as weak texture, high noise, and ambiguous object boundaries. This work
explores a novel perspective by reformulating SAR target recognition as a
multimodal reasoning task. We leverage multimodal large language models
(MLLMs), specifically GPT-4o, to perform target classification based on SAR
imagery, guided by candidate categories and enhanced with Chain-of-Thought
(CoT) reasoning. A new dataset is constructed based on the FAIR-CSAR benchmark,
comprising raw SAR images, structured target annotations, candidate label sets,
and GPT-generated CoT reasoning chains. Experimental results show that the
MLLMs are capable of generating logically coherent and interpretable inferences
in most scenarios. Our analysis highlights both the strengths and current
limitations of MLLMs in interpreting SAR imagery, and we provide detailed
insights into model behavior through failure case analysis. This work
demonstrates the feasibility of incorporating MLLMs into SAR analysis pipelines
and establishes a foundation for future research in SAR-oriented visual
reasoning.

</details>


### [13] [Novel Physics-Aware Attention-Based Machine Learning Approach for Mutual Coupling Modeling](https://arxiv.org/abs/2507.09561)
*Can Wang,Wei Liu,Hanzhi Ma,Xiaonan Jiang,Erping Li,Steven Gao*

Main category: eess.SP

TL;DR: 提出了一种物理感知卷积长短时记忆网络(PC-LSTM)，用于高效准确提取偶极天线阵列的互阻抗矩阵，结合物理机制和注意力机制，实现了快速且高精度的仿真替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统全波仿真方法如CST微波工作室计算天线阵列的互阻抗矩阵耗时较长，需要一种快速且物理可解释的替代方法。

Method: 通过重新诠释Green函数，嵌入自适应损失函数，结合注意力机制处理复数值特征，利用卷积长短时记忆网络提取阻抗矩阵。

Result: 在五个基准测试中验证了方法的有效性，精度高且速度提升7倍。

Conclusion: PC-LSTM是一种高效且物理可解释的替代方案，适用于天线阵列互耦合特性分析。

Abstract: This article presents a physics-aware convolutional long short-term memory
(PC-LSTM) network for efficient and accurate extraction of mutual impedance
matrices in dipole antenna arrays. By reinterpreting the Green's function
through a physics-aware neural network and embedding it into an adaptive loss
function, the proposed machine learning-based approach achieves enhanced
physical interpretability in mutual coupling modeling. Also, an attention
mechanism is carefully designed to calibrate complex-valued features by fusing
the real and imaginary parts of the Green's function matrix. These fused
representations are then processed by a convolutional long short-term memory
network, and the impedance matrix of the linear antenna array can be finally
derived. Validation against five benchmarks underscores the efficacy of the
proposed approach, demonstrating accurate impedance extraction with up to a 7x
speedup compared to CST Microwave Studio, making it a fast alternative to
full-wave simulations for mutual coupling characterization.

</details>


### [14] [A New Wireless Image Transmission System Using Code Index Modulation and Image Enhancement for High-Rate Next Generation Networks](https://arxiv.org/abs/2507.09713)
*Burak Ahmet Ozden,Erdogan Aydin,Ahmet Elbir,Filiz Gurkan*

Main category: eess.SP

TL;DR: 提出了一种基于码索引调制（CIM）的无线图像传输系统（CIM-IT），结合扩频码索引和QAM技术，提高了传输效率，并在接收端通过增强滤波器优化图像质量。


<details>
  <summary>Details</summary>
Motivation: 无线网络技术的发展对高分辨率、高可靠性的图像传输系统提出了需求，尤其是在医疗和军事领域。

Method: 使用CIM和QAM技术映射图像像素值并通过无线信道传输，接收端采用解扩最大似然检测器恢复图像，并通过滤波器优化图像质量。

Result: 系统在错误性能、频谱效率、能量效率和吞吐量上优于传统无线通信技术。

Conclusion: CIM-IT系统为高效率和高质量无线图像传输提供了一种有效解决方案。

Abstract: With the development of wireless network technologies, the wireless image
transmission area has become prominent. The need for high resolution, data
traffic density, widespread use of multimedia applications, and the importance
of high rate and reliable image transmission in medical and military fields
necessitate the design of novel and high-performance wireless image
transmission systems. This paper proposes a code index modulation (CIM)-based
image transmission (CIM-IT) system that utilizes spreading code index and
quadrature amplitude modulation (QAM) symbol for image transmission over a
wireless channel. The proposed CIM-IT system maps bits to each pixel value of
the image to be transmitted and transmits these bits over a wireless channel
using a single-input and multiple-output system comprising code index
modulation and QAM techniques. At the receiver, the active spreading code index
and the selected QAM symbol are estimated using a despreading-based maximum
likelihood detector, and the corresponding bits are obtained. The image
conveyed from the transmitter is then reconstructed at the receiver side using
the pixel values corresponding to the bits. The obtained noisy image is
enhanced using important enhancement filters. In addition, an advanced filter
is proposed to improve the transmitted degraded image with optimum results.
Furthermore, error performance, spectral efficiency, energy efficiency, and
throughputof the CIM-IT system are performed and the results are compared with
traditional wireless communication techniques.

</details>


### [15] [Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing](https://arxiv.org/abs/2507.09776)
*Mihir Kavishwar,Naresh Shanbhag*

Main category: eess.SP

TL;DR: 提出了CACTUS算法，通过优化ADC参数提高模拟内存计算的能效与精度。


<details>
  <summary>Details</summary>
Motivation: 模拟内存计算（AIMC）能效受高精度ADC能耗限制，需找到满足目标精度的最低ADC精度。

Method: 开发计算信噪比（CSNR）分析表达式，提出CACTUS算法优化ADC参数。

Result: 在28nm CMOS工艺中，CACTUS将ADC精度要求降低3位，同时CSNR提高6dB。

Conclusion: CACTUS算法在特定条件下优于传统SQNR优化方法，为AIMC提供更高能效与精度。

Abstract: Analog in-memory computing (AIMC) is an energy-efficient alternative to
digital architectures for accelerating machine learning and signal processing
workloads. However, its energy efficiency is limited by the high energy cost of
the column analog-to-digital converters (ADCs). Reducing the ADC precision is
an effective approach to lowering its energy cost. However, doing so also
reduces the AIMC's computational accuracy thereby making it critical to
identify the minimum precision required to meet a target accuracy. Prior works
overestimate the ADC precision requirements by modeling quantization error as
input-independent noise, maximizing the signal-to-quantization-noise ratio
(SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address
these limitations by developing analytical expressions for estimating the
compute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and
propose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a
circuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we
show that for a 256-dimensional binary dot product, CACTUS reduces the ADC
precision requirements by 3b while achieving 6dB higher CSNR over prior
methods. We also delineate operating conditions under which our proposed
CSNR-optimal ADCs outperform conventional SQNR-optimal ADCs.

</details>


### [16] [Precoded Zak-OTFS for Per-Carrier Equalization](https://arxiv.org/abs/2507.09894)
*Saif Khan Mohammed,Amit Kumar Pathak,Muhammad Ubadah,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS调制利用延迟-多普勒域的脉冲作为载波波形，通过散射环境图像预测信道响应，提出新型预编码技术，降低复杂度并提高频谱效率。


<details>
  <summary>Details</summary>
Motivation: 研究Zak-OTFS调制中信道响应的预测方法，并开发低复杂度的预编码技术以减少干扰和提高频谱效率。

Method: 提出基于扭曲卷积的二维部分响应信道模型，设计新型预编码技术，实现延迟-多普勒载波的独立均衡。

Result: 预编码技术显著降低复杂度，减少保护载波开销，提高频谱效率，且散射环境图像变化缓慢。

Conclusion: Zak-OTFS调制结合新型预编码技术，适用于高动态信道环境，具有高效性和低复杂度的优势。

Abstract: In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform
is a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic
localized function with specific periods along delay and Doppler. When the
channel delay spread is less than the delay period, and the channel Doppler
spread is less than the Doppler period, the response to a single Zak-OTFS
carrier provides an image of the scattering environment and can be used to
predict the effective channel at all other carriers. The image of the
scattering environment changes slowly, making it possible to employ precoding
at the transmitter. Precoding techniques were developed more than thirty years
ago for wireline modem channels (V.34 standard) defined by linear convolution
where a pulse in the time domain (TD) is used to probe the one-dimensional
partial response channel. The action of a doubly spread channel on Zak-OTFS
modulation determines a two-dimensional partial response channel defined by
twisted convolution, and we develop a novel precoding technique for this
channel. The proposed precoder leads to separate equalization of each DD
carrier which has significantly lower complexity than joint equalization of all
carriers. Further, the effective precoded channel results in non-interfering DD
carriers which significantly reduces the overhead of guard carriers separating
data and pilot carriers, which improves the spectral efficiency significantly.

</details>


### [17] [AI-Enhanced Wide-Area Data Imaging via Massive Non-Orthogonal Direct Device-to-HAPS Transmission](https://arxiv.org/abs/2507.09895)
*Hyung-Joo Moon,Chan-Byoung Chae,Kai-Kit Wong,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: MAP-X是一个创新的框架，通过高空伪卫星和分布式传感器重建空间相关的地面数据，并探索了两种AI集成方法。


<details>
  <summary>Details</summary>
Motivation: 为延迟敏感的IoT应用提供实时、高精度的数据重建解决方案。

Method: 采用了DNN点估计和CNN图像重建两种AI方法，并提出了地面-HAPS合作框架。

Result: 两种AI方法均显著优于传统的IDFT线性后处理方法。

Conclusion: AI增强的MAP-X适用于多种实际场景，如灾害响应和网络管理。

Abstract: Massive Aerial Processing for X MAP-X is an innovative framework for
reconstructing spatially correlated ground data, such as environmental or
industrial measurements distributed across a wide area, into data maps using a
single high altitude pseudo-satellite (HAPS) and a large number of distributed
sensors. With subframe-level data reconstruction, MAP-X provides a
transformative solution for latency-sensitive IoT applications. This article
explores two distinct approaches for AI integration in the post-processing
stage of MAP-X. The DNN-based pointwise estimation approach enables real-time,
adaptive reconstruction through online training, while the CNN-based image
reconstruction approach improves reconstruction accuracy through offline
training with non-real-time data. Simulation results show that both approaches
significantly outperform the conventional inverse discrete Fourier transform
(IDFT)-based linear post-processing method. Furthermore, to enable AI-enhanced
MAP-X, we propose a ground-HAPS cooperation framework, where terrestrial
stations collect, process, and relay training data to the HAPS. With its
enhanced capability in reconstructing field data, AI-enhanced MAP-X is
applicable to various real-world use cases, including disaster response and
network management.

</details>


### [18] [VoxelRF: Voxelized Radiance Field for Fast Wireless Channel Modeling](https://arxiv.org/abs/2507.09987)
*Zihang Zeng,Shu Sun,Meixia Tao,Yin Xu,Xianghao Yu*

Main category: eess.SP

TL;DR: VoxelRF提出了一种基于体素化辐射场的神经表示方法，用于快速准确合成无线信道空间谱，解决了传统方法和神经辐射场（NeRF）在准确性、效率和可扩展性上的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统无线信道建模方法在准确性、效率和可扩展性方面存在不足，而基于神经辐射场（NeRF）的方法训练和推理速度慢，VoxelRF旨在解决这些问题。

Method: VoxelRF用基于体素网格的三线性插值替代了NeRF中的多层感知器（MLP），并结合两个浅层MLP建模传播和发射器相关效应，同时引入渐进学习、空空间跳过和背景熵损失函数以加速训练和提高泛化能力。

Result: 实验表明，VoxelRF在计算量显著减少和训练数据有限的情况下，仍能实现竞争性准确性，更适合实时和资源受限的无线应用。

Conclusion: VoxelRF为无线信道建模提供了一种高效且准确的解决方案，适用于实际部署场景。

Abstract: Wireless channel modeling in complex environments is crucial for wireless
communication system design and deployment. Traditional channel modeling
approaches face challenges in balancing accuracy, efficiency, and scalability,
while recent neural approaches such as neural radiance field (NeRF) suffer from
long training and slow inference. To tackle these challenges, we propose
voxelized radiance field (VoxelRF), a novel neural representation for wireless
channel modeling that enables fast and accurate synthesis of spatial spectra.
VoxelRF replaces the costly multilayer perception (MLP) used in NeRF-based
methods with trilinear interpolation of voxel grid-based representation, and
two shallow MLPs to model both propagation and transmitter-dependent effects.
To further accelerate training and improve generalization, we introduce
progressive learning, empty space skipping, and an additional background
entropy loss function. Experimental results demonstrate that VoxelRF achieves
competitive accuracy with significantly reduced computation and limited
training data, making it more practical for real-time and resource-constrained
wireless applications.

</details>


### [19] [Sparsity-Aware Extended Kalman Filter for Tracking Dynamic Graphs](https://arxiv.org/abs/2507.09999)
*Lital Dabush,Nir Shlezinger,Tirza Routtenberg*

Main category: eess.SP

TL;DR: 论文提出了一种基于状态空间模型和图滤波的方法，用于跟踪动态图拓扑的变化，并通过稀疏感知的扩展卡尔曼滤波和动态编程方案提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 动态图拓扑在多个领域中具有重要应用（如电力系统、脑机接口等），但跟踪其变化是一个基础性挑战。

Method: 方法结合了图基非线性状态空间模型、图滤波和稀疏感知的扩展卡尔曼滤波，参数化图拉普拉斯矩阵并通过动态编程计算雅可比矩阵。

Result: 数值研究表明，该方法能够在非线性测量、不同噪声水平和高变化率的实际条件下，高效准确地跟踪稀疏时变图。

Conclusion: 所提方法在复杂环境下表现优越，计算复杂度低，适用于动态图拓扑的跟踪问题。

Abstract: A broad range of applications involve signals with irregular structures that
can be represented as a graph. As the underlying structures can change over
time, the tracking dynamic graph topologies from observed signals is a
fundamental challenge in graph signal processing (GSP), with applications in
various domains, such as power systems, the brain-machine interface, and
communication systems. In this paper, we propose a method for tracking dynamic
changes in graph topologies. Our approach builds on a representation of the
dynamics as a graph-based nonlinear state-space model (SSM), where the
observations are graph signals generated through graph filtering, and the
underlying evolving topology serves as the latent states. In our formulation,
the graph Laplacian matrix is parameterized using the incidence matrix and edge
weights, enabling a structured representation of the state. In order to track
the evolving topology in the resulting SSM, we develop a sparsity-aware
extended Kalman filter (EKF) that integrates $\ell_1$-regularized updates
within the filtering process. Furthermore, a dynamic programming scheme to
efficiently compute the Jacobian of the graph filter is introduced. Our
numerical study demonstrates the ability of the proposed method to accurately
track sparse and time-varying graphs under realistic conditions, with highly
nonlinear measurements, various noise levels, and different change rates, while
maintaining low computational complexity.

</details>


### [20] [Deep Learning-Based Beamforming Design Using Target Beam Patterns](https://arxiv.org/abs/2507.10063)
*Hongpu Zhang,Shu Sun,Hangsong Yan,Jianhua Mo*

Main category: eess.SP

TL;DR: 论文提出了一种基于深度学习的波束成形设计框架，通过轻量级编码器-解码器网络直接将目标波束图案映射到多天线阵列架构中的最优波束成形向量。


<details>
  <summary>Details</summary>
Motivation: 在多天线阵列架构（如数字、模拟和混合波束成形）中，如何高效地将目标波束图案映射为最优波束成形向量是一个关键问题。传统方法在有限的信道状态信息（CSI）条件下表现不佳，因此需要一种更高效且适应性强的方法。

Method: 采用轻量级编码器-解码器网络，编码器将复杂波束图案压缩为低维特征向量，解码器在满足硬件约束的条件下重建波束成形向量。通过两阶段训练（离线预训练和在线训练）解决有限CSI条件下的训练挑战。

Result: 仿真结果表明，该方法在有限CSI条件下能实现接近全数字波束成形的频谱效率，且优于已有的代表性方法。

Conclusion: 所提框架在多天线阵列架构中表现优异，尤其在有限信道状态信息条件下，为波束成形设计提供了一种高效的解决方案。

Abstract: This paper proposes a deep learning-based beamforming design framework that
directly maps a target beam pattern to optimal beamforming vectors across
multiple antenna array architectures, including digital, analog, and hybrid
beamforming. The proposed method employs a lightweight encoder-decoder network
where the encoder compresses the complex beam pattern into a low-dimensional
feature vector and the decoder reconstructs the beamforming vector while
satisfying hardware constraints. To address training challenges under diverse
and limited channel station information (CSI) conditions, a two-stage training
process is introduced, which consists of an offline pre-training for robust
feature extraction using an auxiliary module, followed by online training of
the decoder with a composite loss function that ensures alignment between the
synthesized and target beam patterns in terms of the main lobe shape and side
lobe suppression. Simulation results based on NYUSIM-generated channels show
that the proposed method can achieve spectral efficiency close to that of fully
digital beamforming under limited CSI and outperforms representative existing
methods.

</details>


### [21] [Intrinsic frequency distribution characterises neural dynamics](https://arxiv.org/abs/2507.10145)
*Ryohei Fukuma,Yoshinobu Kawahara,Okito Yamashita,Kei Majima,Haruhiko Kishima,Takufumi Yanagisawa*

Main category: eess.SP

TL;DR: 论文提出使用动态模式分解（DMD）的固有频率分布来表征神经活动，表明其可作为区分健康人与痴呆或帕金森病患者的新生物标志物，效果优于传统傅里叶变换。


<details>
  <summary>Details</summary>
Motivation: 为了理解、预测和控制非线性时空动态系统（如大脑），需要分解多元时间序列为基本动态模式。传统傅里叶变换方法存在局限性，无法捕捉非平稳成分。

Method: 采用动态模式分解（DMD）方法，将非线性时空动态分解为固有频率和衰减率的基本动态模式，并分析其频率分布。

Result: 通过分析健康人和患者的脑电图数据，发现DMD频率分布能更准确地区分患者和健康人，优于离散傅里叶变换的振幅谱。

Conclusion: DMD频率分布能表征非线性时空动态，可能成为神经电生理信号的新生物标志物。

Abstract: Decomposing multivariate time series with certain basic dynamics is crucial
for understanding, predicting and controlling nonlinear spatiotemporally
dynamic systems such as the brain. Dynamic mode decomposition (DMD) is a method
for decomposing nonlinear spatiotemporal dynamics into several basic dynamics
(dynamic modes; DMs) with intrinsic frequencies and decay rates. In particular,
unlike Fourier transform-based methods, which are used to decompose a
single-channel signal into the amplitudes of sinusoidal waves with discrete
frequencies at a regular interval, DMD can derive the intrinsic frequencies of
a multichannel signal on the basis of the available data; furthermore, it can
capture nonstationary components such as alternations between states with
different intrinsic frequencies. Here, we propose the use of the distribution
of intrinsic frequencies derived from DMDs (DM frequencies) to characterise
neural activities. The distributions of DM frequencies in the
electroencephalograms of healthy subjects and patients with dementia or
Parkinson's disease in a resting state were evaluated. By using the
distributions, these patients were distinguished from healthy subjects with
significantly greater accuracy than when using amplitude spectra derived by
discrete Fourier transform. This finding suggests that the distribution of DM
frequencies exhibits distinct behaviour from amplitude spectra, and therefore,
the distribution may serve as a new biomarker by characterising the nonlinear
spatiotemporal dynamics of electrophysiological signals.

</details>


### [22] [Pinching-Antenna Systems for Physical Layer Security](https://arxiv.org/abs/2507.10167)
*Kaidi Wang,Zhiguo Ding,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 研究捏握天线系统如何通过振幅和相位调整增强物理层安全性，提出基于Shapley值的天线激活算法，显著提升保密率。


<details>
  <summary>Details</summary>
Motivation: 探索捏握天线系统在物理层安全中的潜力，以解决传统方法在信号增强和干扰设计上的不足。

Method: 通过预装多根天线，构建联盟博弈模型，提出基于Shapley值的天线激活算法，量化各天线的贡献。

Result: 仿真结果表明，该系统显著提升了保密率，且基于Shapley值的算法优于传统方案。

Conclusion: 捏握天线系统及其算法为物理层安全提供了高效公平的解决方案。

Abstract: This letter investigates the potential of pinching-antenna systems for
enhancing physical layer security. By pre-installing multiple pinching antennas
at discrete positions along a waveguide, the capability of the considered
system to perform amplitude and phase adjustment is validated through the
formulation of a secrecy rate maximization problem. Specifically, amplitude
control is applied to enhance the signal quality at the legitimate user, while
phase alignment is designed to degrade the received signal quality at the
eavesdropper. This cooperation among pinching antennas is modeled as a
coalitional game, and a corresponding antenna activation algorithm is proposed.
The individual impact of each antenna is quantified based on the Shapley value
and marginal contribution, providing a fair and efficient method for
performance evaluation. Simulation results show that the considered
pinching-antenna system achieves significant improvements in secrecy rate, and
that the Shapley value based algorithm outperforms conventional coalition value
based solutions.

</details>


### [23] [Pinching-Antenna Systems with LoS Blockages](https://arxiv.org/abs/2507.10173)
*Kaidi Wang,Chongjun Ouyang,Yuanwei Liu,Zhiguo Ding*

Main category: eess.SP

TL;DR: 该论文研究了利用pinching天线系统在存在视线(LoS)阻塞时构建LoS链路的能力，通过优化波导分配和天线激活以最大化总速率，验证了系统动态建立LoS链路并减轻干扰的效果。


<details>
  <summary>Details</summary>
Motivation: 探索pinching天线系统在LoS阻塞情况下构建LoS链路的潜力，以增强信号并消除用户间干扰。

Method: 提出了一种基于匹配的算法，通过联合优化波导分配和天线激活来解决总速率最大化问题。

Result: 仿真结果表明，该系统能动态建立LoS链路并有效利用LoS阻塞减轻干扰，显著提升系统吞吐量。

Conclusion: pinching天线系统及其优化算法能有效应对LoS阻塞，提升通信系统性能。

Abstract: The aim of this letter is to explore the capability of pinching-antenna
systems to construct line-of-sight (LoS) links in the presence of LoS
blockages. Specifically, pinching antennas are pre-installed at preconfigured
positions along waveguides and can be selectively activated to create LoS links
for enhancing desired signals and non-line-of-sight (NLoS) links for
eliminating inter-user interference. On this basis, a sum-rate maximization
problem is formulated by jointly optimizing waveguide assignment and antenna
activation. To solve this problem, a matching based algorithm is proposed using
two distinct preference designs. Simulation results demonstrate that the
considered pinching-antenna system and proposed solutions can dynamically
establish LoS links and effectively exploit LoS blockages to mitigate
interference, thereby significantly improving system throughput.

</details>


### [24] [Enhanced Throughput and Seamless Handover Solutions for Urban 5G-Vehicle C-Band Integrated Satellite-Terrestrial Networks](https://arxiv.org/abs/2507.10308)
*Hung Nguyen-Kha,Vu Nguyen Ha,Eva Lagunas,Symeon Chatzinotas,Joel Grotz*

Main category: eess.SP

TL;DR: 论文研究了5G卫星地面网络中的下行传输问题，提出了一种多目标优化算法，以提高吞吐量和无缝切换性能。


<details>
  <summary>Details</summary>
Motivation: 城市环境中，由于密集的障碍物、用户移动性及卫星动态覆盖，用户关联和资源分配面临挑战。

Method: 提出了一种基于SCA技术的迭代算法和预测算法，联合优化功率分配和用户关联。

Result: 仿真结果显示，所提算法在吞吐量和连接变更次数上优于贪婪算法和基准算法。

Conclusion: 算法在现实场景中有效解决了5G卫星地面网络的传输问题。

Abstract: This paper investigates downlink transmission in 5G Integrated
Satellite-Terrestrial Networks (ISTNs) supporting automotive users (UEs) in
urban environments, where base stations (BSs) and Low Earth Orbit (LEO)
satellites (LSats) cooperate to serve moving UEs over shared C-band frequency
carriers. Urban settings, characterized by dense obstructions, together with UE
mobility, and the dynamic movement and coverage of LSats pose significant
challenges to user association and resource allocation. To address these
challenges, we formulate a multi-objective optimization problem designed to
improve both throughput and seamless handover (HO). Particularly, the
formulated problem balances sum-rate (SR) maximization and connection change
(CC) minimization through a weighted trade-off by jointly optimizing power
allocation and BS-UE/LSat-UE associations over a given time window. This is a
mixed-integer and non-convex problem which is inherently difficult to solve. To
solve this problem efficiently, we propose an iterative algorithm based on the
Successive Convex Approximation (SCA) technique. Furthermore, we introduce a
practical prediction-based algorithm capable of providing efficient solutions
in real-world implementations. Especially, the simulations use a realistic 3D
map of London and UE routes obtained from the Google Navigator application to
ensure practical examination. Thanks to these realistic data, the simulation
results can show valuable insights into the link budget assessment in urban
areas due to the impact of buildings on transmission links under the blockage,
reflection, and diffraction effects. Furthermore, the numerical results
demonstrate the effectiveness of our proposed algorithms in terms of SR and the
CC-number compared to the greedy and benchmark algorithms.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [25] [Transformer based Collaborative Reinforcement Learning for Fluid Antenna System (FAS)-enabled 3D UAV Positioning](https://arxiv.org/abs/2507.09094)
*Xiaoren Xu,Hao Xu,Dongyu Wei,Walid Saad,Mehdi Bennis,Mingzhe Chen*

Main category: cs.NI

TL;DR: 提出了一种基于流体天线系统（FAS）的无人机（UAV）三维定位框架，利用多智能体强化学习优化轨迹和天线选择，显著降低定位误差。


<details>
  <summary>Details</summary>
Motivation: 解决移动目标无人机的实时三维定位问题，通过优化控制无人机的轨迹和天线选择，提高定位精度。

Method: 采用基于注意力的循环多智能体强化学习（AR-MARL）方案，结合RNN和注意力机制优化局部Q函数，提升全局定位性能。

Result: 仿真结果显示，相比VD-MARL和非FAS方法，定位误差分别降低17.5%和58.5%。

Conclusion: AR-MARL方案有效提升了FAS-UAV系统的定位精度，具有显著优势。

Abstract: In this paper, a novel Three dimensional (3D) positioning framework of fluid
antenna system (FAS)-enabled unmanned aerial vehicles (UAVs) is developed. In
the proposed framework, a set of controlled UAVs cooperatively estimate the
real-time 3D position of a target UAV. Here, the active UAV transmits a
measurement signal to the passive UAVs via the reflection from the target UAV.
Each passive UAV estimates the distance of the active-target-passive UAV link
and selects an antenna port to share the distance information with the base
station (BS) that calculates the real-time position of the target UAV. As the
target UAV is moving due to its task operation, the controlled UAVs must
optimize their trajectories and select optimal antenna port, aiming to estimate
the real-time position of the target UAV. We formulate this problem as an
optimization problem to minimize the target UAV positioning error via
optimizing the trajectories of all controlled UAVs and antenna port selection
of passive UAVs. Here, an attention-based recurrent multi-agent reinforcement
learning (AR-MARL) scheme is proposed, which enables each controlled UAV to use
the local Q function to determine its trajectory and antenna port while
optimizing the target UAV positioning performance without knowing the
trajectories and antenna port selections of other controlled UAVs. Different
from current MARL methods, the proposed method uses a recurrent neural network
(RNN) that incorporates historical state-action pairs of each controlled UAV,
and an attention mechanism to analyze the importance of these historical
state-action pairs, thus improving the global Q function approximation accuracy
and the target UAV positioning accuracy. Simulation results show that the
proposed AR-MARL scheme can reduce the average positioning error by up to 17.5%
and 58.5% compared to the VD-MARL scheme and the proposed method without FAS.

</details>


### [26] [Reliable Task Offloading in MEC through Transmission Diversity and Jamming-Aware Scheduling](https://arxiv.org/abs/2507.09352)
*Ghazal Asemian,Mohammadreza Amini,Burak Kantarci*

Main category: cs.NI

TL;DR: 该论文提出了一种动态MEC框架，通过结合传输多样性解决动态任务卸载和资源分配的挑战，特别是在干扰环境下。提出的算法显著降低了任务丢弃率并提高了资源利用率。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）能够通过将计算任务放在靠近用户的位置来实现低延迟应用，但动态任务到达和通信干扰（如干扰）使得任务卸载和资源分配变得复杂。因此，需要一种能够应对干扰的动态解决方案。

Method: 论文定义并评估了关键网络指标（如任务丢弃率和带宽利用率），同时考虑边缘服务器对先前任务的承诺。提出了一种基于传输多样性的干扰感知卸载和资源块（RB）分配框架，通过分布式gNBs的优化调度实现。

Result: 在信号干扰噪声比（SJNR）为4 dB时，所提算法的任务丢弃率为0.26，显著优于无传输多样性的场景（0.50）以及FCFS（0.63）和STF（0.52）策略。

Conclusion: 该算法有效减轻了干扰的影响，显著提高了资源利用率和任务完成率，非常适合任务关键的MEC应用。

Abstract: Mobile Edge Computing (MEC) enables low-latency applications by bringing
computation closer to the user, but dynamic task arrivals and communication
threats like jamming complicate reliable task offloading and resource
allocation. In this paper, we formulate a dynamic MEC framework considering the
transmission diversity that jointly addresses task scheduling and resource
block (RB) assignment in the presence of jamming. First, we define and evaluate
key network metrics-including dropped task ratio and bandwidth
utilization-while maintaining service continuity by accounting for the existing
commitments of the edge server to previously offloaded tasks. Then, we propose
a jamming-aware offloading and RB allocation framework that leverages
transmission diversity and optimal scheduling across distributed gNBs. The
proposed solution is compared to a similar scenario without transmission
diversity and two baseline strategies of first-come-first-served (FCFS) and
shortest task first (STF). The proposed algorithm effectively mitigates the
impact of jamming while enhancing resource utilization and minimizing task drop
rates, making it highly suitable for mission-critical MEC applications. At
signal-to-jamming-and-noise ratio (SJNR) of 4 dB, the proposed method achieves
a $0.26$ task drop rate, outperforming the scenario without transmission
diversity with a task drop rate of 0.50 and STF and FCFS strategies with 0.52
and 0.63 task drop rates, respectively.

</details>


### [27] [Wi-Fi: Twenty-Five Years and Counting](https://arxiv.org/abs/2507.09613)
*Giovanni Geraci,Francesca Meneghello,Francesc Wilhelmi,David Lopez-Perez,Iñaki Val,Lorenzo Galati Giordano,Carlos Cordeiro,Monisha Ghosh,Edward Knightly,Boris Bellalta*

Main category: cs.NI

TL;DR: 这篇论文提供了一个全面的Wi-Fi技术和历史教程，从IEEE 802.11b（Wi-Fi 1）到IEEE 802.11bn（Wi-Fi 8），总结了Wi-Fi发展的关键机制和进步。


<details>
  <summary>Details</summary>
Motivation: 尽管Wi-Fi已有25年历史，但其技术已发生了翻天覆地的变化。本文旨在填补从Wi-Fi 1到Wi-Fi 8的教程空白，并提供全面的技术演进分析。

Method: 通过分析频谱分配、物理层技术、媒体访问控制、多用户接入、节能机制、多频段聚合以及接入点协调等关键机制，探讨Wi-Fi的进步。

Result: 论文总结了Wi-Fi在数据速率、多用户接入、能源效率和频谱利用等方面的显著提升，并展望了未来发展方向。

Conclusion: Wi-Fi的持续演进展示了其适应性和创新性，未来的发展方向包括毫米波集成、传感技术与人工智能的应用。

Abstract: Today, Wi-Fi is over 25 years old. Yet, despite sharing the same branding
name, today's Wi-Fi boasts entirely new capabilities that were not even on the
roadmap 25 years ago. This article aims to provide a holistic and comprehensive
technical and historical tutorial on Wi-Fi, beginning with IEEE 802.11b (Wi-Fi
1) and looking forward to IEEE 802.11bn (Wi-Fi 8). This is the first tutorial
article to span these eight generations. Rather than a generation-by-generation
exposition, we describe the key mechanisms that have advanced Wi-Fi. We begin
by discussing spectrum allocation and coexistence, and detailing the IEEE
802.11 standardization cycle. Second, we provide an overview of the physical
layer and describe key elements that have enabled data rates to increase by
over 1,000x. Third, we describe how Wi-Fi Medium Access Control has been
enhanced from the original Distributed Coordination Function to now include
capabilities spanning from frame aggregation to wideband spectrum access.
Fourth, we describe how Wi-Fi 5 first broke the one-user-at-a-time paradigm and
introduced multi-user access. Fifth, given the increasing use of mobile,
battery-powered devices, we describe Wi-Fi's energy-saving mechanisms over the
generations. Sixth, we discuss how Wi-Fi was enhanced to seamlessly aggregate
spectrum across 2.4 GHz, 5 GHz, and 6 GHz bands to improve throughput,
reliability, and latency. Finally, we describe how Wi-Fi enables nearby Access
Points to coordinate in order to improve performance and efficiency. In the
Appendix, we further discuss Wi-Fi developments beyond 802.11bn, including
integrated mmWave operations, sensing, security and privacy extensions, and the
adoption of AI/ML.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [28] [Joint Access Point Activation and Power Allocation for Cell-Free Massive MIMO Aided ISAC Systems](https://arxiv.org/abs/2507.09425)
*Nguyen Xuan Tung,Le Tung Giang,Trinh Van Chien,Hoang Trong Minh,Lajos Hanzo*

Main category: cs.IT

TL;DR: 论文研究了基于无蜂窝大规模MIMO的ISAC系统，通过激活部分AP实现节能，并提出了一种结合Branch-and-Bound和HetGNN的方法，显著提升效率和速度。


<details>
  <summary>Details</summary>
Motivation: 研究无蜂窝大规模MIMO ISAC系统中通过选择性激活AP和功率控制优化能源效率的需求。

Method: 采用Branch-and-Bound方法作为基线，指导半监督异构图神经网络（HetGNN）进行AP选择和功率分配。

Result: HetGNN将功耗降低20-25%，运行速度比传统方法快近10,000倍。

Conclusion: 该方法在能源效率和计算效率上具有显著优势，适用于大规模ISAC系统。

Abstract: Cell-free massive multiple-input multiple-output (MIMO)-aided integrated
sensing and communication (ISAC) systems are investigated where distributed
access points jointly serve users and sensing targets. We demonstrate that only
a subset of access points (APs) has to be activated for both tasks, while
deactivating redundant APs is essential for power savings. This motivates joint
active AP selection and power control for optimizing energy efficiency. The
resultant problem is a mixed-integer nonlinear program (MINLP). To address
this, we propose a model-based Branch-and-Bound approach as a strong baseline
to guide a semi-supervised heterogeneous graph neural network (HetGNN) for
selecting the best active APs and the power allocation. Comprehensive numerical
results demonstrate that the proposed HetGNN reduces power consumption by
20-25\% and runs nearly 10,000 times faster than model-based benchmarks.

</details>


### [29] [Introducing Meta-Fiber into Stacked Intelligent Metasurfaces for MIMO Communications: A Low-Complexity Design with only Two Layers](https://arxiv.org/abs/2507.09575)
*Hong Niu,Jiancheng An,Tuo Wu,Jiangong Chen,Yufei Zhao,Yong Liang Guan,Marco Di Renzo,Merouane Debbah,George K. Karagiannidis,H. Vincent Poor,Chau Yuen*

Main category: cs.IT

TL;DR: 论文提出了一种新型的堆叠智能超表面（SIM）设计，通过引入元纤维连接两层SIM，提高了能量效率并减少了层数，同时优化了相位偏移以提升信道容量。


<details>
  <summary>Details</summary>
Motivation: 当前SIM设计面临复杂的相位偏移优化和多层能量衰减问题，为此研究提出采用元纤维连接减少层数并提高效率。

Method: 提出元纤维连接的两层SIM结构，通过优化相位偏移和交替优化算法，建立了非干扰系统并行子信道。

Result: 新型两层SIM相比传统七层SIM，信道容量提升25%，元原子总数减少59%。

Conclusion: 元纤维连接的SIM设计在减少复杂性和提高性能方面具有显著优势，为未来高效SIM系统提供了新思路。

Abstract: Stacked intelligent metasurfaces (SIMs), which integrate multiple
programmable metasurface layers, have recently emerged as a promising
technology for advanced wave-domain signal processing. SIMs benefit from
flexible spatial degree-of-freedom (DoF) while reducing the requirement for
costly radio-frequency (RF) chains. However, current state-of-the-art SIM
designs face challenges such as complex phase shift optimization and energy
attenuation from multiple layers. To address these aspects, we propose
incorporating meta-fibers into SIMs, with the aim of reducing the number of
layers and enhancing the energy efficiency. First, we introduce a
meta-fiber-connected 2-layer SIM that exhibits the same flexible signal
processing capabilities as conventional multi-layer structures, and explains
the operating principle. Subsequently, we formulate and solve the optimization
problem of minimizing the mean square error (MSE) between the SIM channel and
the desired channel matrices. Specifically, by designing the phase shifts of
the meta-atoms associated with the transmitting-SIM and receiving-SIM, a
non-interference system with parallel subchannels is established. In order to
reduce the computational complexity, a closed-form expression for each phase
shift at each iteration of an alternating optimization (AO) algorithm is
proposed. We show that the proposed algorithm is applicable to conventional
multi-layer SIMs. The channel capacity bound and computational complexity are
analyzed to provide design insights. Finally, numerical results are
illustrated, demonstrating that the proposed two-layer SIM with meta-fiber
achieves over a 25% improvement in channel capacity while reducing the total
number of meta-atoms by 59% as compared with a conventional seven-layer SIM.

</details>


### [30] [Learning-Aided Iterative Receiver for Superimposed Pilots: Design and Experimental Evaluation](https://arxiv.org/abs/2507.10074)
*Xinjie Li,Xingyu Zhou,Yixiao Cao,Jing Zhang,Chao-Kai Wen,Xiao Li,Shi Jin*

Main category: cs.IT

TL;DR: 提出了一种基于叠加导频传输方案的迭代接收机，通过联合信道估计、检测和解码提升性能，深度学习估计器在性能与复杂度间取得较好平衡。


<details>
  <summary>Details</summary>
Motivation: 叠加导频传输方案在MIMO-OFDM系统中可提升频谱效率，但导频污染和数据干扰带来接收机设计挑战。

Method: 采用变分消息传递（VMP）及其低复杂度版本（VMP-L）进行信道估计，并提出基于深度学习的估计器，结合解扩模块和注意力机制。

Result: 仿真和实验表明，该接收机在吞吐量和误块率上均优于传统正交导频基准，深度学习估计器尤其适用于动态无线环境。

Conclusion: 该设计在实际部署中表现出色，特别是深度学习方法在性能与复杂度间取得了良好平衡。

Abstract: The superimposed pilot transmission scheme offers substantial potential for
improving spectral efficiency in MIMO-OFDM systems, but it presents significant
challenges for receiver design due to pilot contamination and data
interference. To address these issues, we propose an advanced iterative
receiver based on joint channel estimation, detection, and decoding, which
refines the receiver outputs through iterative feedback. The proposed receiver
incorporates two adaptive channel estimation strategies to enhance robustness
under time-varying and mismatched channel conditions. First, a variational
message passing (VMP) method and its low-complexity variant (VMP-L) are
introduced to perform inference without relying on time-domain correlation.
Second, a deep learning (DL) based estimator is developed, featuring a
convolutional neural network with a despreading module and an attention
mechanism to extract and fuse relevant channel features. Extensive simulations
under multi-stream and high-mobility scenarios demonstrate that the proposed
receiver consistently outperforms conventional orthogonal pilot baselines in
both throughput and block error rate. Moreover, over-the-air experiments
validate the practical effectiveness of the proposed design. Among the methods,
the DL based estimator achieves a favorable trade-off between performance and
complexity, highlighting its suitability for real-world deployment in dynamic
wireless environments.

</details>


### [31] [Improved Differential Evolution for Enhancing the Aggregated Channel Estimation of RIS-Aided Cell-Free Massive MIMO](https://arxiv.org/abs/2507.10113)
*Trinh Van Chien,Nguyen Hoang Viet,Symeon Chatzinotas,Lajos Hanzo*

Main category: cs.IT

TL;DR: 研究支持RIS的无蜂窝大规模MIMO系统，通过优化RIS相位偏移提升信道估计性能，提出改进的差分进化算法避免局部最优，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在空间相关性的背景下，需要通过RIS优化信道估计性能，解决传统方法在非凸问题中的局限性。

Method: 采用LMMSE估计聚合信道，设计优化问题最小化NMSE，并提出增强的差分进化算法以避免局部最优。

Result: 数值结果表明，所提算法在信道估计质量上显著优于现有基准方法。

Conclusion: 支持RIS的无蜂窝大规模MIMO系统通过优化相位偏移和改进算法，有效提升了信道估计性能。

Abstract: Cell-Free Massive multiple-input multiple-output (MIMO) systems are
investigated with the support of a reconfigurable intelligent surface (RIS).
The RIS phase shifts are designed for improved channel estimation in the
presence of spatial correlation. Specifically, we formulate the channel
estimate and estimation error expressions using linear minimum mean square
error (LMMSE) estimation for the aggregated channels. An optimization problem
is then formulated to minimize the average normalized mean square error (NMSE)
subject to practical phase shift constraints. To circumvent the problem of
inherent nonconvexity, we then conceive an enhanced version of the differential
evolution algorithm that is capable of avoiding local minima by introducing an
augmentation operator applied to some high-performing Diffential Evolution (DE)
individuals. Numerical results indicate that our proposed algorithm can
significantly improve the channel estimation quality of the state-of-the-art
benchmarks.

</details>


### [32] [Low-Power Wake-Up Signal Design in 3GPP 5G-Advanced Release 19](https://arxiv.org/abs/2507.10207)
*Sebastian Wagner*

Main category: cs.IT

TL;DR: 5G-Advanced Release 19引入LP-WUS和LP-SS，显著提升物联网通信的能效。


<details>
  <summary>Details</summary>
Motivation: 为了减少物联网设备的功耗，改进5G通信的能效。

Method: 采用LP-WUS和LP-SS程序，通过低功耗能量检测器（ED）检测信号，主无线电（MR）保持关闭。

Result: 与传统5G寻呼机制相比，功耗降低高达80%。

Conclusion: LP-WUS和LP-SS是5G物联网通信中节能的关键技术。

Abstract: The Low-Power Wake-Up Signal (LP-WUS) and Low-Power Synchronization Signal
(LP-SS), introduced in 3GPP 5G-Advanced Release 19, represent a major step
forward in enabling power-efficient IoT communications. This paper presents a
comprehensive overview of the LP-WUS and LP-SS procedures in the RRC_IDLE and
RRC_INACTIVE states, and outlines key physical layer design choices. The LP-WUS
is designed to be detected by a low-power energy detector (ED), allowing the
main radio (MR) to remain switched off. This architecture enables power savings
of up to 80% compared to conventional 5G paging mechanisms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [33] [Continuous-Time Signal Decomposition: An Implicit Neural Generalization of PCA and ICA](https://arxiv.org/abs/2507.09091)
*Shayan K. Azmoodeh,Krishna Subramani,Paris Smaragdis*

Main category: cs.LG

TL;DR: 论文提出了一个广义的隐式神经信号表示框架，用于解决连续时间向量值信号的低秩分解问题，统一了PCA和ICA方法。


<details>
  <summary>Details</summary>
Motivation: 将低秩分解问题（如PCA和ICA）推广到连续时间向量值信号，并提供一个模型无关的框架来解决该问题。

Method: 通过将信号建模为连续时间随机过程，并引入对比函数项来强制源信号的统计特性（去相关、独立性）。

Result: 该方法可以应用于点云和不规则采样信号，解决了标准技术无法适用的问题。

Conclusion: 该框架在连续域中统一了PCA和ICA方法，扩展了传统分解技术的应用范围。

Abstract: We generalize the low-rank decomposition problem, such as principal and
independent component analysis (PCA, ICA) for continuous-time vector-valued
signals and provide a model-agnostic implicit neural signal representation
framework to learn numerical approximations to solve the problem. Modeling
signals as continuous-time stochastic processes, we unify the approaches to
both the PCA and ICA problems in the continuous setting through a contrast
function term in the network loss, enforcing the desired statistical properties
of the source signals (decorrelation, independence) learned in the
decomposition. This extension to a continuous domain allows the application of
such decompositions to point clouds and irregularly sampled signals where
standard techniques are not applicable.

</details>


### [34] [TolerantECG: A Foundation Model for Imperfect Electrocardiogram](https://arxiv.org/abs/2507.09887)
*Huynh Nguyen Dang,Thang Pham,Ngan Le,Van Nguyen*

Main category: cs.LG

TL;DR: 这篇论文提出了TolerantECG模型，它通过结合对比学习和自监督学习框架，能够在噪声或部分导联缺失的情况下有效处理ECG信号，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: ECG是诊断心脏病的重要工具，但噪声和导联缺失会影响其准确性，因此需要一种更鲁棒的解决方案。

Method: 采用对比学习和自监督学习框架，联合学习ECG信号的表示、文本报告描述以及噪声或导联缺失的信号。

Result: 在PTB-XL数据集的各种条件下表现最佳或次佳，在MIT-BIH Arrhythmia Database上达到最高性能。

Conclusion: TolerantECG模型在噪声和导联缺失的情况下表现出优异的鲁棒性和性能。

Abstract: The electrocardiogram (ECG) is an essential and effective tool for diagnosing
heart diseases. However, its effectiveness can be compromised by noise or
unavailability of one or more leads of the standard 12-lead recordings,
resulting in diagnostic errors or uncertainty. To address these challenges, we
propose TolerantECG, a foundation model for ECG signals that is robust to noise
and capable of functioning with arbitrary subsets of the standard 12-lead ECG.
TolerantECG training combines contrastive and self-supervised learning
frameworks to jointly learn ECG signal representations alongside their
corresponding knowledge-retrieval-based text report descriptions and corrupted
or lead-missing signals. Comprehensive benchmarking results demonstrate that
TolerantECG consistently ranks as the best or second-best performer across
various ECG signal conditions and class levels in the PTB-XL dataset, and
achieves the highest performance on the MIT-BIH Arrhythmia Database.

</details>


### [35] [Convergence of Agnostic Federated Averaging](https://arxiv.org/abs/2507.10325)
*Herlock,Rahimi,Dionysis Kalogerias*

Main category: cs.LG

TL;DR: 该论文分析了联邦学习中客户端非均匀随机参与的问题，提出了无需知道参与分布知识的FedAvg算法，并证明了其在非平滑凸损失下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中客户端间歇性参与和参与概率未知的问题，填补现有假设（全设备参与或均匀分布）与实践之间的差距。

Method: 提出基于随机且可变大小客户端参与的FedAvg算法，理论分析其优化问题与收敛性。

Result: 证明了算法在非平滑凸损失下的收敛性，并实证表明其优于常见的加权聚合FedAvg变体。

Conclusion: 该研究为联邦学习中的非均匀客户端参与提供了理论基础，展示了FedAvg算法的实际优势。

Abstract: Federated learning (FL) enables decentralized model training without
centralizing raw data. However, practical FL deployments often face a key
realistic challenge: Clients participate intermittently in server aggregation
and with unknown, possibly biased participation probabilities. Most existing
convergence results either assume full-device participation, or rely on
knowledge of (in fact uniform) client availability distributions -- assumptions
that rarely hold in practice. In this work, we characterize the optimization
problem that consistently adheres to the stochastic dynamics of the well-known
\emph{agnostic Federated Averaging (FedAvg)} algorithm under random (and
variably-sized) client availability, and rigorously establish its convergence
for convex, possibly nonsmooth losses, achieving a standard rate of order
$\mathcal{O}(1/\sqrt{T})$, where $T$ denotes the aggregation horizon. Our
analysis provides the first convergence guarantees for agnostic FedAvg under
general, non-uniform, stochastic client participation, without knowledge of the
participation distribution. We also empirically demonstrate that agnostic
FedAvg in fact outperforms common (and suboptimal) weighted aggregation FedAvg
variants, even with server-side knowledge of participation weights.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [36] [CovertAuth: Joint Covert Communication and Authentication in MmWave Systems](https://arxiv.org/abs/2507.08904)
*Yulin Teng,Keshuang Han,Pinchang Zhang,Xiaohong Jiang,Yulong Shen,Fu Xiao*

Main category: cs.CR

TL;DR: 本文提出了一种名为CovertAuth的安全框架，用于增强毫米波通信中波束对准阶段的安全性，防止窃听和身份冒充攻击。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信的波束对准阶段因其全向性和广播特性，易受窃听和身份冒充攻击，亟需一种安全解决方案。

Method: 通过推导成功的波束对准概率和隐蔽传输速率的闭式表达式，优化问题被提出并采用交替优化算法解决；利用天线阵列受损的耦合效应设计物理层认证方案，并通过理论模型分析性能。

Result: 仿真结果表明，CovertAuth在相同隐蔽性要求下具有更高的检测精度。

Conclusion: CovertAuth有效提升了毫米波通信波束对准阶段的安全性，为相关攻击提供了可靠的防御手段。

Abstract: Beam alignment (BA) is a crucial process in millimeter-wave (mmWave)
communications, enabling precise directional transmission and efficient link
establishment. However, due to characteristics like omnidirectional exposure
and the broadcast nature of the BA phase, it is particularly vulnerable to
eavesdropping and identity impersonation attacks. To this end, this paper
proposes a novel secure framework named CovertAuth, designed to enhance the
security of the BA phase against such attacks. In particular, to combat
eavesdropping attacks, the closed-form expressions of successful BA probability
and covert transmission rate are first derived. Then, a covert communication
problem aimed at jointly optimizing beam training budget and transmission power
is formulated to maximize covert communication rate, subject to the covertness
requirement. An alternating optimization algorithm combined with successive
convex approximation is employed to iteratively achieve optimal results. To
combat impersonation attacks, the mutual coupling effect of antenna array
impairments is explored as a device feature to design a weighted-sum energy
detector based physical layer authentication scheme. Moreover, theoretical
models for authentication metrics like detection and false alarm probabilities
are also provided to conduct performance analysis. Based on these models, an
optimization problem is constructed to determine the optimal weight value that
maximizes authentication accuracy. Finally, simulation results demonstrate that
CovertAuth presents improved detection accuracy under the same covertness
requirement compared to existing works.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [37] [Signed Graph Learning: Algorithms and Theory](https://arxiv.org/abs/2507.09717)
*Abdullah Karaaslanli,Bisakh Banerjee,Tapabrata Maiti,Selin Aviyente*

Main category: stat.ML

TL;DR: 论文提出了一种从平滑有符号图信号中学习有符号图结构的方法，通过定义净拉普拉斯矩阵作为图移位算子，并利用ADMM算法求解非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的数据通常通过样本间的关系表示为图结构。现有研究主要关注无符号图，但许多生物和社会系统更适合用有符号图来描述。

Method: 使用净拉普拉斯矩阵作为图移位算子，定义平滑有符号图信号，并通过ADMM算法优化求解非凸问题。

Result: 算法具有线性复杂度，并提供了收敛性证明和估计误差界限。方法在模拟数据和基因调控网络推断中表现优于现有方法。

Conclusion: 该方法有效地学习了有符号图结构，为复杂系统的建模提供了新工具。

Abstract: Real-world data is often represented through the relationships between data
samples, forming a graph structure. In many applications, it is necessary to
learn this graph structure from the observed data. Current graph learning
research has primarily focused on unsigned graphs, which consist only of
positive edges. However, many biological and social systems are better
described by signed graphs that account for both positive and negative
interactions, capturing similarity and dissimilarity between samples. In this
paper, we develop a method for learning signed graphs from a set of smooth
signed graph signals. Specifically, we employ the net Laplacian as a graph
shift operator (GSO) to define smooth signed graph signals as the outputs of a
low-pass signed graph filter defined by the net Laplacian. The signed graph is
then learned by formulating a non-convex optimization problem where the total
variation of the observed signals is minimized with respect to the net
Laplacian. The proposed problem is solved using alternating direction method of
multipliers (ADMM) and a fast algorithm reducing the per-ADMM iteration
complexity from quadratic to linear in the number of nodes is introduced.
Furthermore, theoretical proofs of convergence for the algorithm and a bound on
the estimation error of the learned net Laplacian as a function of sample size,
number of nodes, and graph topology are provided. Finally, the proposed method
is evaluated on simulated data and gene regulatory network inference problem
and compared to existing signed graph learning methods.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [38] [Unscented Kalman Filter with a Nonlinear Propagation Model for Navigation Applications](https://arxiv.org/abs/2507.10082)
*Amit Levy,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种改进无迹卡尔曼滤波器中sigma点传播的新方法，以提高导航精度。


<details>
  <summary>Details</summary>
Motivation: 在导航应用中，无迹卡尔曼滤波器的均值和协方差矩阵预测对滤波器稳定性至关重要。

Method: 通过非线性动态模型传播sigma点，改进导航误差状态向量的预测。

Result: 实验表明，该方法提高了滤波器精度和导航性能。

Conclusion: 新方法在自主水下车辆的真实数据中验证了其有效性。

Abstract: The unscented Kalman filter is a nonlinear estimation algorithm commonly used
in navigation applications. The prediction of the mean and covariance matrix is
crucial to the stable behavior of the filter. This prediction is done by
propagating the sigma points according to the dynamic model at hand. In this
paper, we introduce an innovative method to propagate the sigma points
according to the nonlinear dynamic model of the navigation error state vector.
This improves the filter accuracy and navigation performance. We demonstrate
the benefits of our proposed approach using real sensor data recorded by an
autonomous underwater vehicle during several scenarios.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [39] [Cyclic Multichannel Wiener Filter for Acoustic Beamforming](https://arxiv.org/abs/2507.10159)
*Giovanni Bologni,Richard Heusdens,Richard C. Hendriks*

Main category: eess.AS

TL;DR: 论文提出了一种针对周期性语音信号的循环多通道维纳滤波器（cMWF），利用谐波频率的频谱相关性降低均方误差（MSE），实验显示其在合成数据上表现优异，但对基频估计精度敏感。


<details>
  <summary>Details</summary>
Motivation: 传统声学波束赋形模型假设语音信号在短时帧内是广义平稳的，但实际语音更接近周期性平稳（CS）过程。本文旨在利用这一特性改进语音增强效果。

Method: 基于周期性平稳模型，推导出循环多通道维纳滤波器（cMWF），通过谐波频率的频谱相关性优化MSE。

Result: 仿真数据实验显示SI-SDR显著提升，但对基频估计精度要求高，实际数据效果受限。

Conclusion: cMWF在周期性语音信号增强上优于传统方法，但实际应用中需提高基频估计精度。

Abstract: Acoustic beamforming models typically assume wide-sense stationarity of
speech signals within short time frames. However, voiced speech is better
modeled as a cyclostationary (CS) process, a random process whose mean and
autocorrelation are $T_1$-periodic, where $\alpha_1=1/T_1$ corresponds to the
fundamental frequency of vowels. Higher harmonic frequencies are found at
integer multiples of the fundamental. This work introduces a cyclic
multichannel Wiener filter (cMWF) for speech enhancement derived from a
cyclostationary model. This beamformer exploits spectral correlation across the
harmonic frequencies of the signal to further reduce the mean-squared error
(MSE) between the target and the processed input. The proposed cMWF is optimal
in the MSE sense and reduces to the MWF when the target is wide-sense
stationary. Experiments on simulated data demonstrate considerable improvements
in scale-invariant signal-to-distortion ratio (SI-SDR) on synthetic data but
also indicate high sensitivity to the accuracy of the estimated fundamental
frequency $\alpha_1$, which limits effectiveness on real data.

</details>


### [40] [Harmonics to the Rescue: Why Voiced Speech is Not a Wss Process](https://arxiv.org/abs/2507.10176)
*Giovanni Bologni,Richard Heusdens,Richard C. Hendriks*

Main category: eess.AS

TL;DR: 传统语音处理常假设语音为宽平稳（WSS）过程，但该模型不适用于频谱相关的过程。本文提出用循环平稳（CS）模型更准确地描述语音信号，并展示了其在功率谱密度估计、源分离和波束成形中的优势。


<details>
  <summary>Details</summary>
Motivation: 现有语音处理模型（WSS）未充分考虑频谱相关性，限制了语音信号处理的准确性。探索更合适的统计模型（CS）以提升性能。

Method: 将语音信号建模为循环平稳（CS）过程，利用其在谐波频率上的相关性，改进系统识别和信号处理任务。

Result: 实验证明，CS模型能更准确地估计功率谱密度，并在源分离和波束成形中表现优于WSS模型。

Conclusion: 循环平稳模型为语音信号处理提供了更佳的理论框架，显著提升了相关任务的性能。

Abstract: Speech processing algorithms often rely on statistical knowledge of the
underlying process. Despite many years of research, however, the debate on the
most appropriate statistical model for speech still continues. Speech is
commonly modeled as a wide-sense stationary (WSS) process. However, the use of
the WSS model for spectrally correlated processes is fundamentally wrong, as
WSS implies spectral uncorrelation. In this paper, we demonstrate that voiced
speech can be more accurately represented as a cyclostationary (CS) process. By
employing the CS rather than the WSS model for processes that are inherently
correlated across frequency, it is possible to improve the estimation of
cross-power spectral densities (PSDs), source separation, and beamforming. We
illustrate how the correlation between harmonic frequencies of CS processes can
enhance system identification, and validate our findings using both simulated
and real speech data.

</details>
