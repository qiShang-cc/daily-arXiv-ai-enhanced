{"id": "2509.06966", "pdf": "https://arxiv.org/pdf/2509.06966", "abs": "https://arxiv.org/abs/2509.06966", "authors": ["Neal G. Ravindra", "Arijit Sehanobish"], "title": "Cross-device Zero-shot Label Transfer via Alignment of Time Series Foundation Model Embeddings", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "5 pages, 3 figures, 1 table. tl;dr: Adversarial alignment of\n  Time-Series Foundation Model (TSFM) embeddings enables transfer of\n  high-quality clinical labels from medical-grade to consumer-grade wearables,\n  enabling zero-shot prediction of gestational age without requiring paired\n  data", "summary": "High-quality, medically validated labels exist for clinical actigraphy data\nbut not for ubiquitous consumer wearables like the Apple Watch. Manually\nlabeling wearables data is expensive and doesn't scale. This paper offers a\nnovel framework that transfers valuable labels from a source domain (e.g.,\nactigraphy) to a target domain (e.g., Apple Watch) without requiring paired\ndata. Instead of working with raw time-series signals, we project both domains\ninto a shared latent embedding space using time-series foundation models\n(TSFMs) and develop a new framework to align the cross-device representations.\nOur method, Adversarial Alignment of TSFM Embeddings forces the distributions\nof source and target embeddings to align within this space, facilitating label\ntransfer across device type.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u5c06\u6e90\u57df\u548c\u76ee\u6807\u57df\u6295\u5f71\u5230\u5171\u4eab\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u7528\u5bf9\u6297\u6027\u5bf9\u9f50\u65b9\u6cd5\u5b9e\u73b0\u8de8\u8bbe\u5907\u6807\u7b7e\u8f6c\u79fb\u3002", "motivation": "\u89e3\u51b3\u6d88\u8d39\u7ea7\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u533b\u5b66\u6807\u7b7e\u7684\u95ee\u9898\uff0c\u907f\u514d\u6602\u8d35\u4e14\u4e0d\u53ef\u6269\u5c55\u7684\u624b\u52a8\u6807\u6ce8\u3002", "method": "\u4f7f\u7528TSFMs\u5c06\u6e90\u57df\u548c\u76ee\u6807\u57df\u6295\u5c04\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u6027\u5bf9\u9f50\u6280\u672f\u5bf9\u9f50\u4e24\u8005\u7684\u5206\u5e03\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u8bbe\u5907\uff08\u5982\u4ece\u4e34\u5e8a\u52a8\u6001\u8bb0\u5f55\u4eea\u5230Apple Watch\uff09\u7684\u6807\u7b7e\u8f6c\u79fb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6d88\u8d39\u7ea7\u53ef\u7a7f\u6234\u8bbe\u5907\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u6807\u7b7e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06967", "pdf": "https://arxiv.org/pdf/2509.06967", "abs": "https://arxiv.org/abs/2509.06967", "authors": ["Tianyu Huo", "Jian Xiong", "Yiyan Wu", "Songjie Yang", "Bo Liu", "Wenjun Zhang"], "title": "Cross-field SNR Analysis and Tensor Channel Estimation for Multi-UAV Near-field Communications", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "Extremely large antenna array (ELAA) is key to enhancing spectral efficiency\nin 6G networks. Leveraging the distributed nature of multi-unmanned aerial\nvehicle (UAV) systems enables the formation of distributed ELAA, which often\noperate in the near-field region with spatial sparsity, rendering the\nconventional far-field plane wave assumption invalid. This paper investigates\nchannel estimation for distributed near-field multi-UAV communication systems.\nWe first derive closed-form signal-to-noise ratio (SNR) expressions under the\nplane wave model (PWM), spherical wave model (SWM), and a hybrid\nspherical-plane wave model (HSPWM), also referred to as the cross-field model,\nwithin a distributed uniform planar array (UPA) scenario. The analysis shows\nthat HSPWM achieves a good balance between modeling accuracy and analytical\ntractability. Based on this, we propose two channel estimation algorithms: the\nspherical-domain orthogonal matching pursuit (SD-OMP) and the tensor-OMP. The\nSD-OMP generalizes the polar domain to jointly consider elevation, azimuth, and\nrange. Under the HSPWM, the channel is naturally formulated as a tensor,\nenabling the use of tensor-OMP. Simulation results demonstrate that tensor-OMP\nachieves normalized mean square error (NMSE) performance comparable to SD-OMP,\nwhile offering reduced computational complexity and improved scalability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u8fd1\u573a\u591a\u65e0\u4eba\u673a\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7403\u9762-\u5e73\u9762\u6ce2\u6a21\u578b\uff08HSPWM\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4e24\u79cd\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\uff1a\u7403\u9762\u57df\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\uff08SD-OMP\uff09\u548c\u5f20\u91cf-OMP\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5f20\u91cf-OMP\u5728\u6027\u80fd\u4e0a\u4e0eSD-OMP\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\u4e14\u53ef\u6269\u5c55\u6027\u66f4\u597d\u3002", "motivation": "\u8d85\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\uff08ELAA\uff09\u57286G\u7f51\u7edc\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5176\u5206\u5e03\u5f0f\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u5e38\u5de5\u4f5c\u5728\u8fd1\u573a\u533a\u57df\uff0c\u4f20\u7edf\u7684\u8fdc\u573a\u5e73\u9762\u6ce2\u5047\u8bbe\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63a8\u5bfc\u4e86\u5e73\u9762\u6ce2\u6a21\u578b\uff08PWM\uff09\u3001\u7403\u9762\u6ce2\u6a21\u578b\uff08SWM\uff09\u548c\u6df7\u5408\u7403\u9762-\u5e73\u9762\u6ce2\u6a21\u578b\uff08HSPWM\uff09\u7684\u4fe1\u566a\u6bd4\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51faSD-OMP\u548c\u5f20\u91cf-OMP\u4e24\u79cd\u7b97\u6cd5\u8fdb\u884c\u4fe1\u9053\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5f20\u91cf-OMP\u7684\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\uff08NMSE\uff09\u6027\u80fd\u4e0eSD-OMP\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\uff0c\u53ef\u6269\u5c55\u6027\u66f4\u5f3a\u3002", "conclusion": "HSPWM\u5728\u5efa\u6a21\u7cbe\u5ea6\u548c\u5206\u6790\u6613\u5904\u7406\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u5f20\u91cf-OMP\u4e3a\u8be5\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06968", "pdf": "https://arxiv.org/pdf/2509.06968", "abs": "https://arxiv.org/abs/2509.06968", "authors": ["Murat Temiz", "Yongwei Zhang", "Yanwei Fu", "Chi Zhang", "Chenfeng Meng", "Orhan Kaplan", "Christos Masouros"], "title": "Deep Learning-based Techniques for Integrated Sensing and Communication Systems: State-of-the-Art, Challenges, and Opportunities", "categories": ["eess.SP", "cs.AI"], "comment": "35 Pages, 13 Figures, 11 Tables, corrected version of the published\n  journal article in IEEE Open Journal of the Communications Society", "summary": "This article comprehensively reviews recent developments and research on deep\nlearning-based (DL-based) techniques for integrated sensing and communication\n(ISAC) systems. ISAC, which combines sensing and communication functionalities,\nis regarded as a key enabler for 6G and beyond networks, as many emerging\napplications, such as vehicular networks and industrial robotics, necessitate\nboth sensing and communication capabilities for effective operation. A unified\nplatform that provides both functions can reduce hardware complexity, alleviate\nfrequency spectrum congestion, and improve energy efficiency. However,\nintegrating these functionalities on the same hardware requires highly\noptimized signal processing and system design, introducing significant\ncomputational complexity when relying on conventional iterative or\noptimization-based techniques. As an alternative to conventional techniques,\nDL-based techniques offer efficient and near-optimal solutions with reduced\ncomputational complexity. Hence, such techniques are well-suited for operating\nunder limited computational resources and low latency requirements in real-time\nsystems. DL-based techniques can swiftly and effectively yield near-optimal\nsolutions for a wide range of sophisticated ISAC-related tasks, including\nwaveform design, channel estimation, sensing signal processing, data\ndemodulation, and interference mitigation. Therefore, motivated by these\nadvantages, recent studies have proposed various DL-based approaches for ISAC\nsystem design. After briefly introducing DL architectures and ISAC\nfundamentals, this survey presents a comprehensive and categorized review of\nstate-of-the-art DL-based techniques for ISAC, highlights their key advantages\nand major challenges, and outlines potential directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7cfb\u7edf\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u5f3a\u8c03\u4e86\u5176\u57286G\u7f51\u7edc\u4e2d\u7684\u91cd\u8981\u6027\u53ca\u5176\u4f18\u52bf\u3002", "motivation": "ISAC\u901a\u8fc7\u7ed3\u5408\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\uff0c\u88ab\u89c6\u4e3a6G\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\uff0c\u80fd\u591f\u964d\u4f4e\u786c\u4ef6\u590d\u6742\u5ea6\u3001\u7f13\u89e3\u9891\u8c31\u62e5\u5835\u5e76\u63d0\u9ad8\u80fd\u6548\u3002", "method": "\u8bba\u6587\u56de\u987e\u4e86\u591a\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684ISAC\u6280\u672f\uff0c\u5305\u62ec\u6ce2\u5f62\u8bbe\u8ba1\u3001\u4fe1\u9053\u4f30\u8ba1\u3001\u611f\u77e5\u4fe1\u53f7\u5904\u7406\u7b49\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6280\u672f\u80fd\u591f\u9ad8\u6548\u5730\u4e3a\u590d\u6742ISAC\u4efb\u52a1\u63d0\u4f9b\u8fd1\u6700\u4f18\u89e3\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u7cfb\u7edf\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u5e76\u5206\u7c7b\u4e86\u524d\u6cbf\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684ISAC\u6280\u672f\uff0c\u6307\u51fa\u4e86\u5176\u4f18\u52bf\u3001\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.07134", "pdf": "https://arxiv.org/pdf/2509.07134", "abs": "https://arxiv.org/abs/2509.07134", "authors": ["Baris Donmez", "Sebastien Loranger", "Gunes Karabulut Kurt"], "title": "Modeling the Doppler Shift in Cislunar Environment with Gaussian Mixture Models", "categories": ["eess.SP"], "comment": "6 pages", "summary": "This study investigates the RF-based Doppler shift distribution\ncharacterization of the Lunar South Pole (LSP) based inter-satellite link (ISL)\nin varying inclination. Doppler shift in parts per million (ppm) is determined\nand analyzed, as it provides an independence from the carrier frequency. Due to\nunknown relative velocity states duration, the Gaussian Mixture Model (GMM) is\nfound to be the best fitting distribution for ISLs with $1^\\circ$ inclination\ninterval Doppler shift with respect to a predetermined satellite.\nGoodness-of-fit is investigated and quantified with Kullback-Leibler (KL)\ndivergence and weighted mean relative difference (WMRD) error metrics.\nSimulation results show that ISL Doppler shifts reach up to $\\pm1.89$ ppm as\nthe inclination of the other orbit deviates higher from the reference orbit,\ninclining $80^\\circ$. Regarding the error measurements of GMM fitting, the WMRD\nand KL divergence metrics for ISL take values up to 0.6575 and 2.2963,\nrespectively.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u5206\u6790\u4e86\u6708\u7403\u5357\u6781\uff08LSP\uff09\u536b\u661f\u95f4\u94fe\u8def\uff08ISL\uff09\u5728\u4e0d\u540c\u503e\u89d2\u4e0b\u7684\u591a\u666e\u52d2\u9891\u79fb\u5206\u5e03\uff0c\u9891\u79fb\u53ef\u8fbe\u00b11.89 ppm\uff0c\u62df\u5408\u8bef\u5dee\u6307\u6807WMRD\u548cKL\u6563\u5ea6\u5206\u522b\u9ad8\u8fbe0.6575\u548c2.2963\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u8868\u5f81\u6708\u7403\u5357\u6781\u536b\u661f\u95f4\u94fe\u8def\u5728\u4e0d\u540c\u503e\u89d2\u4e0b\u7684\u591a\u666e\u52d2\u9891\u79fb\u5206\u5e03\uff0c\u4ee5\u63d0\u4f9b\u72ec\u7acb\u4e8e\u8f7d\u6ce2\u9891\u7387\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u62df\u5408\u591a\u666e\u52d2\u9891\u79fb\u6570\u636e\uff0c\u5e76\u901a\u8fc7KL\u6563\u5ea6\u548c\u52a0\u6743\u5e73\u5747\u76f8\u5bf9\u5dee\u5f02\uff08WMRD\uff09\u8bc4\u4f30\u62df\u5408\u4f18\u5ea6\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u8f68\u9053\u503e\u89d2\u504f\u79bb\u53c2\u8003\u8f68\u905380\u00b0\u65f6\uff0c\u591a\u666e\u52d2\u9891\u79fb\u53ef\u8fbe\u00b11.89 ppm\uff1bGMM\u62df\u5408\u7684WMRD\u548cKL\u6563\u5ea6\u6700\u5927\u5206\u522b\u4e3a0.6575\u548c2.2963\u3002", "conclusion": "\u7ed3\u8bba\u663e\u793aGMM\u662f\u62df\u5408ISL\u591a\u666e\u52d2\u9891\u79fb\u5206\u5e03\u7684\u6709\u6548\u6a21\u578b\uff0c\u4f46\u8bef\u5dee\u6307\u6807\u8f83\u9ad8\uff0c\u8868\u660e\u4ecd\u9700\u4f18\u5316\u6a21\u578b\u6216\u65b9\u6cd5\u3002"}}
{"id": "2509.07162", "pdf": "https://arxiv.org/pdf/2509.07162", "abs": "https://arxiv.org/abs/2509.07162", "authors": ["Martin Matak", "Mohanraj Devendran Ashanti", "Karl Van Wyk", "Tucker Hermans"], "title": "First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous multi-finger grasping is a fundamental capability in robotic\nmanipulation. Optimization-based approaches show strong performance, but tend\nto be sensitive to initialization and are potentially time-consuming. As an\nalternative, the generator-evaluator-planner framework has been proposed. A\ngenerator generates grasp candidates, an evaluator ranks the proposed grasps,\nand a motion planner plans a trajectory to the highest-ranked grasp. If the\nplanner doesn't find a trajectory, a new trajectory optimization is started\nwith the next-best grasp as the target and so on. However, executing\nlower-ranked grasps means a lower chance of grasp success, and multiple\ntrajectory optimizations are time-consuming. Alternatively, relaxing the\nthreshold for motion planning accuracy allows for easier computation of a\nsuccessful trajectory but implies lower accuracy in estimating grasp success\nlikelihood. It's a lose-lose proposition: either spend more time finding a\nsuccessful trajectory or have a worse estimate of grasp success. We propose a\nframework that plans trajectories to a set of generated grasp targets in\nparallel, the evaluator estimates the grasp success likelihood of the resulting\ntrajectories, and the robot executes the trajectory most likely to succeed. To\nplan trajectories to different targets efficiently, we propose the use of a\nvectorized motion planner. Our experiments show our approach improves over the\ntraditional generator-evaluator-planner framework across different objects,\ngenerators, and motion planners, and successfully generalizes to novel\nenvironments in the real world, including different shelves and table heights.\nProject website https://sites.google.com/view/fpte", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u89c4\u5212\u8f68\u8ff9\u7684\u65b0\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u591a\u6307\u6293\u53d6\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "motivation": "\u4f20\u7edf\u751f\u6210-\u8bc4\u4f30-\u89c4\u5212\u6846\u67b6\u5728\u5bfb\u627e\u6210\u529f\u8f68\u8ff9\u65f6\u5b58\u5728\u65f6\u95f4\u6d88\u8017\u5927\u6216\u6210\u529f\u7387\u4f30\u8ba1\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u884c\u89c4\u5212\u8f68\u8ff9\u81f3\u591a\u4e2a\u6293\u53d6\u76ee\u6807\u7684\u6846\u67b6\uff0c\u5e76\u4f7f\u7528\u5411\u91cf\u5316\u8fd0\u52a8\u89c4\u5212\u5668\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5bf9\u8c61\u3001\u751f\u6210\u5668\u548c\u8fd0\u52a8\u89c4\u5212\u5668\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u63a8\u5e7f\u5230\u771f\u5b9e\u73af\u5883\u4e2d\u3002", "conclusion": "\u65b0\u6846\u67b6\u5728\u6293\u53d6\u6210\u529f\u7387\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2509.07172", "pdf": "https://arxiv.org/pdf/2509.07172", "abs": "https://arxiv.org/abs/2509.07172", "authors": ["Paula Isabel Tilleria Lucero", "Bryan Fernando Sarango Rodr\u00edguez", "Fernando Dar\u00edo Almeida Garc\u00eda", "Jos\u00e9 C\u00e2ndido Silveira Santos Filho"], "title": "Impact of Fading Correlation on the High-SNR Regime of Reconfigurable Intelligent Surfaces", "categories": ["eess.SP"], "comment": "Accepted for publication in the XLIII Brazilian Symposium on\n  Telecommunications and Signal Processing, 2025", "summary": "This paper addresses three critical limitations in previous analyses of\nRIS-aided wireless systems: propagation environments with fixed diversity gain,\nrestricted spatial correlation profiles, and approximation methods that fail to\ncapture the system behavior in the high signal-to-noise ratio (SNR) regime. To\novercome these challenges, we conduct an exact asymptotic analysis focused on\nthe left tail of the SNR distribution, which plays a critical role in high-SNR\nsystem performance. Additionally, to account for general correlation profiles\nand fading environments with variable diversity and coding gains, we consider\narbitrarily correlated Nakagami-m fading channels. The analytical results show\nthat fading correlation induces a horizontal shift in the asymptotic behavior\n-- represented as a straight line in the log-dB scale -- of the PDF and CDF,\ndisplacing these curves to the left. The asymptotic linear coefficient\nquantifies this shift, while the angular coefficient remains unaffected.\nMoreover, the results reveal that the high sensitivity of the linear\ncoefficient to correlation arises from the aggregated contribution of all\nmarginal asymptotic terms, effectively capturing each channel's correlation\ncharacteristics.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86RIS\u8f85\u52a9\u65e0\u7ebf\u7cfb\u7edf\u5728\u9ad8SNR\u533a\u7684\u6027\u80fd\uff0c\u514b\u670d\u4e86\u56fa\u5b9a\u5206\u96c6\u589e\u76ca\u3001\u53d7\u9650\u7a7a\u95f4\u76f8\u5173\u6027\u548c\u65e0\u6548\u8fd1\u4f3c\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "motivation": "\u89e3\u51b3\u5148\u524d\u7814\u7a76\u4e2d\u56fa\u5b9a\u5206\u96c6\u589e\u76ca\u3001\u7a7a\u95f4\u76f8\u5173\u6027\u53d7\u9650\u53ca\u9ad8SNR\u533a\u884c\u4e3a\u672a\u80fd\u51c6\u786e\u6355\u6349\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cbe\u786e\u6e10\u8fd1\u5206\u6790\u6cd5\uff0c\u7814\u7a76SNR\u5206\u5e03\u5de6\u5c3e\u884c\u4e3a\uff0c\u5e76\u8003\u8651\u5177\u6709\u53ef\u53d8\u5206\u96c6\u548c\u7f16\u7801\u589e\u76ca\u7684Nakagami-m\u8870\u843d\u4fe1\u9053\u3002", "result": "\u7ed3\u679c\u8868\u660e\u8870\u843d\u76f8\u5173\u6027\u5bfc\u81f4PDF\u548cCDF\u66f2\u7ebf\u7684\u6c34\u5e73\u4f4d\u79fb\uff0c\u7ebf\u6027\u7cfb\u6570\u91cf\u5316\u4f4d\u79fb\u89d2\u5ea6\u7cfb\u6570\u4e0d\u53d8\u3002", "conclusion": "\u9ad8SNR\u533a\u6027\u80fd\u5206\u6790\u7684\u5173\u952e\u5728\u4e8e\u76f8\u5173\u6027\u5bf9\u6240\u6709\u6e10\u8fd1\u9879\u7684\u7d2f\u79ef\u8d21\u732e\uff0c\u51c6\u786e\u53cd\u6620\u4e86\u4fe1\u9053\u7279\u6027\u3002"}}
{"id": "2509.07216", "pdf": "https://arxiv.org/pdf/2509.07216", "abs": "https://arxiv.org/abs/2509.07216", "authors": ["Hassen Nigatu", "Shi Gaokun", "Li Jituo", "Wang Jin", "Lu Guodong", "Howard Li"], "title": "Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators", "categories": ["cs.RO"], "comment": null, "summary": "Optimizing high-degree of freedom robotic manipulators requires searching\ncomplex, high-dimensional configuration spaces, a task that is computationally\nchallenging for classical methods. This paper introduces a quantum native\nframework that integrates quantum machine learning with Grover's algorithm to\nsolve kinematic optimization problems efficiently. A parameterized quantum\ncircuit is trained to approximate the forward kinematics model, which then\nconstructs an oracle to identify optimal configurations. Grover's algorithm\nleverages this oracle to provide a quadratic reduction in search complexity.\nDemonstrated on 1-DoF, 2-DoF, and dual-arm manipulator tasks, the method\nachieves significant speedups-up to 93x over classical optimizers like Nelder\nMead as problem dimensionality increases. This work establishes a foundational,\nquantum-native framework for robot kinematic optimization, effectively bridging\nquantum computing and robotics problems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50\u539f\u751f\u6846\u67b6\uff0c\u7ed3\u5408\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u548cGrover\u7b97\u6cd5\uff0c\u9ad8\u6548\u89e3\u51b3\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4f18\u5316\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u76f8\u5bf9\u4e8e\u7ecf\u5178\u65b9\u6cd5\u7684\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4f18\u5316\u4e2d\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u8fd1\u4f3c\u6b63\u8fd0\u52a8\u5b66\u6a21\u578b\uff0c\u6784\u5efa\u7528\u4e8e\u8bc6\u522b\u6700\u4f18\u914d\u7f6e\u7684oracle\uff0c\u5e76\u5229\u7528Grover\u7b97\u6cd5\u5b9e\u73b0\u641c\u7d22\u590d\u6742\u5ea6\u7684\u4e8c\u6b21\u964d\u4f4e\u3002", "result": "\u57281-DoF\u30012-DoF\u548c\u53cc\u81c2\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\uff0c\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe93\u500d\u7684\u52a0\u901f\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4f18\u5316\u5efa\u7acb\u4e86\u91cf\u5b50\u539f\u751f\u6846\u67b6\uff0c\u6709\u6548\u8fde\u63a5\u4e86\u91cf\u5b50\u8ba1\u7b97\u4e0e\u673a\u5668\u4eba\u5b66\u95ee\u9898\u3002"}}
{"id": "2509.07229", "pdf": "https://arxiv.org/pdf/2509.07229", "abs": "https://arxiv.org/abs/2509.07229", "authors": ["Navid Reyhanian", "Reza Ghaderi Zefreh", "Parisa Ramezani", "Emil Bj\u00f6rnson"], "title": "Joint Spatial and Spectral Hybrid Precoding for Multi-User MIMO-OFDM Systems", "categories": ["eess.SP"], "comment": null, "summary": "The deployment of millimeter wave (mmWave) multiple-input multiple-output\n(MIMO) systems cannot rely solely on digital precoding due to hardware\nconstraints. Instead, hybrid precoding, which combines digital and radio\nfrequency (RF) techniques, has emerged as a potential alternative. This\napproach strikes a balance between performance and cost, addressing the\nlimitations of signal mixers and analog-to-digital converters in mmWave\nsystems. mmWave systems are designed to function in wideband channels with\nfrequency selectivity, necessitating the use of orthogonal frequency-division\nmultiplexing (OFDM) to mitigate dispersive channels. However, OFDM faces\nseveral challenges. First, it suffers from a high peak-to-average power ratio\n(PAPR) due to the linear combination of subcarriers. Second, it suffers from\nout-of-band (OOB) emissions due to the sharp spectral transitions of OFDM\nsubcarriers and windowing-induced spectral leakage. Furthermore, phase shifter\n(PS) impairments at the RF transmitter precoder and the user combiner represent\na limitation in practical mmWave systems, leading to phase errors. This work\naddresses these challenges.\n  We study the problem of robust digital-RF precoding optimization for the\ndownlink sum-rate maximization in hybrid multi-user (MU) MIMO-OFDM systems\nunder maximum transmit power, PAPR, and OOB emission constraints. The\nformulated maximization problem is non-convex and difficult to solve. We\npropose a weighted minimum mean squared error (WMMSE) based block coordinate\ndescent (BCD) method to iteratively optimize digital-RF precoders at the\ntransmitter and digital-RF combiners at the users. Low-cost and scalable\noptimization approaches are proposed to efficiently solve the BCD subproblems.\nExtensive simulation results are conducted to demonstrate the efficiency of the\nproposed approaches and exhibit their superiority relative to well-known\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6df7\u5408\u591a\u7528\u6237MIMO-OFDM\u7cfb\u7edf\u4e2d\u4f18\u5316\u7684\u6570\u5b57-RF\u9884\u7f16\u7801\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86OFDM\u7684\u9ad8PAPR\u548cOOB\u95ee\u9898\uff0c\u5e76\u901a\u8fc7WMMSE-BCD\u65b9\u6cd5\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u7531\u4e8e\u786c\u4ef6\u9650\u5236\uff0c\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u65e0\u6cd5\u4ec5\u4f9d\u8d56\u6570\u5b57\u9884\u7f16\u7801\u3002\u6df7\u5408\u9884\u7f16\u7801\u6210\u4e3a\u5e73\u8861\u6027\u80fd\u548c\u6210\u672c\u7684\u6f5c\u5728\u65b9\u6848\uff0c\u4f46\u9762\u4e34OFDM\u7684\u9ad8PAPR\u548cOOB\u6392\u653e\u95ee\u9898\uff0c\u4ee5\u53ca\u76f8\u4f4d\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWMMSE-BCD\u7684\u65b9\u6cd5\uff0c\u8fed\u4ee3\u4f18\u5316\u53d1\u5c04\u7aef\u7684\u6570\u5b57-RF\u9884\u7f16\u7801\u5668\u548c\u7528\u6237\u7aef\u7684\u6570\u5b57-RF\u5408\u5e76\u5668\uff0c\u89e3\u51b3\u4e86\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u5df2\u77e5\u57fa\u51c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408MIMO-OFDM\u7cfb\u7edf\u4e2d\u7684\u9884\u7f16\u7801\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07239", "pdf": "https://arxiv.org/pdf/2509.07239", "abs": "https://arxiv.org/abs/2509.07239", "authors": ["Max Asselmeier", "Abdel Zaro", "Dhruv Ahuja", "Ye Zhao", "Patricio A. Vela"], "title": "Safe Gap-based Planning in Dynamic Settings", "categories": ["cs.RO"], "comment": "Accepted to Algorithms for Machine Vision in Navigation and Control -\n  Springer Publishing House", "summary": "This chapter extends the family of perception-informed gap-based local\nplanners to dynamic environments. Existing perception-informed local planners\nthat operate in dynamic environments often rely on emergent or empirical\nrobustness for collision avoidance as opposed to performing formal analysis of\ndynamic obstacles. This proposed planner, dynamic gap, explicitly addresses\ndynamic obstacles through several steps in the planning pipeline. First, polar\nregions of free space known as gaps are tracked and their dynamics are\nestimated in order to understand how the local environment evolves over time.\nThen, at planning time, gaps are propagated into the future through novel gap\npropagation algorithms to understand what regions are feasible for passage.\nLastly, pursuit guidance theory is leveraged to generate local trajectories\nthat are provably collision-free under ideal conditions. Additionally,\nobstacle-centric ungap processing is performed in situations where no gaps\nexist to robustify the overall planning framework. A set of gap-based planners\nare benchmarked against a series of classical and learned motion planners in\ndynamic environments, and dynamic gap is shown to outperform all other\nbaselines in all environments. Furthermore, dynamic gap is deployed on a\nTurtleBot2 platform in several real-world experiments to validate collision\navoidance behaviors.", "AI": {"tldr": "\u672c\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3adynamic gap\u7684\u52a8\u6001\u73af\u5883\u611f\u77e5\u5c40\u90e8\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u8ddf\u8e2a\u81ea\u7531\u7a7a\u95f4\u4e2d\u7684\u95f4\u9699\uff08gap\uff09\u5e76\u9884\u6d4b\u5176\u52a8\u6001\u53d8\u5316\uff0c\u7ed3\u5408\u8f68\u8ff9\u751f\u6210\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u6001\u73af\u5883\u5c40\u90e8\u89c4\u5212\u5668\u5927\u591a\u4f9d\u8d56\u7ecf\u9a8c\u6027\u9c81\u68d2\u6027\u800c\u975e\u5bf9\u52a8\u6001\u969c\u788d\u7269\u7684\u6b63\u5f0f\u5206\u6790\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u5904\u7406\u52a8\u6001\u969c\u788d\u7269\u3002", "method": "\u901a\u8fc7\u8ddf\u8e2a\u81ea\u7531\u7a7a\u95f4\u4e2d\u7684\u95f4\u9699\u5e76\u9884\u6d4b\u5176\u52a8\u6001\u53d8\u5316\uff0c\u7ed3\u5408\u4f20\u64ad\u7b97\u6cd5\u548c\u8ffd\u51fb\u5f15\u5bfc\u7406\u8bba\u751f\u6210\u5c40\u90e8\u8f68\u8ff9\uff0c\u540c\u65f6\u5728\u65e0\u95f4\u9699\u60c5\u51b5\u4e0b\u8fdb\u884c\u969c\u788d\u7269\u4e2d\u5fc3\u5316\u5904\u7406\u3002", "result": "dynamic gap\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f18\u4e8e\u57fa\u51c6\u5bf9\u6bd4\u7684\u6240\u6709\u7ecf\u5178\u548c\u5b66\u4e60\u578b\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u5e76\u5728TurtleBot2\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5176\u907f\u969c\u80fd\u529b\u3002", "conclusion": "dynamic gap\u901a\u8fc7\u6b63\u5f0f\u5206\u6790\u52a8\u6001\u969c\u788d\u7269\u5e76\u7ed3\u5408\u95f4\u9699\u4f20\u64ad\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u73af\u5883\u5bfc\u822a\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.07293", "pdf": "https://arxiv.org/pdf/2509.07293", "abs": "https://arxiv.org/abs/2509.07293", "authors": ["Miguel Saavedra-Melo", "Benjamin Bradshaw", "Vanessa Yao", "Ender Ayanoglu", "Lee Swindlehurst", "Filippo Capolino"], "title": "Experimental Analysis of Biasing Voltage Generation in Wave-Controlled RIS", "categories": ["eess.SP"], "comment": "13 pages, 19 figures, 2 tables", "summary": "Reconfigurable intelligent surfaces (RISs), an emerging technology proposed\nfor inclusion in next generation wireless communication systems, are\nprogrammable surfaces that can adaptively reflect incident electromagnetic\nradiation in different desired directions. To reduce the complexity and\nphysical profile of conventional RIS designs, a novel concept known as\nWave-Controlled RIS has been proposed, in which standing waves along a\ntransmission line are used to generate the required dc bias for reflective\ncontrol. This paper shows the design of such a Wave-Controlled RIS and its\nbiasing transmission line. The effectiveness of this approach in generating the\ncorrect dc bias from a single standing wave frequency is analyzed through both\ntheoretical modeling and experimental validation, which uncovered a dependence\non impedance matching not accounted for by the theory. Additionally, the\npotential for reflective control using only a single standing wave frequency on\nthe biasing transmission line is explored, demonstrating the ability of\nsingle-beam steering toward angles near broadside.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684Wave-Controlled RIS\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5355\u4e00\u9a7b\u6ce2\u9891\u7387\u751f\u6210\u76f4\u6d41\u504f\u7f6e\uff0c\u964d\u4f4eRIS\u7684\u590d\u6742\u6027\u548c\u7269\u7406\u5c3a\u5bf8\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u4f20\u7edf\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8bbe\u8ba1\u7684\u590d\u6742\u6027\u548c\u7269\u7406\u5c3a\u5bf8\uff0c\u63d0\u51fa\u4e86Wave-Controlled RIS\u7684\u6982\u5ff5\u3002", "method": "\u8bbe\u8ba1\u4e86Wave-Controlled RIS\u53ca\u5176\u504f\u7f6e\u4f20\u8f93\u7ebf\uff0c\u901a\u8fc7\u7406\u8bba\u5efa\u6a21\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5206\u6790\u4e86\u5355\u4e00\u9a7b\u6ce2\u9891\u7387\u751f\u6210\u76f4\u6d41\u504f\u7f6e\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u963b\u6297\u5339\u914d\u7684\u5f71\u54cd\u672a\u88ab\u7406\u8bba\u5b8c\u5168\u8003\u8651\uff0c\u4f46\u8bc1\u660e\u4e86\u5355\u675f\u6ce2\u675f\u8f6c\u5411\u63a5\u8fd1\u6b63\u9762\u7684\u80fd\u529b\u3002", "conclusion": "Wave-Controlled RIS\u5c55\u793a\u4e86\u901a\u8fc7\u5355\u4e00\u9a7b\u6ce2\u9891\u7387\u5b9e\u73b0\u53cd\u5c04\u63a7\u5236\u7684\u6f5c\u529b\uff0c\u7b80\u5316\u4e86RIS\u8bbe\u8ba1\u3002"}}
{"id": "2509.07321", "pdf": "https://arxiv.org/pdf/2509.07321", "abs": "https://arxiv.org/abs/2509.07321", "authors": ["Casey D. Majhor", "Jeremy P. Bos"], "title": "Performance Characterization of a Point-Cloud-Based Path Planner in Off-Road Terrain", "categories": ["cs.RO"], "comment": "This work has been published in the Journal of Field Robotics", "summary": "We present a comprehensive evaluation of a point-cloud-based navigation\nstack, MUONS, for autonomous off-road navigation. Performance is characterized\nby analyzing the results of 30,000 planning and navigation trials in simulation\nand validated through field testing. Our simulation campaign considers three\nkinematically challenging terrain maps and twenty combinations of seven\npath-planning parameters. In simulation, our MUONS-equipped AGV achieved a 0.98\nsuccess rate and experienced no failures in the field. By statistical and\ncorrelation analysis we determined that the Bi-RRT expansion radius used in the\ninitial planning stages is most correlated with performance in terms of\nplanning time and traversed path length. Finally, we observed that the\nproportional variation due to changes in the tuning parameters is remarkably\nwell correlated to performance in field testing. This finding supports the use\nof Monte-Carlo simulation campaigns for performance assessment and parameter\ntuning.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u70b9\u4e91\u5bfc\u822a\u7cfb\u7edfMUONS\u5728\u81ea\u4e3b\u8d8a\u91ce\u5bfc\u822a\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u5730\u6d4b\u8bd5\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1MUONS\u5728\u590d\u6742\u5730\u5f62\u4e2d\u7684\u5bfc\u822a\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u4f18\u5316\u53c2\u6570\u4ee5\u63d0\u9ad8\u6210\u529f\u7387\u3002", "method": "\u8fdb\u884c\u4e8630,000\u6b21\u4eff\u771f\u548c\u5b9e\u5730\u6d4b\u8bd5\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u5730\u5f62\u548c\u8def\u5f84\u89c4\u5212\u53c2\u6570\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "MUONS\u5728\u4eff\u771f\u4e2d\u6210\u529f\u7387\u9ad8\u8fbe0.98\uff0c\u4e14\u672a\u5728\u5b9e\u5730\u6d4b\u8bd5\u4e2d\u51fa\u73b0\u6545\u969c\u3002Bi-RRT\u6269\u5c55\u534a\u5f84\u5bf9\u6027\u80fd\u5f71\u54cd\u6700\u5927\u3002", "conclusion": "\u4eff\u771f\u7ed3\u679c\u4e0e\u5b9e\u5730\u8868\u73b0\u9ad8\u5ea6\u76f8\u5173\uff0c\u652f\u6301\u8499\u7279\u5361\u6d1b\u6a21\u62df\u5728\u6027\u80fd\u8bc4\u4f30\u548c\u53c2\u6570\u8c03\u4f18\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2509.07416", "pdf": "https://arxiv.org/pdf/2509.07416", "abs": "https://arxiv.org/abs/2509.07416", "authors": ["Lianming Hu", "Xiaotong Zhang", "Kamal Youcef-Toumi"], "title": "Eye Movement Feature-Guided Signal De-Drifting in Electrooculography Systems", "categories": ["eess.SP"], "comment": "This manuscript has been accepted for presentation at the 2025 IEEE\n  21st International Conference on Automation Science and Engineering (CASE)\n  and is currently under publication", "summary": "Electrooculography (EOG) is widely used for gaze tracking in Human-Robot\nCollaboration (HRC). However, baseline drift caused by low-frequency noise\nsignificantly impacts the accuracy of EOG signals, creating challenges for\nfurther sensor fusion. This paper presents an Eye Movement Feature-Guided\nDe-drift (FGD) method for mitigating drift artifacts in EOG signals. The\nproposed approach leverages active eye-movement feature recognition to\nreconstruct the feature-extracted EOG baseline and adaptively correct signal\ndrift while preserving the morphological integrity of the EOG waveform. The FGD\nis evaluated using both simulation data and real-world data, achieving a\nsignificant reduction in mean error. The average error is reduced to\n0.896{\\deg} in simulation, representing a 36.29% decrease, and to 1.033{\\deg}\nin real-world data, corresponding to a 26.53% reduction. Despite additional and\nunpredictable noise in real-world data, the proposed method consistently\noutperforms conventional de-drifting techniques, demonstrating its\neffectiveness in practical applications such as enhancing human performance\naugmentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u773c\u52a8\u7279\u5f81\u7684\u53bb\u6f02\u79fb\uff08FGD\uff09\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11EOG\u4fe1\u53f7\u4e2d\u7684\u57fa\u7ebf\u6f02\u79fb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6ce8\u89c6\u8ddf\u8e2a\u7684\u51c6\u786e\u6027\u3002", "motivation": "EOG\u4fe1\u53f7\u5728HRC\u4e2d\u88ab\u5e7f\u6cdb\u7528\u4e8e\u6ce8\u89c6\u8ddf\u8e2a\uff0c\u4f46\u4f4e\u9891\u566a\u58f0\u5f15\u8d77\u7684\u57fa\u7ebf\u6f02\u79fb\u4e25\u91cd\u5f71\u54cd\u4e86\u4fe1\u53f7\u51c6\u786e\u6027\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "FGD\u65b9\u6cd5\u901a\u8fc7\u4e3b\u52a8\u8bc6\u522b\u773c\u52a8\u7279\u5f81\u91cd\u5efaEOG\u57fa\u7ebf\uff0c\u81ea\u9002\u5e94\u6821\u6b63\u6f02\u79fb\uff0c\u540c\u65f6\u4fdd\u6301\u6ce2\u5f62\u5f62\u6001\u5b8c\u6574\u3002", "result": "\u5728\u4eff\u771f\u548c\u5b9e\u9645\u6570\u636e\u4e2d\uff0cFGD\u65b9\u6cd5\u7684\u5e73\u5747\u8bef\u5dee\u5206\u522b\u964d\u4f4e\u4e8636.29%\u548c26.53%\u3002", "conclusion": "FGD\u65b9\u6cd5\u5728\u5b9e\u7528\u573a\u666f\u4e2d\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\uff0c\u589e\u5f3a\u4e86\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2509.07362", "pdf": "https://arxiv.org/pdf/2509.07362", "abs": "https://arxiv.org/abs/2509.07362", "authors": ["Yandi Yang", "Jianping Li", "Youqi Liao", "Yuhao Li", "Yizhe Zhang", "Zhen Dong", "Bisheng Yang", "Naser El-Sheimy"], "title": "Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark", "categories": ["cs.RO"], "comment": null, "summary": "Accurate visual localization in dense urban environments poses a fundamental\ntask in photogrammetry, geospatial information science, and robotics. While\nimagery is a low-cost and widely accessible sensing modality, its effectiveness\non visual odometry is often limited by textureless surfaces, severe viewpoint\nchanges, and long-term drift. The growing public availability of airborne laser\nscanning (ALS) data opens new avenues for scalable and precise visual\nlocalization by leveraging ALS as a prior map. However, the potential of\nALS-based localization remains underexplored due to three key limitations: (1)\nthe lack of platform-diverse datasets, (2) the absence of reliable ground-truth\ngeneration methods applicable to large-scale urban environments, and (3)\nlimited validation of existing Image-to-Point Cloud (I2P) algorithms under\naerial-ground cross-platform settings. To overcome these challenges, we\nintroduce a new large-scale dataset that integrates ground-level imagery from\nmobile mapping systems with ALS point clouds collected in Wuhan, Hong Kong, and\nSan Francisco.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u673a\u8f7d\u6fc0\u5149\u626b\u63cf\uff08ALS\uff09\u6570\u636e\u4f5c\u4e3a\u5148\u9a8c\u5730\u56fe\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u89c6\u89c9\u5b9a\u4f4d\u7684\u6311\u6218\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "motivation": "\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u7cbe\u786e\u89c6\u89c9\u5b9a\u4f4d\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u65e0\u7eb9\u7406\u8868\u9762\u3001\u89c6\u89d2\u53d8\u5316\u5927\u548c\u957f\u671f\u6f02\u79fb\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002ALS\u6570\u636e\u7684\u516c\u5f00\u53ef\u7528\u6027\u4e3a\u65b0\u7684\u5b9a\u4f4d\u65b9\u6cd5\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u636e\u96c6\u3001\u5730\u9762\u771f\u5b9e\u751f\u6210\u548c\u8de8\u5e73\u53f0\u9a8c\u8bc1\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u901a\u8fc7\u6574\u5408\u5730\u9762\u79fb\u52a8\u6d4b\u7ed8\u7cfb\u7edf\u7684\u56fe\u50cf\u548cALS\u70b9\u4e91\u6570\u636e\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u8de8\u5e73\u53f0\u3001\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u7528\u4e8eALS\u57fa\u4e8e\u89c6\u89c9\u5b9a\u4f4d\u7684\u65b0\u6570\u636e\u96c6\uff0c\u8986\u76d6\u6b66\u6c49\u3001\u9999\u6e2f\u548c\u65e7\u91d1\u5c71\u7b49\u591a\u4e2a\u57ce\u5e02\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u65b0\u6570\u636e\u96c6\uff0c\u8bba\u6587\u4e3aALS\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u89c6\u89c9\u5b9a\u4f4d\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2509.07422", "pdf": "https://arxiv.org/pdf/2509.07422", "abs": "https://arxiv.org/abs/2509.07422", "authors": ["Lu Bai", "Zengrui Han", "Xuesong Cai", "Xiang Cheng"], "title": "Multi-Modal Intelligent Channel Modeling Framework for 6G-Enabled Networked Intelligent Systems", "categories": ["eess.SP"], "comment": null, "summary": "The design and technology development of 6G-enabled networked intelligent\nsystems needs an accurate real-time channel model as the cornerstone. However,\nwith the new requirements of 6G-enabled networked intelligent systems, the\nconventional channel modeling methods face many limitations. Fortunately, the\nmulti-modal sensors equipped on the intelligent agents bring timely\nopportunities, i.e., the intelligent integration and mutually beneficial\nmechanism between communications and multi-modal sensing could be investigated\nbased on the artificial intelligence (AI) technologies. In this case, the\nmapping relationship between physical environment and electromagnetic channel\ncould be explored via Synesthesia of Machines (SoM). This article presents a\nnovel multi-modal intelligent channel modeling (MMICM) framework for 6G-enabled\nnetworked intelligent systems, which establishes a nonlinear model between\nmulti-modal sensing and channel characteristics, including large-scale and\nsmall-scale channel characteristics. The architecture and features of proposed\nintelligent modeling framework are expounded and the key technologies involved\nare also analyzed. Finally, the system-engaged applications and potential\nresearch directions of MMICM framework are outlined.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u667a\u80fd\u4fe1\u9053\u5efa\u6a21\uff08MMICM\uff09\u6846\u67b6\uff0c\u7528\u4e8e6G\u7f51\u7edc\u667a\u80fd\u7cfb\u7edf\uff0c\u901a\u8fc7AI\u6280\u672f\u63a2\u7d22\u901a\u4fe1\u4e0e\u591a\u6a21\u6001\u611f\u77e5\u7684\u878d\u5408\u3002", "motivation": "\u4f20\u7edf\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u5728\u65b0\u9700\u6c42\u76846G\u7f51\u7edc\u667a\u80fd\u7cfb\u7edf\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u591a\u6a21\u6001\u4f20\u611f\u5668\u4e3a\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u57fa\u4e8eAI\u6280\u672f\uff0c\u5efa\u7acb\u4e86\u591a\u6a21\u6001\u611f\u77e5\u4e0e\u4fe1\u9053\u7279\u6027\uff08\u5927\u5c3a\u5ea6\u548c\u5c0f\u5c3a\u5ea6\uff09\u4e4b\u95f4\u7684\u975e\u7ebf\u6027\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86MMICM\u6846\u67b6\u7684\u67b6\u6784\u3001\u7279\u70b9\u53ca\u5173\u952e\u6280\u672f\uff0c\u5e76\u5c55\u671b\u4e86\u5176\u7cfb\u7edf\u5e94\u7528\u548c\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "MMICM\u6846\u67b6\u4e3a6G\u7f51\u7edc\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2509.07381", "pdf": "https://arxiv.org/pdf/2509.07381", "abs": "https://arxiv.org/abs/2509.07381", "authors": ["Sichao Wu", "Jiang Wu", "Xingyu Cao", "Fawang Zhang", "Guangyuan Yu", "Junjie Zhao", "Yue Qu", "Fei Ma", "Jingliang Duan"], "title": "TransMPC: Transformer-based Explicit MPC with Variable Prediction Horizon", "categories": ["cs.RO"], "comment": null, "summary": "Traditional online Model Predictive Control (MPC) methods often suffer from\nexcessive computational complexity, limiting their practical deployment.\nExplicit MPC mitigates online computational load by pre-computing control\npolicies offline; however, existing explicit MPC methods typically rely on\nsimplified system dynamics and cost functions, restricting their accuracy for\ncomplex systems. This paper proposes TransMPC, a novel Transformer-based\nexplicit MPC algorithm capable of generating highly accurate control sequences\nin real-time for complex dynamic systems. Specifically, we formulate the MPC\npolicy as an encoder-only Transformer leveraging bidirectional self-attention,\nenabling simultaneous inference of entire control sequences in a single forward\npass. This design inherently accommodates variable prediction horizons while\nensuring low inference latency. Furthermore, we introduce a direct policy\noptimization framework that alternates between sampling and learning phases.\nUnlike imitation-based approaches dependent on precomputed optimal\ntrajectories, TransMPC directly optimizes the true finite-horizon cost via\nautomatic differentiation. Random horizon sampling combined with a replay\nbuffer provides independent and identically distributed (i.i.d.) training\nsamples, ensuring robust generalization across varying states and horizon\nlengths. Extensive simulations and real-world vehicle control experiments\nvalidate the effectiveness of TransMPC in terms of solution accuracy,\nadaptability to varying horizons, and computational efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86TransMPC\uff0c\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u663e\u5f0fMPC\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u751f\u6210\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u9ad8\u7cbe\u5ea6\u63a7\u5236\u5e8f\u5217\u3002", "motivation": "\u73b0\u6709\u663e\u5f0fMPC\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7b80\u5316\u7684\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u6210\u672c\u51fd\u6570\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7cfb\u7edf\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4ec5\u7f16\u7801\u5668\u7684Transformer\u67b6\u6784\uff0c\u7ed3\u5408\u53cc\u5411\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u76f4\u63a5\u4f18\u5316\u6709\u9650\u65f6\u57df\u6210\u672c\u5e76\u901a\u8fc7\u968f\u673a\u65f6\u57df\u91c7\u6837\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u4eff\u771f\u548c\u5b9e\u9645\u8f66\u8f86\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TransMPC\u5728\u7cbe\u5ea6\u3001\u9002\u5e94\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "TransMPC\u4e3a\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5b9e\u65f6\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07432", "pdf": "https://arxiv.org/pdf/2509.07432", "abs": "https://arxiv.org/abs/2509.07432", "authors": ["Senith Jayakody", "Kalana Jayasooriya", "Sashini Liyanage", "Roshan Godaliyadda", "Parakrama Ekanayake", "Chathura Rathnayake"], "title": "Spectrotemporal Feature Extraction in EHG Signals and Tocograms for Enhanced Preterm Birth Prediction", "categories": ["eess.SP"], "comment": "12 pages, 4 figures, 5 tables, manuscript under review", "summary": "Preterm birth (PTB), defined as delivery before 37 weeks of gestation, is a\nleading cause of neonatal mortality and long term health complications. Early\ndetection is essential for enabling timely medical interventions.\nElectrohysterography (EHG) and tocography (TOCO) are promising non invasive\ntools for PTB prediction, but prior studies often suffer from class imbalance,\nimproper oversampling, and reliance on features with limited physiological\nrelevance. This work presents a machine learning pipeline incorporating robust\npreprocessing, physiologically grounded feature extraction, and rigorous\nevaluation. Features were extracted from EHG (and TOCO) signals using Mel\nfrequency cepstral coefficients, statistical descriptors of wavelet\ncoefficients, and peaks of the normalized power spectrum. Signal quality was\nenhanced via Karhunen Lo\\`eve Transform (KLT) denoising through eigenvalue\nbased subspace decomposition. Multiple classifiers, including Logistic\nRegression, Support Vector Machines, Random Forest, Gradient Boosting,\nMultilayer Perceptron, and CatBoost, were evaluated on the TPEHGT dataset. The\nCatBoost classifier with KLT denoising achieved the highest performance on\nfixed interval segments of the TPEHGT dataset, reaching 97.28% accuracy and an\nAUC of 0.9988. Ablation studies confirmed the critical role of both KLT\ndenoising and physiologically informed features. Comparative analysis showed\nthat including TOCO signals did not substantially improve prediction over EHG\nalone, highlighting the sufficiency of EHG for PTB detection. These results\ndemonstrate that combining denoising with domain relevant features can yield\nhighly accurate, robust, and clinically interpretable models, supporting the\ndevelopment of cost effective and accessible PTB prediction tools, particularly\nin low resource healthcare settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53bb\u566a\u548c\u751f\u7406\u76f8\u5173\u7279\u5f81\u7684\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\uff0c\u7528\u4e8e\u65e9\u4ea7\u9884\u6d4b\uff0cCatBoost\u5206\u7c7b\u5668\u5728TPEHGT\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8697.28%\u7684\u51c6\u786e\u7387\u548c0.9988\u7684AUC\u3002", "motivation": "\u65e9\u4ea7\u662f\u65b0\u751f\u513f\u6b7b\u4ea1\u548c\u957f\u671f\u5065\u5eb7\u95ee\u9898\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u65e9\u671f\u68c0\u6d4b\u5bf9\u53ca\u65f6\u533b\u7597\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528Mel\u9891\u7387\u5012\u8c31\u7cfb\u6570\u3001\u5c0f\u6ce2\u7cfb\u6570\u7edf\u8ba1\u63cf\u8ff0\u548c\u5f52\u4e00\u5316\u529f\u7387\u8c31\u5cf0\u503c\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u7279\u5f81\u503c\u7684KL\u53d8\u6362\u53bb\u566a\u3002\u8bc4\u4f30\u4e86\u591a\u79cd\u5206\u7c7b\u5668\u3002", "result": "CatBoost\u5206\u7c7b\u5668\u7ed3\u5408KL\u53bb\u566a\u5728TPEHGT\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0cEHG\u4fe1\u53f7\u5355\u72ec\u4f7f\u7528\u5df2\u8db3\u591f\u9884\u6d4b\u65e9\u4ea7\u3002", "conclusion": "\u7ed3\u5408\u53bb\u566a\u548c\u751f\u7406\u76f8\u5173\u7279\u5f81\u53ef\u6784\u5efa\u9ad8\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u652f\u6301\u4f4e\u6210\u672c\u65e9\u4ea7\u9884\u6d4b\u5de5\u5177\u7684\u7814\u53d1\u3002"}}
{"id": "2509.07412", "pdf": "https://arxiv.org/pdf/2509.07412", "abs": "https://arxiv.org/abs/2509.07412", "authors": ["Zhen Tian", "Fujiang Yuan", "Yangfan He", "Qinghao Li", "Changlin Chen", "Huilin Chen", "Tianxiang Xu", "Jianyu Duan", "Yanhong Peng", "Zhihao Lin"], "title": "Attention and Risk-Aware Decision Framework for Safe Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous driving has attracted great interest due to its potential\ncapability in full-unsupervised driving. Model-based and learning-based methods\nare widely used in autonomous driving. Model-based methods rely on pre-defined\nmodels of the environment and may struggle with unforeseen events. Proximal\npolicy optimization (PPO), an advanced learning-based method, can adapt to the\nabove limits by learning from interactions with the environment. However,\nexisting PPO faces challenges with poor training results, and low training\nefficiency in long sequences. Moreover, the poor training results are\nequivalent to collisions in driving tasks. To solve these issues, this paper\ndevelops an improved PPO by introducing the risk-aware mechanism, a\nrisk-attention decision network, a balanced reward function, and a\nsafety-assisted mechanism. The risk-aware mechanism focuses on highlighting\nareas with potential collisions, facilitating safe-driving learning of the PPO.\nThe balanced reward function adjusts rewards based on the number of surrounding\nvehicles, promoting efficient exploration of the control strategy during\ntraining. Additionally, the risk-attention network enhances the PPO to hold\nchannel and spatial attention for the high-risk areas of input images.\nMoreover, the safety-assisted mechanism supervises and prevents the actions\nwith risks of collisions during the lane keeping and lane changing. Simulation\nresults on a physical engine demonstrate that the proposed algorithm\noutperforms benchmark algorithms in collision avoidance, achieving higher peak\nreward with less training time, and shorter driving time remaining on the risky\nareas among multiple testing traffic flow scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u98ce\u9669\u611f\u77e5\u673a\u5236\u3001\u98ce\u9669\u6ce8\u610f\u529b\u51b3\u7b56\u7f51\u7edc\u3001\u5e73\u8861\u5956\u52b1\u51fd\u6570\u548c\u5b89\u5168\u8f85\u52a9\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709PPO\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u8bad\u7ec3\u6548\u679c\u5dee\u548c\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709PPO\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u9762\u4e34\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\u548c\u6548\u7387\u4f4e\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u957f\u5e8f\u5217\u8bad\u7ec3\u4e2d\u5bb9\u6613\u53d1\u751f\u78b0\u649e\u73b0\u8c61\uff0c\u4e9f\u9700\u6539\u8fdb\u4ee5\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u56db\u79cd\u6539\u8fdb\u65b9\u6cd5\uff1a\u98ce\u9669\u611f\u77e5\u673a\u5236\u3001\u98ce\u9669\u6ce8\u610f\u529b\u51b3\u7b56\u7f51\u7edc\u3001\u5e73\u8861\u5956\u52b1\u51fd\u6570\u548c\u5b89\u5168\u8f85\u52a9\u673a\u5236\uff0c\u5206\u522b\u7528\u4e8e\u589e\u5f3a\u5bf9\u9ad8\u98ce\u9669\u533a\u57df\u7684\u5173\u6ce8\u3001\u4f18\u5316\u5956\u52b1\u5206\u914d\u3001\u63d0\u5347\u51b3\u7b56\u5b89\u5168\u548c\u9632\u6b62\u78b0\u649e\u884c\u4e3a\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u6539\u8fdb\u540e\u7684PPO\u7b97\u6cd5\u5728\u78b0\u649e\u907f\u514d\u3001\u5cf0\u503c\u5956\u52b1\u548c\u8bad\u7ec3\u65f6\u95f4\u7b49\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u51c6\u7b97\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u533a\u57df\u7684\u884c\u9a76\u65f6\u95f4\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u591a\u65b9\u9762\u7684\u6539\u8fdb\u673a\u5236\uff0c\u8be5\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86PPO\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07436", "pdf": "https://arxiv.org/pdf/2509.07436", "abs": "https://arxiv.org/abs/2509.07436", "authors": ["Feifan Zhang", "Yuyang Du", "Yifan Xiang", "Xiaoyan Liu", "Soung Chang Liew"], "title": "SA-OOSC: A Multimodal LLM-Distilled Semantic Communication Framework for Enhanced Coding Efficiency with Scenario Understanding", "categories": ["eess.SP"], "comment": null, "summary": "This paper introduces SA-OOSC, a multimodal large language models\n(MLLM)-distilled semantic communication framework that achieves efficient\nsemantic coding with scenario-aware importance allocations. This approach\naddresses a critical limitation of existing object-oriented semantic\ncommunication (OOSC) systems - assigning static importance values to specific\nclasses of objects regardless of their contextual relevance. Our framework\nutilizes MLLMs to identify the scenario-augmented (SA) semantic importance for\nobjects within the image. Through knowledge distillation with the\nMLLM-annotated data, our vectorization/de-vectorization networks and JSCC\nencoder/decoder learn to dynamically allocate coding resources based on\ncontextual significance, i.e., distinguishing between high-importance objects\nand low-importance according to the SA scenario information of the task. The\nframework features three core innovations: a MLLM-guided knowledge distillation\npipeline, an importance-weighted variable-length JSCC framework, and novel loss\nfunction designs that facilitate the knowledge distillation within the JSCC\nframework. Experimental validation demonstrates our framework's superior coding\nefficiency over conventional semantic communication systems, with open-sourced\nMLLM-annotated and human-verified datasets established as new benchmarks for\nfuture research in semantic communications.", "AI": {"tldr": "SA-OOSC\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u77e5\u8bc6\u84b8\u998f\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u914d\u7f16\u7801\u8d44\u6e90\u5b9e\u73b0\u9ad8\u6548\u7684\u8bed\u4e49\u7f16\u7801\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfOOSC\u7cfb\u7edf\u4e2d\u9759\u6001\u5206\u914d\u91cd\u8981\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709OOSC\u7cfb\u7edf\u4e3a\u5bf9\u8c61\u5206\u914d\u9759\u6001\u91cd\u8981\u6027\u503c\uff0c\u5ffd\u7565\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u9650\u5236\u4e86\u8bed\u4e49\u901a\u4fe1\u7684\u6548\u7387\u3002SA-OOSC\u65e8\u5728\u901a\u8fc7\u573a\u666f\u611f\u77e5\u52a8\u6001\u5206\u914d\u91cd\u8981\u6027\u3002", "method": "\u5229\u7528MLLM\u6807\u6ce8\u573a\u666f\u589e\u5f3a\u7684\u8bed\u4e49\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u5411\u91cf\u5316/\u53cd\u5411\u91cf\u5316\u7f51\u7edc\u548cJSCC\u7f16\u89e3\u7801\u5668\uff0c\u52a8\u6001\u5206\u914d\u7f16\u7801\u8d44\u6e90\u3002\u6838\u5fc3\u521b\u65b0\u5305\u62ecMLLM\u84b8\u998f\u6d41\u7a0b\u3001\u53ef\u53d8\u957f\u5ea6JSCC\u6846\u67b6\u548c\u65b0\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSA-OOSC\u5728\u7f16\u7801\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u7684\u57fa\u51c6\u3002", "conclusion": "SA-OOSC\u901a\u8fc7\u573a\u666f\u611f\u77e5\u52a8\u6001\u5206\u914d\u7f16\u7801\u8d44\u6e90\uff0c\u663e\u8457\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u6548\u7387\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2509.07413", "pdf": "https://arxiv.org/pdf/2509.07413", "abs": "https://arxiv.org/abs/2509.07413", "authors": ["Yuhan Pang", "Bingyi Xia", "Zhe Zhang", "Zhirui Sun", "Peijia Xie", "Bike Zhu", "Wenjun Xu", "Jiankun Wang"], "title": "Robust Docking Maneuvers for Autonomous Trolley Collection: An Optimization-Based Visual Servoing Scheme", "categories": ["cs.RO"], "comment": null, "summary": "Service robots have demonstrated significant potential for autonomous trolley\ncollection and redistribution in public spaces like airports or warehouses to\nimprove efficiency and reduce cost. Usually, a fully autonomous system for the\ncollection and transportation of multiple trolleys is based on a\nLeader-Follower formation of mobile manipulators, where reliable docking\nmaneuvers of the mobile base are essential to align trolleys into organized\nqueues. However, developing a vision-based robotic docking system faces\nsignificant challenges: high precision requirements, environmental\ndisturbances, and inherent robot constraints. To address these challenges, we\npropose an optimization-based Visual Servoing scheme that incorporates active\ninfrared markers for robust feature extraction across diverse lighting\nconditions. This framework explicitly models nonholonomic kinematics and\nvisibility constraints within the Hybrid Visual Servoing problem, augmented\nwith an observer for disturbance rejection to ensure precise and stable\ndocking. Experimental results across diverse environments demonstrate the\nrobustness of this system, with quantitative evaluations confirming high\ndocking accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7684\u89c6\u89c9\u4f3a\u670d\u65b9\u6848\uff0c\u7528\u4e8e\u63d0\u5347\u670d\u52a1\u673a\u5668\u4eba\u5728\u9ad8\u7cbe\u5ea6\u8981\u6c42\u3001\u73af\u5883\u5e72\u6270\u548c\u673a\u5668\u4eba\u7ea6\u675f\u4e0b\u7684\u5bf9\u63a5\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u670d\u52a1\u673a\u5668\u4eba\u5728\u516c\u5171\u7a7a\u95f4\u4e2d\u81ea\u4e3b\u6536\u96c6\u548c\u8fd0\u8f93\u591a\u4e2a\u624b\u63a8\u8f66\u65f6\uff0c\u7531\u4e8e\u9ad8\u7cbe\u5ea6\u8981\u6c42\u3001\u73af\u5883\u5e72\u6270\u548c\u673a\u5668\u4eba\u7ea6\u675f\u5bfc\u81f4\u7684\u5bf9\u63a5\u96be\u9898\u3002", "method": "\u7ed3\u5408\u4e3b\u52a8\u7ea2\u5916\u6807\u8bb0\u8fdb\u884c\u9c81\u68d2\u7279\u5f81\u63d0\u53d6\uff0c\u5c06\u975e\u5b8c\u6574\u8fd0\u52a8\u5b66\u548c\u53ef\u89c1\u6027\u7ea6\u675f\u660e\u786e\u5efa\u6a21\u5230\u6df7\u5408\u89c6\u89c9\u4f3a\u670d\u95ee\u9898\u4e2d\uff0c\u5e76\u5f15\u5165\u89c2\u6d4b\u5668\u4ee5\u6291\u5236\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u7cfb\u7edf\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u5b9a\u91cf\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u9ad8\u5bf9\u63a5\u7cbe\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f18\u5316\u89c6\u89c9\u4f3a\u670d\u65b9\u6848\u663e\u8457\u63d0\u5347\u4e86\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u5bf9\u63a5\u7684\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2509.07441", "pdf": "https://arxiv.org/pdf/2509.07441", "abs": "https://arxiv.org/abs/2509.07441", "authors": ["Sangjun Hwang", "Chan-Byoung Chae"], "title": "Node Position Estimation in Diffusion-Based Molecular Communications Using Multi-Layer Perceptron", "categories": ["eess.SP", "94A12", "C.2.1"], "comment": "2 pages, 2 figures; accepted to ACM NanoCom '25 (short paper). This\n  arXiv version is the author-accepted manuscript", "summary": "This paper proposes a method for accurately estimating the relative position\nbetween two nodes with unknown locations in a diffusion-based molecular\ncommunication environment. A specialized node structure is designed, combining\na central absorbing receiver with multiple transmitters placed at predefined\nspherical coordinates. Pilot molecules are released, and their absorption time\nand concentration are measured. By partitioning the spherical coordinate space,\nthese spatially distinct measurements serve as input to a multilayer perceptron\n(MLP)-based model. The proposed method significantly improves the precision of\ndistance and direction estimation. Simulation results demonstrate localization\naccuracy, confirming the effectiveness of the neural network model in capturing\nthe underlying physical characteristics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5206\u5b50\u901a\u4fe1\u73af\u5883\u4e2d\u7cbe\u786e\u4f30\u8ba1\u672a\u77e5\u4f4d\u7f6e\u8282\u70b9\u76f8\u5bf9\u4f4d\u7f6e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4e13\u7528\u8282\u70b9\u7ed3\u6784\u5e76\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ddd\u79bb\u548c\u65b9\u5411\u4f30\u8ba1\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5728\u6269\u6563\u5206\u5b50\u901a\u4fe1\u73af\u5883\u4e2d\uff0c\u7cbe\u786e\u4f30\u8ba1\u672a\u77e5\u4f4d\u7f6e\u8282\u70b9\u7684\u76f8\u5bf9\u4f4d\u7f6e\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u590d\u6742\u73af\u5883\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b\u4e2d\u5fc3\u5438\u6536\u63a5\u6536\u5668\u548c\u591a\u4e2a\u9884\u5b9a\u4e49\u7403\u5750\u6807\u53d1\u5c04\u5668\u7684\u8282\u70b9\u7ed3\u6784\uff0c\u91ca\u653e\u5bfc\u9891\u5206\u5b50\u5e76\u6d4b\u91cf\u5176\u5438\u6536\u65f6\u95f4\u548c\u6d53\u5ea6\uff0c\u901a\u8fc7\u5212\u5206\u7403\u5750\u6807\u7a7a\u95f4\u5e76\u5c06\u6d4b\u91cf\u6570\u636e\u8f93\u5165\u591a\u5c42\u611f\u77e5\u5668\u6a21\u578b\u8fdb\u884c\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8ddd\u79bb\u548c\u65b9\u5411\u4f30\u8ba1\u7684\u7cbe\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u6355\u6349\u7269\u7406\u7279\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5206\u5b50\u901a\u4fe1\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u8282\u70b9\u4f4d\u7f6e\u4f30\u8ba1\uff0c\u8bc1\u660e\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u6b64\u7c7b\u95ee\u9898\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.07438", "pdf": "https://arxiv.org/pdf/2509.07438", "abs": "https://arxiv.org/abs/2509.07438", "authors": ["Ya-Chuan Hsu", "Jonathan DeCastro", "Andrew Silva", "Guy Rosman"], "title": "Timing the Message: Language-Based Notifications for Time-Critical Assistive Settings", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "In time-critical settings such as assistive driving, assistants often rely on\nalerts or haptic signals to prompt rapid human attention, but these cues\nusually leave humans to interpret situations and decide responses\nindependently, introducing potential delays or ambiguity in meaning.\nLanguage-based assistive systems can instead provide instructions backed by\ncontext, offering more informative guidance. However, current approaches (e.g.,\nsocial assistive robots) largely prioritize content generation while\noverlooking critical timing factors such as verbal conveyance duration, human\ncomprehension delays, and subsequent follow-through duration. These timing\nconsiderations are crucial in time-critical settings, where even minor delays\ncan substantially affect outcomes. We aim to study this inherent trade-off\nbetween timeliness and informativeness by framing the challenge as a sequential\ndecision-making problem using an augmented-state Markov Decision Process. We\ndesign a framework combining reinforcement learning and a generated offline\ntaxonomy dataset, where we balance the trade-off while enabling a scalable\ntaxonomy dataset generation pipeline. Empirical evaluation with synthetic\nhumans shows our framework improves success rates by over 40% compared to\nmethods that ignore time delays, while effectively balancing timeliness and\ninformativeness. It also exposes an often-overlooked trade-off between these\ntwo factors, opening new directions for optimizing communication in\ntime-critical human-AI assistance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u8a00\u8f85\u52a9\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u79bb\u7ebf\u5206\u7c7b\u6570\u636e\u96c6\u5e73\u8861\u53ca\u65f6\u6027\u4e0e\u4fe1\u606f\u91cf\uff0c\u5728\u65f6\u95f4\u5173\u952e\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u8f85\u52a9\u7cfb\u7edf\uff08\u5982\u793e\u4ea4\u8f85\u52a9\u673a\u5668\u4eba\uff09\u5ffd\u89c6\u4e86\u65f6\u95f4\u56e0\u7d20\uff08\u5982\u4f20\u8fbe\u65f6\u95f4\u3001\u7406\u89e3\u5ef6\u8fdf\u7b49\uff09\uff0c\u800c\u8fd9\u4e9b\u56e0\u7d20\u5728\u65f6\u95f4\u5173\u952e\u573a\u666f\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u589e\u5f3a\u72b6\u6001\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u95ee\u9898\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u79bb\u7ebf\u5206\u7c7b\u6570\u636e\u96c6\u751f\u6210\u6846\u67b6\uff0c\u5e73\u8861\u53ca\u65f6\u6027\u4e0e\u4fe1\u606f\u91cf\u3002", "result": "\u4e0e\u5ffd\u7565\u65f6\u95f4\u5ef6\u8fdf\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6846\u67b6\u5c06\u6210\u529f\u7387\u63d0\u9ad840%\u4ee5\u4e0a\uff0c\u5e76\u63ed\u793a\u4e86\u53ca\u65f6\u6027\u4e0e\u4fe1\u606f\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65f6\u95f4\u5173\u952e\u7684\u4eba\u673a\u534f\u4f5c\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2509.07442", "pdf": "https://arxiv.org/pdf/2509.07442", "abs": "https://arxiv.org/abs/2509.07442", "authors": ["Ashish Patwari", "Andr\u00e9s Alay\u00f3n Glazunov"], "title": "A Systematic Framework to Test the Resilience of Three-Fold Redundant Sparse Arrays Against Two Sensor Failures and Some Never-Before Findings", "categories": ["eess.SP"], "comment": "6 pages, 5 Figures, and 2 Tables", "summary": "As the field of sparse arrays progressed, numerous array designs have been\nintroduced with a focus on larger apertures and higher degrees of freedom\n(DOFs), resulting in maximally economic sparse arrays (MESAs) that operate with\nthe least number of sensors required to provide a given aperture while ensuring\na hole-free difference coarray (DCA). Consequently, MESAs are least robust to\nsensor failures and cannot afford the failure of even a single sensor.\nMultifold redundant sparse arrays (MFRSAs) provide a practical solution to the\nproblem of sensor failures in sparse arrays by making sure that the array\ncontains enough sensor pairs necessary to produce each spatial lag multiple\ntimes. Owing to this property, a \\b{eta}-fold redundant array can withstand\nsimultaneous failure of at least \\b{eta}-1 sensors without losing the hole-free\nDCA property. Nevertheless, MFRSAs are also prone to hidden dependencies that\nprevent them from being fully robust. In this work, we present a systematic\nframework to evaluate the robustness of triple redundant sparse linear arrays\n(TRSLAs) against all possible two-sensor failures. After detailing the proposed\napproach, we present the failure analysis of representative TRSLAs available in\nexisting literature. It is found that existing TRSLAs have some hidden\nvulnerabilities against the failure of some peculiar sensor pairs.\nCorresponding MATLAB programs and numerical simulations are provided for\nevaluation and use by the array processing community. The proposed approach has\na great archival value as it can evaluate the robustness of any present or\nfuture TRSLAs through objective means.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\u6765\u8bc4\u4f30\u4e09\u91cd\u5197\u4f59\u7a00\u758f\u7ebf\u6027\u9635\u5217\uff08TRSLAs\uff09\u7684\u9c81\u68d2\u6027\uff0c\u9488\u5bf9\u6240\u6709\u53ef\u80fd\u7684\u53cc\u4f20\u611f\u5668\u6545\u969c\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u53d1\u73b0\u73b0\u6709\u8bbe\u8ba1\u5b58\u5728\u9690\u85cf\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u7a00\u758f\u9635\u5217\u9886\u57df\u7684\u53d1\u5c55\uff0c\u6700\u5927\u5316\u7ecf\u6d4e\u7a00\u758f\u9635\u5217\uff08MESA\uff09\u5bf9\u5355\u4e2a\u4f20\u611f\u5668\u6545\u969c\u6781\u4e3a\u654f\u611f\uff0c\u65e0\u6cd5\u627f\u53d7\u4efb\u4f55\u4f20\u611f\u5668\u6545\u969c\u3002\u591a\u91cd\u5197\u4f59\u7a00\u758f\u9635\u5217\uff08MFRSA\uff09\u901a\u8fc7\u786e\u4fdd\u6bcf\u4e2a\u7a7a\u95f4\u6ede\u540e\u591a\u6b21\u751f\u6210\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u9690\u85cf\u4f9d\u8d56\u6027\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30TRSLAs\u5728\u6240\u6709\u53ef\u80fd\u7684\u53cc\u4f20\u611f\u5668\u6545\u969c\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7MATLAB\u7a0b\u5e8f\u548c\u6570\u503c\u6a21\u62df\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u73b0\u6709TRSLAs\u5728\u67d0\u4e9b\u7279\u5b9a\u4f20\u611f\u5668\u5bf9\u6545\u969c\u65f6\u5b58\u5728\u9690\u85cf\u8106\u5f31\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u957f\u671f\u4ef7\u503c\uff0c\u53ef\u7528\u4e8e\u5ba2\u89c2\u8bc4\u4f30\u73b0\u6709\u6216\u672a\u6765TRSLAs\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.07445", "pdf": "https://arxiv.org/pdf/2509.07445", "abs": "https://arxiv.org/abs/2509.07445", "authors": ["Harrison Field", "Max Yang", "Yijiong Lin", "Efi Psomopoulou", "David Barton", "Nathan F. Lepora"], "title": "Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted at CoRL 2025", "summary": "Large language models (LLMs) are beginning to automate reward design for\ndexterous manipulation. However, no prior work has considered tactile sensing,\nwhich is known to be critical for human-like dexterity. We present Text2Touch,\nbringing LLM-crafted rewards to the challenging task of multi-axis in-hand\nobject rotation with real-world vision based tactile sensing in palm-up and\npalm-down configurations. Our prompt engineering strategy scales to over 70\nenvironment variables, and sim-to-real distillation enables successful policy\ntransfer to a tactile-enabled fully actuated four-fingered dexterous robot\nhand. Text2Touch significantly outperforms a carefully tuned human-engineered\nbaseline, demonstrating superior rotation speed and stability while relying on\nreward functions that are an order of magnitude shorter and simpler. These\nresults illustrate how LLM-designed rewards can significantly reduce the time\nfrom concept to deployable dexterous tactile skills, supporting more rapid and\nscalable multimodal robot learning. Project website:\nhttps://hpfield.github.io/text2touch-website", "AI": {"tldr": "Text2Touch\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u89e6\u89c9\u611f\u77e5\uff0c\u5b9e\u73b0\u4e86\u591a\u8f74\u624b\u5185\u7269\u4f53\u65cb\u8f6c\u4efb\u52a1\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e2d\u7f3a\u4e4f\u5bf9\u89e6\u89c9\u611f\u77e5\u7684\u5173\u6ce8\uff0c\u800c\u89e6\u89c9\u5bf9\u4eba\u7c7b\u7075\u6d3b\u6027\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u5229\u7528LLM\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u89e6\u89c9\u611f\u77e5\uff0c\u63d0\u5347\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faText2Touch\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6269\u5c55\u523070\u591a\u4e2a\u73af\u5883\u53d8\u91cf\uff0c\u5e76\u5229\u7528\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u84b8\u998f\u6280\u672f\uff0c\u5c06\u7b56\u7565\u8fc1\u79fb\u5230\u5177\u6709\u89e6\u89c9\u529f\u80fd\u7684\u673a\u5668\u4eba\u624b\u4e0a\u3002", "result": "Text2Touch\u5728\u65cb\u8f6c\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\uff0c\u540c\u65f6\u5956\u52b1\u51fd\u6570\u66f4\u7b80\u6d01\u3002", "conclusion": "LLM\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\u53ef\u4ee5\u663e\u8457\u7f29\u77ed\u4ece\u6982\u5ff5\u5230\u53ef\u90e8\u7f72\u6280\u80fd\u7684\u5f00\u53d1\u65f6\u95f4\uff0c\u652f\u6301\u66f4\u5feb\u3001\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u673a\u5668\u4eba\u5b66\u4e60\u3002"}}
{"id": "2509.07482", "pdf": "https://arxiv.org/pdf/2509.07482", "abs": "https://arxiv.org/abs/2509.07482", "authors": ["Joan \u00c7ollaku", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Takumi Takahashi"], "title": "Integrated Communication and Computing in Time-Varying mmWave Channels", "categories": ["eess.SP"], "comment": "Submitted to the IEEE for possible publication", "summary": "We propose a novel framework for integrated communication and computing (ICC)\ntransceiver design in time-varying millimeter-wave (mmWave) channels. In\nparticular, in order to cope with the dynamics of time-varying mmWave channels,\nthe detection of communication symbols and the execution of an over-the-air\ncomputing (AirComp) operation are performed in parallel with channel tracking,\nas opposed to existing state-of-the-art (SotA) on ICC where perfect knowledge\nof the channel at all time instances is typically assumed. For clarity of\nexposition, we consider a single-input multiple-output (SIMO) uplink scenario\nwhere multiple single-antenna user equipment (UE) transmit to a base station\n(BS) equipped with multiple antennas, such that each UE, or edge device (ED),\nprecodes its own transmit signal, while the BS, or access points (APs), also\nperforms receive beamforming. The proposed transceiver framework then estimates\nchannel state information (CSI) and data symbols in parallel, using a bilinear\nGaussian belief propagation (BiGaBP) algorithm for joint channel and data\ndetection (JCDE), aided by a channel prediction (CP) algorithm executed before\neach estimation window at the BS. The AirComp operation is then executed by\nmeans of an optimal combination of the residual signal. Simulation results\ndemonstrate the effectiveness of the proposed scheme in performing ICC in\nchallenging time-varying mmWave channels, with minimal degradation to both\ncommunication and computing performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6beb\u7c73\u6ce2\u65f6\u53d8\u4fe1\u9053\u4e0b\u901a\u4fe1\u4e0e\u8ba1\u7b97\u4e00\u4f53\u5316\uff08ICC\uff09\u6536\u53d1\u5668\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u4fe1\u9053\u8ddf\u8e2a\u4e0e\u7b26\u53f7\u68c0\u6d4b\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u6709ICC\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u4fe1\u9053\u5b8c\u7f8e\u5df2\u77e5\uff0c\u800c\u65f6\u53d8\u6beb\u7c73\u6ce2\u4fe1\u9053\u7684\u52a8\u6001\u6027\u9700\u8981\u66f4\u9c81\u68d2\u7684\u8bbe\u8ba1\u3002", "method": "\u4f7f\u7528BiGaBP\u7b97\u6cd5\u8054\u5408\u4fe1\u9053\u4e0e\u6570\u636e\u68c0\u6d4b\uff08JCDE\uff09\uff0c\u7ed3\u5408\u4fe1\u9053\u9884\u6d4b\uff08CP\uff09\u7b97\u6cd5\uff0c\u5b9e\u73b0\u5e76\u884cCSI\u4e0e\u6570\u636e\u7b26\u53f7\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u8868\u660e\u8be5\u6846\u67b6\u5728\u65f6\u53d8\u6beb\u7c73\u6ce2\u4fe1\u9053\u4e0b\u80fd\u6709\u6548\u6267\u884cICC\uff0c\u901a\u4fe1\u4e0e\u8ba1\u7b97\u6027\u80fd\u51e0\u4e4e\u65e0\u9000\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e76\u884c\u5904\u7406\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u65f6\u53d8\u4fe1\u9053\u4e0b\u7684ICC\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u6beb\u7c73\u6ce2\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.07463", "pdf": "https://arxiv.org/pdf/2509.07463", "abs": "https://arxiv.org/abs/2509.07463", "authors": ["Sven Kirchner", "Nils Purschke", "Ross Greer", "Alois C. Knoll"], "title": "DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Ensuring reliable robot operation when visual input is degraded or\ninsufficient remains a central challenge in robotics. This letter introduces\nDepthVision, a framework for multimodal scene understanding designed to address\nthis problem. Unlike existing Vision-Language Models (VLMs), which use only\ncamera-based visual input alongside language, DepthVision synthesizes RGB\nimages from sparse LiDAR point clouds using a conditional generative\nadversarial network (GAN) with an integrated refiner network. These synthetic\nviews are then combined with real RGB data using a Luminance-Aware Modality\nAdaptation (LAMA), which blends the two types of data dynamically based on\nambient lighting conditions. This approach compensates for sensor degradation,\nsuch as darkness or motion blur, without requiring any fine-tuning of\ndownstream vision-language models. We evaluate DepthVision on real and\nsimulated datasets across various models and tasks, with particular attention\nto safety-critical tasks. The results demonstrate that our approach improves\nperformance in low-light conditions, achieving substantial gains over RGB-only\nbaselines while preserving compatibility with frozen VLMs. This work highlights\nthe potential of LiDAR-guided RGB synthesis for achieving robust robot\noperation in real-world environments.", "AI": {"tldr": "DepthVision\u6846\u67b6\u901a\u8fc7\u7ed3\u5408LiDAR\u70b9\u4e91\u751f\u6210\u7684RGB\u56fe\u50cf\u548c\u771f\u5b9eRGB\u6570\u636e\uff0c\u52a8\u6001\u9002\u5e94\u5149\u7167\u6761\u4ef6\uff0c\u63d0\u5347\u4e86\u673a\u5668\u4eba\u89c6\u89c9\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u8f93\u5165\u53d7\u9650\uff08\u5982\u4f4e\u5149\u6216\u8fd0\u52a8\u6a21\u7cca\uff09\u65f6\u673a\u5668\u4eba\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6761\u4ef6GAN\u4ece\u7a00\u758fLiDAR\u70b9\u4e91\u5408\u6210RGB\u56fe\u50cf\uff0c\u5e76\u901a\u8fc7LAMA\u52a8\u6001\u878d\u5408\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u3002", "result": "\u5728\u4f4e\u5149\u6761\u4ef6\u4e0b\u663e\u8457\u4f18\u4e8e\u7eafRGB\u57fa\u7ebf\uff0c\u4e14\u65e0\u9700\u5fae\u8c03\u4e0b\u6e38\u6a21\u578b\u3002", "conclusion": "LiDAR\u5f15\u5bfc\u7684RGB\u5408\u6210\u6709\u52a9\u4e8e\u589e\u5f3a\u673a\u5668\u4eba\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.07483", "pdf": "https://arxiv.org/pdf/2509.07483", "abs": "https://arxiv.org/abs/2509.07483", "authors": ["Ivan Iudice", "Domenico Pascarella", "Sonia Zappia", "Giovanni Cuciniello", "Hernan M. R. Giannetta", "Marta Albano", "Enrico Cavallini"], "title": "A Methodological Framework for Positioning of Wireless Sensors in New Generation Launchers", "categories": ["eess.SP"], "comment": "6 pages, 3 figures, 5 tables, accepted for publication in the\n  proceedings of 2025 IEEE 12th International Workshop on Metrology for\n  AeroSpace (MetroAeroSpace)", "summary": "In wireless sensor networks for reusable launchers, the electromagnetic\ncharacterization and electromagnetic compatibility analyses are relevant due to\nthe reference operational scenario, which implies a complex, and sometimes\ndynamic, electromagnetic environment. This work proposes a methodological\nframework for the design of the network and for the analysis of the related\nelectromagnetic environment within the stages of a given launcher. Based on the\npreliminary positioning of the network nodes, the framework prescribes a\nworkflow and the related toolset for determining the optimal network topology\nfocusing on the weights, the operation of the transceivers, and the overall\nradiated power. The optimal network configuration is simulated by using\ncomputational electromagnetics strategies in order to assess the\nelectromagnetic environment induced by the sensor network itself. The paper\nprovides some results concerning a case study for a specific launcher.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u53ef\u91cd\u590d\u4f7f\u7528\u706b\u7bad\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u8bbe\u8ba1\u548c\u7535\u78c1\u73af\u5883\u5206\u6790\u7684\u6846\u67b6\uff0c\u91cd\u70b9\u4f18\u5316\u7f51\u7edc\u62d3\u6251\u548c\u8f90\u5c04\u529f\u7387\u3002", "motivation": "\u7531\u4e8e\u590d\u6742\u7684\u7535\u78c1\u73af\u5883\uff0c\u9700\u8981\u5bf9\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u8fdb\u884c\u7535\u78c1\u7279\u6027\u548c\u517c\u5bb9\u6027\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u7f51\u7edc\u8282\u70b9\u7684\u521d\u6b65\u5b9a\u4f4d\uff0c\u63d0\u51fa\u5de5\u4f5c\u6d41\u7a0b\u548c\u5de5\u5177\u96c6\uff0c\u4f7f\u7528\u8ba1\u7b97\u7535\u78c1\u5b66\u7b56\u7565\u6a21\u62df\u6700\u4f18\u7f51\u7edc\u914d\u7f6e\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u7279\u5b9a\u706b\u7bad\u7684\u7535\u78c1\u73af\u5883\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u4f18\u5316\u4e86\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u7535\u78c1\u517c\u5bb9\u6027\u3002"}}
{"id": "2509.07464", "pdf": "https://arxiv.org/pdf/2509.07464", "abs": "https://arxiv.org/abs/2509.07464", "authors": ["Rui Yang", "Lei Zheng", "Shuzhi Sam Ge", "Jun Ma"], "title": "Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "16 pages, 13 figures", "summary": "Autonomous vehicles must navigate dynamically uncertain environments while\nbalancing the safety and driving efficiency. This challenge is exacerbated by\nthe unpredictable nature of surrounding human-driven vehicles (HVs) and\nperception inaccuracies, which require planners to adapt to evolving\nuncertainties while maintaining safe trajectories. Overly conservative planners\ndegrade driving efficiency, while deterministic approaches may encounter\nserious issues and risks of failure when faced with sudden and unexpected\nmaneuvers. To address these issues, we propose a real-time contingency\ntrajectory optimization framework in this paper. By employing event-triggered\nonline learning of HV control-intent sets, our method dynamically quantifies\nmulti-modal HV uncertainties and refines the forward reachable set (FRS)\nincrementally. Crucially, we enforce invariant safety through FRS-based barrier\nconstraints that ensure safety without reliance on accurate trajectory\nprediction of HVs. These constraints are embedded in contingency trajectory\noptimization and solved efficiently through consensus alternative direction\nmethod of multipliers (ADMM). The system continuously adapts to the\nuncertainties in HV behaviors, preserving feasibility and safety without\nresorting to excessive conservatism. High-fidelity simulations on highway and\nurban scenarios, as well as a series of real-world experiments demonstrate\nsignificant improvements in driving efficiency and passenger comfort while\nmaintaining safety under uncertainty. The project page is available at\nhttps://pathetiue.github.io/frscp.github.io/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u5e94\u6025\u8f68\u8ff9\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u5b66\u4e60\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\u7684\u63a7\u5236\u610f\u56fe\u96c6\uff0c\u52a8\u6001\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u5e76\u786e\u4fdd\u5b89\u5168\u9a7e\u9a76\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5bfc\u822a\u65f6\u9700\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u9a7e\u9a76\u6548\u7387\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e8b\u4ef6\u89e6\u53d1\u7684\u5728\u7ebf\u5b66\u4e60\u7b56\u7565\uff0c\u52a8\u6001\u91cf\u5316\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\u7684\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8eFRS\u7684\u5c4f\u969c\u7ea6\u675f\u786e\u4fdd\u5b89\u5168\u6027\u3002", "result": "\u9ad8\u4fdd\u771f\u4eff\u771f\u548c\u5b9e\u9645\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u9a7e\u9a76\u6548\u7387\u548c\u4e58\u5ba2\u8212\u9002\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u4e0d\u4f9d\u8d56\u51c6\u786e\u8f68\u8ff9\u9884\u6d4b\u7684\u60c5\u51b5\u4e0b\uff0c\u6210\u529f\u5e73\u8861\u4e86\u5b89\u5168\u6027\u4e0e\u9a7e\u9a76\u6548\u7387\u3002"}}
{"id": "2509.07511", "pdf": "https://arxiv.org/pdf/2509.07511", "abs": "https://arxiv.org/abs/2509.07511", "authors": ["Jinming Wang", "Lipeng Zhu", "Shuai Han", "He Sun", "Rui Zhang"], "title": "Joint Antenna Positioning and Beamforming for Movable Antenna Array Aided Ground Station in Low-Earth Orbit Satellite Communication", "categories": ["eess.SP"], "comment": null, "summary": "This paper proposes a new architecture for the low-earth orbit (LEO)\nsatellite ground station aided by movable antenna (MA) array. Unlike\nconventional fixed-position antenna (FPA), the MA array can flexibly adjust\nantenna positions to reconfigure array geometry, for more effectively\nmitigating interference and improving communication performance in ultra-dense\nLEO satellite networks. To reduce movement overhead, we configure antenna\npositions at the antenna initialization stage, which remain unchanged during\nthe whole communication period of the ground station. To this end, an\noptimization problem is formulated to maximize the average achievable rate of\nthe ground station by jointly optimizing its antenna position vector (APV) and\ntime-varying beamforming weights, i.e., antenna weight vectors (AWVs). To solve\nthe resulting non-convex optimization problem, we adopt the Lagrangian dual\ntransformation and quadratic transformation to reformulate the objective\nfunction into a more tractable form. Then, we develop an efficient block\ncoordinate descent-based iterative algorithm that alternately optimizes the APV\nand AWVs until convergence is reached. Simulation results demonstrate that our\nproposed MA scheme significantly outperforms traditional FPA by increasing the\nachievable rate at ground stations under various system setups, thus providing\nan efficient solution for interference mitigation in future ultra-dense LEO\nsatellite communication networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u79fb\u52a8\u5929\u7ebf\u9635\u5217\u7684\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u5730\u9762\u7ad9\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u6ce2\u675f\u8d4b\u5f62\u6743\u91cd\u63d0\u5347\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u5728\u8d85\u5bc6\u96c6\u536b\u661f\u7f51\u7edc\u4e2d\u5e72\u6270\u4e25\u91cd\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\u3002", "method": "\u91c7\u7528\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u53d8\u6362\u548c\u4e8c\u6b21\u53d8\u6362\u91cd\u6784\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u5757\u5750\u6807\u4e0b\u964d\u8fed\u4ee3\u7b97\u6cd5\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u6ce2\u675f\u8d4b\u5f62\u6743\u91cd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u9762\u7ad9\u7684\u901a\u4fe1\u901f\u7387\uff0c\u4f18\u4e8e\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u65b9\u6848\u3002", "conclusion": "\u53ef\u79fb\u52a8\u5929\u7ebf\u9635\u5217\u4e3a\u672a\u6765\u8d85\u5bc6\u96c6\u536b\u661f\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e72\u6270\u7f13\u89e3\u65b9\u6848\u3002"}}
{"id": "2509.07496", "pdf": "https://arxiv.org/pdf/2509.07496", "abs": "https://arxiv.org/abs/2509.07496", "authors": ["Ayano Miyamichi", "Moju Zhao", "Kazuki Sugihara", "Junichiro Sugihara", "Masanori Konishi", "Kunio Kojima", "Kei Okada", "Masayuki Inaba"], "title": "Flexible Morphing Aerial Robot with Inflatable Structure for Perching-based Human-Robot Interaction", "categories": ["cs.RO"], "comment": null, "summary": "Birds in nature perform perching not only for rest but also for interaction\nwith human such as the relationship with falconers. Recently, researchers\nachieve perching-capable aerial robots as a way to save energy, and deformable\nstructure demonstrate significant advantages in efficiency of perching and\ncompactness of configuration. However, ensuring flight stability remains\nchallenging for deformable aerial robots due to the difficulty of controlling\nflexible arms. Furthermore, perching for human interaction requires high\ncompliance along with safety. Thus, this study aims to develop a deformable\naerial robot capable of perching on humans with high flexibility and grasping\nability. To overcome the challenges of stability of both flight and perching,\nwe propose a hybrid morphing structure that combines a unilateral flexible arm\nand a pneumatic inflatable actuators. This design allows the robot's arms to\nremain rigid during flight and soft while perching for more effective grasping.\nWe also develop a pneumatic control system that optimizes pressure regulation\nwhile integrating shock absorption and adjustable grasping forces, enhancing\ninteraction capabilities and energy efficiency. Besides, we focus on the\nstructural characteristics of the unilateral flexible arm and identify\nsufficient conditions under which standard quadrotor modeling and control\nremain effective in terms of flight stability. Finally, the developed prototype\ndemonstrates the feasibility of compliant perching maneuvers on humans, as well\nas the robust recovery even after arm deformation caused by thrust reductions\nduring flight. To the best of our knowledge, this work is the first to achieve\nan aerial robot capable of perching on humans for interaction.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u53d8\u5f62\u7a7a\u4e2d\u673a\u5668\u4eba\uff0c\u80fd\u591f\u5728\u4eba\u7c7b\u8eab\u4e0a\u6816\u606f\uff0c\u5177\u5907\u9ad8\u7075\u6d3b\u6027\u548c\u6293\u53d6\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u53d8\u5f62\u673a\u5668\u4eba\u98de\u884c\u7a33\u5b9a\u6027\u4e0e\u6816\u606f\u5b89\u5168\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u81ea\u7136\u754c\u4e2d\u9e1f\u7c7b\u6816\u606f\u4e0d\u4ec5\u4e3a\u4f11\u606f\uff0c\u4e5f\u4e3a\u4e0e\u4eba\u7c7b\u4e92\u52a8\uff08\u5982\u4e0e\u730e\u9e70\u8005\u7684\u5173\u7cfb\uff09\u3002\u53ef\u53d8\u5f62\u7a7a\u4e2d\u673a\u5668\u4eba\u901a\u8fc7\u6816\u606f\u80fd\u8282\u7701\u80fd\u91cf\uff0c\u4f46\u5176\u98de\u884c\u7a33\u5b9a\u6027\u548c\u6816\u606f\u5b89\u5168\u6027\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u53d8\u5f62\u7ed3\u6784\uff0c\u7ed3\u5408\u5355\u4fa7\u67d4\u6027\u81c2\u548c\u6c14\u52a8\u9a71\u52a8\u88c5\u7f6e\uff0c\u5b9e\u73b0\u98de\u884c\u65f6\u81c2\u521a\u6027\u3001\u6816\u606f\u65f6\u81c2\u67d4\u8f6f\u7684\u8bbe\u8ba1\uff1b\u5f00\u53d1\u4e86\u6c14\u52a8\u63a7\u5236\u7cfb\u7edf\uff0c\u4f18\u5316\u538b\u529b\u8c03\u8282\u4e0e\u80fd\u91cf\u6548\u7387\u3002", "result": "\u8bbe\u8ba1\u7684\u539f\u578b\u5c55\u793a\u4e86\u5728\u4eba\u7c7b\u8eab\u4e0a\u7075\u6d3b\u6816\u606f\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u98de\u884c\u4e2d\u63a8\u529b\u51cf\u5c0f\u5bfc\u81f4\u81c2\u53d8\u5f62\u540e\u7684\u5feb\u901f\u6062\u590d\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5b9e\u73b0\u4e86\u53ef\u5728\u4eba\u7c7b\u8eab\u4e0a\u4e92\u52a8\u7684\u7a7a\u4e2d\u673a\u5668\u4eba\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.07610", "pdf": "https://arxiv.org/pdf/2509.07610", "abs": "https://arxiv.org/abs/2509.07610", "authors": ["Ahsan Mehmood", "Ioannis Krikidis", "Ghassan M. Kraidy"], "title": "Asymmetric Modulation Design for Fluid-Antenna SWIPT Systems", "categories": ["eess.SP", "cs.NA", "math.NA"], "comment": "Accepted for Publication in Globecomm Green Communication Conference", "summary": "In this work, we propose the design of modulation schemes that improve the\nrate-energy region of fluid antenna-assisted simultaneous wireless information\nand power transfer (SWIPT) systems. By considering the nonlinear\ncharacteristics of practical energy harvesting circuits, we formulate a\ndual-objective rate-energy (RE) region optimization problem to jointly maximize\nthe discrete-input mutual information (DIMI) and harvested current. The problem\nis solved using the epsilon-constraint method and optimized constellations are\ndesigned for various energy harvesting thresholds. We then evaluate the\nperformance of the optimized constellations under three different fluid antenna\n(FA) port selection strategies: (i) Best Port, (ii) Fixed Port, and (iii)\nRandom Port. Our simulation results demonstrate significant performance gains\nof optimized constellations over conventional constellations in both\ninformation rate and energy harvesting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8c03\u5236\u65b9\u6848\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u9ad8\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u7684\u65e0\u7ebf\u4fe1\u606f\u4e0e\u80fd\u91cf\u540c\u65f6\u4f20\u8f93\uff08SWIPT\uff09\u7cfb\u7edf\u7684\u901f\u7387-\u80fd\u91cf\u533a\u57df\u6027\u80fd\u3002", "motivation": "\u8003\u8651\u5230\u5b9e\u9645\u80fd\u91cf\u6536\u96c6\u7535\u8def\u7684\u975e\u7ebf\u6027\u7279\u6027\uff0c\u7814\u7a76\u65e8\u5728\u8054\u5408\u6700\u5927\u5316\u79bb\u6563\u8f93\u5165\u4e92\u4fe1\u606f\uff08DIMI\uff09\u548c\u6536\u96c6\u7535\u6d41\u3002", "method": "\u91c7\u7528epsilon\u7ea6\u675f\u65b9\u6cd5\u89e3\u51b3\u4e86\u901f\u7387-\u80fd\u91cf\u533a\u57df\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4e3a\u4e0d\u540c\u80fd\u91cf\u6536\u96c6\u9608\u503c\u8bbe\u8ba1\u4e86\u4f18\u5316\u661f\u5ea7\u56fe\u3002", "result": "\u901a\u8fc7\u4e09\u79cd\u6d41\u4f53\u5929\u7ebf\u7aef\u53e3\u9009\u62e9\u7b56\u7565\u8bc4\u4f30\u4f18\u5316\u661f\u5ea7\u56fe\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u8868\u660e\u5176\u5728\u4fe1\u606f\u901f\u7387\u548c\u80fd\u91cf\u6536\u96c6\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u661f\u5ea7\u56fe\u3002", "conclusion": "\u4f18\u5316\u7684\u8c03\u5236\u65b9\u6848\u5728SWIPT\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.07500", "pdf": "https://arxiv.org/pdf/2509.07500", "abs": "https://arxiv.org/abs/2509.07500", "authors": ["Yinan Deng", "Yufeng Yue", "Jianyu Dou", "Jingyu Zhao", "Jiahui Wang", "Yujie Tang", "Yi Yang", "Mengyin Fu"], "title": "OmniMap: A General Mapping Framework Integrating Optics, Geometry, and Semantics", "categories": ["cs.RO"], "comment": "Accepted by IEEE Transactions on Robotics (TRO), project website:\n  https://omni-map.github.io/", "summary": "Robotic systems demand accurate and comprehensive 3D environment perception,\nrequiring simultaneous capture of photo-realistic appearance (optical), precise\nlayout shape (geometric), and open-vocabulary scene understanding (semantic).\nExisting methods typically achieve only partial fulfillment of these\nrequirements while exhibiting optical blurring, geometric irregularities, and\nsemantic ambiguities. To address these challenges, we propose OmniMap. Overall,\nOmniMap represents the first online mapping framework that simultaneously\ncaptures optical, geometric, and semantic scene attributes while maintaining\nreal-time performance and model compactness. At the architectural level,\nOmniMap employs a tightly coupled 3DGS-Voxel hybrid representation that\ncombines fine-grained modeling with structural stability. At the implementation\nlevel, OmniMap identifies key challenges across different modalities and\nintroduces several innovations: adaptive camera modeling for motion blur and\nexposure compensation, hybrid incremental representation with normal\nconstraints, and probabilistic fusion for robust instance-level understanding.\nExtensive experiments show OmniMap's superior performance in rendering\nfidelity, geometric accuracy, and zero-shot semantic segmentation compared to\nstate-of-the-art methods across diverse scenes. The framework's versatility is\nfurther evidenced through a variety of downstream applications, including\nmulti-domain scene Q&A, interactive editing, perception-guided manipulation,\nand map-assisted navigation.", "AI": {"tldr": "OmniMap\u662f\u4e00\u79cd\u5728\u7ebf3D\u73af\u5883\u611f\u77e5\u6846\u67b6\uff0c\u9996\u6b21\u540c\u65f6\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5149\u5b66\u3001\u7cbe\u786e\u51e0\u4f55\u548c\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u6355\u6349\uff0c\u5177\u5907\u5b9e\u65f6\u6027\u548c\u6a21\u578b\u7d27\u51d1\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5149\u5b66\u3001\u51e0\u4f55\u548c\u8bed\u4e49\u6355\u6349\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5982\u6a21\u7cca\u3001\u4e0d\u89c4\u5219\u548c\u6b67\u4e49\uff0c\u9700\u8981\u4e00\u79cd\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u75283DGS-Voxel\u6df7\u5408\u8868\u793a\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u76f8\u673a\u5efa\u6a21\u3001\u6df7\u5408\u589e\u91cf\u8868\u793a\u548c\u6982\u7387\u878d\u5408\u7b49\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cOmniMap\u5728\u6e32\u67d3\u4fdd\u771f\u5ea6\u3001\u51e0\u4f55\u7cbe\u5ea6\u548c\u96f6\u6837\u672c\u8bed\u4e49\u5206\u5272\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "OmniMap\u7684\u591a\u6837\u6027\u652f\u6301\u591a\u79cd\u4e0b\u6e38\u5e94\u7528\uff0c\u5c55\u73b0\u4e86\u7efc\u5408\u611f\u77e5\u6846\u67b6\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.07754", "pdf": "https://arxiv.org/pdf/2509.07754", "abs": "https://arxiv.org/abs/2509.07754", "authors": ["Felix Artmann", "Daniel Gil Gaviria", "Benedikt Geiger", "Laurent Schmalen"], "title": "Interference Mitigation for OFDM-based Integrated Sensing and Communications with Arbitrary Modulation Formats", "categories": ["eess.SP"], "comment": null, "summary": "Integrated sensing and communication will be a key feature of future mobile\nnetworks, enabling highly efficient systems and numerous new applications by\nleveraging communication signals for sensing. In this paper, we analyze the\nimpact of arbitrary modulation alphabets on the sensing performance of\ncommunication-centric OFDM systems as expected in the next-generation 6G\nnetworks. We evaluate existing interference mitigation techniques, such as\ncoherent successive target cancellation, and propose an enhanced version of\nthis algorithm. A systematic performance evaluation in multi-target scenarios,\nincluding the effects of scattering, demonstrates that our proposed\ninterference mitigation methods achieve performance comparable to\nsensing-optimal constant modulus signals while utilizing higher order\nconstellations for more efficient communications.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u4e0d\u540c\u8c03\u5236\u5b57\u6bcd\u5bf9OFDM\u7cfb\u7edf\u611f\u77e5\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u5e72\u6270\u6d88\u9664\u7b97\u6cd5\uff0c\u5728\u591a\u76ee\u6807\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u652f\u6301\u9ad8\u6548\u901a\u4fe1\u3002", "motivation": "\u672a\u6765\u7684\u79fb\u52a8\u7f51\u7edc\u9700\u8981\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\uff0c\u901a\u8fc7\u901a\u4fe1\u4fe1\u53f7\u5b9e\u73b0\u9ad8\u6548\u611f\u77e5\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d226G\u7f51\u7edc\u4e2dOFDM\u7cfb\u7edf\u8c03\u5236\u5b57\u6bcd\u5bf9\u611f\u77e5\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u8bc4\u4f30\u73b0\u6709\u5e72\u6270\u6d88\u9664\u6280\u672f\uff08\u5982\u8fde\u8d2f\u8fde\u7eed\u76ee\u6807\u6d88\u9664\uff09\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7248\u672c\u3002\u901a\u8fc7\u591a\u76ee\u6807\u573a\u666f\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\u5206\u6790\uff0c\u9a8c\u8bc1\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u63d0\u51fa\u7684\u5e72\u6270\u6d88\u9664\u65b9\u6cd5\u5728\u591a\u76ee\u6807\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6027\u80fd\u63a5\u8fd1\u611f\u77e5\u6700\u4f73\u5e38\u6570\u6a21\u4fe1\u53f7\uff0c\u540c\u65f6\u652f\u6301\u9ad8\u9636\u8c03\u5236\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u3002", "conclusion": "\u6539\u8fdb\u7684\u5e72\u6270\u6d88\u9664\u7b97\u6cd5\u80fd\u5728\u590d\u6742\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8\u6548\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u5e73\u8861\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2509.07542", "pdf": "https://arxiv.org/pdf/2509.07542", "abs": "https://arxiv.org/abs/2509.07542", "authors": ["Bartlomiej Kulecki", "Dominik Belter"], "title": "Improving Machine Learning-Based Robot Self-Collision Checking with Input Positional Encoding", "categories": ["cs.RO"], "comment": null, "summary": "This manuscript investigates the integration of positional encoding -- a\ntechnique widely used in computer graphics -- into the input vector of a binary\nclassification model for self-collision detection. The results demonstrate the\nbenefits of incorporating positional encoding, which enhances classification\naccuracy by enabling the model to better capture high-frequency variations,\nleading to a more detailed and precise representation of complex collision\npatterns. The manuscript shows that machine learning-based techniques, such as\nlightweight multilayer perceptrons (MLPs) operating in a low-dimensional\nfeature space, offer a faster alternative for collision checking than\ntraditional methods that rely on geometric approaches, such as\ntriangle-to-triangle intersection tests and Bounding Volume Hierarchies (BVH)\nfor mesh-based models.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4e8c\u5143\u5206\u7c7b\u6a21\u578b\u4e2d\u96c6\u6210\u4f4d\u7f6e\u7f16\u7801\u6280\u672f\u4ee5\u6539\u8fdb\u81ea\u78b0\u649e\u68c0\u6d4b\u7684\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u80fd\u63d0\u5347\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u51e0\u4f55\u65b9\u6cd5\uff08\u5982\u4e09\u89d2\u5f62\u76f8\u4ea4\u6d4b\u8bd5\uff09\u5728\u81ea\u78b0\u649e\u68c0\u6d4b\u4e2d\u6548\u7387\u8f83\u4f4e\uff0c\u56e0\u6b64\u63a2\u7d22\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002", "method": "\u5c06\u4f4d\u7f6e\u7f16\u7801\u6280\u672f\u878d\u5165\u8f93\u5165\u5411\u91cf\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u5728\u4f4e\u7ef4\u7279\u5f81\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u66f4\u597d\u6355\u6349\u9ad8\u9891\u53d8\u5316\uff0c\u63d0\u5347\u5206\u7c7b\u7cbe\u5ea6\uff0c\u4e14\u6bd4\u4f20\u7edf\u51e0\u4f55\u65b9\u6cd5\u66f4\u5feb\u901f\u3002", "conclusion": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u81ea\u78b0\u649e\u68c0\u6d4b\u65b9\u6cd5\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f4d\u7f6e\u7f16\u7801\u7684\u5f15\u5165\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2509.07758", "pdf": "https://arxiv.org/pdf/2509.07758", "abs": "https://arxiv.org/abs/2509.07758", "authors": ["Pietro Savazzi", "Anna Vizziello", "Sherif Badran", "Josep M. Jornet"], "title": "Experimental Evaluation of Joint Clock Recovery and Equalization for Sub-Terahertz Links", "categories": ["eess.SP"], "comment": "To be presented at the 13th IEEE INTERNATIONAL CONFERENCE ON WIRELESS\n  FOR SPACE AND EXTREME ENVIRONMENTS WiSEE 2025", "summary": "This paper proposes and experimentally evaluates a joint clock recovery (CR)\nand equalization architecture tailored for high-speed sub-terahertz (sub-THz)\nwireless communication links. Specifically, a Baud-spaced digital receiver\narchitecture is investigated that combines a constant modulus algorithm (CMA)\nequalizer with a blind timing error detector (TED), enabling robust symbol\ntiming synchronization without decision-directed (DD) feedback or pilot\nsymbols. The proposed TED leverages the CMA filter coefficients to estimate\ntiming errors, which are then used to drive a Farrow interpolator operating at\ntwice the symbol rate. The system is validated experimentally using a 140~GHz\nwireless testbed with 16-QAM modulation over a 10~GHz bandwidth. Results show\nthat the proposed TED schemes outperform conventional blind TEDs, such as\nGardner and blind implementations of Mueller \\& M\\\"uller, in terms of bit error\nrate (BER), error vector magnitude (EVM), and intersymbol interference (ISI)\nsuppression. These capabilities are especially relevant to next-generation\nspaceborne communication systems, where wideband sub-THz links are expected to\nplay a key role in enabling ultra-high-data-rate inter-satellite and deep-space\ncommunications under challenging synchronization constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9ad8\u901f\u4e9a\u592a\u8d6b\u5179\u65e0\u7ebf\u901a\u4fe1\u94fe\u8def\u7684\u8054\u5408\u65f6\u949f\u6062\u590d\u548c\u5747\u8861\u67b6\u6784\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728BER\u3001EVM\u548cISI\u6291\u5236\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e0b\u4e00\u4ee3\u5929\u57fa\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u8d85\u9ad8\u901f\u7387\u901a\u4fe1\u63d0\u4f9b\u9c81\u68d2\u7684\u7b26\u53f7\u5b9a\u65f6\u540c\u6b65\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408CMA\u5747\u8861\u5668\u548c\u76f2TED\u7684Baud\u95f4\u9694\u6570\u5b57\u63a5\u6536\u67b6\u6784\uff0c\u5229\u7528CMA\u6ee4\u6ce2\u5668\u7cfb\u6570\u4f30\u8ba1\u5b9a\u65f6\u8bef\u5dee\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u5728140GHz\u65e0\u7ebf\u6d4b\u8bd5\u5e8a\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u76f2TED\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u9ad8\u5e26\u5bbd\u4e9a\u592a\u8d6b\u5179\u94fe\u8def\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5177\u6709\u6311\u6218\u6027\u7684\u540c\u6b65\u7ea6\u675f\u573a\u666f\u3002"}}
{"id": "2509.07593", "pdf": "https://arxiv.org/pdf/2509.07593", "abs": "https://arxiv.org/abs/2509.07593", "authors": ["Gavin Tao", "Yinuo Wang", "Jinzhao Zhou"], "title": "Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.SY", "eess.IV", "eess.SY"], "comment": "4 figures and 6 tables", "summary": "End-to-end reinforcement learning for motion control promises unified\nperception-action policies that scale across embodiments and tasks, yet most\ndeployed controllers are either blind (proprioception-only) or rely on fusion\nbackbones with unfavorable compute-memory trade-offs. Recurrent controllers\nstruggle with long-horizon credit assignment, and Transformer-based fusion\nincurs quadratic cost in token length, limiting temporal and spatial context.\nWe present a vision-driven cross-modal RL framework built on SSD-Mamba2, a\nselective state-space backbone that applies state-space duality (SSD) to enable\nboth recurrent and convolutional scanning with hardware-aware streaming and\nnear-linear scaling. Proprioceptive states and exteroceptive observations\n(e.g., depth tokens) are encoded into compact tokens and fused by stacked\nSSD-Mamba2 layers. The selective state-space updates retain long-range\ndependencies with markedly lower latency and memory use than quadratic\nself-attention, enabling longer look-ahead, higher token resolution, and stable\ntraining under limited compute. Policies are trained end-to-end under curricula\nthat randomize terrain and appearance and progressively increase scene\ncomplexity. A compact, state-centric reward balances task progress, energy\nefficiency, and safety. Across diverse motion-control scenarios, our approach\nconsistently surpasses strong state-of-the-art baselines in return, safety\n(collisions and falls), and sample efficiency, while converging faster at the\nsame compute budget. These results suggest that SSD-Mamba2 provides a practical\nfusion backbone for scalable, foresightful, and efficient end-to-end motion\ncontrol.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSSD-Mamba2\u7684\u8de8\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u8fd0\u52a8\u63a7\u5236\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6280\u672f\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u548c\u957f\u8ddd\u79bb\u4f9d\u8d56\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8fd0\u52a8\u63a7\u5236\u5668\u591a\u4e3a\u76f2\u63a7\u6216\u8ba1\u7b97-\u5185\u5b58\u6548\u7387\u4f4e\u7684\u878d\u5408\u6846\u67b6\uff0c\u9012\u5f52\u63a7\u5236\u5668\u56e0\u957f\u65f6\u7a0b\u4fe1\u7528\u5206\u914d\u56f0\u96be\u8868\u73b0\u4e0d\u4f73\uff0c\u800cTransformer\u7684\u6210\u672c\u968ftoken\u957f\u5ea6\u5448\u4e8c\u6b21\u589e\u957f\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u878d\u5408\u6846\u67b6\u3002", "method": "\u91c7\u7528SSD-Mamba2\u4f5c\u4e3a\u4e3b\u5e72\u7f51\u7edc\uff0c\u7ed3\u5408\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6280\u672f\uff0c\u5c06\u672c\u4f53\u611f\u77e5\u548c\u5916\u611f\u77e5\u89c2\u5bdf\u7f16\u7801\u4e3a\u7d27\u51d1token\uff0c\u901a\u8fc7\u5806\u53e0SSD-Mamba2\u5c42\u8fdb\u884c\u878d\u5408\u3002\u901a\u8fc7\u968f\u673a\u5316\u548c\u6e10\u8fdb\u589e\u52a0\u7684\u8bfe\u7a0b\u5b66\u4e60\u8bad\u7ec3\u7aef\u5230\u7aef\u7b56\u7565\u3002", "result": "\u5728\u591a\u8fd0\u52a8\u63a7\u5236\u573a\u666f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u56de\u62a5\u3001\u5b89\u5168\u6027\uff08\u78b0\u649e\u548c\u6454\u5012\uff09\u548c\u6837\u672c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4e14\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u6536\u655b\u66f4\u5feb\u3002", "conclusion": "SSD-Mamba2\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u524d\u77bb\u6027\u5f3a\u4e14\u53ef\u6269\u5c55\u7684\u7aef\u5230\u7aef\u8fd0\u52a8\u63a7\u5236\u878d\u5408\u6846\u67b6\u3002"}}
{"id": "2509.07775", "pdf": "https://arxiv.org/pdf/2509.07775", "abs": "https://arxiv.org/abs/2509.07775", "authors": ["Yu Ge", "Ossi Kaltiokallio", "Elizaveta Rastorgueva-Foi", "Musa Furkan Keskin", "Hui Chen", "Guillaume Jornod", "Jukka Talvitie", "Mikko Valkama", "Frank Hofmann", "Henk Wymeersch"], "title": "Sensing with Mobile Devices through Radio SLAM: Models, Methods, Opportunities, and Challenges", "categories": ["eess.SP"], "comment": null, "summary": "The integration of sensing and communication (ISAC) is a cornerstone of 6G,\nenabling simultaneous environmental awareness and communication. This paper\nexplores radio SLAM (simultaneous localization and mapping) as a key ISAC\napproach, using radio signals for mapping and localization. We analyze radio\nSLAM across different frequency bands, discussing trade-offs in coverage,\nresolution, and hardware requirements. We also highlight opportunities for\nintegration with sensing, positioning, and cooperative networks. The findings\npave the way for standardized solutions in 6G applications such as autonomous\nsystems and industrial robotics.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e866G\u4e2d\u611f\u77e5\u4e0e\u901a\u4fe1\u96c6\u6210\uff08ISAC\uff09\u7684\u6838\u5fc3\u6280\u672f\u2014\u2014\u65e0\u7ebf\u7535SLAM\uff08\u5373\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\uff09\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u9891\u6bb5\u7684\u6027\u80fd\u6743\u8861\uff0c\u5e76\u6307\u51fa\u4e86\u4e0e\u611f\u77e5\u3001\u5b9a\u4f4d\u53ca\u534f\u4f5c\u7f51\u7edc\u7684\u878d\u5408\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u65e0\u7ebf\u7535SLAM\u4f5c\u4e3a6G ISAC\u7684\u5173\u952e\u65b9\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u65e0\u7ebf\u7535\u4fe1\u53f7\u5b9e\u73b0\u73af\u5883\u611f\u77e5\u4e0e\u901a\u4fe1\uff0c\u63a8\u52a8\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002", "method": "\u5206\u6790\u4e86\u65e0\u7ebf\u7535SLAM\u5728\u4e0d\u540c\u9891\u6bb5\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5305\u62ec\u8986\u76d6\u8303\u56f4\u3001\u5206\u8fa8\u7387\u53ca\u786c\u4ef6\u9700\u6c42\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0e\u611f\u77e5\u3001\u5b9a\u4f4d\u548c\u534f\u4f5c\u7f51\u7edc\u7684\u96c6\u6210\u673a\u4f1a\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3a6G\u5e94\u7528\uff08\u5982\u81ea\u4e3b\u7cfb\u7edf\u548c\u5de5\u4e1a\u673a\u5668\u4eba\uff09\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u7684\u57fa\u7840\u3002", "conclusion": "\u65e0\u7ebf\u7535SLAM\u662f6G ISAC\u7684\u91cd\u8981\u6280\u672f\uff0c\u5176\u591a\u9891\u6bb5\u5206\u6790\u53ca\u96c6\u6210\u6f5c\u529b\u4e3a\u672a\u6765\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.07646", "pdf": "https://arxiv.org/pdf/2509.07646", "abs": "https://arxiv.org/abs/2509.07646", "authors": ["Yanlong Peng", "Zhigang Wang", "Ziwen He", "Pengxu Chang", "Chuangchuang Zhou", "Yu Yan", "Ming Chen"], "title": "Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network", "categories": ["cs.RO"], "comment": null, "summary": "In robots task and motion planning (TAMP), it is crucial to sample within the\nrobot's configuration space to meet task-level global constraints and enhance\nthe efficiency of subsequent motion planning. Due to the complexity of joint\nconfiguration sampling under multi-level constraints, traditional methods often\nlack efficiency. This paper introduces the principle of RobKiNet, a\nkinematics-informed neural network, for end-to-end sampling within the\nContinuous Feasible Set (CFS) under multiple constraints in configuration\nspace, establishing its Optimization Expectation Model. Comparisons with\ntraditional sampling and learning-based approaches reveal that RobKiNet's\nkinematic knowledge infusion enhances training efficiency by ensuring stable\nand accurate gradient optimization.Visualizations and quantitative analyses in\na 2-DOF space validate its theoretical efficiency, while its application on a\n9-DOF autonomous mobile manipulator robot(AMMR) demonstrates superior\nwhole-body and decoupled control, excelling in battery disassembly tasks.\nRobKiNet outperforms deep reinforcement learning with a training speed 74.29\ntimes faster and a sampling accuracy of up to 99.25%, achieving a 97.33% task\ncompletion rate in real-world scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faRobKiNet\uff0c\u4e00\u79cd\u8fd0\u52a8\u5b66\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u9ad8\u6548\u6ee1\u8db3\u4efb\u52a1\u7ea7\u5168\u5c40\u7ea6\u675f\u7684\u673a\u5668\u4eba\u914d\u7f6e\u7a7a\u95f4\u91c7\u6837\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u591a\u7ea7\u7ea6\u675f\u4e0b\u673a\u5668\u4eba\u914d\u7f6e\u7a7a\u95f4\u91c7\u6837\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8fd0\u52a8\u5b66\u77e5\u8bc6\u6ce8\u5165\u7684\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7aef\u5230\u7aef\u8fde\u7eed\u53ef\u884c\u96c6\u91c7\u6837\uff0c\u5e76\u5efa\u7acb\u4f18\u5316\u671f\u671b\u6a21\u578b\u3002", "result": "\u57282-DOF\u548c9-DOF\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u6548\u7387\u548c\u5b9e\u9645\u6027\u80fd\uff0c\u91c7\u6837\u7cbe\u5ea6\u8fbe99.25%\uff0c\u4efb\u52a1\u5b8c\u6210\u738797.33%\u3002", "conclusion": "RobKiNet\u5728\u8bad\u7ec3\u901f\u5ea6\u548c\u91c7\u6837\u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u9002\u7528\u590d\u6742\u4efb\u52a1\u3002"}}
{"id": "2509.07839", "pdf": "https://arxiv.org/pdf/2509.07839", "abs": "https://arxiv.org/abs/2509.07839", "authors": ["Florian Strasser", "Marion B\u00e4ro", "Wolfgang Utschick"], "title": "Enhancements in Score-based Channel Estimation for Real-Time Wireless Systems", "categories": ["eess.SP"], "comment": "Presented at 28th International Workshop on Smart Antennas 2025,\n  https://www.wsa2025.fau.de/", "summary": "We propose enhancements to score-based generative modeling techniques for\nlow-latency pilot-based channel estimation in a point-to-point single-carrier\nmultiple-input multiple-output (MIMO) wireless system. Building on recent\nadvances in score-based models, we investigate a specific noise schedule design\nand sampling acceleration by step-skipping to reduce the number of denoising\nsteps during inference. We additionally propose a single-step signal-to-noise\nratio informed denoiser as an extreme case of the step-skipping approach. Our\nmethods achieve significant latency reductions without performance degradation,\nas demonstrated on a synthetic channel dataset representing an urban macrocell\nMIMO communications scenario.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5206\u6570\u7684\u751f\u6210\u6a21\u578b\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f4e\u5ef6\u8fdf\u7684\u4fe1\u9053\u4f30\u8ba1\uff0c\u901a\u8fc7\u566a\u58f0\u8c03\u5ea6\u8bbe\u8ba1\u548c\u62bd\u6837\u52a0\u901f\u6765\u51cf\u5c11\u53bb\u566a\u6b65\u9aa4\u3002", "motivation": "\u5728\u5355\u8f7d\u6ce2MIMO\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u63d0\u5347\u4f4e\u5ef6\u8fdf\u4fe1\u9053\u4f30\u8ba1\u7684\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u7279\u5b9a\u7684\u566a\u58f0\u8c03\u5ea6\u548c\u62bd\u6837\u52a0\u901f\uff08\u5982\u8df3\u8fc7\u6b65\u9aa4\uff09\uff0c\u5e76\u63d0\u51fa\u5355\u6b65\u4fe1\u566a\u6bd4\u901a\u77e5\u53bb\u566a\u5668\u3002", "result": "\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u4fe1\u9053\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u57ce\u5e02\u5b8f\u8702\u7a9dMIMO\u901a\u4fe1\u573a\u666f\u3002"}}
{"id": "2509.07655", "pdf": "https://arxiv.org/pdf/2509.07655", "abs": "https://arxiv.org/abs/2509.07655", "authors": ["Angelos Zacharia", "Mihir Dharmadhikari", "Kostas Alexis"], "title": "Collaborative Exploration with a Marsupial Ground-Aerial Robot Team through Task-Driven Map Compression", "categories": ["cs.RO"], "comment": "Accepted for publication in IEEE Robotics and Automation Letters\n  (RA-L)", "summary": "Efficient exploration of unknown environments is crucial for autonomous\nrobots, especially in confined and large-scale scenarios with limited\ncommunication. To address this challenge, we propose a collaborative\nexploration framework for a marsupial ground-aerial robot team that leverages\nthe complementary capabilities of both platforms. The framework employs a\ngraph-based path planning algorithm to guide exploration and deploy the aerial\nrobot in areas where its expected gain significantly exceeds that of the ground\nrobot, such as large open spaces or regions inaccessible to the ground\nplatform, thereby maximizing coverage and efficiency. To facilitate large-scale\nspatial information sharing, we introduce a bandwidth-efficient, task-driven\nmap compression strategy. This method enables each robot to reconstruct\nresolution-specific volumetric maps while preserving exploration-critical\ndetails, even at high compression rates. By selectively compressing and sharing\nkey data, communication overhead is minimized, ensuring effective map\nintegration for collaborative path planning. Simulation and real-world\nexperiments validate the proposed approach, demonstrating its effectiveness in\nimproving exploration efficiency while significantly reducing data\ntransmission.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5730\u9762-\u7a7a\u4e2d\u673a\u5668\u4eba\u56e2\u961f\u534f\u540c\u63a2\u7d22\u672a\u77e5\u73af\u5883\u7684\u9ad8\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u4e92\u8865\u80fd\u529b\u548c\u5e26\u5bbd\u4f18\u5316\u7b56\u7565\u63d0\u5347\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u6709\u9650\u901a\u4fe1\u73af\u5883\u4e0b\u9ad8\u6548\u63a2\u7d22\u672a\u77e5\u73af\u5883\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u548c\u5e26\u5bbd\u9ad8\u6548\u7684\u4efb\u52a1\u9a71\u52a8\u5730\u56fe\u538b\u7f29\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u6570\u636e\u4f20\u8f93\u3002", "conclusion": "\u8be5\u534f\u540c\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u673a\u5668\u4eba\u56e2\u961f\u5728\u63a2\u7d22\u4efb\u52a1\u4e2d\u7684\u8986\u76d6\u8303\u56f4\u548c\u6548\u7387\u3002"}}
{"id": "2509.05003", "pdf": "https://arxiv.org/pdf/2509.05003", "abs": "https://arxiv.org/abs/2509.05003", "authors": ["Saeideh Mansouri", "Mohamed Shamekh", "Simon Indola", "Petri Mahonen"], "title": "Estimating Cellular Network Delays in Finnish Railways: A Machine Learning Enhanced Approach", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": "Accepted for presentation at IEEE PIMRC 2025. 6 pages, 7 figures", "summary": "There is growing interest in using public cellular networks for specialized\ncommunication applications, replacing standalone sector-specific networks. One\nsuch application is transitioning from the aging GSM-R railway network to\npublic 4G and 5G networks. Finland is modernizing its railway communication\nsystem through the Digirail project, leveraging public cellular networks. To\nevaluate network performance, a nationwide measurement campaign was conducted\nin two modes: Best Quality and Packet Replication. However, Best Quality mode\nintroduces artificial delays, making it unsuitable for real-world assessments.\nIn this paper, railway network delays are modeled using machine learning based\non measurements from the Packet Replication mode. The best-performing model is\nthen employed to generate a dataset estimating network delays across Finland's\nrailway network. This dataset provides a more accurate representation of\nnetwork performance. Machine learning based network performance prediction is\nshown to be feasible, and the results indicate that Finland's public cellular\nnetwork can meet the stringent performance requirements of railway network\ncontrol.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u516c\u5171\u8702\u7a9d\u7f51\u7edc\u66ff\u4ee3\u4e13\u7528\u94c1\u8def\u901a\u4fe1\u7f51\u7edc\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u5efa\u6a21\u8bc4\u4f30\u82ac\u5170\u94c1\u8def\u7f51\u7edc\u7684\u5ef6\u8fdf\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u516c\u5171\u8702\u7a9d\u7f51\u7edc\u7684\u53d1\u5c55\uff0c\u5c06\u5176\u7528\u4e8e\u4e13\u7528\u901a\u4fe1\u5e94\u7528\uff08\u5982\u94c1\u8def\u901a\u4fe1\uff09\u6210\u4e3a\u53ef\u80fd\uff0c\u82ac\u5170\u901a\u8fc7Digirail\u9879\u76ee\u63a8\u52a8\u8fd9\u4e00\u8f6c\u578b\u3002", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u5efa\u6a21\uff0c\u57fa\u4e8ePacket Replication\u6a21\u5f0f\u7684\u6d4b\u91cf\u6570\u636e\uff0c\u751f\u6210\u94c1\u8def\u7f51\u7edc\u5ef6\u8fdf\u6570\u636e\u96c6\u3002", "result": "\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u7f51\u7edc\u6027\u80fd\u53ef\u884c\uff0c\u516c\u5171\u8702\u7a9d\u7f51\u7edc\u80fd\u6ee1\u8db3\u94c1\u8def\u63a7\u5236\u7684\u4e25\u683c\u6027\u80fd\u8981\u6c42\u3002", "conclusion": "\u516c\u5171\u8702\u7a9d\u7f51\u7edc\u53ef\u6709\u6548\u66ff\u4ee3\u4f20\u7edf\u94c1\u8def\u901a\u4fe1\u7f51\u7edc\uff0c\u82ac\u5170\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2509.07674", "pdf": "https://arxiv.org/pdf/2509.07674", "abs": "https://arxiv.org/abs/2509.07674", "authors": ["Tamlin Love", "Antonio Andriella", "Guillem Aleny\u00e0"], "title": "Temporal Counterfactual Explanations of Behaviour Tree Decisions", "categories": ["cs.RO", "cs.HC"], "comment": "23 pages, 6 figures, submitted to Engineering Applications of\n  Artificial Intelligence", "summary": "Explainability is a critical tool in helping stakeholders understand robots.\nIn particular, the ability for robots to explain why they have made a\nparticular decision or behaved in a certain way is useful in this regard.\nBehaviour trees are a popular framework for controlling the decision-making of\nrobots and other software systems, and thus a natural question to ask is\nwhether or not a system driven by a behaviour tree is capable of answering\n\"why\" questions. While explainability for behaviour trees has seen some prior\nattention, no existing methods are capable of generating causal, counterfactual\nexplanations which detail the reasons for robot decisions and behaviour.\nTherefore, in this work, we introduce a novel approach which automatically\ngenerates counterfactual explanations in response to contrastive \"why\"\nquestions. Our method achieves this by first automatically building a causal\nmodel from the structure of the behaviour tree as well as domain knowledge\nabout the state and individual behaviour tree nodes. The resultant causal model\nis then queried and searched to find a set of diverse counterfactual\nexplanations. We demonstrate that our approach is able to correctly explain the\nbehaviour of a wide range of behaviour tree structures and states. By being\nable to answer a wide range of causal queries, our approach represents a step\ntowards more transparent, understandable and ultimately trustworthy robotic\nsystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u884c\u4e3a\u6811\u7ed3\u6784\u548c\u9886\u57df\u77e5\u8bc6\u81ea\u52a8\u751f\u6210\u56e0\u679c\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u4ee5\u63d0\u9ad8\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u7406\u89e3\u6027\u3002", "motivation": "\u884c\u4e3a\u6811\u662f\u63a7\u5236\u673a\u5668\u4eba\u51b3\u7b56\u7684\u6d41\u884c\u6846\u67b6\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u80fd\u591f\u751f\u6210\u56e0\u679c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u9650\u5236\u4e86\u5176\u89e3\u91ca\u6027\u3002", "method": "\u901a\u8fc7\u884c\u4e3a\u6811\u7ed3\u6784\u548c\u9886\u57df\u77e5\u8bc6\u81ea\u52a8\u6784\u5efa\u56e0\u679c\u6a21\u578b\uff0c\u5e76\u67e5\u8be2\u548c\u641c\u7d22\u4ee5\u751f\u6210\u591a\u6837\u5316\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6b63\u786e\u89e3\u91ca\u5404\u79cd\u884c\u4e3a\u6811\u7ed3\u6784\u548c\u72b6\u6001\u7684\u884c\u4e3a\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u7406\u89e3\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u89e3\u91ca\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5176\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2509.07128", "pdf": "https://arxiv.org/pdf/2509.07128", "abs": "https://arxiv.org/abs/2509.07128", "authors": ["Jingyi Yin", "Jingke Zhang", "Lijie Huang", "U-Wai Lok", "Ryan M DeRuiter", "Kaipeng Ji", "Yanzhe Zhao", "Kate M. Knoll", "Kendra E. Petersen", "Tao Wu", "Xiang-yang Zhu", "James D Krier", "Kathryn A. Robinson", "Lilach O Lerman", "Andrew J. Bentall", "Shigao Chen", "Chengwu Huang"], "title": "Contrast-Free Ultrasound Microvascular Imaging via Radiality and Similarity Weighting", "categories": ["physics.med-ph", "eess.IV", "eess.SP"], "comment": "22 pages,11 figures", "summary": "Microvascular imaging has advanced significantly with ultrafast data\nacquisition and improved clutter filtering, enhancing the sensitivity of power\nDoppler imaging to small vessels. However, the image quality remains limited by\nspatial resolution and elevated background noise, both of which impede\nvisualization and accurate quantification. To address these limitations, this\nstudy proposes a high-resolution cross-correlation Power Doppler (HR-XPD)\nmethod that integrates spatial radiality weighting with Doppler signal\ncoherence analysis, thereby enhancing spatial resolution while suppressing\nartifacts and background noise. Quantitative evaluations in simulation and in\nvivo experiments on healthy human liver, transplanted human kidney, and pig\nkidney demonstrated that HR-XPD significantly improves microvascular\nresolvability and contrast compared to conventional PD. In vivo results showed\nup to a 2 to 3-fold enhancement in spatial resolution and an increase in\ncontrast by up to 20 dB. High-resolution vascular details were clearly depicted\nwithin a short acquisition time of only 0.3 s-1.2 s without the use of contrast\nagents. These findings indicate that HR-XPD provides an effective,\ncontrast-free, and high-resolution microvascular imaging approach with broad\napplicability in both preclinical and clinical research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u5206\u8fa8\u7387\u4ea4\u53c9\u76f8\u5173\u80fd\u91cf\u591a\u666e\u52d2\u65b9\u6cd5\uff08HR-XPD\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u7a7a\u95f4\u5f84\u5411\u52a0\u6743\u548c\u591a\u666e\u52d2\u4fe1\u53f7\u76f8\u5e72\u5206\u6790\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5fae\u8840\u7ba1\u6210\u50cf\u7684\u5206\u8fa8\u7387\u548c\u5bf9\u6bd4\u5ea6\u3002", "motivation": "\u73b0\u6709\u5fae\u8840\u7ba1\u6210\u50cf\u6280\u672f\u56e0\u7a7a\u95f4\u5206\u8fa8\u7387\u4f4e\u548c\u80cc\u666f\u566a\u58f0\u9ad8\u800c\u53d7\u9650\uff0c\u5f71\u54cd\u4e86\u5c0f\u8840\u7ba1\u7684\u53ef\u89c6\u5316\u548c\u5b9a\u91cf\u5206\u6790\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86HR-XPD\uff0c\u7ed3\u5408\u7a7a\u95f4\u5f84\u5411\u52a0\u6743\u548c\u76f8\u5e72\u5206\u6790\uff0c\u589e\u5f3a\u5206\u8fa8\u7387\u5e76\u6291\u5236\u566a\u58f0\u3002", "result": "\u6a21\u62df\u548c\u5b9e\u9a8c\u8868\u660e\uff0cHR-XPD\u663e\u8457\u63d0\u5347\u4e86\u5fae\u8840\u7ba1\u7684\u53ef\u5206\u8fa8\u6027\u548c\u5bf9\u6bd4\u5ea6\uff0c\u5206\u8fa8\u7387\u63d0\u9ad8\u4e862-3\u500d\uff0c\u5bf9\u6bd4\u5ea6\u589e\u52a0\u4e8620 dB\u3002", "conclusion": "HR-XPD\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u9020\u5f71\u5242\u7684\u9ad8\u6548\u3001\u9ad8\u5206\u8fa8\u7387\u5fae\u8840\u7ba1\u6210\u50cf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u548c\u4e34\u5e8a\u524d\u7814\u7a76\u3002"}}
{"id": "2509.07683", "pdf": "https://arxiv.org/pdf/2509.07683", "abs": "https://arxiv.org/abs/2509.07683", "authors": ["Luis Diener", "Jens Kalkkuhl", "Markus Enzweiler"], "title": "Robust Radar SLAM for Vehicle Parking Applications", "categories": ["cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We address ego-motion estimation for automated parking, where\ncentimeter-level accuracy is crucial due to tight spaces and nearby obstacles.\nTraditional methods using inertial-measurement units and wheel encoders require\ncalibration, making them costly and time-consuming. To overcome this, we\npropose a radar-based simultaneous localization and mapping (SLAM) approach\nthat leverages the robustness of radar to adverse weather and support for\nonline calibration. Our robocentric formulation fuses feature positions and\nDoppler velocities for robust data association and filter convergence. Key\ncontributions include a Doppler-augmented radar SLAM method, multi-radar\nsupport and an information-based feature-pruning strategy. Experiments\ndemonstrate high-accuracy localization and improved robustness over\nstate-of-the-art methods, meeting the demands of automated parking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f7\u8fbe\u7684SLAM\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u505c\u8f66\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u81ea\u8fd0\u52a8\u4f30\u8ba1\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6821\u51c6\u95ee\u9898\uff0c\u5177\u6709\u591a\u96f7\u8fbe\u652f\u6301\u548c\u5728\u7ebf\u6821\u51c6\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u60ef\u6027\u6d4b\u91cf\u5355\u5143\u548c\u8f66\u8f6e\u7f16\u7801\u5668\u65b9\u6cd5\u9700\u8981\u6821\u51c6\uff0c\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u96f7\u8fbeSLAM\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4ee5\u673a\u5668\u4eba\u4e3a\u4e2d\u5fc3\u7684\u96f7\u8fbeSLAM\u65b9\u6cd5\uff0c\u7ed3\u5408\u7279\u5f81\u4f4d\u7f6e\u548c\u591a\u666e\u52d2\u901f\u5ea6\uff0c\u652f\u6301\u591a\u96f7\u8fbe\u548c\u4fe1\u606f\u7279\u5f81\u4fee\u526a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u7cbe\u5ea6\u7684\u5b9a\u4f4d\u80fd\u529b\u548c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u7a33\u5065\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6ee1\u8db3\u4e86\u81ea\u52a8\u505c\u8f66\u5bf9\u9ad8\u7cbe\u5ea6\u548c\u7a33\u5065\u6027\u7684\u9700\u6c42\u3002"}}
{"id": "2509.07415", "pdf": "https://arxiv.org/pdf/2509.07415", "abs": "https://arxiv.org/abs/2509.07415", "authors": ["Arslan Majal", "Aamir Hussain Chughtai", "Muhammad Tahir"], "title": "EMORF-II: Adaptive EM-based Outlier-Robust Filtering with Correlated Measurement Noise", "categories": ["cs.LG", "eess.SP"], "comment": "6 pages, 4 figures, To appear in MLSP 2025 proceedings", "summary": "We present a learning-based outlier-robust filter for a general setup where\nthe measurement noise can be correlated. Since it is an enhanced version of\nEM-based outlier robust filter (EMORF), we call it as EMORF-II. As it is\nequipped with an additional powerful feature to learn the outlier\ncharacteristics during inference along with outlier-detection, EMORF-II has\nimproved outlier-mitigation capability. Numerical experiments confirm\nperformance gains as compared to the state-of-the-art methods in terms of\naccuracy with an increased computational overhead. However, thankfully the\ncomputational complexity order remains at par with other practical methods\nmaking it a useful choice for diverse applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u578b\u79bb\u7fa4\u70b9\u9c81\u68d2\u6ee4\u6ce2\u5668EMORF-II\uff0c\u5177\u5907\u66f4\u5f3a\u7684\u79bb\u7fa4\u70b9\u68c0\u6d4b\u4e0e\u7f13\u89e3\u80fd\u529b\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4f4e\u4f46\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u6d4b\u91cf\u566a\u58f0\u53ef\u80fd\u76f8\u5173\u7684\u573a\u666f\uff0c\u63d0\u5347\u73b0\u6709EMORF\u7b97\u6cd5\u7684\u79bb\u7fa4\u70b9\u9c81\u68d2\u6027\u3002", "method": "\u7ed3\u5408\u5b66\u4e60\u673a\u5236\u4e0e\u79bb\u7fa4\u70b9\u68c0\u6d4b\uff0c\u52a8\u6001\u5b66\u4e60\u79bb\u7fa4\u70b9\u7279\u5f81\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u7cbe\u5ea6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u63a7\u3002", "conclusion": "EMORF-II\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u7684\u9ad8\u6548\u79bb\u7fa4\u70b9\u9c81\u68d2\u6ee4\u6ce2\u5668\u3002"}}
{"id": "2509.07707", "pdf": "https://arxiv.org/pdf/2509.07707", "abs": "https://arxiv.org/abs/2509.07707", "authors": ["Muzaffar Habib", "Adnan Maqsood", "Adnan Fayyaz ud Din"], "title": "Fault Tolerant Control of a Quadcopter using Reinforcement Learning", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "e-ISSN: 1946-3901, ISSN: 1946-3855,\n  https://www.sae.org/publications/technical-papers/content/01-18-01-0006/", "summary": "This study presents a novel reinforcement learning (RL)-based control\nframework aimed at enhancing the safety and robustness of the quadcopter, with\na specific focus on resilience to in-flight one propeller failure. Addressing\nthe critical need of a robust control strategy for maintaining a desired\naltitude for the quadcopter to safe the hardware and the payload in physical\napplications. The proposed framework investigates two RL methodologies Dynamic\nProgramming (DP) and Deep Deterministic Policy Gradient (DDPG), to overcome the\nchallenges posed by the rotor failure mechanism of the quadcopter. DP, a\nmodel-based approach, is leveraged for its convergence guarantees, despite high\ncomputational demands, whereas DDPG, a model-free technique, facilitates rapid\ncomputation but with constraints on solution duration. The research challenge\narises from training RL algorithms on large dimensions and action domains. With\nmodifications to the existing DP and DDPG algorithms, the controllers were\ntrained not only to cater for large continuous state and action domain and also\nachieve a desired state after an inflight propeller failure. To verify the\nrobustness of the proposed control framework, extensive simulations were\nconducted in a MATLAB environment across various initial conditions and\nunderscoring its viability for mission-critical quadcopter applications. A\ncomparative analysis was performed between both RL algorithms and their\npotential for applications in faulty aerial systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u578b\u63a7\u5236\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u56db\u65cb\u7ffc\u98de\u884c\u5668\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u9488\u5bf9\u98de\u884c\u4e2d\u5355\u87ba\u65cb\u6868\u6545\u969c\u7684\u6062\u590d\u80fd\u529b\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u9c81\u68d2\u7684\u63a7\u5236\u7b56\u7565\u6765\u786e\u4fdd\u56db\u65cb\u7ffc\u98de\u884c\u5668\u5728\u7269\u7406\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u548c\u8f7d\u8377\u4fdd\u62a4\uff0c\u5c24\u5176\u662f\u5728\u98de\u884c\u4e2d\u53d1\u751f\u87ba\u65cb\u6868\u6545\u969c\u65f6\u3002", "method": "\u7814\u7a76\u4e86\u52a8\u6001\u89c4\u5212\uff08DP\uff09\u548c\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u4e24\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4fee\u6539\u7b97\u6cd5\u6765\u9002\u5e94\u5927\u7ef4\u5ea6\u548c\u52a8\u4f5c\u57df\u7684\u8bad\u7ec3\u9700\u6c42\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5e76\u5bf9\u6bd4\u4e86DP\u548cDDPG\u5728\u6545\u969c\u98de\u884c\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a7\u5236\u6846\u67b6\u9002\u7528\u4e8e\u5173\u952e\u4efb\u52a1\u7684\u56db\u65cb\u7ffc\u98de\u884c\u5668\u5e94\u7528\uff0c\u5c55\u793a\u4e86DP\u548cDDPG\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.07773", "pdf": "https://arxiv.org/pdf/2509.07773", "abs": "https://arxiv.org/abs/2509.07773", "authors": ["Sebastian Macaluso", "Giovanni Geraci", "El\u00edas F. Combarro", "Sergi Abadal", "Ioannis Arapakis", "Sofia Vallecorsa", "Eduard Alarc\u00f3n"], "title": "Quantum Computing for Large-scale Network Optimization: Opportunities and Challenges", "categories": ["cs.NI", "cs.IT", "cs.LG", "eess.SP", "math.IT", "quant-ph"], "comment": "7 pages, 4 figures", "summary": "The complexity of large-scale 6G-and-beyond networks demands innovative\napproaches for multi-objective optimization over vast search spaces, a task\noften intractable. Quantum computing (QC) emerges as a promising technology for\nefficient large-scale optimization. We present our vision of leveraging QC to\ntackle key classes of problems in future mobile networks. By analyzing and\nidentifying common features, particularly their graph-centric representation,\nwe propose a unified strategy involving QC algorithms. Specifically, we outline\na methodology for optimization using quantum annealing as well as quantum\nreinforcement learning. Additionally, we discuss the main challenges that QC\nalgorithms and hardware must overcome to effectively optimize future networks.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\uff08QC\uff09\u89e3\u51b3\u672a\u67656G\u53ca\u4ee5\u4e0a\u7f51\u7edc\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u9000\u706b\u548c\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u7b56\u7565\u3002", "motivation": "\u5927\u89c4\u6a216G\u53ca\u4ee5\u4e0a\u7f51\u7edc\u7684\u590d\u6742\u6027\u9700\u8981\u521b\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5e9e\u5927\u641c\u7d22\u7a7a\u95f4\u4e2d\u5f80\u5f80\u96be\u4ee5\u5904\u7406\uff0c\u91cf\u5b50\u8ba1\u7b97\u88ab\u89c6\u4e3a\u6f5c\u5728\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5206\u6790\u95ee\u9898\u5171\u6027\uff08\u5c24\u5176\u662f\u56fe\u4e2d\u5fc3\u8868\u793a\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u9000\u706b\u548c\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u4f18\u5316\u7b56\u7565\u3002", "result": "\u8bba\u6587\u6982\u8ff0\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u672a\u6765\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5173\u6280\u672f\u6311\u6218\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u6709\u671b\u89e3\u51b3\u672a\u6765\u7f51\u7edc\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u4ecd\u9700\u514b\u670d\u7b97\u6cd5\u548c\u786c\u4ef6\u65b9\u9762\u7684\u6311\u6218\u3002"}}
{"id": "2509.07812", "pdf": "https://arxiv.org/pdf/2509.07812", "abs": "https://arxiv.org/abs/2509.07812", "authors": ["Kristan Hilby", "Ian Hunter"], "title": "Unlocking Stopped-Rotor Flight: Development and Validation of SPERO, a Novel UAV Platform", "categories": ["cs.RO"], "comment": "15 pages, 11 figures, 5 tables", "summary": "Stop-rotor aircraft have long been proposed as the ideal vertical takeoff and\nlanding (VTOL) aircraft for missions with equal time spent in both flight\nregimes, such as agricultural monitoring, search and rescue, and last-mile\ndelivery. Featuring a central lifting surface that rotates in VTOL to generate\nvertical thrust and locks in forward flight to generate passive lift, the\nstop-rotor offers the potential for high efficiency across both modes. However,\npractical implementation has remained infeasible due to aerodynamic and\nstability conflicts between flight modes. In this work, we present SPERO\n(Stopped-Penta Rotor), a stop-rotor uncrewed aerial vehicle (UAV) featuring a\nflipping and latching wing, an active center of pressure mechanism, thrust\nvectored counterbalances, a five-rotor architecture, and an eleven-state\nmachine flight controller coordinating geometric and controller\nreconfiguration. Furthermore, SPERO establishes a generalizable design and\ncontrol framework for stopped-rotor UAVs. Together, these innovations overcome\nlongstanding challenges in stop-rotor flight and enable the first stable,\nbidirectional transition between VTOL and forward flight.", "AI": {"tldr": "SPERO\u662f\u4e00\u79cd\u91c7\u7528\u7ffb\u8f6c\u9501\u5b9a\u7ffc\u548c\u4e94\u65cb\u7ffc\u7ed3\u6784\u7684\u65e0\u4eba\u673a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65cb\u505c\u98de\u884c\u5668\u5728\u5782\u76f4\u548c\u6c34\u5e73\u98de\u884c\u6a21\u5f0f\u95f4\u7684\u6c14\u52a8\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53cc\u5411\u7a33\u5b9a\u8f6c\u6362\u3002", "motivation": "\u7814\u7a76\u89e3\u51b3\u65cb\u505c\u98de\u884c\u5668\u5728\u5782\u76f4\u8d77\u964d\u548c\u6c34\u5e73\u98de\u884c\u6a21\u5f0f\u95f4\u7684\u6c14\u52a8\u51b2\u7a81\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4ee5\u9002\u7528\u4e8e\u519c\u4e1a\u76d1\u6d4b\u3001\u641c\u6551\u7b49\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u7ffb\u8f6c\u9501\u5b9a\u7ffc\u3001\u4e3b\u52a8\u538b\u529b\u4e2d\u5fc3\u673a\u5236\u3001\u63a8\u529b\u77e2\u91cf\u5e73\u8861\u3001\u4e94\u65cb\u7ffc\u7ed3\u6784\u548c11\u72b6\u6001\u98de\u884c\u63a7\u5236\u5668\u7b49\u521b\u65b0\u8bbe\u8ba1\u3002", "result": "\u9996\u6b21\u5b9e\u73b0\u4e86\u65cb\u505c\u98de\u884c\u5668\u5728\u5782\u76f4\u8d77\u964d\u548c\u6c34\u5e73\u98de\u884c\u95f4\u7684\u53cc\u5411\u7a33\u5b9a\u8f6c\u6362\uff0c\u5e76\u5efa\u7acb\u4e86\u901a\u7528\u8bbe\u8ba1\u548c\u63a7\u5236\u6846\u67b6\u3002", "conclusion": "SPERO\u901a\u8fc7\u6280\u672f\u521b\u65b0\u89e3\u51b3\u4e86\u65cb\u505c\u98de\u884c\u5668\u7684\u957f\u671f\u6311\u6218\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.07832", "pdf": "https://arxiv.org/pdf/2509.07832", "abs": "https://arxiv.org/abs/2509.07832", "authors": ["Jieao Zhu", "Linglong Dai"], "title": "RAQ-MIMO: MIMO for Multi-Band Rydberg Atomic Quantum Receiver", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": "Submitted to IEEE JSAC. In this paper, we first point out the\n  intermediate frequency interference (IFI) problem of multi-band Rydberg\n  atomic quantum receivers (RAQRs). Simulation codes will be provided at\n  https://oa.ee.tsinghua.edu.cn/dailinglong/publications/publications.html", "summary": "Rydberg atomic quantum receivers (RAQRs) are capable of receiving multi-band\nradio-frequency (RF) signals simultaneously, which are expected to break Chu's\nlimit for classical electronic antennas. However, signals from different users\nwill interfere with each other in the optical intermediate frequency (IF)\ndomain of the multi-band quantum receiver, which is termed the IF interference\n(IFI) problem. To address this problem, in this paper, we propose a multi-input\nmulti-output (MIMO) architecture for Rydberg atomic quantum receiver (RAQ-MIMO)\nby exploiting the additional spatial diversity of MIMO receivers. Specifically,\nby applying the dynamic signal model of RAQRs, we clarify the physical\nrelationship between the quantum local oscillator (LO) configurations and the\nmulti-band gains with the concept of quantum transconductance. Then, with the\nquantum transconductance-based signal model, we formulate the spectral\nefficiency (SE) maximization problem and further propose the quantum weighted\nminimum mean square error (qWMMSE) algorithm, which jointly optimizes the\nquantum LO configurations and the classical precoder/combiner matrices.\nFurthermore, we test the qWMMSE algorithm within the standard space division\nmultiple access (SDMA) scheme and the frequency division multiple access (FDMA)\nscheme. Simulation results demonstrate that the qWMMSE optimization framework\ncan significantly improve the SE of RAQ-MIMO systems for both multiple access\nschemes, and that RAQ-MIMO systems can outperform classical electronic\nreceiver-based multi-user MIMO systems by eliminating the mutual coupling\neffect between classical antennas.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRydberg\u539f\u5b50\u91cf\u5b50\u63a5\u6536\u5668\uff08RAQ-MIMO\uff09\u7684\u591a\u8f93\u5165\u591a\u8f93\u51fa\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u591a\u9891\u6bb5\u91cf\u5b50\u63a5\u6536\u5668\u4e2d\u7684\u4e2d\u9891\u5e72\u6270\u95ee\u9898\uff0c\u5e76\u4f18\u5316\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u591a\u9891\u6bb5\u91cf\u5b50\u63a5\u6536\u5668\u4e2d\u4e0d\u540c\u7528\u6237\u4fe1\u53f7\u7684\u5149\u5b66\u4e2d\u9891\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u5347\u901a\u4fe1\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86RAQ-MIMO\u67b6\u6784\uff0c\u5229\u7528\u91cf\u5b50\u8de8\u5bfc\u6a21\u578b\u548cqWMMSE\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u91cf\u5b50\u672c\u632f\u914d\u7f6e\u548c\u7ecf\u5178\u9884\u7f16\u7801/\u5408\u5e76\u77e9\u9635\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0cqWMMSE\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86RAQ-MIMO\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\uff0c\u4e14\u4f18\u4e8e\u7ecf\u5178\u7535\u5b50\u63a5\u6536\u5668\u591a\u7528\u6237MIMO\u7cfb\u7edf\u3002", "conclusion": "RAQ-MIMO\u7cfb\u7edf\u901a\u8fc7\u6d88\u9664\u7ecf\u5178\u5929\u7ebf\u95f4\u7684\u4e92\u8026\u6548\u5e94\uff0c\u4e3a\u591a\u9891\u6bb5\u91cf\u5b50\u901a\u4fe1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07916", "pdf": "https://arxiv.org/pdf/2509.07916", "abs": "https://arxiv.org/abs/2509.07916", "authors": ["Jianshu Zhou", "Wei Chen", "Junda Huang", "Boyuan Liang", "Yunhui Liu", "Masayoshi Tomizuka"], "title": "Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability", "categories": ["cs.RO"], "comment": null, "summary": "Robotic systems operating in unstructured environments require the ability to\nswitch between compliant and rigid states to perform diverse tasks such as\nadaptive grasping, high-force manipulation, shape holding, and navigation in\nconstrained spaces, among others. However, many existing variable stiffness\nsolutions rely on complex actuation schemes, continuous input power, or\nmonolithic designs, limiting their modularity and scalability. This paper\npresents the Programmable Locking Cell (PLC)-a modular, tendon-driven unit that\nachieves discrete stiffness modulation through mechanically interlocked joints\nactuated by cable tension. Each unit transitions between compliant and firm\nstates via structural engagement, and the assembled system exhibits high\nstiffness variation-up to 950% per unit-without susceptibility to damage under\nhigh payload in the firm state. Multiple PLC units can be assembled into\nreconfigurable robotic structures with spatially programmable stiffness. We\nvalidate the design through two functional prototypes: (1) a variable-stiffness\ngripper capable of adaptive grasping, firm holding, and in-hand manipulation;\nand (2) a pipe-traversing robot composed of serial PLC units that achieves\nshape adaptability and stiffness control in confined environments. These\nresults demonstrate the PLC as a scalable, structure-centric mechanism for\nprogrammable stiffness and motion, enabling robotic systems with reconfigurable\nmorphology and task-adaptive interaction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u3001\u808c\u8171\u9a71\u52a8\u7684\u53ef\u7f16\u7a0b\u9501\u5b9a\u5355\u5143(PLC)\uff0c\u901a\u8fc7\u673a\u68b0\u4e92\u9501\u5173\u8282\u5b9e\u73b0\u79bb\u6563\u521a\u5ea6\u8c03\u8282\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u673a\u5668\u4eba\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u53ef\u53d8\u521a\u5ea6\u65b9\u6848\u7684\u590d\u6742\u9a71\u52a8\u3001\u6301\u7eed\u529f\u8017\u548c\u6a21\u5757\u5316\u9650\u5236\u95ee\u9898\u3002", "method": "\u4f7f\u7528PLC\u5355\u5143\uff0c\u901a\u8fc7\u7535\u7f06\u5f20\u529b\u9a71\u52a8\u673a\u68b0\u4e92\u9501\u5173\u8282\uff0c\u5b9e\u73b0\u521a\u5ea6\u548c\u72b6\u6001\u5207\u6362\u3002", "result": "PLC\u5355\u5143\u521a\u5ea6\u53d8\u5316\u9ad8\u8fbe950%\uff0c\u7ec4\u88c5\u7cfb\u7edf\u53ef\u91cd\u6784\u4e14\u9ad8\u8d1f\u8f7d\u4e0b\u4e0d\u6613\u635f\u574f\u3002\u901a\u8fc7\u6293\u53d6\u5668\u548c\u7ba1\u9053\u673a\u5668\u4eba\u9a8c\u8bc1\u8bbe\u8ba1\u3002", "conclusion": "PLC\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u7ed3\u6784\u4e2d\u5fc3\u673a\u5236\uff0c\u9002\u7528\u4e8e\u91cd\u6784\u5f62\u6001\u548c\u4efb\u52a1\u81ea\u9002\u5e94\u4ea4\u4e92\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002"}}
{"id": "2509.07840", "pdf": "https://arxiv.org/pdf/2509.07840", "abs": "https://arxiv.org/abs/2509.07840", "authors": ["Patrick Kreidl"], "title": "Sensor Management in Multi-Stage Stochastic Control Problems with Imperfect State Information", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": "34 pages, 9 figures, unpublished/unreviewed manuscript circa 2002", "summary": "Technological advancements in miniaturization and wireless communications are\nyielding more affordable and versatile sensors and, in turn, more applications\nin which a network of sensors can be actively managed to best support overall\ndecision-making objectives. We propose modeling the opportunity for sensor\nmanagement within multi-stage stochastic control problems with imperfect state\ninformation. Such formulations inherently assume the state of the modeled\nenvironment cannot be accessed directly but instead the controller can observe\nonly noisy measurements of the state and, therefore, at each decision stage\nsome form of state estimation is required before a control is actuated. The\nnotion of sensor management arises when the modeled controls not only affect\nthe subsequent evolution of the state but can also affect the nature of future\nmeasurements and, hence, the quality of state estimates that drive future\ncontrol decisions. In principle, the optimal strategy for any appropriately\nmodeled multi-stage stochastic control problem with imperfect state information\n(with or without opportunity for sensor management) is the solution to a\ndynamic program; in practice, the computational requirements are typically\nprohibitive yet dynamic programming methods are still useful to guide the\ndevelopment of effective suboptimal strategies. In this spirit, we model the\nopportunity for sensor management within small-scale examples of two\nwell-studied dynamic programming formulations, namely (1) the\nfinite-state/finite-action Partially-Observable Markov Decision Process\n(PO-MDP) and (2) the Linear-Quadratic-Gaussian Regulator (LQGR). These examples\nadmit solvable dynamic programs and confirm how the interplay between sensing\nand acting is a natural by-product of a dynamic programming solution.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u5584\u7684\u591a\u9636\u6bb5\u968f\u673a\u63a7\u5236\u95ee\u9898\u4e2d\u5efa\u6a21\u4f20\u611f\u5668\u7ba1\u7406\u673a\u4f1a\uff0c\u5229\u7528\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u6307\u5bfc\u6b21\u4f18\u7b56\u7565\u7684\u5f00\u53d1\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u5c0f\u89c4\u6a21\u52a8\u6001\u89c4\u5212\u793a\u4f8b\u9a8c\u8bc1\u4e86\u611f\u77e5\u4e0e\u884c\u52a8\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u6280\u672f\u7684\u8fdb\u6b65\u4f7f\u4f20\u611f\u5668\u7f51\u7edc\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e94\u7528\u66f4\u52a0\u5e7f\u6cdb\uff0c\u4f46\u5982\u4f55\u4f18\u5316\u4f20\u611f\u5668\u7ba1\u7406\u4ee5\u63d0\u9ad8\u72b6\u6001\u4f30\u8ba1\u548c\u63a7\u5236\u51b3\u7b56\u7684\u8d28\u91cf\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u6709\u9650\u72b6\u6001/\u6709\u9650\u52a8\u4f5c\u7684\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08PO-MDP\uff09\u548c\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u8c03\u8282\u5668\uff08LQGR\uff09\u4e24\u79cd\u52a8\u6001\u89c4\u5212\u6a21\u578b\u6765\u7814\u7a76\u4f20\u611f\u5668\u7ba1\u7406\u7684\u673a\u4f1a\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u52a8\u6001\u89c4\u5212\u89e3\u51b3\u65b9\u6848\u81ea\u7136\u4f53\u73b0\u4e86\u611f\u77e5\u4e0e\u884c\u52a8\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4e3a\u5f00\u53d1\u6709\u6548\u7684\u6b21\u4f18\u7b56\u7565\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "\u4f20\u611f\u5668\u7ba1\u7406\u5728\u591a\u9636\u6bb5\u968f\u673a\u63a7\u5236\u95ee\u9898\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u867d\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4f46\u4ecd\u80fd\u901a\u8fc7\u5c0f\u89c4\u6a21\u793a\u4f8b\u63ed\u793a\u5176\u6f5c\u529b\u3002"}}
{"id": "2509.07953", "pdf": "https://arxiv.org/pdf/2509.07953", "abs": "https://arxiv.org/abs/2509.07953", "authors": ["Zheyuan Hu", "Robyn Wu", "Naveen Enock", "Jasmine Li", "Riya Kadakia", "Zackory Erickson", "Aviral Kumar"], "title": "RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Modern paradigms for robot imitation train expressive policy architectures on\nlarge amounts of human demonstration data. Yet performance on contact-rich,\ndeformable-object, and long-horizon tasks plateau far below perfect execution,\neven with thousands of expert demonstrations. This is due to the inefficiency\nof existing ``expert'' data collection procedures based on human teleoperation.\nTo address this issue, we introduce RaC, a new phase of training on\nhuman-in-the-loop rollouts after imitation learning pre-training. In RaC, we\nfine-tune a robotic policy on human intervention trajectories that illustrate\nrecovery and correction behaviors. Specifically, during a policy rollout, human\noperators intervene when failure appears imminent, first rewinding the robot\nback to a familiar, in-distribution state and then providing a corrective\nsegment that completes the current sub-task. Training on this data composition\nexpands the robotic skill repertoire to include retry and adaptation behaviors,\nwhich we show are crucial for boosting both efficiency and robustness on\nlong-horizon tasks. Across three real-world bimanual control tasks: shirt\nhanging, airtight container lid sealing, takeout box packing, and a simulated\nassembly task, RaC outperforms the prior state-of-the-art using 10$\\times$ less\ndata collection time and samples. We also show that RaC enables test-time\nscaling: the performance of the trained RaC policy scales linearly in the\nnumber of recovery maneuvers it exhibits. Videos of the learned policy are\navailable at https://rac-scaling-robot.github.io/.", "AI": {"tldr": "RaC\u901a\u8fc7\u5728\u4eba\u673a\u534f\u4f5c\u4e2d\u6536\u96c6\u7ea0\u6b63\u884c\u4e3a\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u4eff\u5b66\u4e60\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u51cf\u5c11\u4e86\u6570\u636e\u6536\u96c6\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u6e90\u4e8e\u4eba\u7c7b\u8fdc\u7a0b\u64cd\u4f5c\u6536\u96c6\u7684\u4e13\u5bb6\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faRaC\u65b9\u6cd5\uff0c\u5728\u6a21\u4eff\u5b66\u4e60\u9884\u8bad\u7ec3\u540e\uff0c\u901a\u8fc7\u4eba\u7c7b\u5e72\u9884\u8f68\u8ff9\u8fdb\u884c\u5fae\u8c03\uff0c\u5b66\u4e60\u7ea0\u6b63\u548c\u6062\u590d\u884c\u4e3a\u3002", "result": "RaC\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6570\u636e\u6536\u96c6\u6548\u7387\u63d0\u534710\u500d\uff0c\u4e14\u6027\u80fd\u968f\u7ea0\u6b63\u884c\u4e3a\u6570\u91cf\u7ebf\u6027\u589e\u957f\u3002", "conclusion": "RaC\u4e0d\u4ec5\u63d0\u5347\u4e86\u4efb\u52a1\u8868\u73b0\uff0c\u8fd8\u5c55\u793a\u4e86\u6d4b\u8bd5\u65f6\u6027\u80fd\u968f\u7ea0\u6b63\u884c\u4e3a\u589e\u52a0\u7684\u7ebf\u6027\u6269\u5c55\u6027\u3002"}}
{"id": "2509.07957", "pdf": "https://arxiv.org/pdf/2509.07957", "abs": "https://arxiv.org/abs/2509.07957", "authors": ["Shunlei Li", "Longsen Gao", "Jiuwen Cao", "Yingbai Hu"], "title": "Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation", "categories": ["cs.RO"], "comment": "This paper is submitted to IEEE IROS 2025 Workshop AIR4S", "summary": "Acquiring dexterous robotic skills from human video demonstrations remains a\nsignificant challenge, largely due to conventional reliance on low-level\ntrajectory replication, which often fails to generalize across varying objects,\nspatial layouts, and manipulator configurations. To address this limitation, we\nintroduce Graph-Fused Vision-Language-Action (GF-VLA), a unified framework that\nenables dual-arm robotic systems to perform task-level reasoning and execution\ndirectly from RGB-D human demonstrations. GF-VLA employs an\ninformation-theoretic approach to extract task-relevant cues, selectively\nhighlighting critical hand-object and object-object interactions. These cues\nare structured into temporally ordered scene graphs, which are subsequently\nintegrated with a language-conditioned transformer to produce hierarchical\nbehavior trees and interpretable Cartesian motion primitives. To enhance\nefficiency in bimanual execution, we propose a cross-arm allocation strategy\nthat autonomously determines gripper assignment without requiring explicit\ngeometric modeling. We validate GF-VLA on four dual-arm block assembly\nbenchmarks involving symbolic structure construction and spatial\ngeneralization. Empirical results demonstrate that the proposed representation\nachieves over 95% graph accuracy and 93% subtask segmentation, enabling the\nlanguage-action planner to generate robust, interpretable task policies. When\ndeployed on a dual-arm robot, these policies attain 94% grasp reliability, 89%\nplacement accuracy, and 90% overall task success across stacking,\nletter-formation, and geometric reconfiguration tasks, evidencing strong\ngeneralization and robustness under diverse spatial and semantic variations.", "AI": {"tldr": "GF-VLA\u6846\u67b6\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u878d\u5408\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u4ece\u4eba\u7c7b\u89c6\u9891\u4e2d\u5b66\u4e60\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u53cc\u81c2\u4efb\u52a1\u6267\u884c\u3002", "motivation": "\u4f20\u7edf\u4f4e\u5c42\u7ea7\u8f68\u8ff9\u590d\u5236\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0cGF-VLA\u65e8\u5728\u901a\u8fc7\u4efb\u52a1\u7ea7\u63a8\u7406\u76f4\u63a5\u5904\u7406\u4eba\u7c7b\u6f14\u793a\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u63d0\u53d6\u5173\u952e\u4ea4\u4e92\uff0c\u6784\u5efa\u65f6\u6001\u573a\u666f\u56fe\uff0c\u7ed3\u5408\u8bed\u8a00\u6761\u4ef6\u53d8\u6362\u5668\u751f\u6210\u884c\u4e3a\u6811\u548c\u8fd0\u52a8\u57fa\u5143\u3002", "result": "\u5728\u53cc\u81c2\u7ec4\u88c5\u4efb\u52a1\u4e2d\uff0cGF-VLA\u8fbe\u523095%\u7684\u56fe\u51c6\u786e\u7387\uff0c93%\u7684\u5b50\u4efb\u52a1\u5206\u5272\u7387\uff0c\u5e76\u5c55\u793a\u4e86\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "GF-VLA\u80fd\u6709\u6548\u6cdb\u5316\u5e76\u63d0\u5347\u53cc\u81c2\u673a\u5668\u4eba\u7684\u4efb\u52a1\u6267\u884c\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u7a7a\u95f4\u548c\u8bed\u4e49\u53d8\u5316\u3002"}}
{"id": "2509.07962", "pdf": "https://arxiv.org/pdf/2509.07962", "abs": "https://arxiv.org/abs/2509.07962", "authors": ["Zongzheng Zhang", "Haobo Xu", "Zhuo Yang", "Chenghao Yue", "Zehao Lin", "Huan-ang Gao", "Ziwei Wang", "Hao Zhao"], "title": "TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models", "categories": ["cs.RO"], "comment": "Accepted to CoRL 2025, project page:\n  \\url{https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/}", "summary": "Many robotic manipulation tasks require sensing and responding to force\nsignals such as torque to assess whether the task has been successfully\ncompleted and to enable closed-loop control. However, current\nVision-Language-Action (VLA) models lack the ability to integrate such subtle\nphysical feedback. In this work, we explore Torque-aware VLA models, aiming to\nbridge this gap by systematically studying the design space for incorporating\ntorque signals into existing VLA architectures. We identify and evaluate\nseveral strategies, leading to three key findings. First, introducing torque\nadapters into the decoder consistently outperforms inserting them into the\nencoder.Third, inspired by joint prediction and planning paradigms in\nautonomous driving, we propose predicting torque as an auxiliary output, which\nfurther improves performance. This strategy encourages the model to build a\nphysically grounded internal representation of interaction dynamics. Extensive\nquantitative and qualitative experiments across contact-rich manipulation\nbenchmarks validate our findings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u626d\u77e9\u611f\u77e5\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u7814\u7a76\u4e86\u5c06\u626d\u77e9\u4fe1\u53f7\u878d\u5165\u73b0\u6709\u67b6\u6784\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u7269\u7406\u4ea4\u4e92\u8868\u793a\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u7269\u7406\u529b\u53cd\u9988\u4fe1\u53f7\uff08\u5982\u626d\u77e9\uff09\uff0c\u9650\u5236\u4e86\u5176\u5728\u673a\u5668\u4eba\u64cd\u63a7\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u4e86\u626d\u77e9\u4fe1\u53f7\u7684\u878d\u5165\u7b56\u7565\uff0c\u5305\u62ec\u5728\u89e3\u7801\u5668\u4e2d\u5f15\u5165\u626d\u77e9\u9002\u914d\u5668\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u8f85\u52a9\u8f93\u51fa\u6765\u9884\u6d4b\u626d\u77e9\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u89e3\u7801\u5668\u5f15\u5165\u626d\u77e9\u9002\u914d\u5668\u4f18\u4e8e\u7f16\u7801\u5668\uff0c\u4e14\u9884\u6d4b\u626d\u77e9\u7684\u8f85\u52a9\u8f93\u51fa\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u626d\u77e9\u611f\u77e5\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u7269\u7406\u4ea4\u4e92\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u4e3a\u673a\u5668\u4eba\u64cd\u63a7\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u529b\u53cd\u9988\u96c6\u6210\u65b9\u6cd5\u3002"}}
{"id": "2509.07234", "pdf": "https://arxiv.org/pdf/2509.07234", "abs": "https://arxiv.org/abs/2509.07234", "authors": ["Yanlin Zhou", "Manshi Limbu", "Xuesu Xiao"], "title": "Efficient Multi-Agent Coordination via Dynamic Joint-State Graph Construction", "categories": ["cs.MA", "cs.RO"], "comment": null, "summary": "Multi-agent pathfinding (MAPF) traditionally focuses on collision avoidance,\nbut many real-world applications require active coordination between agents to\nimprove team performance. This paper introduces Team Coordination on Graphs\nwith Risky Edges (TCGRE), where agents collaborate to reduce traversal costs on\nhigh-risk edges via support from teammates. We reformulate TCGRE as a 3D\nmatching problem-mapping robot pairs, support pairs, and time steps-and\nrigorously prove its NP-hardness via reduction from Minimum 3D Matching. To\naddress this complexity, (in the conference version) we proposed efficient\ndecomposition methods, reducing the problem to tractable subproblems:\nJoint-State Graph (JSG): Encodes coordination as a single-agent shortest-path\nproblem. Coordination-Exhaustive Search (CES): Optimizes support assignments\nvia exhaustive pairing. Receding-Horizon Optimistic Cooperative A* (RHOCA*):\nBalances optimality and scalability via horizon-limited planning. Further in\nthis extension, we introduce a dynamic graph construction method\n(Dynamic-HJSG), leveraging agent homogeneity to prune redundant states and\nreduce computational overhead by constructing the joint-state graph\ndynamically. Theoretical analysis shows Dynamic-HJSG preserves optimality while\nlowering complexity from exponential to polynomial in key cases. Empirical\nresults validate scalability for large teams and graphs, with HJSG\noutperforming baselines greatly in runtime in different sizes and types of\ngraphs. This work bridges combinatorial optimization and multi-agent planning,\noffering a principled framework for collaborative pathfinding with provable\nguarantees, and the key idea of the solution can be widely extended to many\nother collaborative optimization problems, such as MAPF.", "AI": {"tldr": "TCGRE\u5c06\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u4e3b\u52a8\u534f\u4f5c\u95ee\u9898\u8f6c\u5316\u4e3a3D\u5339\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u5206\u89e3\u65b9\u6cd5\uff08JSG\u3001CES\u3001RHOCA*\uff09\u548c\u52a8\u6001\u56fe\u6784\u5efa\uff08Dynamic-HJSG\uff09\uff0c\u5728\u4fdd\u8bc1\u6700\u4f18\u6027\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edfMAPF\u4ec5\u5173\u6ce8\u907f\u78b0\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u667a\u80fd\u4f53\u4e3b\u52a8\u534f\u4f5c\u4ee5\u63d0\u5347\u56e2\u961f\u6027\u80fd\u3002", "method": "1. \u5c06TCGRE\u5efa\u6a21\u4e3a3D\u5339\u914d\u95ee\u9898\uff1b2. \u63d0\u51faJSG\u3001CES\u3001RHOCA*\u4e09\u79cd\u5206\u89e3\u65b9\u6cd5\uff1b3. \u6269\u5c55\u7248\u5f15\u5165\u52a8\u6001\u56fe\u6784\u5efa\uff08Dynamic-HJSG\uff09\u3002", "result": "Dynamic-HJSG\u5728\u5173\u952e\u60c5\u51b5\u4e0b\u5c06\u590d\u6742\u5ea6\u4ece\u6307\u6570\u964d\u81f3\u591a\u9879\u5f0f\uff0c\u5b9e\u8bc1\u663e\u793a\u5176\u5728\u5927\u89c4\u6a21\u56e2\u961f\u548c\u56fe\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TCGRE\u4e3a\u534f\u4f5c\u8def\u5f84\u89c4\u5212\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5176\u601d\u60f3\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u534f\u4f5c\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2509.07411", "pdf": "https://arxiv.org/pdf/2509.07411", "abs": "https://arxiv.org/abs/2509.07411", "authors": ["Zhen Tian", "Zhihao Lin"], "title": "Adaptive Evolutionary Framework for Safe, Efficient, and Cooperative Autonomous Vehicle Interactions", "categories": ["cs.MA", "cs.RO"], "comment": null, "summary": "Modern transportation systems face significant challenges in ensuring road\nsafety, given serious injuries caused by road accidents. The rapid growth of\nautonomous vehicles (AVs) has prompted new traffic designs that aim to optimize\ninteractions among AVs. However, effective interactions between AVs remains\nchallenging due to the absence of centralized control. Besides, there is a need\nfor balancing multiple factors, including passenger demands and overall traffic\nefficiency. Traditional rule-based, optimization-based, and game-theoretic\napproaches each have limitations in addressing these challenges. Rule-based\nmethods struggle with adaptability and generalization in complex scenarios,\nwhile optimization-based methods often require high computational resources.\nGame-theoretic approaches, such as Stackelberg and Nash games, suffer from\nlimited adaptability and potential inefficiencies in cooperative settings. This\npaper proposes an Evolutionary Game Theory (EGT)-based framework for AV\ninteractions that overcomes these limitations by utilizing a decentralized and\nadaptive strategy evolution mechanism. A causal evaluation module (CEGT) is\nintroduced to optimize the evolutionary rate, balancing mutation and evolution\nby learning from historical interactions. Simulation results demonstrate the\nproposed CEGT outperforms EGT and popular benchmark games in terms of lower\ncollision rates, improved safety distances, higher speeds, and overall better\nperformance compared to Nash and Stackelberg games across diverse scenarios and\nparameter settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fdb\u5316\u535a\u5f08\u8bba\uff08EGT\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AV\uff09\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u56e0\u679c\u8bc4\u4f30\u6a21\u5757\uff08CEGT\uff09\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u4ea4\u901a\u7cfb\u7edf\u5728\u786e\u4fdd\u9053\u8def\u5b89\u5168\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u5feb\u901f\u666e\u53ca\u5e26\u6765\u7684\u4ea4\u4e92\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u9002\u5e94\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u534f\u4f5c\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eEGT\u7684\u5206\u6563\u5f0f\u81ea\u9002\u5e94\u7b56\u7565\u6f14\u5316\u6846\u67b6\uff0c\u5e76\u5f15\u5165CEGT\u6a21\u5757\u4f18\u5316\u6f14\u5316\u901f\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cCEGT\u5728\u78b0\u649e\u7387\u3001\u5b89\u5168\u8ddd\u79bb\u3001\u901f\u5ea6\u548c\u6574\u4f53\u6027\u80fd\u4e0a\u4f18\u4e8eEGT\u53ca\u5176\u4ed6\u57fa\u51c6\u535a\u5f08\u65b9\u6cd5\u3002", "conclusion": "EGT\u6846\u67b6\u7ed3\u5408CEGT\u6a21\u5757\u6709\u6548\u89e3\u51b3\u4e86AV\u4ea4\u4e92\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2509.07561", "pdf": "https://arxiv.org/pdf/2509.07561", "abs": "https://arxiv.org/abs/2509.07561", "authors": ["Raina Zakir", "Timoteo Carletti", "Marco Dorigo", "Andreagiovanni Reina"], "title": "Bio-inspired decision making in swarms under biases from stubborn robots, corrupted communication, and independent discovery", "categories": ["cs.MA", "cs.RO"], "comment": null, "summary": "Minimalistic robot swarms offer a scalable, robust, and cost-effective\napproach to performing complex tasks with the potential to transform\napplications in healthcare, disaster response, and environmental monitoring.\nHowever, coordinating such decentralised systems remains a fundamental\nchallenge, particularly when robots are constrained in communication,\ncomputation, and memory. In our study, individual robots frequently make errors\nwhen sensing the environment, yet the swarm can rapidly and reliably reach\nconsensus on the best among $n$ discrete options. We compare two canonical\nmechanisms of opinion dynamics -- direct-switch and cross-inhibition -- which\nare simple yet effective rules for collective information processing observed\nin biological systems across scales, from neural populations to insect\ncolonies. We generalise the existing mean-field models by considering asocial\nbiases influencing the opinion dynamics. While swarms using direct-switch\nreliably select the best option in absence of asocial dynamics, their\nperformance deteriorates once such biases are introduced, often resulting in\ndecision deadlocks. In contrast, bio-inspired cross-inhibition enables faster,\nmore cohesive, accurate, robust, and scalable decisions across a wide range of\nbiased conditions. Our findings provide theoretical and practical insights into\nthe coordination of minimal swarms and offer insights that extend to a broad\nclass of decentralised decision-making systems in biology and engineering.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u76f4\u63a5\u5207\u6362\u548c\u4ea4\u53c9\u6291\u5236\u4e24\u79cd\u610f\u89c1\u52a8\u6001\u673a\u5236\u5728\u5fae\u578b\u673a\u5668\u4eba\u7fa4\u4f53\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u4ea4\u53c9\u6291\u5236\u673a\u5236\u5728\u5b58\u5728\u504f\u89c1\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u534f\u8c03\u5fae\u578b\u673a\u5668\u4eba\u7fa4\u4f53\u5728\u901a\u4fe1\u3001\u8ba1\u7b97\u548c\u5185\u5b58\u53d7\u9650\u60c5\u51b5\u4e0b\u7684\u884c\u4e3a\u4ecd\u7136\u662f\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u4e2a\u4f53\u673a\u5668\u4eba\u611f\u77e5\u73af\u5883\u5b58\u5728\u8bef\u5dee\u65f6\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u76f4\u63a5\u5207\u6362\u548c\u4ea4\u53c9\u6291\u5236\u4e24\u79cd\u610f\u89c1\u52a8\u6001\u673a\u5236\uff0c\u5e76\u63a8\u5e7f\u4e86\u73b0\u6709\u7684\u5e73\u5747\u573a\u6a21\u578b\u4ee5\u8003\u8651\u504f\u89c1\u5bf9\u610f\u89c1\u52a8\u6001\u7684\u5f71\u54cd\u3002", "result": "\u4ea4\u53c9\u6291\u5236\u673a\u5236\u5728\u504f\u89c1\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u51b3\u7b56\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u3001\u66f4\u5177\u9c81\u68d2\u6027\u548c\u6269\u5c55\u6027\u3002", "conclusion": "\u4ea4\u53c9\u6291\u5236\u673a\u5236\u4e3a\u5fae\u578b\u673a\u5668\u4eba\u7fa4\u4f53\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u534f\u8c03\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5206\u6563\u51b3\u7b56\u7cfb\u7edf\u3002"}}
{"id": "2509.07873", "pdf": "https://arxiv.org/pdf/2509.07873", "abs": "https://arxiv.org/abs/2509.07873", "authors": ["Hieu Tran", "Go-Eum Cha", "Sooyeon Jeong"], "title": "A Robot That Listens: Enhancing Self-Disclosure and Engagement Through Sentiment-based Backchannels and Active Listening", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "As social robots get more deeply integrated intoour everyday lives, they will\nbe expected to engage in meaningful conversations and exhibit socio-emotionally\nintelligent listening behaviors when interacting with people. Active listening\nand backchanneling could be one way to enhance robots' communicative\ncapabilities and enhance their effectiveness in eliciting deeper\nself-disclosure, providing a sense of empathy,and forming positive rapport and\nrelationships with people.Thus, we developed an LLM-powered social robot that\ncan exhibit contextually appropriate sentiment-based backchannelingand active\nlistening behaviors (active listening+backchanneling) and compared its efficacy\nin eliciting people's self-disclosurein comparison to robots that do not\nexhibit any of these listening behaviors (control) and a robot that only\nexhibitsbackchanneling behavior (backchanneling-only). Through ourexperimental\nstudy with sixty-five participants, we found theparticipants who conversed with\nthe active listening robot per-ceived the interactions more positively, in\nwhich they exhibited the highest self-disclosures, and reported the strongest\nsenseof being listened to. The results of our study suggest that the\nimplementation of active listening behaviors in social robotshas the potential\nto improve human-robot communication andcould further contribute to the\nbuilding of deeper human-robot relationships and rapport.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u793e\u4ea4\u673a\u5668\u4eba\uff0c\u80fd\u591f\u901a\u8fc7\u60c5\u611f\u5316\u7684\u79ef\u6781\u503e\u542c\u548c\u53cd\u9988\u884c\u4e3a\uff08\u5982\u5e94\u548c\u58f0\uff09\u6765\u589e\u5f3a\u4eba\u673a\u4ea4\u6d41\u6548\u679c\uff0c\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u673a\u5668\u4eba\u80fd\u663e\u8457\u63d0\u5347\u7528\u6237\u7684\u81ea\u6211\u62ab\u9732\u548c\u5bf9\u4e92\u52a8\u7684\u79ef\u6781\u611f\u53d7\u3002", "motivation": "\u968f\u7740\u793e\u4ea4\u673a\u5668\u4eba\u66f4\u6df1\u5165\u5730\u878d\u5165\u65e5\u5e38\u751f\u6d3b\uff0c\u4eba\u4eec\u671f\u671b\u5b83\u4eec\u80fd\u591f\u8fdb\u884c\u6709\u610f\u4e49\u7684\u5bf9\u8bdd\u5e76\u8868\u73b0\u51fa\u793e\u4f1a\u60c5\u611f\u667a\u80fd\u7684\u503e\u542c\u884c\u4e3a\uff0c\u4ee5\u589e\u5f3a\u4eba\u673a\u4e92\u52a8\u6548\u679c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u6839\u636e\u4e0a\u4e0b\u6587\u60c5\u611f\u8fdb\u884c\u79ef\u6781\u503e\u542c\u548c\u53cd\u9988\u884c\u4e3a\u7684LLM\u793e\u4ea4\u673a\u5668\u4eba\uff0c\u5e76\u4e0e\u4ec5\u53cd\u9988\u884c\u4e3a\u7684\u673a\u5668\u4eba\u548c\u65e0\u503e\u542c\u884c\u4e3a\u7684\u673a\u5668\u4eba\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u79ef\u6781\u503e\u542c\u673a\u5668\u4eba\u4e92\u52a8\u7684\u53c2\u4e0e\u8005\u5bf9\u4e92\u52a8\u7684\u8bc4\u4ef7\u66f4\u79ef\u6781\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u81ea\u6211\u62ab\u9732\uff0c\u5e76\u611f\u89c9\u81ea\u5df1\u88ab\u503e\u542c\u7684\u6548\u679c\u6700\u5f3a\u3002", "conclusion": "\u5728\u793e\u4ea4\u673a\u5668\u4eba\u4e2d\u5b9e\u73b0\u79ef\u6781\u503e\u542c\u884c\u4e3a\u6709\u52a9\u4e8e\u6539\u5584\u4eba\u673a\u4ea4\u6d41\uff0c\u5e76\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u66f4\u6df1\u5c42\u6b21\u7684\u4eba\u673a\u5173\u7cfb\u548c\u60c5\u611f\u8fde\u63a5\u3002"}}
{"id": "2509.07942", "pdf": "https://arxiv.org/pdf/2509.07942", "abs": "https://arxiv.org/abs/2509.07942", "authors": ["James M. Berzuk", "Lauren Corcoran", "Brannen McKenzie-Lefurgey", "Katie Szilagyi", "James E. Young"], "title": "Knowledge Isn't Power: The Ethics of Social Robots and the Difficulty of Informed Consent", "categories": ["cs.HC", "cs.RO"], "comment": "Submitted to the International Journal of Social Robotics. 18 pages,\n  1 figure", "summary": "Contemporary robots are increasingly mimicking human social behaviours to\nfacilitate interaction, such as smiling to signal approachability, or\nhesitating before taking an action to allow people time to react. Such\ntechniques can activate a person's entrenched social instincts, triggering\nemotional responses as though they are interacting with a fellow human, and can\nprompt them to treat a robot as if it truly possesses the underlying life-like\nprocesses it outwardly presents, raising significant ethical questions. We\nengage these issues through the lens of informed consent: drawing upon\nprevailing legal principles and ethics, we examine how social robots can\ninfluence user behaviour in novel ways, and whether under those circumstances\nusers can be appropriately informed to consent to these heightened\ninteractions. We explore the complex circumstances of human-robot interaction\nand highlight how it differs from more familiar interaction contexts, and we\napply legal principles relating to informed consent to social robots in order\nto reconceptualize the current ethical debates surrounding the field. From this\ninvestigation, we synthesize design goals for robot developers to achieve more\nethical and informed human-robot interaction.", "AI": {"tldr": "\u5f53\u4ee3\u673a\u5668\u4eba\u6a21\u4eff\u4eba\u7c7b\u793e\u4ea4\u884c\u4e3a\u4ee5\u4fc3\u8fdb\u4e92\u52a8\uff0c\u4f46\u5f15\u53d1\u4f26\u7406\u95ee\u9898\uff0c\u7279\u522b\u662f\u5173\u4e8e\u77e5\u60c5\u540c\u610f\u7684\u8ba8\u8bba\u3002", "motivation": "\u63a2\u8ba8\u793e\u4ea4\u673a\u5668\u4eba\u5982\u4f55\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\u5f71\u54cd\u7528\u6237\u60c5\u611f\u548c\u884c\u4e3a\uff0c\u4ee5\u53ca\u7528\u6237\u80fd\u5426\u5728\u9ad8\u5ea6\u4e92\u52a8\u4e2d\u771f\u6b63\u77e5\u60c5\u540c\u610f\u3002", "method": "\u7ed3\u5408\u6cd5\u5f8b\u539f\u5219\u548c\u4f26\u7406\u5b66\uff0c\u5206\u6790\u793e\u4ea4\u673a\u5668\u4eba\u5bf9\u7528\u6237\u884c\u4e3a\u7684\u65b0\u5f71\u54cd\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4eba\u7c7b-\u673a\u5668\u4eba\u4e92\u52a8\u60c5\u5883\u3002", "result": "\u63d0\u51fa\u673a\u5668\u4eba\u5f00\u53d1\u8005\u5e94\u9075\u5faa\u7684\u8bbe\u8ba1\u76ee\u6807\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9053\u5fb7\u548c\u77e5\u60c5\u7684\u4eba\u7c7b-\u673a\u5668\u4eba\u4e92\u52a8\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003\u5e76\u8bbe\u8ba1\u793e\u4ea4\u673a\u5668\u4eba\uff0c\u4ee5\u786e\u4fdd\u7528\u6237\u5728\u4e92\u52a8\u4e2d\u7684\u77e5\u60c5\u540c\u610f\u548c\u4f26\u7406\u5408\u89c4\u6027\u3002"}}
