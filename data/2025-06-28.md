<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
*Zijun Wang,Shawn Tsai,Rama Kiran,Rui Zhang*

Main category: eess.SP

TL;DR: 提出一种低复杂度的近场波束训练方案，利用传统的DFT码本，通过分析近场波束模式和推导闭式表达式，实现高效用户距离估计。


<details>
  <summary>Details</summary>
Motivation: 超大天线阵列(ELAAs)在高频段的应用推动了近场通信的发展，需要低复杂度的波束训练方案以提升性能。

Method: 通过分析近场波束模式的波宽和中心增益，定义角度相关的修正瑞利距离，开发复杂度为O(1)的用户距离估计方法，并通过简单优化提升准确性。

Result: 仿真结果显示，相比穷举搜索，单用户和多用户场景分别获得最高2.38 dB的信噪比提升，且通过MLE优化后，估计精度接近Cramer--Rao界。

Conclusion: 所提方案在低复杂度下显著提升性能，单用户和多用户的速率接近理想信道状态信息下的表现。

Abstract: Extremely large antenna arrays (ELAAs) operating in high-frequency bands have
spurred the development of near-field communication, driving advancements in
beam training and signal processing design. In this work, we present a
low-complexity near-field beam training scheme that fully utilizes the
conventional discrete Fourier transform (DFT) codebook designed for far-field
users. We begin by analyzing the received beam pattern in the near field and
derive closed-form expressions for the beam width and central gain. These
analytical results enable the definition of an angle-dependent, modified
Rayleigh distance, which effectively distinguishes near-field and far-field
user regimes. Building on the analysis, we develop a direct and computationally
efficient method to estimate user distance, with a complexity of O(1), and
further improve its accuracy through a simple refinement. Simulation results
demonstrate significant gains in both single- and multi-user settings, with up
to 2.38 dB SNR improvement over exhaustive search. To further enhance
estimation accuracy, we additionally propose a maximum likelihood estimation
(MLE) based refinement method, leveraging the Rician distribution of signal
amplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).
Simulation shows the single-user and multi-user achievable rates can both
approach those obtained with ideal channel state information.

</details>


### [2] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
*Mohammad Taghi Dabiri,Mazen Hasna,Saif Al-Kuwari,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 基于纠缠的量子密钥分发(QKD)协议在卫星间通信中具有信息论安全性，但实际物理层挑战未被充分研究。本文通过光子级建模分析性能，提供优化参数方案。


<details>
  <summary>Details</summary>
Motivation: 现有文献未解决卫星间自由空间光通信中光子损耗等问题对QKD性能的影响，需要针对性的性能分析和优化。

Method: 开发了关于信号检测概率、背景光子影响、多对光子发射及QBER的解析模型，结合链路距离、发射器抖动等参数进行模拟。

Result: 模拟结果显示系统性能对跟踪误差和视场限制具有非线性敏感性，并确定了最大化密钥率且保持QBER低于阈值的优化参数区间。

Conclusion: 模型为基于纠缠的卫星QKD系统的可靠高效部署提供了实用设计指导。

Abstract: Entanglement-based quantum key distribution (QKD) protocols, such as E91 and
BBM92, offer strong information-theoretic security and are naturally suited for
satellite-to-satellite QKD (SatQKD) links. However, implementing these
protocols over long-distance inter-satellite free-space optical (FSO) channels
poses critical physical-layer challenges that are not addressed in the existing
literature. In particular, photon losses due to beam divergence, pointing
errors, and background noise can severely degrade the key generation rate and
quantum bit error rate (QBER), especially under narrow receiver field-of-view
(FoV) constraints. This paper presents a comprehensive performance analysis of
entanglement-based inter-satellite QKD, focusing on photon-level modeling and
the impact of practical impairments. We develop analytical expressions for
signal detection probabilities, background photon influence, multi-pair
emissions, and QBER, incorporating key parameters such as link distance,
transmitter tracking jitter, receiver misalignment, and photon pair generation
rate. Simulation results reveal the nonlinear sensitivity of system performance
to tracking error and FoV limitations, and highlight optimal parameter regimes
that jointly maximize secret key rate while maintaining QBER below acceptable
thresholds. The proposed model provides actionable design insights for reliable
and efficient deployment of entanglement-based SatQKD systems.

</details>


### [3] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
*Mohammad Taghi Dabiri,Mazen Hasna*

Main category: eess.SP

TL;DR: 提出了一种高效的解析框架，用于评估轨道角动量（OAM）光束在指向误差下的卫星间通信性能，显著减少了计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡罗方法计算量大，无法满足动态低地球轨道卫星星座的实时链路适配需求。

Method: 开发了精确的解析模型，分析了OAM光束对准误差引起的模态间串扰，并推导了性能优化表达式。

Result: 提出的方法在计算时间大幅减少的同时保持高精度，非对称OAM模式配置在指向误差下表现更优。

Conclusion: 该框架适用于高移动性光学无线系统，如LEO卫星网络，具有实际应用价值。

Abstract: This paper presents an efficient analytical framework for evaluating the
performance of inter-satellite communication systems utilizing orbital angular
momentum (OAM) beams under pointing errors. An accurate analytical model is
first developed to characterize intermodal crosstalk caused by beam
misalignment in OAM-based inter-satellite links. Building upon this model, we
derive efficient expressions to analyze and optimize system performance in
terms of bit error rate (BER). Unlike traditional Monte Carlo-based methods
that are computationally intensive, the proposed approach offers accurate
performance predictions. This enables a substantial decrease in computation
time while maintaining high accuracy, thanks to the use of analytical
expressions for both crosstalk and BER. This fast and accurate evaluation
capability is particularly critical for dynamic low Earth orbit (LEO) satellite
constellations, where network topology and channel conditions change rapidly,
requiring real-time link adaptation. Furthermore, we systematically design and
evaluate asymmetric OAM mode sets, which significantly outperform symmetric
configurations in the presence of pointing errors. Our results also reveal key
insights into the interaction between beam divergence, tracking accuracy, and
link distance, demonstrating that the proposed framework enables real-time
optimization of system parameters with high fidelity. The analytical findings
are rigorously validated against extensive Monte Carlo simulations, confirming
their practical applicability for high-mobility optical wireless systems such
as LEO satellite networks.

</details>


### [4] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
*Jamil Farhat,Gianni Pasolini,Enrico Paolini,Muhammad Asad Ullah,Richard Demo Souza*

Main category: eess.SP

TL;DR: 本文提出四种多普勒估计与补偿框架，以提升LoRa卫星物联网的性能，并分析其与理想场景的对比及关键参数的权衡。


<details>
  <summary>Details</summary>
Motivation: LEO卫星在物联网应用中因多普勒效应导致LoRa性能下降，需探索有效的估计与补偿方法。

Method: 提出四种多普勒估计与补偿框架，并通过数值模拟分析其性能及与关键参数（如扩频因子）的权衡。

Result: 框架性能对比为设计稳健的LoRa卫星物联网配置提供了重要见解。

Conclusion: 通过多普勒补偿框架，可以有效提升LoRa在卫星物联网中的性能。

Abstract: Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology
has garnered significant interest as a connectivity solution for IoT
applications due to its ability to offer low-cost, low-power, and long-range
communications. One emerging use case of LoRa is DtS connectivity, which
extends coverage to remote areas for supporting IoT operations. The satellite
IoT industry mainly prefers LEO because it has lower launch costs and less path
loss compared to Geostationary orbit. However, a major drawback of LEO
satellites is the impact of the Doppler effect caused by their mobility.
Earlier studies have confirmed that the Doppler effect significantly degrades
the LoRa DtS performance. In this paper, we propose four frameworks for Doppler
estimation and compensation in LoRa DtS connectivity and numerically compare
the performance against the ideal scenario without the Doppler effect.
Furthermore, we investigate the trade-offs among these frameworks by analyzing
the interplay between spreading factor, and other key parameters related to the
Doppler effect. The results provide insights into how to achieve robust LoRa
configurations for DtS connectivity.

</details>


### [5] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
*Naoki Ishikawa,Giuseppe Thadeu Freitas de Abreu,Petar Popovski,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum computing is poised to redefine the algorithmic foundations of
communication systems. While quantum superposition and entanglement enable
quadratic or exponential speedups for specific problems, identifying use cases
where these advantages yield engineering benefits is, however, still
nontrivial. This article presents the fundamentals of quantum computing in a
style familiar to the communications society, outlining the current limits of
fault-tolerant quantum computing and uncovering a mathematical harmony between
quantum and wireless systems, which makes the topic more enticing to wireless
researchers. Based on a systematic review of pioneering and state-of-the-art
studies, we distill common design trends for the research and development of
quantum-accelerated communication systems and highlight lessons learned. The
key insight is that classical heuristics can sharpen certain quantum
parameters, underscoring the complementary strengths of classical and quantum
computing. This article aims to catalyze interdisciplinary research at the
frontier of quantum information processing and future communication systems.

</details>


### [6] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
*Haijia Jin,Jun Wu,Weijie Yuan,Fan Liu,Yuanhao Cui*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The rapid advancement of Internet of Things (IoT) services and the evolution
toward the sixth generation (6G) have positioned unmanned aerial vehicles
(UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This
work investigates the co-design of integrated sensing, communication, and
control ($\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite
blocklength (FBL) transmission. In particular, the UAVs continuously monitor
the state of the field robots and transmit their observations to the robot
controller to ensure stable control while cooperating to localize an unknown
sensing target (ST). To this end, a weighted optimization problem is first
formulated by jointly considering the control and localization performance in
terms of the linear quadratic regulator (LQR) cost and the determinant of the
Fisher information matrix (FIM), respectively. The resultant problem,
optimizing resource allocations, the UAVs' deployment positions, and multi-user
scheduling, is non-convex. To circumvent this challenge, we first derive a
closed-form expression of the LQR cost with respect to other variables.
Subsequently, the non-convex optimization problem is decomposed into a series
of sub-problems by leveraging the alternating optimization (AO) approach, in
which the difference of convex functions (DC) programming and projected
gradient descent (PGD) method are employed to obtain an efficient near-optimal
solution. Furthermore, the convergence and computational complexity of the
proposed algorithm are thoroughly analyzed. Extensive simulation results are
presented to validate the effectiveness of our proposed approach compared to
the benchmark schemes and reveal the trade-off between control and sensing
performance.

</details>


### [7] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A differential microphone array (DMA) offers enhanced capabilities to obtain
sharp nulls at the cost of relatively broad peaks in the beam power pattern.
This can be used for applications that require nullification or attenuation of
interfering sources. To the best of our knowledge, the existing literature
lacks measures that directly assess the efficacy of nulls, and null-related
measures have not been investigated in the context of differential microphone
arrays (DMAs). This paper offers new insights about the utility of DMAs by
proposing measures that characterize the nulls in their beam power patterns. We
investigate the performance of differential beamformers by presenting and
evaluating null-related measures namely null depth (ND) and Null Width (NW) as
a function of depth level relative to the beam power pattern maxima. A study of
signal quantization effects due to data acquisition for 1st, 2nd and 3rd order
linear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid
and supercardioid is presented. An analytical expression for the quantized
beamformed output for any general $ N^{th} $ order DMA is formulated.
Simulation results of the variation of ND with number of quantization bits and
the variation of NW as a function of depth are also presented and inferences
are drawn. Lab experiments are conducted in a fully anechoic room to support
the simulation results. The measured beampattern exhibits a pronounced null
depth, confirming the effectiveness of the experimental setup.

</details>


### [8] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
*Yancheng Wang,Wei Guo,Guanying Chen,Ye Zhang,Shuguang Cui*

Main category: eess.SP

TL;DR: 论文提出了一种联合模型和数据驱动的方法，通过点云环境数据和少量位置标记的通道信息构建CKM，显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的CKM构建方案使用过于简化的环境信息，导致准确性不足。

Method: 提出一种点选择器和神经通道增益估计器，利用点云数据和实地测量数据进行训练。

Result: 在PDP和无线电地图的CKM构建中，RMSE显著低于传统方法。

Conclusion: 联合模型和数据驱动的方法有效提升了CKM的构建精度。

Abstract: Channel knowledge map (CKM) provides certain levels of channel state
information (CSI) for an area of interest, serving as a critical enabler for
environment-aware communications by reducing the overhead of frequent CSI
acquisition. However, existing CKM construction schemes adopt over-simplified
environment information, which significantly compromises their accuracy. To
address this issue, this work proposes a joint model- and data-driven approach
to construct CKM by leveraging point cloud environmental data along with a few
samples of location-tagged channel information. First, we propose a novel point
selector to identify subsets of point cloud that contain environmental
information relevant to multipath channel gains, by constructing a set of
co-focal ellipsoids based on different time of arrival (ToAs). Then, we trained
a neural channel gain estimator to learn the mapping between each selected
subset and its corresponding channel gain, using a real-world dataset we
collected through field measurements, comprising environmental point clouds and
corresponding channel data. Finally, experimental results demonstrate that: For
CKM construction of power delay profile (PDP), the proposed method achieves a
root mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB
achieved by the conventional ray-tracing method; for CKM construction of
received power values, i.e., radio map, it achieves an RMSE of 1.04 dB,
surpassing the Kriging interpolation method with an RMSE of 1.68 dB.

</details>


### [9] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
*Hao Wu,Chongwu Xie,Xinyuan Yao,Kang-Da Wu,Shanchi Wu,Rui Ni,Guo-Yong Xiang,Chen Gong*

Main category: eess.SP

TL;DR: 论文研究了Rydberg原子传感器在多频信号接收时的互干扰特性，分析了两种不同载频信号的相互干扰，并通过实验验证了误码率和符号错误率。


<details>
  <summary>Details</summary>
Motivation: Rydberg原子传感器在多用户通信中具有吸引力，但其多频信号接收会带来互干扰问题，需要深入研究。

Method: 基于接收器特性引入联合响应系数，分析两种信号的干扰特性，并计算误码率和符号错误率。

Result: 实验验证了误码率（BER）和符号错误率（SER）的结果。

Conclusion: 研究为Rydberg原子传感器在多频信号接收中的干扰问题提供了分析和验证方法。

Abstract: Rydberg atomic sensors have been adopted for novel radio frequency (RF)
measurement technique and the sensing capability for signals in multiple
frequencies makes it attractive for multi-user communication. However, unlike
traditional antennas where the signals in multiple frequencies are orthogonal,
the received signals of atomic sensors corresponding to different energy levels
will be downconverted to the baseband simultaneously, resulting in multi-user
interference. Thus, in this paper, we analyze the mutual interference
characteristics of two RF signals with different carrier frequencies coupling
different energy levels. We introduce the joint response coefficient based on
the receiver characteristics and analyze the interference of one user to
another. We analyze the bit-error rate (BER) and symbol-error rate (SER) for
two signals coupling two different energy levels. We also conduct experiments
to validate the BER and SER results.

</details>


### [10] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
*Shengjie Liu,Chenyang Yang*

Main category: eess.SP

TL;DR: 通过对抗训练（AT）增强无监督训练深度神经网络（DNNs）的分布外（OOD）泛化能力，提出一步梯度上升方法并在混合预编码优化中验证其效果。


<details>
  <summary>Details</summary>
Motivation: DNNs在资源分配优化中应用广泛，但其性能易受训练与测试数据分布变化（如信道变化）的影响，需提升OOD泛化能力。

Method: 重新设计AT以捕获OOD性能退化，并开发一步梯度上升的对抗训练方法。

Result: 在仅使用瑞利衰落信道训练的情况下，多种DNNs在不同信道分布下的OOD性能显著提升。

Conclusion: 所提方法能有效增强DNNs在未知信道环境中的泛化能力，为资源分配优化提供新思路。

Abstract: Deep neural networks (DNNs) have widespread applications for optimizing
resource allocation. Yet, their performance is vulnerable to distribution
shifts between training and test data, say channels. In this letter, we resort
to adversarial training (AT) for enhancing out-of-distribution (OOD)
generalizability of DNNs trained in unsupervised manner. We reformulate AT to
capture the OOD degradation, and propose a one-step gradient ascent method for
AT. The proposed method is validated by optimizing hybrid precoding. Simulation
results showcase the enhanced OOD performance of multiple kinds of DNNs across
various channel distributions, when only Rayleigh fading channels are used for
training.

</details>


### [11] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
*Nima Mozaffarikhosravi,Prathapasinghe Dharmawansa,Italo Atzeni*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Shifting 6G-and-beyond wireless communication systems to higher frequency
bands and the utilization of massive multiple-input multiple-output arrays will
extend the near-field region, affecting beamforming and user localization
schemes. In this paper, we propose a localization-based beam-focusing strategy
that leverages the dominant line-of-sight (LoS) propagation arising at mmWave
and sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC
algorithm for distance estimation by examining its spectrum in simplified,
tractable setups with minimal numbers of antennas and users. Lastly, we compare
the proposed localization-based beam focusing, with locations estimated via
2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of
uplink sum spectral efficiency. Our numerical results show that the proposed
method becomes more effective under LoS-dominated propagation, short coherence
blocks, and strong noise power arising at high carrier frequencies and with
large bandwidths.

</details>


### [12] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
*Ying Gao,Qingqing Wu,Weidong Mei,Guangji Chen,Wen Chen,Ziyuan Zheng*

Main category: eess.SP

TL;DR: 研究利用智能反射面（IRS）辅助可移动天线（MA）系统，通过联合优化MA位置、IRS反射系数和发射波束成形，提高目标区域的覆盖性能。提出三种方案，并开发算法框架解决非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 扩展无线覆盖范围到多个目标区域，同时平衡性能与成本的关系。

Method: 提出三种方案（area-adaptive MA-IRS、area-adaptive MA-staIRS、shared MA-staIRS），并开发通用算法框架解决非凸优化问题。

Result: 仿真显示MA方案优于固定天线方案，adaptive MA-IRS性能最优；天线数量与IRS单元成本比例对性能有影响。

Conclusion: MA方案显著提升覆盖性能，优化天线数量和IRS配置可进一步改善性能。

Abstract: This paper investigates an intelligent reflecting surface (IRS)-aided movable
antenna (MA) system, where multiple IRSs cooperate with a multi-MA base station
to extend wireless coverage to multiple designated target areas. The objective
is to maximize the worst-case signal-to-noise ratio (SNR) across all locations
within these areas through joint optimization of MA positions, IRS reflection
coefficients, and transmit beamforming. To achieve this while balancing the
performance-cost trade-off, we propose three coverage-enhancement schemes: the
area-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared
MA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients
configured only once during installation. These schemes lead to challenging
non-convex optimization problems with implicit objective functions, which are
difficult to solve optimally. To address these problems, we propose a general
algorithmic framework that can be applied to solve each problem efficiently
albeit suboptimally. Simulation results demonstrate that: 1) the proposed
MA-based schemes consistently outperform their fixed-position antenna
(FPA)-based counterparts under both area-adaptive and static IRS
configurations, with the area-adaptive MA-IRS scheme achieving the best
worst-case SNR performance; 2) as transmit antennas are typically far fewer
than IRS elements, the area-adaptive MA-staIRS scheme may underperform the
baseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but
a modest increase in antenna number can reverse this trend; 3) under a fixed
total cost, the optimal MA-to-IRS-element ratio for the worst-case SNR
maximization is empirically found to be proportional to the reciprocal of their
unit cost ratio.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [13] [Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing](https://arxiv.org/abs/2506.20782)
*Marc Bara*

Main category: cs.NE

TL;DR: 提出了首个将脉冲神经网络（SNN）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架，填补了领域空白，并在能效上表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着地球观测数据量的激增（如NISAR任务预计两年产生100PB数据），高效能处理成为数据中心可持续运行的关键。SNN因其事件驱动模型，可节能30-100倍。

Method: 开发了针对相位数据的脉冲编码方案，提出利用相位解缠空间传播特性的SNN架构，并分析了计算复杂度和收敛性。

Result: SNN的时间动态特性自然地建模了相位解缠的空间连续性约束，表现出与传统方法相当的精度。

Conclusion: 该研究为神经形态计算与SAR干涉测量的交叉领域开辟了新方向，为大规模InSAR处理提供了可持续的补充方案。

Abstract: We present the first theoretical framework for applying spiking neural
networks (SNNs) to synthetic aperture radar (SAR) interferometric phase
unwrapping. Despite extensive research in both domains, our comprehensive
literature review confirms that SNNs have never been applied to phase
unwrapping, representing a significant gap in current methodologies. As Earth
observation data volumes continue to grow exponentially (with missions like
NISAR expected to generate 100PB in two years) energy-efficient processing
becomes critical for sustainable data center operations. SNNs, with their
event-driven computation model, offer potential energy savings of 30-100x
compared to conventional approaches while maintaining comparable accuracy. We
develop spike encoding schemes specifically designed for wrapped phase data,
propose SNN architectures that leverage the spatial propagation nature of phase
unwrapping, and provide theoretical analysis of computational complexity and
convergence properties. Our framework demonstrates how the temporal dynamics
inherent in SNNs can naturally model the spatial continuity constraints
fundamental to phase unwrapping. This work opens a new research direction at
the intersection of neuromorphic computing and SAR interferometry, offering a
complementary approach to existing algorithms that could enable more
sustainable large-scale InSAR processing.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [14] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
*Maxime Leiber,Yosra Marnissi,Axel Barrau,Sylvain Meignen,Laurent Massoulié*

Main category: cs.SD

TL;DR: 提出了一种可微分的STFT方法，通过梯度优化参数，解决了传统STFT参数调整的局限性，并与神经网络结合，提升了时频表示和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统STFT参数调整依赖手动或启发式方法，效果不佳且计算量大。

Method: 提出了统一的可微分STFT框架，支持基于梯度的参数优化，并与神经网络联合训练。

Result: 在仿真和真实数据实验中，该方法显著提升了时频表示和下游任务效果。

Conclusion: 可微分STFT是一种高效且灵活的解决方案，适用于信号处理和分析任务。

Abstract: The short-time Fourier transform (STFT) is widely used for analyzing
non-stationary signals. However, its performance is highly sensitive to its
parameters, and manual or heuristic tuning often yields suboptimal results. To
overcome this limitation, we propose a unified differentiable formulation of
the STFT that enables gradient-based optimization of its parameters. This
approach addresses the limitations of traditional STFT parameter tuning
methods, which often rely on computationally intensive discrete searches. It
enables fine-tuning of the time-frequency representation (TFR) based on any
desired criterion. Moreover, our approach integrates seamlessly with neural
networks, allowing joint optimization of the STFT parameters and network
weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and
improving performance in downstream tasks is demonstrated through experiments
on both simulated and real-world data.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [15] [Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks](https://arxiv.org/abs/2506.20762)
*Shisheng Hu,Jie Gao,Xue Qin,Conghao Zhou,Xinyu Huang,Mushu Li,Mingcheng He,Xuemin Shen*

Main category: cs.NI

TL;DR: 本文提出了一种新的漂移自适应切片资源管理方案，用于协作式集成感知与通信网络，通过数字孪生技术优化资源分配，提升服务满意度并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决移动设备和感知目标空间分布非平稳性导致的建模漂移和规划决策失效问题，优化集成感知与通信网络的资源管理。

Method: 建立两个网络切片分别提供感知和通信服务，利用数字孪生技术开发漂移自适应统计模型和仿真功能，实现高效决策与验证。

Result: 数值结果表明，相较于基准方案，该方案可将服务满意度提升至18%，资源消耗降低13.1%。

Conclusion: 漂移自适应切片资源管理方案有效解决了非平稳分布下的资源分配问题，显著提升了网络性能。

Abstract: In this paper, we propose a novel drift-adaptive slicing-based resource
management scheme for cooperative integrated sensing and communication (ISAC)
networks. Particularly, we establish two network slices to provide sensing and
communication services, respectively. In the large-timescale planning for the
slices, we partition the sensing region of interest (RoI) of each mobile device
and reserve network resources accordingly, facilitating low-complexity
distance-based sensing target assignment in small timescales. To cope with the
non-stationary spatial distributions of mobile devices and sensing targets,
which can result in the drift in modeling the distributions and ineffective
planning decisions, we construct digital twins (DTs) of the slices. In each DT,
a drift-adaptive statistical model and an emulation function are developed for
the spatial distributions in the corresponding slice, which facilitates
closed-form decision-making and efficient validation of a planning decision,
respectively. Numerical results show that the proposed drift-adaptive
slicing-based resource management scheme can increase the service satisfaction
ratio by up to 18% and reduce resource consumption by up to 13.1% when compared
with benchmark schemes.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [16] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [17] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
*Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert*

Main category: eess.IV

TL;DR: PTACL是一种多模态对比学习框架，通过整合CMR的空间-时间信息增强ECG表征，以弥补ECG在心脏功能评估上的不足。


<details>
  <summary>Details</summary>
Motivation: ECG无法直接测量心脏功能参数（如心室容积和射血分数），而CMR虽为金标准但昂贵且不易获取，因此需一种方法来结合两者的优势。

Method: PTACL结合全局患者级和局部时间级对比损失，通过对比学习对齐ECG与CMR的嵌入表征，无需引入新参数。

Result: 在UK Biobank数据上，PTACL在患者检索和心脏功能参数预测任务上优于基线方法。

Conclusion: PTACL有望增强基于ECG的非侵入性心脏诊断，代码已开源。

Abstract: An electrocardiogram (ECG) is a widely used, cost-effective tool for
detecting electrical abnormalities in the heart. However, it cannot directly
measure functional parameters, such as ventricular volumes and ejection
fraction, which are crucial for assessing cardiac function. Cardiac magnetic
resonance (CMR) is the gold standard for these measurements, providing detailed
structural and functional insights, but is expensive and less accessible. To
bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive
Learning), a multimodal contrastive learning framework that enhances ECG
representations by integrating spatio-temporal information from CMR. PTACL uses
global patient-level contrastive loss and local temporal-level contrastive
loss. The global loss aligns patient-level representations by pulling ECG and
CMR embeddings from the same patient closer together, while pushing apart
embeddings from different patients. Local loss enforces fine-grained temporal
alignment within each patient by contrasting encoded ECG segments with
corresponding encoded CMR frames. This approach enriches ECG representations
with diagnostic information beyond electrical activity and transfers more
insights between modalities than global alignment alone, all without
introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data
from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL
achieves better performance in two clinically relevant tasks: (1) retrieving
patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac
function parameters, such as ventricular volumes and ejection fraction. Our
results highlight the potential of PTACL to enhance non-invasive cardiac
diagnostics using ECG. The code is available at:
https://github.com/alsalivan/ecgcmr

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [18] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
*Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker*

Main category: cs.LG

TL;DR: 本文提出了一种基于FINN框架的通用方法，用于在FPGA上高效部署LSTM模型，解决了现有工具主要针对前馈网络的问题，并通过量化验证和硬件映射优化实现了性能与资源消耗的平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管LSTM在时间序列任务中表现优异，但其计算复杂度和实时部署的挑战使得在资源受限环境中难以应用。FPGA虽能高效加速AI，但现有工具缺乏对LSTM的支持。

Method: 利用FINN框架和ONNX的Scan操作符建模LSTM的循环特性，支持混合量化，并通过FINN编译器将量化后的计算图映射到硬件块。

Result: 实验表明，生成的量化ConvLSTM加速器在性能和资源消耗上取得了平衡，同时保持了与先进模型相当的推理精度。

Conclusion: 提出的通用流程为FPGA上资源高效的RNN加速器设计奠定了基础。

Abstract: Recurrent neural networks (RNNs), particularly LSTMs, are effective for
time-series tasks like sentiment analysis and short-term stock prediction.
However, their computational complexity poses challenges for real-time
deployment in resource constrained environments. While FPGAs offer a promising
platform for energy-efficient AI acceleration, existing tools mainly target
feed-forward networks, and LSTM acceleration typically requires full custom
implementation. In this paper, we address this gap by leveraging the
open-source and extensible FINN framework to enable the generalized deployment
of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open
Neural Network Exchange (ONNX) specification to model the recurrent nature of
LSTM computations, enabling support for mixed quantisation within them and
functional verification of LSTM-based models. Furthermore, we introduce custom
transformations within the FINN compiler to map the quantised ONNX computation
graph to hardware blocks from the HLS kernel library of the FINN compiler and
Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM
model for a mid-price stock prediction task using the widely used dataset and
generating a corresponding hardware IP of the model using our flow, targeting
the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator
through our flow achieves a balance between performance (latency) and resource
consumption, while matching (or bettering) inference accuracy of
state-of-the-art models with reduced precision. We believe that the
generalisable nature of the proposed flow will pave the way for
resource-efficient RNN accelerator designs on FPGAs.

</details>


### [19] [Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management](https://arxiv.org/abs/2506.20853)
*Ziyang Lu,Subodh Kalia,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney*

Main category: cs.LG

TL;DR: 多功能的认知雷达系统中的时间分配问题，研究如何平衡扫描新目标和跟踪已检测目标，采用深度强化学习方法比较DDPG与SAC算法。


<details>
  <summary>Details</summary>
Motivation: 解决认知雷达在动态环境中平衡多目标的问题，提升系统效率和适应性。

Method: 将问题建模为多目标优化，采用DDPG和SAC算法，并使用NSGA-II算法估计Pareto前沿。

Result: SAC在稳定性和样本效率上优于DDPG，有效适应不同场景。

Conclusion: 该研究为开发更高效的认知雷达系统提供了方法，能有效平衡动态环境中的多目标。

Abstract: The time allocation problem in multi-function cognitive radar systems focuses
on the trade-off between scanning for newly emerging targets and tracking the
previously detected targets. We formulate this as a multi-objective
optimization problem and employ deep reinforcement learning to find
Pareto-optimal solutions and compare deep deterministic policy gradient (DDPG)
and soft actor-critic (SAC) algorithms. Our results demonstrate the
effectiveness of both algorithms in adapting to various scenarios, with SAC
showing improved stability and sample efficiency compared to DDPG. We further
employ the NSGA-II algorithm to estimate an upper bound on the Pareto front of
the considered problem. This work contributes to the development of more
efficient and adaptive cognitive radar systems capable of balancing multiple
competing objectives in dynamic environments.

</details>


### [20] [Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection](https://arxiv.org/abs/2506.21093)
*Li Fan,Peng Wang,Jing Yang,Cong Shen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Transformers have shown potential in solving wireless communication problems,
particularly via in-context learning (ICL), where models adapt to new tasks
through prompts without requiring model updates. However, prior ICL-based
Transformer models rely on deep architectures with many layers to achieve
satisfactory performance, resulting in substantial storage and computational
costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a
CoT-enhanced shallow Transformer framework for wireless symbol detection. By
introducing autoregressive latent reasoning steps within the hidden space,
CHOOSE significantly improves the reasoning capacity of shallow models (1-2
layers) without increasing model depth. This design enables lightweight
Transformers to achieve detection performance comparable to much deeper models,
making them well-suited for deployment on resource-constrained mobile devices.
Experimental results demonstrate that our approach outperforms conventional
shallow Transformers and achieves performance comparable to that of deep
Transformers, while maintaining storage and computational efficiency. This
represents a promising direction for implementing Transformer-based algorithms
in wireless receivers with limited computational resources.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [21] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
*Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami*

Main category: cs.CV

TL;DR: MedPrompt是一个统一框架，结合LLM和模块化CNN，实现灵活、可扩展的医学图像分析。


<details>
  <summary>Details</summary>
Motivation: 解决现有医学图像分析系统任务单一、缺乏灵活性及用户定义工作流支持的问题。

Method: 使用少量提示的LLM（Llama-4-17B）进行高层次任务规划，结合模块化CNN（DeepFusionLab）进行低层次图像处理，动态路由任务特定权重。

Result: 在19个公共数据集上测试，任务执行正确率97%，推理延迟2.5秒；分割和分类性能优异（如肺部Dice 0.9856）。

Conclusion: MedPrompt通过结合LLM的解释性和模块化CNN的高效性，实现了可扩展的、即时驱动的医学图像分析。

Abstract: Current medical image analysis systems are typically task-specific, requiring
separate models for classification and segmentation, and lack the flexibility
to support user-defined workflows. To address these challenges, we introduce
MedPrompt, a unified framework that combines a few-shot prompted Large Language
Model (Llama-4-17B) for high-level task planning with a modular Convolutional
Neural Network (DeepFusionLab) for low-level image processing. The LLM
interprets user instructions and generates structured output to dynamically
route task-specific pretrained weights. This weight routing approach avoids
retraining the entire framework when adding new tasks-only task-specific
weights are required, enhancing scalability and deployment. We evaluated
MedPrompt across 19 public datasets, covering 12 tasks spanning 5 imaging
modalities. The system achieves a 97% end-to-end correctness in interpreting
and executing prompt-driven instructions, with an average inference latency of
2.5 seconds, making it suitable for near real-time applications. DeepFusionLab
achieves competitive segmentation accuracy (e.g., Dice 0.9856 on lungs) and
strong classification performance (F1 0.9744 on tuberculosis). Overall,
MedPrompt enables scalable, prompt-driven medical imaging by combining the
interpretability of LLMs with the efficiency of modular CNNs.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [22] [Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications](https://arxiv.org/abs/2506.21078)
*Tian Han,Shalanika Dayarathna,Rajitha Senanayake,Peter Smith,Aryan Kaushik,Alain Mourad,Richard A. Stirling-Gallacher,Jamie Evans*

Main category: cs.IT

TL;DR: 论文探讨了集成传感与通信（ISAC）中多载波波形（如OFDM）的高PAPR问题，提出了适合资源受限物联网（IoT）场景的恒定模波形设计，并分析了其性能。


<details>
  <summary>Details</summary>
Motivation: 多载波波形（如OFDM）在ISAC中因高数据速率和良好的时频特性而被广泛使用，但其高PAPR值限制了在资源受限的IoT场景中的应用。

Method: 提出了几种单载波频率和相位调制波形，利用其单位PAPR特性，适用于资源受限场景。

Result: 通过雷达模糊函数、带宽特性、数据速率和通信接收器复杂度等指标，全面评估了这些波形的雷达传感和通信性能。

Conclusion: 恒定模波形设计在资源受限的IoT场景中更具优势，能够克服OFDM的高PAPR问题，同时满足传感和通信需求。

Abstract: Integrated sensing and communications (ISAC) is considered a key enabler to
support application scenarios such as the Internet-of-Things (IoT) in which
both communications and sensing play significant roles. Multi-carrier
waveforms, such as orthogonal frequency division multiplexing (OFDM), have been
considered as good candidates for ISAC due to their high communications data
rate and good time bandwidth property for sensing. Nevertheless, their high
peak-to-average-power-ratio (PAPR) values lead to either performance
degradation or an increase in system complexity. This can make OFDM unsuitable
for IoT applications with insufficient resources in terms of power, system
complexity, hardware size or cost. This article provides IoT-centric constant
modulus waveform designs that leverage the advantage of unit PAPR and thus are
more suitable in resource-limited scenarios. More specifically, several
single-carrier frequency and/or phase-modulated waveforms are considered. A
comprehensive discussion on their radar sensing and communications performance
is conducted based on performance metrics, including the radar ambiguity
function, the bandwidth property, the data rate, and the communications
receiver complexity.

</details>


### [23] [Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications](https://arxiv.org/abs/2506.21370)
*Jiuyu Liu,Yi Ma,Qihao Peng,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出了一种面向卫星通信的集群感知两阶段MIMO检测方法，利用用户地理集群内的信道相关性提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统迭代MIMO检测器在卫星通信中由于集群内用户信道高度相关，导致收敛缓慢。

Method: 采用两阶段策略：先用小矩阵逆消除集群内干扰，再利用预计算矩阵加速标准迭代检测器（如GS和SSOR）处理集群间干扰。

Result: 仿真显示，完美信道状态下收敛速度快12倍，存在信道误差时仍快9倍。

Conclusion: 该方法高效且鲁棒，适用于下一代卫星MIMO通信。

Abstract: In this paper, a cluster-aware two-stage multiple-input multiple-output
(MIMO) detection method is proposed for direct-to-cell satellite
communications. The method achieves computational efficiency by exploiting a
distinctive property of satellite MIMO channels: users within the same
geographical cluster exhibit highly correlated channel characteristics due to
their physical proximity, which typically impedes convergence in conventional
iterative MIMO detectors. The proposed method implements a two-stage strategy
that first eliminates intra-cluster interference using computationally
efficient small matrix inversions, then utilizes these pre-computed matrices to
accelerate standard iterative MIMO detectors such as Gauss-Seidel (GS) and
symmetric successive over-relaxation (SSOR) for effective inter-cluster
interference cancellation. Computer simulations demonstrate that the proposed
method achieves more than 12 times faster convergence under perfect channel
state information. Even when accounting for channel estimation errors, the
method maintains 9 times faster convergence, demonstrating its robustness and
effectiveness for next-generation satellite MIMO communications.

</details>
