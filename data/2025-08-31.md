<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 7]
- [cs.RO](#cs.RO) [Total: 23]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.IT](#cs.IT) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Error Analysis for Over-the-Air Federated Learning under Misaligned and Time-Varying Channels](https://arxiv.org/abs/2508.20277)
*Xiaoyan Ma,Shahryar Zehtabi,Taejoon Kim,Christopher G. Brinton*

Main category: eess.SP

TL;DR: 本文研究了基于OFDM的空中联邦学习（OTA-FL）系统，分析了高移动性设备导致的信道估计不完美对模型聚合的影响，并提出了量化累积误差的理论方法。


<details>
  <summary>Details</summary>
Motivation: 研究高移动性设备（如无人机）在OTA-FL系统中由于信道估计不完美导致的模型参数不对齐问题，以及时变信道对模型聚合的影响。

Method: 通过推导单轮全局模型更新的闭式表达式，扩展至多轮更新的累积误差分析，并通过数值模拟验证理论结果。

Result: 量化了信道不完美对OTA-FL训练过程的失真影响，并得出了累积误差的界限。

Conclusion: 理论分析和模拟验证表明，信道不完美会显著影响OTA-FL的性能，需在设计系统中加以考虑。

Abstract: This paper investigates an OFDM-based over-the-air federated learning
(OTA-FL) system, where multiple mobile devices, e.g., unmanned aerial vehicles
(UAVs), transmit local machine learning (ML) models to a central parameter
server (PS) for global model aggregation. The high mobility of local devices
results in imperfect channel estimation, leading to a misalignment problem,
i.e., the model parameters transmitted from different local devices do not
arrive at the central PS simultaneously. Moreover, the mobility introduces
time-varying uploading channels, which further complicates the aggregation
process. All these factors collectively cause distortions in the OTA-FL
training process which are underexplored. To quantify these effects, we first
derive a closed-form expression for a single-round global model update in terms
of these channel imperfections. We then extend our analysis to capture multiple
rounds of global updates, yielding a bound on the accumulated error in OTA-FL.
We validate our theoretical results via extensive numerical simulations, which
corroborate our derived analysis.

</details>


### [2] [Dual-IRS Aided Near-/Hybrid-Field SWIPT: Passive Beamforming and Independent Antenna Power Splitting Design](https://arxiv.org/abs/2508.20531)
*Chaoying Huang,Wen Chen,Qingqing Wu,Xusheng Zhu,Zhendong Li,Ying Wang,Jinhong Yuan*

Main category: eess.SP

TL;DR: 论文提出了一种新型双智能反射面（IRS）辅助的SWIPT系统，通过独立功率分配优化信息与能量传输的权衡，并比较了近场和混合场模型。


<details>
  <summary>Details</summary>
Motivation: 提升SWIPT系统性能，通过双IRS和独立功率分配优化信息与能量的传输效率。

Method: 建立了近场和混合场信道模型，提出交替优化算法并使用拉格朗日对偶方法和DC规划解决问题。混合场情况下，利用双IRS相位不变性转化为凸优化问题。

Result: 数值结果表明，双IRS辅助的SWIPT系统在独立功率分配下表现优于其他基准方案。

Conclusion: 双IRS结合独立功率分配策略能显著提升SWIPT系统性能，尤其在近场和混合场环境下。

Abstract: This paper proposes a novel dual-intelligent reflecting surface (IRS) aided
interference-limited simultaneous wireless information and power transfer
(SWIPT) system with independent power splitting (PS), where each receiving
antenna applies different PS factors to offer an advantageous trade-off between
the useful information and harvested energy. We separately establish the near-
and hybrid-field channel models for IRS-reflected links to evaluate the
performance gain more precisely and practically. Specifically, we formulate an
optimization problem of maximizing the harvested power by jointly optimizing
dual-IRS phase shifts, independent PS ratio, and receive beamforming vector in
both near- and hybrid-field cases. In the near-field case, the alternating
optimization algorithm is proposed to solve the non-convex problem by applying
the Lagrange duality method and the difference-of-convex (DC) programming. In
the hybrid-field case, we first present an interesting result that the
AP-IRS-user channel gains are invariant to the phase shifts of dual-IRS, which
allows the optimization problem to be transformed into a convex one. Then, we
derive the asymptotic performance of the combined channel gains in closed-form
and analyze the characteristics of the dual-IRS. Numerical results validate our
analysis and indicate the performance gains of the proposed scheme that
dual-IRS-aided SWIPT with independent PS over other benchmark schemes.

</details>


### [3] [Towards Automated EEG-Based Detection Using Deep Convolutional Autoencoders](https://arxiv.org/abs/2508.20535)
*Annika Stiehl,Nicolas Weeger,Christian Uhl,Dominic Bechtold,Nicole Ille,Stefan Geißelsöder*

Main category: eess.SP

TL;DR: 该论文提出了一种深度卷积自编码器（DCAE），用于从EEG信号中提取低维潜在表示，以解决癫痫检测中高灵敏度和低误报率的需求。


<details>
  <summary>Details</summary>
Motivation: 癫痫是一种常见神经系统疾病，需要可靠高效的癫痫发作检测方法。现有深度学习方法在EEG信号分析中面临高灵敏度和低误报率的平衡问题，且缺乏统一的输入表示方式。

Method: 提出DCAE模型，结合时间和频域损失函数，提取EEG信号的低维潜在表示，并通过比较重建误差评估模型性能。

Result: 实验表明，结合时间和频域损失的DCAE模型在重建性能上表现最佳，证实单一信号表示可能无法保留所有相关信息。

Conclusion: 该研究为深度学习模型处理EEG数据提供了新见解，表明结合多域信息有助于更好地捕捉信号特征。

Abstract: Epilepsy is one of the most common neurological disorders. This disease
requires reliable and efficient seizure detection methods.
Electroencephalography (EEG) is the gold standard for seizure monitoring, but
its manual analysis is a time-consuming task that requires expert knowledge. In
addition, there are no well-defined features that allow fully automated
analysis. Existing deep learning-based approaches struggle to achieve high
sensitivity while maintaining a low false alarm rate per hour (FAR/h) and lack
consistency in the optimal EEG input representation, whether in the time or
frequency domain. To address these issues, we propose a Deep Convolutional
Autoencoder (DCAE) to extract low-dimensional latent representations that
preserve essential EEG signal features. The ability of the model to preserve
relevant information was evaluated by comparing reconstruction errors based on
both time series and frequency-domain representations. Several autoencoders
with different loss functions based on time and frequency were trained and
evaluated to determine their effectiveness in reconstructing EEG features. Our
results show that the DCAE model taking both time series and frequency losses
into account achieved the best reconstruction performance. This indicates that
Deep Neural Networks with a single representation might not preserve the
relevant signal properties. This work provides insight into how deep learning
models process EEG data and examines whether frequency information is captured
when time series signals are used as input.

</details>


### [4] [Removing motion artifacts from mechanomyographic signals: an innovative filtering method applied to human movement analysis](https://arxiv.org/abs/2508.20602)
*Matthieu Correa,Nicolas Vignais,Isabelle A. Siegler,Maxime Projetti*

Main category: eess.SP

TL;DR: 该研究提出了一种基于自适应滤波的肌动图(MMG)信号处理方法，有效减少运动伪影，但在行走或跑步时仍需谨慎解释信号。


<details>
  <summary>Details</summary>
Motivation: 肌动图(MMG)是一种有潜力的肌肉活动测量工具，但其对运动伪影的敏感性限制了其应用。

Method: 提出基于完全集合经验模态分解的自适应滤波方法，结合自适应噪声和谱模糊熵，动态隔离MMG信号中的运动伪影。

Result: 与传统带通滤波相比，新方法在三角肌和竖脊肌的运动重构上表现更优（R${}^2$ = 0.907和0.842），动态过滤5-20 Hz带宽内的伪影。

Conclusion: 新方法显著提升了MMG信号质量，但对躯干和下肢肌肉的MMG信号在行走或跑步时的解释仍需谨慎。

Abstract: Mechanomyography (MMG) is a promising tool for measuring muscle activity in
the field but its sensitivity to motion artifacts limits its application. In
this study, we proposed an adaptative filtering method for MMG accelerometers
based on the complete ensemble empirical mode decomposition, with adaptative
noise and spectral fuzzy entropy, to isolate motions artefacts from the MMG
signal in dynamic conditions. We compared our method with the traditional
band-pass filtering technique, demonstrating better results concerning motion
recomposition for deltoid and erector spinae muscles (R${}^2$ = 0.907 and
0.842). Thus, this innovative method allows the filtering of motion artifacts
dynamically in the 5-20 Hz bandwidth, which is not achievable with traditional
method. However, the interpretation of accelerometric MMG signals from the
trunk and lower-limb muscles during walking or running should be approached
with great caution as impact-related accelerations are still present, though
their exact quantity still needs to be quantified.

</details>


### [5] [Weighted Bayesian Cram$\acute{\text{e}}$r-Rao Bound for Mixed-Resolution Parameter Estimation](https://arxiv.org/abs/2508.20761)
*Yaniv Mazor,Tirza Routtenberg*

Main category: eess.SP

TL;DR: 研究了混合分辨率系统中的参数估计下界，提出了加权的贝叶斯Cramér-Rao界（WBCRB）及其在两种特殊情况下的应用，并通过分区方法近似MSE，验证了其在LGO模型中的有效性。


<details>
  <summary>Details</summary>
Motivation: 混合分辨率系统在降低硬件成本和功耗方面有优势，但粗量化数据引入了参数估计的复杂权衡，需要开发更准确的性能界限。

Method: 推导了混合分辨率设置下的WBCRB，并提出了基于分区的MSE近似方法，应用于线性高斯正交（LGO）模型。

Result: WBCRB优于经典BCRB，其基于BFIM-Inverse加权的版本接近最优WBCRB，MSE近似方法能准确预测量化误差下的非单调行为。

Conclusion: 提出的WBCRB和分区MSE近似方法在混合分辨率系统中表现出色，为实际信号处理应用提供了更准确的性能评估工具。

Abstract: Mixed-resolution architectures, combining high-resolution (analog) data with
coarsely quantized (e.g., 1-bit) data, are widely employed in emerging
communication and radar systems to reduce hardware costs and power consumption.
However, the use of coarsely quantized data introduces non-trivial tradeoffs in
parameter estimation tasks. In this paper, we investigate the derivation of
lower bounds for such systems. In particular, we develop the weighted Bayesian
Cramer-Rao bound (WBCRB) for the mixed-resolution setting with a general weight
function. We demonstrate the special cases of: (i) the classical BCRB; (ii) the
WBCRB that is based on the Bayesian Fisher information matrix (BFIM)-Inverse
weighting; and (iii) the Aharon-Tabrikian tightest WBCRB with an optimal weight
function. Based on the developed WBCRB, we propose a new method to approximate
the mean-squared-error (MSE) by partitioning the estimation problem into two
regions: (a) where the 1-bit quantized data is informative; and (b) where it is
saturated. We apply region-specific WBCRB approximations in these regions to
achieve an accurate composite MSE estimate. We derive the bounds and MSE
approximation for the linear Gaussian orthonormal (LGO) model, which is
commonly used in practical signal processing applications. Our simulation
results demonstrate the use of the proposed bounds and approximation method in
the LGO model with a scalar unknown parameter. It is shown that the WBCRB
outperforms the BCRB, where the BFIM-Inverse weighting version approaches the
optimal WBCRB. Moreover, it is shown that the WBCRB-based MSE approximation is
tighter and accurately predicts the non-monotonic behavior of the MSE in the
presence of quantization errors.

</details>


### [6] [Breaking Barriers in Health Monitoring: Multi-Scenario Vital Sign Detection Using Mm-Wave MIMO FMCW Radar](https://arxiv.org/abs/2508.20864)
*Ehsan Sadeghi,Paul Havinga*

Main category: eess.SP

TL;DR: 论文探讨了毫米波FMCW雷达在多场景下的生命体征检测，通过改进信号处理技术和提出Prony与MUSIC算法的变体，显著提高了非接触式监测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统传感方法在生命体征监测中存在局限性，尤其是非接触式监测的准确性和抗干扰能力不足。本研究旨在通过改进算法解决这些问题。

Method: 引入了Prony和MUSIC算法的变体，优化信号处理技术，以实时监测心率和呼吸频率，同时抑制噪声和谐波干扰。

Result: 在心率检测中，MUSIC和Prony的平均绝对误差分别为1.8和0.81；呼吸频率检测中，MAEs分别为1.01和0.8，证明了算法的优越性。

Conclusion: FMCW雷达结合改进算法具有成为临床和急救场景中可靠、非侵入性生命体征监测方案的潜力。

Abstract: This paper explores the deployment of mm-wave Frequency Modulated Continuous
Wave (FMCW) radar for vital sign detection across multiple scenarios. We focus
on overcoming the limitations of traditional sensing methods by enhancing
signal processing techniques to capture subtle physiological changes
effectively. Our study introduces novel adaptations of the Prony and MUSIC
algorithms tailored for real-time heart and respiration rate monitoring,
significantly advancing the accuracy and reliability of non-contact vital sign
monitoring using radar technologies. Notably, these algorithms demonstrate a
robust ability to suppress noise and harmonic interference. For instance, the
mean absolute errors (MAE) for MUSIC and Prony in heart rate detection are 1.8
and 0.81, respectively, while for respiration rate, the MAEs are 1.01 and 0.8,
respectively. These results underscore the potential of FMCW radar as a
reliable, non-invasive solution for continuous vital sign monitoring in
healthcare settings, particularly in clinical and emergency scenarios where
traditional contact-based monitoring is impractical.

</details>


### [7] [A Correction for the Paper "Symplectic geometry mode decomposition and its application to rotating machinery compound fault diagnosis"](https://arxiv.org/abs/2508.20990)
*Hong-Yan Zhang,Haoting Liu,Rui-Jia Lin,Yu Zhou*

Main category: eess.SP

TL;DR: 本文指出了SGMD方法的局限性，并通过回拉定理修复了计算时间序列分量的错误。


<details>
  <summary>Details</summary>
Motivation: SGMD方法在分解时间序列时虽基于SSA的DAP原则，但其轨迹矩阵形式未同步更新，因此存在缺陷。

Method: 通过回拉定理重新计算轨迹矩阵分量，以修复SGMD方法的局限性。

Result: 修复了SGMD方法的错误，使其更准确地分解时间序列。

Conclusion: 改进后的SGMD方法更加可靠，适用于时间序列分析。

Abstract: The symplectic geometry mode decomposition (SGMD) is a powerful method for
decomposing time series, which is based on the diagonal averaging principle
(DAP) inherited from the singular spectrum analysis (SSA). Although the authors
of SGMD method generalized the form of the trajectory matrix in SSA, the DAP is
not updated simultaneously. In this work, we pointed out the limitations of the
SGMD method and fixed the bugs with the pulling back theorem for computing the
given component of time series from the corresponding component of trajectory
matrix.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [8] [Learning Fast, Tool aware Collision Avoidance for Collaborative Robots](https://arxiv.org/abs/2508.20457)
*Joonho Lee,Yunho Kim,Seokjoon Kim,Quan Nguyen,Youngjin Heo*

Main category: cs.RO

TL;DR: 提出了一种实时调整工具大小和交互模式的碰撞避免系统，通过学习感知模型和强化学习控制策略，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在人机协作中，动态环境下机器人的安全和高效操作具有挑战性，现有控制器假设完全可见性和固定工具，导致碰撞或保守行为。

Method: 使用学习感知模型过滤点云中的机器人和工具部分，推断遮挡区域，预测碰撞，并通过约束强化学习训练的控制策略生成实时避障动作。

Result: 在仿真和实际测试中，系统在动态环境中优于传统方法（APF, MPPI），保持亚毫米精度，且计算成本降低60%。

Conclusion: 该系统为动态环境中的机器人提供了模块化、高效且有效的碰撞避免方案，并通过协作机器人应用证明了其实用性。

Abstract: Ensuring safe and efficient operation of collaborative robots in human
environments is challenging, especially in dynamic settings where both obstacle
motion and tasks change over time. Current robot controllers typically assume
full visibility and fixed tools, which can lead to collisions or overly
conservative behavior. In our work, we introduce a tool-aware collision
avoidance system that adjusts in real time to different tool sizes and modes of
tool-environment interaction. Using a learned perception model, our system
filters out robot and tool components from the point cloud, reasons about
occluded area, and predicts collision under partial observability. We then use
a control policy trained via constrained reinforcement learning to produce
smooth avoidance maneuvers in under 10 milliseconds. In simulated and
real-world tests, our approach outperforms traditional approaches (APF, MPPI)
in dynamic environments, while maintaining sub-millimeter accuracy. Moreover,
our system operates with approximately 60% lower computational cost compared to
a state-of-the-art GPU-based planner. Our approach provides modular, efficient,
and effective collision avoidance for robots operating in dynamic environments.
We integrate our method into a collaborative robot application and demonstrate
its practical use for safe and responsive operation.

</details>


### [9] [SPGrasp: Spatiotemporal Prompt-driven Grasp Synthesis in Dynamic Scenes](https://arxiv.org/abs/2508.20547)
*Yunpeng Mei,Hongjie Cao,Yinqiu Xia,Wei Xiao,Zhaohan Feng,Gang Wang,Jie Chen*

Main category: cs.RO

TL;DR: SPGrasp 是一个新型框架，通过结合用户提示与时空上下文，实现了动态物体的实时交互抓取合成，延迟低至 59 毫秒，并在多个数据集中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态物体抓取合成中难以同时实现低延迟和高互动性，SPGrasp 旨在解决这一矛盾。

Method: 扩展了 SAMv2 模型，整合用户提示与时空上下文，实现端到端的低延迟抓取估计。

Result: 在多个数据集上取得高准确率（如 Jacquard 的 93.8%），延迟显著降低（比 RoG-SAM 减少 58.5%），实际实验中抓取成功率达 94.8%。

Conclusion: SPGrasp 成功解决了动态抓取合成中的延迟与互动性之间的权衡问题。

Abstract: Real-time interactive grasp synthesis for dynamic objects remains challenging
as existing methods fail to achieve low-latency inference while maintaining
promptability. To bridge this gap, we propose SPGrasp (spatiotemporal
prompt-driven dynamic grasp synthesis), a novel framework extending segment
anything model v2 (SAMv2) for video stream grasp estimation. Our core
innovation integrates user prompts with spatiotemporal context, enabling
real-time interaction with end-to-end latency as low as 59 ms while ensuring
temporal consistency for dynamic objects. In benchmark evaluations, SPGrasp
achieves instance-level grasp accuracies of 90.6% on OCID and 93.8% on
Jacquard. On the challenging GraspNet-1Billion dataset under continuous
tracking, SPGrasp achieves 92.0% accuracy with 73.1 ms per-frame latency,
representing a 58.5% reduction compared to the prior state-of-the-art
promptable method RoG-SAM while maintaining competitive accuracy. Real-world
experiments involving 13 moving objects demonstrate a 94.8% success rate in
interactive grasping scenarios. These results confirm SPGrasp effectively
resolves the latency-interactivity trade-off in dynamic grasp synthesis. Code
is available at https://github.com/sejmoonwei/SPGrasp.

</details>


### [10] [SimShear: Sim-to-Real Shear-based Tactile Servoing](https://arxiv.org/abs/2508.20561)
*Kipp McAdam Freud,Yijiong Lin,Nathan F. Lepora*

Main category: cs.RO

TL;DR: SimShear是一个将模拟转换为现实的触觉控制流程，利用剪切信息而无需显式模拟剪切动力学。


<details>
  <summary>Details</summary>
Motivation: 剪切在动态物体交互任务中至关重要，但模拟剪切动力学具有挑战性。

Method: 提出shPix2pix，一种基于剪切条件的U-Net GAN，将无剪切模拟触觉图像与剪切信息转换为真实的剪切变形图像。

Result: 该方法在模拟触觉图像及姿态/剪切预测上优于基线pix2pix，成功应用于两个控制任务，接触误差保持在1-2毫米内。

Conclusion: SimShear验证了使用刚性体模拟器进行剪切建模的可行性，为触觉机器人模拟开辟了新方向。

Abstract: We present SimShear, a sim-to-real pipeline for tactile control that enables
the use of shear information without explicitly modeling shear dynamics in
simulation. Shear, arising from lateral movements across contact surfaces, is
critical for tasks involving dynamic object interactions but remains
challenging to simulate. To address this, we introduce shPix2pix, a
shear-conditioned U-Net GAN that transforms simulated tactile images absent of
shear, together with a vector encoding shear information, into realistic
equivalents with shear deformations. This method outperforms baseline pix2pix
approaches in simulating tactile images and in pose/shear prediction. We apply
SimShear to two control tasks using a pair of low-cost desktop robotic arms
equipped with a vision-based tactile sensor: (i) a tactile tracking task, where
a follower arm tracks a surface moved by a leader arm, and (ii) a collaborative
co-lifting task, where both arms jointly hold an object while the leader
follows a prescribed trajectory. Our method maintains contact errors within 1
to 2 mm across varied trajectories where shear sensing is essential, validating
the feasibility of sim-to-real shear modeling with rigid-body simulators and
opening new directions for simulation in tactile robotics.

</details>


### [11] [Traversing the Narrow Path: A Two-Stage Reinforcement Learning Framework for Humanoid Beam Walking](https://arxiv.org/abs/2508.20661)
*TianChen Huang,Wei Gao,Runchen Xu,Shiwu Zhang*

Main category: cs.RO

TL;DR: 提出了一种两阶段框架，结合了XCoM/LIPM步态模板和轻量级残余规划器，实现了人形机器人在狭窄梁上的可靠行走。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在狭窄梁上行走时接触稀疏、安全关键性强以及纯学习策略脆弱的问题。

Method: 采用两阶段方法：第一阶段在平地上训练跟踪器，第二阶段在梁上模拟训练高层规划器，优化步态模板。

Result: 在模拟和真实实验中，该方法在成功率、中心线跟随和安全裕度上优于基线方法。

Conclusion: 两阶段框架通过结构化步态接口实现了透明分析和低摩擦的模拟到现实迁移。

Abstract: Traversing narrow beams is challenging for humanoids due to sparse,
safety-critical contacts and the fragility of purely learned policies. We
propose a physically grounded, two-stage framework that couples an XCoM/LIPM
footstep template with a lightweight residual planner and a simple low-level
tracker. Stage-1 is trained on flat ground: the tracker learns to robustly
follow footstep targets by adding small random perturbations to heuristic
footsteps, without any hand-crafted centerline locking, so it acquires stable
contact scheduling and strong target-tracking robustness. Stage-2 is trained in
simulation on a beam: a high-level planner predicts a body-frame residual
(Delta x, Delta y, Delta psi) for the swing foot only, refining the template
step to prioritize safe, precise placement under narrow support while
preserving interpretability. To ease deployment, sensing is kept minimal and
consistent between simulation and hardware: the planner consumes compact,
forward-facing elevation cues together with onboard IMU and joint signals. On a
Unitree G1, our system reliably traverses a 0.2 m-wide, 3 m-long beam. Across
simulation and real-world studies, residual refinement consistently outperforms
template-only and monolithic baselines in success rate, centerline adherence,
and safety margins, while the structured footstep interface enables transparent
analysis and low-friction sim-to-real transfer.

</details>


### [12] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 论文提出了一种基于数字孪生的边缘辅助跨系统框架，解决了工业元宇宙中实时人机交互的高计算负载、带宽限制和严格延迟问题。通过预测操作员动作，支持主动元宇宙渲染和远程设备预控制，并在两种任务中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 工业元宇宙中的实时人机交互面临高计算负载、带宽限制和严格延迟等问题，亟需一种高效的解决方案。

Method: 采用数字孪生技术将系统解耦为视觉显示和机器人控制两个虚拟功能，并提出了HITL-MAML算法动态调整预测范围。

Result: 在轨迹绘制控制任务中，加权RMSE从0.0712米降至0.0101米；在核退役的3D场景表示任务中，PSNR为22.11，SSIM为0.8729，LPIPS为0.1298。

Conclusion: 所提出的框架在实时高风险工业环境中能确保空间精度和视觉保真度。

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


### [13] [Task Allocation for Autonomous Machines using Computational Intelligence and Deep Reinforcement Learning](https://arxiv.org/abs/2508.20688)
*Thanh Thi Nguyen,Quoc Viet Hung Nguyen,Jonathan Kua,Imran Razzak,Dung Nguyen,Saeid Nahavandi*

Main category: cs.RO

TL;DR: 本文综述了多自主机器协同控制算法，重点关注计算智能（CI）和深度强化学习（RL）在任务分配中的应用，分析其优缺点，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 开发高效的协同控制算法以实现多自主机器的可靠运行，尤其是在复杂环境中。

Method: 综述了CI和深度RL在任务分配中的方法，并分析了它们的优缺点。

Result: CI和深度RL能有效解决动态和不确定环境中的复杂任务分配问题，尤其是深度RL成为研究热点。

Conclusion: 本文为研究人员提供了自主机器学习研究的全面概览，并指出了未来的研究方向。

Abstract: Enabling multiple autonomous machines to perform reliably requires the
development of efficient cooperative control algorithms. This paper presents a
survey of algorithms that have been developed for controlling and coordinating
autonomous machines in complex environments. We especially focus on task
allocation methods using computational intelligence (CI) and deep reinforcement
learning (RL). The advantages and disadvantages of the surveyed methods are
analysed thoroughly. We also propose and discuss in detail various future
research directions that shed light on how to improve existing algorithms or
create new methods to enhance the employability and performance of autonomous
machines in real-world applications. The findings indicate that CI and deep RL
methods provide viable approaches to addressing complex task allocation
problems in dynamic and uncertain environments. The recent development of deep
RL has greatly contributed to the literature on controlling and coordinating
autonomous machines, and it has become a growing trend in this area. It is
envisaged that this paper will provide researchers and engineers with a
comprehensive overview of progress in machine learning research related to
autonomous machines. It also highlights underexplored areas, identifies
emerging methodologies, and suggests new avenues for exploration in future
research within this domain.

</details>


### [14] [Non-expert to Expert Motion Translation Using Generative Adversarial Networks](https://arxiv.org/abs/2508.20740)
*Yuki Tanaka,Seiichiro Katsura*

Main category: cs.RO

TL;DR: 论文提出了一种基于生成对抗网络的柔性运动翻译方法，旨在解决机器人技能传递中任务灵活性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 全球熟练工人减少是一个严重问题，技能从专家向机器人的传递成为研究重点。现有模仿学习方法在任务灵活性上存在不足。

Method: 使用生成对抗网络实现柔性运动翻译，允许用户通过输入数据和训练模型教授机器人任务和技能。

Result: 在3自由度书法机器人上进行了评估。

Conclusion: 该方法为提高机器人技能传递的灵活性和适应性提供了新思路。

Abstract: Decreasing skilled workers is a very serious problem in the world. To deal
with this problem, the skill transfer from experts to robots has been
researched. These methods which teach robots by human motion are called
imitation learning. Experts' skills generally appear in not only position data,
but also force data. Thus, position and force data need to be saved and
reproduced. To realize this, a lot of research has been conducted in the
framework of a motion-copying system. Recent research uses machine learning
methods to generate motion commands. However, most of them could not change
tasks by following human intention. Some of them can change tasks by
conditional training, but the labels are limited. Thus, we propose the flexible
motion translation method by using Generative Adversarial Networks. The
proposed method enables users to teach robots tasks by inputting data, and
skills by a trained model. We evaluated the proposed system with a 3-DOF
calligraphy robot.

</details>


### [15] [Uncertainty Aware-Predictive Control Barrier Functions: Safer Human Robot Interaction through Probabilistic Motion Forecasting](https://arxiv.org/abs/2508.20812)
*Lorenzo Busellato,Federico Cunico,Diego Dall'Alba,Marco Emporio,Andrea Giachetti,Riccardo Muradore,Marco Cristani*

Main category: cs.RO

TL;DR: UA-PCBFs结合概率预测和屏障控制，提升人机协作的安全性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决人机共享空间中的安全与效率冲突问题，避免传统方法的保守性和不灵活性。

Method: 提出不确定性感知预测控制屏障函数(UA-PCBFs)，结合人类动作概率预测和安全控制屏障。

Result: 实验表明UA-PCBFs减少安全空间冲突，提升任务性能和人机交互流畅度。

Conclusion: UA-PCBFs为安全高效的人机协作提供了新方法。

Abstract: To enable flexible, high-throughput automation in settings where people and
robots share workspaces, collaborative robotic cells must reconcile stringent
safety guarantees with the need for responsive and effective behavior. A
dynamic obstacle is the stochastic, task-dependent variability of human motion:
when robots fall back on purely reactive or worst-case envelopes, they brake
unnecessarily, stall task progress, and tamper with the fluidity that true
Human-Robot Interaction demands. In recent years, learning-based human-motion
prediction has rapidly advanced, although most approaches produce worst-case
scenario forecasts that often do not treat prediction uncertainty in a
well-structured way, resulting in over-conservative planning algorithms,
limiting their flexibility. We introduce Uncertainty-Aware Predictive Control
Barrier Functions (UA-PCBFs), a unified framework that fuses probabilistic
human hand motion forecasting with the formal safety guarantees of Control
Barrier Functions. In contrast to other variants, our framework allows for
dynamic adjustment of the safety margin thanks to the human motion uncertainty
estimation provided by a forecasting module. Thanks to uncertainty estimation,
UA-PCBFs empower collaborative robots with a deeper understanding of future
human states, facilitating more fluid and intelligent interactions through
informed motion planning. We validate UA-PCBFs through comprehensive real-world
experiments with an increasing level of realism, including automated setups (to
perform exactly repeatable motions) with a robotic hand and direct human-robot
interactions (to validate promptness, usability, and human confidence).
Relative to state-of-the-art HRI architectures, UA-PCBFs show better
performance in task-critical metrics, significantly reducing the number of
violations of the robot's safe space during interaction with respect to the
state-of-the-art.

</details>


### [16] [A Soft Fabric-Based Thermal Haptic Device for VR and Teleoperation](https://arxiv.org/abs/2508.20831)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 提出了一种新型织物基热触觉接口，用于虚拟现实和遥操作，集成了气动驱动和导电织物，重量轻，并能快速调节温度和压力。


<details>
  <summary>Details</summary>
Motivation: 为虚拟现实和遥操作提供一种轻量、高效的触觉反馈方案。

Method: 利用气动驱动和导电织物，设计超轻量化手指单元，嵌入加热元件实现动态热反馈。

Result: 快速温度调制（3°C/s）和高力输出（8.93 N），用户实验中温度识别准确率高（0.98），任务成功率显著提升。

Conclusion: 集成热触觉反馈显著提升了人机交互效果，适用于高级应用。

Abstract: This paper presents a novel fabric-based thermal-haptic interface for virtual
reality and teleoperation. It integrates pneumatic actuation and conductive
fabric with an innovative ultra-lightweight design, achieving only 2~g for each
finger unit. By embedding heating elements within textile pneumatic chambers,
the system delivers modulated pressure and thermal stimuli to fingerpads
through a fully soft, wearable interface.
  Comprehensive characterization demonstrates rapid thermal modulation with
heating rates up to 3$^{\circ}$C/s, enabling dynamic thermal feedback for
virtual or teleoperation interactions. The pneumatic subsystem generates forces
up to 8.93~N at 50~kPa, while optimization of fingerpad-actuator clearance
enhances cooling efficiency with minimal force reduction. Experimental
validation conducted with two different user studies shows high temperature
identification accuracy (0.98 overall) across three thermal levels, and
significant manipulation improvements in a virtual pick-and-place tasks.
Results show enhanced success rates (88.5\% to 96.4\%, p = 0.029) and improved
force control precision (p = 0.013) when haptic feedback is enabled, validating
the effectiveness of the integrated thermal-haptic approach for advanced
human-machine interaction applications.

</details>


### [17] [Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration](https://arxiv.org/abs/2508.20836)
*Ahmed A. Elgohary,Rohan Palanikumar,Sameh A. Eisa*

Main category: cs.RO

TL;DR: 提出了一种新的极值搜索控制（ESC）方法，模拟昆虫和蜂鸟的悬停和源寻找现象，并在实验中验证其在扑翼机器人中的模型自由、实时控制潜力。


<details>
  <summary>Details</summary>
Motivation: 探索扑翼系统的悬停和源寻找物理学，提供一种无需模型的实时仿生控制设计方法。

Method: 使用极值搜索控制（ESC）方法，首次在实验中对扑翼机器人进行模型自由、实时的悬停和源寻找控制测试。

Result: 实验结果（限于1D）证实了ESC作为扑翼飞行和机器人领域自然控制方法和仿生机制的潜力。

Conclusion: ESC是一种有效的仿生控制方法，适用于扑翼机器人的实时控制。

Abstract: In a recent effort, we successfully proposed a categorically novel approach
to mimic the phenomenoa of hovering and source seeking by flapping insects and
hummingbirds using a new extremum seeking control (ESC) approach. Said ESC
approach was shown capable of characterizing the physics of hovering and source
seeking by flapping systems, providing at the same time uniquely novel
opportunity for a model-free, real-time biomimicry control design. In this
paper, we experimentally test and verify, for the first time in the literature,
the potential of ESC in flapping robots to achieve model-free, real-time
controlled hovering and source seeking. The results of this paper, while being
restricted to 1D, confirm the premise of introducing ESC as a natural control
method and biomimicry mechanism to the field of flapping flight and robotics.

</details>


### [18] [Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing](https://arxiv.org/abs/2508.20959)
*Curtis C. Johnson,Daniel Webb,David Hill,Marc D. Killpack*

Main category: cs.RO

TL;DR: 摘要提出了一种用于大规模触觉感知的完整架构，通过硬件和拓扑设计解决了布线复杂性和数据吞吐量问题，实现了实时控制，并在抓取任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决触觉感知在大规模应用中面临的布线复杂性、数据吞吐量和系统可靠性等挑战。

Method: 结合开源织物传感器和定制电子读取技术，减少信号串扰，并引入新型菊花链SPI总线拓扑。

Result: 系统能够实时同步传输超过8,000个传感器数据，更新率超过50 FPS，成功应用于稳定抓取任务。

Conclusion: 该架构为未来全身控制和物理人机交互研究提供了可靠的技术平台。

Abstract: Scaling tactile sensing for robust whole-body manipulation is a significant
challenge, often limited by wiring complexity, data throughput, and system
reliability. This paper presents a complete architecture designed to overcome
these barriers. Our approach pairs open-source, fabric-based sensors with
custom readout electronics that reduce signal crosstalk to less than 3.3%
through hardware-based mitigation. Critically, we introduce a novel,
daisy-chained SPI bus topology that avoids the practical limitations of common
wireless protocols and the prohibitive wiring complexity of USB hub-based
systems. This architecture streams synchronized data from over 8,000 taxels
across 1 square meter of sensing area at update rates exceeding 50 FPS,
confirming its suitability for real-time control. We validate the system's
efficacy in a whole-body grasping task where, without feedback, the robot's
open-loop trajectory results in an uncontrolled application of force that
slowly crushes a deformable cardboard box. With real-time tactile feedback, the
robot transforms this motion into a gentle, stable grasp, successfully
manipulating the object without causing structural damage. This work provides a
robust and well-characterized platform to enable future research in advanced
whole-body control and physical human-robot interaction.

</details>


### [19] [Learning Primitive Embodied World Models: Towards Scalable Robotic Learning](https://arxiv.org/abs/2508.20840)
*Qiao Sun,Liujia Yang,Wei Tang,Wei Huang,Kaixin Xu,Yongchao Chen,Mingyu Liu,Jiange Yang,Haoyi Zhu,Yating Wang,Tong He,Yilun Chen,Xili Dai,Nanyang Ye,Qinying Gu*

Main category: cs.RO

TL;DR: 论文提出了一种新的世界建模范式——原始具身世界模型（PEWM），通过限制视频生成的短时范围，解决了具身数据稀缺、高维度和收集困难的问题，提高了语言与动作的对齐细粒度，降低了学习复杂性和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 具身世界模型依赖大规模具身交互数据，但这些数据的稀缺、高维度和难以收集限制了语言与动作的对齐细粒度，并增加了长时视频生成的难度。

Method: PEWM通过限制视频生成到固定短时范围，结合模块化视觉语言模型（VLM）规划器和起点-目标热图引导机制（SGG），实现了精细的语言-视觉对齐、降低学习复杂度并提高数据效率。

Result: PEWM能够灵活地进行闭环控制，支持原始级策略在复杂任务中的组合泛化，并利用视频模型的时间空间先验和视觉语言模型的语义感知能力，弥合细粒度物理交互与高层推理之间的差距。

Conclusion: PEWM为解决具身智能的可扩展性、可解释性和通用性问题提供了新途径。

Abstract: While video-generation-based embodied world models have gained increasing
attention, their reliance on large-scale embodied interaction data remains a
key bottleneck. The scarcity, difficulty of collection, and high dimensionality
of embodied data fundamentally limit the alignment granularity between language
and actions and exacerbate the challenge of long-horizon video
generation--hindering generative models from achieving a "GPT moment" in the
embodied domain. There is a naive observation: the diversity of embodied data
far exceeds the relatively small space of possible primitive motions. Based on
this insight, we propose a novel paradigm for world modeling--Primitive
Embodied World Models (PEWM). By restricting video generation to fixed short
horizons, our approach 1) enables fine-grained alignment between linguistic
concepts and visual representations of robotic actions, 2) reduces learning
complexity, 3) improves data efficiency in embodied data collection, and 4)
decreases inference latency. By equipping with a modular Vision-Language Model
(VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further
enables flexible closed-loop control and supports compositional generalization
of primitive-level policies over extended, complex tasks. Our framework
leverages the spatiotemporal vision priors in video models and the semantic
awareness of VLMs to bridge the gap between fine-grained physical interaction
and high-level reasoning, paving the way toward scalable, interpretable, and
general-purpose embodied intelligence.

</details>


### [20] [Genetic Informed Trees (GIT*): Path Planning via Reinforced Genetic Programming Heuristics](https://arxiv.org/abs/2508.20871)
*Liding Zhang,Kuanqi Cai,Zhenshan Bing,Chaoqun Wang,Alois Knoll*

Main category: cs.RO

TL;DR: GIT*算法通过整合更多环境数据优化启发式函数，结合RGP提升计算效率和路径规划质量，在多种维度问题中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法常忽视环境数据并简化启发式函数结构，限制了搜索效率和解决方案质量。

Method: 提出GIT*算法，整合环境数据改进EIT*，并引入RGP通过遗传编程和奖励反馈优化启发式函数。

Result: GIT*在多维问题（R^4到R^16）和现实任务中表现优于现有单查询采样规划器。

Conclusion: GIT*结合RGP显著提升路径规划的计算效率和解决方案质量，适用性强。

Abstract: Optimal path planning involves finding a feasible state sequence between a
start and a goal that optimizes an objective. This process relies on heuristic
functions to guide the search direction. While a robust function can improve
search efficiency and solution quality, current methods often overlook
available environmental data and simplify the function structure due to the
complexity of information relationships. This study introduces Genetic Informed
Trees (GIT*), which improves upon Effort Informed Trees (EIT*) by integrating a
wider array of environmental data, such as repulsive forces from obstacles and
the dynamic importance of vertices, to refine heuristic functions for better
guidance. Furthermore, we integrated reinforced genetic programming (RGP),
which combines genetic programming with reward system feedback to mutate
genotype-generative heuristic functions for GIT*. RGP leverages a multitude of
data types, thereby improving computational efficiency and solution quality
within a set timeframe. Comparative analyses demonstrate that GIT* surpasses
existing single-query, sampling-based planners in problems ranging from R^4 to
R^16 and was tested on a real-world mobile manipulation task. A video
showcasing our experimental results is available at
https://youtu.be/URjXbc_BiYg

</details>


### [21] [Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning](https://arxiv.org/abs/2508.20884)
*Liding Zhang,Qiyang Zong,Yu Zhang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 介绍了一种基于深度模糊神经网络的运动规划算法LIT*，通过动态调整参数提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划算法缺乏对环境适应性的动态调整能力。

Method: 采用深度模糊神经网络和采样方法，动态调整批量大小和最近邻参数。

Result: LIT*在高维空间中表现优异，收敛更快且路径成本更低。

Conclusion: LIT*是一种高效的动态规划方法，适用于复杂环境。

Abstract: Efficient motion planning algorithms are essential in robotics. Optimizing
essential parameters, such as batch size and nearest neighbor selection in
sampling-based methods, can enhance performance in the planning process.
However, existing approaches often lack environmental adaptability. Inspired by
the method of the deep fuzzy neural networks, this work introduces
Learning-based Informed Trees (LIT*), a sampling-based deep fuzzy
learning-based planner that dynamically adjusts batch size and nearest neighbor
parameters to obstacle distributions in the configuration spaces. By encoding
both global and local ratios via valid and invalid states, LIT* differentiates
between obstacle-sparse and obstacle-dense regions, leading to lower-cost paths
and reduced computation time. Experimental results in high-dimensional spaces
demonstrate that LIT* achieves faster convergence and improved solution
quality. It outperforms state-of-the-art single-query, sampling-based planners
in environments ranging from R^8 to R^14 and is successfully validated on a
dual-arm robot manipulation task. A video showcasing our experimental results
is available at: https://youtu.be/NrNs9zebWWk

</details>


### [22] [CoCoL: A Communication Efficient Decentralized Collaborative Method for Multi-Robot Systems](https://arxiv.org/abs/2508.20898)
*Jiaxi Huang,Yan Huang,Yixian Zhao,Wenchao Meng,Jinming Xu*

Main category: cs.RO

TL;DR: CoCoL是一种高效通信的分散协作学习方法，专为多机器人系统设计，通过近似牛顿更新和梯度跟踪方案减少通信和计算成本，并在非IID数据等挑战性场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统的协作学习面临通信开销高和数据异构性的挑战，需要一种高效的协作学习方法。

Method: CoCoL采用镜像下降框架，利用近似牛顿更新捕捉机器人目标函数的相似性，并通过梯度跟踪方案增强对数据异构性的鲁棒性。

Result: 实验表明，CoCoL显著减少了通信轮数和总带宽消耗，同时保持了先进的准确性，尤其在非IID数据等复杂场景中表现优异。

Conclusion: CoCoL为多机器人系统协作学习提供了一种高效且鲁棒的解决方案，适用于复杂的数据和网络环境。

Abstract: Collaborative learning enhances the performance and adaptability of
multi-robot systems in complex tasks but faces significant challenges due to
high communication overhead and data heterogeneity inherent in multi-robot
tasks. To this end, we propose CoCoL, a Communication efficient decentralized
Collaborative Learning method tailored for multi-robot systems with
heterogeneous local datasets. Leveraging a mirror descent framework, CoCoL
achieves remarkable communication efficiency with approximate Newton-type
updates by capturing the similarity between objective functions of robots, and
reduces computational costs through inexact sub-problem solutions. Furthermore,
the integration of a gradient tracking scheme ensures its robustness against
data heterogeneity. Experimental results on three representative multi robot
collaborative learning tasks show the superiority of the proposed CoCoL in
significantly reducing both the number of communication rounds and total
bandwidth consumption while maintaining state-of-the-art accuracy. These
benefits are particularly evident in challenging scenarios involving non-IID
(non-independent and identically distributed) data distribution, streaming
data, and time-varying network topologies.

</details>


### [23] [Language-Enhanced Mobile Manipulation for Efficient Object Search in Indoor Environments](https://arxiv.org/abs/2508.20899)
*Liding Zhang,Zeqi Li,Kuanqi Cai,Qian Huang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 提出了一个语言增强的分层导航框架（GODHS），结合语义感知和空间推理，利用大语言模型（LLMs）推断场景语义并通过多层决策层次引导搜索过程。


<details>
  <summary>Details</summary>
Motivation: 传统场景表示缺乏动态语义和可解释的上下文推理能力，难以在陌生环境中高效搜索目标对象。

Method: 使用结构化提示和逻辑约束的分层决策框架，结合启发式运动规划器，生成高效探索路径。

Result: 在Isaac Sim中的实验表明，GODHS比传统非语义搜索策略更高效。

Conclusion: GODHS通过语言增强的语义推理显著提升了复杂环境中对象搜索的效率和可靠性。

Abstract: Enabling robots to efficiently search for and identify objects in complex,
unstructured environments is critical for diverse applications ranging from
household assistance to industrial automation. However, traditional scene
representations typically capture only static semantics and lack interpretable
contextual reasoning, limiting their ability to guide object search in
completely unfamiliar settings. To address this challenge, we propose a
language-enhanced hierarchical navigation framework that tightly integrates
semantic perception and spatial reasoning. Our method, Goal-Oriented
Dynamically Heuristic-Guided Hierarchical Search (GODHS), leverages large
language models (LLMs) to infer scene semantics and guide the search process
through a multi-level decision hierarchy. Reliability in reasoning is achieved
through the use of structured prompts and logical constraints applied at each
stage of the hierarchy. For the specific challenges of mobile manipulation, we
introduce a heuristic-based motion planner that combines polar angle sorting
with distance prioritization to efficiently generate exploration paths.
Comprehensive evaluations in Isaac Sim demonstrate the feasibility of our
framework, showing that GODHS can locate target objects with higher search
efficiency compared to conventional, non-semantic search strategies. Website
and Video are available at: https://drapandiger.github.io/GODHS

</details>


### [24] [PLUME: Procedural Layer Underground Modeling Engine](https://arxiv.org/abs/2508.20926)
*Gabriel Manuel Garcia,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: PLUME是一个用于生成3D地下环境的开源框架，旨在支持太空探索中的AI训练、机器人算法评估等。


<details>
  <summary>Details</summary>
Motivation: 地下环境在太空探索中具有重要潜力，但地球上的类似环境难以准确代表太阳系的多样性。

Method: 提出PLUME框架，通过灵活的流程生成多样化地下环境，支持持续改进。

Result: PLUME已与机器人模拟器结合使用，开源发布在Github上。

Conclusion: PLUME为地下环境研究提供了高效工具，支持多领域应用。

Abstract: As space exploration advances, underground environments are becoming
increasingly attractive due to their potential to provide shelter, easier
access to resources, and enhanced scientific opportunities. Although such
environments exist on Earth, they are often not easily accessible and do not
accurately represent the diversity of underground environments found throughout
the solar system. This paper presents PLUME, a procedural generation framework
aimed at easily creating 3D underground environments. Its flexible structure
allows for the continuous enhancement of various underground features, aligning
with our expanding understanding of the solar system. The environments
generated using PLUME can be used for AI training, evaluating robotics
algorithms, 3D rendering, and facilitating rapid iteration on developed
exploration algorithms. In this paper, it is demonstrated that PLUME has been
used along with a robotic simulator. PLUME is open source and has been released
on Github. https://github.com/Gabryss/P.L.U.M.E

</details>


### [25] [ActLoc: Learning to Localize on the Move via Active Viewpoint Selection](https://arxiv.org/abs/2508.20981)
*Jiajie Li,Boyang Sun,Luca Di Giammarino,Hermann Blum,Marc Pollefeys*

Main category: cs.RO

TL;DR: ActLoc是一种主动视角感知规划框架，通过选择最佳视角提升机器人导航的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有定位系统假设所有视角信息量均等，但实践中遇到未映射、模糊或无信息区域时定位不可靠。

Method: ActLoc利用基于注意力的模型预测3D位置各视角的定位精度分布，并将其集成到路径规划中。

Result: ActLoc在单视角选择和完整轨迹规划中均表现出色，适用于多种导航任务。

Conclusion: ActLoc通过主动视角规划显著提升定位可靠性，具有模块化设计和广泛适用性。

Abstract: Reliable localization is critical for robot navigation, yet most existing
systems implicitly assume that all viewing directions at a location are equally
informative. In practice, localization becomes unreliable when the robot
observes unmapped, ambiguous, or uninformative regions. To address this, we
present ActLoc, an active viewpoint-aware planning framework for enhancing
localization accuracy for general robot navigation tasks. At its core, ActLoc
employs a largescale trained attention-based model for viewpoint selection. The
model encodes a metric map and the camera poses used during map construction,
and predicts localization accuracy across yaw and pitch directions at arbitrary
3D locations. These per-point accuracy distributions are incorporated into a
path planner, enabling the robot to actively select camera orientations that
maximize localization robustness while respecting task and motion constraints.
ActLoc achieves stateof-the-art results on single-viewpoint selection and
generalizes effectively to fulltrajectory planning. Its modular design makes it
readily applicable to diverse robot navigation and inspection tasks.

</details>


### [26] [UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception](https://arxiv.org/abs/2508.20982)
*Junhao Gong,Kit-Wa Sou,Shoujie Li,Changqing Guo,Yan Huang,Chuqiao Lyu,Ziwu Song,Wenbo Ding*

Main category: cs.RO

TL;DR: UltraTac传感器结合视觉触觉成像和超声波传感，通过同轴光声架构实现材料特征感知，具备近距传感、材料分类和双模式物体识别能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉触觉传感器无法感知物体材料特征的问题。

Method: 采用同轴光声架构，结合视觉触觉成像与超声波传感，并通过声学匹配设计实现双模态集成。

Result: 实验验证了传感器的近距传感（3-8 cm，R²=0.90）、材料分类（平均准确率99.20%）和双模式物体识别（15类任务准确率92.11%）。

Conclusion: UltraTac传感器在高级人机交互和精准机器人操作中显示出潜力。

Abstract: Visuotactile sensors provide high-resolution tactile information but are
incapable of perceiving the material features of objects. We present UltraTac,
an integrated sensor that combines visuotactile imaging with ultrasound sensing
through a coaxial optoacoustic architecture. The design shares structural
components and achieves consistent sensing regions for both modalities.
Additionally, we incorporate acoustic matching into the traditional
visuotactile sensor structure, enabling integration of the ultrasound sensing
modality without compromising visuotactile performance. Through tactile
feedback, we dynamically adjust the operating state of the ultrasound module to
achieve flexible functional coordination. Systematic experiments demonstrate
three key capabilities: proximity sensing in the 3-8 cm range ($R^2=0.90$),
material classification (average accuracy: 99.20%), and texture-material
dual-mode object recognition achieving 92.11% accuracy on a 15-class task.
Finally, we integrate the sensor into a robotic manipulation system to
concurrently detect container surface patterns and internal content, which
verifies its potential for advanced human-machine interaction and precise
robotic manipulation.

</details>


### [27] [Rapid Mismatch Estimation via Neural Network Informed Variational Inference](https://arxiv.org/abs/2508.21007)
*Mateusz Jaszczuk,Nadia Figueroa*

Main category: cs.RO

TL;DR: 论文提出了一种名为Rapid Mismatch Estimation (RME)的自适应框架，用于在线估计机器人末端执行器的动力学不匹配问题，提升物理交互的安全性和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在人类环境中的广泛应用，确保机器人与人类、环境或其他机器之间的柔软和安全物理交互变得至关重要。现有的方法依赖于精确的动力学模型，模型不匹配会导致任务失败和不安全行为。

Method: RME是一个控制器无关的概率框架，通过机器人本体反馈，结合神经网络模型不匹配估计器和变分推断求解器，在线快速估计未知参数并量化不确定性。

Result: 实验表明，RME能在约400毫秒内适应末端执行器的质量和质心突变，并在动态协作场景中表现出快速且安全的适应性。

Conclusion: RME为机器人在物理交互中动态适应变化提供了一种高效、安全且无需外部传感器的解决方案。

Abstract: With robots increasingly operating in human-centric environments, ensuring
soft and safe physical interactions, whether with humans, surroundings, or
other machines, is essential. While compliant hardware can facilitate such
interactions, this work focuses on impedance controllers that allow
torque-controlled robots to safely and passively respond to contact while
accurately executing tasks. From inverse dynamics to quadratic
programming-based controllers, the effectiveness of these methods relies on
accurate dynamics models of the robot and the object it manipulates. Any model
mismatch results in task failures and unsafe behaviors. Thus, we introduce
Rapid Mismatch Estimation (RME), an adaptive, controller-agnostic,
probabilistic framework that estimates end-effector dynamics mismatches online,
without relying on external force-torque sensors. From the robot's
proprioceptive feedback, a Neural Network Model Mismatch Estimator generates a
prior for a Variational Inference solver, which rapidly converges to the
unknown parameters while quantifying uncertainty. With a real 7-DoF manipulator
driven by a state-of-the-art passive impedance controller, RME adapts to sudden
changes in mass and center of mass at the end-effector in $\sim400$ ms, in
static and dynamic settings. We demonstrate RME in a collaborative scenario
where a human attaches an unknown basket to the robot's end-effector and
dynamically adds/removes heavy items, showcasing fast and safe adaptation to
changing dynamics during physical interaction without any external sensory
system.

</details>


### [28] [HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning](https://arxiv.org/abs/2508.21043)
*Zhi Su,Bike Zhang,Nima Rahmanian,Yuman Gao,Qiayuan Liao,Caitlin Regan,Koushil Sreenath,S. Shankar Sastry*

Main category: cs.RO

TL;DR: 该论文提出了一种分层框架，通过模型规划器和强化学习控制器结合，实现了人形机器人在快速动态环境中的乒乓球运动控制，并展示了在实际中的成功应用。


<details>
  <summary>Details</summary>
Motivation: 为了提升人形机器人在动态环境中的快速交互能力，特别是如乒乓球这类高要求的任务，论文旨在解决高反应速度和精确性的挑战。

Method: 采用分层框架，结合基于模型的预测器和强化学习控制器，规划球轨迹和击球动作，并通过训练中引入人类动作参考生成自然运动。

Result: 实验验证中，机器人与人类对打时实现了106次连续击球，并能与其他机器人持续对打，展示了秒级反应控制的能力。

Conclusion: 该方法为人形机器人实现敏捷和交互行为提供了重要进展。

Abstract: Humanoid robots have recently achieved impressive progress in locomotion and
whole-body control, yet they remain constrained in tasks that demand rapid
interaction with dynamic environments through manipulation. Table tennis
exemplifies such a challenge: with ball speeds exceeding 5 m/s, players must
perceive, predict, and act within sub-second reaction times, requiring both
agility and precision. To address this, we present a hierarchical framework for
humanoid table tennis that integrates a model-based planner for ball trajectory
prediction and racket target planning with a reinforcement learning-based
whole-body controller. The planner determines striking position, velocity and
timing, while the controller generates coordinated arm and leg motions that
mimic human strikes and maintain stability and agility across consecutive
rallies. Moreover, to encourage natural movements, human motion references are
incorporated during training. We validate our system on a general-purpose
humanoid robot, achieving up to 106 consecutive shots with a human opponent and
sustained exchanges against another humanoid. These results demonstrate
real-world humanoid table tennis with sub-second reactive control, marking a
step toward agile and interactive humanoid behaviors.

</details>


### [29] [Prompt-to-Product: Generative Assembly via Bimanual Manipulation](https://arxiv.org/abs/2508.21063)
*Ruixuan Liu,Philip Huang,Ava Pun,Kangle Deng,Shobhit Aggarwal,Kevin Tang,Michelle Liu,Deva Ramanan,Jun-Yan Zhu,Jiaoyang Li,Changliu Liu*

Main category: cs.RO

TL;DR: 该论文提出了一种名为Prompt-to-Product的自动化流程，通过自然语言提示生成现实世界的组装产品。


<details>
  <summary>Details</summary>
Motivation: 传统的组装产品设计需要大量手动工作和专业知识，限制了创意实现的门槛。

Method: 利用LEGO积木作为组装平台，自动化生成可物理构建的设计，并通过双臂机器人系统实现实际组装。

Result: 用户研究显示，该方法显著降低了从想象中创建组装产品的门槛和手动工作量。

Conclusion: Prompt-to-Product有效地将用户想象转化为现实产品，简化了组装过程的复杂性。

Abstract: Creating assembly products demands significant manual effort and expert
knowledge in 1) designing the assembly and 2) constructing the product. This
paper introduces Prompt-to-Product, an automated pipeline that generates
real-world assembly products from natural language prompts. Specifically, we
leverage LEGO bricks as the assembly platform and automate the process of
creating brick assembly structures. Given the user design requirements,
Prompt-to-Product generates physically buildable brick designs, and then
leverages a bimanual robotic system to construct the real assembly products,
bringing user imaginations into the real world. We conduct a comprehensive user
study, and the results demonstrate that Prompt-to-Product significantly lowers
the barrier and reduces manual effort in creating assembly products from
imaginative ideas.

</details>


### [30] [Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation](https://arxiv.org/abs/2508.21065)
*Jiahe Pan,Jiaxu Xing,Rudolf Reiter,Yifan Zhai,Elie Aljalbout,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出了一种在线自适应学习框架，用于快速调整机器人控制策略以适应现实世界的动态变化。


<details>
  <summary>Details</summary>
Motivation: 现有的方法（如域随机化和Real2Sim2Real）在应对非分布条件时需要昂贵的离线重新训练或效果不佳。

Method: 结合残差动力学学习和实时策略调整，通过可微分仿真框架实现梯度反向传播。

Result: 在5秒内完成策略调整，减少了高达81%的悬停误差，并在视觉控制中表现出鲁棒性。

Conclusion: 该框架显著提升了策略在现实世界中的适应性和性能。

Abstract: Learning control policies in simulation enables rapid, safe, and
cost-effective development of advanced robotic capabilities. However,
transferring these policies to the real world remains difficult due to the
sim-to-real gap, where unmodeled dynamics and environmental disturbances can
degrade policy performance. Existing approaches, such as domain randomization
and Real2Sim2Real pipelines, can improve policy robustness, but either struggle
under out-of-distribution conditions or require costly offline retraining. In
this work, we approach these problems from a different perspective. Instead of
relying on diverse training conditions before deployment, we focus on rapidly
adapting the learned policy in the real world in an online fashion. To achieve
this, we propose a novel online adaptive learning framework that unifies
residual dynamics learning with real-time policy adaptation inside a
differentiable simulation. Starting from a simple dynamics model, our framework
refines the model continuously with real-world data to capture unmodeled
effects and disturbances such as payload changes and wind. The refined dynamics
model is embedded in a differentiable simulation framework, enabling gradient
backpropagation through the dynamics and thus rapid, sample-efficient policy
updates beyond the reach of classical RL methods like PPO. All components of
our system are designed for rapid adaptation, enabling the policy to adjust to
unseen disturbances within 5 seconds of training. We validate the approach on
agile quadrotor control under various disturbances in both simulation and the
real world. Our framework reduces hovering error by up to 81% compared to
L1-MPC and 55% compared to DATT, while also demonstrating robustness in
vision-based control without explicit state estimation.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [31] [Electrical Impedance Tomography with an Integrated Picoliter-Volume Subtractive Microfluidic Chamber in 65 nm CMOS](https://arxiv.org/abs/2508.20431)
*Antonio Victor Machado de Oliveira,Debjit Sarkar,Ali Hajimiri*

Main category: physics.ins-det

TL;DR: 首次在CMOS芯片中实现了完全集成的微流控与电子学的电阻抗成像技术，能够在皮升体积中进行处理和成像。


<details>
  <summary>Details</summary>
Motivation: 探索CMOS作为微流控与电子学共集成平台的潜力。

Method: 在65纳米CMOS芯片的后处理中制作腔室和电极，通过16电极阵列读取电压数据并离片处理。

Result: 成功实现了皮升体积的电阻抗成像，并分析了重建中的变化源。

Conclusion: 该系统为CMOS作为共集成微流控与电子学平台的可行性提供了概念验证。

Abstract: Electrical impedance tomography with fully integrated microfluidics and
electronics is presented for the first time in a CMOS chip. Chambers and
electrodes are fabricated in the interconnect layers of a 65 nm CMOS chip
through post-processing, enabling picoliter-volumes to be processed and imaged.
Tomography maps are reconstructed by reading out voltages from a 16-element
electrode array and processing the data off-chip, and sources of variation in
reconstruction are discussed. The EIT system presented in this work serves as a
proof-of-concept towards using CMOS as a platform for co-integrated
microfluidics and electronics.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [32] [Encoding Tactile Stimuli for Organoid Intelligence in Braille Recognition](https://arxiv.org/abs/2508.20850)
*Tianyi Liu,Hemma Philamore,Benjamin Ward-Cherrier*

Main category: cs.NE

TL;DR: 该研究提出了一种将触觉传感器数据映射到电刺激模式的通用编码策略，使神经类器官能够完成开环人工触觉盲文分类任务。


<details>
  <summary>Details</summary>
Motivation: 探索类器官作为低功耗、适应性强的生物混合计算元件的潜力，并为未来可扩展的生物混合计算架构提供编码框架。

Method: 通过在低密度微电极阵列（MEA）上培养的人类前脑类器官，系统地施加电刺激，分析刺激参数与类器官响应（如放电活动和活动中心的空间位移）之间的关系。

Result: 单类器官的盲文字母分类平均准确率为61%，而三器官组合的准确率显著提升至83%。多器官配置还表现出对人工引入噪声的更强鲁棒性。

Conclusion: 该研究展示了类器官作为生物混合计算元件的潜力，并提供了一个可扩展的生物混合计算编码框架。

Abstract: This study proposes a generalizable encoding strategy that maps tactile
sensor data to electrical stimulation patterns, enabling neural organoids to
perform an open-loop artificial tactile Braille classification task. Human
forebrain organoids cultured on a low-density microelectrode array (MEA) are
systematically stimulated to characterize the relationship between electrical
stimulation parameters (number of pulse, phase amplitude, phase duration, and
trigger delay) and organoid responses, measured as spike activity and spatial
displacement of the center of activity. Implemented on event-based tactile
inputs recorded from the Evetac sensor, our system achieved an average Braille
letter classification accuracy of 61 percent with a single organoid, which
increased significantly to 83 percent when responses from a three-organoid
ensemble were combined. Additionally, the multi-organoid configuration
demonstrated enhanced robustness against various types of artificially
introduced noise. This research demonstrates the potential of organoids as
low-power, adaptive bio-hybrid computational elements and provides a
foundational encoding framework for future scalable bio-hybrid computing
architectures.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [33] [Adaptive Segmentation of EEG for Machine Learning Applications](https://arxiv.org/abs/2508.20336)
*Johnson Zhou,Joseph West,Krista A. Ehinger,Zhenming Ren,Sam E. John,David B. Grayden*

Main category: cs.LG

TL;DR: 本文介绍了一种新型自适应分割方法CTXSEG，用于EEG信号预处理，相比固定长度分割方法，提高了癫痫检测性能，且适用于现代机器学习。


<details>
  <summary>Details</summary>
Motivation: 现有EEG信号预处理采用固定时间切片，缺乏生物相关性，而大脑状态并非固定间隔。研究自适应分割方法是否能提升机器学习EEG分析效果。

Method: 提出CTXSEG方法，基于EEG数据的统计差异生成可变长度分段，并通过可控合成数据和真实癫痫检测案例验证其性能。

Result: CTXSEG在标准化框架下显著提升了癫痫检测性能，且所需分段更少，无需修改机器学习方法。

Conclusion: CTXSEG是一种有前景的EEG信号预处理替代方案，可直接应用于现代机器学习，提升性能。

Abstract: Objective. Electroencephalography (EEG) data is derived by sampling
continuous neurological time series signals. In order to prepare EEG signals
for machine learning, the signal must be divided into manageable segments. The
current naive approach uses arbitrary fixed time slices, which may have limited
biological relevance because brain states are not confined to fixed intervals.
We investigate whether adaptive segmentation methods are beneficial for machine
learning EEG analysis.
  Approach. We introduce a novel adaptive segmentation method, CTXSEG, that
creates variable-length segments based on statistical differences in the EEG
data and propose ways to use them with modern machine learning approaches that
typically require fixed-length input. We assess CTXSEG using controllable
synthetic data generated by our novel signal generator CTXGEN. While our CTXSEG
method has general utility, we validate it on a real-world use case by applying
it to an EEG seizure detection problem. We compare the performance of CTXSEG
with fixed-length segmentation in the preprocessing step of a typical EEG
machine learning pipeline for seizure detection.
  Main results. We found that using CTXSEG to prepare EEG data improves seizure
detection performance compared to fixed-length approaches when evaluated using
a standardized framework, without modifying the machine learning method, and
requires fewer segments.
  Significance. This work demonstrates that adaptive segmentation with CTXSEG
can be readily applied to modern machine learning approaches, with potential to
improve performance. It is a promising alternative to fixed-length segmentation
for signal preprocessing and should be considered as part of the standard
preprocessing repertoire in EEG machine learning applications.

</details>


### [34] [Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees](https://arxiv.org/abs/2508.21001)
*Yaniv Hassidof,Tom Jurgenson,Kiril Solovey*

Main category: cs.LG

TL;DR: DiTree是一个结合扩散策略和采样规划器的框架，用于高效解决动力系统运动规划问题，提高成功率和速度。


<details>
  <summary>Details</summary>
Motivation: 现有采样规划器（SBPs）探索速度慢，而学习方法的泛化性和安全性不足。

Method: 利用扩散策略（DPs）作为采样器指导SBPs搜索，结合DPs的复杂分布建模能力和SBPs的完备性。

Result: DiTree在OOD场景中比SBPs快3倍，成功率提高30%以上。

Conclusion: DiTree是一种高效、安全的运动规划方法，适用于复杂动力系统。

Abstract: Kinodynamic motion planning is concerned with computing collision-free
trajectories while abiding by the robot's dynamic constraints. This critical
problem is often tackled using sampling-based planners (SBPs) that explore the
robot's high-dimensional state space by constructing a search tree via action
propagations. Although SBPs can offer global guarantees on completeness and
solution quality, their performance is often hindered by slow exploration due
to uninformed action sampling. Learning-based approaches can yield
significantly faster runtimes, yet they fail to generalize to
out-of-distribution (OOD) scenarios and lack critical guarantees, e.g., safety,
thus limiting their deployment on physical robots. We present Diffusion Tree
(DiTree): a \emph{provably-generalizable} framework leveraging diffusion
policies (DPs) as informed samplers to efficiently guide state-space search
within SBPs. DiTree combines DP's ability to model complex distributions of
expert trajectories, conditioned on local observations, with the completeness
of SBPs to yield \emph{provably-safe} solutions within a few action propagation
iterations for complex dynamical systems. We demonstrate DiTree's power with an
implementation combining the popular RRT planner with a DP action sampler
trained on a \emph{single environment}. In comprehensive evaluations on OOD
scenarios, % DiTree has comparable runtimes to a standalone DP (3x faster than
classical SBPs), while improving the average success rate over DP and SBPs.
DiTree is on average 3x faster than classical SBPs, and outperforms all other
approaches by achieving roughly 30\% higher success rate. Project webpage:
https://sites.google.com/view/ditree.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [35] [Live Vocal Extraction from K-pop Performances](https://arxiv.org/abs/2508.20273)
*Yujin Kim,Richa Namballa,Magdalena Fuentes*

Main category: eess.AS

TL;DR: 提出了一种自动从K-pop现场表演中提取人声的方法，结合源分离、互相关和幅度缩放技术。


<details>
  <summary>Details</summary>
Motivation: 受K-pop粉丝文化的启发，研究如何自动分离现场表演中的真实人声。

Method: 使用源分离、互相关和幅度缩放技术，自动去除预录音轨和伴奏。

Result: 初步工作提出了现场人声分离的任务，并为未来研究奠定了基础。

Conclusion: 该方法为K-pop现场表演中的真实人声提取提供了新的研究方向。

Abstract: K-pop's global success is fueled by its dynamic performances and vibrant fan
engagement. Inspired by K-pop fan culture, we propose a methodology for
automatically extracting live vocals from performances. We use a combination of
source separation, cross-correlation, and amplitude scaling to automatically
remove pre-recorded vocals and instrumentals from a live performance. Our
preliminary work introduces the task of live vocal separation and provides a
foundation for future research in this topic.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [36] [Enhancing Automatic Modulation Recognition With a Reconstruction-Driven Vision Transformer Under Limited Labels](https://arxiv.org/abs/2508.20193)
*Hossein Ahmadi,Banafsheh Saffari*

Main category: cs.CV

TL;DR: 提出了一种基于视觉变换器（ViT）的统一框架，用于自动调制识别（AMR），通过结合监督、自监督和重建目标，显著减少对标注数据的需求。


<details>
  <summary>Details</summary>
Motivation: 现有AMR方法依赖大量标注数据或多阶段训练流程，限制了实际应用中的可扩展性和泛化能力，因此需要一种更高效且泛化性强的解决方案。

Method: 使用ViT编码器、轻量级卷积解码器和线性分类器，结合信号重建任务，通过自监督预训练和部分标签微调实现高效特征学习。

Result: 在RML2018.01A数据集上，该方法在低标签场景下优于监督CNN和ViT基线，仅需15-20%标注数据即可达到ResNet级别精度，且在不同SNR水平下表现稳健。

Conclusion: 该框架为AMR提供了一种简单、通用且标签高效的解决方案。

Abstract: Automatic modulation recognition (AMR) is critical for cognitive radio,
spectrum monitoring, and secure wireless communication. However, existing
solutions often rely on large labeled datasets or multi-stage training
pipelines, which limit scalability and generalization in practice. We propose a
unified Vision Transformer (ViT) framework that integrates supervised,
self-supervised, and reconstruction objectives. The model combines a ViT
encoder, a lightweight convolutional decoder, and a linear classifier; the
reconstruction branch maps augmented signals back to their originals, anchoring
the encoder to fine-grained I/Q structure. This strategy promotes robust,
discriminative feature learning during pretraining, while partial label
supervision in fine-tuning enables effective classification with limited
labels. On the RML2018.01A dataset, our approach outperforms supervised CNN and
ViT baselines in low-label regimes, approaches ResNet-level accuracy with only
15-20% labeled data, and maintains strong performance across varying SNR
levels. Overall, the framework provides a simple, generalizable, and
label-efficient solution for AMR.

</details>


### [37] [SKGE-SWIN: End-To-End Autonomous Vehicle Waypoint Prediction and Navigation Using Skip Stage Swin Transformer](https://arxiv.org/abs/2508.20762)
*Fachri Najm Noer Kartiman,Rasim,Yaya Wihardi,Nurul Hasanah,Oskar Natan,Bambang Wahono,Taufik Ibnu Salim*

Main category: cs.CV

TL;DR: 提出SKGE-Swin架构，利用Swin Transformer和跳阶段机制提升自动驾驶车辆模型的全局和层级特征表示能力，并在CARLA平台上验证其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提升自动驾驶车辆模型对复杂环境的理解能力，通过全局特征表示和多层级信息保留优化其性能。

Method: 结合Swin Transformer的Shifted Window-based Multi-head Self-Attention机制和跳阶段机制，实现远距离像素信息提取和关键信息保留。

Result: 模型在CARLA平台的对抗场景中表现出色，驾驶评分优于现有方法。

Conclusion: SKGE-Swin架构通过多组件协作显著提升自动驾驶能力，未来将进一步通过消融研究验证各组件贡献。

Abstract: Focusing on the development of an end-to-end autonomous vehicle model with
pixel-to-pixel context awareness, this research proposes the SKGE-Swin
architecture. This architecture utilizes the Swin Transformer with a skip-stage
mechanism to broaden feature representation globally and at various network
levels. This approach enables the model to extract information from distant
pixels by leveraging the Swin Transformer's Shifted Window-based Multi-head
Self-Attention (SW-MSA) mechanism and to retain critical information from the
initial to the final stages of feature extraction, thereby enhancing its
capability to comprehend complex patterns in the vehicle's surroundings. The
model is evaluated on the CARLA platform using adversarial scenarios to
simulate real-world conditions. Experimental results demonstrate that the
SKGE-Swin architecture achieves a superior Driving Score compared to previous
methods. Furthermore, an ablation study will be conducted to evaluate the
contribution of each architectural component, including the influence of skip
connections and the use of the Swin Transformer, in improving model
performance.

</details>


### [38] [To New Beginnings: A Survey of Unified Perception in Autonomous Vehicle Software](https://arxiv.org/abs/2508.20892)
*Loïc Stratil,Felix Fent,Esteban Rivera,Markus Lienkamp*

Main category: cs.CV

TL;DR: 综述探讨了自动驾驶感知领域中的统一感知范式，通过整合检测、跟踪和预测任务提升性能，并提出了分类法和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决模块化感知流程中的错误累积和任务间协同不足问题，推动更鲁棒、高效且可解释的感知系统。

Method: 提出基于任务集成、跟踪定义和表征流的三类统一感知范式（早期、晚期和完全统一），并系统回顾现有方法及其架构、训练策略和数据集。

Result: 建立了首个统一感知的综合框架，为未来研究提供了方向，并促进了更通用且可解释的感知系统发展。

Conclusion: 统一感知是自动驾驶感知领域的重要方向，通过整合多任务和系统性分类，未来研究有望进一步提升感知系统的性能和可靠性。

Abstract: Autonomous vehicle perception typically relies on modular pipelines that
decompose the task into detection, tracking, and prediction. While
interpretable, these pipelines suffer from error accumulation and limited
inter-task synergy. Unified perception has emerged as a promising paradigm that
integrates these sub-tasks within a shared architecture, potentially improving
robustness, contextual reasoning, and efficiency while retaining interpretable
outputs. In this survey, we provide a comprehensive overview of unified
perception, introducing a holistic and systemic taxonomy that categorizes
methods along task integration, tracking formulation, and representation flow.
We define three paradigms -Early, Late, and Full Unified Perception- and
systematically review existing methods, their architectures, training
strategies, datasets used, and open-source availability, while highlighting
future research directions. This work establishes the first comprehensive
framework for understanding and advancing unified perception, consolidates
fragmented efforts, and guides future research toward more robust,
generalizable, and interpretable perception.

</details>


### [39] [COMETH: Convex Optimization for Multiview Estimation and Tracking of Humans](https://arxiv.org/abs/2508.20920)
*Enrico Martini,Ho Jin Choi,Nadia Figueroa,Nicola Bombieri*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量级算法COMETH，用于实时多视角人体姿态融合，通过集成运动和生物力学约束，提高关节定位精度，适用于工业和安防应用。


<details>
  <summary>Details</summary>
Motivation: 在工业5.0时代，监测人体活动对保证人体工程学安全和整体健康至关重要。然而，传统多摄像头集中式方法存在计算和带宽成本高的问题，限制了其扩展性和实时性。边缘设备的资源受限又会导致精度下降。因此，需要一种高效、轻量的算法来解决这些问题。

Method: COMETH算法基于三个核心概念：1）集成运动和生物力学约束以提高关节定位精度；2）基于凸优化的逆运动学实现空间融合；3）使用状态观察器改进时间一致性。

Result: 在公共和工业数据集上的评估表明，COMETH在定位、检测和跟踪精度上优于现有方法。

Conclusion: COMETH作为一种轻量级算法，能够实现高精度、可扩展的人体运动跟踪，适用于工业和安防等高要求场景。

Abstract: In the era of Industry 5.0, monitoring human activity is essential for
ensuring both ergonomic safety and overall well-being. While multi-camera
centralized setups improve pose estimation accuracy, they often suffer from
high computational costs and bandwidth requirements, limiting scalability and
real-time applicability. Distributing processing across edge devices can reduce
network bandwidth and computational load. On the other hand, the constrained
resources of edge devices lead to accuracy degradation, and the distribution of
computation leads to temporal and spatial inconsistencies. We address this
challenge by proposing COMETH (Convex Optimization for Multiview Estimation and
Tracking of Humans), a lightweight algorithm for real-time multi-view human
pose fusion that relies on three concepts: it integrates kinematic and
biomechanical constraints to increase the joint positioning accuracy; it
employs convex optimization-based inverse kinematics for spatial fusion; and it
implements a state observer to improve temporal consistency. We evaluate COMETH
on both public and industrial datasets, where it outperforms state-of-the-art
methods in localization, detection, and tracking accuracy. The proposed fusion
pipeline enables accurate and scalable human motion tracking, making it
well-suited for industrial and safety-critical applications. The code is
publicly available at https://github.com/PARCO-LAB/COMETH.

</details>


### [40] [CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification](https://arxiv.org/abs/2508.21046)
*Wei Li,Renshan Zhang,Rui Shao,Jie He,Liqiang Nie*

Main category: cs.CV

TL;DR: CogVLA是一种基于认知对齐的视觉-语言-动作框架，通过指令驱动路由和稀疏化提升效率与性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型需要大量后训练，计算开销高，限制了可扩展性和部署能力，CogVLA旨在解决这一问题。

Method: 采用3阶段架构：1) EFA-Routing选择性聚合视觉令牌；2) LFP-Routing剪枝无关令牌；3) CAtten结合注意力机制生成动作。

Result: 在LIBERO基准和实际任务中，CogVLA分别达到97.4%和70.0%的成功率，训练和推理效率显著提升。

Conclusion: CogVLA在性能和效率上均优于现有方法，具有实际部署潜力。

Abstract: Recent Vision-Language-Action (VLA) models built on pre-trained
Vision-Language Models (VLMs) require extensive post-training, resulting in
high computational overhead that limits scalability and deployment.We propose
CogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages
instruction-driven routing and sparsification to improve both efficiency and
performance. CogVLA draws inspiration from human multimodal coordination and
introduces a 3-stage progressive architecture. 1) Encoder-FiLM based
Aggregation Routing (EFA-Routing) injects instruction information into the
vision encoder to selectively aggregate and compress dual-stream visual tokens,
forming a instruction-aware latent representation. 2) Building upon this
compact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)
introduces action intent into the language model by pruning
instruction-irrelevant visually grounded tokens, thereby achieving token-level
sparsity. 3) To ensure that compressed perception inputs can still support
accurate and coherent action generation, we introduce V-L-A Coupled Attention
(CAtten), which combines causal vision-language attention with bidirectional
action parallel decoding. Extensive experiments on the LIBERO benchmark and
real-world robotic tasks demonstrate that CogVLA achieves state-of-the-art
performance with success rates of 97.4% and 70.0%, respectively, while reducing
training costs by 2.5-fold and decreasing inference latency by 2.8-fold
compared to OpenVLA. CogVLA is open-sourced and publicly available at
https://github.com/JiuTian-VL/CogVLA.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [41] [Achieving Optimal Performance-Cost Trade-Off in Hierarchical Cell-Free Massive MIMO](https://arxiv.org/abs/2508.20704)
*Wei Jiang,Hans D Schotten*

Main category: cs.IT

TL;DR: 本文提出了一种分层无蜂窝（HCF）大规模MIMO设计，通过替换部分接入点为中央基站来降低成本，同时保持性能，并首次全面分析了其上行链路配置。


<details>
  <summary>Details</summary>
Motivation: 传统的无蜂窝大规模MIMO部署成本高，HCF设计通过优化架构降低成本，同时维持性能表现。

Method: 开发了统一的频谱效率分析框架，支持任意组合方案，并提出了一种专为HCF双层架构设计的层次化组合方法。

Result: 通过分析用户公平性、系统容量、前传需求和计算复杂度，发现HCF采用集中化零迫组合在性能和成本效率上取得最佳平衡。

Conclusion: HCF设计是一种经济高效的大规模MIMO解决方案，特别是在成本和性能之间寻求平衡的场景中。

Abstract: Cell-free (CF) massive MIMO offers uniform service via distributed access
points (APs), which impose high deployment costs. A novel design called
hierarchical cell-free (HCF) addresses this problem by replacing some APs with
a central base station, thereby lowering the costs of fronthaul network
(wireless sites and fiber cables) while preserving performance. To identify the
optimal uplink configuration in HCF massive MIMO, this paper provides the first
comprehensive analysis, benchmarking it against cellular and CF systems. We
develop a unified analytical framework for spectral efficiency that supports
arbitrary combining schemes and introduce a novel hierarchical combining
approach tailored to HCF two-tier architecture. Through analysis and evaluation
of user fairness, system capacity, fronthaul requirements, and computational
complexity, this paper identifies that HCF using centralized zero-forcing
combining achieves the optimal balance between performance and cost-efficiency.

</details>


### [42] [What is the Most Efficient Technique for Uplink Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.20708)
*Wei Jiang,Hans D. Schotten*

Main category: cs.IT

TL;DR: 该论文旨在确定无蜂窝大规模MIMO系统中最有效率的上行链路技术，解决了现有研究中的方法分散性和假设不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究在方法上分散且假设不一致（例如单天线与多天线接入点、理想与空间相关信道），限制了技术的统一性和实用性。

Method: 论文建立了统一的分析框架，适用于集中式/分布式处理和多样化组合方案；开发了通用的最大-最小功率控制优化策略；并对四个关键指标进行了全面研究。

Result: 通过分析和评估，该研究确定了实际无蜂窝部署中的最佳上行链路技术。

Conclusion: 该论文提供了一种统一且实用的解决方案，显著提升了无蜂窝大规模MIMO系统的效率和性能。

Abstract: This paper seeks to determine the most efficient uplink technique for
cell-free massive MIMO systems. Despite offering great advances, existing works
suffer from fragmented methodologies and inconsistent assumptions (e.g.,
single- vs. multi-antenna access points, ideal vs. spatially correlated
channels). To address these limitations, we: (1) establish a unified analytical
framework compatible with centralized/distributed processing and diverse
combining schemes; (2) develop a universal optimization strategy for max-min
power control; and (3) conduct a holistic study among four critical metrics:
worst-case user spectral efficiency (fairness), system capacity, fronthaul
signaling, and computational complexity. Through analyses and evaluation, this
work ultimately identifies the optimal uplink technique for practical cell-free
deployments.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [43] [Regulation-Aware Game-Theoretic Motion Planning for Autonomous Racing](https://arxiv.org/abs/2508.20203)
*Francesco Prignoli,Francesco Borrelli,Paolo Falcone,Mark Pustilnik*

Main category: eess.SY

TL;DR: 该论文提出了一种针对自动驾驶赛车场景的规则感知运动规划框架，通过将赛车规则编码为混合逻辑动力学约束，并利用广义纳什均衡问题（GNEP）和迭代最佳响应方案，开发了一种安全且非保守的超车策略。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶赛车中车辆交互时规则遵守和安全性问题，提出了一种规则感知的规划框架，以确保车辆在超车等复杂场景中既安全又高效。

Method: 采用了模型预测控制和混合逻辑动力学约束编码赛车规则，并通过广义纳什均衡问题和迭代最佳响应方案求解车辆交互问题，最终开发了规则感知的博弈论规划器（RA-GTP）。

Result: 仿真结果表明，RA-GTP在超车等场景中优于假设对手模型非交互或无视规则的基线方法，既能保持规则合规性，又能生成更有效的机动策略。

Conclusion: 该框架为自动驾驶赛车提供了一种兼顾安全性和高效性的解决方案，尤其在需要复杂交互的竞赛场景中表现优异。

Abstract: This paper presents a regulation-aware motion planning framework for
autonomous racing scenarios. Each agent solves a Regulation-Compliant Model
Predictive Control problem, where racing rules - such as right-of-way and
collision avoidance responsibilities - are encoded using Mixed Logical
Dynamical constraints. We formalize the interaction between vehicles as a
Generalized Nash Equilibrium Problem (GNEP) and approximate its solution using
an Iterative Best Response scheme. Building on this, we introduce the
Regulation-Aware Game-Theoretic Planner (RA-GTP), in which the attacker reasons
over the defender's regulation-constrained behavior. This game-theoretic layer
enables the generation of overtaking strategies that are both safe and
non-conservative. Simulation results demonstrate that the RA-GTP outperforms
baseline methods that assume non-interacting or rule-agnostic opponent models,
leading to more effective maneuvers while consistently maintaining compliance
with racing regulations.

</details>
