<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [math.OC](#math.OC) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CC](#cs.CC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Temporal Convolutional Autoencoder for Interference Mitigation in FMCW Radar Altimeters](https://arxiv.org/abs/2505.22783)
*Charles E. Thornton,Jamie Sloop,Samuel Brown,Aaron Orndorff,William C. Headley,Stephen Young*

Main category: eess.SP

TL;DR: 该论文研究了一种基于卷积自编码器的端到端高度估计方法，用于抑制FMCW雷达高度计中的干扰。通过Temporal Convolutional Network (TCN)自编码器，该方法直接处理FMCW信号，在时间相关性利用和干扰抑制方面优于LMS滤波器。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理FMCW雷达高度计的干扰时存在局限性，无法充分利用时间相关性。论文旨在探索深度学习在宽频FMCW干扰抑制中的潜力，并解决其在实时性和泛化性上的挑战。

Method: 采用Temporal Convolutional Network (TCN)自编码器，直接处理接收到的FMCW信号，利用时间相关性进行干扰抑制，并与Least Mean Squares (LMS)自适应滤波器进行对比。

Result: TCN自编码器在干扰抑制方面表现优于LMS滤波器，但深度学习在宽频FMCW干扰抑制中的实时性和任意干扰条件下的泛化性仍需进一步优化。

Conclusion: 深度学习在FMCW干扰抑制中展现出潜力，但需未来研究解决实时性和泛化性问题，以推动实际应用。

Abstract: We investigate the end-to-end altitude estimation performance of a
convolutional autoencoder-based interference mitigation approach for
frequency-modulated continuous-wave (FMCW) radar altimeters. Specifically, we
show that a Temporal Convolutional Network (TCN) autoencoder effectively
exploits temporal correlations in the received signal, providing superior
interference suppression compared to a Least Mean Squares (LMS) adaptive
filter. Unlike existing approaches, the present method operates directly on the
received FMCW signal. Additionally, we identify key challenges in applying deep
learning to wideband FMCW interference mitigation and outline directions for
future research to enhance real-time feasibility and generalization to
arbitrary interference conditions.

</details>


### [2] [Flexure-FET-Based Receiver with Competitive Binding for Interference Mitigation in Molecular Communication](https://arxiv.org/abs/2505.22849)
*Dilara Aktas,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 论文提出了一种新型分子通信接收器模型，通过引入竞争结合动力学提升在高干扰环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有分子通信研究多未充分考虑多分子物种共存时的受体竞争效应，限制了系统在复杂环境中的可靠性。

Method: 通过整合竞争结合模型，动态调整配体浓度与受体亲和力，优化Flexure-FET接收器性能。

Result: 结果显示竞争建模能显著改善信噪比、符号错误率等关键指标，提升复杂环境下的检测鲁棒性。

Conclusion: 竞争结合模型为分子通信系统提供了更现实的干扰管理框架，为未来生物启发的应用奠定基础。

Abstract: Molecular communication (MC), a biologically inspired technology, enables
applications in nanonetworks and the Internet of Everything (IoE), with great
potential for intra-body systems such as drug delivery, health monitoring, and
disease detection. This paper extends our prior work on the Flexure-FET MC
receiver by integrating a competitive binding model to enhance performance in
high-interference environments, where multiple molecular species coexist in the
reception space. Previous studies have largely focused on ligand concentration
estimation and detection, without fully addressing the effects of inter-species
competition for receptor binding. Our proposed framework captures this
competition, offering a more biologically accurate model for multitarget
environments. By incorporating competition dynamics, the model improves
understanding of MC behavior under interference. This approach enables
fine-tuning of receptor responses by adjusting ligand concentrations and
receptor affinities, thereby optimizing the performance of the Flexure-FET MC
receiver. Comprehensive analysis shows that accounting for competitive binding
is crucial for improving reliability and accuracy in complex MC systems.
Factors such as signal-to-noise ratio (SNR), symbol error probability (SEP),
interferer concentration, and receptor dynamics are shown to significantly
affect performance. The proposed framework highlights the need to manage these
factors effectively. Results demonstrate that modeling interference through
competitive binding offers a realistic system perspective and allows tuning of
receiver response, enabling robust detection in environments with multiple
coexisting species.

</details>


### [3] [Bi-Residual Neural Network based Synchronous Motor Electrical Faults Diagnosis: Intra-link Layer Design for High-frequency Features](https://arxiv.org/abs/2505.23097)
*Qianchao Wang,Leena Heistrene,Yoash Levron,Yuxuan Ding,Yaping Du*

Main category: eess.SP

TL;DR: 论文提出了一种名为Bi-ResNet的双残差神经网络，用于在资源受限环境中高效提取高频率故障关键信息，通过嵌入时空卷积块和内部链接层，实现了无需增加参数的深层网络性能。实验证明其在低分辨率噪声数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的实际环境中，高效提取潜在高频率故障关键信息是一个固有难题。

Method: 采用双残差神经网络Bi-ResNet，嵌入时空卷积块和内部链接层，提取时空高频特征。

Result: 实验表明Bi-ResNet在低分辨率噪声数据上表现更优，内部链接层有助于高频成分提取与定位，且内部链接数量与输入数据复杂度存在权衡。

Conclusion: Bi-ResNet通过嵌入高频提取器，实现了浅层网络达到深层网络的性能，为资源受限环境中的故障诊断提供了有效解决方案。

Abstract: In practical resource-constrained environments, efficiently extracting the
potential high-frequency fault-critical information is an inherent problem. To
overcome this problem, this work suggests leveraging a bi-residual neural
network named Bi-ResNet to extract the inner spatial-temporal high-frequency
features using embedded spatial-temporal convolution blocks and intra-link
layers. It can be considered as embedding a high-frequency extractor into
networks without adding any parameters, helping shallow networks achieve the
performance of deep networks. In our experiments, five advanced CNN-based
neural networks and two baselines across a real-life dataset are utilized for
synchronous motor electrical fault diagnosis to demonstrate the effectiveness
of Bi-ResNet including one analytical, comparative, and ablation experiments.
The corresponding experiments show: 1) The Bi-ResNet can perform better on
low-resolution noisy data. 2) The proposed intra-links can help high-frequency
components extraction and location from raw data. 3) There is a trade-off
between intra-link number and input data complexity.

</details>


### [4] [Joint Phase Shift Optimization and Precoder Selection for RIS-Assisted 5G NR MIMO Systems](https://arxiv.org/abs/2505.23154)
*Osman Mert Yilmaz,Tayfun Yilmaz,Ali Gorcin,Ibrahim Hokelek,Ertugrul Guvenkaya,Haci Ilhan*

Main category: eess.SP

TL;DR: 本文提出了一种基于奇异值（λ）的RIS优化策略，通过配置RIS相位偏移以最大化级联信道矩阵的主导奇异值，并利用对应的奇异向量进行MIMO预编码，降低了时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 5G及后续网络中，RIS相位偏移与MIMO预编码的联合优化尚未充分探索，本文旨在填补这一空白。

Method: 提出λ-based RIS优化策略，并采用最大交叉交换算法（MCA）求解优化问题。

Result: 仿真结果表明，所提出的预编码选择方法在λ-based RIS优化下优于传统方法。

Conclusion: 该方法为RIS辅助的MIMO系统提供了高效的优化方案，显著提升了性能。

Abstract: By intelligently reconfiguring wireless propagation environment,
reconfigurable intelligent surfaces (RISs) can enhance signal quality, suppress
interference, and improve channel conditions, thereby serving as a powerful
complement to multiple-input multiple-output (MIMO) architectures. However,
jointly optimizing the RIS phase shifts and the MIMO transmit precoder in 5G
and beyond networks remains largely unexplored. This paper addresses this gap
by proposing a singular value ($\lambda$)-based RIS optimization strategy,
where the phase shifts are configured to maximize the dominant singular values
of the cascaded channel matrix, and the corresponding singular vectors are
utilized for MIMO transmit precoding. The proposed precoder selection does not
require mutual information computation across subbands, thereby reducing time
complexity. To solve the $\lambda$-based optimization problem, maximum
cross-swapping algorithm (MCA) is applied while an effective rank-based method
is utilized for benchmarking purposes. The simulation results show that the
proposed precoder selection method consistently outperforms the conventional
approach under $\lambda$-based RIS optimization.

</details>


### [5] [Topological Adaptive Least Mean Squares Algorithms over Simplicial Complexes](https://arxiv.org/abs/2505.23160)
*Lorenzo Marinucci,Claudio Battiloro,Paolo Di Lorenzo*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的自适应框架，用于处理基于单纯复形的动态流信号，将经典最小均方(LMS)方法扩展到高阶拓扑领域。通过离散霍奇理论，我们提出了一种拓扑LMS算法，高效处理时间变化的边子集上的流信号。我们还进行了随机分析，推导了算法的稳定性、稳态均方误差和收敛速度，并探索了边采样对性能的影响。此外，我们假设对复杂结构的部分了解，提出了自适应拓扑推断方法。实验表明，我们的方法在集中式和分布式场景中均优于基于图的LMS方法。


<details>
  <summary>Details</summary>
Motivation: 传统的LMS方法在处理动态网络信号时难以捕捉高阶拓扑特征。本文旨在通过引入基于单纯复形的自适应框架，弥补这一不足，以更好地处理流信号并优化性能。

Method: 本文构建了一个拓扑LMS算法，基于离散霍奇理论，处理流信号并支持时间变化的边子集采样。此外，提出了最优边采样概率设计策略，并结合自适应拓扑推断方法。最后，扩展了分布式版本并分析其稳定性。

Result: 理论和实验结果表明，所提出的算法在稳定性和收敛速度上表现优异，且能通过高阶拓扑特征显著提升性能。分布式版本同样展现了稳定的性能。

Conclusion: 本文提出的自适应框架成功扩展了LMS方法，为高阶拓扑域的信号处理提供了有效工具，并在理论和实践中验证了其优越性。

Abstract: This paper introduces a novel adaptive framework for processing dynamic flow
signals over simplicial complexes, extending classical least-mean-squares (LMS)
methods to high-order topological domains. Building on discrete Hodge theory,
we present a topological LMS algorithm that efficiently processes streaming
signals observed over time-varying edge subsets. We provide a detailed
stochastic analysis of the algorithm, deriving its stability conditions,
steady-state mean-square-error, and convergence speed, while exploring the
impact of edge sampling on performance. We also propose strategies to design
optimal edge sampling probabilities, minimizing rate while ensuring desired
estimation accuracy. Assuming partial knowledge of the complex structure (e.g.,
the underlying graph), we introduce an adaptive topology inference method that
integrates with the proposed LMS framework. Additionally, we propose a
distributed version of the algorithm and analyze its stability and
mean-square-error properties. Empirical results on synthetic and real-world
traffic data demonstrate that our approach, in both centralized and distributed
settings, outperforms graph-based LMS methods by leveraging higher-order
topological features.

</details>


### [6] [Deep Learning-Based CSI Feedback for Wi-Fi Systems With Temporal Correlation](https://arxiv.org/abs/2505.23198)
*Junyong Shin,Eunsung Jeon,Inhyoung Kim,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 提出了一个基于深度学习的CSI反馈框架，用于下一代Wi-Fi系统，通过编码器和解码器神经网络压缩和重构CSI角度参数，并结合量化模块和时间相关性策略提升性能，实验结果显示性能优于现有标准方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高下一代Wi-Fi系统的吞吐量，需要高效压缩和反馈信道状态信息（CSI）。现有方法在压缩和反馈效率上存在不足，因此提出基于深度学习的解决方案以优化性能。

Method: 设计了包含编码器和解码器的深度学习框架，集成可训练的矢量量化模块，并提出基于角度差分的反馈策略及CSI细化模块，利用时间相关性提升效率。

Result: 仿真结果表明，该框架在压缩和重构CSI角度参数方面优于当前Wi-Fi系统标准方法，角度差分反馈策略和CSI细化模块显著提升了性能。

Conclusion: 该研究为下一代Wi-Fi系统提供了一种高效的CSI反馈方案，通过深度学习技术和时间相关性优化，显著提升了系统吞吐量和反馈准确性。

Abstract: To achieve higher throughput in next-generation Wi-Fi systems, a station
(STA) needs to efficiently compress channel state information (CSI) and feed it
back to an access point (AP). In this paper, we propose a novel deep learning
(DL)-based CSI feedback framework tailored for next-generation Wi-Fi systems.
Our framework incorporates a pair of encoder and decoder neural networks to
compress and reconstruct the angle parameters of the CSI. To enable an
efficient finite-bit representation of the encoder output, we introduce a
trainable vector quantization module, which is integrated after the encoder
network and jointly trained with both the encoder and decoder networks in an
end-to-end manner. Additionally, we further enhance our framework by leveraging
the temporal correlation of the angle parameters. Specifically, we propose an
angle-difference feedback strategy which transmits the difference between the
current and previous angle parameters when the difference is sufficiently
small. This strategy accounts for the periodicity of the angle parameters
through proper preprocessing and mitigates error propagation effects using
novel feedback methods. We also introduce a DL-based CSI refinement module for
the AP, which improves the reconstruction accuracy of the angle parameters by
simultaneously utilizing both the previous and current feedback information.
Simulation results demonstrate that our framework outperforms the standard
method employed in current Wi-Fi systems. Our results also demonstrate
significant performance gains achieved by the angle-difference feedback
strategy and the CSI refinement module.

</details>


### [7] [LCB-CV-UNet: Enhanced Detector for High Dynamic Range Radar Signals](https://arxiv.org/abs/2505.23454)
*Yanbin Wang,Xingyu Chen,Yumiao Wang,Xiang Wang,Chuanfei Zang,Guolong Cui,Jiahuan Liu*

Main category: eess.SP

TL;DR: 论文提出了LCB-CV-UNet模型，通过Logarithmic Connect Block（LCB）模块和双混合数据集构建方法，有效处理高动态范围（HDR）雷达信号，提升检测概率并保持较低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决高动态范围雷达信号导致的性能下降问题，尤其是在典型城市目标信号噪比范围内（11-13 dB）的表现。

Method: 提出硬件高效的LCB模块以保持相位一致性，并采用双混合数据集构建方法生成半合成数据集。

Result: 仿真显示总检测概率提升约1%，计算复杂度仅增加0.9%，且在11-13 dB噪比范围内优于基线5%。

Conclusion: 模型通过实验验证了实用性，为HDR雷达信号处理提供了有效解决方案。

Abstract: We propose the LCB-CV-UNet to tackle performance degradation caused by High
Dynamic Range (HDR) radar signals. Initially, a hardware-efficient,
plug-and-play module named Logarithmic Connect Block (LCB) is proposed as a
phase coherence preserving solution to address the inherent challenges in
handling HDR features. Then, we propose the Dual Hybrid Dataset Construction
method to generate a semi-synthetic dataset, approximating typical HDR signal
scenarios with adjustable target distributions. Simulation results show about
1% total detection probability improvement with under 0.9% computational
complexity added compared with the baseline. Furthermore, it excels 5% over the
baseline at the range in 11-13 dB signal-to-noise ratio typical for urban
targets. Finally, the real experiment validates the practicality of our model.

</details>


### [8] [Dual-Task Graph Neural Network for Joint Seizure Onset Zone Localization and Outcome Prediction using Stereo EEG](https://arxiv.org/abs/2505.23669)
*Syeda Abeera Amir,Artur Agaronyan,William Gaillard,Chima Oluigbo,Syed Muhammad Anwar*

Main category: eess.SP

TL;DR: 该论文提出了一种基于图神经网络的框架，利用sEEG数据预测癫痫手术后的无发作结果并定位癫痫发作起始区。


<details>
  <summary>Details</summary>
Motivation: 癫痫手术的成功依赖于准确识别癫痫发作起始区和预测手术效果。目前临床方法主观性强，亟需数据驱动的自动化解决方案。

Method: 研究采用双任务图神经网络框架，基于sEEG数据构建功能连接图，并提取丰富的节点特征与全局图特征，通过交叉验证优化模型。

Result: 模型在预测无发作准确率为89.31±0.0976%，定位癫痫发作起始区的准确率为94.72±0.0041%。

Conclusion: 该方法展示了高准确性，为癫痫手术规划和患者管理提供了自动化工具。

Abstract: Accurately localizing the brain regions that triggers seizures and predicting
whether a patient will be seizure-free after surgery are vital for surgical
planning and patient management in drug-resistant epilepsy.
Stereo-electroencephalography (sEEG) delivers high-fidelity intracranial
recordings that enable clinicians to precisely locate epileptogenic networks.
However, the clinical identification is subjective and dependent on the
expertise of the clinical team. Data driven approaches in this domain are
sparse, despite the fact that sEEG offers high temporal-fidelity related to
seizure dynamics that can be leveraged using graph structures ideal for
imitating brain networks. In this study, we introduce a dual-task graph-neural
network (GNN) framework that operates on windowed sEEG recordings to jointly
predict seizure-freedom outcomes and identify seizure-onset-zone (SOZ)
channels. We assemble non-overlapping 10 second windows from 51 clinical
seizures spread across 20 pediatric patients, with sEEG data annotated by
clinical experts. For each temporal window we construct a functional
connectivity graph via thresholded Pearson correlations and extract rich node
features (spectral, statistical, wavelet, Hjorth and local graph features),
alongside six global graph descriptors. We optimize a combined cross-entropy
loss with a tunable task-weight, and select model hyper-parameters via Optuna.
Under window-level 10-fold cross-validation, the model achieves a mean
graph-level accuracy of $89.31 \pm 0.0976 \%$ for seizure-freedom prediction
and a node-level SOZ localization accuracy of $94.72. \pm 0.0041 \%$. For the
best performing model, we ran additive and leave-one-out ablation studies to
explore feature importance for graph and node-level accuracy.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [9] [On the Convergence of Decentralized Stochastic Gradient-Tracking with Finite-Time Consensus](https://arxiv.org/abs/2505.23577)
*Aaron Fainman,Stefan Vlaski*

Main category: math.OC

TL;DR: 该研究探讨了在基于梯度跟踪的去中心化优化算法中，近似有限时间共识序列对收敛性的影响，并分析了序列精度、长度与问题参数（如平滑度和梯度噪声）之间的关系。


<details>
  <summary>Details</summary>
Motivation: 在去中心化优化和学习中，使用实现有限时间共识的时间变化矩阵序列可以改善基于梯度跟踪的算法的通信和迭代复杂度。然而，实践中可能因网络拓扑信息不完善、序列长度限制或数值不稳定性而无法获得精确的有限时间共识序列。

Method: 研究量化了近似有限时间共识序列对基于梯度跟踪的去中心化优化算法收敛性的影响，分析了序列准确性和长度以及典型问题参数（如平滑度和梯度噪声）之间的相互作用。

Result: 研究表明，近似有限时间共识序列对算法收敛性有显著影响，需要平衡序列精度和长度以优化性能。

Conclusion: 近似有限时间共识序列在实际应用中可能无法完全精确，但通过合理调节序列精度和长度，仍能有效支持基于梯度跟踪的去中心化优化算法的收敛。

Abstract: Algorithms for decentralized optimization and learning rely on local
optimization steps coupled with combination steps over a graph. Recent works
have demonstrated that using a time-varying sequence of matrices that achieve
finite-time consensus can improve the communication and iteration complexity of
decentralized optimization algorithms based on gradient tracking. In practice,
a sequence of matrices satisfying the exact finite-time consensus property may
not be available due to imperfect knowledge of the network topology, a limit on
the length of the sequence, or numerical instabilities. In this work, we
quantify the impact of approximate finite-time consensus sequences on the
convergence of a gradient-tracking based decentralized optimization algorithm,
clarifying the interplay between accuracy and length of the sequence as well as
typical problem parameters such as smoothness and gradient noise.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [10] [Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats](https://arxiv.org/abs/2505.23706)
*Utku Demir,Yalin E. Sagduyu,Tugba Erpek,Hossein Jafari,Sastry Kompella,Mengran Xue*

Main category: cs.NI

TL;DR: 该论文提出了一种分布式联邦学习（DFL）方法来解决车联网中安全消息分类的挑战，通过车辆间协作训练模型，显著提升了分类准确性，并分析了其在多域攻击下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 车联网中，集中式数据收集或纯本地训练的局限性促使研究DFL，以应对大规模、高移动性和异构数据分布的挑战。

Method: 采用DFL方法，车辆通过与一跳邻居交换模型更新和多跳传播模型，利用VeReMi扩展数据集进行训练。

Result: DFL显著提升了所有车辆的分类准确性，尤其是低准确性车辆；但面对无线干扰和数据投毒等多域攻击时表现出脆弱性。

Conclusion: DFL在车联网中效果显著，但需更鲁棒的策略以应对多域攻击，确保安全性。

Abstract: In connected and autonomous vehicles, machine learning for safety message
classification has become critical for detecting malicious or anomalous
behavior. However, conventional approaches that rely on centralized data
collection or purely local training face limitations due to the large scale,
high mobility, and heterogeneous data distributions inherent in inter-vehicle
networks. To overcome these challenges, this paper explores Distributed
Federated Learning (DFL), whereby vehicles collaboratively train deep learning
models by exchanging model updates among one-hop neighbors and propagating
models over multiple hops. Using the Vehicular Reference Misbehavior (VeReMi)
Extension Dataset, we show that DFL can significantly improve classification
accuracy across all vehicles compared to learning strictly with local data.
Notably, vehicles with low individual accuracy see substantial accuracy gains
through DFL, illustrating the benefit of knowledge sharing across the network.
We further show that local training data size and time-varying network
connectivity correlate strongly with the model's overall accuracy. We
investigate DFL's resilience and vulnerabilities under attacks in multiple
domains, namely wireless jamming and training data poisoning attacks. Our
results reveal important insights into the vulnerabilities of DFL when
confronted with multi-domain attacks, underlining the need for more robust
strategies to secure DFL in vehicular networks.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [11] [Dynamic Estimation Loss Control in Variational Quantum Sensing via Online Conformal Inference](https://arxiv.org/abs/2505.23389)
*Ivana Nikoloska,Hamdi Joudeh,Ruud van Sloun,Osvaldo Simeone*

Main category: quant-ph

TL;DR: 该论文提出了一种用于变分量子传感（VQS）的在线控制框架，通过动态更新参数并提供确定性误差边界，结合在线共形推理技术实现可靠量子传感。


<details>
  <summary>Details</summary>
Motivation: 现有变分量子传感方法在噪声中等规模量子（NISQ）设备上缺乏严格的性能保证，且受限于噪声和采样约束。

Method: 提出动态VQS框架，利用在线共形推理技术动态更新参数并生成具有长期风险保证的序列估计集。

Result: 在量子磁力测量任务中验证了动态VQS的可靠性，同时保持高精度估计。

Conclusion: 结合变分量子算法与在线共形推理可实现NISQ设备上的可靠量子传感。

Abstract: Quantum sensing exploits non-classical effects to overcome limitations of
classical sensors, with applications ranging from gravitational-wave detection
to nanoscale imaging. However, practical quantum sensors built on noisy
intermediate-scale quantum (NISQ) devices face significant noise and sampling
constraints, and current variational quantum sensing (VQS) methods lack
rigorous performance guarantees. This paper proposes an online control
framework for VQS that dynamically updates the variational parameters while
providing deterministic error bars on the estimates. By leveraging online
conformal inference techniques, the approach produces sequential estimation
sets with a guaranteed long-term risk level. Experiments on a quantum
magnetometry task confirm that the proposed dynamic VQS approach maintains the
required reliability over time, while still yielding precise estimates. The
results demonstrate the practical benefits of combining variational quantum
algorithms with online conformal inference to achieve reliable quantum sensing
on NISQ devices.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [12] [Fast Compressed-Domain N-Point Discrete Fourier Transform](https://arxiv.org/abs/2505.23718)
*Saulo Queiroz*

Main category: cs.CC

TL;DR: 提出了基于递归矩形索引压缩(RIC)和结构化频移的新型N点DFT算法，无需复数乘法，支持非2的幂次输入长度，计算复杂度为O(N log N)。


<details>
  <summary>Details</summary>
Motivation: 传统FFT算法需输入长度为2的幂次，否则需补零，效率低且可能引入误差。本研究旨在通过RIC和频移技术，放宽这一限制并提升计算效率。

Method: 递归压缩信号至C点后计算其DFT，再通过全局频移获取奇数索引系数，支持N=c·2^k的输入长度。

Result: 算法在避免补零的情境下性能优于radix-2 FFT，复杂度保持O(N log N)，且拓展了DFT结构理论的应用潜力。

Conclusion: RIC DFT为DFT计算提供了新思路，可能影响数值稳定性、硬件实现及稀疏变换等DFT相关领域。

Abstract: This paper presents a novel algorithm for computing the N-point Discrete
Fourier Transform (DFT) based solely on recursive Rectangular Index Compression
(RIC) [1][2] and structured frequency shifts. The RIC DFT algorithm compresses
a signal from $N=CL$ to $C\in[2,N/2]$ points at the expense of $N-1$ complex
additions and no complex multiplication. It is shown that a $C$-point DFT on
the compressed signal corresponds exactly to $C$ DFT coefficients of the
original $N$-point DFT, namely, $X_{kL}$, $k=0,1,\ldots,C-1$ with no need for
twiddle factors. We rely on this strategy to decompose the DFT by recursively
compressing the input signal and applying global frequency shifts (to get
odd-indexed DFT coefficients). We show that this new structure can relax the
power-of-two assumption of the radix-2 FFT by enabling signal input lengths
such as $N=c\cdot 2^k$ (for $k\geq 0$ and a non-power-of-two $c>0$). Thus, our
algorithm potentially outperforms radix-2 FFTs for the cases where significant
zero-padding is needed. The proposed approach achieves a computational
complexity of $O(N \log N)$ and offers a new structural perspective on DFT
computation, with potential impacts on several DFT issues like numerical
stability, hardware implementation, sparse transforms, convolutions, and others
DFT-based procedures.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [DeepFilterGAN: A Full-band Real-time Speech Enhancement System with GAN-based Stochastic Regeneration](https://arxiv.org/abs/2505.23515)
*Sanberk Serbest,Tijana Stojkovic,Milos Cernak,Andrew Harper*

Main category: eess.AS

TL;DR: 提出了一种基于GAN随机再生的全频带实时语音增强系统，结合预测模型和生成模型以减少失真，系统参数少、延迟低，实验显示性能提升并通过消融研究验证了噪声条件的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决预测模型因仅估计目标分布均值而可能导致语音内容过度抑制的问题，结合生成模型以学习完整分布，减少输出失真。

Method: 采用基于GAN的随机再生框架，结合预测与生成模型，设计轻量级架构（3.58M参数）实现低延迟实时流处理。

Result: 系统在NISQA-MOS指标上优于初始阶段，消融研究验证噪声条件的关键作用，并应用于2025 Urgent Challenge后续改进。

Conclusion: 通过生成与预测模型结合，实现了高效实时语音增强，噪声条件对系统性能至关重要。

Abstract: In this work, we propose a full-band real-time speech enhancement system with
GAN-based stochastic regeneration. Predictive models focus on estimating the
mean of the target distribution, whereas generative models aim to learn the
full distribution. This behavior of predictive models may lead to
over-suppression, i.e. the removal of speech content. In the literature, it was
shown that combining a predictive model with a generative one within the
stochastic regeneration framework can reduce the distortion in the output. We
use this framework to obtain a real-time speech enhancement system. With 3.58M
parameters and a low latency, our system is designed for real-time streaming
with a lightweight architecture. Experiments show that our system improves over
the first stage in terms of NISQA-MOS metric. Finally, through an ablation
study, we show the importance of noisy conditioning in our system. We
participated in 2025 Urgent Challenge with our model and later made further
improvements.

</details>
