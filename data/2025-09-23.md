<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 26]
- [cs.RO](#cs.RO) [Total: 74]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 12]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [eess.SY](#eess.SY) [Total: 5]
- [math.OC](#math.OC) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [MRADNET: a Compact Radar Object Detector with MetaFormer](https://arxiv.org/abs/2509.16223)
*Huaiyu Chen,Fahed Hassanat,Robert Laganiere,Martin Bouchard*

Main category: eess.SP

TL;DR: 本文提出了一种名为mRadNet的新型雷达目标检测模型，注重模型的紧凑性和效率，改进了现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 频调连续波雷达在汽车行业中应用广泛，但现有模型在紧凑性和效率方面存在不足，mRadNet旨在解决这一问题。

Method: mRadNet采用U-net架构和MetaFormer模块，结合可分卷积和注意力令牌混合器，提升局部和全局特征提取能力。

Result: 在CRUW数据集上的实验表明，mRadNet在性能上优于现有技术。

Conclusion: mRadNet通过高效的设计和结构优化，为雷达目标检测提供了紧凑且高效的解决方案。

Abstract: Frequency-modulated continuous wave radars have gained increasing popularity
in the automotive industry. Its robustness against adverse weather conditions
makes it a suitable choice for radar object detection in advanced driver
assistance systems. These real-time embedded systems have requirements for the
compactness and efficiency of the model, which have been largely overlooked in
previous work. In this work, we propose mRadNet, a novel radar object detection
model with compactness in mind. mRadNet employs a U-net style architecture with
MetaFormer blocks, in which separable convolution and attention token mixers
are used to capture both local and global features effectively. More efficient
token embedding and merging strategies are introduced to further facilitate the
lightweight design of the model. The performance of mRadNet is validated on the
CRUW dataset, improving state-of-the-art performance.

</details>


### [2] [Power Spectral Density Estimation via Universal Truncated Order Statistics Filtering](https://arxiv.org/abs/2509.16359)
*David Campos Anchieta,John R. Buck*

Main category: eess.SP

TL;DR: 提出了一种通过动态调整混合权重来优化水下声学数据中瞬态信号处理的PSD估计方法，减少了固定秩选择的依赖。


<details>
  <summary>Details</summary>
Motivation: 瞬态信号会增加背景噪声PSD估计的偏差和方差，现有方法需要实时动态调整秩选择，操作复杂。

Method: 采用不同秩的OSF凸组合，并通过动态调整混合权重，优先选择方差最小的OSF。

Result: 混合OSF在仿真和实际数据中有效过滤瞬态信号，性能接近固定秩的最佳OSF。

Conclusion: 该方法避免了显式选择阈值秩的复杂性，适用于动态环境中的实时应用。

Abstract: Loud transient signals in underwater acoustic data increase the bias and
variance of background noise power spectral density (PSD) estimates based on
sample mean. Recently, two PSD estimators mitigated the loud transient impact
on PSD estimates by applying order statistics filtering (OSF). The first, the
Schwock and Abadi Welch Percentile, scales a single rank order statistic (OS)
of consecutive periodograms. The second, the truncated linear order statistics
filter, is a weighted sum of OS up to a chosen rank. In order to minimize
variance, both OSFs must carefully choose the highest rank that still
eliminates the loud transients. However, in real-time applications in dynamic
environments, loud transients occur at unpredictable rates, requiring dynamic
adjustment of the OSF ranks to keep low bias and variance. To circumvent the
challenges of real-time rank selection, this paper proposes a convex sum of
OSFs across ranks with blending weights that are sequentially adjusted to favor
the lowest variance OSFs over a recent time window. The performance of the
blended sum provably approaches the performance of the best fixed rank OSF.
Simulations and real data confirm the blended OSFs effectively filter loud
transients out of spectrograms without explicitly choosing a threshold rank.

</details>


### [3] [Hybrid FIM and STAR-BD-RIS-Aided Wireless Communications with Short Packet Length: A Meta-TD3 Approach](https://arxiv.org/abs/2509.16417)
*Ayla Eftekhari,Maryam Cheraghy,Armin Farhadi,Mohammad Robat Mili,Qingqing Wu*

Main category: eess.SP

TL;DR: 提出了一种结合FIM和STAR-BD-RIS的新型系统架构，通过优化配置和深度学习算法提升多用户无线通信的性能。


<details>
  <summary>Details</summary>
Motivation: 结合FIM和RIS的优势，提升信道质量和系统性能，满足短块长度条件下的高接收功率需求。

Method: 部署FIM天线和STAR-BD-RIS，优化FIM配置、波束赋形向量和RIS相移矩阵，采用基于元学习的Meta-TD3算法。

Result: 混合系统性能优于传统FIM或RIS单独配置，Meta-TD3算法优于经典学习技术。

Conclusion: 新型架构和算法显著提升了系统性能，展示了深度学习在无线通信中的潜力。

Abstract: Reconfigurable intelligent surfaces (RIS) and flexible intelligent
metasurfaces (FIM) have been widely adopted in multi-user wireless
communication systems to enhance channel quality through simultaneous
transmission and reflection of signals and three-dimensional reconfiguration of
antennas. In this paper, we propose a novel system architecture that integrates
the benefits of both technologies by deploying an FIM antenna at the base
station (BS) and a simultaneously transmitting and reflecting beyond diagonal
RIS (STAR-BD-RIS) along the transmission path to ensure sufficient received
power for single-antenna users. The objective is to maximize the achievable sum
rate considering the short block length by jointly optimizing the FIM surface
configuration, the transmit beamforming vector, and STAR-BD-RIS phase shift
matrix subject to practical constraints including minimum
signal-to-interference-plus-noise ratio (SINR), power limitations, FIM
constraint, and the STAR-BD-RIS phase-shift matrix. To solve the resulting
non-convex optimization problem, we develop a learning-based approach that
incorporates meta-learning into the twin delayed deep deterministic policy
gradient (TD3) algorithm, referred to as Meta-TD3. The simulation results
demonstrate that the proposed hybrid system outperforms conventional
configurations employing either FIM or RIS alone, while the Meta-TD3 algorithm
achieves superior performance compared to classic learning techniques.

</details>


### [4] [Advancing Accessible Hand-Arm Vibration Safety Monitoring: ISO-Compliance with Wearable Sensors and Transfer Functions](https://arxiv.org/abs/2509.16536)
*Johannes Mootz,Reza Akhavian*

Main category: eess.SP

TL;DR: 研究提出了一种基于可穿戴传感器的振动数据收集方法，并开发了一种误差最小化传递函数，用于实时监控工人手部振动暴露，以减少健康风险。


<details>
  <summary>Details</summary>
Motivation: 现场工人常暴露于有害振动，增加手-臂振动综合征（HAVS）等健康问题的风险。现有标准ISO 5349-1基于实验室条件，使用高质量传感器直接固定在工具上，而实际现场条件复杂，需要更灵活、低成本的解决方案。

Method: 研究采用可穿戴传感器在不同采样频率下测量振动数据，开发了传递函数以校正传感器位置差异和阻尼效应，并通过锤击混凝土的实验验证。

Result: 结果显示手掌与上臂间振动显著减弱，采样频率对数据准确性有重要影响，传递函数成功实现了与ISO标准的可比性。

Conclusion: 该方法为实时、低成本监测HAVS风险提供了可行方案，可帮助预防长期健康问题。

Abstract: Field workers are frequently exposed to hazardous vibrations, increasing the
risk of Hand-Arm Vibration Syndrome (HAVS) and other long-term health problems.
ISO 5349-1 provides guidelines for measuring vibration exposure. However, this
standard was established in controlled conditions using high-quality
accelerometers directly attached to power tool handles. This study investigates
an alternative, wearable sensor-based data collection process and develops an
error-minimization transfer function that derives values comparable to ISO
benchmarks for safety monitoring. Experiments are performed with subjects
hammer drilling into concrete while vibrations are measured using three
accelerometers at different sampling frequencies. The transfer function maps
vibration data across sensor positions by accounting for damping effects. The
findings indicate a significant reduction in acceleration between the palm and
upper arm, highlight the impact of sampling frequency on data accuracy, and
enable accurate comparison of true hand-arm vibration levels with existing
standard limits to allow accessible, real-time, and cost-effective HAVS
prevention.

</details>


### [5] [Bearing-only Tracking using Towed Sensor-Array with Non-Gaussian Measurement Noise Statistics](https://arxiv.org/abs/2509.16570)
*Rohit Kumar Singh,Subrata Kumar,Shovan Bhaumik*

Main category: eess.SP

TL;DR: 该论文提出了一种用于拖曳电缆传感器阵列系统（TCSAS）的动态模型，结合非高斯噪声的最大相关熵准则卡尔曼滤波，以提高被动仅方位跟踪（BOT）的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有BOT方法在拖船机动时暂停测量更新或假设传感器阵列位置固定，导致状态估计不可靠。为解决这一问题，需要一个动态模型来准确跟踪传感器阵列位置。

Method: 采用集总质量方法建立TCSAS的动态模型，通过求解力矩平衡和准静态平衡条件确定3D空间中的动态行为，并结合最大相关熵准则卡尔曼滤波处理非高斯噪声。

Result: 所提出的动态模型在实际BOT场景中得到验证，能够有效跟踪传感器阵列位置，改善目标状态估计。

Conclusion: 该方法通过动态建模改进传感器阵列定位，结合噪声处理技术，显著提升了BOT的可靠性和精度。

Abstract: Passive bearing-only tracking (BOT) estimates the target states by utilising
noisy bearing measurements captured by a sensor array. The sensor array is
often towed behind the ship, using a long flexible cable to reduce interference
from the own-ship's inherent noises. This forms a towed cable sensor-array
system (TCSAS). During BOT, the tow-ship has to perform a manoeuvre to make the
tracking system observable. Such a manoeuvre destabilises the TCSAS, thus
making its exact location unknown \emph{w.r.t.} tow-ship. However, it is very
crucial to know the exact location of the towed sensor-array to perform
efficient and reliable target state estimation. The existing BOT approaches
perform TMA during own-ship manoeuvre either by pausing the measurement
updation step of the estimation algorithm or assuming a fixed aft position for
the towed sensor-array. These assumptions lead to unreliable state estimation.
To address this, we propose a dynamic model for TCSAS, using a lumped mass
approach, which will provide the location of the sensor array during the
own-ship manoeuvre. This location will be fed to the state estimation
algorithm. The dynamic of TCSAS in 3D space is obtained by solving the
equations obtained from the moment balance condition and quasi-static
equilibrium condition at the lumped mass points. Moreover, the bearing data
captured by the towed sensor-array is corrupted with non-Gaussian noise. It is
handled using the maximum correntropy criterion based Kalman filter with a
kernel bandwidth selection technique, proposed in this paper. The proposed
sensor-array dynamic model is verified for a real-world BOT engagement
scenario.

</details>


### [6] [Fusing Spectral Correlation Density Imaging with Deep Learning for Intelligent Fault Diagnosis in Rotating Machinery](https://arxiv.org/abs/2509.16580)
*Dilshara Herath,Chinthaka Abeyrathne,Chamindu Adithya,Chathura Seneviratne*

Main category: eess.SP

TL;DR: 论文提出了一种基于谱相关密度（SCD）图像和深度学习的轴承故障诊断方法，通过CNN模型在复杂振动信号中实现了高精度的故障分类。


<details>
  <summary>Details</summary>
Motivation: 传统的故障诊断方法（如FFT）难以处理非平稳振动信号，因此需要一种更有效的方法来早期检测轴承故障。

Method: 利用SCD图像识别故障特征，并开发了三种CNN模型（Custom CNN、ResNet152V2和EfficientNetB0）进行分类。

Result: Custom CNN在两个轴承壳（A和B）上的分类准确率最高（分别达96.58%和94.95%）。

Conclusion: 该方法为复杂振动数据的处理和边缘智能应用提供了高效、鲁棒的解决方案。

Abstract: Bearing fault diagnosis in rotating machinery is critical for ensuring
operational reliability, therefore early fault detection is essential to avoid
catastrophic failures and expensive emergency repairs. Traditional methods like
Fast Fourier Transform (FFT) often fail to capture the complex, non-stationary
nature of vibration signals. This study leverages the cyclostationary
properties of vibration data through Spectral Correlation Density (SCD) images
to enhance fault detection and apply deep learning for classification. Using a
publicly available dataset with bearing faults seeded in two distinct housings
(A and B) under varying load conditions (0 Nm, 2 Nm, 4 Nm), we processed
vibration signals into 2D SCD images to reveal fault-specific periodicities,
such as broadband spectra (2000--8000 Hz) for larger faults. Three
convolutional neural network (CNN) models, Custom CNN, ResNet152V2, and
EfficientNetB0, were developed to classify seven bearing conditions. The custom
CNN achieved the highest accuracies of 96.58\% and 94.95\% on Housing A and B,
respectively, followed by ResNet152V2 at 96.49\% and 95.35\%, and
EfficientNetB0 at 94.16\% and 91.65\%, respectively. The models' high
accuracies across different housings demonstrate a robust solution suitable for
cost-effective condition monitoring deployable near sensing platforms,
contributing to applied machine learning for edge intelligence and showcasing
effective signal processing strategies for handling complex, potentially
large-scale vibration data.

</details>


### [7] [Robust Sparse Subspace Tracking from Corrupted Data Observations](https://arxiv.org/abs/2509.16585)
*Ta Giang Thuy Loan,Hoang-Lan Nguyen,Nguyen Thi Ngoc Lan,Do Hai Son,Tran Thi Thuy Quynh,Nguyen Linh Trung,Karim Abed-Meraim,Thanh Trung Le*

Main category: eess.SP

TL;DR: 本文探讨了利用α散度进行稀疏子空间估计与跟踪的方法，提升了数据在非高斯噪声和稀疏性下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在高维数据中，数据样本常受到非高斯噪声影响且可能呈现稀疏性，现有方法对此不够鲁棒。

Method: 采用α散度进行子空间估计与跟踪，同时保持低计算复杂度和内存占用。

Result: 所提方法在鲁棒子空间跟踪和DOA估计中表现优于现有最先进方法。

Conclusion: 该方法在复杂数据环境下具有显著优势，适用于实际应用。

Abstract: Subspace tracking is a fundamental problem in signal processing, where the
goal is to estimate and track the underlying subspace that spans a sequence of
data streams over time. In high-dimensional settings, data samples are often
corrupted by non-Gaussian noises and may exhibit sparsity. This paper explores
the alpha divergence for sparse subspace estimation and tracking, offering
robustness to data corruption. The proposed method outperforms the
state-of-the-art robust subspace tracking methods while achieving a low
computational complexity and memory storage. Several experiments are conducted
to demonstrate its effectiveness in robust subspace tracking and
direction-of-arrival (DOA) estimation.

</details>


### [8] [Affine Frequency Division Multiplexing for Communication and Channel Sounding: Requirements, Challenges, and Key Technologies](https://arxiv.org/abs/2509.16643)
*Yu Zhou,Chao Zou,Nanhao Zhou,Yanqun Tang,Xiaoying Zhang,Haoran Yin,Xiaoran Liu,Ruisi He,Pan Tang,Weijie Yuan,Yong Zeng*

Main category: eess.SP

TL;DR: 本文提出了一种集成信道探测与通信（ICSC）方法，解决传统信道模型在下一代空天地海一体化网络（SAGSIN）中动态变化的问题，并利用仿频分多路复用（AFDM）实现通信与信道探测的双重功能。


<details>
  <summary>Details</summary>
Motivation: 传统信道探测系统无法适应SAGSIN中动态信道变化，导致信道模型过时，无法为通信系统提供可靠先验信息。

Method: 提出基于AFDM的ICSC方法，该技术能够提供信道的全时延-多普勒表示，实现通信与信道探测的同时进行。

Result: 探索了AFDM-ICSC的关键性能指标，并阐明了信道探测、估计、跟踪与散射体感知的区别与关系。

Conclusion: 总结了AFDM-ICSC的应用场景与实现挑战，为未来技术发展提供了方向。

Abstract: Channel models are crucial for theoretical analysis, performance evaluation,
and deployment of wireless communication systems. Traditional channel sounding
systems are insufficient for handling the dynamic changes of channels in the
next-generation space-air-ground-sea integrated networks (SAGSIN), which often
results in outdated channel models that fail to provide reliable prior
information for communication systems. To address this challenge, this paper
proposes an integrated channel sounding and communication (ICSC) method as a
practical solution. Unlike orthogonal frequency division multiplexing, affine
frequency division multiplexing (AFDM) provides a full delay-Doppler
representation of the channel, achieving optimal diversity in time-frequency
doubly dispersive channels and effectively addressing the aforementioned
challenges. Thus, we investigate the fundamental principles of AFDM, showing
how it enables simultaneous communication and channel sounding, and explore key
performance metrics for both functionalities. We also clarify the distinction
and relationship between channel sounding, estimation, tracking and scatterer
sensing. Additionally, several potential application scenarios for AFDM-ICSC
are explored. Finally, we highlight the key challenges in implementing
AFDM-ICSC, outline future research directions, and provide valuable insights
for the continued development of this technology.

</details>


### [9] [Near-Field Channel Estimation with ELAA Modular Arrays Under Hardware Impairments](https://arxiv.org/abs/2509.16688)
*Özlem Tuğfe Demir,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种用于模块化大规模天线阵的近场视距信道估计方法，通过利用阵列几何和恒模结构，提高了估计精度并减少了前传信号。


<details>
  <summary>Details</summary>
Motivation: 模块化大规模天线阵虽然能降低成本，但硬件损伤（如低噪声放大器）会影响信道估计，需要高效且准确的估计方法。

Method: 采用基于阵列几何和恒模结构的计算方法，包括新型二维DFT掩膜技术。

Result: 数值结果表明，所提方法显著优于传统最小二乘法。

Conclusion: 提出的方法在降低硬件成本的同时，提高了信道估计的效率和准确性。

Abstract: Extremely large-scale antenna arrays (ELAAs) enable high spatial resolution
and multiplexing, especially for user equipments (UEs) in the radiative
near-field. To reduce hardware cost, modular ELAA architectures with
distributed baseband units (BBUs) are gaining traction. This paper addresses
near-field line-of-sight (LOS) channel estimation under low noise amplifier
(LNA)-induced hardware impairments in such modular systems. We propose
computationally efficient estimators that exploit the array geometry and
constant-modulus structure of near-field LOS channels, including a novel
two-dimensional (2D) discrete Fourier transform (DFT) masking technique that
improves estimation accuracy and significantly reduces fronthaul signaling.
Numerical results show that the proposed methods significantly outperform the
conventional least squares (LS) method.

</details>


### [10] [Data-Driven Two-Stage IRS-Aided Sumrate Maximization with Inexact Precoding](https://arxiv.org/abs/2509.16776)
*Hassaan Hashmi,Spyridon Pougkakiotis,Dionysis Kalogerias*

Main category: eess.SP

TL;DR: iZoSGA是一种数据驱动算法，用于无线网络中联合被动长期智能反射面(IRS)波束成形和主动短期预编码。


<details>
  <summary>Details</summary>
Motivation: 解决具有连续不确定性和

Method: 基于零阶随机拟梯度上升方法，处理具有

Result: 在最小假设下，证明了iZoSGA收敛到原始问题的稳定解邻域。

Conclusion: iZoSGA在多种不精确场景中有效，支持IRS在不同配置下的高效运行。

Abstract: We propose iZoSGA, a data-driven learning algorithm for joint passive
long-term intelligent reflective surface (IRS)-aided beamforming and active
short-term precoding in wireless networks. iZoSGA is based on a zeroth-order
stochastic quasigradient ascent methodology designed for tackling two-stage
nonconvex stochastic programs with continuous uncertainty and objective
functions with "black-box" terms, and where second-stage optimization is
inexact. As such, iZoSGA utilizes inexact precoding oracles, enabling practical
implementation when short-term (e.g., WMMSE-based) beamforming is solved
approximately. The proposed method is agnostic to channel models or statistics,
and applies to arbitrary IRS/network configurations. We prove non-asymptotic
convergence of iZoSGA to a neighborhood of a stationary solution of the
original exact problem under minimal assumptions. Our numerics confirm the
efficacy iZoSGA in several "inexact regimes", enabling passive yet fully
effective IRS operation in diverse and realistic IRS-aided scenarios.

</details>


### [11] [On the Secrecy Performance of Pinching-Antenna Systems](https://arxiv.org/abs/2509.16854)
*Nianzu Li,Weidong Mei,Lipeng Zhu,Peiran Wu,Boyu Ning*

Main category: eess.SP

TL;DR: 本文研究了夹持天线的保密性能，分析了其在窃听者存在时的保密中断概率（SOP），并推导了其渐近行为和性能下限。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统因其在减少信号传播路径损耗方面的卓越能力而备受关注，但其在窃听环境下的保密性能尚未充分研究。

Method: 作者推导了夹持天线系统的保密中断概率的近似表达式，并分析了其渐近行为，同时提出了一个性能下限。

Result: 推导的性能下限为$rac{2π−1}{24}$，显著优于传统固定位置天线系统的0.5，并通过仿真验证了理论结果的正确性。

Conclusion: 夹持天线系统在保密性能上优于传统天线系统，未来可进一步探索其实际应用潜力。

Abstract: Pinching-antenna systems have recently gained significant attention as a
novel reconfigurable-antenna technology due to its exceptional capability of
mitigating signal-propagation path loss. In this letter, we investigate the
secrecy performance of a pinching-antenna system in the presence of an
eavesdropper. In particular, we derive an approximate expression of the
system's secrecy outage probability (SOP) with respect to the random locations
of the legitimate user and eavesdropper and analyze its asymptotic behavior.
Moreover, we derive a constant performance lower bound on the SOP of the
considered system, i.e., $\frac{2\pi-1}{24}$, which is significantly lower than
that of conventional fixed-position antenna systems, i.e., $0.5$. Finally,
simulation results are provided to validate the correctness of our analytical
results.

</details>


### [12] [Graph Fractional Hilbert Transform: Theory and Application](https://arxiv.org/abs/2509.16910)
*Daxiang Li,Zhichao Zhang*

Main category: eess.SP

TL;DR: 该论文提出了一种改进的图信号处理工具——图分数希尔伯特变换（GFRHT），解决了现有图希尔伯特变换的局限性，具有更高的灵活性和性能。


<details>
  <summary>Details</summary>
Motivation: 图希尔伯特变换（GHT）在图信号处理中存在诸多限制，包括固定的相位偏移、信息丢失以及对图傅里叶域的依赖。论文目标是提出一种更灵活且高效的替代方案。

Method: 论文引入了图分数希尔伯特变换（GFRHT），采用双参数框架（分数阶α和角度β），通过可变相位和分数域分析，解决了GHT的不足，并实现了更精确的信号分析。

Result: 实验表明，GFRHT在图信号的边缘检测、异常识别和语音分类任务中表现优于GHT，展现了更高的灵活性和性能优势。

Conclusion: GFRHT作为一种新型图信号处理工具，解决了GHT的局限性，为图信号分析提供了更强大的支持。

Abstract: The graph Hilbert transform (GHT) is a key tool in constructing analytic
signals and extracting envelope and phase information in graph signal
processing. However, its utility is limited by confinement to the graph Fourier
domain, a fixed phase shift, information loss for real-valued spectral
components, and the absence of tunable parameters. The graph fractional Fourier
transform introduces domain flexibility through a fractional order parameter
$\alpha$ but does not resolve the issues of phase rigidity and information
loss. Inspired by the dual-parameter fractional Hilbert transform (FRHT) in
classical signal processing, we propose the graph FRHT (GFRHT). The GFRHT
incorporates a dual-parameter framework: the fractional order $\alpha$ enables
analysis across arbitrary fractional domains, interpolating between vertex and
spectral spaces, while the angle parameter $\beta$ provides adjustable phase
shifts and a non-zero real-valued response ($\cos\beta$) for real eigenvalues,
thereby eliminating information loss. We formally define the GFRHT, establish
its core properties, and design a method for graph analytic signal
construction, enabling precise envelope extraction and demodulation.
Experiments on edge detection, anomaly identification, and speech
classification demonstrate that GFRHT outperforms GHT, offering greater
flexibility and superior performance in graph signal processing.

</details>


### [13] [Bi-modal Prediction and Transformation Coding for Compressing Complex Human Dynamics](https://arxiv.org/abs/2509.16919)
*Huong Hoang,Keito Suzuki,Truong Nguyen,Pamela Cosman*

Main category: eess.SP

TL;DR: 该研究提出了一种双模态编码框架，通过结合语义分割和区域特定变换建模，提升动态人体运动序列的压缩效率，尤其是在快速运动和非刚性变形场景下。


<details>
  <summary>Details</summary>
Motivation: 原始的KeyNode-Driven编解码器在处理快速运动或强烈非刚性变形时效率不足，因此需要一种更灵活的运动表示方法。

Method: 研究提出了一种双模态编码框架，结合语义分割和区域特定变换建模，混合应用刚性和仿射变换，并通过拉格朗日率-失真优化指导参数选择和编码。

Result: 实验结果显示，双模态方法在复杂非刚性运动中能更准确地实现网格变形，同时在不增加简单区域压缩负担的情况下，平均比特率节省了33.81%。

Conclusion: 该框架显著提高了动态人体运动序列的压缩效率和变形表现，尤其在处理非刚性变形时效果突出。

Abstract: For dynamic human motion sequences, the original KeyNode-Driven codec often
struggles to retain compression efficiency when confronted with rapid movements
or strong non-rigid deformations. This paper proposes a novel Bi-modal coding
framework that enhances the flexibility of motion representation by integrating
semantic segmentation and region-specific transformation modeling. The rigid
transformation model (rotation & translation) is extended with a hybrid scheme
that selectively applies affine transformations-rotation, translation, scaling,
and shearing-only to deformation-rich regions (e.g., the torso, where loose
clothing induces high variability), while retaining rigid models elsewhere. The
affine model is decomposed into minimal parameter sets for efficient coding and
combined through a component selection strategy guided by a Lagrangian
Rate-Distortion optimization. The results show that the Bi-modal method
achieves more accurate mesh deformation, especially in sequences involving
complex non-rigid motion, without compromising compression efficiency in
simpler regions, with an average bit-rate saving of 33.81% compared to the
baseline.

</details>


### [14] [Asymptotic Scaling Law Analysis of Multicast Satellite Communications with Massive MIMO](https://arxiv.org/abs/2509.16921)
*Seyong Kim,Jeonghun Park*

Main category: eess.SP

TL;DR: 本文分析了在GEO卫星通信系统中使用大规模MIMO进行多播传输的性能，揭示了用户密度的增加可以精确补偿多播传输带来的速率下降。


<details>
  <summary>Details</summary>
Motivation: 研究在GEO卫星通信系统中采用大规模MIMO和多播传输的性能表现，特别是如何通过用户密度的调整来优化速率。

Method: 通过泊松点过程建模地面用户的空间分布，并采用固定波束预编码，推导出速率缩放规律的闭式表达式。

Result: 分析结果表明，通过增加用户密度，可以精确抵消多播传输带来的速率下降。

Conclusion: 研究为GEO卫星通信系统中的大规模MIMO多播传输提供了理论支持，展示了用户密度优化的重要性。

Abstract: In this paper, we consider a geostationary orbit (GEO) satellite
communication system that employs massive multiple-input multiple-output (MIMO)
for multicast transmission. By modeling the spatial distribution of ground
users using a Poisson point process (PPP) and assuming a fixed-beam precoding
is adopted, we find a closed-form expression for the asymptotical rate scaling
law as a function of the number of antennas and the scaling factors of user
density and multicast users. From the derived analytical expression, we reveal
that the rate degradation caused by multicast transmission can be precisely
compensated by increasing the user density accordingly.

</details>


### [15] [Functional WMMSE Algorithm for Continuous Aperture Array Systems](https://arxiv.org/abs/2509.17101)
*Shiyong Chen*

Main category: eess.SP

TL;DR: 提出了一种适用于连续孔径阵列MU-MIMO系统的功能扩展WMMSE算法，通过积分替代矩阵运算提升了性能。


<details>
  <summary>Details</summary>
Motivation: 针对连续孔径阵列的MU-MIMO系统，传统离散WMMSE算法不适用，需扩展为连续函数形式以优化波束成形。

Method: 将离散WMMSE算法中的矩阵和向量提升为连续函数，用Galerkin投影和Gauss-Legendre积分实现闭式更新。

Result: 仿真显示，该方法在频谱效率和计算复杂度上优于基线。

Conclusion: 功能扩展WMMSE算法为连续孔径阵列系统提供了高效且计算复杂度低的解决方案。

Abstract: In this paper, we propose a functional extension of the weighted minimum
mean-squared error (WMMSE) algorithm for downlink beamforming in multiuser
multiple-input multiple-output (MU-MIMO) systems where both the base station
(BS) and the users employ continuous-aperture arrays (CAPAs). The method lifts
the matrices and vectors in the classical discrete WMMSE recursion to
continuous functions by replacing matrix products and inner products with
integrals over the apertures. In practice, we apply a Galerkin projection to
map functions to coefficient matrices, solve the resulting discrete WMMSE
problem via closed-form updates, and then lift these updates back to the
functional domain. All integrals are implemented using Gauss-Legendre
quadrature, which preserves the closed-form structure through weighted matrix
products. Simulations show that the proposed method outperforms baselines in
both spectral efficiency (SE) and computational complexity.

</details>


### [16] [Resilient Signal Reflection under CSI Perturbations: A Robust Approach for Secure RIS Communication](https://arxiv.org/abs/2509.17181)
*Mahdi Shamsi,Hadi Zayyani,Farokh Marvasti*

Main category: eess.SP

TL;DR: 研究提出了一种鲁棒方法，通过一阶近似技术增强RIS配置对CSI扰动的抗干扰能力，优化信号反射和传输，显著提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决RIS辅助系统中CSI扰动问题，尤其是在安全通信场景中的挑战。

Method: 利用一阶近似技术开发鲁棒方法，优化RIS配置，减少计算复杂度。

Result: 仿真结果显示安全性和效率显著提升，同时保持低计算复杂度。

Conclusion: 该方法证明了RIS在下一代网络（如6G）中实现安全可靠通信的潜力。

Abstract: Reconfigurable Intelligent Surfaces (RIS) have emerged as a transformative
technology in wireless communication, enabling dynamic control over signal
propagation. This paper tackles the challenge of mitigating Channel State
Information (CSI) perturbations in RIS-aided systems, particularly for secure
communication scenarios. Leveraging a first-order approximation technique, we
develop a robust approach that strengthens the resilience of RIS configurations
against CSI imperfections. The study considers both untrusted user interception
and stealth radar applications, focusing on optimizing signal reflection and
transmission in the presence of eavesdroppers. Simulation results demonstrate
notable gains in security and efficiency while maintaining low computational
complexity. By extending the stability range, the proposed method updates RIS
elements using only a few matrix-vector multiplications, eliminating the need
for repeated inverse or pseudo-inverse computations under small channel
perturbations. Additionally, the framework provides a baseline for quantifying
algorithmic sensitivity to CSI variations. Overall, the findings underscore the
potential of RIS to enable secure and reliable communication in next-generation
networks such as 6G.

</details>


### [17] [Estimation of Specific Gravity of Potato Tubers Using Dielectric Properties](https://arxiv.org/abs/2509.17267)
*Taorui Chen,Yuki Gao,Yi Wang,Hai-Han Sun*

Main category: eess.SP

TL;DR: 论文提出了一个基于介电常数估计土豆比重的模型，通过微波传感技术为土豆生产和加工中的农艺性状评估奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 目前微波传感技术用于地下土豆检测和质量评估，但缺乏将土豆介电特性与其关键农艺性状（如比重）关联的准确模型。

Method: 在0.3 GHz至3.0 GHz频率范围内，对5种类型的250个土豆进行了比重测量和介电光谱测量，并使用线性回归模型构建了比重与介电常数的关系。

Result: 模型在验证数据上表现出高精度，平均绝对误差(MAE)小于4.8×10−3，平均绝对百分比误差(MAPE)小于0.45%。

Conclusion: 该研究为微波传感技术在土豆生产和加工中的农艺性状评估提供了理论支持，并公开了所有测量数据。

Abstract: Potatoes are an economically important crop, and their quality is closely
related to the starch content, which is typically inferred from specific
gravity (SG). Although microwave sensing technologies have been increasingly
developed for underground potato detection and quality assessment in recent
years, no accurate model has yet been established to link the dielectric
properties of potatoes with their key agronomic traits. To address this gap, we
developed a model for estimating potato tubers' SG based on their dielectric
constant. To construct and validate the model, we conducted SG measurements and
dielectric spectroscopy measurements in the frequency range of 0.3 GHz to 3.0
GHz on 250 potatoes of five different types (red, russet, yellow, purple, and
chipping potatoes, with 50 samples per type). Out of the 250 data sets, 200
data sets were used for model development, and 50 data sets were used for model
validation. A linear regression model was used to summarize the relationship
between SG and dielectric constant, where the regression coefficients are
expressed as fourth-order polynomial functions of frequency. Experimental
results on the 50 validation data sets show that the model achieves high
estimation accuracy with mean absolute errors (MAE) less than
\(4.8\times10^{-3}\) and mean absolute percentage errors (MAPE) less than
0.45\%. The study of the dielectric properties of potatoes, along with the
derived SG estimation model, provides a foundation for the future development
of microwave sensing technologies for agronomic trait assessment in the potato
production and processing industries. All measured data will be made publicly
available upon acceptance of the paper.

</details>


### [18] [On Mutual Information Neural Estimation for Localization](https://arxiv.org/abs/2509.17344)
*Sven Hinderer,Manuel Buchfink,Bin Yang*

Main category: eess.SP

TL;DR: 论文提出了一种新的神经互信息估计算法（MINE），用于评估和优化定位系统中的非线性依赖关系，并在模拟的多边定位系统中验证了其收敛性和一致性。


<details>
  <summary>Details</summary>
Motivation: 互信息是评估和优化定位系统的理想指标，但其计算成本高，尤其在多维问题中限制了实际应用。本文旨在通过神经互信息估计算法解决这一问题。

Method: 采用MINE算法估算用户设备位置与相关测量数据之间的互信息，并在模拟多边定位系统中应用蒙特卡罗方法验证其准确性。

Result: 实验验证了MINE算法的收敛性和一致性，并探讨了互信息在评估简单多边定位系统中的实用性。

Conclusion: MINE算法为解决互信息计算的高成本问题提供了有效途径，适用于定位系统的评估和优化。

Abstract: Mutual information (MI) is a promising candidate measure for the assessment
and optimization of localization systems, as it captures nonlinear dependencies
between random variables. However, the high cost of computing MI, especially
for high-dimensional problems, prohibits its application for many real-world
localization systems. We evaluate an algorithm from a new class of neural MI
estimators called Mutual Information Neural Estimation (MINE) to approximate
the MI between the set of feasible user element (UE) locations and the
corresponding set of measurements from said UE locations used for positioning.
We apply this estimator to a simulated multilateration (MLAT) system, where the
true MI for benchmarking can be approximated by Monte Carlo simulation. The
estimator is experimentally evaluated w.r.t. its convergence and consistency
and we investigate the usefulness of MI for assessing simple MLAT systems.

</details>


### [19] [On the Design of Capacity-Achieving Distributions for Discrete-Time Poisson Channel with Low-Precision ADCs](https://arxiv.org/abs/2509.17483)
*Qianqian Li,Lintao Li,Lixiang Liu,Lei Yang,Caihong Gong,Hua Li,Shiya Hao,Xiaoming Dai*

Main category: eess.SP

TL;DR: 该论文研究了带暗电流效应的离散时间泊松信道（DTPC）在低精度模数转换器（ADC）下的容量达到输入分布设计，提出了一种结合牛顿-拉夫逊和Blahut-Arimoto（BA）方法的优化算法，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究在低精度ADC和暗电流效应下，离散时间泊松信道（DTPC）的容量达到输入分布，以优化信道性能。

Method: 提出了一种结合牛顿-拉夫逊和Blahut-Arimoto（BA）方法的优化算法，并利用KKT条件验证最优性。

Result: 仿真结果显示，1-bit和2-bit量化DTPC在5 dB下分别达到理论容量的72%和83%。

Conclusion: 有限精度量化的DTPC可以通过非均匀离散输入分布实现容量最大化。

Abstract: This paper investigates the design of the capacity-achieving input
distribution for the discrete-time Poisson channel (DTPC) under dark current
effects with low-precision analog-to-digital converters (ADCs). This study
introduces an efficient optimization algorithm that integrates the
Newton-Raphson and Blahut-Arimoto (BA) methods to determine the
capacity-achieving input distribution and the corresponding amplitudes of input
mass points for the DTPC, subject to both peak and average power constraints.
Additionally, the Karush-Kuhn-Tucker (KKT) conditions are established to
provide necessary and sufficient conditions for the optimality of the obtained
capacity-achieving distribution. Simulation results illustrate that the
proposed algorithm attains $72\%$ and $83\%$ of the theoretical capacity at 5
dB for 1-bit and 2-bit quantized DTPC, respectively. Furthermore, for a
finite-precision quantized DTPC (i.e., ${\log _2}K$ bits), the capacity can be
achieved by a non-uniform discrete input distribution with support for $K$ mass
points, under the given power constraints.

</details>


### [20] [Single-Snapshot Localization Using Sparse Extremely Large Aperture Arrays](https://arxiv.org/abs/2509.17511)
*Yunqiao Hu,Xuesu Xiao,Steven Jones,Shunqiao Sun*

Main category: eess.SP

TL;DR: 研究了汽车雷达中单快拍DOA估计和目标定位，提出了SS-MUSIC和SS-ESPRIT方法，分别针对非相干和相干处理，表现出不同的优势。


<details>
  <summary>Details</summary>
Motivation: 解决汽车雷达中稀疏超大孔径阵列（ELAAs）的相干信号处理问题，提高目标定位和角度估计的精度。

Method: 提出SS-MUSIC算法用于非相干处理，并通过几何交扩展至近场定位；开发SS-ESPRIT方法用于相干处理，利用稀疏ELAAs孔径进行高分辨率角度估计。

Result: SS-ESPRIT在远场目标角度分辨率上表现优越，SS-MUSIC在近场定位和混合场景中更具鲁棒性和灵活性。

Conclusion: SS-ESPRIT和SS-MUSIC方法分别适用于不同的应用场景，为汽车雷达中的目标定位提供了有效解决方案。

Abstract: This paper investigates single-snapshot direction-of-arrival (DOA) estimation
and target localization with coherent sparse extremely large aperture arrays
(ELAAs) in automotive radar applications. Far-field and near-field signal
models are formulated for distributed bistatic configurations. To enable
noncoherent processing, a single-snapshot MUSIC (SS-MUSIC) algorithm is
proposed to fuse local spectra from individual subarrays and extended to
near-field localization via geometric intersection. For coherent processing, a
single-snapshot ESPRIT (SS-ESPRIT) method with ambiguity dealiasing is
developed to fully exploit the aperture of sparse ELAAs for high-resolution
angle estimation. Simulation results demonstrate that SS-ESPRIT provides
superior angular resolution for closely spaced far-field targets, while
SS-MUSIC offers robustness in near-field localization and flexibility in hybrid
scenarios.

</details>


### [21] [Predicting Chest Radiograph Findings from Electrocardiograms Using Interpretable Machine Learning](https://arxiv.org/abs/2509.17674)
*Julia Matejas,Olaf Żurawski,Nils Strodthoff,Juan Miguel Lopez Alcaraz*

Main category: eess.SP

TL;DR: 研究发现，心电图（ECG）特征和患者人口统计学数据可通过可解释的机器学习方法预测胸部X光检查结果，为资源有限地区提供早期分诊或预筛查的可能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的地区，胸部X光检查（CXR）难以及时获取，而ECG设备广泛可用且非侵入性。研究旨在探索ECG是否能替代CXR进行早期诊断。

Method: 使用MIMIC-IV数据库，通过XGBoost分类器训练模型，利用ECG特征和人口统计学数据预测CXR结果。采用递归特征消除和SHAP分析解释特征贡献。

Result: 模型对不同CXR结果的预测准确性不一。特征选择和加入人口统计学数据提升了性能。SHAP分析揭示了ECG特征的临床意义。

Conclusion: ECG特征结合人口统计学数据可作为CXR某些结果的替代指标，尤其在资源有限情况下。可解释的机器学习有望优化放射学工作流程和患者护理。

Abstract: Purpose: Chest X-rays are essential for diagnosing pulmonary conditions, but
limited access in resource-constrained settings can delay timely diagnosis.
Electrocardiograms (ECGs), in contrast, are widely available, non-invasive, and
often acquired earlier in clinical workflows. This study aims to assess whether
ECG features and patient demographics can predict chest radiograph findings
using an interpretable machine learning approach.
  Methods: Using the MIMIC-IV database, Extreme Gradient Boosting (XGBoost)
classifiers were trained to predict diverse chest radiograph findings from
ECG-derived features and demographic variables. Recursive feature elimination
was performed independently for each target to identify the most predictive
features. Model performance was evaluated using the area under the receiver
operating characteristic curve (AUROC) with bootstrapped 95% confidence
intervals. Shapley Additive Explanations (SHAP) were applied to interpret
feature contributions.
  Results: Models successfully predicted multiple chest radiograph findings
with varying accuracy. Feature selection tailored predictors to each target,
and including demographic variables consistently improved performance. SHAP
analysis revealed clinically meaningful contributions from ECG features to
radiographic predictions.
  Conclusion: ECG-derived features combined with patient demographics can serve
as a proxy for certain chest radiograph findings, enabling early triage or
pre-screening in settings where radiographic imaging is limited. Interpretable
machine learning demonstrates potential to support radiology workflows and
improve patient care.

</details>


### [22] [SSNet: Flexible and robust channel extrapolation for fluid antenna systems enabled by an self-supervised learning framework](https://arxiv.org/abs/2509.17797)
*Yuan Gao,Yiming Liu,Runze Yu,Shengli Liu,Yanliang Jin,Shunqing Zhang,Shugong Xu,Xiaoli Chu*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的自监督学习网络（SSNet），用于流体天线系统（FAS）中的高效自适应信道外推，避免了传统方法的计算复杂度高和适应性差的问题。


<details>
  <summary>Details</summary>
Motivation: FAS在6G通信中展现出高效频谱利用和鲁棒性优势，但其复杂物理结构导致信道状态信息（CSI）获取困难。传统方法计算复杂且适应性不足，数据驱动方法则依赖大量标注数据且易受噪声影响。

Method: SSNet将信道外推问题建模为图像重建任务，通过自监督学习减少对标注数据的依赖，并提出混合专家（MoE）模块以增强特征提取和抗噪能力。

Result: 实验结果证明SSNet在少量标注数据下显著优于AGMAE和LSTM网络等基准模型。

Conclusion: SSNet为FAS中的高效信道外推提供了创新解决方案，兼具高适应性和抗噪性能。

Abstract: Fluid antenna systems (FAS) signify a pivotal advancement in 6G communication
by enhancing spectral efficiency and robustness. However, obtaining accurate
channel state information (CSI) in FAS poses challenges due to its complex
physical structure. Traditional methods, such as pilot-based interpolation and
compressive sensing, are not only computationally intensive but also lack
adaptability. Current extrapolation techniques relying on rigid parametric
models do not accommodate the dynamic environment of FAS, while data-driven
deep learning approaches demand extensive training and are vulnerable to noise
and hardware imperfections. To address these challenges, this paper introduces
a novel self-supervised learning network (SSNet) designed for efficient and
adaptive channel extrapolation in FAS. We formulate the problem of channel
extrapolation in FAS as an image reconstruction task. Here, a limited number of
unmasked pixels (representing the known CSI of the selected ports) are used to
extrapolate the masked pixels (the CSI of unselected ports). SSNet capitalizes
on the intrinsic structure of FAS channels, learning generalized
representations from raw CSI data, thus reducing dependency on large labelled
datasets. For enhanced feature extraction and noise resilience, we propose a
mix-of-expert (MoE) module. In this setup, multiple feedforward neural networks
(FFNs) operate in parallel. The outputs of the MoE module are combined using a
weighted sum, determined by a gating function that computes the weights of each
FFN using a softmax function. Extensive simulations validate the superiority of
the proposed model. Results indicate that SSNet significantly outperforms
benchmark models, such as AGMAE and long short-term memory (LSTM) networks by
using a much smaller labelled dataset.

</details>


### [23] [Generalized Beyond-Diagonal RIS Architectures: Theory and Design via Structure-oriented Symmetric Unitary Projection](https://arxiv.org/abs/2509.17804)
*Xiaohua Zhou,Tianyu Fang,Yijie Mao,Bruno Clerckx*

Main category: eess.SP

TL;DR: 论文提出两种新型BD-RIS架构（stem-connected和cluster-connected），在电路复杂性和性能间取得平衡，并设计了通用的散射矩阵设计方法。


<details>
  <summary>Details</summary>
Motivation: BD-RIS技术在6G及未来网络中具有潜力，但其电路复杂度高，亟需新型架构以平衡性能与复杂性。

Method: 开发了stem-connected和cluster-connected RIS架构，并提出一种结构导向的对称酉投影方法，用于设计散射矩阵。

Result: stem-connected RIS能以更低复杂度达到与全连接RIS相同的性能；cluster-connected RIS框架更具灵活性。

Conclusion: 两种新型BD-RIS架构显著优化了性能与复杂性的权衡范围，算法高效且通用。

Abstract: Beyond-diagonal reconfigurable intelligent surface (BD-RIS), which enables
advanced wave control through interconnection of RIS elements, are gaining
growing recognition as a promising technology for 6G and beyond. However, the
enhanced flexibility of BD-RIS in controlling the phase and amplitude of
reflected signals comes at the cost of high circuit complexity. In this paper,
we propose two novel BD-RIS architectures, namely, the stem-connected RIS and
cluster-connected RIS, to explore trade-off between circuit complexity and
performance. Specifically, the proposed stem-connected RIS is capable of
achieving the same performance as fully-connected RIS while significantly
reducing circuit complexity. The proposed cluster-connected RIS offers a
unified framework that generalizes existing BD-RIS architectures--including
single-connected, fully-connected, group-connected, tree-connected (arrowhead),
and forest-connected (arrowhead) RISs--as special cases. This framework enables
a much more flexible trade-offs between circuit complexity and system
performance than existing ones. Based on the proposed BD-RIS architectures, we
introduce a novel and generalized structure-oriented symmetric unitary
projection method for designing the scattering matrix across all BD-RIS
configurations. This method is effectively applied to solve the sum channel
gain maximization problem and other utility-based optimization problems.
Numerical results demonstrate that the proposed stem-connected RIS is the
simplest architecture that achieves optimal BD-RIS performance, while the
cluster-connected RIS further enlarges the performance-complexity trade-off
range. Furthermore, the proposed projection-based algorithms demonstrate high
efficiency.

</details>


### [24] [Joint Pilot Allocation and Sequence Design for MIMO-OFDM Systems With Channel Sparsity](https://arxiv.org/abs/2509.17916)
*Kabuto Arai,Koji Ishibashi,Hiroki Iimori,Yuto Hama,Paulo Valente Klaine,Szabolcs Malomsoky*

Main category: eess.SP

TL;DR: 本文提出了一种联合优化方法，用于MIMO-OFDM系统中的导频子载波分配与非正交序列设计，以压缩感知为基础的信道估计为目标，最小化感知矩阵的相干性。


<details>
  <summary>Details</summary>
Motivation: 基于压缩感知的信道估计性能依赖于感知矩阵的相干性指标，因此需要一种高效的联合优化方法来最小化这一指标。

Method: 通过引入块稀疏惩罚，将离散变量问题转化为连续变量优化问题，并利用感知矩阵的结构计算相干性指标及其梯度，采用梯度下降法高效求解。

Result: 数值结果显示，所提出的导频序列具有优越的相干性，提升了基于压缩感知的信道估计性能。

Conclusion: 该方法通过联合优化导频分配与非正交序列设计，成功解决了MINLP的计算难题，显著提升了信道估计的效率与性能。

Abstract: This paper proposes a joint optimization of pilot subcarrier allocation and
non-orthogonal sequence for multiple-input-multiple-output (MIMO)-orthogonal
frequency-division multiplexing (OFDM) systems under compressed sensing
(CS)-based channel estimation exploiting delay and angle sparsity. Since the
performance of CS-based approaches depends on a coherence metric of the sensing
matrix in the measurement process, we formulate a joint optimization problem to
minimize this coherence. Due to the discrete nature of subcarrier allocation, a
straightforward formulation of the joint optimization results in a
mixed-integer nonlinear program (MINLP), which is computationally intractable
due to the combinatorial explosion of allocation candidates. To overcome the
intractability of discrete variables, we introduce a block sparse penalty for
pilots across all subcarriers, which ensures that the power of some unnecessary
pilots approaches zero. This framework enables joint optimization using only
continuous variables. In addition, we propose an efficient computation method
for the coherence metric by exploiting the structure of the sensing matrix,
which allows its gradient to be derived in closed form, making the joint
optimization problem solvable in an efficient way via a gradient descent
approach. Numerical results confirm that the proposed pilot sequence exhibits
superior coherence properties and enhances the CS-based channel estimation
performance.

</details>


### [25] [Autoregressive-Gaussian Mixture Models: Efficient Generative Modeling of WSS Signals](https://arxiv.org/abs/2509.17953)
*Kathrin Klein,Benedikt Böck,Nurettin Turan,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 提出了一种结合自回归参数化的高斯混合模型，适用于资源受限环境，减少了参数量但保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型在资源受限环境（如移动通信系统）中的适用性问题。

Method: 将自回归参数化集成到高斯混合模型中，用于建模宽平稳过程，并利用结构约束减少参数。

Result: 在小样本情况下优于标准高斯混合模型及其变体；在大数据集上与传统方法性能相当但计算效率更高。

Conclusion: 该方法在减少参数和计算负担的同时，保持了高建模精度，适用于资源受限环境。

Abstract: This work addresses the challenge of making generative models suitable for
resource-constrained environments like mobile wireless communication systems.
We propose a generative model that integrates Autoregressive (AR)
parameterization into a Gaussian Mixture Model (GMM) for modeling Wide-Sense
Stationary (WSS) processes. By exploiting model-based insights allowing for
structural constraints, the approach significantly reduces parameters while
maintaining high modeling accuracy. Channel estimation experiments show that
the model can outperform standard GMMs and variants using Toeplitz or circulant
covariances, particularly with small sample sizes. For larger datasets, it
matches the performance of conventional methods while improving computational
efficiency and reducing the memory requirements.

</details>


### [26] [Bridge Micro-Deformation Monitoring Scheme with Integrated Sensing and Communications](https://arxiv.org/abs/2509.17983)
*Boxuan Sun,Hongliang Luo,Shaodan Ma,Feifei Gao*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的集成传感与通信（ISAC）方案，用于复杂环境下的桥梁微变形监测（BMDM）。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂环境中实现桥梁微变形的精确监测。

Method: 提出了激振-桥梁耦合模型、OFDM回波信道模型，以及基于平均消除算法和最小二乘算法的相位统计分析与圆拟合方法。

Result: 仿真结果表明该方案能有效抑制动态和静态干扰，并准确提取微变形特征。

Conclusion: 所提出的BMDM方案在复杂环境中表现出高效性和鲁棒性。

Abstract: In this paper, we propose a novel integrated sensing and communications
(ISAC) scheme to perform bridge micro-deformation monitoring (BMDM) in complex
environments. We first provide an excitation-bridge coupling model to represent
the micro-deformation process of the bridge. Next, we design a novel frame
structure for BMDM applications, and construct the OFDM echo channel model for
basic scene of BMDM, including micro-deformation, dynamic objects, and static
environment. Then, we develop a phasor statistical analysis method based on
average cancellation algorithm to suppress the interference of dynamic objects,
as well as a circle fitting method based on least squares algorithm to remove
the interference of static environment near the monitoring area. Furthermore,
we extract the micro-deformation feature vector from the OFDM echo signals
after inverse discrete fourier transform (IDFT), and derive vertical
micro-deformation value with the time-frequency phase resources. Simulation
results demonstrate the effectiveness of the proposed BMDM scheme and its
robustness against both dynamic interferences and static interferences.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [27] [RaFD: Flow-Guided Radar Detection for Robust Autonomous Driving](https://arxiv.org/abs/2509.16261)
*Shuocheng Yang,Zikun Xu,Jiahao Wang,Shahid Nawaz,Jianqiang Wang,Shaobing Xu*

Main category: cs.RO

TL;DR: RaFD框架通过估计BEV流并结合几何线索，提升了雷达图像的物体检测精度，在RADIATE数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 雷达图像常受噪声和‘鬼影’干扰，仅依赖语义特征进行物体检测效果有限，因此需要结合几何信息以提升检测性能。

Method: 设计了监督流估计辅助任务，与检测网络联合训练，并利用流引导前一帧特征传播至当前帧。

Result: 在RADIATE数据集上实现了最先进的检测性能。

Conclusion: 结合几何信息能有效解决雷达信号的语义模糊性，提升检测效果。

Abstract: Radar has shown strong potential for robust perception in autonomous driving;
however, raw radar images are frequently degraded by noise and "ghost"
artifacts, making object detection based solely on semantic features highly
challenging. To address this limitation, we introduce RaFD, a radar-based
object detection framework that estimates inter-frame bird's-eye-view (BEV)
flow and leverages the resulting geometric cues to enhance detection accuracy.
Specifically, we design a supervised flow estimation auxiliary task that is
jointly trained with the detection network. The estimated flow is further
utilized to guide feature propagation from the previous frame to the current
one. Our flow-guided, radar-only detector achieves achieves state-of-the-art
performance on the RADIATE dataset, underscoring the importance of
incorporating geometric information to effectively interpret radar signals,
which are inherently ambiguous in semantics.

</details>


### [28] [Tactile-Based Human Intent Recognition for Robot Assistive Navigation](https://arxiv.org/abs/2509.16353)
*Shaoting Peng,Dakarai Crowder,Wenzhen Yuan,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: Tac-Nav是一种机器人辅助导航系统，通过圆柱形触觉皮肤提升导航意图识别的自然性和效率，采用的CK-SVM算法在模拟和真实数据中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助导航系统界面不够直观，无法模拟人类与护理者之间的高效物理交流，限制了其效果。

Method: 开发了Tac-Nav系统，使用圆柱形触觉皮肤和专门设计的CK-SVM算法来识别用户导航意图。

Result: CK-SVM在模拟和真实数据中的分类准确率分别达到97.1%和90.8%，用户更偏好触觉界面而非传统操控方式。

Conclusion: Tac-Nav通过触觉界面和CK-SVM算法显著提升了机器人辅助导航系统的性能和用户体验。

Abstract: Robot assistive navigation (RAN) is critical for enhancing the mobility and
independence of the growing population of mobility-impaired individuals.
However, existing systems often rely on interfaces that fail to replicate the
intuitive and efficient physical communication observed between a person and a
human caregiver, limiting their effectiveness. In this paper, we introduce
Tac-Nav, a RAN system that leverages a cylindrical tactile skin mounted on a
Stretch 3 mobile manipulator to provide a more natural and efficient interface
for human navigational intent recognition. To robustly classify the tactile
data, we developed the Cylindrical Kernel Support Vector Machine (CK-SVM), an
algorithm that explicitly models the sensor's cylindrical geometry and is
consequently robust to the natural rotational shifts present in a user's grasp.
Comprehensive experiments were conducted to demonstrate the effectiveness of
our classification algorithm and the overall system. Results show that CK-SVM
achieved superior classification accuracy on both simulated (97.1%) and
real-world (90.8%) datasets compared to four baseline models. Furthermore, a
pilot study confirmed that users more preferred the Tac-Nav tactile interface
over conventional joystick and voice-based controls.

</details>


### [29] [Dynamic Objects Relocalization in Changing Environments with Flow Matching](https://arxiv.org/abs/2509.16398)
*Francesco Argenziano,Miguel Saavedra-Ruiz,Sacha Morin,Daniele Nardi,Liam Paull*

Main category: cs.RO

TL;DR: FlowMaps利用Flow Matching模型预测动态环境中物体的多模态位置，解决未知重定位问题。


<details>
  <summary>Details</summary>
Motivation: 动态环境中物体的频繁移动增加任务失败风险，利用人类活动模式可预测物体位置。

Method: 提出基于Flow Matching的FlowMaps模型，推断物体在时空中的多模态位置。

Result: 实验结果支持假设，显示模型有效性。

Conclusion: FlowMaps为复杂应用奠定基础，代码已开源。

Abstract: Task and motion planning are long-standing challenges in robotics, especially
when robots have to deal with dynamic environments exhibiting long-term
dynamics, such as households or warehouses. In these environments, long-term
dynamics mostly stem from human activities, since previously detected objects
can be moved or removed from the scene. This adds the necessity to find such
objects again before completing the designed task, increasing the risk of
failure due to missed relocalizations. However, in these settings, the nature
of such human-object interactions is often overlooked, despite being governed
by common habits and repetitive patterns. Our conjecture is that these cues can
be exploited to recover the most likely objects' positions in the scene,
helping to address the problem of unknown relocalization in changing
environments. To this end we propose FlowMaps, a model based on Flow Matching
that is able to infer multimodal object locations over space and time. Our
results present statistical evidence to support our hypotheses, opening the way
to more complex applications of our approach. The code is publically available
at https://github.com/Fra-Tsuna/flowmaps

</details>


### [30] [Subteaming and Adaptive Formation Control for Coordinated Multi-Robot Navigation](https://arxiv.org/abs/2509.16412)
*Zihao Deng,Peng Gao,Williard Joshua Jose,Maggie Wigness,John Rogers,Brian Reily,Christopher Reardon,Hao Zhang*

Main category: cs.RO

TL;DR: 提出了一种新的子团队与自适应编队（STAF）方法，用于动态分割机器人团队并通过复杂场景。


<details>
  <summary>Details</summary>
Motivation: 需在复杂环境中保持机器人团队编队，但刚性编队在狭窄走廊等场景中不可行。

Method: 采用分层学习框架：高层深度图切割分割团队，中层图学习协调子团队导航，低层策略学习控制单个机器人。

Result: 在室内外环境中进行实验，STAF展示了子团队和自适应编队控制的新能力。

Conclusion: STAF在多机器人协同导航中表现优异，适用于挑战性场景。

Abstract: Coordinated multi-robot navigation is essential for robots to operate as a
team in diverse environments. During navigation, robot teams usually need to
maintain specific formations, such as circular formations to protect human
teammates at the center. However, in complex scenarios such as narrow
corridors, rigidly preserving predefined formations can become infeasible.
Therefore, robot teams must be capable of dynamically splitting into smaller
subteams and adaptively controlling the subteams to navigate through such
scenarios while preserving formations. To enable this capability, we introduce
a novel method for SubTeaming and Adaptive Formation (STAF), which is built
upon a unified hierarchical learning framework: (1) high-level deep graph cut
for team splitting, (2) intermediate-level graph learning for facilitating
coordinated navigation among subteams, and (3) low-level policy learning for
controlling individual mobile robots to reach their goal positions while
avoiding collisions. To evaluate STAF, we conducted extensive experiments in
both indoor and outdoor environments using robotics simulations and physical
robot teams. Experimental results show that STAF enables the novel capability
for subteaming and adaptive formation control, and achieves promising
performance in coordinated multi-robot navigation through challenging
scenarios. More details are available on the project website:
https://hcrlab.gitlab.io/project/STAF.

</details>


### [31] [End-to-end RL Improves Dexterous Grasping Policies](https://arxiv.org/abs/2509.16434)
*Ritvik Singh,Karl Van Wyk,Pieter Abbeel,Jitendra Malik,Nathan Ratliff,Ankur Handa*

Main category: cs.RO

TL;DR: 该研究提出了一种将模拟器和强化学习解耦到不同GPU上的新方法，以解决基于视觉的强化学习在训练过程中的瓶颈问题，显著提升了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何扩展基于视觉的端到端学习方法，以解决传统数据并行技术在训练基于视觉的强化学习策略时内存效率低下的问题。

Method: 提出将模拟器与强化学习（包括训练和经验缓冲区）解耦到不同GPU上的方法，利用多GPU节点提高环境数量和训练效率。

Result: 通过解耦方法，环境数量相较传统数据并行技术翻倍，深度蒸馏至RGB网络的策略表现更优，仿真和实际部署中均显著提升性能。

Conclusion: 解耦模拟器和强化学习的方法有效提升了基于视觉的端到端学习效率，并在实际应用中取得了优于现有技术的效果。

Abstract: This work explores techniques to scale up image-based end-to-end learning for
dexterous grasping with an arm + hand system. Unlike state-based RL,
vision-based RL is much more memory inefficient, resulting in relatively low
batch sizes, which is not amenable for algorithms like PPO. Nevertheless, it is
still an attractive method as unlike the more commonly used techniques which
distill state-based policies into vision networks, end-to-end RL can allow for
emergent active vision behaviors. We identify a key bottleneck in training
these policies is the way most existing simulators scale to multiple GPUs using
traditional data parallelism techniques. We propose a new method where we
disaggregate the simulator and RL (both training and experience buffers) onto
separate GPUs. On a node with four GPUs, we have the simulator running on three
of them, and PPO running on the fourth. We are able to show that with the same
number of GPUs, we can double the number of existing environments compared to
the previous baseline of standard data parallelism. This allows us to train
vision-based environments, end-to-end with depth, which were previously
performing far worse with the baseline. We train and distill both depth and
state-based policies into stereo RGB networks and show that depth distillation
leads to better results, both in simulation and reality. This improvement is
likely due to the observability gap between state and vision policies which
does not exist when distilling depth policies into stereo RGB. We further show
that the increased batch size brought about by disaggregated simulation also
improves real world performance. When deploying in the real world, we improve
upon the previous state-of-the-art vision-based results using our end-to-end
policies.

</details>


### [32] [FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning](https://arxiv.org/abs/2509.16445)
*Naoki Yokoyama,Sehoon Ha*

Main category: cs.RO

TL;DR: FiLM-Nav是一种通过直接微调预训练视觉语言模型（VLM）来实现导航的方法，能够基于轨迹历史和导航目标选择最佳探索路径，在HM3D ObjectNav和HM3D-OVON基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究目标是使机器人助手能够在复杂环境中导航并定位自由语言描述的对象，利用VLM的语义理解能力来解决现实世界中的导航挑战。

Method: FiLM-Nav直接微调预训练VLM作为导航策略，结合模拟数据（ObjectNav、OVON、ImageNav和空间推理任务）进行训练，以适配具体的导航动态和视觉模式。

Result: FiLM-Nav在HM3D ObjectNav中实现了最高的SPL和成功率，在HM3D-OVON基准测试中也达到了SPL的最优性能，表现出对未见对象类别的强泛化能力。

Conclusion: 研究表明，直接在多样化的模拟数据上微调VLM是实现通用且高效语义导航能力的有效途径。

Abstract: Enabling robotic assistants to navigate complex environments and locate
objects described in free-form language is a critical capability for real-world
deployment. While foundation models, particularly Vision-Language Models
(VLMs), offer powerful semantic understanding, effectively adapting their
web-scale knowledge for embodied decision-making remains a key challenge. We
present FiLM-Nav (Fine-tuned Language Model for Navigation), an approach that
directly fine-tunes pre-trained VLM as the navigation policy. In contrast to
methods that use foundation models primarily in a zero-shot manner or for map
annotation, FiLM-Nav learns to select the next best exploration frontier by
conditioning directly on raw visual trajectory history and the navigation goal.
Leveraging targeted simulated embodied experience allows the VLM to ground its
powerful pre-trained representations in the specific dynamics and visual
patterns relevant to goal-driven navigation. Critically, fine-tuning on a
diverse data mixture combining ObjectNav, OVON, ImageNav, and an auxiliary
spatial reasoning task proves essential for achieving robustness and broad
generalization. FiLM-Nav sets a new state-of-the-art in both SPL and success
rate on HM3D ObjectNav among open-vocabulary methods, and sets a
state-of-the-art SPL on the challenging HM3D-OVON benchmark, demonstrating
strong generalization to unseen object categories. Our work validates that
directly fine-tuning VLMs on diverse simulated embodied data is a highly
effective pathway towards generalizable and efficient semantic navigation
capabilities.

</details>


### [33] [A Framework for Optimal Ankle Design of Humanoid Robots](https://arxiv.org/abs/2509.16469)
*Guglielmo Cervettini,Roberto Mauceri,Alex Coppola,Fabio Bergonti,Luca Fiorio,Marco Maggiali,Daniele Pucci*

Main category: cs.RO

TL;DR: 本文提出了一种统一的并联踝关节机构设计与评估方法，通过多目标优化生成几何结构，并采用标量成本函数评估性能，验证了优化设计的高效性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人踝关节的设计对安全高效的地面交互至关重要，但目前设计依赖于执行器可用性和任务需求，缺乏统一评估方法。

Method: 提出了基于多目标优化的并联踝关节设计方法，分析了SPU和RSU两种架构，改进了RSU的可行工作空间参数化方法。

Result: 优化后的RSU设计在性能上优于原始串行设计和传统RSU，成本函数分别降低41%和14%。

Conclusion: 统一的设计与评估方法能够显著提升并联踝关节的性能，为机器人设计提供更高效的支持。

Abstract: The design of the humanoid ankle is critical for safe and efficient ground
interaction. Key factors such as mechanical compliance and motor mass
distribution have driven the adoption of parallel mechanism architectures.
However, selecting the optimal configuration depends on both actuator
availability and task requirements. We propose a unified methodology for the
design and evaluation of parallel ankle mechanisms. A multi-objective
optimization synthesizes the mechanism geometry, the resulting solutions are
evaluated using a scalar cost function that aggregates key performance metrics
for cross-architecture comparison. We focus on two representative
architectures: the Spherical-Prismatic-Universal (SPU) and the
Revolute-Spherical-Universal (RSU). For both, we resolve the kinematics, and
for the RSU, introduce a parameterization that ensures workspace feasibility
and accelerates optimization. We validate our approach by redesigning the ankle
of an existing humanoid robot. The optimized RSU consistently outperforms both
the original serial design and a conventionally engineered RSU, reducing the
cost function by up to 41% and 14%, respectively.

</details>


### [34] [Robot Conga: A Leader-Follower Walking Approach to Sequential Path Following in Multi-Agent Systems](https://arxiv.org/abs/2509.16482)
*Pranav Tiwari,Soumyodipta Nath*

Main category: cs.RO

TL;DR: 提出了一种基于空间位移的领导者-跟随控制策略Robot Conga，解决了多机器人系统路径跟随中的同步和刚性行为问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于时间的路径跟随方法在同步和灵活性上存在问题，因此需要一种新的控制策略来提高多机器人系统的路径跟随性能。

Method: 采用领导者-跟随策略，通过空间位移而非时间参数更新跟随者的期望状态，依赖全局位置参考。

Result: 仿真实验验证了算法的有效性，TurtleBot3和四足机器人都能快速收敛并保持稳定的间距。

Conclusion: Robot Conga算法在多机器人路径跟随中表现出高效性和适应性，适用于室内环境。

Abstract: Coordinated path following in multi-agent systems is a key challenge in
robotics, with applications in automated logistics, surveillance, and
collaborative exploration. Traditional formation control techniques often rely
on time-parameterized trajectories and path integrals, which can result in
synchronization issues and rigid behavior. In this work, we address the problem
of sequential path following, where agents maintain fixed spatial separation
along a common trajectory, guided by a leader under centralized control. We
introduce Robot Conga, a leader-follower control strategy that updates each
agent's desired state based on the leader's spatial displacement rather than
time, assuming access to a global position reference, an assumption valid in
indoor environments equipped with motion capture, vision-based tracking, or UWB
localization systems. The algorithm was validated in simulation using both
TurtleBot3 and quadruped (Laikago) robots. Results demonstrate accurate
trajectory tracking, stable inter-agent spacing, and fast convergence, with all
agents aligning within 250 time steps (approx. 0.25 seconds) in the quadruped
case, and almost instantaneously in the TurtleBot3 implementation.

</details>


### [35] [Substrate-Timing-Independence for Meta-State Stability of Distributed Robotic Swarms](https://arxiv.org/abs/2509.16492)
*Tinapat Limsila,Mehul Sharma,Paulo Garcia*

Main category: cs.RO

TL;DR: 论文提出了一种基于并发过程演算的方法，用于分析机器人群体设计中的时间无关性正确性问题，通过识别和纠正可能导致错误元状态的设计问题。


<details>
  <summary>Details</summary>
Motivation: 分布式系统中的时序不可预测性会导致错误元状态，机器人群体中这一问题尤为突出，而实证验证成本过高，因此需要一种形式化方法来独立于底层时序进行分析。

Method: 利用并发过程演算（如通信顺序进程），提出了一种自动识别和纠正潜在错误元状态的方法，确保设计在时序变化下保持稳定。

Result: 实验验证表明，该方法能有效识别并纠正问题，机器人群体在修正后行为一致正确。

Conclusion: 该技术可推广至不同设计方法，为机器人学提供了一种形式化工具。

Abstract: Emergent properties in distributed systems arise due to timing
unpredictability; asynchronous state evolution within each sub-system may lead
the macro-system to faulty meta-states. Empirical validation of correctness is
often prohibitively expensive, as the size of the state-space is too large to
be tractable. In robotic swarms this problem is exacerbated, when compared to
software systems, by the variability of the implementation substrate across the
design, or even the deployment, process. We present an approach for formally
reasoning about the correctness of robotic swarm design in a
substrate-timing-independent way. By leveraging concurrent process calculi
(namely, Communicating Sequential Processes), we introduce a methodology that
can automatically identify possible causes of faulty meta-states and correct
such designs such that meta-states are consistently stable, even in the
presence of timing variability due to substrate changes. We evaluate this
approach on a robotic swarm with a clearly identified fault, realized in both
simulation and reality. Results support the research hypothesis, showing that
the swarm reaches an illegal meta-state before the correction is applied, but
behaves consistently correctly after the correction. Our techniques are
transferable across different design methodologies, contributing to the toolbox
of formal methods for roboticists.

</details>


### [36] [No Need for Real 3D: Fusing 2D Vision with Pseudo 3D Representations for Robotic Manipulation Learning](https://arxiv.org/abs/2509.16532)
*Run Yu,Yangdi Liu,Wen-Da Wei,Chen Li*

Main category: cs.RO

TL;DR: 论文提出了一种名为NoReal3D的新框架，通过3DStructureFormer模块将单目图像转换为几何上有意义的伪点云特征，解决了3D点云数据获取成本高的问题，提升了机器人对3D空间结构的理解。


<details>
  <summary>Details</summary>
Motivation: 解决3D点云数据获取成本高的问题，同时保持3D信息对性能的优势。

Method: 提出3DStructureFormer模块，生成伪点云特征并与2D编码器输出特征融合，设计伪点云编码器保留几何结构。

Result: 实验表明，该框架在多项任务中性能与基于真实点云的方法相当，且成本大幅降低。

Conclusion: NoReal3D框架有效替代了传统点云数据，在保持性能的同时显著降低了成本。

Abstract: Recently,vision-based robotic manipulation has garnered significant attention
and witnessed substantial advancements. 2D image-based and 3D point cloud-based
policy learning represent two predominant paradigms in the field, with recent
studies showing that the latter consistently outperforms the former in terms of
both policy performance and generalization, thereby underscoring the value and
significance of 3D information. However, 3D point cloud-based approaches face
the significant challenge of high data acquisition costs, limiting their
scalability and real-world deployment. To address this issue, we propose a
novel framework NoReal3D: which introduces the 3DStructureFormer, a learnable
3D perception module capable of transforming monocular images into
geometrically meaningful pseudo-point cloud features, effectively fused with
the 2D encoder output features. Specially, the generated pseudo-point clouds
retain geometric and topological structures so we design a pseudo-point cloud
encoder to preserve these properties, making it well-suited for our framework.
We also investigate the effectiveness of different feature fusion
strategies.Our framework enhances the robot's understanding of 3D spatial
structures while completely eliminating the substantial costs associated with
3D point cloud acquisition.Extensive experiments across various tasks validate
that our framework can achieve performance comparable to 3D point cloud-based
methods, without the actual point cloud data.

</details>


### [37] [TranTac: Leveraging Transient Tactile Signals for Contact-Rich Robotic Manipulation](https://arxiv.org/abs/2509.16550)
*Yinghao Wu,Shuhong Hou,Haowen Zheng,Yichen Li,Weiyi Lu,Xun Zhou,Yitian Shao*

Main category: cs.RO

TL;DR: TranTac是一种低成本、高效的数据触觉感应与控制框架，通过结合单点触敏6轴IMU和变压器编码器，提升了机器人精细插入任务的完成率。


<details>
  <summary>Details</summary>
Motivation: 解决视觉感知不足时机器人插入任务失败的问题，利用触觉感应实现精确调整。

Method: 集成6轴IMU于弹性体夹持器尖端，结合变压器编码器和扩散策略，模仿人类插入行为。

Result: TranTac在结合视觉的情况下插入任务成功率达79%，优于纯视觉和6D力传感方法；触觉定位任务成功率达88%。

Conclusion: TranTac展示了在精细操作任务中的潜力，可推广至未见过的物体任务。

Abstract: Robotic manipulation tasks such as inserting a key into a lock or plugging a
USB device into a port can fail when visual perception is insufficient to
detect misalignment. In these situations, touch sensing is crucial for the
robot to monitor the task's states and make precise, timely adjustments.
Current touch sensing solutions are either insensitive to detect subtle changes
or demand excessive sensor data. Here, we introduce TranTac, a data-efficient
and low-cost tactile sensing and control framework that integrates a single
contact-sensitive 6-axis inertial measurement unit within the elastomeric tips
of a robotic gripper for completing fine insertion tasks. Our customized
sensing system can detect dynamic translational and torsional deformations at
the micrometer scale, enabling the tracking of visually imperceptible pose
changes of the grasped object. By leveraging transformer-based encoders and
diffusion policy, TranTac can imitate human insertion behaviors using transient
tactile cues detected at the gripper's tip during insertion processes. These
cues enable the robot to dynamically control and correct the 6-DoF pose of the
grasped object. When combined with vision, TranTac achieves an average success
rate of 79% on object grasping and insertion tasks, outperforming both
vision-only policy and the one augmented with end-effector 6D force/torque
sensing. Contact localization performance is also validated through
tactile-only misaligned insertion tasks, achieving an average success rate of
88%. We assess the generalizability by training TranTac on a single prism-slot
pair and testing it on unseen data, including a USB plug and a metal key, and
find that the insertion tasks can still be completed with an average success
rate of nearly 70%. The proposed framework may inspire new robotic tactile
sensing systems for delicate manipulation tasks.

</details>


### [38] [Video-to-BT: Generating Reactive Behavior Trees from Human Demonstration Videos for Robotic Assembly](https://arxiv.org/abs/2509.16611)
*Xiwei Zhao,Yiwei Wang,Yansong Wu,Fan Wu,Teng Sun,Zhonghua Miao,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: 论文提出了一种名为Video-to-BT的分层框架，通过结合行为树（BTs）和视觉语言模型（VLM），将人类示范视频分解为子任务并生成行为树，实现了灵活可靠的机器人装配系统。


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配系统缺乏灵活性和适应性，难以应对产品变化和环境波动。为提升系统的灵活性和可靠性，作者提出了结合行为树和视觉语言模型的新方法。

Method: 利用视觉语言模型（VLM）分析人类示范视频，生成行为树（BTs）。在执行过程中，结合实时场景解读和VLM驱动的重新规划，形成一个闭环结构。

Result: 实验验证表明，该系统在真实装配任务中表现出高规划可靠性、长时程任务中的稳健性能，以及对多样化和干扰条件的强泛化能力。

Conclusion: Video-to-BT框架通过结合行为树和视觉语言模型，有效提升了机器人装配系统的灵活性和可靠性，适用于动态环境中的复杂任务。

Abstract: Modern manufacturing demands robotic assembly systems with enhanced
flexibility and reliability. However, traditional approaches often rely on
programming tailored to each product by experts for fixed settings, which are
inherently inflexible to product changes and lack the robustness to handle
variations. As Behavior Trees (BTs) are increasingly used in robotics for their
modularity and reactivity, we propose a novel hierarchical framework,
Video-to-BT, that seamlessly integrates high-level cognitive planning with
low-level reactive control, with BTs serving both as the structured output of
planning and as the governing structure for execution. Our approach leverages a
Vision-Language Model (VLM) to decompose human demonstration videos into
subtasks, from which Behavior Trees are generated. During the execution, the
planned BTs combined with real-time scene interpretation enable the system to
operate reactively in the dynamic environment, while VLM-driven replanning is
triggered upon execution failure. This closed-loop architecture ensures
stability and adaptivity. We validate our framework on real-world assembly
tasks through a series of experiments, demonstrating high planning reliability,
robust performance in long-horizon assembly tasks, and strong generalization
across diverse and perturbed conditions. Project website:
https://video2bt.github.io/video2bt_page/

</details>


### [39] [ORN-CBF: Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks](https://arxiv.org/abs/2509.16614)
*Bojan Derajić,Sebastian Bernhard,Wolfgang Hönig*

Main category: cs.RO

TL;DR: 论文提出了一种基于Hamilton-Jacobi可达性分析的观测条件神经控制屏障函数（CBFs），用于解决现有学习型CBFs中的次优安全集、部分可观测环境适用性和缺乏严格安全保证的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CBFs设计复杂，学习型方法存在安全集不足、部分观测环境不适用且缺乏严格安全保证的缺陷，亟需改进。

Method: 基于Hamilton-Jacobi可达性分析设计观测条件神经CBFs，利用HJ值函数的数学特性确保安全集不与失败集相交，并采用超网络架构适配安全滤波器设计。

Result: 在模拟和硬件实验中，该方法在地面机器人和四轴飞行器上表现出更高的成功率和更好的泛化能力。

Conclusion: 提出的方法有效解决了现有CBFs的问题，验证了其在安全控制和泛化能力上的优势。

Abstract: Control barrier functions (CBFs) have been demonstrated as an effective
method for safety-critical control of autonomous systems. Although CBFs are
simple to deploy, their design remains challenging, motivating the development
of learning-based approaches. Yet, issues such as suboptimal safe sets,
applicability in partially observable environments, and lack of rigorous safety
guarantees persist. In this work, we propose observation-conditioned neural
CBFs based on Hamilton-Jacobi (HJ) reachability analysis, which approximately
recover the maximal safe sets. We exploit certain mathematical properties of
the HJ value function, ensuring that the predicted safe set never intersects
with the observed failure set. Moreover, we leverage a hypernetwork-based
architecture that is particularly suitable for the design of
observation-conditioned safety filters. The proposed method is examined both in
simulation and hardware experiments for a ground robot and a quadcopter. The
results show improved success rates and generalization to out-of-domain
environments compared to the baselines.

</details>


### [40] [LLM-Guided Task- and Affordance-Level Exploration in Reinforcement Learning](https://arxiv.org/abs/2509.16615)
*Jelle Luijkx,Runyu Ma,Zlatan Ajanović,Jens Kober*

Main category: cs.RO

TL;DR: 论文提出LLM-TALE框架，通过结合大语言模型（LLM）的规划能力引导强化学习（RL）的探索，提高样本效率和学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在机器人操作中样本效率低且探索空间大，而LLM生成的任务规划可能存在物理不可行的问题。

Method: LLM-TALE在任务层面和可操作性层面整合LLM的规划，动态纠正次优计划并实现多模式探索。

Result: 在标准RL基准测试中，LLM-TALE提高了样本效率和成功率，并在真实机器人上展示了零样本迁移能力。

Conclusion: LLM-TALE通过有效利用LLM的规划能力，为强化学习的机器人操作任务提供了一种高效且可靠的解决方案。

Abstract: Reinforcement learning (RL) is a promising approach for robotic manipulation,
but it can suffer from low sample efficiency and requires extensive exploration
of large state-action spaces. Recent methods leverage the commonsense knowledge
and reasoning abilities of large language models (LLMs) to guide exploration
toward more meaningful states. However, LLMs can produce plans that are
semantically plausible yet physically infeasible, yielding unreliable behavior.
We introduce LLM-TALE, a framework that uses LLMs' planning to directly steer
RL exploration. LLM-TALE integrates planning at both the task level and the
affordance level, improving learning efficiency by directing agents toward
semantically meaningful actions. Unlike prior approaches that assume optimal
LLM-generated plans or rewards, LLM-TALE corrects suboptimality online and
explores multimodal affordance-level plans without human supervision. We
evaluate LLM-TALE on pick-and-place tasks in standard RL benchmarks, observing
improvements in both sample efficiency and success rates over strong baselines.
Real-robot experiments indicate promising zero-shot sim-to-real transfer. Code
and supplementary material are available at https://llm-tale.github.io.

</details>


### [41] [KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control](https://arxiv.org/abs/2509.16638)
*Jinrui Han,Weiji Xie,Jiakun Zheng,Jiyuan Shi,Weinan Zhang,Ting Xiao,Chenjia Bai*

Main category: cs.RO

TL;DR: VMS是一个统一的全身控制器，通过混合跟踪目标和OMoE架构实现了多样化运动技能的模仿与稳定性。


<details>
  <summary>Details</summary>
Motivation: 通过学习多样化的全身运动技能，提升通用人形机器人的多功能性和稳定性。

Method: 结合混合跟踪目标和OMoE架构，引入了分段级别跟踪奖励以增强鲁棒性。

Result: 在仿真和现实实验中，VMS能够准确模仿动态技能，并在长时间序列中保持稳定，对未见过的动作具有强泛化能力。

Conclusion: VMS作为多功能人形机器人控制的扩展基础具有巨大潜力。

Abstract: Learning versatile whole-body skills by tracking various human motions is a
fundamental step toward general-purpose humanoid robots. This task is
particularly challenging because a single policy must master a broad repertoire
of motion skills while ensuring stability over long-horizon sequences. To this
end, we present VMS, a unified whole-body controller that enables humanoid
robots to learn diverse and dynamic behaviors within a single policy. Our
framework integrates a hybrid tracking objective that balances local motion
fidelity with global trajectory consistency, and an Orthogonal
Mixture-of-Experts (OMoE) architecture that encourages skill specialization
while enhancing generalization across motions. A segment-level tracking reward
is further introduced to relax rigid step-wise matching, enhancing robustness
when handling global displacements and transient inaccuracies. We validate VMS
extensively in both simulation and real-world experiments, demonstrating
accurate imitation of dynamic skills, stable performance over minute-long
sequences, and strong generalization to unseen motions. These results highlight
the potential of VMS as a scalable foundation for versatile humanoid whole-body
control. The project page is available at
https://kungfubot2-humanoid.github.io.

</details>


### [42] [HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos](https://arxiv.org/abs/2509.16757)
*Haoyang Weng,Yitang Li,Nikhil Sobanbabu,Zihan Wang,Zhengyi Luo,Tairan He,Deva Ramanan,Guanya Shi*

Main category: cs.RO

TL;DR: HDMI框架通过学习单目RGB视频实现人形机器人全身交互，解决了运动数据稀缺和接触密集的挑战，展示了模拟到现实的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人与人-物体交互(WOI)中的数据稀缺和接触密集问题，提升交互能力。

Method: 通过提取并重定向视频中的人类和物体轨迹构建数据集，结合统一物体表示、残差动作空间和交互奖励训练RL策略，并直接在真实机器人上部署。

Result: 在Unitree G1人形机器人上实现了67次连续门穿越和6种真实世界的运动操作任务，以及14种模拟任务。

Conclusion: HDMI是一种简单且通用的框架，能够从人类视频中学习交互技能。

Abstract: Enabling robust whole-body humanoid-object interaction (HOI) remains
challenging due to motion data scarcity and the contact-rich nature. We present
HDMI (HumanoiD iMitation for Interaction), a simple and general framework that
learns whole-body humanoid-object interaction skills directly from monocular
RGB videos. Our pipeline (i) extracts and retargets human and object
trajectories from unconstrained videos to build structured motion datasets,
(ii) trains a reinforcement learning (RL) policy to co-track robot and object
states with three key designs: a unified object representation, a residual
action space, and a general interaction reward, and (iii) zero-shot deploys the
RL policies on real humanoid robots. Extensive sim-to-real experiments on a
Unitree G1 humanoid demonstrate the robustness and generality of our approach:
HDMI achieves 67 consecutive door traversals and successfully performs 6
distinct loco-manipulation tasks in the real world and 14 tasks in simulation.
Our results establish HDMI as a simple and general framework for acquiring
interactive humanoid skills from human videos.

</details>


### [43] [Improve bounding box in Carla Simulator](https://arxiv.org/abs/2509.16773)
*Mohamad Mofeed Chaar,Jamal Raiyn,Galia Weidl*

Main category: cs.RO

TL;DR: 本文介绍了CARLA模拟器中用于自动驾驶数据生成的边界框方法，并针对其主要问题（如幽灵框和误检）提出了改进方案，结果表明改进方法具有高准确性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要高效准确的边界框标注方法，但现有方法存在误检和幽灵框等问题，因此需要改进。

Method: 通过在CARLA模拟器中捕获物体坐标，并相对于自车的坐标系生成边界框，改进方法进一步过滤了不必要的框。

Result: 性能分析显示，改进方法显著提高了边界框标注的准确性。

Conclusion: 改进后的方法有效解决了幽灵框和误检问题，为自动驾驶数据生成提供了更可靠的解决方案。

Abstract: The CARLA simulator (Car Learning to Act) serves as a robust platform for
testing algorithms and generating datasets in the field of Autonomous Driving
(AD). It provides control over various environmental parameters, enabling
thorough evaluation. Development bounding boxes are commonly utilized tools in
deep learning and play a crucial role in AD applications. The predominant
method for data generation in the CARLA Simulator involves identifying and
delineating objects of interest, such as vehicles, using bounding boxes. The
operation in CARLA entails capturing the coordinates of all objects on the map,
which are subsequently aligned with the sensor's coordinate system at the ego
vehicle and then enclosed within bounding boxes relative to the ego vehicle's
perspective. However, this primary approach encounters challenges associated
with object detection and bounding box annotation, such as ghost boxes.
Although these procedures are generally effective at detecting vehicles and
other objects within their direct line of sight, they may also produce false
positives by identifying objects that are obscured by obstructions. We have
enhanced the primary approach with the objective of filtering out unwanted
boxes. Performance analysis indicates that the improved approach has achieved
high accuracy.

</details>


### [44] [SMART-3D: Three-Dimensional Self-Morphing Adaptive Replanning Tree](https://arxiv.org/abs/2509.16812)
*Priyanshu Agrawal,Shalabh Gupta,Zongyuan Shen*

Main category: cs.RO

TL;DR: SMART-3D是SMART算法的3D扩展，通过树形结构和热点节点实现动态环境中的实时路径规划。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境下快速障碍物的实时路径规划问题。

Method: 采用树形自适应重规划算法，利用热点节点替代网格分解以提高计算效率。

Result: 在2D和3D环境中成功率高且重规划时间短。

Conclusion: SMART-3D适合实时应用。

Abstract: This paper presents SMART-3D, an extension of the SMART algorithm to 3D
environments. SMART-3D is a tree-based adaptive replanning algorithm for
dynamic environments with fast moving obstacles. SMART-3D morphs the underlying
tree to find a new path in real-time whenever the current path is blocked by
obstacles. SMART-3D removed the grid decomposition requirement of the SMART
algorithm by replacing the concept of hot-spots with that of hot-nodes, thus
making it computationally efficient and scalable to 3D environments. The
hot-nodes are nodes which allow for efficient reconnections to morph the
existing tree to find a new safe and reliable path. The performance of SMART-3D
is evaluated by extensive simulations in 2D and 3D environments populated with
randomly moving dynamic obstacles. The results show that SMART-3D achieves high
success rates and low replanning times, thus highlighting its suitability for
real-time onboard applications.

</details>


### [45] [Factorizing Diffusion Policies for Observation Modality Prioritization](https://arxiv.org/abs/2509.16830)
*Omkar Patil,Prabin Rath,Kartikay Pangaonkar,Eric Rosen,Nakul Gopalan*

Main category: cs.RO

TL;DR: 该论文提出了一种名为'因子化扩散策略'(FDP)的新方法，通过设计使不同观测模态在动作扩散过程中具有不同的影响力，从而提高了策略的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在处理多模态观测时，未能捕捉不同模态对任务的不同影响力，导致策略性能不足或鲁棒性差。

Method: FDP通过因子化观测条件的方法，使得某些模态（如视觉或触觉）能够优先影响扩散过程。

Result: FDP在低数据环境下表现出显著改进（成功率高15%），并且在分布偏移情况下（如视觉干扰或相机遮挡）鲁棒性更强（成功率高40%）。

Conclusion: FDP为实际场景中的部署提供了比标准扩散策略更安全、更鲁棒的替代方案。

Abstract: Diffusion models have been extensively leveraged for learning robot skills
from demonstrations. These policies are conditioned on several observational
modalities such as proprioception, vision and tactile. However, observational
modalities have varying levels of influence for different tasks that diffusion
polices fail to capture. In this work, we propose 'Factorized Diffusion
Policies' abbreviated as FDP, a novel policy formulation that enables
observational modalities to have differing influence on the action diffusion
process by design. This results in learning policies where certain observations
modalities can be prioritized over the others such as $\texttt{vision>tactile}$
or $\texttt{proprioception>vision}$. FDP achieves modality prioritization by
factorizing the observational conditioning for diffusion process, resulting in
more performant and robust policies. Our factored approach shows strong
performance improvements in low-data regimes with $15\%$ absolute improvement
in success rate on several simulated benchmarks when compared to a standard
diffusion policy that jointly conditions on all input modalities. Moreover, our
benchmark and real-world experiments show that factored policies are naturally
more robust with $40\%$ higher absolute success rate across several visuomotor
tasks under distribution shifts such as visual distractors or camera
occlusions, where existing diffusion policies fail catastrophically. FDP thus
offers a safer and more robust alternative to standard diffusion policies for
real-world deployment. Videos are available at
https://fdp-policy.github.io/fdp-policy/ .

</details>


### [46] [Robot Learning with Sparsity and Scarcity](https://arxiv.org/abs/2509.16834)
*Jingxi Xu*

Main category: cs.RO

TL;DR: 论文讨论了机器人学习中的两大挑战：数据稀疏性和数据稀缺性，并通过触觉传感和康复机器人两个领域的研究展示了解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器人学习缺乏大规模数据资源，具体表现为数据稀疏性和数据稀缺性，需要有效的算法来解决这些问题。

Method: 在触觉传感领域，使用无模型强化学习从稀疏的触觉信息中学习探索和操控策略；在康复机器人领域，采用半监督学习、元学习和生成AI方法，从少量生物信号中推断患者意图。

Result: 提出的算法能够高效利用稀疏的触觉数据，并在数据极少的康复机器人任务中成功推断患者意图。

Conclusion: 通过针对数据稀疏性和稀缺性的算法设计，可以有效提升机器人学习的性能，特别是在触觉传感和康复机器人领域。

Abstract: Unlike in language or vision, one of the fundamental challenges in robot
learning is the lack of access to vast data resources. We can further break
down the problem into (1) data sparsity from the angle of data representation
and (2) data scarcity from the angle of data quantity. In this thesis, I will
discuss selected works on two domains: (1) tactile sensing and (2)
rehabilitation robots, which are exemplars of data sparsity and scarcity,
respectively. Tactile sensing is an essential modality for robotics, but
tactile data are often sparse, and for each interaction with the physical
world, tactile sensors can only obtain information about the local area of
contact. I will discuss my work on learning vision-free tactile-only
exploration and manipulation policies through model-free reinforcement learning
to make efficient use of sparse tactile information. On the other hand,
rehabilitation robots are an example of data scarcity to the extreme due to the
significant challenge of collecting biosignals from disabled-bodied subjects at
scale for training. I will discuss my work in collaboration with the medical
school and clinicians on intent inferral for stroke survivors, where a hand
orthosis developed in our lab collects a set of biosignals from the patient and
uses them to infer the activity that the patient intends to perform, so the
orthosis can provide the right type of physical assistance at the right moment.
My work develops machine learning algorithms that enable intent inferral with
minimal data, including semi-supervised, meta-learning, and generative AI
methods.

</details>


### [47] [Benchmarking Offline Reinforcement Learning for Emotion-Adaptive Social Robotics](https://arxiv.org/abs/2509.16858)
*Soon Jynn Chu,Raju Gottumukkala,Alan Barhorst*

Main category: cs.RO

TL;DR: 论文研究了离线强化学习在情感自适应社交机器人中的应用，通过预收集数据解决了在线学习的高成本和安全性问题，并比较了不同算法的性能。


<details>
  <summary>Details</summary>
Motivation: 开发能够响应人类情感的社交机器人需要高效且安全的方法，而在线强化学习因数据收集成本高和潜在风险不适用。

Method: 采用离线强化学习技术，利用预收集数据构建系统架构，结合多模态感知、决策和自适应响应，并在人机游戏场景中进行算法比较。

Result: BCQ和CQL算法在数据稀疏情况下表现更优，相比NFQ、DQN和DDQN具有更高的状态-动作价值。

Conclusion: 研究为情感自适应机器人的离线强化学习提供了基准，并为未来实际应用（如对话代理、教育伙伴等）奠定了基础。

Abstract: The ability of social robots to respond to human emotions is crucial for
building trust and acceptance in human-robot collaborative environments.
However, developing such capabilities through online reinforcement learning is
sometimes impractical due to the prohibitive cost of data collection and the
risk of generating unsafe behaviors. In this paper, we study the use of offline
reinforcement learning as a practical and efficient alternative. This technique
uses pre-collected data to enable emotion-adaptive social robots. We present a
system architecture that integrates multimodal sensing and recognition,
decision-making, and adaptive responses. Using a limited dataset from a
human-robot game-playing scenario, we establish a benchmark for comparing
offline reinforcement learning algorithms that do not require an online
environment. Our results show that BCQ and CQL are more robust to data
sparsity, achieving higher state-action values compared to NFQ, DQN, and DDQN.
This work establishes a foundation for benchmarking offline RL in
emotion-adaptive robotics and informs future deployment in real-world HRI. Our
findings provide empirical insight into the performance of offline
reinforcement learning algorithms in data-constrained HRI. This work
establishes a foundation for benchmarking offline RL in emotion-adaptive
robotics and informs its future deployment in real-world HRI, such as in
conversational agents, educational partners, and personal assistants, require
reliable emotional responsiveness.

</details>


### [48] [HOGraspFlow: Exploring Vision-based Generative Grasp Synthesis with Hand-Object Priors and Taxonomy Awareness](https://arxiv.org/abs/2509.16871)
*Yitian Shi,Zicheng Guo,Rosa Wolf,Edgar Welte,Rania Rayyes*

Main category: cs.RO

TL;DR: HO-GraspFlow通过结合RGB基础特征、手-物接触重建和抓取类型分类先验，提出了无需显式几何先验的多模态抓取合成方法，效果优于扩散变体。


<details>
  <summary>Details</summary>
Motivation: 目标是从RGB图像中学习多模态的可执行抓取姿态，而不依赖显式的手-物接触输入或对象几何信息。

Method: 利用手重建和视觉基础模型，结合RGB特征、接触重建和抓取类型分类先验，通过去噪流匹配合成SE(3)抓取姿态。

Result: 实验显示抓取合成保真度高，分布一致性强，优化更稳定，真实场景中平均成功率超过83%。

Conclusion: HO-GraspFlow是一种高效且可靠的抓取合成方法，适用于实际应用。

Abstract: We propose Hand-Object\emph{(HO)GraspFlow}, an affordance-centric approach
that retargets a single RGB with hand-object interaction (HOI) into multi-modal
executable parallel jaw grasps without explicit geometric priors on target
objects. Building on foundation models for hand reconstruction and vision, we
synthesize $SE(3)$ grasp poses with denoising flow matching (FM), conditioned
on the following three complementary cues: RGB foundation features as visual
semantics, HOI contact reconstruction, and taxonomy-aware prior on grasp types.
Our approach demonstrates high fidelity in grasp synthesis without explicit HOI
contact input or object geometry, while maintaining strong contact and taxonomy
recognition. Another controlled comparison shows that \emph{HOGraspFlow}
consistently outperforms diffusion-based variants (\emph{HOGraspDiff}),
achieving high distributional fidelity and more stable optimization in $SE(3)$.
We demonstrate a reliable, object-agnostic grasp synthesis from human
demonstrations in real-world experiments, where an average success rate of over
$83\%$ is achieved.

</details>


### [49] [End2Race: Efficient End-to-End Imitation Learning for Real-Time F1Tenth Racing](https://arxiv.org/abs/2509.16894)
*Zhijie Qiao,Haowei Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: End2Race是一种用于F1Tenth自动驾驶赛车的新型端到端模仿学习算法，采用GRU架构和LiDAR数据标准化方法，实现了高效训练和快速推理，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车需要在高速下快速决策，传统自动驾驶算法不适用，因此需要开发专为赛车优化的新算法。

Method: 提出End2Race算法，使用GRU捕捉时间依赖性，并采用基于sigmoid的LiDAR数据标准化方法。

Result: 在F1Tenth模拟器中，End2Race安全性达94.2%，超车成功率59.2%，推理时间低于0.5毫秒。

Conclusion: End2Race是F1Tinth赛车平台的领先解决方案，代码已开源。

Abstract: F1Tenth is a widely adopted reduced-scale platform for developing and testing
autonomous racing algorithms, hosting annual competitions worldwide. With high
operating speeds, dynamic environments, and head-to-head interactions,
autonomous racing requires algorithms that diverge from those in classical
autonomous driving. Training such algorithms is particularly challenging: the
need for rapid decision-making at high speeds severely limits model capacity.
To address this, we propose End2Race, a novel end-to-end imitation learning
algorithm designed for head-to-head autonomous racing. End2Race leverages a
Gated Recurrent Unit (GRU) architecture to capture continuous temporal
dependencies, enabling both short-term responsiveness and long-term strategic
planning. We also adopt a sigmoid-based normalization function that transforms
raw LiDAR scans into spatial pressure tokens, facilitating effective model
training and convergence. The algorithm is extremely efficient, achieving an
inference time of less than 0.5 milliseconds on a consumer-class GPU.
Experiments in the F1Tenth simulator demonstrate that End2Race achieves a 94.2%
safety rate across 2,400 overtaking scenarios, each with an 8-second time
limit, and successfully completes overtakes in 59.2% of cases. This surpasses
previous methods and establishes ours as a leading solution for the F1Tenth
racing testbed. Code is available at
https://github.com/michigan-traffic-lab/End2Race.

</details>


### [50] [SwarmChat: An LLM-Based, Context-Aware Multimodal Interaction System for Robotic Swarms](https://arxiv.org/abs/2509.16920)
*Ettilla Mohiuddin Eumi,Hussein Abbass,Nadine Marcus*

Main category: cs.RO

TL;DR: SwarmChat是一个基于大型语言模型（LLMs）的多模态交互系统，通过自然语言命令实现人机交互，提升决策速度和灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的人机交互方法缺乏直观的实时自适应界面，导致决策慢、认知负荷高且命令灵活性不足。

Method: 系统采用四模块结构（Context Generator、Intent Recognition、Task Planner、Modality Selector）和三层次架构，支持多模态输入并动态优化命令。

Result: 初步评估显示，SwarmChat能准确解析上下文、识别意图并高效传递命令，用户满意度高。

Conclusion: SwarmChat通过LLM和多模态设计有效解决了传统人机交互的局限性，为未来研究提供了重要参考。

Abstract: Traditional Human-Swarm Interaction (HSI) methods often lack intuitive
real-time adaptive interfaces, making decision making slower and increasing
cognitive load while limiting command flexibility. To solve this, we present
SwarmChat, a context-aware, multimodal interaction system powered by Large
Language Models (LLMs). SwarmChat enables users to issue natural language
commands to robotic swarms using multiple modalities, such as text, voice, or
teleoperation. The system integrates four LLM-based modules: Context Generator,
Intent Recognition, Task Planner, and Modality Selector. These modules
collaboratively generate context from keywords, detect user intent, adapt
commands based on real-time robot state, and suggest optimal communication
modalities. Its three-layer architecture offers a dynamic interface with both
fixed and customizable command options, supporting flexible control while
optimizing cognitive effort. The preliminary evaluation also shows that the
SwarmChat's LLM modules provide accurate context interpretation, relevant
intent recognition, and effective command delivery, achieving high user
satisfaction.

</details>


### [51] [A Reliable Robot Motion Planner in Complex Real-world Environments via Action Imagination](https://arxiv.org/abs/2509.16963)
*Chengjin Wang,Yanmin Zhou,Zhipeng Wang,Zheng Yan,Feng Luan,Shuo Jiang,Runjie Shen,Hongrui Sang,Bin He*

Main category: cs.RO

TL;DR: 提出了一个受生物启发的想象运动规划框架（I-MP），通过模拟空间状态增强机器人在复杂环境中的动作可靠性。


<details>
  <summary>Details</summary>
Motivation: 受人类和动物通过想象动作结果实时调整运动的能力启发，旨在提升机器人在未知非结构化环境中的动作可靠性。

Method: 提出I-MP框架，通过拓扑化工作空间、构建感知-动作循环、利用不动点理论和Hausdorff距离计算收敛空间状态，并通过能量梯度实时计算趋近目标状态。

Result: 实验结果表明I-MP在复杂杂乱环境中具有实用性和鲁棒性。

Conclusion: I-MP框架通过模拟和实时计算有效提升了机器人的动作可靠性，适用于复杂环境。

Abstract: Humans and animals can make real-time adjustments to movements by imagining
their action outcomes to prevent unanticipated or even catastrophic motion
failures in unknown unstructured environments. Action imagination, as a refined
sensorimotor strategy, leverages perception-action loops to handle physical
interaction-induced uncertainties in perception and system modeling within
complex systems. Inspired by the action-awareness capability of animal
intelligence, this study proposes an imagination-inspired motion planner (I-MP)
framework that specifically enhances robots' action reliability by imagining
plausible spatial states for approaching. After topologizing the workspace,
I-MP build perception-action loop enabling robots autonomously build contact
models. Leveraging fixed-point theory and Hausdorff distance, the planner
computes convergent spatial states under interaction characteristics and
mission constraints. By homogenously representing multi-dimensional
environmental characteristics through work, the robot can approach the imagined
spatial states via real-time computation of energy gradients. Consequently,
experimental results demonstrate the practicality and robustness of I-MP in
complex cluttered environments.

</details>


### [52] [Geometric Interpolation of Rigid Body Motions](https://arxiv.org/abs/2509.16966)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 论文提出两种刚体运动插值问题：k阶初始值轨迹插值（k-IV-TIP）和k阶边界值轨迹插值（k-BV-TIP），并分别给出解决方案和数值示例。


<details>
  <summary>Details</summary>
Motivation: 研究刚体运动插值问题，满足不同阶数的初始条件和边界条件，以生成更准确的轨迹。

Method: 提出k-IV-TIP和k-BV-TIP两种插值方法，分别解决初始和边界条件下的高阶导数插值问题，并展示了1到4阶的解决方案。

Result: 成功解决了1-IV-TBP问题，提出了一种新的三次插值方法，并在数值示例中验证了方法的有效性。

Conclusion: 论文提出的方法能够有效解决高阶刚体运动插值问题，且新提出的三次插值法在零扭力条件下与最小加速度曲线一致。

Abstract: The problem of interpolating a rigid body motion is to find a spatial
trajectory between a prescribed initial and terminal pose. Two variants of this
interpolation problem are addressed. The first is to find a solution that
satisfies initial conditions on the k-1 derivatives of the rigid body twist.
This is called the kth-order initial value trajectory interpolation problem
(k-IV-TIP). The second is to find a solution that satisfies conditions on the
rigid body twist and its k-1 derivatives at the initial and terminal pose. This
is called the kth-order boundary value trajectory interpolation problem
(k-BV-TIP). Solutions to the k-IV-TIP for k=1,...,4, i.e. the initial twist and
up to the 4th time derivative are prescribed. Further, a solution to the
1-IV-TBP is presented, i.e. the initial and terminal twist are prescribed. The
latter is a novel cubic interpolation between two spatial configurations with
given initial and terminal twist. This interpolation is automatically identical
to the minimum acceleration curve when the twists are set to zero. The general
approach to derive higher-order solutions is presented. Numerical results are
shown for two examples.

</details>


### [53] [IDfRA: Self-Verification for Iterative Design in Robotic Assembly](https://arxiv.org/abs/2509.16998)
*Nishka Khendry,Christos Margadji,Sebastian W. Pattinson*

Main category: cs.RO

TL;DR: 该论文提出了迭代机器人装配设计（IDfRA）框架，通过自我评估迭代优化设计方案，取代传统依赖物理仿真的方法，显著提升了装配成功率和语义识别准确性。


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配设计方案依赖耗时且不灵活的手动规划或物理仿真，难以适应复杂任务和真实环境。论文旨在利用大语言模型的语义理解能力，通过迭代优化实现更高效的自动化设计。

Method: IDfRA框架结合规划、执行、验证和重新规划的迭代循环，利用自我评估逐步优化设计，同时避免依赖物理仿真。输入为结构和部分环境描述，输出为兼顾语义和物理可行性的方案。

Result: 实验显示，IDfRA在语义识别准确率达到73.3%，装配成功率为86.9%，且设计质量随迭代提升。人工对比也验证了其优于基线方法。

Conclusion: IDfRA通过自我验证和环境适应，在非结构化制造场景中展现出强实用性，为自动化装配设计提供了新思路。

Abstract: As robots proliferate in manufacturing, Design for Robotic Assembly (DfRA),
which is designing products for efficient automated assembly, is increasingly
important. Traditional approaches to DfRA rely on manual planning, which is
time-consuming, expensive and potentially impractical for complex objects.
Large language models (LLM) have exhibited proficiency in semantic
interpretation and robotic task planning, stimulating interest in their
application to the automation of DfRA. But existing methodologies typically
rely on heuristic strategies and rigid, hard-coded physics simulators that may
not translate into real-world assembly contexts. In this work, we present
Iterative Design for Robotic Assembly (IDfRA), a framework using iterative
cycles of planning, execution, verification, and re-planning, each informed by
self-assessment, to progressively enhance design quality within a fixed yet
initially under-specified environment, thereby eliminating the physics
simulation with the real world itself. The framework accepts as input a target
structure together with a partial environmental representation. Through
successive refinement, it converges toward solutions that reconcile semantic
fidelity with physical feasibility. Empirical evaluation demonstrates that
IDfRA attains 73.3\% top-1 accuracy in semantic recognisability, surpassing the
baseline on this metric. Moreover, the resulting assembly plans exhibit robust
physical feasibility, achieving an overall 86.9\% construction success rate,
with design quality improving across iterations, albeit not always
monotonically. Pairwise human evaluation further corroborates the advantages of
IDfRA relative to alternative approaches. By integrating self-verification with
context-aware adaptation, the framework evidences strong potential for
deployment in unstructured manufacturing scenarios.

</details>


### [54] [Generalized Momenta-Based Koopman Formalism for Robust Control of Euler-Lagrangian Systems](https://arxiv.org/abs/2509.17010)
*Rajpal Singh,Aditya Singh,Chidre Shravista Kashyap,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 提出了一种基于隐式广义动量状态空间表示的Koopman算子方法，用于欧拉-拉格朗日动力学，通过解耦线性驱动通道与状态依赖动态，优化了线性Koopman建模。


<details>
  <summary>Details</summary>
Motivation: 传统显式方法将输入与状态依赖动态非线性耦合，适合双线性Koopman模型但计算成本高。新方法通过结构分离，仅需学习非驱动动态，降低参数数量并提高效率。

Method: 采用隐式广义动量状态空间表示，结合神经网络架构构建Koopman嵌入，并通过线性广义扩展状态观测器（GESO）实时估计和补偿扰动。

Result: 新方法显著减少了可学习参数，提升了数据效率和模型简化，其线性模型预测性能优于传统双线性模型且更高效。

Conclusion: 新框架在机器人操作器上验证了高精度、鲁棒性和学习效率，优于现有方法。

Abstract: This paper presents a novel Koopman operator formulation for Euler Lagrangian
dynamics that employs an implicit generalized momentum-based state space
representation, which decouples a known linear actuation channel from state
dependent dynamics and makes the system more amenable to linear Koopman
modeling. By leveraging this structural separation, the proposed formulation
only requires to learn the unactuated dynamics rather than the complete
actuation dependent system, thereby significantly reducing the number of
learnable parameters, improving data efficiency, and lowering overall model
complexity. In contrast, conventional explicit formulations inherently couple
inputs with the state dependent terms in a nonlinear manner, making them more
suitable for bilinear Koopman models, which are more computationally expensive
to train and deploy. Notably, the proposed scheme enables the formulation of
linear models that achieve superior prediction performance compared to
conventional bilinear models while remaining substantially more efficient. To
realize this framework, we present two neural network architectures that
construct Koopman embeddings from actuated or unactuated data, enabling
flexible and efficient modeling across different tasks. Robustness is ensured
through the integration of a linear Generalized Extended State Observer (GESO),
which explicitly estimates disturbances and compensates for them in real time.
The combined momentum-based Koopman and GESO framework is validated through
comprehensive trajectory tracking simulations and experiments on robotic
manipulators, demonstrating superior accuracy, robustness, and learning
efficiency relative to state of the art alternatives.

</details>


### [55] [Orchestrate, Generate, Reflect: A VLM-Based Multi-Agent Collaboration Framework for Automated Driving Policy Learning](https://arxiv.org/abs/2509.17042)
*Zengqi Peng,Yusen Xie,Yubin Wang,Rui Yang,Qifeng Chen,Jun Ma*

Main category: cs.RO

TL;DR: 论文提出了一种名为OGR的自动化驾驶策略学习框架，利用视觉语言模型的多智能体协作，解决了自动驾驶中奖励函数和训练课程手动设计的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶策略学习需要手动设计奖励函数和训练课程，这不仅耗时耗力，还限制了模型的灵活性和性能。

Method: OGR框架通过分层智能体系统，利用视觉语言模型的高级推理和多模态理解能力，实现了自动化的奖励课程生成和迭代优化。

Result: 实验表明，OGR在CARLA模拟器中表现优越，具有强大的泛化能力，并能适配多种强化学习算法。

Conclusion: OGR框架为自动驾驶策略学习提供了高效、自动化的解决方案，具有实际应用的潜力。

Abstract: The advancement of foundation models fosters new initiatives for policy
learning in achieving safe and efficient autonomous driving. However, a
critical bottleneck lies in the manual engineering of reward functions and
training curricula for complex and dynamic driving tasks, which is a
labor-intensive and time-consuming process. To address this problem, we propose
OGR (Orchestrate, Generate, Reflect), a novel automated driving policy learning
framework that leverages vision-language model (VLM)-based multi-agent
collaboration. Our framework capitalizes on advanced reasoning and multimodal
understanding capabilities of VLMs to construct a hierarchical agent system.
Specifically, a centralized orchestrator plans high-level training objectives,
while a generation module employs a two-step analyze-then-generate process for
efficient generation of reward-curriculum pairs. A reflection module then
facilitates iterative optimization based on the online evaluation. Furthermore,
a dedicated memory module endows the VLM agents with the capabilities of
long-term memory. To enhance robustness and diversity of the generation
process, we introduce a parallel generation scheme and a human-in-the-loop
technique for augmentation of the reward observation space. Through efficient
multi-agent cooperation and leveraging rich multimodal information, OGR enables
the online evolution of reinforcement learning policies to acquire
interaction-aware driving skills. Extensive experiments in the CARLA simulator
demonstrate the superior performance, robust generalizability across distinct
urban scenarios, and strong compatibility with various RL algorithms. Further
real-world experiments highlight the practical viability and effectiveness of
our framework. The source code will be available upon acceptance of the paper.

</details>


### [56] [FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks](https://arxiv.org/abs/2509.17053)
*Haizhou Ge,Yufei Jia,Zheng Li,Yue Li,Zhixing Chen,Ruqi Huang,Guyue Zhou*

Main category: cs.RO

TL;DR: FILIC是一个力引导的模仿学习框架，通过阻抗扭矩控制和力反馈机制，显著提升了接触密集型操作的性能。


<details>
  <summary>Details</summary>
Motivation: 传统模仿学习策略缺乏力感知能力，而配备力/扭矩传感器的协作机械臂成本高。FILIC旨在解决这些问题。

Method: 结合了Transformer模仿学习策略与阻抗控制器，提出低成本末端力估计器，并通过数字孪生进行补偿。

Result: FILIC在实验中优于仅基于视觉和关节扭矩的方法，实现了更安全、更柔顺的操作。

Conclusion: FILIC为接触密集型操作提供了一种高效、低成本的解决方案。

Abstract: Contact-rich manipulation is crucial for robots to perform tasks requiring
precise force control, such as insertion, assembly, and in-hand manipulation.
However, most imitation learning (IL) policies remain position-centric and lack
explicit force awareness, and adding force/torque sensors to collaborative
robot arms is often costly and requires additional hardware design. To overcome
these issues, we propose FILIC, a Force-guided Imitation Learning framework
with impedance torque control. FILIC integrates a Transformer-based IL policy
with an impedance controller in a dual-loop structure, enabling compliant
force-informed, force-executed manipulation. For robots without force/torque
sensors, we introduce a cost-effective end-effector force estimator using joint
torque measurements through analytical Jacobian-based inversion while
compensating with model-predicted torques from a digital twin. We also design
complementary force feedback frameworks via handheld haptics and VR
visualization to improve demonstration quality. Experiments show that FILIC
significantly outperforms vision-only and joint-torque-based methods, achieving
safer, more compliant, and adaptable contact-rich manipulation. Our code can be
found in https://github.com/TATP-233/FILIC.

</details>


### [57] [RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments](https://arxiv.org/abs/2509.17057)
*Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Hanbit Oh,Koshi Makihara,Keisuke Shirai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: RoboManipBaselines是一个统一的机器人模仿学习框架，整合了仿真和真实机器人的数据收集、训练和评估。


<details>
  <summary>Details</summary>
Motivation: 提供一个系统化的基准平台，支持多样化的任务、机器人和多模态策略的研究。

Method: 通过开放的框架设计，强调集成性、通用性、可扩展性和可重复性。

Result: 实现了仿真与真实机器人环境的无缝衔接和高效评估。

Conclusion: RoboManipBaselines为机器人模仿学习提供了一个全面且灵活的基准工具。

Abstract: RoboManipBaselines is an open framework for robot imitation learning that
unifies data collection, training, and evaluation across simulation and real
robots. We introduce it as a platform enabling systematic benchmarking of
diverse tasks, robots, and multimodal policies with emphasis on integration,
generality, extensibility, and reproducibility.

</details>


### [58] [CoPlanner: An Interactive Motion Planner with Contingency-Aware Diffusion for Autonomous Driving](https://arxiv.org/abs/2509.17080)
*Ruiguo Zhong,Ruoyu Yao,Pei Liu,Xiaolong Chen,Rui Yang,Jun Ma*

Main category: cs.RO

TL;DR: 论文提出了一种名为CoPlanner的统一框架，用于解决自动驾驶系统中轨迹预测与运动规划的挑战，通过联合建模多模态不确定性和多代理交互，提升安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统的轨迹预测和运动规划存在过度自信决策和缺乏后备策略的问题，且预测与规划模块通常解耦，导致社交不一致或不现实的轨迹。为了解决这些问题，作者提出了一种新的方法。

Method: CoPlanner采用了一种锚定共享短期段并随机生成长时段分支的扩散机制，同时设计了多情景评分策略，综合评估候选轨迹的安全性和舒适性。

Result: 在nuPlan基准测试中，CoPlanner在安全性和舒适性方面显著优于现有方法，特别是在反应和非反应场景下表现优异。

Conclusion: CoPlanner通过联合建模轨迹生成和运动规划，提供了更真实的交互感知规划，并在不确定条件下保持了后备选项，有效提升了自动驾驶系统的性能。

Abstract: Accurate trajectory prediction and motion planning are crucial for autonomous
driving systems to navigate safely in complex, interactive environments
characterized by multimodal uncertainties. However, current
generation-then-evaluation frameworks typically construct multiple plausible
trajectory hypotheses but ultimately adopt a single most likely outcome,
leading to overconfident decisions and a lack of fallback strategies that are
vital for safety in rare but critical scenarios. Moreover, the usual decoupling
of prediction and planning modules could result in socially inconsistent or
unrealistic joint trajectories, especially in highly interactive traffic. To
address these challenges, we propose a contingency-aware diffusion planner
(CoPlanner), a unified framework that jointly models multi-agent interactive
trajectory generation and contingency-aware motion planning. Specifically, the
pivot-conditioned diffusion mechanism anchors trajectory sampling on a
validated, shared short-term segment to preserve temporal consistency, while
stochastically generating diverse long-horizon branches that capture multimodal
motion evolutions. In parallel, we design a contingency-aware multi-scenario
scoring strategy that evaluates candidate ego trajectories across multiple
plausible long-horizon evolution scenarios, balancing safety, progress, and
comfort. This integrated design preserves feasible fallback options and
enhances robustness under uncertainty, leading to more realistic
interaction-aware planning. Extensive closed-loop experiments on the nuPlan
benchmark demonstrate that CoPlanner consistently surpasses state-of-the-art
methods on both Val14 and Test14 datasets, achieving significant improvements
in safety and comfort under both reactive and non-reactive settings. Code and
model will be made publicly available upon acceptance.

</details>


### [59] [Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation](https://arxiv.org/abs/2509.17125)
*Liang Heng,Jiadong Xu,Yiwen Wang,Xiaoqi Li,Muhe Cai,Yan Shen,Juan Zhu,Guanghui Ren,Hao Dong*

Main category: cs.RO

TL;DR: Imagine2Act是一个3D模仿学习框架，通过结合语义和几何约束来提升机器人在关系对象重排任务中的精确操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖预收集的演示（难以捕捉复杂几何约束），要么通过生成目标状态观察捕获语义和几何知识，但未明确耦合对象变换与动作预测，导致生成噪声误差。

Method: Imagine2Act通过生成基于语言指令的目标图像并重建3D点云，将这些点云作为策略模型的输入，同时采用对象-动作一致性策略和软姿态监督，显式对齐预测的动作与对象变换。

Result: 实验表明，Imagine2Act在仿真和现实环境中均优于现有最先进策略。

Conclusion: Imagine2Act通过结合语义和几何约束，显著提升了机器人在高精度操作任务中的表现。

Abstract: Relational object rearrangement (ROR) tasks (e.g., insert flower to vase)
require a robot to manipulate objects with precise semantic and geometric
reasoning. Existing approaches either rely on pre-collected demonstrations that
struggle to capture complex geometric constraints or generate goal-state
observations to capture semantic and geometric knowledge, but fail to
explicitly couple object transformation with action prediction, resulting in
errors due to generative noise. To address these limitations, we propose
Imagine2Act, a 3D imitation-learning framework that incorporates semantic and
geometric constraints of objects into policy learning to tackle high-precision
manipulation tasks. We first generate imagined goal images conditioned on
language instructions and reconstruct corresponding 3D point clouds to provide
robust semantic and geometric priors. These imagined goal point clouds serve as
additional inputs to the policy model, while an object-action consistency
strategy with soft pose supervision explicitly aligns predicted end-effector
motion with generated object transformation. This design enables Imagine2Act to
reason about semantic and geometric relationships between objects and predict
accurate actions across diverse tasks. Experiments in both simulation and the
real world demonstrate that Imagine2Act outperforms previous state-of-the-art
policies. More visualizations can be found at
https://sites.google.com/view/imagine2act.

</details>


### [60] [History-Aware Visuomotor Policy Learning via Point Tracking](https://arxiv.org/abs/2509.17141)
*Jingjing Chen,Hongjie Fang,Chenxi Wang,Shiquan Wang,Cewu Lu*

Main category: cs.RO

TL;DR: 提出了一种基于点追踪的物体为中心的历史表示方法，以解决现有视觉运动策略因马尔可夫假设而难以处理重复状态或长时依赖性任务的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以满足多样化的记忆需求，尤其是在处理重复状态或长时依赖的任务中表现不足。

Method: 通过点追踪将过去观测抽象为紧凑且结构化的物体级历史表示，并将其无缝整合到视觉运动策略中。

Result: 该方法在多样化的操作任务中显著优于马尔可夫基准和先前的历史方法，解决了任务阶段识别、空间记忆等多种记忆需求。

Conclusion: 提出的物体为中心的历史表示方法在提高任务性能和决策准确性方面具有高效性和通用性。

Abstract: Many manipulation tasks require memory beyond the current observation, yet
most visuomotor policies rely on the Markov assumption and thus struggle with
repeated states or long-horizon dependencies. Existing methods attempt to
extend observation horizons but remain insufficient for diverse memory
requirements. To this end, we propose an object-centric history representation
based on point tracking, which abstracts past observations into a compact and
structured form that retains only essential task-relevant information. Tracked
points are encoded and aggregated at the object level, yielding a compact
history representation that can be seamlessly integrated into various
visuomotor policies. Our design provides full history-awareness with high
computational efficiency, leading to improved overall task performance and
decision accuracy. Through extensive evaluations on diverse manipulation tasks,
we show that our method addresses multiple facets of memory requirements - such
as task stage identification, spatial memorization, and action counting, as
well as longer-term demands like continuous and pre-loaded memory - and
consistently outperforms both Markovian baselines and prior history-based
approaches. Project website: http://tonyfang.net/history

</details>


### [61] [MAST: Multi-Agent Spatial Transformer for Learning to Collaborate](https://arxiv.org/abs/2509.17195)
*Damian Owerko,Frederic Vatnsdal,Saurav Agarwal,Vijay Kumar,Alejandro Ribeiro*

Main category: cs.RO

TL;DR: 本文提出了一种新型多智能体空间变换器（MAST），用于大规模分散协作多机器人系统（DC-MRS）中的通信策略学习，解决了部分可观测状态、有限通信范围和独立执行动作等挑战。


<details>
  <summary>Details</summary>
Motivation: 在DC-MRS中，机器人协作面临部分可观测状态、有限通信范围和独立执行动作的挑战，需要一种能够优化共同任务的通信策略。

Method: MAST是一种分散式变换器架构，通过新的位置编码策略和注意力操作（如窗口化）实现局部计算和置换等价性。

Result: MAST在分散分配导航和分散覆盖控制任务中表现优于基线和其他基于学习的方法，且具有鲁棒性和可扩展性。

Conclusion: MAST是DC-MRS中一种有前景的通信策略学习方法，能够有效应对协作挑战并显著提升性能。

Abstract: This article presents a novel multi-agent spatial transformer (MAST) for
learning communication policies in large-scale decentralized and collaborative
multi-robot systems (DC-MRS). Challenges in collaboration in DC-MRS arise from:
(i) partial observable states as robots make only localized perception, (ii)
limited communication range with no central server, and (iii) independent
execution of actions. The robots need to optimize a common task-specific
objective, which, under the restricted setting, must be done using a
communication policy that exhibits the desired collaborative behavior. The
proposed MAST is a decentralized transformer architecture that learns
communication policies to compute abstract information to be shared with other
agents and processes the received information with the robot's own
observations. The MAST extends the standard transformer with new positional
encoding strategies and attention operations that employ windowing to limit the
receptive field for MRS. These are designed for local computation,
shift-equivariance, and permutation equivariance, making it a promising
approach for DC-MRS. We demonstrate the efficacy of MAST on decentralized
assignment and navigation (DAN) and decentralized coverage control. Efficiently
trained using imitation learning in a centralized setting, the decentralized
MAST policy is robust to communication delays, scales to large teams, and
performs better than the baselines and other learning-based approaches.

</details>


### [62] [Certifiably Optimal Doppler Positioning using Opportunistic LEO Satellites](https://arxiv.org/abs/2509.17198)
*Baoshan Song,Weisong Wen,Qi Zhang,Bing Xu,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 该论文提出了一种利用凸优化实现全局最优的低地球轨道（LEO）多普勒定位方法，解决了传统方法因初始估计不准确而陷入局部最优的问题。


<details>
  <summary>Details</summary>
Motivation: 在全球导航卫星系统（GNSS）无法使用的情况下，低地球轨道（LEO）卫星的多普勒频移可作为机会信号（SOP）用于定位导航与授时（PNT）。由于多普勒定位问题是非凸的，传统局部搜索方法容易陷入局部最优或无法全局最优。

Method: 提出了保证全局最优的定位方法，通过毕业权重近似（GWA）算法和半定规划（SDP）松弛实现，并推导了理想无噪情况和有噪情况下的最优条件。

Result: 仿真和真实测试（如Iridium-NEXT卫星）表明，该方法在无初始估计的情况下能提供140米的3D定位误差，而传统方法在初始点远离真实值时会陷入局部最优。

Conclusion: 该方法不仅提供了全局最优解，还可作为局部搜索方法的初始估计，进一步降低定位误差至130米，证明了其有效性和鲁棒性。

Abstract: To provide backup and augmentation to global navigation satellite system
(GNSS), Doppler shift from Low Earth Orbit (LEO) satellites can be employed as
signals of opportunity (SOP) for position, navigation and timing (PNT). Since
the Doppler positioning problem is non-convex, local searching methods may
produce two types of estimates: a global optimum without notice or a local
optimum given an inexact initial estimate. As exact initialization is
unavailable in some unknown environments, a guaranteed global optimization
method in no need of initialization becomes necessary. To achieve this goal, we
propose a certifiably optimal LEO Doppler positioning method by utilizing
convex optimization. In this paper, the certifiable positioning method is
implemented through a graduated weight approximation (GWA) algorithm and
semidefinite programming (SDP) relaxation. To guarantee the optimality, we
derive the necessary conditions for optimality in ideal noiseless cases and
sufficient noise bounds conditions in noisy cases. Simulation and real tests
are conducted to evaluate the effectiveness and robustness of the proposed
method. Specially, the real test using Iridium-NEXT satellites shows that the
proposed method estimates an certifiably optimal solution with an 3D
positioning error of 140 m without initial estimates while Gauss-Newton and
Dog-Leg are trapped in local optima when the initial point is equal or larger
than 1000 km away from the ground truth. Moreover, the certifiable estimation
can also be used as initialization in local searching methods to lower down the
3D positioning error to 130 m.

</details>


### [63] [Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation](https://arxiv.org/abs/2509.17204)
*James R. Han,Mithun Vanniasinghe,Hshmat Sahak,Nicholas Rhinehart,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 论文提出Ratatouille，通过改进模仿学习的架构和训练方法，显著提升社交机器人导航的安全性和成功率，避免了传统强化学习的风险。


<details>
  <summary>Details</summary>
Motivation: 解决社交机器人导航中强化学习的数据密集性和安全风险问题，通过离线模仿学习实现安全高效的训练。

Method: 采用改进的行为克隆方法（Ratatouille），优化模型架构和训练流程，无需额外数据即可减少碰撞并提高成功率。

Result: 在仿真和真实环境中验证，碰撞率降低6倍，成功率提高3倍，并在大学校园和公共区域取得良好效果。

Conclusion: 精心设计的模仿学习方法能够显著提升社交机器人导航的性能，无需依赖额外数据。

Abstract: Scaling Reinforcement Learning to in-the-wild social robot navigation is both
data-intensive and unsafe, since policies must learn through direct interaction
and inevitably encounter collisions. Offline Imitation learning (IL) avoids
these risks by collecting expert demonstrations safely, training entirely
offline, and deploying policies zero-shot. However, we find that naively
applying Behaviour Cloning (BC) to social navigation is insufficient; achieving
strong performance requires careful architectural and training choices. We
present Ratatouille, a pipeline and model architecture that, without changing
the data, reduces collisions per meter by 6 times and improves success rate by
3 times compared to naive BC. We validate our approach in both simulation and
the real world, where we collected over 11 hours of data on a dense university
campus. We further demonstrate qualitative results in a public food court. Our
findings highlight that thoughtful IL design, rather than additional data, can
substantially improve safety and reliability in real-world social navigation.
Video: https://youtu.be/tOdLTXsaYLQ. Code will be released after acceptance.

</details>


### [64] [HuMam: Humanoid Motion Control via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2509.18046)
*Yinuo Wang,Yuanyang Qi,Jinzhao Zhou,Gavin Tao*

Main category: cs.RO

TL;DR: HuMam是一个基于Mamba的单层编码器框架，用于人形机器人端到端强化学习，提高了训练效率、稳定性和控制经济性。


<details>
  <summary>Details</summary>
Motivation: 解决端到端强化学习在人形机器人运动控制中的训练不稳定、特征融合效率低和高驱动成本问题。

Method: 使用单层Mamba编码器融合机器人状态、足部目标与相位时钟，结合PPO优化策略，六项奖励函数平衡多目标。

Result: 在JVRC-1人形机器人上显著提升学习效率、训练稳定性和任务表现，降低功耗和扭矩峰值。

Conclusion: HuMam是首个采用Mamba作为融合主干的端到端人形RL控制器，展示了在效率、稳定性和经济性上的实质性改进。

Abstract: End-to-end reinforcement learning (RL) for humanoid locomotion is appealing
for its compact perception-action mapping, yet practical policies often suffer
from training instability, inefficient feature fusion, and high actuation cost.
We present HuMam, a state-centric end-to-end RL framework that employs a
single-layer Mamba encoder to fuse robot-centric states with oriented footstep
targets and a continuous phase clock. The policy outputs joint position targets
tracked by a low-level PD loop and is optimized with PPO. A concise six-term
reward balances contact quality, swing smoothness, foot placement, posture, and
body stability while implicitly promoting energy saving. On the JVRC-1 humanoid
in mc-mujoco, HuMam consistently improves learning efficiency, training
stability, and overall task performance over a strong feedforward baseline,
while reducing power consumption and torque peaks. To our knowledge, this is
the first end-to-end humanoid RL controller that adopts Mamba as the fusion
backbone, demonstrating tangible gains in efficiency, stability, and control
economy.

</details>


### [65] [Combining Performance and Passivity in Linear Control of Series Elastic Actuators](https://arxiv.org/abs/2509.17210)
*Shaunak A. Mehta,Dylan P. Losey*

Main category: cs.RO

TL;DR: 论文探讨了在机器人系列弹性执行器（SEAs）中如何平衡安全性与性能，发现通过执行器侧的简易PD控制及传输阻尼设计，可实现高性能与安全性并存。


<details>
  <summary>Details</summary>
Motivation: 人类与机器人物理交互时需要机器人既安全又高效。SEAs通过弹性驱动提升安全性，但同时也降低了精确运动能力，因此需权衡安全性与性能。

Method: 研究了SEAs的不同线性控制及机械配置，分析了其对柔顺性、被动性及跟踪性能的影响，重点探索执行器侧控制的优势。

Result: 执行器侧的简易PD控制结合弹性传输阻尼设计，既能扩大安全增益范围又能实现高性能。仿真与实验表明，低物理刚度和高控制增益的设计可实现精确性能与安全性。

Conclusion: 通过优化SEAs的控制与机械设计，可兼顾高性能与人机交互的安全性。

Abstract: When humans physically interact with robots, we need the robots to be both
safe and performant. Series elastic actuators (SEAs) fundamentally advance
safety by introducing compliant actuation. On the one hand, adding a spring
mitigates the impact of accidental collisions between human and robot; but on
the other hand, this spring introduces oscillations and fundamentally decreases
the robot's ability to perform precise, accurate motions. So how should we
trade off between physical safety and performance? In this paper, we enumerate
the different linear control and mechanical configurations for series elastic
actuators, and explore how each choice affects the rendered compliance,
passivity, and tracking performance. While prior works focus on load side
control, we find that actuator side control has significant benefits. Indeed,
simple PD controllers on the actuator side allow for a much wider range of
control gains that maintain safety, and combining these with a damper in the
elastic transmission yields high performance. Our simulations and real world
experiments suggest that, by designing a system with low physical stiffness and
high controller gains, this solution enables accurate performance while also
ensuring user safety during collisions.

</details>


### [66] [RadarSFD: Single-Frame Diffusion with Pretrained Priors for Radar Point Clouds](https://arxiv.org/abs/2509.18068)
*Bin Zhao,Nakul Garg*

Main category: cs.RO

TL;DR: RadarSFD是一种基于条件潜在扩散框架的方法，能够从单帧雷达数据重建高密度LiDAR样点云。与需要多帧或合成孔径的现有方法不同，该方法在紧凑机器人系统中实现了高分辨率的单帧雷达感知。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达在雾、烟、尘和低光条件下具有鲁棒性，适合小型机器人平台。然而，现有雷达成像方法需要多帧或合成孔径来提高分辨率，限制了其在小规模系统中的应用。

Method: RadarSFD通过从单帧雷达数据中重建点云，利用了预训练的单目深度估计器的几何先验，并将其通过通道级潜在连接与雷达输入结合。优化采用双空间目标，结合潜在和像素空间损失。

Result: 在RadarHD基准测试中，RadarSFD在单帧条件下性能显著优于基线，并与多帧方法竞争。实验结果展示了其在狭窄间隙和精细结构恢复中的能力，并验证了其泛化性。

Conclusion: RadarSFD首次实现了无需运动或合成孔径的毫米波雷达单帧高密度点云感知，为紧凑机器人系统提供了一种实用解决方案。

Abstract: Millimeter-wave radar provides perception robust to fog, smoke, dust, and low
light, making it attractive for size, weight, and power constrained robotic
platforms. Current radar imaging methods, however, rely on synthetic aperture
or multi-frame aggregation to improve resolution, which is impractical for
small aerial, inspection, or wearable systems. We present RadarSFD, a
conditional latent diffusion framework that reconstructs dense LiDAR-like point
clouds from a single radar frame without motion or SAR. Our approach transfers
geometric priors from a pretrained monocular depth estimator into the diffusion
backbone, anchors them to radar inputs via channel-wise latent concatenation,
and regularizes outputs with a dual-space objective combining latent and
pixel-space losses. On the RadarHD benchmark, RadarSFD achieves 35 cm Chamfer
Distance and 28 cm Modified Hausdorff Distance, improving over the single-frame
RadarHD baseline (56 cm, 45 cm) and remaining competitive with multi-frame
methods using 5-41 frames. Qualitative results show recovery of fine walls and
narrow gaps, and experiments across new environments confirm strong
generalization. Ablation studies highlight the importance of pretrained
initialization, radar BEV conditioning, and the dual-space loss. Together,
these results establish the first practical single-frame, no-SAR mmWave radar
pipeline for dense point cloud perception in compact robotic systems.

</details>


### [67] [Neural Network and ANFIS based auto-adaptive MPC for path tracking in autonomous vehicles](https://arxiv.org/abs/2509.17213)
*Yassine Kebbati,Naima Ait-Oufroukh,Vincent Vigneron,Dalil Ichala*

Main category: cs.RO

TL;DR: 论文设计了一种基于改进粒子群优化的自适应MPC控制器，用于自动驾驶车辆的路径跟踪任务，结合神经网络和ANFIS在线参数适应，性能优于标准MPC。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在动态环境中面临不确定性和干扰，传统控制器效果不佳，尤其是横向控制。

Method: 设计自适应MPC控制器，利用改进粒子群优化算法进行调参，并采用神经网络和ANFIS实现在线参数适应。

Result: 在三车道变换和轨迹跟踪场景中，该控制器表现优于标准MPC。

Conclusion: 自适应MPC控制器在复杂环境下表现出色，为自动驾驶提供了有效解决方案。

Abstract: Self-driving cars operate in constantly changing environments and are exposed
to a variety of uncertainties and disturbances. These factors render classical
controllers ineffective, especially for lateral control. Therefore, an adaptive
MPC controller is designed in this paper for the path tracking task, tuned by
an improved particle swarm optimization algorithm. Online parameter adaptation
is performed using Neural Networks and ANFIS. The designed controller showed
promising results compared to standard MPC in triple lane change and trajectory
tracking scenarios. Code can be found here:
https://github.com/yassinekebbati/NN_MPC-vs-ANFIS_MPC

</details>


### [68] [Scalable Multi Agent Diffusion Policies for Coverage Control](https://arxiv.org/abs/2509.17244)
*Frederic Vatnsdal,Romina Garcia Camargo,Saurav Agarwal,Alejandro Ribeiro*

Main category: cs.RO

TL;DR: MADP是一种基于扩散模型的分散式机器人群体协作方法，利用扩散模型生成高维动作分布样本，并通过模仿学习训练策略，在覆盖控制任务中表现优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 为解决分散式机器人群体在高维复杂动作分布下的协作问题，提出基于扩散模型的MADP方法，以捕捉机器人动作间的相互依赖性。

Method: MADP通过扩散模型生成高维动作分布样本，每个机器人基于自身观察和同伴感知嵌入的策略采样。采用模仿学习训练策略，扩散过程通过空间变换器架构实现分散推理。

Result: 实验表明，MADP在覆盖控制任务中具有良好的泛化能力和鲁棒性，能够适应不同的机器人密度和环境变化，表现优于现有方法。

Conclusion: MADP展示了扩散模型在分散式机器人群体协作中的潜力，能够有效处理复杂任务并超越现有技术水平。

Abstract: We propose MADP, a novel diffusion-model-based approach for collaboration in
decentralized robot swarms. MADP leverages diffusion models to generate samples
from complex and high-dimensional action distributions that capture the
interdependencies between agents' actions. Each robot conditions policy
sampling on a fused representation of its own observations and perceptual
embeddings received from peers. To evaluate this approach, we task a team of
holonomic robots piloted by MADP to address coverage control-a canonical multi
agent navigation problem. The policy is trained via imitation learning from a
clairvoyant expert on the coverage control problem, with the diffusion process
parameterized by a spatial transformer architecture to enable decentralized
inference. We evaluate the system under varying numbers, locations, and
variances of importance density functions, capturing the robustness demands of
real-world coverage tasks. Experiments demonstrate that our model inherits
valuable properties from diffusion models, generalizing across agent densities
and environments, and consistently outperforming state-of-the-art baselines.

</details>


### [69] [Learning and Optimization with 3D Orientations](https://arxiv.org/abs/2509.17274)
*Alexandros Ntagkas,Constantinos Tsakonas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: 本文总结并对比了3D方向表示方法及其应用，提供了实验基准和实用指南。


<details>
  <summary>Details</summary>
Motivation: 现有3D方向表示方法多样且各有优劣，缺乏统一总结和实证比较，特别是在机器人任务中。

Method: 本文系统梳理了所有可用的方向表示方法及相关技巧，并在四种典型机器人场景中进行了基准测试。

Result: 通过实验为不同场景提供了最佳方向表示方法的推荐。

Conclusion: 文章填补了机器人文献中的空白，为研究人员提供了实用工具和明确的指导。

Abstract: There exist numerous ways of representing 3D orientations. Each
representation has both limitations and unique features. Choosing the best
representation for one task is often a difficult chore, and there exist
conflicting opinions on which representation is better suited for a set of
family of tasks. Even worse, when dealing with scenarios where we need to learn
or optimize functions with orientations as inputs and/or outputs, the set of
possibilities (representations, loss functions, etc.) is even larger and it is
not easy to decide what is best for each scenario. In this paper, we attempt to
a) present clearly, concisely and with unified notation all available
representations, and "tricks" related to 3D orientations (including Lie Group
algebra), and b) benchmark them in representative scenarios. The first part
feels like it is missing from the robotics literature as one has to read many
different textbooks and papers in order have a concise and clear understanding
of all possibilities, while the benchmark is necessary in order to come up with
recommendations based on empirical evidence. More precisely, we experiment with
the following settings that attempt to cover most widely used scenarios in
robotics: 1) direct optimization, 2) imitation/supervised learning with a
neural network controller, 3) reinforcement learning, and 4) trajectory
optimization using differential dynamic programming. We finally provide
guidelines depending on the scenario, and make available a reference
implementation of all the orientation math described.

</details>


### [70] [Event-Based Visual Teach-and-Repeat via Fast Fourier-Domain Cross-Correlation](https://arxiv.org/abs/2509.17287)
*Gokul B. Nair,Alejandro Fontan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 该论文提出了一种基于事件相机的视觉教学与重复导航系统，通过频域互相关框架实现了300Hz以上的处理速度，显著优于传统帧相机系统。


<details>
  <summary>Details</summary>
Motivation: 传统帧相机由于其固定帧率（30-60Hz）限制了系统的响应速度，无法满足实时导航的需求。

Method: 开发了一种频域互相关框架，将事件流匹配问题转换为高效的傅里叶空间乘法运算，并结合事件帧的二进制特性和图像压缩技术提升计算速度。

Result: 实验表明，该系统在4000多米的室内外轨迹上实现了自主导航，平均跟踪误差低于24厘米，控制更新频率远高于传统方法。

Conclusion: 事件相机在实时机器人导航中具有显著优势，本文方法展示了其实用性和高效性。

Abstract: Visual teach-and-repeat navigation enables robots to autonomously traverse
previously demonstrated paths by comparing current sensory input with recorded
trajectories. However, conventional frame-based cameras fundamentally limit
system responsiveness: their fixed frame rates (typically 30-60 Hz) create
inherent latency between environmental changes and control responses. Here we
present the first event-camera-based visual teach-and-repeat system. To achieve
this, we develop a frequency-domain cross-correlation framework that transforms
the event stream matching problem into computationally efficient Fourier space
multiplications, capable of exceeding 300Hz processing rates, an order of
magnitude faster than frame-based approaches. By exploiting the binary nature
of event frames and applying image compression techniques, we further enhance
the computational speed of the cross-correlation process without sacrificing
localization accuracy. Extensive experiments using a Prophesee EVK4 HD event
camera mounted on an AgileX Scout Mini robot demonstrate successful autonomous
navigation across 4000+ meters of indoor and outdoor trajectories. Our system
achieves ATEs below 24 cm while maintaining consistent high-frequency control
updates. Our evaluations show that our approach achieves substantially higher
update rates compared to conventional frame-based systems, underscoring the
practical viability of event-based perception for real-time robotic navigation.

</details>


### [71] [Automated Coral Spawn Monitoring for Reef Restoration: The Coral Spawn and Larvae Imaging Camera System (CSLICS)](https://arxiv.org/abs/2509.17299)
*Dorian Tsai,Christopher A. Brunner,Riki Lamont,F. Mikaela Nordborg,Andrea Severati,Java Terry,Karen Jackel,Matthew Dunbabin,Tobias Fischer,Scarlett Raine*

Main category: cs.RO

TL;DR: 提出了珊瑚产卵计数系统CSLICS，通过低成本模块化摄像头和计算机视觉技术实现自动化计数，显著节省人工时间并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 珊瑚养殖中的人工产卵计数方法效率低下，限制了珊瑚生产和生态修复的规模。

Method: 开发了CSLICS系统，结合低成本摄像头和基于人类标注训练的物体检测算法，实现珊瑚产卵的自动化检测和计数。

Result: 系统在表面产卵检测的F1得分为82.4%，水下产卵检测为65.3%，单次产卵事件可节省5720小时人工。

Conclusion: CSLICS显著提升了珊瑚养殖效率，为应对气候变化带来的生态威胁提供了技术支持。

Abstract: Coral aquaculture for reef restoration requires accurate and continuous spawn
counting for resource distribution and larval health monitoring, but current
methods are labor-intensive and represent a critical bottleneck in the coral
production pipeline. We propose the Coral Spawn and Larvae Imaging Camera
System (CSLICS), which uses low cost modular cameras and object detectors
trained using human-in-the-loop labeling approaches for automated spawn
counting in larval rearing tanks. This paper details the system engineering,
dataset collection, and computer vision techniques to detect, classify and
count coral spawn. Experimental results from mass spawning events demonstrate
an F1 score of 82.4\% for surface spawn detection at different embryogenesis
stages, 65.3\% F1 score for sub-surface spawn detection, and a saving of 5,720
hours of labor per spawning event compared to manual sampling methods at the
same frequency. Comparison of manual counts with CSLICS monitoring during a
mass coral spawning event on the Great Barrier Reef demonstrates CSLICS'
accurate measurement of fertilization success and sub-surface spawn counts.
These findings enhance the coral aquaculture process and enable upscaling of
coral reef restoration efforts to address climate change threats facing
ecosystems like the Great Barrier Reef.

</details>


### [72] [Pose Estimation of a Cable-Driven Serpentine Manipulator Utilizing Intrinsic Dynamics via Physical Reservoir Computing](https://arxiv.org/abs/2509.17308)
*Kazutoshi Tanaka,Tomoya Takahashi,Masashi Hamaya*

Main category: cs.RO

TL;DR: 本文研究了一种轻型电缆驱动蛇形机械臂的位姿估计方法，提出了一种基于物理储备池计算的解决方案，显著提高了位姿估计的精度。


<details>
  <summary>Details</summary>
Motivation: 电缆驱动蛇形机械臂在非结构化环境中具有潜在优势，但其轻量化设计导致的柔性变化（如电缆松弛、伸长和连杆变形）使得位姿估计更具挑战性。

Method: 提出了一种基于物理储备池计算的位姿估计方法，利用机械臂固有的非线性动力学作为高维储备池。

Result: 实验结果显示，该方法平均位姿误差为4.3毫米，优于基线LSTM网络的4.4毫米和解析方法的39.5毫米。

Conclusion: 该研究为轻型电缆驱动蛇形机械臂的控制和感知策略提供了新方向，通过利用其固有的动力学特性提升了性能。

Abstract: Cable-driven serpentine manipulators hold great potential in unstructured
environments, offering obstacle avoidance, multi-directional force application,
and a lightweight design. By placing all motors and sensors at the base and
employing plastic links, we can further reduce the arm's weight. To demonstrate
this concept, we developed a 9-degree-of-freedom cable-driven serpentine
manipulator with an arm length of 545 mm and a total mass of only 308 g.
However, this design introduces flexibility-induced variations, such as cable
slack, elongation, and link deformation. These variations result in
discrepancies between analytical predictions and actual link positions, making
pose estimation more challenging. To address this challenge, we propose a
physical reservoir computing based pose estimation method that exploits the
manipulator's intrinsic nonlinear dynamics as a high-dimensional reservoir.
Experimental results show a mean pose error of 4.3 mm using our method,
compared to 4.4 mm with a baseline long short-term memory network and 39.5 mm
with an analytical approach. This work provides a new direction for control and
perception strategies in lightweight cable-driven serpentine manipulators
leveraging their intrinsic dynamics.

</details>


### [73] [OpenGVL - Benchmarking Visual Temporal Progress for Data Curation](https://arxiv.org/abs/2509.17321)
*Paweł Budzianowski,Emilia Wiśnios,Gracjan Góral,Igor Kulakov,Viktor Petrenko,Krzysztof Walas*

Main category: cs.RO

TL;DR: OpenGVL是一个用于评估任务进展的基准测试，基于GVL方法，用于多样化机器人任务的数据自动标注和筛选。开源模型性能较差，仅为闭源模型的70%，但OpenGVL能高效评估数据质量。


<details>
  <summary>Details</summary>
Motivation: 机器人领域数据稀缺，但现有数据呈指数增长，需要可靠的任务进展预测方法来自动化标注和筛选数据。

Method: 基于GVL方法，利用视觉语言模型（VLMs）从视觉观测中预测任务进展，构建OpenGVL基准测试，评估开源模型性能。

Result: 开源模型在任务进展预测中表现较差，仅为闭源模型的70%，但OpenGVL能有效用于大规模机器人数据的自动筛选和质量评估。

Conclusion: OpenGVL为机器人数据的自动化处理提供了实用工具，但开源模型的性能仍需提升以提高任务进展预测的准确性。

Abstract: Data scarcity remains one of the most limiting factors in driving progress in
robotics. However, the amount of available robotics data in the wild is growing
exponentially, creating new opportunities for large-scale data utilization.
Reliable temporal task completion prediction could help automatically annotate
and curate this data at scale. The Generative Value Learning (GVL) approach was
recently proposed, leveraging the knowledge embedded in vision-language models
(VLMs) to predict task progress from visual observations. Building upon GVL, we
propose OpenGVL, a comprehensive benchmark for estimating task progress across
diverse challenging manipulation tasks involving both robotic and human
embodiments. We evaluate the capabilities of publicly available open-source
foundation models, showing that open-source model families significantly
underperform closed-source counterparts, achieving only approximately $70\%$ of
their performance on temporal progress prediction tasks. Furthermore, we
demonstrate how OpenGVL can serve as a practical tool for automated data
curation and filtering, enabling efficient quality assessment of large-scale
robotics datasets. We release the benchmark along with the complete codebase at
\href{github.com/budzianowski/opengvl}{OpenGVL}.

</details>


### [74] [AERO-MPPI: Anchor-Guided Ensemble Trajectory Optimization for Agile Mapless Drone Navigation](https://arxiv.org/abs/2509.17340)
*Xin Chen,Rui Huang,Longbin Tang,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于GPU加速的框架AERO-MPPI，用于无地图导航的3D环境中无人机自主飞行，结合感知与规划并优化轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在复杂3D环境中高计算成本和误差传播的问题，实现无人机的高效、实时导航。

Method: 设计多分辨率LiDAR点云表示，提取‘锚点’作为中间端点，通过并行MPPI优化器生成多项式轨迹线。

Result: 在模拟和真实环境中实现超过7 m/s的稳定飞行，成功率高于80%，轨迹更平滑。

Conclusion: AERO-MPPI在复杂环境中实现了实时、安全和敏捷的飞行性能，展示了其高效性和鲁棒性。

Abstract: Agile mapless navigation in cluttered 3D environments poses significant
challenges for autonomous drones. Conventional mapping-planning-control
pipelines incur high computational cost and propagate estimation errors. We
present AERO-MPPI, a fully GPU-accelerated framework that unifies perception
and planning through an anchor-guided ensemble of Model Predictive Path
Integral (MPPI) optimizers. Specifically, we design a multi-resolution LiDAR
point-cloud representation that rapidly extracts spatially distributed
"anchors" as look-ahead intermediate endpoints, from which we construct
polynomial trajectory guides to explore distinct homotopy path classes. At each
planning step, we run multiple MPPI instances in parallel and evaluate them
with a two-stage multi-objective cost that balances collision avoidance and
goal reaching. Implemented entirely with NVIDIA Warp GPU kernels, AERO-MPPI
achieves real-time onboard operation and mitigates the local-minima failures of
single-MPPI approaches. Extensive simulations in forests, verticals, and
inclines demonstrate sustained reliable flight above 7 m/s, with success rates
above 80% and smoother trajectories compared to state-of-the-art baselines.
Real-world experiments on a LiDAR-equipped quadrotor with NVIDIA Jetson Orin NX
16G confirm that AERO-MPPI runs in real time onboard and consistently achieves
safe, agile, and robust flight in complex cluttered environments. The code will
be open-sourced upon acceptance of the paper.

</details>


### [75] [DyDexHandover: Human-like Bimanual Dynamic Dexterous Handover using RGB-only Perception](https://arxiv.org/abs/2509.17350)
*Haoran Zhou,Yangwei You,Shuaijun Wang*

Main category: cs.RO

TL;DR: DyDexHandover 是一个基于多智能体强化学习的框架，使用 RGB 图像输入实现双机械臂空中物体交接，生成人类化动作，泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 解决双机械臂空中物体交接中的动态挑战，现有方法依赖动力学模型或深度传感，泛化性和自然性不足。

Method: 采用多智能体强化学习训练端到端 RGB 策略，引入人类策略正则化以生成流畅动作。

Result: 在训练对象上达到 99% 成功率，未见对象 75% 成功率，首次仅用 RGB 实现双机械臂空中交接。

Conclusion: DyDexHandover 是一种高效、泛化性强的解决方案，为双机械臂任务提供了新思路。

Abstract: Dynamic in air handover is a fundamental challenge for dual-arm robots,
requiring accurate perception, precise coordination, and natural motion. Prior
methods often rely on dynamics models, strong priors, or depth sensing,
limiting generalization and naturalness. We present DyDexHandover, a novel
framework that employs multi-agent reinforcement learning to train an end to
end RGB based policy for bimanual object throwing and catching. To achieve more
human-like behavior, the throwing policy is guided by a human policy
regularization scheme, encouraging fluid and natural motion, and enhancing the
generalization capability of the policy. A dual arm simulation environment was
built in Isaac Sim for experimental evaluation. DyDexHandover achieves nearly
99 percent success on training objects and 75 percent on unseen objects, while
generating human-like throwing and catching behaviors. To our knowledge, it is
the first method to realize dual-arm in-air handover using only raw RGB
perception.

</details>


### [76] [Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators](https://arxiv.org/abs/2509.17381)
*Yongliang Wang,Hamidreza Kasaei*

Main category: cs.RO

TL;DR: 该论文提出了一种结合视觉路径规划和强化学习的轨迹规划系统，通过改进PPO算法，提高了机械臂在复杂环境中的避障和轨迹规划效率。


<details>
  <summary>Details</summary>
Motivation: 解决机械臂在非结构化和杂乱环境中生成无障碍轨迹的挑战，克服传统运动规划方法的高计算量问题。

Method: 分为两部分：1) 基于视觉的轨迹规划器，结合FSA模型和B样条优化的动力学路径搜索；2) 改进的PPO算法（集成AE和PF），提升关节空间的避障和目标到达精度。

Result: 实验结果表明，改进的PPO算法增强了模型鲁棒性和规划效率，实现了复杂环境中的实时避障和轨迹规划。

Conclusion: 结合视觉规划和强化学习的系统有效提升了机械臂在复杂环境中的轨迹规划性能，支持从仿真到现实的迁移应用。

Abstract: Generating obstacle-free trajectories for robotic manipulators in
unstructured and cluttered environments remains a significant challenge.
Existing motion planning methods often require additional computational effort
to generate the final trajectory by solving kinematic or dynamic equations.
This paper highlights the strong potential of model-free reinforcement learning
methods over model-based approaches for obstacle-free trajectory planning in
joint space. We propose a fast trajectory planning system for manipulators that
combines vision-based path planning in task space with reinforcement
learning-based obstacle avoidance in joint space. We divide the framework into
two key components. The first introduces an innovative vision-based trajectory
planner in task space, leveraging the large-scale fast segment anything (FSA)
model in conjunction with basis spline (B-spline)-optimized kinodynamic path
searching. The second component enhances the proximal policy optimization (PPO)
algorithm by integrating action ensembles (AE) and policy feedback (PF), which
greatly improve precision and stability in goal-reaching and obstacle avoidance
within the joint space. These PPO enhancements increase the algorithm's
adaptability across diverse robotic tasks, ensuring consistent execution of
commands from the first component by the manipulator, while also enhancing both
obstacle avoidance efficiency and reaching accuracy. The experimental results
demonstrate the effectiveness of PPO enhancements, as well as
simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real)
transfer, in improving model robustness and planner efficiency in complex
scenarios. These enhancements allow the robot to perform obstacle avoidance and
real-time trajectory planning in obstructed environments. Project page
available at: https://sites.google.com/view/ftp4rm/home

</details>


### [77] [High-Precision and High-Efficiency Trajectory Tracking for Excavators Based on Closed-Loop Dynamics](https://arxiv.org/abs/2509.17387)
*Ziqing Zou,Cong Wang,Yue Hu,Xiao Liu,Bowen Xu,Rong Xiong,Changjie Fan,Yingfeng Chen,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出了一种名为EfficientTrack的新型轨迹跟踪方法，解决了液压挖掘机非线性动力学中的时延和控制耦合问题。通过结合基于模型的学习和闭环动力学，该方法显著减少了跟踪误差，并在仿真和实际应用中表现出色，尤其在跟踪精度和学习效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 液压挖掘机的复杂非线性动力学（如时延和控制耦合）使高精度轨迹跟踪变得困难。传统控制方法无法有效处理这些非线性特性，而现有的学习型方法则因需要大量环境交互而效率低下。

Method: EfficientTrack结合了基于模型的学习和闭环动力学，以高效管理非线性动力学并提升学习效率，最终减少跟踪误差。

Result: 在仿真实验中，EfficientTrack在跟踪精度和平滑性上均优于现有学习型方法，且所需交互次数最少。实际实验表明，该方法在负载条件下仍有效，并具备持续学习能力。

Conclusion: EfficientTrack是一种适用于液压挖掘机的高效轨迹跟踪方法，兼具仿真和实际应用的优越性能，具有广泛的实际应用潜力。

Abstract: The complex nonlinear dynamics of hydraulic excavators, such as time delays
and control coupling, pose significant challenges to achieving high-precision
trajectory tracking. Traditional control methods often fall short in such
applications due to their inability to effectively handle these nonlinearities,
while commonly used learning-based methods require extensive interactions with
the environment, leading to inefficiency. To address these issues, we introduce
EfficientTrack, a trajectory tracking method that integrates model-based
learning to manage nonlinear dynamics and leverages closed-loop dynamics to
improve learning efficiency, ultimately minimizing tracking errors. We validate
our method through comprehensive experiments both in simulation and on a
real-world excavator. Comparative experiments in simulation demonstrate that
our method outperforms existing learning-based approaches, achieving the
highest tracking precision and smoothness with the fewest interactions.
Real-world experiments further show that our method remains effective under
load conditions and possesses the ability for continual learning, highlighting
its practical applicability. For implementation details and source code, please
refer to https://github.com/ZiqingZou/EfficientTrack.

</details>


### [78] [3D Printable Soft Liquid Metal Sensors for Delicate Manipulation Tasks](https://arxiv.org/abs/2509.17389)
*Lois Liow,Jonty Milford,Emre Uygun,Andre Farinha,Vinoth Viswanathan,Josh Pinskier,David Howard*

Main category: cs.RO

TL;DR: 提出了一种新型的自由形态、高度传感器化的软质‘物理孪生’打印方法，用于保护脆弱生态系统中的敏感样本处理和数据采集。


<details>
  <summary>Details</summary>
Motivation: 解决在脆弱生态系统中处理敏感样本（如珊瑚）时不损伤样本且能高效获取数据的问题，支持基于学习的自动化方案。

Method: 开发了一种自动化设计工作流，通过3D扫描或模型快速生成复杂、可定制的3D软传感结构，液体金属传感器能精确复刻复杂自然几何形态。

Result: 物理孪生体（如‘传感珊瑚’）能检测小于0.5N的抓取力，适用于珊瑚处理等精细操作；验证了其在自动标记和机器人养殖中的应用。

Conclusion: 该方法为脆弱物品的自动化处理提供了高保真、可扩展且符合伦理的解决方案，未来可扩展至其他软操作任务。

Abstract: Robotics and automation are key enablers to increase throughput in ongoing
conservation efforts across various threatened ecosystems. Cataloguing,
digitisation, husbandry, and similar activities require the ability to interact
with delicate, fragile samples without damaging them. Additionally,
learning-based solutions to these tasks require the ability to safely acquire
data to train manipulation policies through, e.g., reinforcement learning. To
address these twin needs, we introduce a novel method to print free-form,
highly sensorised soft 'physical twins'. We present an automated design
workflow to create complex and customisable 3D soft sensing structures on
demand from 3D scans or models. Compared to the state of the art, our soft
liquid metal sensors faithfully recreate complex natural geometries and display
excellent sensing properties suitable for validating performance in delicate
manipulation tasks. We demonstrate the application of our physical twins as
'sensing corals': high-fidelity, 3D printed replicas of scanned corals that
eliminate the need for live coral experimentation, whilst increasing data
quality, offering an ethical and scalable pathway for advancing autonomous
coral handling and soft manipulation broadly. Through extensive bench-top
manipulation and underwater grasping experiments, we show that our sensing
coral is able to detect grasps under 0.5 N, effectively capturing the delicate
interactions and light contact forces required for coral handling. Finally, we
showcase the value of our physical twins across two demonstrations: (i)
automated coral labelling for lab identification and (ii) robotic coral
aquaculture. Sensing physical twins such as ours can provide richer grasping
feedback than conventional sensors providing experimental validation of prior
to deployment in handling fragile and delicate items.

</details>


### [79] [FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS Models to LiDAR](https://arxiv.org/abs/2509.17390)
*Junzhe Wu,Yufei Jia,Yiyi Yan,Zhixing Chen,Tiao Tan,Zifan Wang,Guangyu Wang*

Main category: cs.RO

TL;DR: FGGS-LiDAR是一个框架，能够将任何预训练的3D高斯泼溅模型转换为高保真、水密网格，用于高性能LiDAR模拟。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术在逼真渲染方面取得了突破，但其资产与LiDAR模拟不兼容，而后者对机器人和自动驾驶至关重要。

Method: 通过体积离散化和截断符号距离场提取的通用流程，将3D高斯泼溅模型转换为网格，并配合GPU加速的光线投射模块。

Result: 验证显示其几何保真度卓越，能以超过500FPS的速度模拟LiDAR返回。

Conclusion: 该框架扩展了3D高斯泼溅资产的用途，为可扩展的多模态模拟提供了新功能。

Abstract: While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic
rendering, its vast ecosystem of assets remains incompatible with
high-performance LiDAR simulation, a critical tool for robotics and autonomous
driving. We present \textbf{FGGS-LiDAR}, a framework that bridges this gap with
a truly plug-and-play approach. Our method converts \textit{any} pretrained
3DGS model into a high-fidelity, watertight mesh without requiring
LiDAR-specific supervision or architectural alterations. This conversion is
achieved through a general pipeline of volumetric discretization and Truncated
Signed Distance Field (TSDF) extraction. We pair this with a highly optimized,
GPU-accelerated ray-casting module that simulates LiDAR returns at over 500
FPS. We validate our approach on indoor and outdoor scenes, demonstrating
exceptional geometric fidelity; By enabling the direct reuse of 3DGS assets for
geometrically accurate depth sensing, our framework extends their utility
beyond visualization and unlocks new capabilities for scalable, multimodal
simulation. Our open-source implementation is available at
https://github.com/TATP-233/FGGS-LiDAR.

</details>


### [80] [GPS Denied IBVS-Based Navigation and Collision Avoidance of UAV Using a Low-Cost RGB Camera](https://arxiv.org/abs/2509.17435)
*Xiaoyu Wang,Yan Rui Tan,William Leong,Sunan Huang,Rodney Teo,Cheng Xiang*

Main category: cs.RO

TL;DR: 论文提出了一种仅使用RGB相机的基于图像的视觉伺服（IBVS）框架，用于无人机导航和避障，实现了无需显式路径规划的导航和基于AI的单目深度估计的避障。


<details>
  <summary>Details</summary>
Motivation: 尽管无人机导航已被广泛研究，但在涉及多个视觉目标和避障任务中应用IBVS仍具挑战性。

Method: 提出了一个完全在Jetson平台上运行的IBVS框架，利用AI从RGB图像估计深度以实现避障，无需依赖立体相机或外部工作站。

Result: 实验证明，无人机能在无GPS环境中有效导航并通过多个AprilTags，同时避开障碍物。

Conclusion: 该框架为无人机在复杂环境中的自主导航和避障提供了高效可行的解决方案。

Abstract: This paper proposes an image-based visual servoing (IBVS) framework for UAV
navigation and collision avoidance using only an RGB camera. While UAV
navigation has been extensively studied, it remains challenging to apply IBVS
in missions involving multiple visual targets and collision avoidance. The
proposed method achieves navigation without explicit path planning, and
collision avoidance is realized through AI-based monocular depth estimation
from RGB images. Unlike approaches that rely on stereo cameras or external
workstations, our framework runs fully onboard a Jetson platform, ensuring a
self-contained and deployable system. Experimental results validate that the
UAV can navigate across multiple AprilTags and avoid obstacles effectively in
GPS-denied environments.

</details>


### [81] [Learning Dexterous Manipulation with Quantized Hand State](https://arxiv.org/abs/2509.17450)
*Ying Feng,Hongjie Fang,Yinong He,Jingjing Chen,Chenxi Wang,Zihao He,Ruonan Liu,Cewu Lu*

Main category: cs.RO

TL;DR: DQ-RISE通过量化手部状态简化预测，同时引入连续松弛方法，实现手臂与手的协调控制，解决了现有方法中手部动作主导的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉运动策略将手臂和手的动作耦合在高维空间中，导致手部动作主导并影响手臂控制，影响了精细操作的协调性。

Method: 提出DQ-RISE方法，量化手部状态以简化运动预测，并通过连续松弛方法实现手臂与手状态的联合扩散。

Result: 实验表明DQ-RISE实现了更平衡和高效的学习，为结构化、通用的精细操作提供了可能。

Conclusion: DQ-RISE通过优化手臂与手的协调控制，解决了高维动作空间中的手部动作主导问题，提升了精细操作的效率。

Abstract: Dexterous robotic hands enable robots to perform complex manipulations that
require fine-grained control and adaptability. Achieving such manipulation is
challenging because the high degrees of freedom tightly couple hand and arm
motions, making learning and control difficult. Successful dexterous
manipulation relies not only on precise hand motions, but also on accurate
spatial positioning of the arm and coordinated arm-hand dynamics. However, most
existing visuomotor policies represent arm and hand actions in a single
combined space, which often causes high-dimensional hand actions to dominate
the coupled action space and compromise arm control. To address this, we
propose DQ-RISE, which quantizes hand states to simplify hand motion prediction
while preserving essential patterns, and applies a continuous relaxation that
allows arm actions to diffuse jointly with these compact hand states. This
design enables the policy to learn arm-hand coordination from data while
preventing hand actions from overwhelming the action space. Experiments show
that DQ-RISE achieves more balanced and efficient learning, paving the way
toward structured and generalizable dexterous manipulation. Project website:
http://rise-policy.github.io/DQ-RISE/

</details>


### [82] [Morphologies of a sagging elastica with intrinsic sensing and actuation](https://arxiv.org/abs/2509.17572)
*Vishnu Deo Mishra,S Ganga Prasath*

Main category: cs.RO

TL;DR: 该论文研究了通过简单的比例反馈策略调整柔软机器人的形状，分析了传感器和执行器的限制对形状调整的影响，并探讨了其在复杂任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 柔软机器人在形状调整中由于几何非线性、建模误差以及传感/执行能力限制，往往难以计算所需的执行力矩。本文旨在探索简单反馈策略对此的影响。

Method: 将柔软机器人建模为弹性体，使用比例反馈策略（执行力矩与感知曲率成正比），并通过滤波器模拟有限数量的传感器和执行器。研究了补偿自重引起的下垂的任务。

Result: 研究发现，设备在相空间中经历了一系列形态不稳定性。在复杂形状调整任务中，传感和执行能力的限制导致长、短波长特征的捕获需要权衡错误最小化。

Conclusion: 模型为设计和研究具有有限传感和执行能力的柔软机器人提供了定量分析工具，适用于复杂操控任务。

Abstract: The morphology of a slender soft-robot can be modified by sensing its shape
via sensors and exerting moments via actuators embedded along its body. The
actuating moments required to morph these soft-robots to a desired shape are
often difficult to compute due to the geometric non-linearity associated with
the structure, the errors in modeling the experimental system, and the
limitations in sensing and feedback/actuation capabilities. In this article, we
explore the effect of a simple feedback strategy (actuation being proportional
to the sensed curvature) on the shape of a soft-robot, modeled as an elastica.
The finite number of sensors and actuators, often seen in experiments, is
captured in the model via filters of specified widths. Using proportional
feedback, we study the simple task of straightening the device by compensating
for the sagging introduced by its self-weight. The device undergoes a hierarchy
of morphological instabilities defined in the phase-space given by the
gravito-bending number, non-dimensional sensing/feedback gain, and the scaled
width of the filter. For complex shape-morphing tasks, given a perfect model of
the device with limited sensing and actuating capabilities, we find that a
trade-off arises (set by the sensor spacing & actuator size) between capturing
the long and short wavelength features. We show that the error in
shape-morphing is minimal for a fixed filter width when we choose an
appropriate actuating gain (whose magnitude goes as a square of the filter
width). Our model provides a quantitative lens to study and design slender soft
devices with limited sensing and actuating capabilities for complex maneuvering
applications.

</details>


### [83] [GeCCo - a Generalist Contact-Conditioned Policy for Loco-Manipulation Skills on Legged Robots](https://arxiv.org/abs/2509.17582)
*Vassil Atanassov,Wanming Yu,Siddhant Gangapurwala,James Wilson,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 该论文提出了一种名为GeCCo的通用接触条件策略，通过深度强化学习训练，能够跟踪四足机器人的任意接触点，避免了每次新任务都需要重新训练策略的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要为每个新任务重新定义和调整奖励函数，耗时且难以扩展。

Method: 使用深度强化学习训练通用接触条件策略（GeCCo），并复用该低层策略完成多种高层任务。

Result: 在多种运动和操作任务中展现了方法的可扩展性和鲁棒性，如行走、穿越复杂地形和与物体交互。

Conclusion: GeCCo能够高效地适应新任务，仅需结合特定任务的高层接触规划器即可，无需从头训练。

Abstract: Most modern approaches to quadruped locomotion focus on using Deep
Reinforcement Learning (DRL) to learn policies from scratch, in an end-to-end
manner. Such methods often fail to scale, as every new problem or application
requires time-consuming and iterative reward definition and tuning. We present
Generalist Contact-Conditioned Policy (GeCCo) -- a low-level policy trained
with Deep Reinforcement Learning that is capable of tracking arbitrary contact
points on a quadruped robot. The strength of our approach is that it provides a
general and modular low-level controller that can be reused for a wider range
of high-level tasks, without the need to re-train new controllers from scratch.
We demonstrate the scalability and robustness of our method by evaluating on a
wide range of locomotion and manipulation tasks in a common framework and under
a single generalist policy. These include a variety of gaits, traversing
complex terrains (eg. stairs and slopes) as well as previously unseen
stepping-stones and narrow beams, and interacting with objects (eg. pushing
buttons, tracking trajectories). Our framework acquires new behaviors more
efficiently, simply by combining a task-specific high-level contact planner and
the pre-trained generalist policy. A supplementary video can be found at
https://youtu.be/o8Dd44MkG2E.

</details>


### [84] [Robust and Resilient Soft Robotic Object Insertion with Compliance-Enabled Contact Formation and Failure Recovery](https://arxiv.org/abs/2509.17666)
*Mimo Shirasaka,Cristian C. Beltran-Hernandez,Masashi Hamaya,Yoshitaka Ushiku*

Main category: cs.RO

TL;DR: 论文提出了一种基于被动柔顺软腕的稳健物体插入方法，通过大变形吸收接触力，无需高频控制或力感知，并结合自动失败恢复策略。


<details>
  <summary>Details</summary>
Motivation: 传统的物体插入任务在姿态不确定和环境变化下容易失败，需要手动微调或控制器重新训练，本文旨在解决这一问题。

Method: 利用被动柔顺软腕实现大变形接触吸收，将插入任务建模为柔顺接触状态序列，并整合自动失败恢复策略。使用预训练的视觉语言模型（VLM）评估执行效果并提出恢复动作。

Result: 在模拟实验中，该方法在83%的情况下成功，能够从随机条件（如5度的抓取偏差、20mm的孔位误差、5倍摩擦增加等）中恢复，并在真实机器人上验证了有效性。

Conclusion: 柔顺设计结合自动化失败恢复策略能够显著提升物体插入任务的鲁棒性和适应性，适用于多样化场景。

Abstract: Object insertion tasks are prone to failures under pose uncertainties and
environmental variations, traditionally requiring manual finetuning or
controller retraining. We present a novel approach for robust and resilient
object insertion using a passively compliant soft wrist that enables safe
contact absorption through large deformations, without high-frequency control
or force sensing. Our method structures insertion as compliance-enabled contact
formations, sequential contact states that progressively constrain degrees of
freedom, and integrates automated failure recovery strategies. Our key insight
is that wrist compliance permits safe, repeated recovery attempts; hence, we
refer to it as compliance-enabled failure recovery. We employ a pre-trained
vision-language model (VLM) that assesses each skill execution from terminal
poses and images, identifies failure modes, and proposes recovery actions by
selecting skills and updating goals. In simulation, our method achieved an 83%
success rate, recovering from failures induced by randomized
conditions--including grasp misalignments up to 5 degrees, hole-pose errors up
to 20mm, fivefold increases in friction, and previously unseen
square/rectangular pegs--and we further validate the approach on a real robot.

</details>


### [85] [Towards Learning Boulder Excavation with Hydraulic Excavators](https://arxiv.org/abs/2509.17683)
*Jonas Gruetter,Lorenzo Terenzi,Pascal Egli,Marco Hutter*

Main category: cs.RO

TL;DR: 论文展示了如何通过强化学习让标准挖掘机在不更换专用夹具的情况下处理不规则大岩石，成功率达70%，接近人类操作员的83%。


<details>
  <summary>Details</summary>
Motivation: 解决建筑工地在挖掘或平整作业中需移除大岩石的问题，避免因更换夹具而中断工作流程。

Method: 使用强化学习策略在模拟环境中训练，结合稀疏LiDAR数据和本体反馈控制标准挖掘铲。

Result: 现场测试成功率为70%，接近于人类操作员的83%。

Conclusion: 标准建筑设备能在感知稀疏和恶劣户外条件下学习复杂操作。

Abstract: Construction sites frequently require removing large rocks before excavation
or grading can proceed. Human operators typically extract these boulders using
only standard digging buckets, avoiding time-consuming tool changes to
specialized grippers. This task demands manipulating irregular objects with
unknown geometries in harsh outdoor environments where dust, variable lighting,
and occlusions hinder perception. The excavator must adapt to varying soil
resistance--dragging along hard-packed surfaces or penetrating soft
ground--while coordinating multiple hydraulic joints to secure rocks using a
shovel. Current autonomous excavation focuses on continuous media (soil,
gravel) or uses specialized grippers with detailed geometric planning for
discrete objects. These approaches either cannot handle large irregular rocks
or require impractical tool changes that interrupt workflow. We train a
reinforcement learning policy in simulation using rigid-body dynamics and
analytical soil models. The policy processes sparse LiDAR points (just 20 per
rock) from vision-based segmentation and proprioceptive feedback to control
standard excavator buckets. The learned agent discovers different strategies
based on soil resistance: dragging along the surface in hard soil and
penetrating directly in soft conditions. Field tests on a 12-ton excavator
achieved 70% success across varied rocks (0.4-0.7m) and soil types, compared to
83% for human operators. This demonstrates that standard construction equipment
can learn complex manipulation despite sparse perception and challenging
outdoor conditions.

</details>


### [86] [EigenSafe: A Spectral Framework for Learning-Based Stochastic Safety Filtering](https://arxiv.org/abs/2509.17750)
*Inkyu Jang,Jonghae Park,Chams E. Mballo,Sihyun Cho,Claire J. Tomlin,H. Jin Kim*

Main category: cs.RO

TL;DR: EigenSafe是一个基于算子理论的框架，用于随机系统中学习启发的安全关键控制，通过主导特征对提供安全度量。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如Hamilton-Jacobi可达性和控制屏障函数）难以全面衡量随机系统的安全性，EigenSafe通过主导特征对提供更全面的安全评估。

Method: 推导了一个线性算子，其主导特征对包含单个状态和闭环系统的安全信息，并离线学习该特征对及备份策略。

Result: 在三个模拟的安全关键控制任务中验证了框架的有效性。

Conclusion: EigenSafe为随机系统提供了一种新的安全控制方法，通过主导特征对和备份策略增强了安全性。

Abstract: We present EigenSafe, an operator-theoretic framework for learning-enabled
safety-critical control for stochastic systems. In many robotic systems where
dynamics are best modeled as stochastic systems due to factors such as sensing
noise and environmental disturbances, it is challenging for conventional
methods such as Hamilton-Jacobi reachability and control barrier functions to
provide a holistic measure of safety. We derive a linear operator governing the
dynamic programming principle for safety probability, and find that its
dominant eigenpair provides information about safety for both individual states
and the overall closed-loop system. The proposed learning framework, called
EigenSafe, jointly learns this dominant eigenpair and a safe backup policy in
an offline manner. The learned eigenfunction is then used to construct a safety
filter that detects potentially unsafe situations and falls back to the backup
policy. The framework is validated in three simulated stochastic
safety-critical control tasks.

</details>


### [87] [MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies](https://arxiv.org/abs/2509.17759)
*Chengbo Yuan,Rui Zhou,Mengzhen Liu,Yingdong Hu,Shengjie Wang,Li Yi,Chuan Wen,Shanghang Zhang,Yang Gao*

Main category: cs.RO

TL;DR: 这篇论文提出了MotionTrans框架，通过人类与机器人数据共同训练，实现了从人类数据中直接学习新动作以完成任务的目标。


<details>
  <summary>Details</summary>
Motivation: 模仿学习中机器人数据的稀缺性是瓶颈，而人类数据具有丰富的多样性，可以用于动作学习。本文旨在探索人类数据是否能使机器人策略直接学习新动作完成任务。

Method: 提出了MotionTrans框架，包括数据收集系统、人类数据转换管道和加权共同训练策略，并在30个任务上进行共同训练。

Result: 成功将13个任务的运动直接从人类数据转移到机器人策略中，其中9个任务实现了零样本非平凡成功率，预训练-微调性能提升40%。

Conclusion: 研究发现，成功的动作学习关键在于与机器人数据共同训练和广泛的任务相关动作覆盖，这为利用人类数据训练机器人策略提供了新方向。

Abstract: Scaling real robot data is a key bottleneck in imitation learning, leading to
the use of auxiliary data for policy training. While other aspects of robotic
manipulation such as image or language understanding may be learned from
internet-based datasets, acquiring motion knowledge remains challenging. Human
data, with its rich diversity of manipulation behaviors, offers a valuable
resource for this purpose. While previous works show that using human data can
bring benefits, such as improving robustness and training efficiency, it
remains unclear whether it can realize its greatest advantage: enabling robot
policies to directly learn new motions for task completion. In this paper, we
systematically explore this potential through multi-task human-robot
cotraining. We introduce MotionTrans, a framework that includes a data
collection system, a human data transformation pipeline, and a weighted
cotraining strategy. By cotraining 30 human-robot tasks simultaneously, we
direcly transfer motions of 13 tasks from human data to deployable end-to-end
robot policies. Notably, 9 tasks achieve non-trivial success rates in zero-shot
manner. MotionTrans also significantly enhances pretraining-finetuning
performance (+40% success rate). Through ablation study, we also identify key
factors for successful motion learning: cotraining with robot data and broad
task-related motion coverage. These findings unlock the potential of
motion-level learning from human data, offering insights into its effective use
for training robotic manipulation policies. All data, code, and model weights
are open-sourced https://motiontrans.github.io/.

</details>


### [88] [Enhancing the NAO: Extending Capabilities of Legacy Robots for Long-Term Research](https://arxiv.org/abs/2509.17760)
*Austin Wilson,Sahar Kapasi,Zane Greene,Alexis E. Block*

Main category: cs.RO

TL;DR: 论文提出了一种名为Enhanced NAO的升级版机器人，通过改进硬件和软件延长了旧款NAO机器人的使用寿命，显著提升了交互质量和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决因制造商停止支持而无法适配现代传感和交互功能的旧款机器人平台问题。

Method: 升级了麦克风、RGB-D和热成像摄像头，并增加计算资源，同时结合云端和本地模型进行感知与对话。

Result: Enhanced NAO在测试中表现出更高的对话质量和用户偏好，且未增加响应延迟。

Conclusion: 该框架为延长旧款机器人的寿命和研究价值提供了平台无关的策略。

Abstract: Many research groups face challenges when legacy (unsupported) robotic
platforms lose manufacturer support and cannot accommodate modern sensing,
speech, and interaction capabilities. We present the Enhanced NAO, a
revitalized version of Aldebaran's NAO robot that uses upgraded microphones,
RGB-D and thermal cameras, and additional compute resources in a fully
self-contained package. This system combines cloud and local models for
perception and dialogue, while preserving the NAO's expressive body and
behaviors. In a pilot validation study, the Enhanced NAO delivered
significantly higher conversational quality and stronger user preference
compared to the NAO AI Edition, without increasing response latency. Key
upgrades, such as beamforming microphones and low-latency audio processing,
reduced artifacts like self-hearing and improved multi-party separation.
Expanded visual and thermal sensing established a foundation for future
interaction capabilities. Beyond the NAO, our framework provides a
platform-agnostic strategy for extending the lifespan and research utility of
legacy robots, ensuring they remain valuable tools for human-robot interaction.

</details>


### [89] [RoboSeek: You Need to Interact with Your Objects](https://arxiv.org/abs/2509.17783)
*Yibo Peng,Jiahao Yang,Shenhao Yan,Ziyu Huang,Shuang Li,Shuguang Cui,Yiming Zhao,Yatong Han*

Main category: cs.RO

TL;DR: RoboSeek是一个通过互动经验优化机器人操作的框架，利用仿真训练和真实2仿真2真实（real2sim2real）迁移实现高效任务执行，在长时任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 受具身认知理论启发，旨在解决长时机器人操作任务中序列决策、物理约束和感知不确定性等挑战。

Method: 通过3D重建仿真真实环境，结合强化学习和交叉熵方法训练策略，并通过real2sim2real迁移到现实平台。

Result: 在八个长时操作任务中平均成功率79%，显著优于基线（成功率<50%）。

Conclusion: RoboSeek在复杂动态环境中表现出高效性和鲁棒性，推动了更具通用性的机器人学习方法。

Abstract: Optimizing and refining action execution through
  exploration and interaction is a promising way for robotic
  manipulation. However, practical approaches to interaction driven robotic
learning are still underexplored, particularly for
  long-horizon tasks where sequential decision-making, physical
  constraints, and perceptual uncertainties pose significant chal lenges.
Motivated by embodied cognition theory, we propose
  RoboSeek, a framework for embodied action execution that
  leverages interactive experience to accomplish manipulation
  tasks. RoboSeek optimizes prior knowledge from high-level
  perception models through closed-loop training in simulation
  and achieves robust real-world execution via a real2sim2real
  transfer pipeline. Specifically, we first replicate real-world
  environments in simulation using 3D reconstruction to provide
  visually and physically consistent environments., then we train
  policies in simulation using reinforcement learning and the
  cross-entropy method leveraging visual priors. The learned
  policies are subsequently deployed on real robotic platforms
  for execution. RoboSeek is hardware-agnostic and is evaluated
  on multiple robotic platforms across eight long-horizon ma nipulation tasks
involving sequential interactions, tool use, and
  object handling. Our approach achieves an average success rate
  of 79%, significantly outperforming baselines whose success
  rates remain below 50%, highlighting its generalization and
  robustness across tasks and platforms. Experimental results
  validate the effectiveness of our training framework in complex,
  dynamic real-world settings and demonstrate the stability of the
  proposed real2sim2real transfer mechanism, paving the way for
  more generalizable embodied robotic learning. Project Page:
  https://russderrick.github.io/Roboseek/

</details>


### [90] [Tac2Motion: Contact-Aware Reinforcement Learning with Tactile Feedback for Robotic Hand Manipulation](https://arxiv.org/abs/2509.17812)
*Yitaek Kim,Casper Hewson Rask,Christoffer Sloth*

Main category: cs.RO

TL;DR: Tac2Motion是一个基于触觉感知的强化学习框架，专注于学习接触丰富的手内操作任务，如拧开盖子。通过触觉奖励塑造和嵌入观察空间，提高了数据效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决接触丰富的手内操作任务（如拧开盖子）的学习难题，利用触觉感知提升强化学习的效果。

Method: 提出触觉感知奖励塑造方法，并将触觉信息嵌入观察空间，同时设计奖励以鼓励稳固抓握和流畅手指运动。

Result: 在拧开盖子场景中验证了框架的有效性，展示了对多种物体类型和动态（如扭转摩擦）的泛化能力，且策略可迁移至真实机器人（Shadow Robot）。

Conclusion: Tac2Motion框架通过触觉感知显著提升了手内操作任务的学习效率和性能，并展示了从模拟到真实世界的迁移潜力。

Abstract: This paper proposes Tac2Motion, a contact-aware reinforcement learning
framework to facilitate the learning of contact-rich in-hand manipulation
tasks, such as removing a lid. To this end, we propose tactile sensing-based
reward shaping and incorporate the sensing into the observation space through
embedding. The designed rewards encourage an agent to ensure firm grasping and
smooth finger gaiting at the same time, leading to higher data efficiency and
robust performance compared to the baseline. We verify the proposed framework
on the opening a lid scenario, showing generalization of the trained policy
into a couple of object types and various dynamics such as torsional friction.
Lastly, the learned policy is demonstrated on the multi-fingered robot, Shadow
Robot, showing that the control policy can be transferred to the real world.
The video is available: https://youtu.be/poeJBPR7urQ.

</details>


### [91] [SocialTraj: Two-Stage Socially-Aware Trajectory Prediction for Autonomous Driving via Conditional Diffusion Model](https://arxiv.org/abs/2509.17850)
*Xiao Zhou,Zengqi Peng,Jun Ma*

Main category: cs.RO

TL;DR: SocialTraj是一种新颖的轨迹预测框架，通过结合社会心理学原理（社会价值取向，SVO），提升自动驾驶系统对周围车辆多模态行为的预测能力。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在高度动态和复杂的交通场景中难以捕捉驾驶员的多模态行为，导致预测轨迹与实际未来运动偏离。

Method: 利用贝叶斯逆强化学习（IRL）估计周围车辆的SVO，并将SVO嵌入到条件去噪扩散模型中，同时明确结合自车的未来轨迹以增强交互建模。

Result: 在NGSIM和HighD数据集上的实验表明，SocialTraj能够适应高动态和交互场景，生成社会合规且行为一致的预测轨迹，优于现有基线方法。

Conclusion: 动态SVO估计和明确的自车规划显著提高了预测准确性并大幅减少了推理时间。

Abstract: Accurate trajectory prediction of surrounding vehicles (SVs) is crucial for
autonomous driving systems to avoid misguided decisions and potential
accidents. However, achieving reliable predictions in highly dynamic and
complex traffic scenarios remains a significant challenge. One of the key
impediments lies in the limited effectiveness of current approaches to capture
the multi-modal behaviors of drivers, which leads to predicted trajectories
that deviate from actual future motions. To address this issue, we propose
SocialTraj, a novel trajectory prediction framework integrating social
psychology principles through social value orientation (SVO). By utilizing
Bayesian inverse reinforcement learning (IRL) to estimate the SVO of SVs, we
obtain the critical social context to infer the future interaction trend. To
ensure modal consistency in predicted behaviors, the estimated SVOs of SVs are
embedded into a conditional denoising diffusion model that aligns generated
trajectories with historical driving styles. Additionally, the planned future
trajectory of the ego vehicle (EV) is explicitly incorporated to enhance
interaction modeling. Extensive experiments on NGSIM and HighD datasets
demonstrate that SocialTraj is capable of adapting to highly dynamic and
interactive scenarios while generating socially compliant and behaviorally
consistent trajectory predictions, outperforming existing baselines. Ablation
studies demonstrate that dynamic SVO estimation and explicit ego-planning
components notably improve prediction accuracy and substantially reduce
inference time.

</details>


### [92] [Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection](https://arxiv.org/abs/2509.17877)
*Richard Kuhlmann,Jakob Wolfram,Boyang Sun,Jiaxu Xing,Davide Scaramuzza,Marc Pollefeys,Cesar Cadena*

Main category: cs.RO

TL;DR: 本文提出了一种基于感知的自主检查方法，通过强化学习框架优化机器人轨迹，确保目标可视性。


<details>
  <summary>Details</summary>
Motivation: 传统检查任务仅关注导航到目标位置，忽略了目标可视性的重要性，导致效率低下。

Method: 提出了一个端到端的强化学习框架，明确将目标可视性作为主要目标，并结合感知和本体感知训练策略。

Result: 实验表明，该方法在模拟和真实环境中均优于现有导航方法，生成更高效的检查轨迹。

Conclusion: 研究证明感知导向的检查方法能更有效地完成任务，具有实际应用价值。

Abstract: Autonomous inspection is a central problem in robotics, with applications
ranging from industrial monitoring to search-and-rescue. Traditionally,
inspection has often been reduced to navigation tasks, where the objective is
to reach a predefined location while avoiding obstacles. However, this
formulation captures only part of the real inspection problem. In real-world
environments, the inspection targets may become visible well before their exact
coordinates are reached, making further movement both redundant and
inefficient. What matters more for inspection is not simply arriving at the
target's position, but positioning the robot at a viewpoint from which the
target becomes observable. In this work, we revisit inspection from a
perception-aware perspective. We propose an end-to-end reinforcement learning
framework that explicitly incorporates target visibility as the primary
objective, enabling the robot to find the shortest trajectory that guarantees
visual contact with the target without relying on a map. The learned policy
leverages both perceptual and proprioceptive sensing and is trained entirely in
simulation, before being deployed to a real-world robot. We further develop an
algorithm to compute ground-truth shortest inspection paths, which provides a
reference for evaluation. Through extensive experiments, we show that our
method outperforms existing classical and learning-based navigation approaches,
yielding more efficient inspection trajectories in both simulated and
real-world settings. The project is avialable at
https://sight-over-site.github.io/

</details>


### [93] [The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control](https://arxiv.org/abs/2509.17884)
*Arun L. Bishop,Juan Alvarez-Padilla,Sam Schoedel,Ibrahima Sory Sow,Juee Chandrachud,Sheitej Sharma,Will Kraus,Beomyeong Park,Robert J. Griffin,John M. Dolan,Zachary Manchester*

Main category: cs.RO

TL;DR: 研究表明，使用线性时不变近似动力学的全身模型预测控制器可以在复杂腿部机器人上完成基础运动任务，无需在线非线性动力学计算或矩阵求逆。


<details>
  <summary>Details</summary>
Motivation: 探索在何种情况下运动控制器需要考虑非线性动力学，并验证线性近似方法的有效性。

Method: 开发了一种全身模型预测控制器，采用线性时不变近似动力学，避免了复杂的非线性计算。

Result: 该控制器成功在四足机器人和液压人形机器人上实现了行走、干扰抵抗和目标导航等功能。

Conclusion: 线性时不变近似动力学足以完成复杂机器人上的基础运动任务，简化了控制器的实现和计算负担。

Abstract: When do locomotion controllers require reasoning about nonlinearities? In
this work, we show that a whole-body model-predictive controller using a simple
linear time-invariant approximation of the whole-body dynamics is able to
execute basic locomotion tasks on complex legged robots. The formulation
requires no online nonlinear dynamics evaluations or matrix inversions. We
demonstrate walking, disturbance rejection, and even navigation to a goal
position without a separate footstep planner on a quadrupedal robot. In
addition, we demonstrate dynamic walking on a hydraulic humanoid, a robot with
significant limb inertia, complex actuator dynamics, and large sim-to-real gap.

</details>


### [94] [DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving](https://arxiv.org/abs/2509.17940)
*Shuyao Shang,Yuntao Chen,Yuqi Wang,Yingyan Li,Zhaoxiang Zhang*

Main category: cs.RO

TL;DR: DriveDPO提出了一种安全直接偏好优化策略学习框架，通过结合人类模仿相似性和基于规则的安全评分，改进了端到端自动驾驶的安全性。


<details>
  <summary>Details</summary>
Motivation: 传统端到端自动驾驶方法通过模仿学习训练，但存在安全性问题，无法区分看似人类行为但不安全的轨迹。

Method: DriveDPO结合人类模仿相似性和规则安全评分作为统一策略分布，并通过轨迹级偏好对齐进行优化。

Result: 在NAVSIM基准测试中，DriveDPO达到了90.0的PDMS最高分，并在多种复杂场景中表现出更高的安全性。

Conclusion: DriveDPO框架显著提升了自动驾驶的安全性，能够生成更可靠的行为。

Abstract: End-to-end autonomous driving has substantially progressed by directly
predicting future trajectories from raw perception inputs, which bypasses
traditional modular pipelines. However, mainstream methods trained via
imitation learning suffer from critical safety limitations, as they fail to
distinguish between trajectories that appear human-like but are potentially
unsafe. Some recent approaches attempt to address this by regressing multiple
rule-driven scores but decoupling supervision from policy optimization,
resulting in suboptimal performance. To tackle these challenges, we propose
DriveDPO, a Safety Direct Preference Optimization Policy Learning framework.
First, we distill a unified policy distribution from human imitation similarity
and rule-based safety scores for direct policy optimization. Further, we
introduce an iterative Direct Preference Optimization stage formulated as
trajectory-level preference alignment. Extensive experiments on the NAVSIM
benchmark demonstrate that DriveDPO achieves a new state-of-the-art PDMS of
90.0. Furthermore, qualitative results across diverse challenging scenarios
highlight DriveDPO's ability to produce safer and more reliable driving
behaviors.

</details>


### [95] [ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion](https://arxiv.org/abs/2509.17941)
*Zichao Hu,Chen Tang,Michael J. Munje,Yifeng Zhu,Alex Liu,Shuijing Liu,Garrett Warnell,Peter Stone,Joydeep Biswas*

Main category: cs.RO

TL;DR: 论文提出了ComposableNav方法，让机器人能够在动态环境中根据指令导航，通过分解指令为独立动作并组合实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决指令导航中组合性规格的挑战，避免因动作组合指数增长带来的复杂性。

Method: 采用扩散模型分阶段训练：预训练动态导航的基模型，再通过强化学习微调为不同动作原语。

Result: ComposableNav能生成满足未见规格组合的轨迹，性能显著优于非组合方法。

Conclusion: 组合式方法能高效处理复杂指令，适用于动态环境导航任务。

Abstract: This paper considers the problem of enabling robots to navigate dynamic
environments while following instructions. The challenge lies in the
combinatorial nature of instruction specifications: each instruction can
include multiple specifications, and the number of possible specification
combinations grows exponentially as the robot's skill set expands. For example,
"overtake the pedestrian while staying on the right side of the road" consists
of two specifications: "overtake the pedestrian" and "walk on the right side of
the road." To tackle this challenge, we propose ComposableNav, based on the
intuition that following an instruction involves independently satisfying its
constituent specifications, each corresponding to a distinct motion primitive.
Using diffusion models, ComposableNav learns each primitive separately, then
composes them in parallel at deployment time to satisfy novel combinations of
specifications unseen in training. Additionally, to avoid the onerous need for
demonstrations of individual motion primitives, we propose a two-stage training
procedure: (1) supervised pre-training to learn a base diffusion model for
dynamic navigation, and (2) reinforcement learning fine-tuning that molds the
base model into different motion primitives. Through simulation and real-world
experiments, we show that ComposableNav enables robots to follow instructions
by generating trajectories that satisfy diverse and unseen combinations of
specifications, significantly outperforming both non-compositional VLM-based
policies and costmap composing baselines. Videos and additional materials can
be found on the project page: https://amrl.cs.utexas.edu/ComposableNav/

</details>


### [96] [Guided Multi-Fidelity Bayesian Optimization for Data-driven Controller Tuning with Digital Twins](https://arxiv.org/abs/2509.17952)
*Mahdi Nobar,Jürg Keller,Alessandro Forino,John Lygeros,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 提出了一种引导多保真贝叶斯优化框架，结合数字孪生仿真和真实数据，用于高效控制器调参。


<details>
  <summary>Details</summary>
Motivation: 针对闭环系统中仿真保真度不足或低成本近似的问题，通过校正模型减少模型不匹配。

Method: 构建多保真替代模型，结合校正模型优化数字孪生估计。自适应成本感知采集函数平衡改进、保真度和采样成本。

Result: 实验表明，该方法在机器人驱动硬件和数值研究中均优于标准贝叶斯优化和多保真方法。

Conclusion: 该方法动态调整数字孪生准确性，优化数据利用效率，提升控制器调参效果。

Abstract: We propose a \textit{guided multi-fidelity Bayesian optimization} framework
for data-efficient controller tuning that integrates corrected digital twin
(DT) simulations with real-world measurements. The method targets closed-loop
systems with limited-fidelity simulations or inexpensive approximations. To
address model mismatch, we build a multi-fidelity surrogate with a learned
correction model that refines DT estimates from real data. An adaptive
cost-aware acquisition function balances expected improvement, fidelity, and
sampling cost. Our method ensures adaptability as new measurements arrive. The
accuracy of DTs is re-estimated, dynamically adapting both cross-source
correlations and the acquisition function. This ensures that accurate DTs are
used more frequently, while inaccurate DTs are appropriately downweighted.
Experiments on robotic drive hardware and supporting numerical studies
demonstrate that our method enhances tuning efficiency compared to standard
Bayesian optimization (BO) and multi-fidelity methods.

</details>


### [97] [M3ET: Efficient Vision-Language Learning for Robotics based on Multimodal Mamba-Enhanced Transformer](https://arxiv.org/abs/2509.18005)
*Yanxin Zhang,Liang He,Zeyi Kang,Zuheng Ming,Kaixing Zhao*

Main category: cs.RO

TL;DR: 论文提出了一种轻量级多模态学习模型M3ET，通过结合Mamba模块和自适应注意力机制，优化特征融合和对齐，显著提升推理速度和性能，适用于资源受限的机器人平台。


<details>
  <summary>Details</summary>
Motivation: 当前多模态学习方法在无监督机器人环境中难以充分利用文本模态，且计算复杂度高。为解决这些问题，研究提出了轻量级模型M3ET。

Method: M3ET结合了Mamba模块和基于语义的自适应注意力机制，优化特征融合、对齐和模态重建。

Result: 实验表明，M3ET在预训练推理速度上提升了2.3倍，VQA任务准确率为0.74，模型参数减少了0.67倍。

Conclusion: M3ET的轻量设计使其适合资源受限的机器人平台，尽管在EQA任务上性能有限。

Abstract: In recent years, multimodal learning has become essential in robotic vision
and information fusion, especially for understanding human behavior in complex
environments. However, current methods struggle to fully leverage the textual
modality, relying on supervised pretrained models, which limits semantic
extraction in unsupervised robotic environments, particularly with significant
modality loss. These methods also tend to be computationally intensive, leading
to high resource consumption in real-world applications. To address these
challenges, we propose the Multi Modal Mamba Enhanced Transformer (M3ET), a
lightweight model designed for efficient multimodal learning, particularly on
mobile platforms. By incorporating the Mamba module and a semantic-based
adaptive attention mechanism, M3ET optimizes feature fusion, alignment, and
modality reconstruction. Our experiments show that M3ET improves cross-task
performance, with a 2.3 times increase in pretraining inference speed. In
particular, the core VQA task accuracy of M3ET remains at 0.74, while the
model's parameter count is reduced by 0.67. Although performance on the EQA
task is limited, M3ET's lightweight design makes it well suited for deployment
on resource-constrained robotic platforms.

</details>


### [98] [Prepare Before You Act: Learning From Humans to Rearrange Initial States](https://arxiv.org/abs/2509.18043)
*Yinlong Dai,Andre Keyser,Dylan P. Losey*

Main category: cs.RO

TL;DR: ReSET算法通过允许机器人在执行策略前调整环境，减少模仿学习策略在面对非典型初始状态时的泛化差距。


<details>
  <summary>Details</summary>
Motivation: 模仿学习策略在面对训练数据分布外的观察时表现不佳，而人类通常会调整环境以优化任务执行。研究目标是赋予机器人同样的环境调整能力。

Method: 提出ReSET算法，通过两步流程：先调整对象位姿使场景更接近训练数据，再执行策略。结合人类视频和遥操作数据进行场景调整决策和动作预测。

Result: 实验表明，ReSET在同等训练数据量下，比其他基线方法（如扩散策略和VLA）表现更稳健。

Conclusion: ReSET通过预先调整环境显著提升了模仿学习策略的泛化能力和任务执行鲁棒性。

Abstract: Imitation learning (IL) has proven effective across a wide range of
manipulation tasks. However, IL policies often struggle when faced with
out-of-distribution observations; for instance, when the target object is in a
previously unseen position or occluded by other objects. In these cases,
extensive demonstrations are needed for current IL methods to reach robust and
generalizable behaviors. But when humans are faced with these sorts of atypical
initial states, we often rearrange the environment for more favorable task
execution. For example, a person might rotate a coffee cup so that it is easier
to grasp the handle, or push a box out of the way so they can directly grasp
their target object. In this work we seek to equip robot learners with the same
capability: enabling robots to prepare the environment before executing their
given policy. We propose ReSET, an algorithm that takes initial states -- which
are outside the policy's distribution -- and autonomously modifies object poses
so that the restructured scene is similar to training data. Theoretically, we
show that this two step process (rearranging the environment before rolling out
the given policy) reduces the generalization gap. Practically, our ReSET
algorithm combines action-agnostic human videos with task-agnostic
teleoperation data to i) decide when to modify the scene, ii) predict what
simplifying actions a human would take, and iii) map those predictions into
robot action primitives. Comparisons with diffusion policies, VLAs, and other
baselines show that using ReSET to prepare the environment enables more robust
task execution with equal amounts of total training data. See videos at our
project website: https://reset2025paper.github.io/

</details>


### [99] [V2V-GoT: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multimodal Large Language Models and Graph-of-Thoughts](https://arxiv.org/abs/2509.18053)
*Hsu-kuang Chiu,Ryo Hachiuma,Chien-Yi Wang,Yu-Chiang Frank Wang,Min-Hung Chen,Stephen F. Smith*

Main category: cs.RO

TL;DR: 论文提出了一种基于图思维（Graph-of-Thoughts）的框架，用于多模态大型语言模型（MLLM）协同自动驾驶，解决了传感器被遮挡的安全问题，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统在面对传感器被大型物体遮挡时存在安全隐患，而传统的协同自动驾驶方法未充分利用图思维推理的潜力。

Method: 提出了一种新型图思维框架，结合遮挡感知的感知能力和规划感知的预测能力，并使用V2V-GoT-QA数据集和V2V-GoT模型进行训练与测试。

Result: 实验表明，该方法在协同感知、预测和规划任务中优于其他基线方法。

Conclusion: 通过引入图思维推理，该研究显著提升了协同自动驾驶的性能，为未来研究提供了新方向。

Abstract: Current state-of-the-art autonomous vehicles could face safety-critical
situations when their local sensors are occluded by large nearby objects on the
road. Vehicle-to-vehicle (V2V) cooperative autonomous driving has been proposed
as a means of addressing this problem, and one recently introduced framework
for cooperative autonomous driving has further adopted an approach that
incorporates a Multimodal Large Language Model (MLLM) to integrate cooperative
perception and planning processes. However, despite the potential benefit of
applying graph-of-thoughts reasoning to the MLLM, this idea has not been
considered by previous cooperative autonomous driving research. In this paper,
we propose a novel graph-of-thoughts framework specifically designed for
MLLM-based cooperative autonomous driving. Our graph-of-thoughts includes our
proposed novel ideas of occlusion-aware perception and planning-aware
prediction. We curate the V2V-GoT-QA dataset and develop the V2V-GoT model for
training and testing the cooperative driving graph-of-thoughts. Our
experimental results show that our method outperforms other baselines in
cooperative perception, prediction, and planning tasks.

</details>


### [100] [ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces](https://arxiv.org/abs/2509.18084)
*Jiawen Tian,Liqun Huang,Zhongren Cui,Jingchao Qiao,Jiafeng Xu,Xiao Ma,Zeyu Ren*

Main category: cs.RO

TL;DR: ByteWrist是一种新型的高度灵活且拟人化的并联手腕，用于机器人操作，通过紧凑的三阶段并联驱动机制和弧形末端连杆解决了传统手腕在狭窄空间操作中的局限性，适用于复杂非结构化环境。


<details>
  <summary>Details</summary>
Motivation: 现有串行和并联手腕在狭窄空间操作中存在明显限制，需要一种更紧凑、灵活且高效的设计以应对复杂任务，如家庭服务、医疗辅助和精密装配。

Method: 采用三阶段嵌套电机驱动连杆、弧形末端连杆和中央支撑球的球形关节设计，并通过运动学建模和数值雅可比矩阵解实现精确控制。

Result: ByteWrist在狭窄空间操作和双臂协作任务中表现优异，在紧凑性、效率和刚度方面显著优于传统Kinova系统。

Conclusion: ByteWrist是下一代在受限环境中进行机器人操作的有前途的解决方案，其设计创新和性能表现验证了其在多种应用场景中的潜力。

Abstract: This paper introduces ByteWrist, a novel highly-flexible and anthropomorphic
parallel wrist for robotic manipulation. ByteWrist addresses the critical
limitations of existing serial and parallel wrists in narrow-space operations
through a compact three-stage parallel drive mechanism integrated with
arc-shaped end linkages. The design achieves precise RPY (Roll-Pitch-Yaw)
motion while maintaining exceptional compactness, making it particularly
suitable for complex unstructured environments such as home services, medical
assistance, and precision assembly. The key innovations include: (1) a nested
three-stage motor-driven linkages that minimize volume while enabling
independent multi-DOF control, (2) arc-shaped end linkages that optimize force
transmission and expand motion range, and (3) a central supporting ball
functioning as a spherical joint that enhances structural stiffness without
compromising flexibility. Meanwhile, we present comprehensive kinematic
modeling including forward / inverse kinematics and a numerical Jacobian
solution for precise control. Empirically, we observe ByteWrist demonstrates
strong performance in narrow-space maneuverability and dual-arm cooperative
manipulation tasks, outperforming Kinova-based systems. Results indicate
significant improvements in compactness, efficiency, and stiffness compared to
traditional designs, establishing ByteWrist as a promising solution for
next-generation robotic manipulation in constrained environments.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [101] [Tolerance of Phase Noise in Single-Carrier M-Ary QAM Terahertz Wireless Communications](https://arxiv.org/abs/2509.16843)
*Bowen Liu,Takasumi Tanabe*

Main category: physics.optics

TL;DR: 论文分析了太赫兹无线通信中的相位噪声问题，通过建模和实验评估其对系统性能的影响，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 太赫兹通信因其高带宽潜力成为下一代高速链路的候选技术，但振荡器相位噪声成为了主要限制因素。

Method: 从实测频谱重建相位噪声，并将其嵌入单载波链路模型，评估其对高阶QAM传输的影响。

Result: 研究发现，振荡器稳定性的小幅提升能显著改善误码率，且无需成比例增加功率。

Conclusion: 研究为M-QAM系统中的相位噪声容忍度提供了直观参考，并强调了集成低噪声光子振荡器的重要性。

Abstract: Terahertz wireless communications offer abundant untapped spectrum and are
regarded as a promising playground for next-generation high-throughput links.
Yet oscillator phase noise becomes the dominant impairment at such high
frequencies, severely limiting the reliability of high-order QAM transmission.
Here, phase noise is reconstructed from measured spectra and embedded into a
single-carrier link model to evaluate its impact. Distinct distortion
mechanisms are identified, with slow common phase error and instantaneous phase
jitter, where the latter remains as the residual impairment after carrier phase
recovery. We further adopt 3{\sigma} error criterion that maps residual
distortions onto the constellation, offering a clear and practical indicator of
system robustness. The results indicate that modest improvements in oscillator
stability translate into significant BER gains without proportional power
increase. These findings provide intuitive tolerance of phase noise in M-QAM
systems and emphasizes the importance of integrating low-noise photonic
oscillators.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [102] [Frequency Switching for Simultaneous Wireless Information and Power Transfer](https://arxiv.org/abs/1705.03366)
*Dogay Altinel,Gunes Karabulut Kurt*

Main category: cs.IT

TL;DR: 提出了一种新的频率切换接收器结构，用于多载波通信系统中同时进行无线信息和能量传输，通过动态编程优化子载波分配，提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多载波通信系统中同时进行无线信息传输和能量采集的问题，通过优化子载波分配提高效率。

Method: 采用频率切换接收器结构，动态编程解决子载波分配的二进制背包问题，结合功率分配进一步优化性能。

Result: 数值研究表明，该方法在广泛参数范围内优于现有模型。

Conclusion: 提出的频率切换结构在多载波系统中高效实现信息和能量同步传输，且性能优越。

Abstract: A new frequency switching receiver structure is proposed for simultaneous
wireless information and power transfer in multi-carrier communication systems.
Each subcarrier is switched to either the energy harvesting unit or the
information decoding unit, according to the optimal subcarrier allocation. To
implement the system, one-bit feedback is required for each subcarrier. Two
optimization problems are defined, converted to binary knapsack problems, and
solved using dynamic programming approaches. Upper bounds are obtained using
continuous relaxations. Power allocation is integrated to further increase the
performance. Numerical studies show that the proposed frequency switching based
model is better than existing models in a wide range of parameters.

</details>


### [103] [Diversity Combining for RF Energy Harvesting](https://arxiv.org/abs/1705.10514)
*Dogay Altinel,Gunes Karabulut Kurt*

Main category: cs.IT

TL;DR: 研究探讨了在RF能量收集系统中使用多样性组合技术以提高能量收集效率，并考虑了其功耗对净收益的影响。


<details>
  <summary>Details</summary>
Motivation: RF能量收集技术为无线通信节点提供能源，但其能量供应可能不足，多样性组合技术有望提升能量收集量。

Method: 研究了选择组合(SC)、等增益组合(EGC)和最大比率组合(MRC)技术，并通过仿真比较了它们的性能。

Result: 多样性组合技术能提升能量收集性能，但功耗参数在确定合适技术时至关重要。

Conclusion: 虽然多样性组合技术能改善RF能量收集，但需权衡功耗以选择最优方案。

Abstract: RF energy harvesting (RFEH) is a promising technology for energy requirements
of wireless communication nodes. However, providing sufficient amount of energy
to ensure self-sufficient devices based on RFEH may be challenging. In this
paper, the use of diversity combining in RFEH systems is proposed to increase
the amount of harvested energy. The power consumption of diversity combining
process is also taken into account to analyze the net benefit of diversity
combining. Performances of RFEH systems are investigated for selection
combining (SC), equal gain combining (EGC), and maximal ratio combining (MRC)
techniques. Simulations are conducted to compare the numerical results of SC,
EGC, and MRC, and the results show that although the diversity combining
techniques can improve the energy harvesting performance, the power consumption
parameters have a critical importance while determining the suitable technique.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [104] [Quantum State Tomography for Tensor Networks in Two Dimensions](https://arxiv.org/abs/2509.16852)
*Zhen Qin,Zhihui Zhu*

Main category: quant-ph

TL;DR: 该研究填补了二维量子态（PEPS/PEPO）样本复杂度理论的空白，证明了在两种测量方案下能够稳定恢复量子态。


<details>
  <summary>Details</summary>
Motivation: 尽管一维量子态（MPOs）的恢复已有理论支持，但二维量子态（PEPS/PEPO）的样本复杂度尚未明确，本研究旨在填补这一空白。

Method: 研究采用两种量子测量方案（IC-POVMs和Haar随机投影测量），并通过约束最小二乘估计器实现稳定恢复。

Result: 结果表明，PEPS/PEPO的恢复误差在球形t-design下线性收敛，在Haar随机投影测量下多项式收敛。

Conclusion: 该研究为PEPS/PEPO在量子信息处理中的可靠应用提供了理论支持。

Abstract: Recent work has shown that for one-dimensional quantum states that can be
effectively approximated by matrix product operators (MPOs), a polynomial
number of copies of the state suffices for reconstruction. Compared to MPOs in
one dimension, projected entangled-pair states (PEPSs) and projected
entangled-pair operators (PEPOs), which represent typical low-dimensional
structures in two dimensions, are more prevalent as a looped tensor network.
However, a formal analysis of the sample complexity required for estimating
PEPS or PEPO has yet to be established. In this paper, we aim to address this
gap by providing theoretical guarantees for the stable recovery of PEPS and
PEPO. Our analysis primarily focuses on two quantum measurement schemes: $(i)$
informationally complete positive operator valued measures (IC-POVMs),
specifically the spherical $t$-designs ($t \geq 3$), and $(ii)$ projective
rank-one measurements, in particular Haar random projective measurements. We
first establish stable embeddings for PEPSs (or PEPOs) to ensure that the
information contained in the states can be preserved under these two
measurement schemes. We then show that a constrained least-squares estimator
achieves stable recovery for PEPSs (or PEPOs), with the recovery error bounded
when the number of state copies scales linearly under spherical $t$-designs and
polynomially under Haar-random projective measurements with respect to the
number of qudits. These results provide theoretical support for the reliable
use of PEPS and PEPO in practical quantum information processing.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [105] [Robust, Online, and Adaptive Decentralized Gaussian Processes](https://arxiv.org/abs/2509.18011)
*Fernando Llorente,Daniel Waxman,Sanket Jantre,Nathan M. Urban,Susan E. Minkoff*

Main category: stat.ML

TL;DR: 论文扩展了DRFGP算法，通过引入鲁棒滤波器更新和动态适应机制，提升了在高噪声和动态环境中的表现。


<details>
  <summary>Details</summary>
Motivation: Gaussian processes（GPs）在大规模动态且噪声环境中存在局限性，如计算复杂度高、对异常值敏感等，因此需要改进算法以适应这类场景。

Method: 扩展了DRFGP算法，加入鲁棒滤波器更新以减少异常值影响，并引入动态适应机制以应对时变函数。

Result: 改进后的算法保持了信息滤波的递归结构，同时提升了稳定性和准确性，在大规模地球系统应用中表现优异。

Conclusion: 扩展后的DRFGP算法在高噪声和动态环境中具有更强的适用性和潜力。

Abstract: Gaussian processes (GPs) offer a flexible, uncertainty-aware framework for
modeling complex signals, but scale cubically with data, assume static targets,
and are brittle to outliers, limiting their applicability in large-scale
problems with dynamic and noisy environments. Recent work introduced
decentralized random Fourier feature Gaussian processes (DRFGP), an online and
distributed algorithm that casts GPs in an information-filter form, enabling
exact sequential inference and fully distributed computation without reliance
on a fusion center. In this paper, we extend DRFGP along two key directions:
first, by introducing a robust-filtering update that downweights the impact of
atypical observations; and second, by incorporating a dynamic adaptation
mechanism that adapts to time-varying functions. The resulting algorithm
retains the recursive information-filter structure while enhancing stability
and accuracy. We demonstrate its effectiveness on a large-scale Earth system
application, underscoring its potential for in-situ modeling.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [106] [Sound field estimation with moving microphones using kernel ridge regression](https://arxiv.org/abs/2509.16358)
*Jesper Brunnström,Martin Bo Møller,Jan Østergaard,Shoichi Koyama,Toon van Waterschoot,Marc Moonen*

Main category: eess.AS

TL;DR: 提出一种基于核岭回归（KRR）的方法，用于移动麦克风的声场估计，通过引入先验知识和方向加权改进精度，并提出近似KRR方法以降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 使用移动麦克风进行声场估计可以提高灵活性、减少测量时间和设备限制。

Method: 基于离散傅里叶变换和Herglotz波函数的离散时间连续空间模型构建KRR方法，引入方向加权，并提出使用随机傅里叶特征（RFF）的近似KRR方法。

Result: 方向加权提高了估计精度，RFF方法降低了计算成本但牺牲了部分精度。

Conclusion: 该方法为移动麦克风声场估计提供了高效可行的解决方案，平衡了成本与性能。

Abstract: Sound field estimation with moving microphones can increase flexibility,
decrease measurement time, and reduce equipment constraints compared to using
stationary microphones. In this paper a sound field estimation method based on
kernel ridge regression (KRR) is proposed for moving microphones. The proposed
KRR method is constructed using a discrete time continuous space sound field
model based on the discrete Fourier transform and the Herglotz wave function.
The proposed method allows for the inclusion of prior knowledge as a
regularization penalty, similar to kernel-based methods with stationary
microphones, which is novel for moving microphones. Using a directional
weighting for the proposed method, the sound field estimates are improved,
which is demonstrated on both simulated and real data. Due to the high
computational cost of sound field estimation with moving microphones, an
approximate KRR method is proposed, using random Fourier features (RFF) to
approximate the kernel. The RFF method is shown to decrease computational cost
while obtaining less accurate estimates compared to KRR, providing a trade-off
between cost and performance.

</details>


### [107] [FUN-SSL: Full-band Layer Followed by U-Net with Narrow-band Layers for Multiple Moving Sound Source Localization](https://arxiv.org/abs/2509.17490)
*Yuseon Choi,Hyeonseung Kim,Jewoo Jun,Jong Won Shin*

Main category: eess.AS

TL;DR: 提出了一种基于U-Net的SSL模型，通过多分辨率窄带处理降低计算复杂度，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有双路径处理模型（如FN-SSL和IPDnet）在多源定位中表现优异，但计算成本高，需要优化。

Method: 用FUN块（全频层+多尺度窄带U-Net）替代IPDnet的全窄网络块，并引入跨块跳跃连接。

Result: FUN-SSL性能优于IPDnet，计算复杂度显著降低。

Conclusion: 多分辨率窄带U-Net结构可有效提升SSL模型性能并减少计算负担。

Abstract: Dual-path processing along the temporal and spectral dimensions has shown to
be effective in various speech processing applications. While the sound source
localization (SSL) models utilizing dual-path processing such as the FN-SSL and
IPDnet demonstrated impressive performances in localizing multiple moving
sources, they require significant amount of computation. In this paper, we
propose an architecture for SSL which introduces a U-Net to perform narrow-band
processing in multiple resolutions to reduce computational complexity. The
proposed model replaces the full-narrow network block in the IPDnet consisting
of one full-band LSTM layer along the spectral dimension followed by one
narrow-band LSTM layer along the temporal dimension with the FUN block composed
of one Full-band layer followed by a U-net with Narrow-band layers in multiple
scales. On top of the skip connections within each U-Net, we also introduce the
skip connections between FUN blocks to enrich information. Experimental results
showed that the proposed FUN-SSL outperformed previously proposed approaches
with computational complexity much lower than that of the IPDnet.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [108] [A Scalable and Interoperable Platform for Transforming Building Information with Brick Ontology](https://arxiv.org/abs/2509.16259)
*Rozita Teymourzadeh,Yuya Nakazawa*

Main category: cs.CY

TL;DR: 本文提出了一种智能平台，用于将建筑信息转换为Brick本体和图格式，以解决建筑自动化中的常见挑战。


<details>
  <summary>Details</summary>
Motivation: 建筑自动化公司在数字化和建筑信息化时代面临数据提取和分析的扩展性问题，且由于建筑信息敏感，云传输存在安全风险。

Method: 平台采用Brick本体和图数据结构技术，通过树形图结构和半自动化方法转换建筑信息。

Result: 该平台简化了历史数据检索，并实现了建筑信息的安全离线集成，提高了管理效率。

Conclusion: 开发的平台通过Brick本体和图结构技术，为建筑信息管理提供了半自动化和安全的解决方案。

Abstract: In the digital twin and building information era, many building automation
companies searched for scalable methods to extract and analyze different
building data, including Internet of Things (IoT) sensors, actuators, layout
sections, zones, etc. The necessity for engineers to continuously manage the
entire process for each new building creates scalability challenges.
Furthermore, because construction information is sensitive, transferring data
on vendor platforms via the cloud creates problems. This paper introduces a
platform designed to address some of the common challenges in building
automation. This is a smart platform designed for the transformation of
building information into Brick ontology (Brick 2020) and graph formats. This
technology makes it easy to retrieve historical data and converts the building
point list into a Brick schema model for use in digital twin applications. The
overarching goal of the proposed platform development is semi-automate the
process while offering adaptability to various building configurations. This
platform uses Brick schema and graph data structure techniques to minimize
complexity, offering a semi-automated approach through its use of a tree-based
graph structure. Moreover, the integration of Brick ontology creates a common
language for interoperability and improves building information management. The
seamless and offline integration of historical data within the developed
platform minimizes data security risks when handling building information.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [109] [StereoAdapter: Adapting Stereo Depth Estimation to Underwater Scenes](https://arxiv.org/abs/2509.16415)
*Zhengri Wu,Yiran Wang,Yu Wen,Zeyu Zhang,Biao Wu,Hao Tang*

Main category: cs.CV

TL;DR: StereoAdapter是一种参数高效的自监督框架，解决了水下立体深度估计中的适应性和融合挑战，实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在水下立体深度估计中面临两大挑战：高效适应大型视觉基础编码器和融合单目与立体信息。

Method: 提出StereoAdapter框架，结合LoRA适应单目编码器和循环立体细化模块，引入动态LoRA适应和合成数据集预训练。

Result: 在TartanAir和SQUID上的性能分别提升6.11%和5.12%，并在真实机器人实验中表现出鲁棒性。

Conclusion: StereoAdapter通过高效适应和融合方法，显著提升了水下立体深度估计的性能和鲁棒性。

Abstract: Underwater stereo depth estimation provides accurate 3D geometry for robotics
tasks such as navigation, inspection, and mapping, offering metric depth from
low-cost passive cameras while avoiding the scale ambiguity of monocular
methods. However, existing approaches face two critical challenges: (i)
parameter-efficiently adapting large vision foundation encoders to the
underwater domain without extensive labeled data, and (ii) tightly fusing
globally coherent but scale-ambiguous monocular priors with locally metric yet
photometrically fragile stereo correspondences. To address these challenges, we
propose StereoAdapter, a parameter-efficient self-supervised framework that
integrates a LoRA-adapted monocular foundation encoder with a recurrent stereo
refinement module. We further introduce dynamic LoRA adaptation for efficient
rank selection and pre-training on the synthetic UW-StereoDepth-40K dataset to
enhance robustness under diverse underwater conditions. Comprehensive
evaluations on both simulated and real-world benchmarks show improvements of
6.11% on TartanAir and 5.12% on SQUID compared to state-of-the-art methods,
while real-world deployment with the BlueROV2 robot further demonstrates the
consistent robustness of our approach. Code:
https://github.com/AIGeeksGroup/StereoAdapter. Website:
https://aigeeksgroup.github.io/StereoAdapter.

</details>


### [110] [ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting](https://arxiv.org/abs/2509.16552)
*Xiaoyang Yan,Muleilan Pei,Shaojie Shen*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的空间-时间高斯泼溅（ST-GS）框架，用于提升自动驾驶场景中3D占位预测的空间和时间建模能力，实验表明其在性能和时间一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D语义高斯方法在多视角空间交互和多帧时间一致性上表现不足，限制了自动驾驶场景理解的全面性。

Method: 通过双模式注意力机制的空间聚合策略增强高斯表示的空间交互，同时引入几何感知的时间融合方案以利用历史上下文改善场景完成的时间连续性。

Result: 在大规模nuScenes占位预测基准测试中，该方法不仅达到了最先进的性能，还在时间一致性上显著优于现有高斯方法。

Conclusion: ST-GS框架有效解决了现有方法的局限性，为自动驾驶的场景理解提供了更优的解决方案。

Abstract: 3D occupancy prediction is critical for comprehensive scene understanding in
vision-centric autonomous driving. Recent advances have explored utilizing 3D
semantic Gaussians to model occupancy while reducing computational overhead,
but they remain constrained by insufficient multi-view spatial interaction and
limited multi-frame temporal consistency. To overcome these issues, in this
paper, we propose a novel Spatial-Temporal Gaussian Splatting (ST-GS) framework
to enhance both spatial and temporal modeling in existing Gaussian-based
pipelines. Specifically, we develop a guidance-informed spatial aggregation
strategy within a dual-mode attention mechanism to strengthen spatial
interaction in Gaussian representations. Furthermore, we introduce a
geometry-aware temporal fusion scheme that effectively leverages historical
context to improve temporal continuity in scene completion. Extensive
experiments on the large-scale nuScenes occupancy prediction benchmark showcase
that our proposed approach not only achieves state-of-the-art performance but
also delivers markedly better temporal consistency compared to existing
Gaussian-based methods.

</details>


### [111] [SQS: Enhancing Sparse Perception Models via Query-based Splatting in Autonomous Driving](https://arxiv.org/abs/2509.16588)
*Haiming Zhang,Yiyao Zhu,Wending Zhou,Xu Yan,Yingjie Cai,Bingbing Liu,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: SQS是一种新型的查询驱动的稀疏感知模型预训练方法，通过自监督的splatting技术提升自动驾驶中的3D感知任务性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏感知模型（SPMs）在计算效率和推理速度上表现出色，但需要进一步优化以适应自动驾驶中的多样化任务需求。

Method: SQS在预训练阶段预测3D高斯表示，并通过多视图图像和深度图的自监督重建学习细粒度特征；在微调阶段通过查询交互机制与下游任务结合。

Result: 实验表明，SQS在3D占有率预测和物体检测任务上显著优于现有方法（占有率预测提升1.3 mIoU，3D检测提升1.0 NDS）。

Conclusion: SQS为稀疏感知模型提供了一种高效的预训练方法，显著提升了自动驾驶中多任务3D感知的性能。

Abstract: Sparse Perception Models (SPMs) adopt a query-driven paradigm that forgoes
explicit dense BEV or volumetric construction, enabling highly efficient
computation and accelerated inference. In this paper, we introduce SQS, a novel
query-based splatting pre-training specifically designed to advance SPMs in
autonomous driving. SQS introduces a plug-in module that predicts 3D Gaussian
representations from sparse queries during pre-training, leveraging
self-supervised splatting to learn fine-grained contextual features through the
reconstruction of multi-view images and depth maps. During fine-tuning, the
pre-trained Gaussian queries are seamlessly integrated into downstream networks
via query interaction mechanisms that explicitly connect pre-trained queries
with task-specific queries, effectively accommodating the diverse requirements
of occupancy prediction and 3D object detection. Extensive experiments on
autonomous driving benchmarks demonstrate that SQS delivers considerable
performance gains across multiple query-based 3D perception tasks, notably in
occupancy prediction and 3D object detection, outperforming prior
state-of-the-art pre-training approaches by a significant margin (i.e., +1.3
mIoU on occupancy prediction and +1.0 NDS on 3D detection).

</details>


### [112] [Segment-to-Act: Label-Noise-Robust Action-Prompted Video Segmentation Towards Embodied Intelligence](https://arxiv.org/abs/2509.16677)
*Wenxin Li,Kunyu Peng,Di Wen,Ruiping Liu,Mengfei Duan,Kai Luo,Kailun Yang*

Main category: cs.CV

TL;DR: 这篇论文首次研究了基于动作的视频对象分割任务中的标签噪声问题，提出了两种噪声类型（文本提示噪声和掩码标注噪声），并建立了首个基准ActiSeg-NL。通过分析噪声对模型的影响并引入并行掩码头机制（PMHM），论文展示了不同学习策略的鲁棒性差异。


<details>
  <summary>Details</summary>
Motivation: 基于动作的视频对象分割任务依赖大规模标注和提示，但这些标注常因噪声（如不精确的掩码或文本歧义）而影响模型性能。目前这一挑战尚未被系统研究，因此论文旨在填补这一空白。

Method: 论文首先定义了文本提示噪声和掩码标注噪声两种类型，并构建了ActiSeg-NL基准。随后，论文将六种标签噪声学习策略应用于此任务，并引入并行掩码头机制（PMHM）以应对掩码噪声。

Result: 实验表明，不同学习策略对噪声的鲁棒性各异，部分策略在平衡性能上表现更好，而另一些则以牺牲背景精度为代价提升前景准确性。PMHM有效缓解了掩码噪声的影响。

Conclusion: 论文为基于动作的视频对象分割任务中的标签噪声问题提供了系统性研究框架，并验证了PMHM的有效性。基准和代码将公开，为后续研究奠定了基础。

Abstract: Embodied intelligence relies on accurately segmenting objects actively
involved in interactions. Action-based video object segmentation addresses this
by linking segmentation with action semantics, but it depends on large-scale
annotations and prompts that are costly, inconsistent, and prone to multimodal
noise such as imprecise masks and referential ambiguity. To date, this
challenge remains unexplored. In this work, we take the first step by studying
action-based video object segmentation under label noise, focusing on two
sources: textual prompt noise (category flips and within-category noun
substitutions) and mask annotation noise (perturbed object boundaries to mimic
imprecise supervision). Our contributions are threefold. First, we introduce
two types of label noises for the action-based video object segmentation task.
Second, we build up the first action-based video object segmentation under a
label noise benchmark ActiSeg-NL and adapt six label-noise learning strategies
to this setting, and establish protocols for evaluating them under textual,
boundary, and mixed noise. Third, we provide a comprehensive analysis linking
noise types to failure modes and robustness gains, and we introduce a Parallel
Mask Head Mechanism (PMHM) to address mask annotation noise. Qualitative
evaluations further reveal characteristic failure modes, including boundary
leakage and mislocalization under boundary perturbations, as well as occasional
identity substitutions under textual flips. Our comparative analysis reveals
that different learning strategies exhibit distinct robustness profiles,
governed by a foreground-background trade-off where some achieve balanced
performance while others prioritize foreground accuracy at the cost of
background precision. The established benchmark and source code will be made
publicly available at https://github.com/mylwx/ActiSeg-NL.

</details>


### [113] [Text-Scene: A Scene-to-Language Parsing Framework for 3D Scene Understanding](https://arxiv.org/abs/2509.16721)
*Haoyuan Li,Rui Liu,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: 本文提出Text-Scene框架，通过自动将3D场景解析为文本描述来解决3D场景理解与交互的挑战，结合几何分析和MLLMs生成准确、详细且易于理解的描述。实验证明其有效性，并推出InPlan3D基准测试。


<details>
  <summary>Details</summary>
Motivation: 解决3D场景理解中的挑战，如丰富的空间关系和缺少大规模3D视觉语言数据集。

Method: Text-Scene框架结合几何分析和MLLMs，自动生成3D场景的文本描述。

Result: 实验证明生成的描述能准确表示3D场景并支持下游任务。

Conclusion: Text-Scene为3D场景理解提供了有效的语言描述工具，并推动了相关基准测试的发展。

Abstract: Enabling agents to understand and interact with complex 3D scenes is a
fundamental challenge for embodied artificial intelligence systems. While
Multimodal Large Language Models (MLLMs) have achieved significant progress in
2D image understanding, extending such capabilities to 3D scenes remains
difficult: 1) 3D environment involves richer concepts such as spatial
relationships, affordances, physics, layout, and so on, 2) the absence of
large-scale 3D vision-language datasets has posed a significant obstacle. In
this paper, we introduce Text-Scene, a framework that automatically parses 3D
scenes into textual descriptions for scene understanding. Given a 3D scene, our
model identifies object attributes and spatial relationships, and then
generates a coherent summary of the whole scene, bridging the gap between 3D
observation and language without requiring human-in-the-loop intervention. By
leveraging both geometric analysis and MLLMs, Text-Scene produces descriptions
that are accurate, detailed, and human-interpretable, capturing object-level
details and global-level context. Experimental results on benchmarks
demonstrate that our textual parses can faithfully represent 3D scenes and
benefit downstream tasks. To evaluate the reasoning capability of MLLMs, we
present InPlan3D, a comprehensive benchmark for 3D task planning, consisting of
3174 long-term planning tasks across 636 indoor scenes. We emphasize clarity
and accessibility in our approach, aiming to make 3D scene content
understandable through language. Code and datasets will be released.

</details>


### [114] [L2M-Reg: Building-level Uncertainty-aware Registration of Outdoor LiDAR Point Clouds and Semantic 3D City Models](https://arxiv.org/abs/2509.16832)
*Ziyang Xu,Benedikt Schwab,Yihui Yang,Thomas H. Kolbe,Christoph Holst*

Main category: cs.CV

TL;DR: 论文提出了一种名为L2M-Reg的基于平面的精细配准方法，用于解决LiDAR点云与语义3D城市模型在建筑物级别配准的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决LiDAR与语义3D城市模型在建筑物级别配准时由于模型不确定性带来的挑战。

Method: L2M-Reg通过三个关键步骤实现配准：建立可靠的平面对应关系、构建伪平面约束的高斯-赫尔默特模型以及自适应估计垂直平移。

Result: 在三个真实数据集上的实验表明，L2M-Reg比现有的基于ICP和平面的方法更精确且计算效率更高。

Conclusion: L2M-Reg为存在模型不确定性的LiDAR到模型配准提供了一种新颖的建筑物级别解决方案。

Abstract: Accurate registration between LiDAR (Light Detection and Ranging) point
clouds and semantic 3D city models is a fundamental topic in urban digital
twinning and a prerequisite for downstream tasks, such as digital construction,
change detection and model refinement. However, achieving accurate
LiDAR-to-Model registration at individual building level remains challenging,
particularly due to the generalization uncertainty in semantic 3D city models
at the Level of Detail 2 (LoD2). This paper addresses this gap by proposing
L2M-Reg, a plane-based fine registration method that explicitly accounts for
model uncertainty. L2M-Reg consists of three key steps: establishing reliable
plane correspondence, building a pseudo-plane-constrained Gauss-Helmert model,
and adaptively estimating vertical translation. Experiments on three real-world
datasets demonstrate that L2M-Reg is both more accurate and computationally
efficient than existing ICP-based and plane-based methods. Overall, L2M-Reg
provides a novel building-level solution regarding LiDAR-to-Model registration
when model uncertainty is present.

</details>


### [115] [SLAM-Former: Putting SLAM into One Transformer](https://arxiv.org/abs/2509.16909)
*Yijun Yuan,Zhuoguang Chen,Kenan Li,Weibang Wang,Hang Zhao*

Main category: cs.CV

TL;DR: SLAM-Former是一种新型的神经方法，通过单一Transformer整合了完整的SLAM功能，包括前端和后端协同工作，实现了实时建图和全局优化。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM系统通常需要复杂的多模块设计，SLAM-Former旨在通过单一Transformer简化这一过程，同时提升性能。

Method: SLAM-Former分为前端和后端：前端实时处理单目图像进行增量建图和跟踪，后端进行全局优化以保持几何一致性。两者交替执行以相互促进。

Result: 实验表明，SLAM-Former在性能上优于或与现有密集SLAM方法竞争。

Conclusion: SLAM-Former通过单一Transformer实现了高效且高性能的SLAM功能，展现了神经方法在SLAM领域的潜力。

Abstract: We present SLAM-Former, a novel neural approach that integrates full SLAM
capabilities into a single transformer. Similar to traditional SLAM systems,
SLAM-Former comprises both a frontend and a backend that operate in tandem. The
frontend processes sequential monocular images in real-time for incremental
mapping and tracking, while the backend performs global refinement to ensure a
geometrically consistent result. This alternating execution allows the frontend
and backend to mutually promote one another, enhancing overall system
performance. Comprehensive experimental results demonstrate that SLAM-Former
achieves superior or highly competitive performance compared to
state-of-the-art dense SLAM methods.

</details>


### [116] [CoBEVMoE: Heterogeneity-aware Feature Fusion with Dynamic Mixture-of-Experts for Collaborative Perception](https://arxiv.org/abs/2509.17107)
*Lingzhao Kong,Jiacheng Lin,Siyu Li,Kai Luo,Zhiyong Li,Kailun Yang*

Main category: cs.CV

TL;DR: CoBEVMoE提出了一种新的多智能体协作感知框架，通过动态混合专家（DMoE）架构在BEV空间中建模异构特征，显著提升了感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有中间融合方法忽略了智能体间的感知多样性，限制了协作感知的效果。

Method: 采用BEV空间和DMoE架构，动态生成专家以提取异构特征，并引入DEML损失增强专家多样性。

Result: 在OPV2V和DAIR-V2X-C数据集上的实验表明，IoU提升1.5%，AP@50提升3.0%。

Conclusion: CoBEVMoE验证了异构特征建模在多智能体协作感知中的有效性。

Abstract: Collaborative perception aims to extend sensing coverage and improve
perception accuracy by sharing information among multiple agents. However, due
to differences in viewpoints and spatial positions, agents often acquire
heterogeneous observations. Existing intermediate fusion methods primarily
focus on aligning similar features, often overlooking the perceptual diversity
among agents. To address this limitation, we propose CoBEVMoE, a novel
collaborative perception framework that operates in the Bird's Eye View (BEV)
space and incorporates a Dynamic Mixture-of-Experts (DMoE) architecture. In
DMoE, each expert is dynamically generated based on the input features of a
specific agent, enabling it to extract distinctive and reliable cues while
attending to shared semantics. This design allows the fusion process to
explicitly model both feature similarity and heterogeneity across agents.
Furthermore, we introduce a Dynamic Expert Metric Loss (DEML) to enhance
inter-expert diversity and improve the discriminability of the fused
representation. Extensive experiments on the OPV2V and DAIR-V2X-C datasets
demonstrate that CoBEVMoE achieves state-of-the-art performance. Specifically,
it improves the IoU for Camera-based BEV segmentation by +1.5% on OPV2V and the
AP@50 for LiDAR-based 3D object detection by +3.0% on DAIR-V2X-C, verifying the
effectiveness of expert-based heterogeneous feature modeling in multi-agent
collaborative perception. The source code will be made publicly available at
https://github.com/godk0509/CoBEVMoE.

</details>


### [117] [DepTR-MOT: Unveiling the Potential of Depth-Informed Trajectory Refinement for Multi-Object Tracking](https://arxiv.org/abs/2509.17323)
*Buyin Deng,Lingxin Huang,Kai Luo,Fei Teng,Kailun Yang*

Main category: cs.CV

TL;DR: 论文介绍了DepTR-MOT，一种基于DETR的视觉多目标跟踪方法，通过引入深度信息改进轨迹精度，有效解决遮挡和近距离交互问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D线索的跟踪方法在机器人物密集和频繁遮挡的环境中不可靠，而深度信息的潜力未被充分挖掘。

Method: 提出DepTR-MOT，结合实例级深度标签监督和密集深度图提取，无需额外计算成本即可输出实例级深度。

Result: 在QuadTrack和DanceTrack数据集上分别取得27.59和44.47的HOTA分数，尤其在机器人平台上表现优异。

Conclusion: 深度信息显著提升了跟踪鲁棒性，未来将公开源代码以供社区使用。

Abstract: Visual Multi-Object Tracking (MOT) is a crucial component of robotic
perception, yet existing Tracking-By-Detection (TBD) methods often rely on 2D
cues, such as bounding boxes and motion modeling, which struggle under
occlusions and close-proximity interactions. Trackers relying on these 2D cues
are particularly unreliable in robotic environments, where dense targets and
frequent occlusions are common. While depth information has the potential to
alleviate these issues, most existing MOT datasets lack depth annotations,
leading to its underexploited role in the domain. To unveil the potential of
depth-informed trajectory refinement, we introduce DepTR-MOT, a DETR-based
detector enhanced with instance-level depth information. Specifically, we
propose two key innovations: (i) foundation model-based instance-level soft
depth label supervision, which refines depth prediction, and (ii) the
distillation of dense depth maps to maintain global depth consistency. These
strategies enable DepTR-MOT to output instance-level depth during inference,
without requiring foundation models and without additional computational cost.
By incorporating depth cues, our method enhances the robustness of the TBD
paradigm, effectively resolving occlusion and close-proximity challenges.
Experiments on both the QuadTrack and DanceTrack datasets demonstrate the
effectiveness of our approach, achieving HOTA scores of 27.59 and 44.47,
respectively. In particular, results on QuadTrack, a robotic platform MOT
dataset, highlight the advantages of our method in handling occlusion and
close-proximity challenges in robotic tracking. The source code will be made
publicly available at https://github.com/warriordby/DepTR-MOT.

</details>


### [118] [EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device](https://arxiv.org/abs/2509.17430)
*Gunjan Chhablani,Xiaomeng Ye,Muhammad Zubair Irshad,Zsolt Kira*

Main category: cs.CV

TL;DR: 论文介绍了一种名为EmbodiedSplat的新方法，通过利用3D高斯泼溅（GS）技术和Habitat-Sim模拟器，实现了在真实场景重建中高效训练策略，显著提升了模拟到现实的转换效果。


<details>
  <summary>Details</summary>
Motivation: 当前Embodied AI的训练和评估依赖于仿真环境，但现有的合成环境缺乏真实感或需要昂贵设备捕获的高保真重建，导致模拟到现实的转换仍具挑战性。

Method: EmbodiedSplat结合3D高斯泼溅技术和Habitat-Sim模拟器，利用iPhone捕获的场景重建网格，在近似真实世界的环境中训练策略。

Result: 实验表明，使用EmbodiedSplat微调的智能体在真实世界的图像导航任务中超越了基于大规模真实数据集（HM3D）和合成数据集（HSSD）的基线方法，成功率分别提升了20%和40%。

Conclusion: EmbodiedSplat通过高效的场景重建和策略微调，显著提升了模拟到现实的预测能力，适用于多样化环境。

Abstract: The field of Embodied AI predominantly relies on simulation for training and
evaluation, often using either fully synthetic environments that lack
photorealism or high-fidelity real-world reconstructions captured with
expensive hardware. As a result, sim-to-real transfer remains a major
challenge. In this paper, we introduce EmbodiedSplat, a novel approach that
personalizes policy training by efficiently capturing the deployment
environment and fine-tuning policies within the reconstructed scenes. Our
method leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to
bridge the gap between realistic scene capture and effective training
environments. Using iPhone-captured deployment scenes, we reconstruct meshes
via GS, enabling training in settings that closely approximate real-world
conditions. We conduct a comprehensive analysis of training strategies,
pre-training datasets, and mesh reconstruction techniques, evaluating their
impact on sim-to-real predictivity in real-world scenarios. Experimental
results demonstrate that agents fine-tuned with EmbodiedSplat outperform both
zero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and
synthetically generated datasets (HSSD), achieving absolute success rate
improvements of 20\% and 40\% on real-world Image Navigation task. Moreover,
our approach yields a high sim-vs-real correlation (0.87--0.97) for the
reconstructed meshes, underscoring its effectiveness in adapting policies to
diverse environments with minimal effort. Project page:
https://gchhablani.github.io/embodied-splat

</details>


### [119] [VideoArtGS: Building Digital Twins of Articulated Objects from Monocular Video](https://arxiv.org/abs/2509.17647)
*Yu Liu,Baoxiong Jia,Ruijie Lu,Chuyue Gan,Huayu Chen,Junfeng Ni,Song-Chun Zhu,Siyuan Huang*

Main category: cs.CV

TL;DR: 本文提出VideoArtGS方法，通过单目视频重建高质量的数字孪生体，结合运动先验指导和混合中心网格部件分配模块，显著提升了关节和网格重建性能。


<details>
  <summary>Details</summary>
Motivation: 从单目视频中构建关节物体的数字孪生体是计算机视觉中的关键挑战，但现有方法难以从有限的视角输入中准确解耦物体几何与部件动态。

Method: 提出VideoArtGS方法，包括运动先验指导流程和混合中心网格部件分配模块，优化关节参数初始化和部件运动捕捉。

Result: 实验结果显示，VideoArtGS在关节和网格重建上的性能大幅超越现有方法，重建误差降低约两个数量级。

Conclusion: VideoArtGS为基于视频的关节物体重建设定了新标准，并实现了从单目视频中创建实用数字孪生体的突破。

Abstract: Building digital twins of articulated objects from monocular video presents
an essential challenge in computer vision, which requires simultaneous
reconstruction of object geometry, part segmentation, and articulation
parameters from limited viewpoint inputs. Monocular video offers an attractive
input format due to its simplicity and scalability; however, it's challenging
to disentangle the object geometry and part dynamics with visual supervision
alone, as the joint movement of the camera and parts leads to ill-posed
estimation. While motion priors from pre-trained tracking models can alleviate
the issue, how to effectively integrate them for articulation learning remains
largely unexplored. To address this problem, we introduce VideoArtGS, a novel
approach that reconstructs high-fidelity digital twins of articulated objects
from monocular video. We propose a motion prior guidance pipeline that analyzes
3D tracks, filters noise, and provides reliable initialization of articulation
parameters. We also design a hybrid center-grid part assignment module for
articulation-based deformation fields that captures accurate part motion.
VideoArtGS demonstrates state-of-the-art performance in articulation and mesh
reconstruction, reducing the reconstruction error by about two orders of
magnitude compared to existing methods. VideoArtGS enables practical digital
twin creation from monocular video, establishing a new benchmark for
video-based articulated object reconstruction. Our work is made publicly
available at: https://videoartgs.github.io.

</details>


### [120] [DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning](https://arxiv.org/abs/2509.17684)
*ThankGod Egbe,Peng Wang,Zhihao Guo,Zidong Chen*

Main category: cs.CV

TL;DR: 论文评估了自监督视觉骨干DINOv3在机器人操作中的视觉运动扩散策略学习中的表现，发现其在某些任务中优于传统的监督预训练骨干ResNet-18。


<details>
  <summary>Details</summary>
Motivation: 研究自监督视觉模型是否能作为机器人操作中有效的感知前端，替代传统的监督预训练方法。

Method: 在四种基准任务（Push-T, Lift, Can, Square）中，比较了DINOv3和ResNet-18在从头训练、冻结和微调三种模式下的表现。

Result: (i) 微调后的DINOv3在部分任务中表现优于ResNet-18；(ii) 冻结的DINOv3仍然具有竞争力；(iii) 自监督特征提高了样本效率和鲁棒性。

Conclusion: 自监督大规模视觉模型是机器人操作中高效且通用的感知前端，值得进一步探索无标签预训练的潜力。

Abstract: This paper evaluates DINOv3, a recent large-scale self-supervised vision
backbone, for visuomotor diffusion policy learning in robotic manipulation. We
investigate whether a purely self-supervised encoder can match or surpass
conventional supervised ImageNet-pretrained backbones (e.g., ResNet-18) under
three regimes: training from scratch, frozen, and finetuned. Across four
benchmark tasks (Push-T, Lift, Can, Square) using a unified FiLM-conditioned
diffusion policy, we find that (i) finetuned DINOv3 matches or exceeds
ResNet-18 on several tasks, (ii) frozen DINOv3 remains competitive, indicating
strong transferable priors, and (iii) self-supervised features improve sample
efficiency and robustness. These results support self-supervised large visual
models as effective, generalizable perceptual front-ends for action diffusion
policies, motivating further exploration of scalable label-free pretraining in
robotic manipulation. Compared to using ResNet18 as a backbone, our approach
with DINOv3 achieves up to a 10% absolute increase in test-time success rates
on challenging tasks such as Can, and on-the-par performance in tasks like
Lift, PushT, and Square.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [121] [Toward Engineering AGI: Benchmarking the Engineering Design Capabilities of LLMs](https://arxiv.org/abs/2509.16204)
*Xingang Guo,Yaxin Li,Xiangyi Kong,Yilan Jiang,Xiayu Zhao,Zhihua Gong,Yufan Zhang,Daixuan Li,Tianle Sang,Beixiao Zhu,Gregory Jun,Yingbing Huang,Yiqi Liu,Yuqi Xue,Rahul Dev Kundu,Qi Jian Lim,Yizhou Zhao,Luke Alexander Granger,Mohamed Badr Younis,Darioush Keivan,Nippun Sabharwal,Shreyanka Sinha,Prakhar Agarwal,Kojo Vandyck,Hanlin Mai,Zichen Wang,Aditya Venkatesh,Ayush Barik,Jiankun Yang,Chongying Yue,Jingjie He,Libin Wang,Licheng Xu,Hao Chen,Jinwen Wang,Liujun Xu,Rushabh Shetty,Ziheng Guo,Dahui Song,Manvi Jha,Weijie Liang,Weiman Yan,Bryan Zhang,Sahil Bhandary Karnoor,Jialiang Zhang,Rutva Pandya,Xinyi Gong,Mithesh Ballae Ganesh,Feize Shi,Ruiling Xu,Yifan Zhang,Yanfeng Ouyang,Lianhui Qin,Elyse Rosenbaum,Corey Snyder,Peter Seiler,Geir Dullerud,Xiaojia Shelly Zhang,Zuofu Cheng,Pavan Kumar Hanumolu,Jian Huang,Mayank Kulkarni,Mahdi Namazifar,Huan Zhang,Bin Hu*

Main category: cs.CE

TL;DR: 该研究介绍了ENGDESIGN，一个评估大型语言模型（LLMs）在工程设计任务中能力的多领域基准测试。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏能够评估LLMs在实际工程设计任务中能力的基准测试，特别是涉及领域知识综合和多维度约束下的推理能力。

Method: 研究团队设计了涵盖九个工程领域的任务，每个任务模拟真实设计问题，并通过仿真测试评估LLM生成的设计。

Result: ENGDESIGN首次为评估LLMs在工程设计的综合能力提供了标准化工具，强调了仿真验证的重要性。

Conclusion: 该基准填补了现有测试的空白，为未来开发更强大的AI工程师提供了评估框架。

Abstract: Today, industry pioneers dream of developing general-purpose AI engineers
capable of designing and building humanity's most ambitious projects--from
starships that will carry us to distant worlds to Dyson spheres that harness
stellar energy. Yet engineering design represents a fundamentally different
challenge for large language models (LLMs) compared to traditional
textbook-style problem solving or factual question answering. Real-world
engineering design demands the synthesis of domain knowledge, navigation of
complex trade-offs, and management of the tedious processes that consume much
of practicing engineers' time. Despite these shared challenges across
engineering disciplines, no benchmark currently captures the unique demands of
engineering design work. In this work, we introduce ENGDESIGN, an Engineering
Design benchmark that evaluates LLMs' abilities to perform practical design
tasks across nine engineering domains: Operating System Design, Computer
Architecture Design, Control System Design, Mechanical Systems, Structural
Design, Digital Hardware Design, Analog Integrated Circuit Design, Robotics,
and Signal Processing. Unlike existing benchmarks that focus on factual recall
or question answering, ENGDESIGN uniquely emphasizes LLMs' ability to
synthesize domain knowledge, reason under constraints, and generate functional,
objective-oriented designs. Each task in ENGDESIGN represents a real-world
engineering design problem, accompanied by a detailed task description
specifying design goals, constraints, and performance requirements. We pioneer
a simulation-based evaluation paradigm where LLM-generated designs undergo
rigorous testing through executable, domain-specific simulations-from circuit
SPICE simulations to structural finite element analysis, from control system
validation to robotic motion planning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [122] [Learned Digital Codes for Over-the-Air Federated Learning](https://arxiv.org/abs/2509.16577)
*Antonio Tarizzo,Mohammad Kazemi,Deniz Gündüz*

Main category: cs.LG

TL;DR: 提出了一个基于学习的数字OTA框架，用于联邦边缘学习（FEEL），在低信噪比条件下扩展可靠操作，且不增加上行链路开销。


<details>
  <summary>Details</summary>
Motivation: 现有的数字OTA方法难以同时实现强收敛性和抗噪能力，限制了在低信噪比环境（如物联网设备）中的性能。

Method: 结合展开解码器和联合学习的无源随机访问码本，提出了一种学习型数字OTA框架。

Result: 结果表明，该方法将可靠操作范围扩展了7 dB以上，并在所有信噪比水平上改善了全局模型收敛性。

Conclusion: 基于学习的设计在FEEL中具有潜力，能够提升低信噪比环境下的性能。

Abstract: Federated edge learning (FEEL) enables distributed model training across
wireless devices without centralising raw data, but deployment is constrained
by the wireless uplink. A promising direction is over-the-air (OTA)
aggregation, which merges communication with computation. Existing digital OTA
methods can achieve either strong convergence or robustness to noise, but
struggle to achieve both simultaneously, limiting performance in low
signal-to-noise ratios (SNRs) where many IoT devices operate. This work
proposes a learnt digital OTA framework that extends reliable operation into
low-SNR conditions while maintaining the same uplink overhead as
state-of-the-art. The proposed method combines an unrolled decoder with a
jointly learnt unsourced random access codebook. Results show an extension of
reliable operation by more than 7 dB, with improved global model convergence
across all SNR levels, highlighting the potential of learning-based design for
FEEL.

</details>


### [123] [Discrete Diffusion Models: Novel Analysis and New Sampler Guarantees](https://arxiv.org/abs/2509.16756)
*Yuchen Liang,Yingbin Liang,Lifeng Lai,Ness Shroff*

Main category: cs.LG

TL;DR: 本文提出了一种新的分析方法，用于离散扩散模型，消除了传统$	au$-leaping采样器理论分析中的限制性假设，并改进了收敛界，使其与词汇量线性相关。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在自然语言和图数据应用中表现出色，但现有理论分析依赖严格假设且收敛界不理想，本文旨在解决这些问题。

Method: 通过引入基于微分不等式的新技术，分析$	au$-leaping、Euler方法和Tweedie $	au$-leaping等采样器的收敛性。

Result: 成功将$	au$-leaping采样器的KL散度收敛界从词汇量的二次依赖改进为线性依赖，并首次为其他常用采样器提供收敛保证。

Conclusion: 新方法不仅简化了理论分析，还提升了适用性，对更广泛的随机过程分析可能有独立价值。

Abstract: Discrete diffusion models have recently gained significant prominence in
applications involving natural language and graph data. A key factor
influencing their effectiveness is the efficiency of discretized samplers.
Among these, $\tau$-leaping samplers have become particularly popular due to
their empirical success. However, existing theoretical analyses of
$\tau$-leaping often rely on somewhat restrictive and difficult-to-verify
regularity assumptions, and their convergence bounds contain quadratic
dependence on the vocabulary size. In this work, we introduce a new analytical
approach for discrete diffusion models that removes the need for such
assumptions. For the standard $\tau$-leaping method, we establish convergence
guarantees in KL divergence that scale linearly with vocabulary size, improving
upon prior results with quadratic dependence. Our approach is also more broadly
applicable: it provides the first convergence guarantees for other widely used
samplers, including the Euler method and Tweedie $\tau$-leaping. Central to our
approach is a novel technique based on differential inequalities, offering a
more flexible alternative to the traditional Girsanov change-of-measure
methods. This technique may also be of independent interest for the analysis of
other stochastic processes.

</details>


### [124] [SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing](https://arxiv.org/abs/2509.17197)
*Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang*

Main category: cs.LG

TL;DR: SignalLLM是一种基于大型语言模型（LLM）的通用信号处理框架，通过模块化设计和自适应检索增强生成（RAG）技术，解决了传统信号处理方法在复杂工作流程和有限数据下的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统信号处理方法依赖专家知识和手动工程，泛化能力有限；而LLM具有推理能力和多模态迁移能力，适合自动化信号处理任务。

Method: SignalLLM通过分解高层目标为结构化子任务，结合RAG和分层规划，采用多模态推理、代码合成等方式执行任务。

Result: 在雷达目标检测、人类活动识别等任务中，SignalLLM在少样本和零样本场景下优于传统和现有LLM方法。

Conclusion: SignalLLM展示了LLM在信号处理中的通用性和高效性，为自动化SP工作流程提供了新途径。

Abstract: Modern signal processing (SP) pipelines, whether model-based or data-driven,
often constrained by complex and fragmented workflow, rely heavily on expert
knowledge and manual engineering, and struggle with adaptability and
generalization under limited data. In contrast, Large Language Models (LLMs)
offer strong reasoning capabilities, broad general-purpose knowledge,
in-context learning, and cross-modal transfer abilities, positioning them as
powerful tools for automating and generalizing SP workflows. Motivated by these
potentials, we introduce SignalLLM, the first general-purpose LLM-based agent
framework for general SP tasks. Unlike prior LLM-based SP approaches that are
limited to narrow applications or tricky prompting, SignalLLM introduces a
principled, modular architecture. It decomposes high-level SP goals into
structured subtasks via in-context learning and domain-specific retrieval,
followed by hierarchical planning through adaptive retrieval-augmented
generation (RAG) and refinement; these subtasks are then executed through
prompt-based reasoning, cross-modal reasoning, code synthesis, model
invocation, or data-driven LLM-assisted modeling. Its generalizable design
enables the flexible selection of problem solving strategies across different
signal modalities, task types, and data conditions. We demonstrate the
versatility and effectiveness of SignalLLM through five representative tasks in
communication and sensing, such as radar target detection, human activity
recognition, and text compression. Experimental results show superior
performance over traditional and existing LLM-based methods, particularly in
few-shot and zero-shot settings.

</details>


### [125] [Graph Signal Generative Diffusion Models](https://arxiv.org/abs/2509.17250)
*Yigit Berkay Uslu,Samar Hadou,Sergio Rozada,Shirin Saeedi Bidokhti,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 该论文提出了一种U形编码器-解码器图神经网络（U-GNN），用于通过去噪扩散过程生成随机图信号，并将其应用于股票价格的概率预测。


<details>
  <summary>Details</summary>
Motivation: 传统的确定性预测方法难以捕捉股票价格中的不确定性和尾部事件，因此需要一种能够生成概率性预测的新方法。

Method: 论文采用了U形编码器-解码器架构，结合去噪扩散过程，通过学习不同分辨率的节点特征，并利用跳过连接和零填充池化操作来避免任意图粗化。

Result: 实验表明，U-GNN在股票价格的随机预测中表现有效，能够捕捉到不确定性和尾部事件。

Conclusion: U-GNN是一种有效的图信号生成和概率预测方法，尤其适用于需要处理不确定性和尾部事件的场景。

Abstract: We introduce U-shaped encoder-decoder graph neural networks (U-GNNs) for
stochastic graph signal generation using denoising diffusion processes. The
architecture learns node features at different resolutions with skip
connections between the encoder and decoder paths, analogous to the
convolutional U-Net for image generation. The U-GNN is prominent for a pooling
operation that leverages zero-padding and avoids arbitrary graph coarsening,
with graph convolutions layered on top to capture local dependencies. This
technique permits learning feature embeddings for sampled nodes at deeper
levels of the architecture that remain convolutional with respect to the
original graph. Applied to stock price prediction -- where deterministic
forecasts struggle to capture uncertainties and tail events that are paramount
-- we demonstrate the effectiveness of the diffusion model in probabilistic
forecasting of stock prices.

</details>


### [126] [Physics-Informed Operator Learning for Hemodynamic Modeling](https://arxiv.org/abs/2509.17293)
*Ryan Chappell,Chayan Banerjee,Kien Nguyen,Clinton Fookes*

Main category: cs.LG

TL;DR: 利用物理信息神经算子学习模型（PI-DeepONet）通过知识蒸馏简化心血管动态建模，保持性能的同时降低训练复杂度。


<details>
  <summary>Details</summary>
Motivation: 精确的心血管动态建模对无创监测和治疗规划至关重要，但现有物理信息神经网络（PINN）方法因复杂架构和训练限制难以扩展。

Method: 预训练PI-DeepONet学习穿戴设备波形到血压信号的映射，作为轻量级知识蒸馏的监督信号，简化模型训练。

Result: 实验表明，该方法性能与复杂基线相当（相关性0.766 vs. 0.770，RMSE 4.452 vs. 4.501），训练开销减少4%。

Conclusion: 算子监督可替代复杂训练策略，提供更可扩展且可解释的生理建模方法，降低实现负担。

Abstract: Accurate modeling of personalized cardiovascular dynamics is crucial for
non-invasive monitoring and therapy planning. State-of-the-art physics-informed
neural network (PINN) approaches employ deep, multi-branch architectures with
adversarial or contrastive objectives to enforce partial differential equation
constraints. While effective, these enhancements introduce significant training
and implementation complexity, limiting scalability and practical deployment.
We investigate physics-informed neural operator learning models as efficient
supervisory signals for training simplified architectures through knowledge
distillation. Our approach pre-trains a physics-informed DeepONet (PI-DeepONet)
on high-fidelity cuffless blood pressure recordings to learn operator mappings
from raw wearable waveforms to beat-to-beat pressure signals under embedded
physics constraints. This pre-trained operator serves as a frozen supervisor in
a lightweight knowledge-distillation pipeline, guiding streamlined base models
that eliminate complex adversarial and contrastive learning components while
maintaining performance. We characterize the role of physics-informed
regularization in operator learning and demonstrate its effectiveness for
supervisory guidance. Through extensive experiments, our operator-supervised
approach achieves performance parity with complex baselines (correlation: 0.766
vs. 0.770, RMSE: 4.452 vs. 4.501), while dramatically reducing architectural
complexity from eight critical hyperparameters to a single regularization
coefficient and decreasing training overhead by 4%. Our results demonstrate
that operator-based supervision effectively replaces intricate multi-component
training strategies, offering a more scalable and interpretable approach to
physiological modeling with reduced implementation burden.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [127] [Underground Multi-robot Systems at Work: a revolution in mining](https://arxiv.org/abs/2509.16267)
*Victor V. Puche,Kashish Verma,Matteo Fumagalli*

Main category: eess.SY

TL;DR: 论文提出了一种模块化多机器人系统，用于在危险的地下环境中自主执行矿物提取任务，通过局部行为控制和物理交互能力解决传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 全球对关键原材料（CRMs）的需求增长，促使开发能够适应危险和受限环境的机器人系统。

Method: 采用分层有限状态机（HFSM）行为控制，协调异构机器人平台完成复杂任务，支持机器人间的交互通信。

Result: 系统有效整合软硬件，实现多机器人在受限环境中的协作任务执行。

Conclusion: 提出的系统为危险环境下的矿物提取提供了一种高效、自主的解决方案。

Abstract: The growing global demand for critical raw materials (CRMs) has highlighted
the need to access difficult and hazardous environments such as abandoned
underground mines. These sites pose significant challenges for conventional
machinery and human operators due to confined spaces, structural instability,
and lack of infrastructure. To address this, we propose a modular multi-robot
system designed for autonomous operation in such environments, enabling
sequential mineral extraction tasks. Unlike existing work that focuses
primarily on mapping and inspection through global behavior or central control,
our approach incorporates physical interaction capabilities using specialized
robots coordinated through local high-level behavior control. Our proposed
system utilizes Hierarchical Finite State Machine (HFSM) behaviors to structure
complex task execution across heterogeneous robotic platforms. Each robot has
its own HFSM behavior to perform sequential autonomy while maintaining overall
system coordination, achieved by triggering behavior execution through
inter-robot communication. This architecture effectively integrates software
and hardware components to support collaborative, task-driven multi-robot
operation in confined underground environments.

</details>


### [128] [Servos for Local Map Exploration Onboard Nonholonomic Vehicles for Extremum Seeking](https://arxiv.org/abs/2509.16365)
*Dylan James-Kavanaugh,Patrick McNamee,Qixu Wang,Zahra Nili Ahmadabadi*

Main category: eess.SY

TL;DR: 该论文探讨了极值搜索控制中如何利用周期性或近似周期性扰动函数来估计多变量映射的任意阶导数，并通过实验验证了使用伺服驱动的传感器可以提高非完整车辆寻找源点的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统的极值搜索控制通常使用正弦扰动来估计导数，但其适用性有限。本研究旨在扩展扰动函数的范围，使其包括有界周期或近似周期函数，并解决多变量映射的高阶导数估计问题。

Method: 提出了一个必要且充分的条件，用于判断给定有界周期或近似周期信号下是否存在时变函数来估计多变量映射的任意阶导数。该方法通过伺服驱动的传感器在非完整车辆上进行源点搜索控制的实验验证。

Result: 仿真和实际实验表明，通过将局部地图探索任务分配给伺服驱动的传感器，非完整车辆能够更快地收敛到源点。

Conclusion: 该研究为极值搜索控制提供了更灵活的扰动函数选择，并在实际应用中验证了其有效性，特别适用于多变量映射和非完整系统的控制问题。

Abstract: Extremum seeking control (ESC) often employs perturbation-based estimates of
derivatives for some sensor field or cost function. These estimates are
generally obtained by simply multiplying the output of a single-unit sensor by
some time-varying function. Previous work has focused on sinusoidal
perturbations to generate derivative estimates with results for arbitrary order
derivatives of scalar maps or higher up to third-order derivatives of
multivariable maps. This work extends the perturbations from sinusoidal to
bounded periodic or almost periodic functions and considers multivariable maps.
A necessary and sufficient condition is given for determining if time-varying
functions exist for estimating arbitrary order derivatives of multivariable
maps for any given bounded periodic or almost periodic dither signal. These
results are then used in a source seeking controller for a nonholonomic vehicle
with a sensor actuated by servo. The conducted simulation and real-world
experiments demonstrate that by distributing the local map exploration to a
servo, the nonholonomic vehicle was able to achieve a faster convergence to the
source.

</details>


### [129] [Safe Guaranteed Dynamics Exploration with Probabilistic Models](https://arxiv.org/abs/2509.16650)
*Manish Prajapat,Johannes Köhler,Melanie N. Zeilinger,Andreas Krause*

Main category: eess.SY

TL;DR: 本文提出了一种悲观安全框架，通过乐观探索未知状态来确保动态模型的在线学习，同时保证高概率的安全操作，并在自动驾驶汽车和无人机导航等场景中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在系统动态未知的情况下，如何在确保安全的同时实现最优性能是实际部署智能体的关键挑战。

Method: 提出了一种悲观安全框架，通过乐观探索信息性状态来在线学习动态模型，同时确保安全操作。

Result: 该方法在有限时间内学习动态模型并确保高概率安全，无需重置，并在自动驾驶和无人机导航中验证了其有效性。

Conclusion: 该方法在未知动态系统中实现了安全高效的学习和性能优化，适用于安全关键场景。

Abstract: Ensuring both optimality and safety is critical for the real-world deployment
of agents, but becomes particularly challenging when the system dynamics are
unknown. To address this problem, we introduce a notion of maximum safe
dynamics learning via sufficient exploration in the space of safe policies. We
propose a $\textit{pessimistically}$ safe framework that
$\textit{optimistically}$ explores informative states and, despite not reaching
them due to model uncertainty, ensures continuous online learning of dynamics.
The framework achieves first-of-its-kind results: learning the dynamics model
sufficiently $-$ up to an arbitrary small tolerance (subject to noise) $-$ in a
finite time, while ensuring provably safe operation throughout with high
probability and without requiring resets. Building on this, we propose an
algorithm to maximize rewards while learning the dynamics $\textit{only to the
extent needed}$ to achieve close-to-optimal performance. Unlike typical
reinforcement learning (RL) methods, our approach operates online in a
non-episodic setting and ensures safety throughout the learning process. We
demonstrate the effectiveness of our approach in challenging domains such as
autonomous car racing and drone navigation under aerodynamic effects $-$
scenarios where safety is critical and accurate modeling is difficult.

</details>


### [130] [Delay compensation of multi-input distinct delay nonlinear systems via neural operators](https://arxiv.org/abs/2509.17131)
*Filip Bajraktari,Luke Bhan,Miroslav Krstic,Yuanyuan Shi*

Main category: eess.SY

TL;DR: 本文首次研究了多输入非线性系统中具有不同驱动延迟的近似预测器的稳定性问题，证明了在满足时间一致误差边界条件下可实现半全局实际稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究目的是解决多输入非线性系统中存在不同延迟时的预测器稳定性问题。

Method: 通过将延迟转化为传输PDE，并在ODE-PDE级联上进行分析，实现了对预测器稳定性的理论推导。

Result: 结果表明，若预测器近似满足时间一致的误差边界，则能在所需吸引区域和系统输入数量条件下实现半全局实际稳定性。

Conclusion: 通过神经网络算子验证了误差边界的可行性，为实际应用提供了理论支持。此外，实验展示了该方法在移动机器人中的有效性。

Abstract: In this work, we present the first stability results for approximate
predictors in multi-input non-linear systems with distinct actuation delays. We
show that if the predictor approximation satisfies a uniform (in time) error
bound, semi-global practical stability is correspondingly achieved. For such
approximators, the required uniform error bound depends on the desired region
of attraction and the number of control inputs in the system. The result is
achieved through transforming the delay into a transport PDE and conducting
analysis on the coupled ODE-PDE cascade. To highlight the viability of such
error bounds, we demonstrate our results on a class of approximators - neural
operators - showcasing sufficiency for satisfying such a universal bound both
theoretically and in simulation on a mobile robot experiment.

</details>


### [131] [Trajectory Encryption Cooperative Salvo Guidance](https://arxiv.org/abs/2509.17341)
*Lohitvel Gopikannan,Shashi Ranjan Kumar,Abhinav Sinha*

Main category: eess.SY

TL;DR: 论文提出了一种利用异构制导原理的轨迹加密方法，通过多样化的轨迹家族增强协同目标拦截的鲁棒性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 在无人机协同拦截目标的任务中，传统方法容易受到干扰且轨迹可预测性高，导致拦截意图暴露。本文旨在通过异构制导策略实现轨迹加密，从而提高隐蔽性和鲁棒性。

Method: 通过混合异构的时间到达（time-to-go）策略，设计了一种协同制导方法，使无人机群能够生成多样化的轨迹家族。

Result: 仿真结果表明，异构无人机群能够从多样化的初始配置中同时拦截移动目标，且轨迹不可预测性增强。

Conclusion: 异构制导策略通过轨迹加密有效提高了协同拦截的隐蔽性和鲁棒性，为无人机群任务设计提供了新思路。

Abstract: This paper introduces the concept of trajectory encryption in cooperative
simultaneous target interception, wherein heterogeneity in guidance principles
across a team of unmanned autonomous systems is leveraged as a strategic design
feature. By employing a mix of heterogeneous time-to-go formulations leading to
a cooperative guidance strategy, the swarm of vehicles is able to generate
diverse trajectory families. This diversity expands the feasible solution space
for simultaneous target interception, enhances robustness under disturbances,
and enables flexible time-to-go adjustments without predictable detouring. From
an adversarial perspective, heterogeneity obscures the collective interception
intent by preventing straightforward prediction of swarm dynamics, effectively
acting as an encryption layer in the trajectory domain. Simulations demonstrate
that the swarm of heterogeneous vehicles is able to intercept a moving target
simultaneously from a diverse set of initial engagement configurations.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [132] [Minimization of Nonsmooth Weakly Convex Function over Prox-regular Set for Robust Low-rank Matrix Recovery](https://arxiv.org/abs/2509.17549)
*Keita Kume,Isao Yamada*

Main category: math.OC

TL;DR: 本文提出了一个用于鲁棒低秩矩阵恢复的非凸非光滑优化模型，并展示了其优于传统L1范数方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统L1范数在处理大异常值时表现不足，因此需要一种更鲁棒的损失函数。

Method: 提出了一种基于弱凸函数的模型，并设计了一种投影变量平滑算法进行优化。

Result: 数值实验表明，新模型在处理异常值时比L1范数更有效。

Conclusion: 该模型在鲁棒低秩矩阵恢复问题中表现优于现有方法。

Abstract: We propose a prox-regular-type low-rank constrained nonconvex nonsmooth
optimization model for Robust Low-Rank Matrix Recovery (RLRMR), i.e., estimate
problem of low-rank matrix from an observed signal corrupted by outliers. For
RLRMR, the $\ell_{1}$-norm has been utilized as a convex loss to detect
outliers as well as to keep tractability of optimization models. Nevertheless,
the $\ell_{1}$-norm is not necessarily an ideal robust loss because the
$\ell_{1}$-norm tends to overpenalize entries corrupted by outliers of large
magnitude. In contrast, the proposed model can employ a weakly convex function
as a more robust loss, against outliers, than the $\ell_{1}$-norm. For the
proposed model, we present (i) a projected variable smoothing-type algorithm
applicable for the minimization of a nonsmooth weakly convex function over a
prox-regular set, and (ii) a convergence analysis of the proposed algorithm in
terms of stationary point. Numerical experiments demonstrate the effectiveness
of the proposed model compared with the existing models that employ the
$\ell_{1}$-norm.

</details>


### [133] [A Regularized Riccati Recursion for Interior-Point Optimal Control](https://arxiv.org/abs/2509.16370)
*João Sousa-Pinto,Dominique Orban*

Main category: math.OC

TL;DR: 论文提出了一种正则化LQR问题的闭式扩展解法，并将其用于解决一般约束、非凸、离散时间最优控制问题，同时保证每一步是增强障碍-拉格朗日罚函数的下降方向。


<details>
  <summary>Details</summary>
Motivation: 解决正则化LQR问题和一般约束、非凸最优控制问题，提供高效的算法实现。

Method: 基于Riccati递推的闭式扩展，结合正则化内点法，保证每一步是增强障碍-拉格朗日罚函数的下降方向。

Result: 提出了一种有效的算法，并在C++和JAX中提供了MIT许可的实现。

Conclusion: 该方法为解决复杂最优控制问题提供了新的理论和实用工具。

Abstract: We derive a closed-form extension of Riccati's recursion for solving
regularized LQR problems. We also show how this can be used to solve general
constrained, non-convex, discrete-time optimal control problems via a
regularized interior point method, while guaranteeing that each step is a
descent direction of an Augmented Barrier-Lagrangian merit function. We also
provide MIT-licensed implementations of our method in C++ and JAX.

</details>
