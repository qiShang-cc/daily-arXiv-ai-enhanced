<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 18]
- [cs.LG](#cs.LG) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [PPAAS: PVT and Pareto Aware Analog Sizing via Goal-conditioned Reinforcement Learning](https://arxiv.org/abs/2507.17003)
*Seunggeun Kim,Ziyi Wang,Sungyoung Lee,Youngmin Oh,Hanqing Zhu,Doyun Kim,David Z. Pan*

Main category: eess.SP

TL;DR: 该论文提出了一种基于目标条件强化学习的框架，用于高效训练模拟设备尺寸优化的策略，并通过帕累托前沿目标采样和保守后视经验回放提高了样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 模拟和混合信号电路设计中，设备尺寸优化是一个关键但复杂的任务，尤其是在工艺、电压和温度变化的影响下。传统的强化学习方法需要大量样本和资源来训练能够适应多种设计规格的策略。

Method: 论文采用目标条件强化学习框架，结合帕累托前沿目标采样和保守后视经验回放，提高样本效率。此外，还引入了失败跳过仿真策略，以减少仿真开销。

Result: 实验表明，该方法在样本效率上提高了约1.6倍，在仿真效率上提高了约4.1倍。

Conclusion: 提出的框架在模拟设备尺寸优化中表现出高效性和普适性，为复杂设计条件下的自动化优化提供了可行的解决方案。

Abstract: Device sizing is a critical yet challenging step in analog and mixed-signal
circuit design, requiring careful optimization to meet diverse performance
specifications. This challenge is further amplified under process, voltage, and
temperature (PVT) variations, which cause circuit behavior to shift across
different corners. While reinforcement learning (RL) has shown promise in
automating sizing for fixed targets, training a generalized policy that can
adapt to a wide range of design specifications under PVT variations requires
much more training samples and resources. To address these challenges, we
propose a \textbf{Goal-conditioned RL framework} that enables efficient policy
training for analog device sizing across PVT corners, with strong
generalization capability. To improve sample efficiency, we introduce
Pareto-front Dominance Goal Sampling, which constructs an automatic curriculum
by sampling goals from the Pareto frontier of previously achieved goals. This
strategy is further enhanced by integrating Conservative Hindsight Experience
Replay, which assigns relabeled goals with conservative virtual rewards to
stabilize training and accelerate convergence. To reduce simulation overhead,
our framework incorporates a Skip-on-Fail simulation strategy, which skips
full-corner simulations when nominal-corner simulation fails to meet target
specifications. Experiments on benchmark circuits demonstrate $\sim$1.6$\times$
improvement in sample efficiency and $\sim$4.1$\times$ improvement in
simulation efficiency compared to existing sizing methods. Code and benchmarks
are publicly available at https://github.com/SeunggeunKimkr/PPAAS

</details>


### [2] [Efficient and Distortion-less Spectrum Multiplexer via Neural Network-based Filter Banks](https://arxiv.org/abs/2507.17106)
*Jiazhao Wang,Wenchao Jiang*

Main category: eess.SP

TL;DR: 提出基于神经网络的滤波器组方案，实现高效、低失真的窄带物联网信号多路复用，提高频谱利用率。


<details>
  <summary>Details</summary>
Motivation: 为解决传统方法在多路复用窄带物联网信号时效率低、失真大的问题。

Method: 采用模型驱动方法，将神经网络模型解释为滤波器组，设计NN-based滤波器组。

Result: 实现了-39dB的低失真，效率提升35倍，SNR增益10dB，接收率高达98%。

Conclusion: NN-based滤波器组方案高效、低失真，适用于异构和同构物联网网络。

Abstract: Spectrum multiplexer enables simultaneous transmission of multiple
narrow-band IoT signals through gateway devices, thereby enhancing overall
spectrum utilization. We propose a novel solution based on filter banks that
offer increased efficiency and minimal distortion compared with conventional
methods. We follow a model-driven approach to integrate the neural networks
into the filter bank design by interpreting the neural network models as filter
banks. The proposed NN-based filter banks can leverage advanced learning
capabilities to achieve distortionless multiplexing and harness hardware
acceleration for high efficiency. Then, we evaluate the performance of the
spectrum multiplexer implemented by NN-based filter banks for various types of
signals and environmental conditions. The results show that it can achieve a
low distortion level down to $-39$dB normalized mean squared error.
Furthermore, it achieves up to $35$ times execution efficiency gain and $10$dB
SNR gain compared with the conventional methods. The field applications show
that it can handle both the heterogeneous and homogeneous IoT networks,
resulting in high packet reception ratio at the standard receivers up to
$98\%$.

</details>


### [3] [Stacked Intelligent Metasurface Assisted Multiuser Communications: From a Rate Fairness Perspective](https://arxiv.org/abs/2507.17153)
*Junjie Fang,Chao Zhang,Jiancheng An,Hongwen Yu,Qingqing Wu,Mérouane Debbah,Chau Yuen*

Main category: eess.SP

TL;DR: 本文研究了多层智能超表面（SIM）在多用户下行系统中的潜力，重点关注了两种优化问题：最大化最小速率（MR）以增强用户公平性，以及最大化速率几何平均（GMR）以平衡公平性和系统总速率（SR）。提出了两种算法，分别基于ADMM和AO，并通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在多用户下行系统中增强速率公平性并平衡公平性与系统总速率，研究了多层智能超表面的潜力。

Method: 采用基于共识ADMM的方法解决MR优化问题，并开发基于AO的算法解决GMR优化问题，两者均得到闭式解。

Result: 数值结果显示，MR最大化实现了近乎完美的公平性，而GMR最大化在公平性和系统SR之间取得了平衡。SIM的功耗较低但性能与多天线数字波束成形相当。

Conclusion: 提出的算法在MR和SR性能上均优于现有工作，且SIM在低功耗下表现出色。

Abstract: Stacked intelligent metasurface (SIM) extends the concept of single-layer
reconfigurable holographic surfaces (RHS) by incorporating a multi-layered
structure, thereby providing enhanced control over electromagnetic wave
propagation and improved signal processing capabilities. This study
investigates the potential of SIM in enhancing the rate fairness in multiuser
downlink systems by addressing two key optimization problems: maximizing the
minimum rate (MR) and maximizing the geometric mean of rates (GMR). {The former
strives to enhance the minimum user rate, thereby ensuring fairness among
users, while the latter relaxes fairness requirements to strike a better
trade-off between user fairness and system sum-rate (SR).} For the MR
maximization, we adopt a consensus alternating direction method of multipliers
(ADMM)-based approach, which decomposes the approximated problem into
sub-problems with closed-form solutions. {For GMR maximization, we develop an
alternating optimization (AO)-based algorithm that also yields closed-form
solutions and can be seamlessly adapted for SR maximization. Numerical results
validate the effectiveness and convergence of the proposed algorithms.}
Comparative evaluations show that MR maximization ensures near-perfect
fairness, while GMR maximization balances fairness and system SR. Furthermore,
the two proposed algorithms respectively outperform existing related works in
terms of MR and SR performance. Lastly, SIM with lower power consumption
achieves performance comparable to that of multi-antenna digital beamforming.

</details>


### [4] [Design of a Noval Wearable ECG Monitoring Device](https://arxiv.org/abs/2507.17154)
*Ruihua Wang,Mingtong Chen,Zhengbao Yang*

Main category: eess.SP

TL;DR: 开发一种新型无线供电的可穿戴ECG监测设备，以解决现有设备高功耗和电极舒适性问题。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴ECG设备存在高功耗和电极不适的问题，无法满足长期动态监测需求。

Method: 采用银镀织物一体切割的电极与导线设计，优化信号采集和传输，同时提升佩戴舒适性。

Result: 预期实现低功耗、高精度、高舒适性的长期无线ECG监测。

Conclusion: 新型设计有望解决当前可穿戴ECG技术的限制，推动长期动态心脏监测的应用。

Abstract: The aim of this project is to develop a new wireless powered wearable ECG
monitoring device. The main goal of the project is to provide a wireless,
small-sized ECG monitoring device that can be worn for a long period of time by
the monitored person. Electrocardiogram ECG reflects physiological and
pathological information about heart activity and is commonly used to diagnose
heart disease. Existing wearable smart ECG solutions suffer from high power
consumption in both ECG diagnosis and transmission for high accuracy.
Monitoring of ECG devices is mainly done by data extraction and acquisition,
pre-processing, feature extraction, processing and analysis, visualisation and
auxiliary procedures. During the pre-processing of the information, different
kinds of noise generated during the signal collection need to be taken into
account. The quality of the signal-to-noise ratio can usually be improved by
optimising algorithms and reducing the noise power. The choice of electrodes
usually has a direct impact on the signal-to-noise ratio and the user
experience, and conventional Ag/AgCl gel electrodes are not suitable for
long-term and dynamic monitoring as they are prone to skin irritation,
inflammation and allergic reactions. Therefore, a completely new way of
combining electrodes and wires will be used in the report. The electrodes and
wires are cut in one piece from a silver-plated fabric. The wire portion is cut
into a curved structure close to an S shape to ensure that it has good
ductility for comfort and signal integrity during daily movement of the
garment.

</details>


### [5] [Hybrid Semantic-Complementary Transmission for High-Fidelity Image Reconstruction](https://arxiv.org/abs/2507.17196)
*Hyelin Nam,Jihong Park,Jinho Choi,Seong-Lyun Kim*

Main category: eess.SP

TL;DR: 提出一种混合语义通信（HSC）框架，通过补充语义表示（SR）与残差图像信息（CR），提升图像重建的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的语义通信（SC）系统因训练数据多样性导致难以重建细粒度图像细节，需改进重建保真度。

Method: HSC框架在发送端构建CR补充SR，接收端结合两者生成高保真重建图像，CR传输量可调以优化保真度。

Result: HSC显著降低均方误差（MSE），在不同信道和神经网络架构中优于基线SC。

Conclusion: HSC通过灵活调整CR传输量，实现了更高保真度的图像重建，为语义通信提供新思路。

Abstract: Recent advances in semantic communication (SC) have introduced neural network
(NN)-based transceivers that convey semantic representation (SR) of signals
such as images. However, these NNs are trained over diverse image distributions
and thus often fail to reconstruct fine-grained image-specific details. To
overcome this limited reconstruction fidelity, we propose an extended SC
framework, hybrid semantic communication (HSC), which supplements SR with
complementary representation (CR) capturing residual image-specific
information. The CR is constructed at the transmitter, and is combined with the
actual SC outcome at the receiver to yield a high-fidelity recomposed image.
While the transmission load of SR is fixed due to its NN-based structure, the
load of CR can be flexibly adjusted to achieve a desirable fidelity. This
controllability directly influences the final reconstruction error, for which
we derive a closed-form expression and the corresponding optimal CR. Simulation
results demonstrate that HSC substantially reduces MSE compared to the baseline
SC without CR transmission across various channels and NN architectures.

</details>


### [6] [HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes](https://arxiv.org/abs/2507.17224)
*Feng Cao,Zishuo Feng*

Main category: eess.SP

TL;DR: 论文提出了一种名为HuiduRep的自监督表示学习框架，用于从细胞外尖峰波形中提取判别性和泛化性特征，并结合去噪自编码器和对比学习，构建了一个无需监督的尖峰排序流程。


<details>
  <summary>Details</summary>
Motivation: 在低信噪比、电极漂移和跨会话变异等挑战下，传统的尖峰排序方法表现不佳。作者旨在开发一种鲁棒的自监督学习框架，以改善细胞外记录的尖峰排序性能。

Method: HuiduRep结合了对比学习和去噪自编码器，通过自监督学习提取鲁棒的潜在表示。基于此框架，开发了一个无监督的尖峰排序流程。

Result: 实验表明，HuiduRep在混合和真实数据集上表现出强大的鲁棒性，其排序性能优于或媲美现有先进工具（如KiloSort4和MountainSort5）。

Conclusion: 研究表明，自监督尖峰表示学习是处理细胞外记录的鲁棒且泛化能力强的潜在工具。

Abstract: Extracellular recordings are brief voltage fluctuations recorded near
neurons, widely used in neuroscience as the basis for decoding brain activity
at single-neuron resolution. Spike sorting, which assigns each spike to its
source neuron, is a critical step in brain sensing pipelines. However, it
remains challenging under low signal-to-noise ratio (SNR), electrode drift, and
cross-session variability. In this paper, we propose HuiduRep, a robust
self-supervised representation learning framework that extracts discriminative
and generalizable features from extracellular spike waveforms. By combining
contrastive learning with a denoising autoencoder, HuiduRep learns latent
representations that are robust to noise and drift. Built on HuiduRep, we
develop a spike sorting pipeline that clusters spike representations without
supervision. Experiments on hybrid and real-world datasets demonstrate that
HuiduRep achieves strong robustness and the pipeline matches or outperforms
state-of-the-art tools such as KiloSort4 and MountainSort5. These findings
demonstrate the potential of self-supervised spike representation learning as a
foundational tool for robust and generalizable processing of extracellular
recordings.

</details>


### [7] [Joint Resource Optimization Over Licensed and Unlicensed Spectrum in Spectrum Sharing UAV Networks Against Jamming Attacks](https://arxiv.org/abs/2507.17261)
*Rui Ding,Fuhui Zhou,Yuhang Wu,Qihui Wu,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 通过优化功率、子信道分配和无人机轨迹，提出了一种抗干扰的频谱共享无人机网络算法，显著提升了传输速率。


<details>
  <summary>Details</summary>
Motivation: 无人机通信在高密度用户和数据需求下频谱资源紧张，引入未授权频谱可提升容量，但需解决潜在干扰问题。

Method: 将问题分解为功率与子信道分配、无人机轨迹设计两个子问题，提出交替优化的迭代算法。

Result: 仿真结果表明，所提算法相比基准方案显著提升了总传输速率。

Conclusion: 频谱共享与抗干扰技术的结合为提升无人机通信性能提供了有效途径。

Abstract: Unmanned aerial vehicle (UAV) communication is of crucial importance in
realizing heterogeneous practical wireless application scenarios. However, the
densely populated users and diverse services with high data rate demands has
triggered an increasing scarcity of UAV spectrum utilization. To tackle this
problem, it is promising to incorporate the underutilized unlicensed spectrum
with the licensed spectrum to boost network capacity. However, the openness of
unlicensed spectrum makes UAVs susceptible to security threats from potential
jammers. Therefore, a spectrum sharing UAV network coexisting with licensed
cellular network and unlicensed Wi-Fi network is considered with the
anti-jamming technique in this paper. The sum rate maximization of the
secondary network is studied by jointly optimizing the transmit power,
subchannel allocation, and UAV trajectory. We first decompose the challenging
non-convex problem into two subproblems, 1) the joint power and subchannel
allocation and 2) UAV trajectory design subproblems. A low-complexity iterative
algorithm is proposed in a alternating optimization manner over these two
subproblems to solve the formulated problem. Specifically, the Lagrange dual
decomposition is exploited to jointly optimize the transmit power and
subchannel allocation iteratively. Then, an efficient iterative algorithm
capitalizing on successive convex approximation is designed to get a suboptimal
solution for UAV trajectory. Simulation results demonstrate that our proposed
algorithm can significantly improve the sum transmission rate compared with the
benchmark schemes.

</details>


### [8] [State Estimation with 1-Bit Observations and Imperfect Models: Bussgang Meets Kalman in Neural Networks](https://arxiv.org/abs/2507.17284)
*Chaehyun Jung,TaeJun Ha,Hyeonuk Kim,Jeonghun Park*

Main category: eess.SP

TL;DR: 论文提出了一种处理1位量化状态估计的新方法，包括Bussgang辅助卡尔曼滤波器和深度学习改进版本，适用于非线性、不匹配模型和1位观测。


<details>
  <summary>Details</summary>
Motivation: 传统状态估计方法在处理1位量化时因信息损失严重而失效，需要新方法应对量化失真和信息损失问题。

Method: 结合Bussgang分解技术开发Bussgang辅助卡尔曼滤波器，并提出计算高效变体和基于深度学习的Bussgang辅助KalmanNet。

Result: 在Lorenz-Attractor和Michigan NCLT数据集上的仿真表明，新方法在非线性、不匹配模型下仍能实现准确状态估计。

Conclusion: 论文的方法有效解决了1位量化带来的挑战，适用于复杂现实场景。

Abstract: State estimation from noisy observations is a fundamental problem in many
applications of signal processing. Traditional methods, such as the extended
Kalman filter, work well under fully-known Gaussian models, while recent hybrid
deep learning frameworks, combining model-based and data-driven approaches, can
also handle partially known models and non-Gaussian noise. However, existing
studies commonly assume the absence of quantization distortion, which is
inevitable, especially with non-ideal analog-to-digital converters. In this
work, we consider a state estimation problem with 1-bit quantization. 1-bit
quantization causes significant quantization distortion and severe information
loss, rendering conventional state estimation strategies unsuitable. To address
this, inspired by the Bussgang decomposition technique, we first develop the
Bussgang-aided Kalman filter by assuming perfectly known models. The proposed
method suitably captures quantization distortion into the state estimation
process. In addition, we propose a computationally efficient variant, referred
to as the reduced Bussgang-aided Kalman filter and, building upon it, introduce
a deep learning-based approach for handling partially known models, termed the
Bussgang-aided KalmanNet. In particular, the Bussgang-aided KalmanNet jointly
uses a dithering technique and a gated recurrent unit (GRU) architecture to
effectively mitigate the effects of 1-bit quantization and model mismatch.
Through simulations on the Lorenz-Attractor model and the Michigan NCLT
dataset, we demonstrate that our proposed methods achieve accurate state
estimation performance even under highly nonlinear, mismatched models and 1-bit
observations.

</details>


### [9] [Non-Orthogonal AFDM: A Promising Spectrum-Efficient Waveform for 6G High-Mobility Communications](https://arxiv.org/abs/2507.17292)
*Yu Zhang,Qin Yi,Leila Musavian,Tongyang Xu,Zilong Liu*

Main category: eess.SP

TL;DR: 提出一种高效频谱的非正交AFDM波形，通过压缩因子控制子载波重叠，结合线性预编码和迭代检测来降低干扰，在高移动环境中保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 为6G移动系统的高移动性通信设计一种频谱效率高且可靠的波形方案。

Method: 引入压缩因子实现可控子载波重叠，采用线性预编码和迭代检测技术。

Result: 仿真显示该方法能有效降低干扰并在高压缩因子和高移动性条件下保持稳健的BER性能。

Conclusion: 非正交AFDM波形在动态环境中平衡了频谱效率和抗多普勒能力，是6G网络的潜在解决方案。

Abstract: This paper proposes a spectrum-efficient nonorthogonal affine frequency
division multiplexing (AFDM) waveform for reliable high-mobility communications
in the upcoming sixth-generation (6G) mobile systems. Our core idea is to
introduce a compression factor to enable controllable subcarrier overlapping in
chirp-based AFDM modulation. To mitigate intercarrier interference (ICI), we
introduce linear precoding at the transmitter and an iterative detection scheme
at the receiver. Simulation results demonstrate that these techniques can
effectively reduce interference and maintain robust bit error rate (BER)
performance even under aggressive compression factors and high-mobility channel
conditions. The proposed non-orthogonal AFDM waveform offers a promising
solution for next-generation wireless networks, balancing spectrum efficiency
and Doppler resilience in highly dynamic environments.

</details>


### [10] [LightCom: A Generative AI-Augmented Framework for QoE-Oriented Communications](https://arxiv.org/abs/2507.17352)
*Chunmei Xu,Siqi Zhang,Yi Ma,Rahim Tafazolli*

Main category: eess.SP

TL;DR: LightCom是一个轻量级编码和生成AI增强的解码框架，旨在低信噪比条件下提升QoE，简化发射器设计并利用生成AI在接收端重建高保真内容。


<details>
  <summary>Details</summary>
Motivation: 解决传统QoS驱动系统在数据密集型应用（如虚拟现实）中无法满足严格QoE需求的问题。

Method: 采用低通滤波进行源编码和最小化信道编码，结合生成AI在接收端利用生成先验重建内容。

Result: LightCom在仿真中表现出色，鲁棒性提升14 dB，感知覆盖增强9 dB。

Conclusion: LightCom将通信系统从比特级保真转向以人为中心的QoE指标，为更高效、更具弹性的无线网络铺平道路。

Abstract: Data-intensive and immersive applications, such as virtual reality, impose
stringent quality of experience (QoE) requirements that challenge traditional
quality of service (QoS)-driven communication systems. This paper presents
LightCom, a lightweight encoding and generative AI (GenAI)-augmented decoding
framework, designed for QoE-oriented communications under low signal-to-noise
ratio (SNR) conditions. LightCom simplifies transmitter design by applying
basic low-pass filtering for source coding and minimal channel coding,
significantly reducing processing complexity and energy consumption. At the
receiver, GenAI models reconstruct high-fidelity content from highly compressed
and degraded signals by leveraging generative priors to infer semantic and
structural information beyond traditional decoding capabilities. The key design
principles are analyzed, along with the sufficiency and error-resilience of the
source representation. We also develop importance-aware power allocation
strategies to enhance QoE and extend perceived coverage. Simulation results
demonstrate that LightCom achieves up to a $14$ dB improvement in robustness
and a $9$ dB gain in perceived coverage, outperforming traditional QoS-driven
systems relying on sophisticated source and channel coding. This paradigm shift
moves communication systems towards human-centric QoE metrics rather than
bit-level fidelity, paving the way for more efficient and resilient wireless
networks.

</details>


### [11] [Partially Reflected Surface (PRS)-Loaded Graphene-Based Patch Antenna for 6G](https://arxiv.org/abs/2507.17393)
*Omar Osman,Abdullah Qayyum,Maziar Nekovee*

Main category: eess.SP

TL;DR: 研究了基于石墨烯的缝隙贴片天线与部分反射表面（PRS）集成，用于6G太赫兹频段的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为6G通信的太赫兹频段设计高性能天线，解决带宽和增益问题。

Method: 使用石墨烯材料在Rogers RT Duroid 6010基板上设计天线，集成5x4单元PRS以优化增益。

Result: 天线带宽达70 GHz（750-820 GHz），增益提升1.07 dBi，辐射模式稳定。

Conclusion: PRS有效提升了天线性能，仿真验证了设计可行性。

Abstract: This work investigates a slotted patch antenna integrated with a partially
reflected surface (PRS) to operate in the TeraHertz (THz) frequency range for
6G. The antenna is based on graphene material, on a Rogers RT Duroid 6010
substrate. The proposed antenna achieves a bandwidth of 70 GHz (750 GHz to 820
GHz). The PRS sheet consists of 5x4 unit cells, which are optimised to enhance
the overall realized gain of the antenna. The overall realized gain has
increased by 1.07 dBi. Also, the PRS enhanced the antenna radiation pattern,
showing stable properties over the operating bandwidth. The improved antenna
performance is validated via simulations.

</details>


### [12] [Learning from Scratch: Structurally-masked Transformer for Next Generation Lib-free Simulation](https://arxiv.org/abs/2507.17396)
*Junlang Huang,Hao Chen,Zhong Guan*

Main category: eess.SP

TL;DR: 该论文提出了一种用于多级数据路径的功率和时序预测的神经框架，区别于传统的基于库的分析方法。


<details>
  <summary>Details</summary>
Motivation: 传统的功率和时序预测方法依赖于驱动特性和负载简化，缺乏准确性。论文旨在开发一种基于语言、感知网表的神经网络框架，以更精确地捕捉物理电路行为。

Method: 采用预训练的波形预测和延迟估计神经网络模型，直接从SPICE网表中推断波形和延迟；利用递归传播策略处理多级时序预测；使用混合CNN-Transformer架构处理波形预测。

Result: 实验结果表明，该方法达到SPICE级别的精确度，RMSE低于0.0098，适用于多样化的工业电路。

Conclusion: 框架提供了可扩展、结构适应性强的神经替代方案，能够高保真地模拟物理电路行为。

Abstract: This paper proposes a neural framework for power and timing prediction of
multi-stage data path, distinguishing itself from traditional lib-based
analytical methods dependent on driver characterization and load
simplifications. To the best of our knowledge, this is the first
language-based, netlist-aware neural network designed explicitly for standard
cells. Our approach employs two pre-trained neural models of waveform
prediction and delay estimation that directly infer transient waveforms and
propagation delays from SPICE netlists, conditioned on critical physical
parameters such as load capacitance, input slew, and gate size. This method
accurately captures both intrinsic and coupling-induced delay effects without
requiring simplification or interpolation. For multi-stage timing prediction,
we implement a recursive propagation strategy where predicted waveforms from
each stage feed into subsequent stages, cumulatively capturing delays across
the logic chain. This approach ensures precise timing alignment and complete
waveform visibility throughout complex signal pathways. The waveform prediction
utilizes a hybrid CNN-Transformer architecture with netlist-aware node-level
encoding, addressing traditional Transformers' fixed input dimensionality
constraints. Additionally, specialized subnetworks separately handle primary
delay estimation and crosstalk correction. Experimental results demonstrate
SPICE-level accuracy, consistently achieving RMSE below 0.0098 across diverse
industrial circuits. The proposed framework provides a scalable, structurally
adaptable neural alternative to conventional power and timing engines,
demonstrating high fidelity to physical circuit behaviors.

</details>


### [13] [Power Allocation and RIS Elements Optimisation for Reconfigurable Intelligent Surfaces assisted RSMA](https://arxiv.org/abs/2507.17419)
*Abdullah Qayyum,Maziar Nekovee*

Main category: eess.SP

TL;DR: 论文提出了一种在RIS辅助的RSMA系统中优化功率分配和RIS元素数量的方法，ORIS-RSMA方法在满足目标公共速率的情况下实现了更高的总速率。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的RSMA系统中，优化RIS元素数量和功率分配以最大化总速率并满足目标公共速率。

Method: 提出ORIS-RSMA方法，优化RIS元素数量和功率分配因子（公共和私有部分），以最大化总速率。

Result: ORIS-RSMA与传统RIS-RSMA和RSMA相比，实现了更高的总速率。

Conclusion: ORIS-RSMA在性能上优于传统方法。

Abstract: This paper proposes power allocation and the number of reconfigurable
intelligent surfaces (RIS) elements optimisation in a RIS-assisted rate
splitting multiple access (RSMA) system. The optimised RIS-RSMA (ORIS-RSMA)
method determines the optimal number of RIS elements and the power allocation
factors for both common and private parts of a message. Additionally, it
maximises the sum rate while ensuring that a target common rate is satisfied.
The performance of the proposed ORIS-RSMA is compared to that of the
conventional RIS-RSMA and RSMA. Simulation results show that ORIS-RSMA achieves
a higher sum rate.

</details>


### [14] [Detecting Multiple Targets with Distributed Sensing and Communication in Cell-Free Massive MIMO](https://arxiv.org/abs/2507.17441)
*Zinat Behdad,Ozlem Tugfe Demir,Ki Won Sung,Cicek Cavdar*

Main category: eess.SP

TL;DR: 论文研究了在无蜂窝大规模MIMO框架下的多目标检测，提出了启发式AP模式选择算法和基于信道感知的分布式检测方案，通过功率分配算法平衡通信与感知性能。


<details>
  <summary>Details</summary>
Motivation: 研究在集成感知与通信系统中如何高效实现多目标检测，并解决通信与感知之间的性能权衡问题。

Method: 采用用户中心的通信UE方法，提出启发式AP模式选择算法和基于SIR加权的信道感知分布式检测方案，应用MAPRT检测器，开发功率分配算法以优化检测概率和通信SINR。

Result: 提出的加权方法优于非加权方法；增加更多RX-AP可能因信道较弱而降低感知性能，但可通过优化权重指数缓解；分配更多RX-AP用于感知会导致约10 dB的通信SINR损失。

Conclusion: 研究通过优化方案成功平衡了通信与感知性能，提供了有效的多目标检测方法，但需注意资源分配对性能的影响。

Abstract: This paper investigates multi-target detection in an integrated sensing and
communication (ISAC) system within a cell-free massive MIMO (CF-mMIMO)
framework. We adopt a user-centric approach for communication user equipments
(UEs) and a distributed sensing approach for multi-target detection. A
heuristic access point (AP) mode selection algorithm and a channel-aware
distributed sensing scheme are proposed, where local measurements at receive
APs (RX-APs) are weighted based on the received signals signal-to-interference
ratio (SIR). A maximum a posteriori ratio test (MAPRT) detector is applied
under two awareness levels at RX-APs. To balance the communication-sensing
trade-off, we develop a power allocation algorithm to jointly maximize the
minimum detection probability and communication
signal-to-interference-plus-noise ratio (SINR) while satisfying power
constraints. The proposed scheme outperforms non-weighted methods. Adding test
statistics from more RX-APs can degrade sensing performance due to weaker
channels, but this effect can be mitigated by optimizing the weighting
exponent. Additionally, assigning more sensing RX-APs to a sensing area results
in approximately 10 dB loss in minimum communication SINR due to limited
communication resources.

</details>


### [15] [Slow Fluid Antenna Multiple Access with Multiport Receivers](https://arxiv.org/abs/2507.17505)
*José P. González-Coma,F. Javier López-Martínez*

Main category: eess.SP

TL;DR: 研究多射频链（L>1）的流体天线（FA）接收器是否能提升慢流体天线多址（FAMA）技术的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨在仅接收端有信道状态信息（CSI）的情况下，多射频链能否通过选择与组合FA端口来减少干扰。

Method: 分析慢FAMA用户配备多端口接收器的情况，联合设计端口选择矩阵和组合向量。

Result: 多端口接收在有限射频链的FA系统中表现出显著性能提升。

Conclusion: 多射频链设计在FA系统中具有潜在性能优势。

Abstract: We investigate whether equipping fluid-antenna (FA) receivers with multiple
($L>1$) radiofrequency (RF) chains can improve the performance of the slow
fluid-antenna multiple access (FAMA) technique, which enables open-loop
connectivity with channel state information (CSI) available only at the
receiver side. We analyze the case of slow-FAMA users equipped with multiport
receivers, so that $L$ ports of the FA are selected and combined to reduce
interference. We show that a joint design of the port selection matrix and the
combining vector at each receiver yields significant performance gains over
reference schemes, demonstrating the potential of multiport reception in FA
systems with a limited number of RF chains.

</details>


### [16] [Joint Multi-Target Detection-Tracking in Cognitive Massive MIMO Radar via POMCP](https://arxiv.org/abs/2507.17506)
*Imad Bouhou,Stefano Fortunati,Leila Gharsalli,Alexandre Renaux*

Main category: eess.SP

TL;DR: 提出了一种功率感知的认知雷达框架，用于大规模MIMO雷达环境下多目标的联合检测与跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统均匀功率分配在多目标SNR变化时表现不佳，需优化功率分配以提升检测和跟踪性能。

Method: 基于POMCP的单目标算法扩展至多目标，每个目标分配独立POMCP树；通过预测目标角度和功率自适应设计波形，优化功率分配。

Result: 仿真显示，低SNR目标的检测概率提高，跟踪更准确，优于均匀或正交波形方法。

Conclusion: POMCP框架在多目标雷达系统中具有自适应和高效潜力。

Abstract: This correspondence presents a power-aware cognitive radar framework for
joint detection and tracking of multiple targets in a massive multiple-input
multiple-output (MIMO) radar environment. Building on a previous single-target
algorithm based on Partially Observable Monte Carlo Planning (POMCP), we extend
it to the multi-target case by assigning each target an independent POMCP tree,
enabling scalable and efficient planning.
  Departing from uniform power allocation-which is often suboptimal with
varying signal-to-noise ratios (SNRs)-our approach predicts each target's
future angular position and expected received power, based on its estimated
range and radar cross-section (RCS). These predictions guide adaptive waveform
design via a constrained optimization problem that allocates transmit energy to
enhance the detectability of weaker or distant targets, while ensuring
sufficient power for high-SNR targets. The reward function in the underlying
partially observable Markov decision process (POMDP) is also modified to
prioritize accurate spatial and power estimation.
  Simulations involving multiple targets with different SNRs confirm the
effectiveness of our method. The proposed framework for the cognitive radar
improves detection probability for low-SNR targets and achieves more accurate
tracking compared to approaches using uniform or orthogonal waveforms. These
results demonstrate the potential of the POMCP-based framework for adaptive,
efficient multi-target radar systems.

</details>


### [17] [SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices](https://arxiv.org/abs/2507.17623)
*Guangteng Liu,Xiayue Liu,Zhixiang Xu,Yufeng Yuan,Hui Zhao,Yuxuan Liu,Yufei Jiang*

Main category: eess.SP

TL;DR: 本文提出了一种基于单天线的Wi-Fi感知框架（SA-WiSense），通过跨子载波信道状态信息比率（CSCR）和遗传算法（GASS）解决了盲点问题，并实现了高精度的人体呼吸监测。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知在无接触呼吸监测中具有潜力，但随机相位偏移导致的盲点问题限制了其准确性。本文通过低成本单天线方案解决这一问题，适用于物联网设备。

Method: 提出CSCR方法消除随机相位偏移，并利用GASS算法优化子载波选择，提高信号质量。实验基于ESP32微控制器实现。

Result: 在8米距离内，呼吸监测的检测率达到91.2%，优于现有单天线方法。

Conclusion: SA-WiSense框架在低成本下显著提升了呼吸监测的准确性和实用性。

Abstract: Wi-Fi sensing offers a promising technique for contactless human respiration
monitoring. A key challenge, however, is the blind spot problem caused by
random phase offsets that corrupt the complementarity of respiratory signals.
To address the challenge, we propose a single-antenna-Wi-Fi-sensing
(SA-WiSense) framework to improve accuracy of human respiration monitoring,
robust against random phase offsets. The proposed SA-WiSense framework is
cost-efficient, as only a single antenna is used rather than multiple antennas
as in the previous works. Therefore, the proposed framework is applicable to
Internet of Thing (IoT), where most of sensors are equipped with a single
antenna. On one hand, we propose a cross-subcarrier channel state information
(CSI) ratio (CSCR) based blind spot mitigation approach for IoT, where the
ratios of two values of CSI between subcarriers are leveraged to mitigate
random phase offsets. We prove that the random phase offsets can be cancelled
by the proposed CSCR approach, thereby restoring the inherent complementarity
of signals for blind-spot-free sensing. On the other hand, we propose a genetic
algorithm (GA) based subcarrier selection (GASS) approach by formulating an
optimization problem in terms of the sensing-signal-to-noise ratio (SSNR) of
CSCR between subcarriers. GA is utilized to solve the formulated optimization
problem. We use commodity ESP32 microcontrollers to build an experiment test.
The proposed works are validated to achieve an detection rate of 91.2% for
respiration monitoring at distances up to 8.0 meters, substantially more
accurate than the state-of-the-art methods with a single antenna.

</details>


### [18] [Quaternion-Domain Super MDS for Robust 3D Localization](https://arxiv.org/abs/2507.17645)
*Alessio Lukaj,Keigo Masuoka,Takumi Takahashi,Giuseppe Thadeu Freitas de Abreu,Hideki Ochiai*

Main category: eess.SP

TL;DR: 提出一种基于四元数代数的低复杂度三维定位算法QD-SMDS，通过重构SMDS并利用四元数表示坐标，增强噪声抑制和定位精度，同时提供无需SVD的变体以降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有SMDS算法在高噪声和测量误差场景下定位精度不足，且计算复杂度较高。需改进算法以提高定位准确性和计算效率。

Method: 1. 将SMDS重构为四元数域版本，利用四元数表示三维坐标；2. 构建Gram边缘核矩阵，结合距离和角度信息；3. 利用SVD进行低秩截断以抑制噪声；4. 提出无需SVD的变体，通过矩阵乘法直接估计坐标。

Result: 仿真结果显示，QD-SMDS显著提升了定位精度，尤其在测量误差较大时，且无SVD变体的精度与原方法相近。

Conclusion: QD-SMDS算法在噪声和测量误差场景下表现优异，兼顾精度和计算效率，适用于无线传感器网络的三维定位。

Abstract: This paper proposes a novel low-complexity three-dimensional (3D)
localization algorithm for wireless sensor networks, termed quanternion-domain
super multi-dimensional scaling (QD-SMDS). The algorithm is based on a
reformulation of the SMDS, originally developed in the real domain, using
quaternion algebra. By representing 3D coordinates as quaternions, the method
constructs a rank-1 Gram edge kernel (GEK) matrix that integrates both relative
distance and angular information between nodes, which enhances the noise
reduction effect achieved through low-rank truncation employing singular value
decomposition (SVD), thereby improving robustness against information loss. To
further reduce computational complexity, we also propose a variant of QD-SMDS
that eliminates the need for the computationally expensive SVD by leveraging
the inherent structure of the quaternion-domain GEK matrix. This alternative
directly estimates node coordinates using only matrix multiplications within
the quaternion domain. Simulation results demonstrate that the proposed method
significantly improves localization accuracy compared to the original SMDS
algorithm, especially in scenarios with substantial measurement errors. The
proposed method also achieves comparable localization accuracy without
requiring SVD.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [19] [Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation](https://arxiv.org/abs/2507.17071)
*Juntao Lin,Xianghao Zhan*

Main category: cs.LG

TL;DR: 论文提出了一种基于知识蒸馏（KD）的新方法，用于解决电子鼻系统中传感器漂移问题，显著优于现有方法（DRCA）。


<details>
  <summary>Details</summary>
Motivation: 传感器漂移在电子鼻系统的实际应用中会降低气体分类性能，现有方法缺乏统计严谨性且可能导致过度补偿。

Method: 设计了两种域适应任务，并系统地测试了提出的KD方法、基准方法DRCA及其混合方法KD-DRCA。

Result: KD方法在30次随机测试集分区中表现最佳，准确率提升18%，F1分数提升15%。

Conclusion: KD方法首次应用于电子鼻漂移补偿，显著优于DRCA方法，提升了实际环境中的传感器可靠性。

Abstract: Due to environmental changes and sensor aging, sensor drift challenges the
performance of electronic nose systems in gas classification during real-world
deployment. Previous studies using the UCI Gas Sensor Array Drift Dataset
reported promising drift compensation results but lacked robust statistical
experimental validation and may overcompensate for sensor drift, losing
class-related variance.To address these limitations and improve sensor drift
compensation with statistical rigor, we first designed two domain adaptation
tasks based on the same electronic nose dataset: using the first batch to
predict the remaining batches, simulating a controlled laboratory setting; and
predicting the next batch using all prior batches, simulating continuous
training data updates for online training. We then systematically tested three
methods: our proposed novel Knowledge Distillation (KD) method, the benchmark
method Domain Regularized Component Analysis (DRCA), and a hybrid method
KD-DRCA, across 30 random test set partitions on the UCI dataset. We showed
that KD consistently outperformed both DRCA and KD-DRCA, achieving up to an 18%
improvement in accuracy and 15% in F1-score, demonstrating KD's superior
effectiveness in drift compensation. This is the first application of KD for
electronic nose drift mitigation, significantly outperforming the previous
state-of-the-art DRCA method and enhancing the reliability of sensor drift
compensation in real-world environments.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [20] [To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks](https://arxiv.org/abs/2507.17494)
*Rashika Raina,Nidhi Simmons,David E. Simmons,Michel Daoud Yacoub,Trung Q. Duong*

Main category: stat.ML

TL;DR: 论文研究了机器学习模型在多资源分配框架下的校准性能，分析了完美校准时的中断概率特性，并探讨了分类阈值选择对系统可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 下一代通信网络中，机器学习模型不仅需要准确预测，还需提供反映正确决策真实概率的校准置信度分数。

Method: 通过理论分析和仿真实验，研究完美校准预测器的中断概率条件，并使用Platt缩放和等渗回归等后处理校准技术。

Result: 研究表明，完美校准预测器的中断概率随着资源数量增加趋于预期输出，且后处理校准无法改善最小可达到的中断概率。

Conclusion: 论文为系统设计者提供了选择分类阈值以满足可靠性需求的指导，并指出校准模型的准确性-置信度函数需满足单调性条件。

Abstract: In next-generation communications and networks, machine learning (ML) models
are expected to deliver not only accurate predictions but also well-calibrated
confidence scores that reflect the true likelihood of correct decisions. This
paper studies the calibration performance of an ML-based outage predictor
within a single-user, multi-resource allocation framework. We first establish
key theoretical properties of this system's outage probability (OP) under
perfect calibration. Importantly, we show that as the number of resources
grows, the OP of a perfectly calibrated predictor approaches the expected
output conditioned on it being below the classification threshold. In contrast,
when only one resource is available, the system's OP equals the model's overall
expected output. We then derive the OP conditions for a perfectly calibrated
predictor. These findings guide the choice of the classification threshold to
achieve a desired OP, helping system designers meet specific reliability
requirements. We also demonstrate that post-processing calibration cannot
improve the system's minimum achievable OP, as it does not introduce new
information about future channel states. Additionally, we show that
well-calibrated models are part of a broader class of predictors that
necessarily improve OP. In particular, we establish a monotonicity condition
that the accuracy-confidence function must satisfy for such improvement to
occur. To demonstrate these theoretical properties, we conduct a rigorous
simulation-based analysis using post-processing calibration techniques: Platt
scaling and isotonic regression. As part of this framework, the predictor is
trained using an outage loss function specifically designed for this system.
Furthermore, this analysis is performed on Rayleigh fading channels with
temporal correlation captured by Clarke's 2D model, which accounts for receiver
mobility.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [21] [High-Density EEG Enables the Fastest Visual Brain-Computer Interfaces](https://arxiv.org/abs/2507.17242)
*Gege Ming,Weihua Pei,Sen Tian,Xiaogang Chen,Xiaorong Gao,Yijun Wang*

Main category: cs.HC

TL;DR: 研究了如何利用高密度EEG和频率-相位-空间融合编码方法提高视觉BCI系统的信息传输速率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉BCI系统的信息传输速率（ITR）不足以满足实际需求，尤其是空间信息未充分开发。

Method: 提出了一种频率-相位-空间融合编码方法，并结合256通道高密度EEG记录。

Result: 理论ITR提升了55.50%到195.56%，在线系统实现了平均472.7 bpm的实际ITR。

Conclusion: 高密度EEG在解码视觉刺激的时空信息中具有重要作用和巨大潜力。

Abstract: Brain-computer interface (BCI) technology establishes a direct communication
pathway between the brain and external devices. Current visual BCI systems
suffer from insufficient information transfer rates (ITRs) for practical use.
Spatial information, a critical component of visual perception, remains
underexploited in existing systems because the limited spatial resolution of
recording methods hinders the capture of the rich spatiotemporal dynamics of
brain signals. This study proposed a frequency-phase-space fusion encoding
method, integrated with 256-channel high-density electroencephalogram (EEG)
recordings, to develop high-speed BCI systems. In the classical frequency-phase
encoding 40-target BCI paradigm, the 256-66, 128-32, and 64-21 electrode
configurations brought theoretical ITR increases of 83.66%, 79.99%, and 55.50%
over the traditional 64-9 setup. In the proposed frequency-phase-space encoding
200-target BCI paradigm, these increases climbed to 195.56%, 153.08%, and
103.07%. The online BCI system achieved an average actual ITR of 472.7 bpm.
This study demonstrates the essential role and immense potential of
high-density EEG in decoding the spatiotemporal information of visual stimuli.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [22] [Symmetric Private Information Retrieval (SPIR) on Graph-Based Replicated Systems](https://arxiv.org/abs/2507.17736)
*Shreya Meel,Sennur Ulukus*

Main category: cs.IT

TL;DR: 该论文研究了基于图模型复制的对称私有信息检索（SPIR）问题，提出了消息特定共同随机性下的容量下界，并证明了消息特定随机性的最小大小应与消息大小相等，最后推导了路径图和正则图的精确SPIR容量。


<details>
  <summary>Details</summary>
Motivation: 探索图模型复制的数据库中对称私有信息检索的实现，特别是在服务器端共同随机性按图复制的情况下，研究其容量限制和可行性条件。

Method: 通过提出一种可实现的SPIR方案，建立了对一般图的SPIR容量下界，并证明消息特定随机性的最小大小应与消息大小相等。针对路径图和正则图，提供了匹配的上界以推导精确容量。

Result: 论文成功为一般图建立了SPIR容量下界，并证明了消息特定随机性的最小要求。此外，针对路径图和正则图，精确计算了SPIR容量。

Conclusion: 该研究为图模型复制的对称私有信息检索提供了理论框架和实用方案，尤其是在路径图和正则图中的结果具有重要参考价值。

Abstract: We introduce the problem of symmetric private information retrieval (SPIR) on
replicated databases modeled by a simple graph. In this model, each vertex
corresponds to a server, and a message is replicated on two servers if and only
if there is an edge between them. We consider the setting where the server-side
common randomness necessary to accomplish SPIR is also replicated at the
servers according to the graph, and we call this as message-specific common
randomness. In this setting, we establish a lower bound on the SPIR capacity,
i.e., the maximum download rate, for general graphs, by proposing an achievable
SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the
minimum size of message-specific randomness should be equal to the size of a
message. Finally, by providing matching upper bounds, we derive the exact SPIR
capacity for the class of path and regular graphs.

</details>
