<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [cs.RO](#cs.RO) [Total: 64]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [eess.SY](#eess.SY) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Dual Actor DDPG for Airborne STAR-RIS Assisted Communications](https://arxiv.org/abs/2509.13328)
*Danish Rizvi,David Boyle*

Main category: eess.SP

TL;DR: 该论文提出了一种基于无人机搭载的STAR-RIS（Aerial-STAR）的多用户下行通信系统，通过耦合TRC相移模型，优化了无人机轨迹、基站主动波束成形和被动RIS TRC，提出了一种新颖的DA-DDPG算法和HFI奖励函数，显著提升了通信效率和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有研究中TRC通常假设为独立，本文探索了耦合TRC相移模型在无人机搭载STAR-RIS中的应用，以提升多用户通信系统的效率和公平性，同时考虑无人机能量约束。

Method: 提出了DA-DDPG算法，使用双动作网络处理高维混合动作空间，设计了HFI奖励函数确保用户公平性，并联合优化了无人机轨迹、主动波束成形和被动RIS TRC。

Result: 仿真结果表明，DA-DDPG算法比传统方法性能提升24%-97%，3D轨迹优化通信效率提升28%，HFI奖励函数降低QoS拒绝率41%，Aerial-STAR系统表现优于固定部署方案。

Conclusion: Aerial-STAR系统和DA-DDPG算法在优化性能方面具有显著潜力，为未来通信系统设计提供了新思路。

Abstract: This study departs from the prevailing assumption of independent Transmission
and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect
Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a
novel multi-user downlink communication system that leverages a UAV-mounted
STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key
contributions include the joint optimization of UAV trajectory, active
beamforming vectors at the base station, and passive RIS TRCs to enhance
communication efficiency, while considering UAV energy constraints. We design
the TRC as a combination of discrete and continuous actions, and propose a
novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The
algorithm relies on two separate actor networks for high-dimensional hybrid
action space. We also propose a novel harmonic mean index (HFI)-based reward
function to ensure communication fairness amongst users. For comprehensive
analysis, we study the impact of RIS size on UAV aerodynamics showing that it
increases drag and energy demand. Simulation results demonstrate that the
proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based
solutions by 24% and 97%, respectively, in accumulated reward.
Three-dimensional UAV trajectory optimization achieves 28% higher communication
efficiency compared to two-dimensional and altitude optimization. The HFI based
reward function provides 41% lower QoS denial rates as compared to other
benchmarks. The mobile Aerial-STAR system shows superior performance over fixed
deployed counterparts, with the coupled phase STAR-RIS outperforming dual
Transmit/Reflect RIS and conventional RIS setups. These findings highlight the
potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG
approach in optimizing their performance.

</details>


### [2] [Environment Reconstruction in Multi-Bounce Channels with Array Partial Blockage](https://arxiv.org/abs/2509.13559)
*Yuan Liu,Linlong Wu,Xuesong Cai,M. R. Bhavani Shankar*

Main category: eess.SP

TL;DR: 该论文提出了一种针对部分阻塞引起的空间非平稳（SNS）信道的散射体定位和环境重建方法，通过GM-SAGE算法估计信道参数并验证其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 极大型天线阵列（ELAA）在高角度分辨率应用中很重要，但部分阻塞会导致SNS信道问题，亟需解决。

Method: 使用基于图的字典辅助多弹跳空间交替广义期望最大化（GM-SAGE）算法，结合空间变幅和稀疏性建模SNS效应。

Result: 通过射线追踪模拟验证，证明了该方法在处理SNS信道时的鲁棒性。

Conclusion: 该方法能有效解决部分阻塞引起的SNS信道问题，为ELAA应用提供了可靠的支持。

Abstract: Extremely-large antenna arrays (ELAA) are important in applications requiring
high angular resolution. However, a prominent issue is the spatial
non-stationary (SNS) channels due to partial blockage to the ELAA. In this
paper, we address the scatterer localization and subsequent environment
reconstruction considering partially blocked SNS channels. Specifically, the
SNS effects are parametrically modeled through spatial-varying amplitudes with
sparsity. Based on the established signal model, the graph-based
dictionary-aided multi-bounce space-alternating generalized
expectation-maximization (GM-SAGE) algorithm is applied to estimate the channel
parameters and the channel sparsity is empirically detected along with
amplitude estimation. To validate the proposed approach, we generate
multi-bounce paths through ray tracing (RT) simulations, where the SNS channels
caused by partial blockage could be configured flexibly. The simulation results
demonstrate the robustness of the proposed approach in dealing with the SNS
channels.

</details>


### [3] [Fast Single-Snapshot Harmonic Recovery with 2D Sparse Arrays using BCCB Matrices](https://arxiv.org/abs/2509.13592)
*Youval Klioui*

Main category: eess.SP

TL;DR: 本文提出了一种高效的稀疏恢复方法实现，用于通过单次快照进行二维稀疏阵列的谐波估计。通过施加均匀性约束和温和的阵列拓扑约束，展示了稀疏恢复方法中Gram矩阵的BCCB结构，并利用2D FFT显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 旨在提出一种高效的方法，降低二维稀疏阵列谐波估计的计算复杂度，通过利用矩阵结构优化加速稀疏恢复算法的性能。

Method: 在稀疏恢复问题中对子字典的谐波网格施加均匀性约束，并利用BCCB结构，通过2D FFT将矩阵操作的复杂度从O((L1L2)^2)降至O(L1L2 log(L1L2))。实验验证了ISTA、FISTA和ADMM算法的改进。

Result: 实验结果证实了所提方法的有效性，通过利用BCCB结构和FFT显著降低了计算复杂度。

Conclusion: 该方法通过在稀疏恢复中利用BCCB结构和FFT，实现了计算效率的大幅提升，适用于二维稀疏阵列的谐波估计问题。

Abstract: We introduce an efficient implementation of sparse recovery methods for the
problem of harmonic estimation with 2D sparse arrays using a single snapshot.
By imposing a uniformity constraint on the harmonic grids of the
subdictionaries used in the sparse recovery problem, in addition to a mild
constraint on the array topology that consists in having the elements lie on a
grid specified in half-wavelength units, we show that the Gram matrices that
appear in these sparse recovery methods exhibit a block-circulant with
circulant blocks (BCCB) structure. The BCCB structure is then exploited to
reduce the computational complexity of the matrix-vector products that appear
in these methods through the use of 2D fast Fourier transforms (FFT) from
O((L1L2)^2) down to O(L1L2 log(L1L2)) operations per iterations, where L1, L2
are the lengths of the subdictionaries used for estimating the harmonics in the
first and second dimension, respectively. We experimentally verify the proposed
implementation using the iterative shrinkage thresholding algorithm (ISTA), the
fast iterative shrinkage-thresholding algorithm (FISTA), and the alternating
direction method of multipliers (ADMM) where we observe improvements

</details>


### [4] [GNSS Jamming and Spoofing Monitoring Using Low-Cost COTS Receivers](https://arxiv.org/abs/2509.13600)
*Argyris Kriezis,Yu-Hsuan Chen,Dennis Akos,Sherman Lo,Todd Walter*

Main category: eess.SP

TL;DR: 利用低成本商用GNSS接收机检测和分类射频干扰（RFI）事件，结合载噪比和校准接收功率，构建二维检测空间，有效区分干扰和欺骗信号。


<details>
  <summary>Details</summary>
Motivation: 全球导航卫星系统（GNSS）易受射频干扰（RFI）威胁，影响导航和计时服务完整性，需低成本解决方案。

Method: 结合载噪比（C/N0）和校准接收功率，构建二维检测空间，分类正常、干扰、欺骗和阻塞信号。

Result: 在挪威、波兰和东南地中海的实际测试中，验证了低成本商用接收机在RFI监测中的有效性。

Conclusion: 经过校准的低成本商用GNSS接收机可有效用于GNSS RFI监测。

Abstract: The Global Navigation Satellite System (GNSS) is increasingly vulnerable to
radio frequency interference (RFI), including jamming and spoofing, which
threaten the integrity of navigation and timing services. This paper presents a
methodology for detecting and classifying RFI events using low-cost commercial
off-the-shelf (COTS) GNSS receivers. By combining carrier-to-noise ratio (C/N0)
measurements with a calibrated received power metric, a two-dimensional
detection space is constructed to identify and distinguish nominal, jammed,
spoofed, and blocked signal conditions. The method is validated through both
controlled jamming tests in Norway and real-world deployments in Poland, and
the Southeast Mediterranean which have experienced such conditions. Results
demonstrate that COTS-based detection, when properly calibrated, offers a
viable and effective approach for GNSS RFI monitoring.

</details>


### [5] [Theoretical Validation of the Latent Optimally Partitioned-$\ell_2/\ell_1$ Penalty with Application to Angular Power Spectrum Estimation](https://arxiv.org/abs/2509.13745)
*Hiroki Kuroda,Renato Luis Garrido Cavalcante,Masahiro Yukawa*

Main category: eess.SP

TL;DR: LOP-$ℓ_2/ℓ_1$惩罚无需已知块结构即可有效利用块稀疏性，理论证明其优化分区满足信号恢复条件，应用于MIMO系统中的角功率谱估计显著提高了精度。


<details>
  <summary>Details</summary>
Motivation: 解决未知块结构下块稀疏信号的准确恢复问题，并探索其在MIMO系统角功率谱估计中的应用。

Method: 提出LOP-$ℓ_2/ℓ_1$惩罚优化块分区，理论证明其有效性，并应用于块稀疏的角功率谱估计。

Result: 数值模拟显示该方法显著提高了角功率谱的估计精度。

Conclusion: LOP-$ℓ_2/ℓ_1$惩罚在理论和实践中均能有效利用块稀疏性，适用于未知块结构的场景。

Abstract: This paper demonstrates that, in both theory and practice, the latent
optimally partitioned (LOP)-$\ell_2/\ell_1$ penalty is effective for exploiting
block-sparsity without the knowledge of the concrete block structure. More
precisely, we first present a novel theoretical result showing that the
optimized block partition in the LOP-$\ell_2/\ell_1$ penalty satisfy a
condition required for accurate recovery of block-sparse signals. Motivated by
this result, we present a new application of the LOP-$\ell_2/\ell_1$ penalty to
estimation of angular power spectrum, which is block-sparse with unknown block
partition, in MIMO communication systems. Numerical simulations show that the
proposed use of block-sparsity with the LOP-$\ell_2/\ell_1$ penalty
significantly improves the estimation accuracy of the angular power spectrum.

</details>


### [6] [Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization](https://arxiv.org/abs/2509.13786)
*SaiKrishna Saketh Yellapragada,Esa Ollila,Mario Costa*

Main category: eess.SP

TL;DR: 该论文研究了在6G无线通信系统中，通过量化感知训练（QAT）提升神经网络接收器的性能，实现低比特量化下的高效物理层处理。


<details>
  <summary>Details</summary>
Motivation: 随着6G无线通信系统的发展，传统基于模型的方法在性能上存在局限性，而深度学习（DL）为基础的神经接收器展现出优越性能。然而，资源受限的硬件部署需要高效的量化技术以确保低延迟和低能耗。

Method: 论文结合后训练量化（PTQ）和量化感知训练（QAT），在训练过程中引入低精度模拟，以确保在超低比特宽度下的鲁棒性。研究在3GPP CDL-B/D信道环境下评估了QAT/PTQ的性能。

Result: 实验结果表明，4位和8位QAT模型在10%目标BLER下性能接近FP32模型。QAT模型比PTQ模型表现高出3 dB，并实现了8倍压缩。

Conclusion: QAT是实现低复杂度、低延迟6G边缘设备物理层处理的关键技术，为实时处理提供了可行方案。

Abstract: As wireless communication systems advance toward Sixth Generation (6G) Radio
Access Networks (RAN), Deep Learning (DL)-based neural receivers are emerging
as transformative solutions for Physical Layer (PHY) processing, delivering
superior Block Error Rate (BLER) performance compared to traditional
model-based approaches. Practical deployment on resource-constrained hardware,
however, requires efficient quantization to reduce latency, energy, and memory
without sacrificing reliability. We extend Post-Training Quantization (PTQ)
baselines with Quantization-Aware Training (QAT), which incorporates
low-precision simulation during training for robustness at ultra-low bitwidths.
Our study applies QAT/PTQ to a neural receiver architecture and evaluates
across 3GPP Clustered Delay Line (CDL)-B/D channels in LoS and NLoS
environments at user velocities up to 40 m/s. Results show that 4-bit and 8-bit
QAT models achieve BLERs similar to that of FP32 models at 10% target BLER. QAT
models are also shown to outperform PTQ models by up to 3 dB, and yield 8x
compression. These results demonstrate that QAT is a key enabler of
low-complexity and latency-constrained inference at the PHY layer, facilitating
real-time processing in 6G edge devices

</details>


### [7] [Domino: Dominant Path-based Compensation for Hardware Impairments in Modern WiFi Sensing](https://arxiv.org/abs/2509.13807)
*Ruiqi Kong,He Chen*

Main category: eess.SP

TL;DR: Domino提出了一种新的WiFi感知框架，通过将信道状态信息（CSI）转换为信道脉冲响应（CIR），有效补偿硬件引入的射频失真，显著提升了呼吸监测的精度。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi感知系统因802.11ac/ax协议的硬件射频失真问题而可靠性不足，现有补偿方法难以应对这些复杂动态失真。

Method: Domino利用信号路径的均匀性，以主导静态路径为参考，通过延迟域处理精确补偿失真。

Result: 实验表明，Domino在呼吸监测中的平均精度比现有方法至少提高2倍，单天线条件下中位误差低于0.24 bpm。

Conclusion: Domino通过创新的路径补偿方法，显著提升了WiFi感知的可靠性，适用于复杂环境。

Abstract: WiFi sensing faces a critical reliability challenge due to hardware-induced
RF distortions, especially with modern, market-dominant WiFi cards supporting
802.11ac/ax protocols. These cards employ sensitive automatic gain control and
separate RF chains, introducing complex and dynamic distortions that render
existing compensation methods ineffective. In this paper, we introduce Domino,
a new framework that transforms channel state information (CSI) into channel
impulse response (CIR) and leverages it for precise distortion compensation.
Domino is built on the key insight that hardware-induced distortions impact all
signal paths uniformly, allowing the dominant static path to serve as a
reliable reference for effective compensation through delay-domain processing.
Real-world respiration monitoring experiments show that Domino achieves at
least 2x higher mean accuracy over existing methods, maintaining robust
performance with a median error below 0.24 bpm, even using a single antenna in
both direct line-of-sight and obstructed scenarios.

</details>


### [8] [Flow Matching-Based Active Learning for Radio Map Construction with Low-Altitude UAVs](https://arxiv.org/abs/2509.13822)
*Hao Sun,Shicong Liu,Xianghao Yu,Ying Sun*

Main category: eess.SP

TL;DR: 提出了一种基于主动学习的新框架，利用有限测量数据构建低空无线电地图，并通过不确定性引导的路径规划优化无人机轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在低空经济中因飞行时间有限无法进行详尽测量，导致无线电地图构建困难的问题。

Method: 结合PnP改进的流匹配算法和不确定性量化，通过多目标候选选择和路径规划优化无人机测量路线。

Result: 仿真结果显示，该方法比基线方法显著提升，归一化均方误差降低了70%以上。

Conclusion: 提出的框架能高效构建高保真无线电地图，为无人机通信和导航提供可靠支持。

Abstract: The employment of unmanned aerial vehicles (UAVs) in the lowaltitude economy
necessitates precise and real-time radio maps for reliable communication and
safe navigation. However, constructing such maps is hindered by the
infeasibility of exhaustive measurements due to UAVs' limited flight endurance.
To address this, we propose a novel active learning framework for low-altitude
radio map construction based on limited measurements. First, a Plug-and-Play
(PnP)-refined flow matching algorithm is introduced, which leverages flow
matching as a powerful generative prior within a PnP scheme to reconstruct
high-fidelity radio maps. Second, the generative nature of flow matching is
exploited to quantify uncertainty by generating an ensemble of radio maps and
computing the location-wise variance. The resulting uncertainty map guides a
multi-objective candidate selection and then a trajectory is planned via
utility-aware path search (UAPS), directing the UAV to the most informative
locations while taking travel costs into account. Simulation results
demonstrate that our method significantly outperforms the baselines, achieving
more than a 70% reduction in normalized mean squared error (NMSE).

</details>


### [9] [FFT-Free PAPR Reduction Methods for OFDM Signals](https://arxiv.org/abs/2509.13851)
*Hao Su,Jiangtao Wang,Yongchao Wang*

Main category: eess.SP

TL;DR: 提出了两种低复杂度的PAPR降低算法，用于OFDM信号，避免了传统方法中重复FFT和IFFT操作的挑战，并通过仿真验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统PAPR降低算法由于重复的FFT和IFFT操作导致高计算复杂度，因此需要开发低复杂度算法。

Method: 建立非凸优化模型，提出定制化的ADMM算法（T-ADMM及其改进版本TCU-ADMM），所有子问题均可解析求解。

Result: 算法具有线性计算复杂度，且T-ADMM在适当参数下具有理论收敛性。

Conclusion: 提出的T-ADMM和TCU-ADMM算法在降低PAPR时有效且高效。

Abstract: In this paper, we propose two low-complexity peak to average power
ratio(PAPR) reduction algorithms for orthogonal frequency division
multiplexing(OFDM) signals. The main content is as follows: First, a non-convex
optimization model is established by minimizing the signal distortion power.
Then, a customized alternating direction method of multipliers(ADMM) algorithm
is proposed to solve the problem, named time domain ADMM(T-ADMM) along with an
improved version called T-ADMM with constrain update(TCU-ADMM). In the
algorithms, all subproblems can be solved analytically, and each iteration has
linear computational complexity. These algorithms circumvents the challenges
posed by repeated fast Fourier transform(FFT) and inverse FFT(IFFT) operations
in traditional PAPR reduction algorithms. Additionally, we prove that the
T-ADMM algorithm is theoretically guaranteed convergent if proper parameter is
chosen. Finally, simulation results demonstrate the effectiveness of the
proposed methods.

</details>


### [10] [Reconfigurable Intelligent Surface-Assisted Multiuser Tracking and Signal Detection in ISAC](https://arxiv.org/abs/2509.13940)
*Weifeng Zhu,Junyuan Gao,Shuowen Zhang,Liang Liu*

Main category: eess.SP

TL;DR: 本文研究了在可重构智能表面辅助下的集成感知与通信系统中多用户跟踪与信号检测问题，提出了一种新型混合变分消息传递算法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 由于用户移动性高且多样化，缺乏协调的用户状态更新机制会显著降低跟踪与信号检测性能，因此需要建立新的解决方案。

Method: 建立了全面的概率信号模型来表征用户状态、发射信号与接收信号间的依赖关系，并提出了一种基于贝叶斯问题表述的混合变分消息传递算法。

Result: 数值结果表明，所提算法在跟踪和信号检测性能上显著优于代表性贝叶斯估计方法。

Conclusion: 通过提出的算法，成功解决了高移动性用户状态更新的挑战，为集成感知与通信系统提供了高效解决方案。

Abstract: This paper investigates the multiuser tracking and signal detection problem
in integrated sensing and communication (ISAC) systems with the assistance of
reconfigurable intelligent surfaces (RISs). Due to the diverse and high user
mobility, the tracking and signal detection performance can be significantly
deteriorated without choreographed user state (position and velocity) updating
principle. To tackle this challenge, we manage to establish a comprehensive
probabilistic signal model to characterize the interdependencies among user
states, transmit signals, and received signals during the tracking procedure.
Based on the Bayesian problem formulation, we further propose a novel hybrid
variational message passing algorithm for the online estimation of user states,
which can iteratively update the posterior probabilities of user states during
each tracking frame with computational efficiency. Numerical results are
provided to demonstrate that the proposed algorithm can significantly improve
both of the tracking and signal detection performance over the representative
Bayesian estimation counterparts.

</details>


### [11] [Adaptive and robust smartphone-based step detection in multiple sclerosis](https://arxiv.org/abs/2509.13961)
*Lorenza Angelini,Dimitar Stanev,Marta Płonka,Rafał Klimas,Natan Napiórkowski,Gabriela González Chan,Lisa Bunn,Paul S Glazier,Richard Hosking,Jenny Freeman,Jeremy Hobart,Jonathan Marsden,Licinio Craveiro,Mike D Rinderknecht,Mattia Zanon*

Main category: eess.SP

TL;DR: 该研究评估了一种步态检测算法在不同智能手机佩戴位置和环境中的性能，结果显示其对初始和终止步态事件的检测准确率很高。


<details>
  <summary>Details</summary>
Motivation: 验证一种步态检测算法在不同测试设置、智能手机佩戴位置以及步态障碍水平下的表现，以提升真实世界步态评估的准确性和适用性。

Method: 研究招募了健康对照组和多发性硬化症患者，通过实验室和真实世界的步行测试，使用智能手机和参考传感器收集数据，评估算法的F1分数和绝对时间误差。

Result: 算法在所有智能手机佩戴位置和环境中表现优异，初始/终止步态事件的F1分数在健康组和多发性硬化症患者中均很高，时间误差小。性能不受年龄、性别、疾病严重程度等因素影响。

Conclusion: 该步态算法在多发性硬化症患者中表现出准确和一致的步态事件检测能力，适用于真实世界步态评估。

Abstract: Background: Many attempts to validate gait pipelines that process sensor data
to detect gait events have focused on the detection of initial contacts only in
supervised settings using a single sensor. Objective: To evaluate the
performance of a gait pipeline in detecting initial/final contacts using a step
detection algorithm adaptive to different test settings, smartphone wear
locations, and gait impairment levels. Methods: In GaitLab (ISRCTN15993728),
healthy controls (HC) and people with multiple sclerosis (PwMS; Expanded
Disability Status Scale 0.0-6.5) performed supervised Two-Minute Walk Test
[2MWT] (structured in-lab overground and treadmill 2MWT) during two on-site
visits carrying six smartphones and unsupervised walking activities (structured
and unstructured real-world walking) daily for 10-14 days using a single
smartphone. Reference gait data were collected with a motion capture system or
Gait Up sensors. The pipeline's performance in detecting initial/final contacts
was evaluated through F1 scores and absolute temporal error with respect to
reference measurement systems. Results: We studied 35 HC and 93 PwMS.
Initial/final contacts were accurately detected across all smartphone wear
locations. Median F1 scores for initial/final contacts on in-lab 2MWT were
>=98.2%/96.5% in HC and >=98.5%/97.7% in PwMS. F1 scores remained high on
structured (HC: 100% [0.3%]/100% [0.2%]; PwMS: 99.5% [1.9%]/99.4% [2.5%]) and
unstructured real-world walking (HC: 97.8% [2.6%]/97.8% [2.8%]; PwMS: 94.4%
[6.2%]/94.0% [6.5%]). Median temporal errors were <=0.08 s. Neither age, sex,
disease severity, walking aid use, nor setting (outdoor/indoor) impacted
pipeline performance (all p>0.05). Conclusion: This gait pipeline accurately
and consistently detects initial and final contacts in PwMS across different
smartphone locations and environments, highlighting its potential for
real-world gait assessment.

</details>


### [12] [Classification Filtering](https://arxiv.org/abs/2509.13975)
*Ilker Bayram*

Main category: eess.SP

TL;DR: 本文提出了一种融合多分类器输出的状态空间模型，用于实时提高流信号分类精度。


<details>
  <summary>Details</summary>
Motivation: 流信号中每个样本与隐藏类别相关，现有固定策略的多分类器输出融合未充分利用时序信息。

Method: 提出状态空间模型并设计实时滤波器，结合时序信息优化分类。

Result: 在基于IMU数据的活动分类应用中验证了滤波器的有效性。

Conclusion: 所提方法能有效提升分类精度，适用于实时场景。

Abstract: We consider a streaming signal in which each sample is linked to a latent
class. We assume that multiple classifiers are available, each providing class
probabilities with varying degrees of accuracy. These classifiers are employed
following a straightforward and fixed policy. In this setting, we consider the
problem of fusing the output of the classifiers while incorporating the
temporal aspect to improve classification accuracy. We propose a state-space
model and develop a filter tailored for realtime execution. We demonstrate the
effectiveness of the proposed filter in an activity classification application
based on inertial measurement unit (IMU) data from a wearable device.

</details>


### [13] [Distributed Coherent Beamforming at 60 GHz Enabled by Optically-Established Coherence](https://arxiv.org/abs/2509.13984)
*Drake Silbernagel,Yu Rong,Isabella Lenz,Prithvi Hemanth,Carl Morgenstern,Owen Ma,Nolan Matthews,Nader Zaki,Kyle W. Martin,John D. Elgin,Jacob Holtom,Daniel W. Bliss,Kimberly Frey*

Main category: eess.SP

TL;DR: 论文展示了一种60 GHz分布式系统，利用光学时间同步实现节点间精确时间与频率对齐，显著提升信号功率比和干扰抑制能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何在分布式系统中实现高精度的时间与频率对齐，以提升信号处理性能，尤其是在干扰环境下。

Method: 采用光学时间同步系统实现节点间的时间与频率对齐，进行接收波束赋形和发射零陷，测试了干扰环境下的系统性能。

Result: 实验结果表明，系统在接收波束赋形中实现了14.3 dB的信干噪比提升，13.5 dB的干扰抑制；在发射零陷中实现了7.9 dB的信噪比增益和8.9 dB的干扰抑制。

Conclusion: 该系统证明了在V波段分布式网络中无需GPS即可实现高精度同步和干扰抑制，具有重要应用价值。

Abstract: We implement and experimentally demonstrate a 60 GHz distributed system
leveraging an optical time synchronization system that provides precise time
and frequency alignment between independent elements of the distributed mesh.
Utilizing such accurate coherence, we perform receive beamforming with
interference rejection and transmit nulling. In these configurations, the
system achieves a coherent gain over an incoherent network of N nodes,
significantly improving the relevant signal power ratios. Our system
demonstrates extended array phase coherence times, enabling advanced
techniques. Results from over-the-air experiments demonstrate a 14.3 dB
signal-to-interference-plus-noise improvement in interference-laden scenarios
with a contributing 13.5 dB null towards interference in receive beamforming.
In transmit nulling, a signal-to-noise ratio (SNR) gain of 7.9 dB is measured
towards an intended receiver while maintaining an SNR reduction of 8.9 dB at
another receiver. These findings represent the use of distributed coherence in
the V band without the use of GPS timing.

</details>


### [14] [Distributed Deep Learning with RIS Grouping for Accurate Cascaded Channel Estimation](https://arxiv.org/abs/2509.14062)
*Saifur Rahman,Syed Luqman Shah,Salman Khan,Jalal Khan,Muhammad Irfan,Maaz Shafi,Said Muhammad,Fazal Muhammad,Mohammad Shahed Akond*

Main category: eess.SP

TL;DR: 论文提出了一种基于深度学习的RIS信道估计方法，通过分组RIS元素和分布式机器学习策略，显著降低了导频开销并提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: RIS面板在6G网络中虽然成本效益高，但被动特性导致信道估计困难，导频开销和计算复杂度极高。

Method: 采用深度学习框架分组RIS元素，结合分布式机器学习策略，协同训练共享神经网络以提高泛化能力，并设计分层DML架构进一步优化估计精度。

Result: 仿真结果表明，该方法在减少导频开销和复杂度的同时，信道估计精度优于传统方法和单用户模型。

Conclusion: 该方法在6G RIS辅助系统中具有实际可行性和高效性。

Abstract: Reconfigurable Intelligent Surface (RIS) panels are envisioned as a key
technology for sixth-generation (6G) wireless networks, providing a
cost-effective means to enhance coverage and spectral efficiency. A critical
challenge is the estimation of the cascaded base station (BS)-RIS-user channel,
since the passive nature of RIS elements prevents direct channel acquisition,
incurring prohibitive pilot overhead, computational complexity, and energy
consumption. To address this, we propose a deep learning (DL)-based channel
estimation framework that reduces pilot overhead by grouping RIS elements and
reconstructing the cascaded channel from partial pilot observations.
Furthermore, conventional DL models trained under single-user settings suffer
from poor generalization across new user locations and propagation scenarios.
We develop a distributed machine learning (DML) strategy in which the BS and
users collaboratively train a shared neural network using diverse channel
datasets collected across the network, thereby achieving robust generalization.
Building on this foundation, we design a hierarchical DML neural architecture
that first classifies propagation conditions and then employs scenario-specific
feature extraction to further improve estimation accuracy. Simulation results
confirm that the proposed framework substantially reduces pilot overhead and
complexity while outperforming conventional methods and single-user models in
channel estimation accuracy. These results demonstrate the practicality and
effectiveness of the proposed approach for 6G RIS-assisted systems.

</details>


### [15] [Novel Phase-Noise-Tolerant Variational-Autoencoder-Based Equalization Suitable for Space-Division-Multiplexed Transmission](https://arxiv.org/abs/2509.14072)
*Vincent Lauinger,Lennart Schmitz,Patrick Matalla,Andrej Rode,Sebastian Randel,Laurent Schmalen*

Main category: eess.SP

TL;DR: 论文展示了一种基于变分自编码器的相位噪声容忍均衡方案，适用于多芯光纤的空间分割复用传输。


<details>
  <summary>Details</summary>
Motivation: 解决多芯光纤传输中相位噪声对信号质量的影响。

Method: 采用变分自编码器进行均衡化处理，并在150公里随机耦合多芯光纤中实验验证。

Result: 该方法在多芯光纤传输中表现出色，有效抑制了相位噪声。

Conclusion: 该方案为长距离多芯光纤传输提供了一种有效的相位噪声抑制方法。

Abstract: We demonstrate the effectiveness of a novel phase-noise-tolerant,
variational-autoencoder-based equalization scheme for
space-division-multiplexed (SDM) transmission in an experiment over 150km of
randomly-coupled multi-core fibers.

</details>


### [16] [Hardware-Efficient Cognitive Radar: Multi-Target Detection with RL-Driven Transmissive RIS](https://arxiv.org/abs/2509.14160)
*Adam Umra,Aya Mostafa Ahmed,Stefan Roth,Aydin Sezgin*

Main category: eess.SP

TL;DR: 论文提出了一种基于强化学习的透射型可重构智能表面（TRIS）框架，用于优化雷达的波束成形性能，在低信噪比条件下提升多目标检测能力，同时降低硬件复杂度和功耗。


<details>
  <summary>Details</summary>
Motivation: 传统认知MIMO雷达在检测性能上表现优异，但存在硬件复杂度和功耗高的问题。为解决这些问题，研究利用TRIS和强化学习来优化雷达系统。

Method: 采用状态-动作-奖励-状态-动作（SARSA）强化学习算法，动态调整TRIS的相位偏移，以实现自适应波束成形，减少射频链的需求。

Result: 仿真结果表明，TRIS-RL雷达在多目标检测性能上匹配甚至超过传统MIMO雷达，尤其是在元件数量较多时，同时降低了成本和能耗。

Conclusion: 该研究为下一代雷达系统提供了一种高效的替代方案，结合TRIS和强化学习，在不牺牲性能的前提下实现了复杂度和功耗的显著降低。

Abstract: Cognitive radar has emerged as a key paradigm for next-generation sensing,
enabling adaptive, intelligent operation in dynamic and complex environments.
Yet, conventional cognitive multiple-input multiple-output (MIMO) radars offer
strong detection performance but suffer from high hardware complexity and power
demands. To overcome these limitations, we develop a reinforcement learning
(RL)-based framework that leverages a transmissive reconfigurable intelligent
surface (TRIS) for adaptive beamforming. A state-action-reward-state-action
(SARSA) agent tunes TRIS phase shifts to improve multi-target detection in low
signal-to-noise ratio (SNR) conditions while operating with far fewer radio
frequency (RF) chains. Simulations confirm that the proposed TRIS-RL radar
matches or, for large number of elements, even surpasses MIMO performance with
reduced cost and energy requirements.

</details>


### [17] [Quickest Change Detection with Cost-Constrained Experiment Design](https://arxiv.org/abs/2509.14186)
*Patrick Vincent N. Lubenia,Taposh Banerjee*

Main category: eess.SP

TL;DR: 研究了在多实验选择下的最快变化检测问题，提出2E-CUSUM算法以最小化检测延迟，并拓展到多实验设计，证明其渐近最优。


<details>
  <summary>Details</summary>
Motivation: 传统的快速变化检测问题中观察者仅进行一次实验，而现实中决策者需在每次观察时选择不同信息质量和成本的实验，需优化检测延迟。

Method: 提出2E-CUSUM算法处理双实验情况，并扩展到多实验设计，同时探索数据效率（可选择不实验）。

Result: 算法在满足误报和成本约束下最小化最坏情况平均检测延迟，并证明渐近最优性。

Conclusion: 2E-CUSUM及其扩展算法在多实验选择下表现优异，解决了检测延迟优化问题。

Abstract: In the classical quickest change detection problem, an observer performs only
one experiment to monitor a stochastic process. This paper considers the case
where, at each observation time, the decision-maker needs to choose between
multiple experiments with different information qualities and costs. The goal
is to minimize the worst-case average detection delay subject to false alarm
and cost constraints. An algorithm called the 2E-CUSUM Algorithm has been
developed to achieve this goal for the two-experiment case. Extensions to
multiple-experiment designs are also studied, and 2E-CUSUM is extended
accordingly. Data efficiency, where the observer has the choice not to perform
an experiment, is explored as well. The proposed algorithms are analyzed and
shown to be asymptotically optimal.

</details>


### [18] [Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems](https://arxiv.org/abs/2509.14201)
*Guangjin Pan,Liping Bai,Zhuojun Tian,Hui Chen,Mehdi Bennis,Henk Wymeersch*

Main category: eess.SP

TL;DR: 该论文提出了一种基于主动推理框架（AIF）的集成感知、通信与控制（SCC）方法，用于无人机系统，通过统一生成模型优化状态估计、控制和资源分配。


<details>
  <summary>Details</summary>
Motivation: 现有SCC方案常将感知与控制分开处理，导致性能与资源使用欠佳。论文旨在通过AIF框架实现联合优化。

Method: 引入主动推理框架，通过统一生成模型最小化变分自由能（推断）和期望自由能（动作规划）。

Result: 仿真结果表明，相对于基线方法，控制成本和感知成本均有所降低。

Conclusion: AIF框架在SCC无人机系统中有效提升了性能与资源利用率，为6G集成感知与通信提供了新思路。

Abstract: Integrated sensing and communication (ISAC) is a core technology for 6G, and
its application to closed-loop sensing, communication, and control (SCC)
enables various services. Existing SCC solutions often treat sensing and
control separately, leading to suboptimal performance and resource usage. In
this work, we introduce the active inference framework (AIF) into SCC-enabled
unmanned aerial vehicle (UAV) systems for joint state estimation, control, and
sensing resource allocation. By formulating a unified generative model, the
problem reduces to minimizing variational free energy for inference and
expected free energy for action planning. Simulation results show that both
control cost and sensing cost are reduced relative to baselines.

</details>


### [19] [Goal-Oriented Joint Source-Channel Coding: Distortion-Classification-Power Trade-off](https://arxiv.org/abs/2509.14217)
*Andriy Enttsel,Weichen Wang,Mauro Mangia,Riccardo Rovatti,Deniz Gündüz*

Main category: eess.SP

TL;DR: 论文提出了一种联合源信道编码的理论框架，将分类和异常检测融入信号重建目标中，适用于低延迟和低复杂度通信场景。


<details>
  <summary>Details</summary>
Motivation: 在需要低延迟和低复杂度通信的情况下，联合源信道编码是一种有吸引力的方法。本研究旨在将分类和异常检测功能整合到传统的信号重建框架中。

Method: 假设高斯标量源，并限制编码器为分段线性映射，推导出可处理的设计规则，明确表征失真、分类误差和传输功率之间的权衡关系。

Result: 研究结果提供了一个理论框架，能够同时优化信号重建、分类性能和通信效率。

Conclusion: 该框架为低延迟和低复杂度通信中的联合源信道编码提供了新的设计思路和理论支持。

Abstract: Joint source-channel coding is a compelling paradigm when low-latency and
low-complexity communication is required. This work proposes a theoretical
framework that integrates classification and anomaly detection within the
conventional signal reconstruction objective. Assuming a Gaussian scalar source
and constraining the encoder to piecewise linear mappings, we derive tractable
design rules and explicitly characterize the trade-offs between distortion,
classification error, and transmission power.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [20] [Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning](https://arxiv.org/abs/2509.13336)
*Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的无人机路径规划方法，旨在最小化飞行距离并最大化蜂窝连接质量。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在BVLoS飞行中蜂窝通信受限的问题，提升其飞行安全和可靠性。

Method: 使用强化学习训练智能体，以无人机与基站的通信链路质量作为奖励函数。

Result: 仿真结果显示该方法能有效训练智能体并生成可行的路径规划。

Conclusion: 该方法可整合到未来的地面控制系统中，为复杂长距离无人机任务提供支持。

Abstract: This paper presents a reinforcement learning (RL) based approach for path
planning of cellular connected unmanned aerial vehicles (UAVs) operating beyond
visual line of sight (BVLoS). The objective is to minimize travel distance
while maximizing the quality of cellular link connectivity by considering real
world aerial coverage constraints and employing an empirical aerial channel
model. The proposed solution employs RL techniques to train an agent, using the
quality of communication links between the UAV and base stations (BSs) as the
reward function. Simulation results demonstrate the effectiveness of the
proposed method in training the agent and generating feasible UAV path plans.
The proposed approach addresses the challenges due to limitations in UAV
cellular communications, highlighting the need for investigations and
considerations in this area. The RL algorithm efficiently identifies optimal
paths, ensuring maximum connectivity with ground BSs to ensure safe and
reliable BVLoS flight operation. Moreover, the solution can be deployed as an
offline path planning module that can be integrated into future ground control
systems (GCS) for UAV operations, enhancing their capabilities and safety. The
method holds potential for complex long range UAV applications, advancing the
technology in the field of cellular connected UAV path planning.

</details>


### [21] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

TL;DR: 改进现有视觉RGB图像的机器人姿态深度神经网络，通过扩展损失函数结合位置和旋转误差提高鲁棒性，定位精度在室内场景中提升。


<details>
  <summary>Details</summary>
Motivation: 通过改进网络损失函数，提高机器人在视觉信息下的定位精度和训练效率。

Method: 扩展网络的损失函数，结合位置和旋转误差，并使用摄影测量数据生成带标签的数据集。

Result: 室内场景中定位误差中位数分别降低了9.64%（位置）和2.99%（旋转），并实现了0.11米和0.89度的定位精度。

Conclusion: 提出了一套完整的鲁棒导航算法流程，适用于任意室内场景。

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


### [22] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

TL;DR: 研究使用基于Point-JEPA的自监督预训练方法，在低标签数据下高效预测抓取关节角度，结果显示其效果与全监督相当。


<details>
  <summary>Details</summary>
Motivation: 探索自监督预训练方法（Point-JEPA）在抓取关节角度预测任务中的有效性，尤其在低标签数据下。

Method: 利用mesh生成的点云令牌化和预训练的Point-JEPA编码器，训练轻量级多假设头部，通过top-logit选择评估。

Result: 在DLR-Hand II数据集中，Point-JEPA在低标签条件下降低了26%的RMSE，并与全监督效果相当。

Conclusion: JEPA式预训练是一种实用的抓取学习方法，尤其在数据有限的情况下。

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [23] [Using role-play and Hierarchical Task Analysis for designing human-robot interaction](https://arxiv.org/abs/2509.13378)
*Mattias Wingren,Sören Andersson,Sara Rosenberg,Malin Andtfolk,Susanne Hägglund,Prashani Jayasingha Arachchige,Linda Nyholm*

Main category: cs.RO

TL;DR: 论文提倡在人类-机器人交互中更广泛应用角色扮演和层次任务分析，并以社区药房机器人项目为例展示了其优势。


<details>
  <summary>Details</summary>
Motivation: 探索角色扮演和层次任务分析在人类-机器人交互领域的潜力，以改善交互设计和开发过程。

Method: 采用角色扮演和层次任务分析两种方法，通过社区药房机器人项目进行实践和应用。

Result: 角色扮演提供了可控环境以理解用户需求，层次任务分析确保了行为建模的正确性并促进了共同设计。

Conclusion: 未来研究可专注于开发更适合社交机器人交互的任务分析方法。

Abstract: We present the use of two methods we believe warrant more use than they
currently have in the field of human-robot interaction: role-play and
Hierarchical Task Analysis. Some of its potential is showcased through our use
of them in an ongoing research project which entails developing a robot
application meant to assist at a community pharmacy. The two methods have
provided us with several advantages. The role-playing provided a controlled and
adjustable environment for understanding the customers' needs where pharmacists
could act as models for the robot's behavior; and the Hierarchical Task
Analysis ensured the behavior displayed was modelled correctly and aided
development through facilitating co-design. Future research could focus on
developing task analysis methods especially suited for social robot
interaction.

</details>


### [24] [ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy](https://arxiv.org/abs/2509.13380)
*Alejandro D. Mousist*

Main category: cs.RO

TL;DR: 本文介绍了ASTREA，首个在飞行硬件上部署的自主航天器操作系统，结合了资源受限的大型语言模型（LLM）与强化学习控制器，通过地面实验验证了其在热控制中的有效性，但在轨验证中因推理延迟问题导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 解决航天器自主操作中的热控制问题，探索LLM与自适应控制结合的可行性。

Method: 采用异步架构，将资源受限的LLM与强化学习控制器结合，应用于空间平台。

Result: 地面实验显示LLM监督提高了热稳定性，但在轨验证中因推理延迟问题性能下降。

Conclusion: LLM代理系统在航天器自主操作中具有潜力，但需优化推理延迟以适合快速热循环环境。

Abstract: This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.

</details>


### [25] [Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach](https://arxiv.org/abs/2509.13381)
*Zhang Xueyao,Yang Bo,Yu Zhiwen,Cao Xuelin,George C. Alexandropoulos,Merouane Debbah,Chau Yuen*

Main category: cs.RO

TL;DR: 提出了一种分层多代理近端策略优化（H-MAPPO）框架，用于高效且隐蔽的水下协作任务。


<details>
  <summary>Details</summary>
Motivation: 在敌对环境中，如何在确保隐蔽操作的同时实现高效协作是水下任务的关键挑战。

Method: 采用双时间尺度分层框架，高层决定任务参与者，低层通过功率和轨迹控制减少暴露概率。

Result: 仿真显示该框架收敛快、性能优于基准算法，并能在隐蔽操作的同时最大化长期协作效率。

Conclusion: H-MAPPO框架成功解决了水下协作任务中的隐蔽与效率平衡问题。

Abstract: Autonomous Underwater Vehicles (AUVs) have shown great potential for
cooperative detection and reconnaissance. However, collaborative AUV
communications introduce risks of exposure. In adversarial environments,
achieving efficient collaboration while ensuring covert operations becomes a
key challenge for underwater cooperative missions. In this paper, we propose a
novel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization
(H-MAPPO) framework. The high-level component determines the individuals
participating in the task based on a central AUV, while the low-level component
reduces exposure probabilities through power and trajectory control by the
participating AUVs. Simulation results show that the proposed framework
achieves rapid convergence, outperforms benchmark algorithms in terms of
performance, and maximizes long-term cooperative efficiency while ensuring
covert operations.

</details>


### [26] [VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization](https://arxiv.org/abs/2509.13386)
*Hansol Lim,Minhyeok Im,Jonathan Boyack,Jee Won Lee,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: VEGA是一个基于AI的电动汽车导航系统，通过物理信息神经网络和强化学习优化充电路径，无需额外传感器，表现接近Tesla Trip Planner，且具有泛化能力。


<details>
  <summary>Details</summary>
Motivation: 电动汽车需求增长，SDV技术发展催生了更智能的充电路径优化需求，VEGA旨在通过AI和实时车辆数据实现高效导航。

Method: VEGA结合物理信息神经网络（PINO）和强化学习（RL）模块，前者学习车辆动态，后者优化充电路径。使用PPO算法和A*指导。

Result: VEGA在长途路线（如纽约到旧金山）中表现接近Tesla Trip Planner，充电策略保守但适应性强，且在法国和日本也适用。

Conclusion: VEGA成功融合物理信息学习和强化学习，为电动汽车提供了一种低成本、高效的生态路径优化方案，具有广泛适用性。

Abstract: Demands for software-defined vehicles (SDV) are rising and electric vehicles
(EVs) are increasingly being equipped with powerful computers. This enables
onboard AI systems to optimize charge-aware path optimization customized to
reflect vehicle's current condition and environment. We present VEGA, a
charge-aware EV navigation agent that plans over a charger-annotated road graph
using Proximal Policy Optimization (PPO) with budgeted A* teacher-student
guidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.
First, a physics-informed neural operator (PINO), trained on real vehicle speed
and battery-power logs, uses recent vehicle speed logs to estimate aerodynamic
drag, rolling resistance, mass, motor and regenerative-braking efficiencies,
and auxiliary load by learning a vehicle-custom dynamics. Second, a
Reinforcement Learning (RL) agent uses these dynamics to optimize a path with
optimal charging stops and dwell times under SoC constraints. VEGA requires no
additional sensors and uses only vehicle speed signals. It may serve as a
virtual sensor for power and efficiency to potentially reduce EV cost. In
evaluation on long routes like San Francisco to New York, VEGA's stops, dwell
times, SoC management, and total travel time closely track Tesla Trip Planner
while being slightly more conservative, presumably due to real vehicle
conditions such as vehicle parameter drift due to deterioration. Although
trained only in U.S. regions, VEGA was able to compute optimal charge-aware
paths in France and Japan, demonstrating generalizability. It achieves
practical integration of physics-informed learning and RL for EV eco-routing.

</details>


### [27] [A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies](https://arxiv.org/abs/2509.13434)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 提出了一种模拟细丝与刚体接触交互的计算框架，解决了现有方法无法处理的摩擦交互问题。


<details>
  <summary>Details</summary>
Motivation: 由于细丝的低维特性，现有模拟方法常假设其永久附着于刚体，无法准确模拟摩擦交互。

Method: 结合离散弹性杆模型、压力场接触模型和凸接触公式，实现细丝与刚体的精确摩擦模拟。

Result: 通过凸接触公式，每步求解可达到全局最优，验证了摩擦力准确性并展示了软机器人和变形物体操纵的应用。

Conclusion: 该框架为复杂细丝交互系统提供了通用模拟器，具备高物理保真度和应用潜力。

Abstract: We present a computational framework for simulating filaments interacting
with rigid bodies through contact. Filaments are challenging to simulate due to
their codimensionality, i.e., they are one-dimensional structures embedded in
three-dimensional space. Existing methods often assume that filaments remain
permanently attached to rigid bodies. Our framework unifies discrete elastic
rod (DER) modeling, a pressure field patch contact model, and a convex contact
formulation to accurately simulate frictional interactions between slender
filaments and rigid bodies - capabilities not previously achievable. Owing to
the convex formulation of contact, each time step can be solved to global
optimality, guaranteeing complementarity between contact velocity and impulse.
We validate the framework by assessing the accuracy of frictional forces and
comparing its physical fidelity against baseline methods. Finally, we
demonstrate its applicability in both soft robotics, such as a stochastic
filament-based gripper, and deformable object manipulation, such as shoelace
tying, providing a versatile simulator for systems involving complex
filament-filament and filament-rigid body interactions.

</details>


### [28] [Trajectory Tracking with Reachability-Guided Quadratic Programming and Freeze-Resume](https://arxiv.org/abs/2509.13501)
*Hossein Gholampour,Logan E. Beaver*

Main category: cs.RO

TL;DR: 提出了一种针对反馈线性化为双积分器的机器人系统的输出空间方法，确保其在遵循路径时能安全暂停并恢复。


<details>
  <summary>Details</summary>
Motivation: 机器人系统在路径跟踪中需要安全应对人为或物体干预，同时确保速度和加速度限制内运行。

Method: 离线进行可达性检查验证运动计划，在线使用二次规划跟踪路径，并通过一步可达性测试限制扰动。

Result: 系统能高效处理安全停止和非计划偏离，无需重新规划即可恢复跟踪。

Conclusion: 该方法在仿真中表现出优于纯追踪的性能，适用于需要安全路径跟踪的场景。

Abstract: Many robotic systems must follow planned paths yet pause safely and resume
when people or objects intervene. We present an output-space method for systems
whose tracked output can be feedback-linearized to a double integrator (e.g.,
manipulators). The approach has two parts. Offline, we perform a pre-run
reachability check to verify that the motion plan respects speed and
acceleration magnitude limits. Online, we apply a quadratic program to track
the motion plan under the same limits. We use a one-step reachability test to
bound the maximum disturbance the system is capable of rejecting. When the
state coincides with the reference path we recover perfect tracking in the
deterministic case, and we correct errors using a KKT-inspired weight. We
demonstrate that safety stops and unplanned deviations are handled efficiently,
and the system returns to the motion plan without replanning. We demonstrate
our system's improved performance over pure pursuit in simulation.

</details>


### [29] [Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning](https://arxiv.org/abs/2509.13534)
*Chunxin Zheng,Kai Chen,Zhihai Bi,Yulin Li,Liang Pan,Jinni Zhou,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种结合预训练人类运动先验和神经符号距离场（NSDF）的强化学习框架，用于人形机器人全身包裹任务，提升了操作的稳定性和负载能力。


<details>
  <summary>Details</summary>
Motivation: 传统抓取方法在涉及大型物体时受限于稳定性和负载能力，而全身操作（WBM）为解决这一问题提供了新思路。

Method: 采用教师-学生架构从大规模人类运动数据中蒸馏出自然且物理可行的全身运动模式，并结合NSDF提供精确的几何感知。

Result: 仿真和实验表明，该方法能适应不同形状和大小的物体，并成功实现了仿真到现实的迁移。

Conclusion: 该框架为人形机器人的多接触和长时程全身操作任务提供了有效且实用的解决方案。

Abstract: Whole-body manipulation (WBM) for humanoid robots presents a promising
approach for executing embracing tasks involving bulky objects, where
traditional grasping relying on end-effectors only remains limited in such
scenarios due to inherent stability and payload constraints. This paper
introduces a reinforcement learning framework that integrates a pre-trained
human motion prior with a neural signed distance field (NSDF) representation to
achieve robust whole-body embracing. Our method leverages a teacher-student
architecture to distill large-scale human motion data, generating kinematically
natural and physically feasible whole-body motion patterns. This facilitates
coordinated control across the arms and torso, enabling stable multi-contact
interactions that enhance the robustness in manipulation and also the load
capacity. The embedded NSDF further provides accurate and continuous geometric
perception, improving contact awareness throughout long-horizon tasks. We
thoroughly evaluate the approach through comprehensive simulations and
real-world experiments. The results demonstrate improved adaptability to
diverse shapes and sizes of objects and also successful sim-to-real transfer.
These indicate that the proposed framework offers an effective and practical
solution for multi-contact and long-horizon WBM tasks of humanoid robots.

</details>


### [30] [Semantic 3D Reconstructions with SLAM for Central Airway Obstruction](https://arxiv.org/abs/2509.13541)
*Ayberk Acar,Fangjie Li,Hao Li,Lidia Al-Zogbi,Kanyifeechukwu Jane Oguine,Susheela Sharma Stern,Jesse F. d'Almeida,Robert J. Webster III,Ipek Oguz,Jie Ying Wu*

Main category: cs.RO

TL;DR: 提出了一种新方法，结合实时单目SLAM和语义分割，用于中央气道阻塞的3D重建，提高了手术精确度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统治疗中央气道阻塞的方法风险高，新方法通过机器人和自动化为手术提供更安全、精确的解决方案。

Method: 结合DROID-SLAM和分割模型，实时重建气道3D几何并标注阻塞区域，验证通过体外模型与CT扫描对比。

Result: 重建结果与CT扫描高度相似（0.62 mm Chamfer距离），实时生成标注的3D地图，速度快于以往方法。

Conclusion: 首次将语义分割与实时单目SLAM结合用于内镜CAO，框架模块化，可扩展至其他解剖或手术，迈向自主机器人干预的重要一步。

Abstract: Central airway obstruction (CAO) is a life-threatening condition with
increasing incidence, caused by tumors in and outside of the airway.
Traditional treatment methods such as bronchoscopy and electrocautery can be
used to remove the tumor completely; however, these methods carry a high risk
of complications. Recent advances allow robotic interventions with lesser risk.
The combination of robot interventions with scene understanding and mapping
also opens up the possibilities for automation. We present a novel pipeline
that enables real-time, semantically informed 3D reconstructions of the central
airway using monocular endoscopic video.
  Our approach combines DROID-SLAM with a segmentation model trained to
identify obstructive tissues. The SLAM module reconstructs the 3D geometry of
the airway in real time, while the segmentation masks guide the annotation of
obstruction regions within the reconstructed point cloud. To validate our
pipeline, we evaluate the reconstruction quality using ex vivo models.
  Qualitative and quantitative results show high similarity between ground
truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By
integrating segmentation directly into the SLAM workflow, our system produces
annotated 3D maps that highlight clinically relevant regions in real time.
High-speed capabilities of the pipeline allows quicker reconstructions compared
to previous work, reflecting the surgical scene more accurately.
  To the best of our knowledge, this is the first work to integrate semantic
segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our
framework is modular and can generalize to other anatomies or procedures with
minimal changes, offering a promising step toward autonomous robotic
interventions.

</details>


### [31] [Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference](https://arxiv.org/abs/2509.13572)
*Ozan Karaali,Hossam Farag,Strahinja Dosen,Cedomir Stefanovic*

Main category: cs.RO

TL;DR: 研究探讨了利用视觉语言模型（VLM）提升半自主假手的感知能力，通过端到端感知和抓取推理的统一基准测试，评估VLM在单幅图像中完成复杂任务的能力。


<details>
  <summary>Details</summary>
Motivation: 旨在简化假手的感知与控制流程，减少传统方法中多个独立模块的需求，提升效率和实用性。

Method: 测试了八种现代VLM在完成统一任务上的表现，任务包括识别物体属性（名称、形状等）和推断抓取参数（抓握类型、手部旋转等），使用结构化JSON输出和34张常见物体图像。

Result: 模型在物体识别和形状判断上表现优异，但在尺寸估计和抓取参数推断（如手部旋转和开合度）上准确率波动较大。

Conclusion: 研究表明VLM在假肢感知模块中具有潜力，但仍需在复杂参数推断上进一步优化。

Abstract: This study examines the potential of utilizing Vision Language Models (VLMs)
to improve the perceptual capabilities of semi-autonomous prosthetic hands. We
introduce a unified benchmark for end-to-end perception and grasp inference,
evaluating a single VLM to perform tasks that traditionally require complex
pipelines with separate modules for object detection, pose estimation, and
grasp planning. To establish the feasibility and current limitations of this
approach, we benchmark eight contemporary VLMs on their ability to perform a
unified task essential for bionic grasping. From a single static image, they
should (1) identify common objects and their key properties (name, shape,
orientation, and dimensions), and (2) infer appropriate grasp parameters (grasp
type, wrist rotation, hand aperture, and number of fingers). A corresponding
prompt requesting a structured JSON output was employed with a dataset of 34
snapshots of common objects. Key performance metrics, including accuracy for
categorical attributes (e.g., object name, shape) and errors in numerical
estimates (e.g., dimensions, hand aperture), along with latency and cost, were
analyzed. The results demonstrated that most models exhibited high performance
in object identification and shape recognition, while accuracy in estimating
dimensions and inferring optimal grasp parameters, particularly hand rotation
and aperture, varied more significantly. This work highlights the current
capabilities and limitations of VLMs as advanced perceptual modules for
semi-autonomous control of bionic limbs, demonstrating their potential for
effective prosthetic applications.

</details>


### [32] [Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation](https://arxiv.org/abs/2509.13574)
*Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian*

Main category: cs.RO

TL;DR: 本文针对机器人流匹配框架中的泛化问题和推断性能下降现象，提出了非均匀时间调度和密集跳跃积分策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现流匹配框架中泛化能力早期饱和，且增加积分步数会降低策略性能，需要解决积分步数设计与场不稳定性问题。

Method: 提出非均匀时间调度训练策略以加强早期和晚期时间阶段的学习，并采用密集跳跃积分策略避免不稳定区域。

Result: 新策略在多种任务中性能提升23.7%，优于现有基准方法。

Conclusion: 通过优化时间调度和积分策略，提升了流匹配框架的性能和泛化能力。

Abstract: Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.

</details>


### [33] [TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning](https://arxiv.org/abs/2509.13579)
*Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu*

Main category: cs.RO

TL;DR: TreeIRL是一种结合蒙特卡洛树搜索（MCTS）和逆向强化学习（IRL）的自动驾驶规划器，旨在实现高性能的模拟和现实驾驶。它通过MCTS生成安全候选轨迹，再通过深度IRL评分选择最接近人类驾驶的方案。实验证明其在多样场景中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶规划中的复杂性和安全问题，研究结合了经典的MCTS和基于学习的IRL，旨在实现安全、高效且接近人类驾驶的行为。

Method: 方法基于MCTS生成安全候选轨迹，结合深度IRL评分选择最优方案。

Result: 在模拟和拉斯维加斯500+英里实际驾驶测试中，TreeIRL在安全、进度、舒适性和人类相似性方面表现最佳。

Conclusion: 研究首次展示了MCTS在公共道路上的应用潜力，并提出结合经典与学习方法的框架，为自动驾驶规划提供了新方向。

Abstract: We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.

</details>


### [34] [Object Pose Estimation through Dexterous Touch](https://arxiv.org/abs/2509.13591)
*Amir-Hossein Shahidzadeh,Jiyue Zhu,Kezhou Chen,Sha Yi,Cornelia Fermüller,Yiannis Aloimonos,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习的机器人触觉感知方法，用于在视觉数据受限的情况下估计物体位姿。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作任务中，物体位姿的鲁棒估计是关键，尤其在视觉数据受限或易受光照、遮挡和外观影响时。触觉传感器提供的信息有限且局部，难以从部分数据重建位姿。

Method: 利用强化学习主动控制机器人手与物体交互，收集触觉数据并生成3D点云，迭代优化物体形状和位姿。实验采用双手协作，一只手固定物体，另一只手主动探索。

Result: 该方法能够在无物体几何先验知识的情况下，通过主动探索物体表面识别关键位姿特征。

Conclusion: 该方法通过触觉感知和强化学习实现了对物体位姿的有效估计，适用于视觉受限场景。

Abstract: Robust object pose estimation is essential for manipulation and interaction
tasks in robotics, particularly in scenarios where visual data is limited or
sensitive to lighting, occlusions, and appearances. Tactile sensors often offer
limited and local contact information, making it challenging to reconstruct the
pose from partial data. Our approach uses sensorimotor exploration to actively
control a robot hand to interact with the object. We train with Reinforcement
Learning (RL) to explore and collect tactile data. The collected 3D point
clouds are used to iteratively refine the object's shape and pose. In our
setup, one hand holds the object steady while the other performs active
exploration. We show that our method can actively explore an object's surface
to identify critical pose features without prior knowledge of the object's
geometry. Supplementary material and more demonstrations will be provided at
https://amirshahid.github.io/BimanualTactilePose .

</details>


### [35] [Leg-Arm Coordinated Operation for Curtain Wall Installation](https://arxiv.org/abs/2509.13595)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 提出了一种基于分层优化的六足幕墙安装机器人全身控制框架，解决传统幕墙安装方法的劳动强度大、效率低和安全风险高等问题。


<details>
  <summary>Details</summary>
Motivation: 城市化加速导致高层建筑和大公共设施增多，传统幕墙安装方法面临地形多变、效率低和安全风险高等挑战。

Method: 设计了一种六足机器人分层优化的全身控制框架，结合腿部运动与折叠臂和串并联机械臂操作，解决幕墙安装任务中的协调规划问题。

Result: 实验验证了该控制方法的有效性，六足机器人能够完成幕墙安装任务。

Conclusion: 分层优化的臂腿协调框架为六足机器人在复杂施工环境中的应用奠定了基础。

Abstract: With the acceleration of urbanization, the number of high-rise buildings and
large public facilities is increasing, making curtain walls an essential
component of modern architecture with widespread applications. Traditional
curtain wall installation methods face challenges such as variable on-site
terrain, high labor intensity, low construction efficiency, and significant
safety risks. Large panels often require multiple workers to complete
installation. To address these issues, based on a hexapod curtain wall
installation robot, we design a hierarchical optimization-based whole-body
control framework for coordinated arm-leg planning tailored to three key tasks:
wall installation, ceiling installation, and floor laying. This framework
integrates the motion of the hexapod legs with the operation of the folding arm
and the serial-parallel manipulator. We conduct experiments on the hexapod
curtain wall installation robot to validate the proposed control method,
demonstrating its capability in performing curtain wall installation tasks. Our
results confirm the effectiveness of the hierarchical optimization-based
arm-leg coordination framework for the hexapod robot, laying the foundation for
its further application in complex construction site environments.

</details>


### [36] [Barometer-Aided Attitude Estimation](https://arxiv.org/abs/2509.13649)
*Méloné Nyoba Tchonkeu,Soulaimane Berkane,Tarek Hamel*

Main category: cs.RO

TL;DR: 该论文提出了一种基于气压计的姿态估计方法，用于在GNSS信号缺失或动态环境中提高自主车辆的姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号缺失或高度动态的环境中，惯性测量单元（IMUs）的姿态估计因重力与惯性加速度的模糊性而不够可靠。辅助传感器或成本高或不可靠，因此需要一种轻量且有效的替代方案。

Method: 采用气压计辅助的非线性观测器设计，结合确定性Riccati观测器和互补滤波器，确保在均匀可观测条件下实现几乎全局渐进稳定性（AGAS）。

Result: 气压计辅助的姿态估计被证明是一种轻量且有效的补充方式，能够提升姿态估计的鲁棒性。

Conclusion: 该方法在几何一致性和稳定性方面表现优异，为GNSS缺失环境下的姿态估计提供了一种实用解决方案。

Abstract: Accurate and robust attitude estimation is a central challenge for autonomous
vehicles operating in GNSS-denied or highly dynamic environments. In such
cases, Inertial Measurement Units (IMUs) alone are insufficient for reliable
tilt estimation due to the ambiguity between gravitational and inertial
accelerations. While auxiliary velocity sensors, such as GNSS, Pitot tubes,
Doppler radar, or visual odometry, are often used, they can be unavailable,
intermittent, or costly. This work introduces a barometer-aided attitude
estimation architecture that leverages barometric altitude measurements to
infer vertical velocity and attitude within a nonlinear observer on SO(3). The
design cascades a deterministic Riccati observer with a complementary filter,
ensuring Almost Global Asymptotic Stability (AGAS) under a uniform
observability condition while maintaining geometric consistency. The analysis
highlights barometer-aided estimation as a lightweight and effective
complementary modality.

</details>


### [37] [DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](https://arxiv.org/abs/2509.13666)
*Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin*

Main category: cs.RO

TL;DR: DREAM是一种基于视觉语言模型（VLM）的自主框架，用于长期水下探索和栖息地监测，显著提高了目标物（如牡蛎、沉船）的发现和探索效率。


<details>
  <summary>Details</summary>
Motivation: 海洋变暖和酸化增加了对温度敏感的贝类（如牡蛎）大规模死亡的风险，需要长期监测系统，但人工成本高且危险，机器人解决方案更安全高效。

Method: 提出DREAM框架，利用VLM指导水下机器人自主决策，实现无人工干预的实时环境感知。

Result: 在牡蛎监测任务中，框架比基线节省31.5%时间；比普通VLM少用23%步骤，覆盖范围增加8.88%。在沉船场景中，框架实现100%覆盖率，普通VLM仅为60.23%。

Conclusion: DREAM框架显著提升了水下监测的效率和覆盖率，为长期、大面积、低成本的海底监测提供了可行方案。

Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.

</details>


### [38] [SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics](https://arxiv.org/abs/2509.13691)
*Songhao Huang,Yuwei Wu,Guangyao Shi,Gaurav S. Sukhatme,Vijay Kumar*

Main category: cs.RO

TL;DR: 该论文提出了一个利用大型语言模型(LLMs)自动生成规划领域定义语言(PDDL)的框架SPAR，专注于无人机(UAV)任务，通过自然语言输入生成高质量PDDL领域，解决了手动设计复杂问题。


<details>
  <summary>Details</summary>
Motivation: PDDL是机器人规划中的通用语言，但手动设计领域既耗时又易出错，限制了实际应用和部署。

Method: 研究者构建了一个系统验证的UAV规划数据集，结合LLMs生成能力，设计了一个提示框架来自动生成PDDL领域。

Result: 生成的领域通过语法验证、可执行性、可行性和可解释性评估，证明了LLMs可以显著加速复杂规划领域的创建。

Conclusion: SPAR框架为无经验的专家提供了实用工具，促进了无人机任务和自动化规划的未来研究。

Abstract: We investigate the problem of automatic domain generation for the Planning
Domain Definition Language (PDDL) using Large Language Models (LLMs), with a
particular focus on unmanned aerial vehicle (UAV) tasks. Although PDDL is a
widely adopted standard in robotic planning, manually designing domains for
diverse applications such as surveillance, delivery, and inspection is
labor-intensive and error-prone, which hinders adoption and real-world
deployment. To address these challenges, we propose SPAR, a framework that
leverages the generative capabilities of LLMs to automatically produce valid,
diverse, and semantically accurate PDDL domains from natural language input. To
this end, we first introduce a systematically formulated and validated UAV
planning dataset, consisting of ground-truth PDDL domains and associated
problems, each paired with detailed domain and action descriptions. Building on
this dataset, we design a prompting framework that generates high-quality PDDL
domains from language input. The generated domains are evaluated through syntax
validation, executability, feasibility, and interpretability. Overall, this
work demonstrates that LLMs can substantially accelerate the creation of
complex planning domains, providing a reproducible dataset and evaluation
pipeline that enables application experts without prior experience to leverage
it for practical tasks and advance future research in aerial robotics and
automated planning.

</details>


### [39] [HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion](https://arxiv.org/abs/2509.13692)
*Yadan Zeng,Jiadong Zhou,Xiaohan Li,I-Ming Chen*

Main category: cs.RO

TL;DR: HGACNet是一种用于点云补全的新框架，通过分层编码3D几何特征并与单视RGB图像的图像引导先验融合，实现对单个物体完整点云的重建。


<details>
  <summary>Details</summary>
Motivation: 点云补全对于机器人感知、物体重建以及支持抓取规划、避障和操作等下游任务至关重要，但自遮挡和传感器限制导致的不完整几何会显著降低这些任务的性能。

Method: 提出HGACNet框架，核心包括分层图注意力（HGA）编码器，通过基于图注意力的下采样自适应选择关键局部点，并通过跨模态融合模块（MSCF）对齐几何特征与视觉表示。此外，还设计了对比损失（C-Loss）以显式对齐跨模态特征分布。

Result: 在ShapeNet-ViPC和YCB-Complete数据集上的实验表明，HGACNet具有最先进的性能，并在实际机器人操作任务中表现出强适用性。

Conclusion: HGACNet通过分层几何特征提取和跨模态融合，显著提升了点云补全的准确性和实用性。

Abstract: Point cloud completion is essential for robotic perception, object
reconstruction and supporting downstream tasks like grasp planning, obstacle
avoidance, and manipulation. However, incomplete geometry caused by
self-occlusion and sensor limitations can significantly degrade downstream
reasoning and interaction. To address these challenges, we propose HGACNet, a
novel framework that reconstructs complete point clouds of individual objects
by hierarchically encoding 3D geometric features and fusing them with
image-guided priors from a single-view RGB image. At the core of our approach,
the Hierarchical Graph Attention (HGA) encoder adaptively selects critical
local points through graph attention-based downsampling and progressively
refines hierarchical geometric features to better capture structural continuity
and spatial relationships. To strengthen cross-modal interaction, we further
design a Multi-Scale Cross-Modal Fusion (MSCF) module that performs
attention-based feature alignment between hierarchical geometric features and
structured visual representations, enabling fine-grained semantic guidance for
completion. In addition, we proposed the contrastive loss (C-Loss) to
explicitly align the feature distributions across modalities, improving
completion fidelity under modality discrepancy. Finally, extensive experiments
conducted on both the ShapeNet-ViPC benchmark and the YCB-Complete dataset
confirm the effectiveness of HGACNet, demonstrating state-of-the-art
performance as well as strong applicability in real-world robotic manipulation
tasks.

</details>


### [40] [EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility](https://arxiv.org/abs/2509.13720)
*Tianle Zeng,Jianwei Peng,Hanjing Ye,Guangcheng Chen,Senzi Luo,Hong Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种轻量级的闭环系统，用于解决大规模户外环境中零样本物体导航（ZSON）的长距离目标和间歇性可见性问题，通过多尺度图像块层次结构和目标显著性融合，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 在大规模户外环境中，零样本物体导航面临长距离目标缩小为极小投影以及间歇性可见性的挑战，论文旨在解决这些问题。

Method: 使用对齐的多尺度图像块层次结构，通过层次化目标显著性融合，将局部语义对比汇总为稳定的粗层区域显著性，从而提供目标方向和可见性指示。此外，系统通过关键帧记忆、显著性加权的历史航向融合以及在暂时不可见时的主动搜索，实现了可见性感知的航向维持。

Result: 系统在仿真和真实世界的户外试验中，能够检测150米以上的语义目标，通过可见性变化时保持正确航向的概率为82.6%，并将整体任务成功率提升了17.5%。

Conclusion: 该系统有效地实现了对远距离和间歇性可见目标的稳健零样本物体导航，性能优于现有技术。

Abstract: Zero-shot object navigation (ZSON) in large-scale outdoor environments faces
many challenges; we specifically address a coupled one: long-range targets that
reduce to tiny projections and intermittent visibility due to partial or
complete occlusion. We present a unified, lightweight closed-loop system built
on an aligned multi-scale image tile hierarchy. Through hierarchical
target-saliency fusion, it summarizes localized semantic contrast into a stable
coarse-layer regional saliency that provides the target direction and indicates
target visibility. This regional saliency supports visibility-aware heading
maintenance through keyframe memory, saliency-weighted fusion of historical
headings, and active search during temporary invisibility. The system avoids
whole-image rescaling, enables deterministic bottom-up aggregation, supports
zero-shot navigation, and runs efficiently on a mobile robot. Across simulation
and real-world outdoor trials, the system detects semantic targets beyond 150m,
maintains a correct heading through visibility changes with 82.6% probability,
and improves overall task success by 17.5% compared with the SOTA methods,
demonstrating robust ZSON toward distant and intermittently observable targets.

</details>


### [41] [Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings](https://arxiv.org/abs/2509.13731)
*Jeongwoo Park,Seabin Lee,Changmin Park,Wonjong Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的柔性扁平电缆插入方法，利用基础模型实现模拟到真实的迁移，减少训练时间和物理风险。


<details>
  <summary>Details</summary>
Motivation: 工业中柔性扁平电缆插入需要高精度，传统方法耗时且有风险。

Method: 结合强化学习和基础模型（SAM2），在模拟中训练，利用视觉语言模型自动分割掩码。

Result: 方法展示了零样本能力，可直接部署到真实环境。

Conclusion: 该方法有效解决了柔性扁平电缆插入的自动化问题，提升了效率和安全性。

Abstract: The industrial insertion of flexible flat cables (FFCs) into receptacles
presents a significant challenge owing to the need for submillimeter precision
when handling the deformable cables. In manufacturing processes, FFC insertion
with robotic manipulators often requires laborious human-guided trajectory
generation. While Reinforcement Learning (RL) offers a solution to automate
this task without modeling complex properties of FFCs, the nondeterminism
caused by the deformability of FFCs requires significant efforts and time on
training. Moreover, training directly in a real environment is dangerous as
industrial robots move fast and possess no safety measure. We propose an RL
algorithm for FFC insertion that leverages a foundation model-based real-to-sim
approach to reduce the training time and eliminate the risk of physical damages
to robots and surroundings. Training is done entirely in simulation, allowing
for random exploration without the risk of physical damages. Sim-to-real
transfer is achieved through semantic segmentation masks which leave only those
visual features relevant to the insertion tasks such as the geometric and
spatial information of the cables and receptacles. To enhance generality, we
use a foundation model, Segment Anything Model 2 (SAM2). To eleminate human
intervention, we employ a Vision-Language Model (VLM) to automate the initial
prompting of SAM2 to find segmentation masks. In the experiments, our method
exhibits zero-shot capabilities, which enable direct deployments to real
environments without fine-tuning.

</details>


### [42] [FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph](https://arxiv.org/abs/2509.13733)
*Xiaolin Zhou,Tingyang Xiao,Liu Liu,Yucheng Wang,Maiyue Chen,Xinrui Meng,Xinjie Wang,Wei Feng,Wei Sui,Zhizhong Su*

Main category: cs.RO

TL;DR: FSR-VLN提出了一种结合分层多模态场景图和快慢导航推理的视觉语言导航系统，显著提升了长距离导航任务的性能和响应速度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航系统在长距离空间推理上表现不佳，成功率和推理延迟问题突出，亟需改进。

Method: 采用分层多模态场景图（HMSG）提供多模态地图表示，并引入快慢导航推理（FSR）机制，先快速匹配候选目标再精细筛选。

Result: FSR-VLN在四个室内数据集上均达到SOTA性能，检索成功率高，响应时间比现有方法减少82%。

Conclusion: FSR-VLN通过高效的空间推理和自然语言交互，显著提升了机器人导航能力，具有实际部署潜力。

Abstract: Visual-Language Navigation (VLN) is a fundamental challenge in robotic
systems, with broad applications for the deployment of embodied agents in
real-world environments. Despite recent advances, existing approaches are
limited in long-range spatial reasoning, often exhibiting low success rates and
high inference latency, particularly in long-range navigation tasks. To address
these limitations, we propose FSR-VLN, a vision-language navigation system that
combines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow
Navigation Reasoning (FSR). The HMSG provides a multi-modal map representation
supporting progressive retrieval, from coarse room-level localization to
fine-grained goal view and object identification. Building on HMSG, FSR first
performs fast matching to efficiently select candidate rooms, views, and
objects, then applies VLM-driven refinement for final goal selection. We
evaluated FSR-VLN across four comprehensive indoor datasets collected by
humanoid robots, utilizing 87 instructions that encompass a diverse range of
object categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all
datasets, measured by the retrieval success rate (RSR), while reducing the
response time by 82% compared to VLM-based methods on tour videos by activating
slow reasoning only when fast intuition fails. Furthermore, we integrate
FSR-VLN with speech interaction, planning, and control modules on a Unitree-G1
humanoid robot, enabling natural language interaction and real-time navigation.

</details>


### [43] [Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning](https://arxiv.org/abs/2509.13736)
*Muyuan Ma,Long Cheng,Lijun Han,Xiuze Xia,Houcheng Li*

Main category: cs.RO

TL;DR: 一种基于元模仿学习的可穿戴外骨骼辅助算法，通过神经网络预测肘部运动，结合公开数据集训练模型，显著降低新用户在未训练任务中的肌肉激活和代谢成本。


<details>
  <summary>Details</summary>
Motivation: 开发个性化的任务通用辅助算法，以解决可穿戴外骨骼在增强人力和减少疲劳方面的挑战。

Method: 采用元模仿学习框架，利用公开RGB视频和动作捕捉数据训练任务特定神经网络，通过MAML实现快速适应新任务和用户。

Result: 外骨骼显著减少新用户在未训练任务中的肌肉激活和代谢成本。

Conclusion: 该框架有效提升了可穿戴外骨骼系统的任务通用性和用户适应性。

Abstract: Wearable exoskeletons can augment human strength and reduce muscle fatigue
during specific tasks. However, developing personalized and task-generalizable
assistance algorithms remains a critical challenge. To address this, a
meta-imitation learning approach is proposed. This approach leverages a
task-specific neural network to predict human elbow joint movements, enabling
effective assistance while enhancing generalization to new scenarios. To
accelerate data collection, full-body keypoint motions are extracted from
publicly available RGB video and motion-capture datasets across multiple tasks,
and subsequently retargeted in simulation. Elbow flexion trajectories generated
in simulation are then used to train the task-specific neural network within
the model-agnostic meta-learning (MAML) framework, which allows the network to
rapidly adapt to novel tasks and unseen users with only a few gradient updates.
The adapted network outputs personalized references tracked by a
gravity-compensated PD controller to ensure stable assistance. Experimental
results demonstrate that the exoskeleton significantly reduces both muscle
activation and metabolic cost for new users performing untrained tasks,
compared to performing without exoskeleton assistance. These findings suggest
that the proposed framework effectively improves task generalization and user
adaptability for wearable exoskeleton systems.

</details>


### [44] [Dynamic Adaptive Legged Locomotion Policy via Decoupling Reaction Force Control and Gait Control](https://arxiv.org/abs/2509.13737)
*Renjie Wang,Shangke Lyu,Donglin Wang*

Main category: cs.RO

TL;DR: 论文提出了一种解耦框架，通过分离站立腿和摆动腿的控制，增强RL在腿式运动控制中的适应能力，解决了分布外条件和模拟与现实环境差异的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习在腿式运动控制中表现优异，但在分布外条件和模拟与现实环境差异时性能下降。传统方法依赖领域随机化，但效果有限。

Method: 提出解耦框架，分离站立腿和摆动腿的控制，以实现快速在线适应和缓解模拟与现实的差异。

Result: 在模拟和现实实验中，框架有效应对了水平力干扰、不平地面、大负载和模拟与现实差距。

Conclusion: 解耦框架提升了强化学习在腿式运动控制中的鲁棒性和适应性，解决了传统方法的局限性。

Abstract: While Reinforcement Learning (RL) has achieved remarkable progress in legged
locomotion control, it often suffers from performance degradation in
out-of-distribution (OOD) conditions and discrepancies between the simulation
and the real environments. Instead of mainly relying on domain randomization
(DR) to best cover the real environments and thereby close the sim-to-real gap
and enhance robustness, this work proposes an emerging decoupled framework that
acquires fast online adaptation ability and mitigates the sim-to-real problems
in unfamiliar environments by isolating stance-leg control and swing-leg
control. Various simulation and real-world experiments demonstrate its
effectiveness against horizontal force disturbances, uneven terrains, heavy and
biased payloads, and sim-to-real gap.

</details>


### [45] [CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs](https://arxiv.org/abs/2509.13771)
*Mengzhu Li,Yunyu Zhou,He Ying,F. Richard Yu*

Main category: cs.RO

TL;DR: CDFlow提出了一种基于神经ODE的新方法，解决了高自由度机器人配置空间距离场（CDF）在多模态和几何失真上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CDF方法在高自由度机器人中存在多模态梯度模糊和几何失真的问题。

Method: 使用神经ODE学习配置空间的连续流，结合自适应细化采样生成高质量训练数据。

Result: 实验表明CDFlow在运动规划效率、轨迹质量和鲁棒性上显著优于现有CDF方法。

Conclusion: CDFlow通过建模多模态分布和一致性梯度场，提升了复杂环境中机器人规划的效率和鲁棒性。

Abstract: Signed Distance Fields (SDFs) are a fundamental representation in robot
motion planning. Their configuration-space counterpart, the Configuration Space
Distance Field (CDF), directly encodes distances in joint space, offering a
unified representation for optimization and control. However, existing CDF
formulations face two major challenges in high-degree-of-freedom (DoF) robots:
(1) they effectively return only a single nearest collision configuration,
neglecting the multi-modal nature of minimal-distance collision configurations
and leading to gradient ambiguity; and (2) they rely on sparse sampling of the
collision boundary, which often fails to identify the true closest
configurations, producing oversmoothed approximations and geometric distortion
in high-dimensional spaces. We propose CDFlow, a novel framework that addresses
these limitations by learning a continuous flow in configuration space via
Neural Ordinary Differential Equations (Neural ODEs). We redefine the problem
from finding a single nearest point to modeling the distribution of
minimal-distance collision configurations. We also introduce an adaptive
refinement sampling strategy to generate high-fidelity training data for this
distribution. The resulting Neural ODE implicitly models this multi-modal
distribution and produces a smooth, consistent gradient field-derived as the
expected direction towards the distribution-that mitigates gradient ambiguity
and preserves sharp geometric features. Extensive experiments on high-DoF
motion planning tasks demonstrate that CDFlow significantly improves planning
efficiency, trajectory quality, and robustness compared to existing CDF-based
methods, enabling more robust and efficient planning for collision-aware robots
in complex environments.

</details>


### [46] [Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach](https://arxiv.org/abs/2509.13774)
*Piaopiao Jin,Qi Wang,Guokang Sun,Ziwen Cai,Pinjia He,Yangwei You*

Main category: cs.RO

TL;DR: VLA模型在机器人操作中表现良好，但在复杂任务中面临挑战。本文提出了一种基于强化学习的人机协作双执行器微调框架，结合语言命令生成新数据集，实现了高效的多任务和长时任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在复杂任务中表现不足的问题，并通过人机协作提升数据质量和适应性。

Method: 提出了双执行器框架，包括主执行器和微调执行器，结合语言命令生成新数据集，利用强化学习进行微调。

Result: 在真实多任务实验中实现了100%成功率，长时任务保持了50%成功率，多机器人训练效率提升2倍。

Conclusion: 该框架通过人机协作和强化学习显著提升了VLA模型在复杂任务中的性能。

Abstract: Vision-language-action (VLA) models demonstrate strong generalization in
robotic manipulation but face challenges in complex, real-world tasks. While
supervised fine-tuning with demonstrations is constrained by data quality,
reinforcement learning (RL) offers a promising alternative. We propose a
human-in-the-loop dual-actor fine-tuning framework grounded in RL. The
framework integrates a primary actor for robust multi-task performance with a
refinement actor for latent-space adaptation. Beyond standard physical
interventions, we introduce a lightweight talk-and-tweak scheme that converts
human corrections into semantically grounded language commands, thereby
generating a new dataset for policy learning. In real-world multi-task
experiments, our approach achieves 100% success across three tasks within 101
minutes of online fine-tuning. For long-horizon tasks, it sustains a 50%
success rate over 12 consecutive operations. Furthermore, the framework scales
effectively to multi-robot training, achieving up to a 2 times improvement in
efficiency when using dual robots. The experiment videos are available at
https://sites.google.com/view/hil-daft/.

</details>


### [47] [Behavior Foundation Model for Humanoid Robots](https://arxiv.org/abs/2509.13780)
*Weishuai Zeng,Shunlin Lu,Kangning Yin,Xiaojie Niu,Minyue Dai,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 论文提出了一种名为行为基础模型（BFM）的方法，旨在解决全身体控制（WBC）框架的任务特定性和泛化能力不足的问题。BFM通过大规模行为数据预训练，结合掩码在线蒸馏和条件变分自编码器（CVAE），实现了跨任务和技能的高效泛化和快速适应新行为的能力。


<details>
  <summary>Details</summary>
Motivation: 现有全身体控制框架依赖任务特定的奖励设计，泛化能力有限，难以应对复杂现实场景。论文通过识别跨任务的共同目标（生成引导机器人到达目标状态的行为），提出BFM以解决这些问题。

Method: BFM结合掩码在线蒸馏框架和条件变分自编码器（CVAE），预训练于大规模行为数据集，建模行为分布，支持灵活控制模式和高效学习新行为。

Result: 实验表明，BFM在仿真和真实人形机器人平台上均能泛化多样WBC任务，并快速适应新行为。

Conclusion: BFM为通用人形机器人控制提供了有前景的基础模型，显著提升了泛化能力和适应效率。

Abstract: Whole-body control (WBC) of humanoid robots has witnessed remarkable progress
in skill versatility, enabling a wide range of applications such as locomotion,
teleoperation, and motion tracking. Despite these achievements, existing WBC
frameworks remain largely task-specific, relying heavily on labor-intensive
reward engineering and demonstrating limited generalization across tasks and
skills. These limitations hinder their response to arbitrary control modes and
restrict their deployment in complex, real-world scenarios. To address these
challenges, we revisit existing WBC systems and identify a shared objective
across diverse tasks: the generation of appropriate behaviors that guide the
robot toward desired goal states. Building on this insight, we propose the
Behavior Foundation Model (BFM), a generative model pretrained on large-scale
behavioral datasets to capture broad, reusable behavioral knowledge for
humanoid robots. BFM integrates a masked online distillation framework with a
Conditional Variational Autoencoder (CVAE) to model behavioral distributions,
thereby enabling flexible operation across diverse control modes and efficient
acquisition of novel behaviors without retraining from scratch. Extensive
experiments in both simulation and on a physical humanoid platform demonstrate
that BFM generalizes robustly across diverse WBC tasks while rapidly adapting
to new behaviors. These results establish BFM as a promising step toward a
foundation model for general-purpose humanoid control.

</details>


### [48] [Shell-Type Soft Jig for Holding Objects during Disassembly](https://arxiv.org/abs/2509.13802)
*Takuya Kiyokawa,Ryunosuke Takebayashi,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种柔性夹具，用于机器人拆卸，能够安全、通用地固定物体，显著降低对专用夹具设计和精密操作的需求。


<details>
  <summary>Details</summary>
Motivation: 解决传统夹具在拆卸过程中可能导致的部件损坏问题，并适应多样化的物体形状。

Method: 设计了一种基于气球的软性夹具，通过柔性固定机制减少对精确识别、规划和控制的依赖。

Result: 实验验证了该夹具的可行性，与传统夹具相比表现更优，但也明确了其局限性。

Conclusion: 该柔性夹具为机器人拆卸提供了一种高效且通用的解决方案，但仍需进一步优化以适应更复杂的场景。

Abstract: This study addresses a flexible holding tool for robotic disassembly. We
propose a shell-type soft jig that securely and universally holds objects,
mitigating the risk of component damage and adapting to diverse shapes while
enabling soft fixation that is robust to recognition, planning, and control
errors. The balloon-based holding mechanism ensures proper alignment and stable
holding performance, thereby reducing the need for dedicated jig design, highly
accurate perception, precise grasping, and finely tuned trajectory planning
that are typically required with conventional fixtures. Our experimental
results demonstrate the practical feasibility of the proposed jig through
performance comparisons with a vise and a jamming-gripper-inspired soft jig.
Tests on ten different objects further showed representative successes and
failures, clarifying the jig's limitations and outlook.

</details>


### [49] [Soft Regrasping Tool Inspired by Jamming Gripper](https://arxiv.org/abs/2509.13815)
*Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一种基于软夹具的重新抓取方法，通过可变形的夹具减少机器人装配中的位姿不确定性，实现了高成功率的放置，同时指出了其局限性和未来潜力。


<details>
  <summary>Details</summary>
Motivation: 传统刚性夹具缺乏适应性，需要为每个零件专门设计。为解决这一问题，研究提出了一种可变形软夹具，以更灵活地适应不同几何形状的零件。

Method: 利用三角锥形工具压入软夹具的膜中并抽出空气，形成稳定的放置空间。优化压入深度以平衡放置稳定性和抓手可及性。

Result: 在十种不同形状的机械零件上进行了放置实验，大多数零件的成功率超过80%，圆柱形零件成功率超过90%，失败主要由几何约束和膜特性引起。

Conclusion: 软夹具提供了一种通用、精确且可重复的重新抓取方案，未来有望成为刚性夹具的实用替代品，但仍需进一步解决其局限性。

Abstract: Regrasping on fixtures is a promising approach to reduce pose uncertainty in
robotic assembly, but conventional rigid fixtures lack adaptability and require
dedicated designs for each part. To overcome this limitation, we propose a soft
jig inspired by the jamming transition phenomenon, which can be continuously
deformed to accommodate diverse object geometries. By pressing a
triangular-pyramid-shaped tool into the membrane and evacuating the enclosed
air, a stable cavity is formed as a placement space. We further optimize the
stamping depth to balance placement stability and gripper accessibility. In
soft-jig-based regrasping, the key challenge lies in optimizing the cavity size
to achieve precise dropping; once the part is reliably placed, subsequent
grasping can be performed with reduced uncertainty. Accordingly, we conducted
drop experiments on ten mechanical parts of varying shapes, which achieved
placement success rates exceeding 80% for most objects and above 90% for
cylindrical ones, while failures were mainly caused by geometric constraints
and membrane properties. These results demonstrate that the proposed jig
enables general-purpose, accurate, and repeatable regrasping, while also
clarifying its current limitations and future potential as a practical
alternative to rigid fixtures in assembly automation.

</details>


### [50] [Agile in the Face of Delay: Asynchronous End-to-End Learning for Real-World Aerial Navigation](https://arxiv.org/abs/2509.13816)
*Yude Li,Zhexuan Zhou,Huizhe Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 提出了一种异步强化学习框架，解决自主飞行器中感知与控制频率不匹配的问题，通过解耦感知与控制并引入TEM模块处理数据延迟，实现了高频率控制和鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 解决自主飞行器在复杂环境中高频率控制与低频率感知之间的冲突问题，提升导航的敏捷性和鲁棒性。

Method: 采用异步强化学习框架，解耦感知与控制，引入Temporal Encoding Module (TEM) 处理感知延迟，并使用两阶段训练课程确保稳定性。

Result: 在模拟中验证了方法的有效性，并通过零样本仿真到现实的迁移成功部署到实际设备，实现了100Hz的控制频率。

Conclusion: 该方法通过异步处理和延迟补偿策略，显著提升了自主飞行器在复杂环境中的导航性能。

Abstract: Robust autonomous navigation for Autonomous Aerial Vehicles (AAVs) in complex
environments is a critical capability. However, modern end-to-end navigation
faces a key challenge: the high-frequency control loop needed for agile flight
conflicts with low-frequency perception streams, which are limited by sensor
update rates and significant computational cost. This mismatch forces
conventional synchronous models into undesirably low control rates. To resolve
this, we propose an asynchronous reinforcement learning framework that
decouples perception and control, enabling a high-frequency policy to act on
the latest IMU state for immediate reactivity, while incorporating perception
features asynchronously. To manage the resulting data staleness, we introduce a
theoretically-grounded Temporal Encoding Module (TEM) that explicitly
conditions the policy on perception delays, a strategy complemented by a
two-stage curriculum to ensure stable and efficient training. Validated in
extensive simulations, our method was successfully deployed in zero-shot
sim-to-real transfer on an onboard NUC, where it sustains a 100~Hz control rate
and demonstrates robust, agile navigation in cluttered real-world environments.
Our source code will be released for community reference.

</details>


### [51] [How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots](https://arxiv.org/abs/2509.13827)
*Renyuan Liu,Haoting Zhou,Chuankai Fang,Qinbing Fu*

Main category: cs.RO

TL;DR: 论文提出了一种受苍蝇视觉神经元启发的注意力驱动视觉运动控制策略，用于机器人的碰撞感知和反应躲避，并在微型机器人上实现了高效的计算和优雅的避障。


<details>
  <summary>Details</summary>
Motivation: 苍蝇的敏捷性源于其视觉神经系统，这在复杂环境中对机器人实现高效性能有重要启发。论文旨在通过仿生方法解决机器人计算成本与性能之间的权衡问题。

Method: 基于苍蝇的LPLC2神经元模型，设计了简化和优化的70KB内存视觉运动控制策略，并结合多注意力机制模拟分布式响应。

Result: 在微型机器人Colias上的实验显示，该模型在碰撞检测成功率达96.1%，且避障动作更自适应和优雅，性能媲美蝗虫启发的先进模型。

Conclusion: 该工作不仅展示了高效的避障策略，还突显了苍蝇启发的神经模型在昆虫智能集体行为研究中的潜力。

Abstract: Anyone who has tried to swat a fly has likely been frustrated by its
remarkable agility.This ability stems from its visual neural perception system,
particularly the collision-selective neurons within its small brain.For
autonomous robots operating in complex and unfamiliar environments, achieving
similar agility is highly desirable but often constrained by the trade-off
between computational cost and performance.In this context, insect-inspired
intelligence offers a parsimonious route to low-power, computationally
efficient frameworks.In this paper, we propose an attention-driven visuomotor
control strategy inspired by a specific class of fly visual projection
neurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated
escape behaviors.To our knowledge, this represents the first embodiment of an
LPLC2 neural model in the embedded vision of a physical mobile robot, enabling
collision perception and reactive evasion.The model was simplified and
optimized at 70KB in memory to suit the computational constraints of a
vision-based micro robot, the Colias, while preserving key neural perception
mechanisms.We further incorporated multi-attention mechanisms to emulate the
distributed nature of LPLC2 responses, allowing the robot to detect and react
to approaching targets both rapidly and selectively.We systematically evaluated
the proposed method against a state-of-the-art locust-inspired collision
detection model.Results showed that the fly-inspired visuomotor model achieved
comparable robustness, at success rate of 96.1% in collision detection while
producing more adaptive and elegant evasive maneuvers.Beyond demonstrating an
effective collision-avoidance strategy, this work highlights the potential of
fly-inspired neural models for advancing research into collective behaviors in
insect intelligence.

</details>


### [52] [UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography](https://arxiv.org/abs/2509.13832)
*Teng Wang,Haojun Jiang,Yuxuan Wang,Zhenguo Sun,Xiangjie Yan,Xiang Li,Gao Huang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于分层Transformer的决策架构UltraHiT，用于自动化颈动脉超声检查，特别是针对具有挑战性的颈内动脉(ICA)。该方法通过结合高级变异评估和低级动作决策，显著提高了ICA定位的成功率。


<details>
  <summary>Details</summary>
Motivation: 动机源于将个体血管结构视为标准血管模型的形态变异，从而解决ICA由于位置深、路径曲折和个体差异大而带来的扫描复杂性。

Method: 方法是通过分层Transformer架构，高级模块识别变异并切换至低级模块（自适应校正器或标准执行器）。高级模块和自适应校正器均采用因果Transformer，基于历史扫描序列生成预测。

Result: 在28名受试者的164个轨迹和72K样本的大规模ICA扫描数据集上，UltraHiT在未见个体上的ICA定位成功率达95%，优于基线方法。

Conclusion: 结论是UltraHiT通过创新架构有效解决了ICA自动化扫描的挑战，展现了其在实际应用中的潜力。

Abstract: Carotid ultrasound is crucial for the assessment of cerebrovascular health,
particularly the internal carotid artery (ICA). While previous research has
explored automating carotid ultrasound, none has tackled the challenging ICA.
This is primarily due to its deep location, tortuous course, and significant
individual variations, which greatly increase scanning complexity. To address
this, we propose a Hierarchical Transformer-based decision architecture, namely
UltraHiT, that integrates high-level variation assessment with low-level action
decision. Our motivation stems from conceptualizing individual vascular
structures as morphological variations derived from a standard vascular model.
The high-level module identifies variation and switches between two low-level
modules: an adaptive corrector for variations, or a standard executor for
normal cases. Specifically, both the high-level module and the adaptive
corrector are implemented as causal transformers that generate predictions
based on the historical scanning sequence. To ensure generalizability, we
collected the first large-scale ICA scanning dataset comprising 164
trajectories and 72K samples from 28 subjects of both genders. Based on the
above innovations, our approach achieves a 95% success rate in locating the ICA
on unseen individuals, outperforming baselines and demonstrating its
effectiveness. Our code will be released after acceptance.

</details>


### [53] [Track Any Motions under Any Disturbances](https://arxiv.org/abs/2509.13833)
*Zhikai Zhang,Jun Guo,Chao Chen,Jilong Wang,Chenghuai Lin,Yunrui Lian,Han Xue,Zhenrong Wang,Maoqi Liu,Huaping Liu,He Wang,Li Yi*

Main category: cs.RO

TL;DR: Any2Track是一个两阶段强化学习框架，旨在追踪多样化运动并应对现实世界中的动态干扰。


<details>
  <summary>Details</summary>
Motivation: 解决人形运动追踪器在动态干扰下的稳定性和适应性需求。

Method: 采用两阶段RL框架，包括通用运动追踪器AnyTracker和历史信息适应模块AnyAdapter。

Result: 在Unitree G1硬件上成功实现零样本sim2real迁移，表现优异。

Conclusion: Any2Track能有效追踪多样化运动并应对多种现实干扰。

Abstract: A foundational humanoid motion tracker is expected to be able to track
diverse, highly dynamic, and contact-rich motions. More importantly, it needs
to operate stably in real-world scenarios against various dynamics
disturbances, including terrains, external forces, and physical property
changes for general practical use. To achieve this goal, we propose Any2Track
(Track Any motions under Any disturbances), a two-stage RL framework to track
various motions under multiple disturbances in the real world. Any2Track
reformulates dynamics adaptability as an additional capability on top of basic
action execution and consists of two key components: AnyTracker and AnyAdapter.
AnyTracker is a general motion tracker with a series of careful designs to
track various motions within a single policy. AnyAdapter is a history-informed
adaptation module that endows the tracker with online dynamics adaptability to
overcome the sim2real gap and multiple real-world disturbances. We deploy
Any2Track on Unitree G1 hardware and achieve a successful sim2real transfer in
a zero-shot manner. Any2Track performs exceptionally well in tracking various
motions under multiple real-world disturbances.

</details>


### [54] [Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models](https://arxiv.org/abs/2509.13839)
*Motonari Kambara,Komei Sugiura*

Main category: cs.RO

TL;DR: 论文提出了一种预测开放词汇物体操作任务未来成功率的模型，通过多级轨迹融合模块结合状态空间模型和Transformer编码器，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法在操作完成后才判断成功与否，无法预防潜在危险且依赖失败触发重规划，降低效率。

Method: 提出模型预测操作前图像与计划轨迹及自然语言指令的对齐，采用多级轨迹融合模块结合深度状态空间模型和Transformer编码器。

Result: 实验表明，该方法优于现有方法，包括基础模型。

Conclusion: 该模型提高了物体操作序列的效率和安全性，为未来研究提供了新方向。

Abstract: In this work, we address the problem of predicting the future success of
open-vocabulary object manipulation tasks. Conventional approaches typically
determine success or failure after the action has been carried out. However,
they make it difficult to prevent potential hazards and rely on failures to
trigger replanning, thereby reducing the efficiency of object manipulation
sequences. To overcome these challenges, we propose a model, which predicts the
alignment between a pre-manipulation egocentric image with the planned
trajectory and a given natural language instruction. We introduce a Multi-Level
Trajectory Fusion module, which employs a state-of-the-art deep state-space
model and a transformer encoder in parallel to capture multi-level time-series
self-correlation within the end effector trajectory. Our experimental results
indicate that the proposed method outperformed existing methods, including
foundation models.

</details>


### [55] [InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap](https://arxiv.org/abs/2509.13857)
*Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.RO

TL;DR: InterKey是一种跨模态框架，利用道路交叉口作为显著地标进行全球定位，通过结合点云和OSM数据构建紧凑二进制描述符，实验表明其在KITTI数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 全球定位对自动驾驶至关重要，尤其是在GNSS信号受限的环境中。尽管高清地图提供准确先验，但成本限制了其可扩展性。OSM虽免费但抽象粗糙，难以与传感器数据匹配。

Method: 提出InterKey框架，利用道路交叉口作为地标，通过结合点云和OSM数据构建二进制描述符，并引入跨模态策略（如差异缓解和方向确定）实现鲁棒匹配。

Result: 在KITTI数据集上，InterKey表现出色，显著优于现有基线方法，适用于能生成密集点云的传感器。

Conclusion: InterKey提供了一种可扩展且成本效益高的解决方案，为自动驾驶车辆在复杂环境中实现鲁棒定位。

Abstract: Reliable global localization is critical for autonomous vehicles, especially
in environments where GNSS is degraded or unavailable, such as urban canyons
and tunnels. Although high-definition (HD) maps provide accurate priors, the
cost of data collection, map construction, and maintenance limits scalability.
OpenStreetMap (OSM) offers a free and globally available alternative, but its
coarse abstraction poses challenges for matching with sensor data. We propose
InterKey, a cross-modal framework that leverages road intersections as
distinctive landmarks for global localization. Our method constructs compact
binary descriptors by jointly encoding road and building imprints from point
clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,
orientation determination, and area-equalized sampling strategies, enabling
robust cross-modal matching. Experiments on the KITTI dataset demonstrate that
InterKey achieves state-of-the-art accuracy, outperforming recent baselines by
a large margin. The framework generalizes to sensors that can produce dense
structural point clouds, offering a scalable and cost-effective solution for
robust vehicle localization.

</details>


### [56] [Using Petri Nets for Context-Adaptive Robot Explanations](https://arxiv.org/abs/2509.13861)
*Görkem Kılınç Soylu,Neziha Akalin,Maria Riveiro*

Main category: cs.RO

TL;DR: 论文提出使用Petri网（PNs）来建模上下文信息，以实现机器人在人机交互中的自适应解释功能，展示了其形式化、图形化的优势，并通过场景验证了其鲁棒性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 在增强人机交互中的信任和自然沟通方面，机器人需要根据上下文调整其通信方式，而Petri网提供了一种有效的方法来建模这种动态交互。

Method: 利用Petri网（PNs）建模上下文信息，分析用户注意力、存在感等动态因素，并设计机器人的自适应解释行为。

Result: 模型分析验证了Petri网在死锁自由、上下文敏感可达性、有界性和活性等关键性质上的有效性，证明了其在设计上下文自适应解释中的适用性。

Conclusion: Petri网是一种强大且灵活的工具，可用于设计和验证人机交互中机器人的上下文自适应解释行为。

Abstract: In human-robot interaction, robots must communicate in a natural and
transparent manner to foster trust, which requires adapting their communication
to the context. In this paper, we propose using Petri nets (PNs) to model
contextual information for adaptive robot explanations. PNs provide a formal,
graphical method for representing concurrent actions, causal dependencies, and
system states, making them suitable for analyzing dynamic interactions between
humans and robots. We demonstrate this approach through a scenario involving a
robot that provides explanations based on contextual cues such as user
attention and presence. Model analysis confirms key properties, including
deadlock-freeness, context-sensitive reachability, boundedness, and liveness,
showing the robustness and flexibility of PNs for designing and verifying
context-adaptive explanations in human-robot interactions.

</details>


### [57] [Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning](https://arxiv.org/abs/2509.13882)
*Junhwa Hong,Beomjoon Lee,Woojin Lee,Changjoo Nam*

Main category: cs.RO

TL;DR: 提出了一种基于冲突的搜索（CBS）改进方法，通过排斥轨迹修改和梯度下降方法减少冲突，提高多机械臂运动规划的效率。


<details>
  <summary>Details</summary>
Motivation: 多机械臂系统的运动规划因高维度配置空间而计算复杂，现有方法如CBS存在冲突增加的缺陷。

Method: 在CBS的两层结构中，低层规划器使用人工势场进行梯度下降，生成排斥力避免冲突，并开发单步解决冲突的策略。

Result: 方法减少了约束树中的节点扩展，提高成功率和求解速度，优于现有算法。

Conclusion: 通过排斥轨迹和单步冲突解决策略，显著提升了多机械臂运动规划的性能。

Abstract: We propose an efficient motion planning method designed to efficiently find
collision-free trajectories for multiple manipulators. While multi-manipulator
systems offer significant advantages, coordinating their motions is
computationally challenging owing to the high dimensionality of their composite
configuration space. Conflict-Based Search (CBS) addresses this by decoupling
motion planning, but suffers from subsequent conflicts incurred by resolving
existing conflicts, leading to an exponentially growing constraint tree of CBS.
Our proposed method is based on repulsive trajectory modification within the
two-level structure of CBS. Unlike conventional CBS variants, the low-level
planner applies a gradient descent approach using an Artificial Potential
Field. This field generates repulsive forces that guide the trajectory of the
conflicting manipulator away from those of other robots. As a result,
subsequent conflicts are less likely to occur. Additionally, we develop a
strategy that, under a specific condition, directly attempts to find a
conflict-free solution in a single step without growing the constraint tree.
Through extensive tests including physical robot experiments, we demonstrate
that our method consistently reduces the number of expanded nodes in the
constraint tree, achieves a higher success rate, and finds a solution faster
compared to Enhanced CBS and other state-of-the-art algorithms.

</details>


### [58] [PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models](https://arxiv.org/abs/2509.13903)
*Artem Lykov,Jeffrin Sam,Hung Khang Nguyen,Vladislav Kozlovskiy,Yara Mahmoud,Valerii Serpiva,Miguel Altamirano Cabrera,Mikhail Konenkov,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: PhysicalAgent是一个机器人操作框架，结合迭代推理、基于扩散的视频生成和闭环执行，通过生成候选轨迹视频并迭代调整以应对失败，提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 旨在通过视频生成和迭代执行提升机器人操作的鲁棒性和适应性，特别是在面对执行错误时实现恢复。

Method: 使用文本指令生成候选轨迹视频，执行并迭代重规划以应对失败。

Result: 在多种感知模态和机器人平台上，PhysicalAgent平均成功率高达83%，首次尝试成功率为20-30%，通过迭代修正提升至80%。

Conclusion: 该方法展示了视频生成推理在通用机器人操作中的潜力，并强调了迭代执行对恢复失败的重要性。

Abstract: We introduce PhysicalAgent, an agentic framework for robotic manipulation
that integrates iterative reasoning, diffusion-based video generation, and
closed-loop execution. Given a textual instruction, our method generates short
video demonstrations of candidate trajectories, executes them on the robot, and
iteratively re-plans in response to failures. This approach enables robust
recovery from execution errors. We evaluate PhysicalAgent across multiple
perceptual modalities (egocentric, third-person, and simulated) and robotic
embodiments (bimanual UR3, Unitree G1 humanoid, simulated GR1), comparing
against state-of-the-art task-specific baselines. Experiments demonstrate that
our method consistently outperforms prior approaches, achieving up to 83%
success on human-familiar tasks. Physical trials reveal that first-attempt
success is limited (20-30%), yet iterative correction increases overall success
to 80% across platforms. These results highlight the potential of video-based
generative reasoning for general-purpose robotic manipulation and underscore
the importance of iterative execution for recovering from initial failures. Our
framework paves the way for scalable, adaptable, and robust robot control.

</details>


### [59] [MAP: End-to-End Autonomous Driving with Map-Assisted Planning](https://arxiv.org/abs/2509.13926)
*Huilin Yin,Yiming Kan,Daniel Watzenig*

Main category: cs.RO

TL;DR: 提出了一个名为MAP的新型地图辅助端到端轨迹规划框架，通过模块化设计显式整合地图特征和车辆状态，显著提升了轨迹规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法未充分利用在线地图模块的潜力，未能有效结合语义地图特征与轨迹规划。

Method: 设计了三个模块：用于增强规划的在线地图模块、引导规划的车辆状态模块以及基于状态的权重适配器。

Result: 在DAIR-V2X-seq-SPD数据集上，MAP比基线UniV2X减少了16.6%的L2位移误差和56.2%的偏离道路率，整体评分提升44.5%，并在CVPR2025竞赛中领先第二名39.5%。

Conclusion: 显式利用语义地图特征可有效提升端到端自动驾驶规划性能，为系统结构设计提供了新方向。

Abstract: In recent years, end-to-end autonomous driving has attracted increasing
attention for its ability to jointly model perception, prediction, and planning
within a unified framework. However, most existing approaches underutilize the
online mapping module, leaving its potential to enhance trajectory planning
largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel
map-assisted end-to-end trajectory planning framework. MAP explicitly
integrates segmentation-based map features and the current ego status through a
Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and
a Weight Adapter based on current ego status. Experiments conducted on the
DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%
reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a
44.5% improvement in overall score compared to the UniV2X baseline, even
without post-processing. Furthermore, it achieves top ranking in Track 2 of the
End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS
Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of
overall score. These results highlight the effectiveness of explicitly
leveraging semantic map features in planning and suggest new directions for
improving structure design in end-to-end autonomous driving systems. Our code
is available at https://gitee.com/kymkym/map.git

</details>


### [60] [Reinforcement Learning for Autonomous Point-to-Point UAV Navigation](https://arxiv.org/abs/2509.13943)
*Salim Oyinlola,Nitesh Subedi,Soumik Sarkar*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习的无人机自主导航方法，通过自定义奖励函数训练无人机高效避障并到达目标点，实验证明了该方法在现实场景中的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在自动化任务中的应用增加，如何实现可靠自主导航成为一个关键问题，本项目旨在通过强化学习实现无人机的自主点对点导航。

Method: 采用强化学习方法，无人机通过与环境的试错交互学习导航策略，结合自定义奖励函数以提升效率和安全性。控制系统集成ROS和Gym兼容的训练环境。

Result: 经过训练的策略在实际无人机平台上验证，结果显示该无人机能够成功自主导航，证明了强化学习在现实场景中的有效性。

Conclusion: 研究表明，强化学习方法适用于无人机的自主导航任务，能够减少人工干预，为实际应用提供了可行方案。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly used in automated
inspection, delivery, and navigation tasks that require reliable autonomy. This
project develops a reinforcement learning (RL) approach to enable a single UAV
to autonomously navigate between predefined points without manual intervention.
The drone learns navigation policies through trial-and-error interaction, using
a custom reward function that encourages goal-reaching efficiency while
penalizing collisions and unsafe behavior. The control system integrates ROS
with a Gym-compatible training environment, enabling flexible deployment and
testing. After training, the learned policy is deployed on a real UAV platform
and evaluated under practical conditions. Results show that the UAV can
successfully perform autonomous navigation with minimal human oversight,
demonstrating the viability of RL-based control for point-to-point drone
operations in real-world scenarios.

</details>


### [61] [The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot](https://arxiv.org/abs/2509.13948)
*Benedict Barrow,Roger K. Moore*

Main category: cs.RO

TL;DR: 研究发现，社交机器人面部特征中的眼睛形状和大小对人类信任感有显著影响，支持“婴儿脸”假设。


<details>
  <summary>Details</summary>
Motivation: 信任在人与人及人机互动中至关重要，但目前对机器人设计中如何增强人类信任的理解仍不足。

Method: 通过调整Furhat机器人的面部投影（尤其是眼睛形状和大小），研究其对信任感知的影响。

Result: 眼睛形状和大小的变化显著影响人类对机器人可信度的感知。

Conclusion: 研究结果为社交机器人设计提供了重要指导，有助于优化人机交互效果。

Abstract: Trust and the perception of trustworthiness play an important role in
decision-making and our behaviour towards others, and this is true not only of
human-human interactions but also of human-robot interactions. While
significant advances have been made in recent years in the field of social
robotics, there is still some way to go before we fully understand the factors
that influence human trust in robots. This paper presents the results of a
study into the first impressions created by a social robot's facial features,
based on the hypothesis that a `babyface' engenders trust. By manipulating the
back-projected face of a Furhat robot, the study confirms that eye shape and
size have a significant impact on the perception of trustworthiness. The work
thus contributes to an understanding of the design choices that need to be made
when developing social robots so as to optimise the effectiveness of
human-robot interaction.

</details>


### [62] [SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks](https://arxiv.org/abs/2509.13949)
*Jannick Stranghöner,Philipp Hartmann,Marco Braun,Sebastian Wrede,Klaus Neumann*

Main category: cs.RO

TL;DR: 介绍了SHaRe-RL框架，通过整合多种先验知识，解决了高混合低批量工业装配中机器人的效率和安全性问题。


<details>
  <summary>Details</summary>
Motivation: 解决高混合低批量工业装配中机器人系统面临的灵活性和安全性挑战，避免现有方法的不足。

Method: SHaRe-RL结合了预定义技能、人类示范和在线修正，并通过轴向合规性限制交互力。

Result: 在工业连接器插入任务中，SHaRe-RL在0.2-0.4毫米间隙下实现了高效且安全的在线学习。

Conclusion: SHaRe-RL展示了过程专业知识如何有效提升强化学习在工业装配中的应用，实现更安全、稳健和经济可行的部署。

Abstract: High-mix low-volume (HMLV) industrial assembly, common in small and
medium-sized enterprises (SMEs), requires the same precision, safety, and
reliability as high-volume automation while remaining flexible to product
variation and environmental uncertainty. Current robotic systems struggle to
meet these demands. Manual programming is brittle and costly to adapt, while
learning-based methods suffer from poor sample efficiency and unsafe
exploration in contact-rich tasks. To address this, we present SHaRe-RL, a
reinforcement learning framework that leverages multiple sources of prior
knowledge. By (i) structuring skills into manipulation primitives, (ii)
incorporating human demonstrations and online corrections, and (iii) bounding
interaction forces with per-axis compliance, SHaRe-RL enables efficient and
safe online learning for long-horizon, contact-rich industrial assembly tasks.
Experiments on the insertion of industrial Harting connector modules with
0.2-0.4 mm clearance demonstrate that SHaRe-RL achieves reliable performance
within practical time budgets. Our results show that process expertise, without
requiring robotics or RL knowledge, can meaningfully contribute to learning,
enabling safer, more robust, and more economically viable deployment of RL for
industrial assembly.

</details>


### [63] [SEG-Parking: Towards Safe, Efficient, and Generalizable Autonomous Parking via End-to-End Offline Reinforcement Learning](https://arxiv.org/abs/2509.13956)
*Zewei Yang,Zengqi Peng,Jun Ma*

Main category: cs.RO

TL;DR: SEG-Parking是一种新型的端到端离线强化学习框架，旨在解决无结构化环境和动态交互中的自主停车问题，通过专门的停车场数据集和保守正则化策略，实现了高性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为解决无结构化环境和动态交互对自主停车的挑战，研究者提出了SEG-Parking框架，以提升自动驾驶在复杂场景中的安全性和效率。

Method: 构建专用停车场数据集，预训练目标条件状态编码器，并利用保守正则化策略优化离线强化学习策略。

Result: 在CARLA模拟器中的闭环实验显示，SEG-Parking具有最高成功率和优秀泛化能力。

Conclusion: SEG-Parking框架在自主停车任务中表现出色，数据集和源代码将公开，有助于未来研究。

Abstract: Autonomous parking is a critical component for achieving safe and efficient
urban autonomous driving. However, unstructured environments and dynamic
interactions pose significant challenges to autonomous parking tasks. To
address this problem, we propose SEG-Parking, a novel end-to-end offline
reinforcement learning (RL) framework to achieve interaction-aware autonomous
parking. Notably, a specialized parking dataset is constructed for parking
scenarios, which include those without interference from the opposite vehicle
(OV) and complex ones involving interactions with the OV. Based on this
dataset, a goal-conditioned state encoder is pretrained to map the fused
perception information into the latent space. Then, an offline RL policy is
optimized with a conservative regularizer that penalizes out-of-distribution
actions. Extensive closed-loop experiments are conducted in the high-fidelity
CARLA simulator. Comparative results demonstrate the superior performance of
our framework with the highest success rate and robust generalization to
out-of-distribution parking scenarios. The related dataset and source code will
be made publicly available after the paper is accepted.

</details>


### [64] [MetricNet: Recovering Metric Scale in Generative Navigation Policies](https://arxiv.org/abs/2509.13965)
*Abhijeet Nayak,Débora N. P. Oliveira,Samiran Gode,Cordelia Schmid,Wolfram Burgard*

Main category: cs.RO

TL;DR: 论文提出MetricNet，解决生成式导航策略中轨迹无度量基础和短视控制的问题，显著提升导航和探索性能。


<details>
  <summary>Details</summary>
Motivation: 生成式导航策略存在轨迹无度量基础和短视控制的缺点，导致不安全行为。

Method: 提出MetricNet预测路标间的真实距离，并整合到导航策略MetricNav中。

Result: 实验表明MetricNet显著提升导航和探索性能，并在真实环境中验证。

Conclusion: MetricNet和MetricNav有效解决了生成式导航的缺陷，提升了安全性和性能。

Abstract: Generative navigation policies have made rapid progress in improving
end-to-end learned navigation. Despite their promising results, this paradigm
has two structural problems. First, the sampled trajectories exist in an
abstract, unscaled space without metric grounding. Second, the control strategy
discards the full path, instead moving directly towards a single waypoint. This
leads to short-sighted and unsafe actions, moving the robot towards obstacles
that a complete and correctly scaled path would circumvent. To address these
issues, we propose MetricNet, an effective add-on for generative navigation
that predicts the metric distance between waypoints, grounding policy outputs
in real-world coordinates. We evaluate our method in simulation with a new
benchmarking framework and show that executing MetricNet-scaled waypoints
significantly improves both navigation and exploration performance. Beyond
simulation, we further validate our approach in real-world experiments.
Finally, we propose MetricNav, which integrates MetricNet into a navigation
policy to guide the robot away from obstacles while still moving towards the
goal.

</details>


### [65] [BIM Informed Visual SLAM for Construction Monitoring](https://arxiv.org/abs/2509.13972)
*Asier Bikandi,Miguel Fernandez-Cortizas,Muhammad Shaheer,Ali Tourani,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 提出了一种结合BIM先验知识的RGB-D SLAM系统，用于施工环境中的精确定位与建图，显著减少轨迹误差和地图RMSE。


<details>
  <summary>Details</summary>
Motivation: 施工环境中视觉SLAM因重复布局和低纹理结构易产生漂移，需要一种更可靠的方法实现数字计划与实际场景的对齐。

Method: 通过RGB-D SLAM系统，利用BIM作为结构先验知识，持续检测墙面并与其BIM对应物建立约束，优化后端。

Result: 在真实施工环境中验证，平均减少轨迹误差23.71%，地图RMSE降低7.14%。

Conclusion: BIM约束能够在部分施工条件下实现数字计划与实际场景的可靠对齐，优于传统视觉SLAM。

Abstract: Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring
construction sites, where aligning the evolving as-built state with the
as-planned design enables early error detection and reduces costly rework.
LiDAR-based SLAM achieves high geometric precision, but its sensors are
typically large and power-demanding, limiting their use on portable platforms.
Visual SLAM offers a practical alternative with lightweight cameras already
embedded in most mobile devices. however, visually mapping construction
environments remains challenging: repetitive layouts, occlusions, and
incomplete or low-texture structures often cause drift in the trajectory map.
To mitigate this, we propose an RGB-D SLAM system that incorporates the
Building Information Model (BIM) as structural prior knowledge. Instead of
relying solely on visual cues, our system continuously establishes
correspondences between detected wall and their BIM counterparts, which are
then introduced as constraints in the back-end optimization. The proposed
method operates in real time and has been validated on real construction sites,
reducing trajectory error by an average of 23.71% and map RMSE by 7.14%
compared to visual SLAM baselines. These results demonstrate that BIM
constraints enable reliable alignment of the digital plan with the as-built
scene, even under partially constructed conditions.

</details>


### [66] [Flexible and Foldable: Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array](https://arxiv.org/abs/2509.13998)
*Bailey Dacre,Rodrigo Moreno,Serhat Demirtas,Ziqiao Wang,Yuhao Jiang,Jamie Paik,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 提出了一种新型分布式操纵器系统，利用3自由度折纸启发式机器人瓦片和柔性表面层，降低了执行器密度并提高操作范围。


<details>
  <summary>Details</summary>
Motivation: 解决现有分布式操纵器系统高执行器密度和对物体比例限制的问题。

Method: 采用3自由度折纸启发式机器人瓦片和柔性表面层，实现连续可控的操作表面。

Result: 系统可将物体操作范围提高1.84倍，无需增加执行器数量。

Conclusion: 该设计为传统高密度阵列提供了一种低成本、低复杂度的替代方案，并开创了利用柔性表面的新操作策略。

Abstract: Object manipulation is a fundamental challenge in robotics, where systems
must balance trade-offs among manipulation capabilities, system complexity, and
throughput. Distributed manipulator systems (DMS) use the coordinated motion of
actuator arrays to perform complex object manipulation tasks, seeing widespread
exploration within the literature and in industry. However, existing DMS
designs typically rely on high actuator densities and impose constraints on
object-to-actuator scale ratios, limiting their adaptability. We present a
novel DMS design utilizing an array of 3-DoF, origami-inspired robotic tiles
interconnected by a compliant surface layer. Unlike conventional DMS, our
approach enables manipulation not only at the actuator end effectors but also
across a flexible surface connecting all actuators; creating a continuous,
controllable manipulation surface. We analyse the combined workspace of such a
system, derive simple motion primitives, and demonstrate its capabilities to
translate simple geometric objects across an array of tiles. By leveraging the
inter-tile connective material, our approach significantly reduces actuator
density, increasing the area over which an object can be manipulated by x1.84
without an increase in the number of actuators. This design offers a lower cost
and complexity alternative to traditional high-density arrays, and introduces
new opportunities for manipulation strategies that leverage the flexibility of
the interconnected surface.

</details>


### [67] [Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization](https://arxiv.org/abs/2509.14010)
*Zong Chen,Shaoyang Li,Ben Liu,Min Li,Zhouping Yin,Yiqun Li*

Main category: cs.RO

TL;DR: 探讨了一种配备灵巧机械手的全向轮腿四足机器人的设计与全身运动控制，通过动态优化框架解决了冗余自由度、复杂轮地接触动态及运动与操纵协调的挑战。


<details>
  <summary>Details</summary>
Motivation: 轮腿式机器人及其机械手的统一控制在物流、工业自动化和人机协作中具有重大潜力，但仍面临自由度冗余、复杂接触动态及协调难题。

Method: 设计了一种具有独立驱动转向模块和轮毂驱动轮的全向机器人，开发了接触感知的动态优化框架，结合点接触和线接触建模，并引入热启动策略加速优化。

Result: 仿真和实验验证了框架的有效性，展示了机器人在多样化场景下的敏捷地形穿越、高速全向移动和精确操纵能力。

Conclusion: 该平台在半结构化环境中具有工厂自动化、城市物流和服务机器人应用的潜力。

Abstract: Wheel-legged robots with integrated manipulators hold great promise for
mobile manipulation in logistics, industrial automation, and human-robot
collaboration. However, unified control of such systems remains challenging due
to the redundancy in degrees of freedom, complex wheel-ground contact dynamics,
and the need for seamless coordination between locomotion and manipulation. In
this work, we present the design and whole-body motion control of an
omnidirectional wheel-legged quadrupedal robot equipped with a dexterous
manipulator. The proposed platform incorporates independently actuated steering
modules and hub-driven wheels, enabling agile omnidirectional locomotion with
high maneuverability in structured environments. To address the challenges of
contact-rich interaction, we develop a contact-aware whole-body dynamic
optimization framework that integrates point-contact modeling for manipulation
with line-contact modeling for wheel-ground interactions. A warm-start strategy
is introduced to accelerate online optimization, ensuring real-time feasibility
for high-dimensional control. Furthermore, a unified kinematic model tailored
for the robot's 4WIS-4WID actuation scheme eliminates the need for mode
switching across different locomotion strategies, improving control consistency
and robustness. Simulation and experimental results validate the effectiveness
of the proposed framework, demonstrating agile terrain traversal, high-speed
omnidirectional mobility, and precise manipulation under diverse scenarios,
underscoring the system's potential for factory automation, urban logistics,
and service robotics in semi-structured environments.

</details>


### [68] [TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems](https://arxiv.org/abs/2509.14025)
*Rui Huang,Zhiyu Gao,Siyu Tang,Jialin Zhang,Lei He,Ziqian Zhang,Lin Zhao*

Main category: cs.RO

TL;DR: TransforMARS是一种通用的故障容忍重构框架，用于处理任意形状的多无人机系统（MARS），支持多转子或单元故障下的稳定飞行。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅针对矩形MARS的单故障容忍重构，而TransforMARS旨在解决任意形状MARS在多故障下的重构需求。

Method: 开发算法识别最小可控组件并规划拆卸-组装序列，目标是在空中保持稳定。

Result: 实验验证表明，TransforMARS在多样配置和容忍多故障方面优于现有方法。

Conclusion: TransforMARS为MARS提供了更灵活和实用的故障容忍重构能力，拓展了其应用潜力。

Abstract: Modular Aerial Robot Systems (MARS) consist of multiple drone modules that
are physically bound together to form a single structure for flight. Exploiting
structural redundancy, MARS can be reconfigured into different formations to
mitigate unit or rotor failures and maintain stable flight. Prior work on MARS
self-reconfiguration has solely focused on maximizing controllability margins
to tolerate a single rotor or unit fault for rectangular-shaped MARS. We
propose TransforMARS, a general fault-tolerant reconfiguration framework that
transforms arbitrarily shaped MARS under multiple rotor and unit faults while
ensuring continuous in-air stability. Specifically, we develop algorithms to
first identify and construct minimum controllable assemblies containing faulty
units. We then plan feasible disassembly-assembly sequences to transport MARS
units or subassemblies to form target configuration. Our approach enables more
flexible and practical feasible reconfiguration. We validate TransforMARS in
challenging arbitrarily shaped MARS configurations, demonstrating substantial
improvements over prior works in both the capacity of handling diverse
configurations and the number of faults tolerated. The videos and source code
of this work are available at the anonymous repository:
https://anonymous.4open.science/r/TransforMARS-1030/

</details>


### [69] [Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning](https://arxiv.org/abs/2509.14040)
*Zewen Yang,Xiaobing Dai,Dongfa Zhang,Yu Li,Ziyang Meng,Bingkun Huang,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种几何不变性的一步高斯过程学习框架Prompt2Auto，通过单次运动提示实现机器人自动化控制，减少了演示负担并提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人学习演示方法需要大量数据且难以跨坐标变换泛化，Prompt2Auto旨在解决这些问题。

Method: 采用几何不变性高斯过程框架，结合基于坐标变换的数据集构建策略，支持多步预测和多技能自主。

Result: 通过数值模拟和真实实验验证，方法有效、泛化能力强且显著减少演示需求。

Conclusion: Prompt2Auto在机器人自动化控制中表现出高效性和泛化能力，适用于多任务场景。

Abstract: Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io

</details>


### [70] [Language Conditioning Improves Accuracy of Aircraft Goal Prediction in Untowered Airspace](https://arxiv.org/abs/2509.14063)
*Sundhar Vinodh Sangeetha,Chih-Yuan Chiu,Sarah H. Q. Li,Shreyas Kousik*

Main category: cs.RO

TL;DR: 该论文提出了一种多模态框架，结合自然语言理解和空间推理，以提升无人航空器在非塔台空域中的目标预测能力。


<details>
  <summary>Details</summary>
Motivation: 在非塔台空域中，航空器的安全操作依赖于飞行员之间的语音通信，因此需要预测其他航空器的意图和目标位置以支持自主决策。

Method: 结合自动语音识别和大语言模型解析飞行员无线电通信，提取意图标签，并将其与观测轨迹融合，通过时间卷积网络和高斯混合模型进行概率目标预测。

Result: 该方法显著降低了目标预测误差，优于仅依赖运动历史的基线方法，验证了语言条件预测的准确性。

Conclusion: 实验证明了该方法的有效性，展示了其在语言条件机器人运动规划中的潜力。

Abstract: Autonomous aircraft must safely operate in untowered airspace, where
coordination relies on voice-based communication among human pilots. Safe
operation requires an aircraft to predict the intent, and corresponding goal
location, of other aircraft. This paper introduces a multimodal framework for
aircraft goal prediction that integrates natural language understanding with
spatial reasoning to improve autonomous decision-making in such environments.
We leverage automatic speech recognition and large language models to
transcribe and interpret pilot radio calls, identify aircraft, and extract
discrete intent labels. These intent labels are fused with observed
trajectories to condition a temporal convolutional network and Gaussian mixture
model for probabilistic goal prediction. Our method significantly reduces goal
prediction error compared to baselines that rely solely on motion history,
demonstrating that language-conditioned prediction increases prediction
accuracy. Experiments on a real-world dataset from an untowered airport
validate the approach and highlight its potential to enable socially aware,
language-conditioned robotic motion planning.

</details>


### [71] [Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots](https://arxiv.org/abs/2509.14075)
*Yu Li,Hamid Sadeghian,Zewen Yang,Valentin Le Mesle,Sami Haddadin*

Main category: cs.RO

TL;DR: 本文提出了一种新的约束一致扭矩控制器，用于确保RAMIS中的RCM约束，并通过实验验证其在动态和交互条件下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 在RAMIS中，精确执行RCM约束对工具的安全操作至关重要，但现有方法在扭矩级别缺乏鲁棒性或无法保证一致的约束满足。

Method: 通过将RCM视为流形约束，并将其嵌入基于投影的逆动力学框架，实现任务级和运动学表述的统一。

Result: 实验结果表明，该方法在RCM约束满足、扭矩需求减少和扭矩平滑性方面优于现有方法，并适用于多种临床场景。

Conclusion: 约束一致扭矩控制有望提升手术机器人的安全性和可靠性。

Abstract: Robotic-assisted minimally invasive surgery (RAMIS) requires precise
enforcement of the remote center of motion (RCM) constraint to ensure safe tool
manipulation through a trocar. Achieving this constraint under dynamic and
interactive conditions remains challenging, as existing control methods either
lack robustness at the torque level or do not guarantee consistent RCM
constraint satisfaction. This paper proposes a constraint-consistent torque
controller that treats the RCM as a rheonomic holonomic constraint and embeds
it into a projection-based inverse-dynamics framework. The method unifies
task-level and kinematic formulations, enabling accurate tool-tip tracking
while maintaining smooth and efficient torque behavior. The controller is
validated both in simulation and on a RAMIS training platform, and is
benchmarked against state-of-the-art approaches. Results show improved RCM
constraint satisfaction, reduced required torque, and robust performance by
improving joint torque smoothness through the consistency formulation under
clinically relevant scenarios, including spiral trajectories, variable
insertion depths, moving trocars, and human interaction. These findings
demonstrate the potential of constraint-consistent torque control to enhance
safety and reliability in surgical robotics. The project page is available at:
https://rcmpc-cube.github.io

</details>


### [72] [FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video](https://arxiv.org/abs/2509.14082)
*Valerii Serpiva,Artem Lykov,Faryal Batool,Vladislav Kozlovskiy,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: FlightDiffusion是一个基于扩散模型的框架，用于从第一人称视角（FPV）视频训练自主无人机。该模型能从单帧生成逼真的视频序列，并附带动作空间，实现动态环境中的推理导航。


<details>
  <summary>Details</summary>
Motivation: 通过生成逼真的FPV视频和动作空间，减少真实数据收集的高成本，并为无人机研究提供大规模训练数据。

Method: 利用扩散模型生成多样化的FPV轨迹和状态-动作对，用于训练自主无人机。

Result: 生成的数据在物理上可行，位置和方向误差较低（RMSE分别为0.28 m和0.24 rad），模拟与现实的性能无显著差异（p=0.541）。

Conclusion: 该框架为无人机导航、动作生成和数据合成提供了一种统一且高效的范式。

Abstract: We present FlightDiffusion, a diffusion-model-based framework for training
autonomous drones from first-person view (FPV) video. Our model generates
realistic video sequences from a single frame, enriched with corresponding
action spaces to enable reasoning-driven navigation in dynamic environments.
Beyond direct policy learning, FlightDiffusion leverages its generative
capabilities to synthesize diverse FPV trajectories and state-action pairs,
facilitating the creation of large-scale training datasets without the high
cost of real-world data collection. Our evaluation demonstrates that the
generated trajectories are physically plausible and executable, with a mean
position error of 0.25 m (RMSE 0.28 m) and a mean orientation error of 0.19 rad
(RMSE 0.24 rad). This approach enables improved policy learning and dataset
scalability, leading to superior performance in downstream navigation tasks.
Results in simulated environments highlight enhanced robustness, smoother
trajectory planning, and adaptability to unseen conditions. An ANOVA revealed
no statistically significant difference between performance in simulation and
reality (F(1, 16) = 0.394, p = 0.541), with success rates of M = 0.628 (SD =
0.162) and M = 0.617 (SD = 0.177), respectively, indicating strong sim-to-real
transfer. The generated datasets provide a valuable resource for future UAV
research. This work introduces diffusion-based reasoning as a promising
paradigm for unifying navigation, action generation, and data synthesis in
aerial robotics.

</details>


### [73] [GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14117)
*Ali Abouzeid,Malak Mansour,Zezhou Sun,Dezhen Song*

Main category: cs.RO

TL;DR: GeoAware-VLA通过集成几何先验知识提升了VLA模型对新相机视角的泛化能力，显著提高了仿真和真实环境中的性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型在面对新相机视角时表现不佳，主要因为难以从2D图像推断稳健的3D几何信息。本文旨在通过引入几何先验来解决这一问题。

Method: 提出GeoAware-VLA，利用预训练的几何视觉模型提取特征，并通过可训练的投影层将这些特征调整为适合策略解码器的形式，无需从头学习3D一致性。

Result: 在LIBERO基准测试中，新方法显著提升了零样本泛化能力，仿真环境下成功率提升2倍以上；在真实机器人上也表现出色，特别是在未见过的相机角度下。

Conclusion: 几何先验是提升机器人代理泛化能力的关键，GeoAware-VLA在连续和离散动作空间中均表现优异，为构建更通用的机器人代理提供了有效途径。

Abstract: Vision-Language-Action (VLA) models often fail to generalize to novel camera
viewpoints, a limitation stemming from their difficulty in inferring robust 3D
geometry from 2D images. We introduce GeoAware-VLA, a simple yet effective
approach that enhances viewpoint invariance by integrating strong geometric
priors into the vision backbone. Instead of training a visual encoder or
relying on explicit 3D data, we leverage a frozen, pretrained geometric vision
model as a feature extractor. A trainable projection layer then adapts these
geometrically-rich features for the policy decoder, relieving it of the burden
of learning 3D consistency from scratch. Through extensive evaluations on
LIBERO benchmark subsets, we show GeoAware-VLA achieves substantial
improvements in zero-shot generalization to novel camera poses, boosting
success rates by over 2x in simulation. Crucially, these benefits translate to
the physical world; our model shows a significant performance gain on a real
robot, especially when evaluated from unseen camera angles. Our approach proves
effective across both continuous and discrete action spaces, highlighting that
robust geometric grounding is a key component for creating more generalizable
robotic agents.

</details>


### [74] [CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads](https://arxiv.org/abs/2509.14126)
*Viktor Lorentz,Khaled Wahba,Sayantan Auddy,Marc Toussaint,Wolfgang Hönig*

Main category: cs.RO

TL;DR: 提出了一种名为CrazyMARL的去中心化强化学习框架，用于解决多无人机协同运输电缆悬挂负载的控制问题。


<details>
  <summary>Details</summary>
Motivation: 多无人机协同运输负载在灾害救援和精准物流等领域有广泛应用，但负载动力学和电缆模式切换等挑战仍未解决。

Method: 采用去中心化强化学习（RL）框架CrazyMARL，避免了传统的刚性假设。

Result: 仿真结果显示，该方法在抗干扰和跟踪精度上优于传统控制器，且在严苛条件下的恢复率为80%。

Conclusion: 该方法展示了在非结构化环境中执行复杂任务的潜力，为无人机团队的自主性和鲁棒性提供了新方向。

Abstract: Collaborative transportation of cable-suspended payloads by teams of Unmanned
Aerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to
different payload shapes, and provide built-in compliance, making it attractive
for applications ranging from disaster relief to precision logistics. However,
multi-UAV coordination under disturbances, nonlinear payload dynamics, and
slack--taut cable modes remains a challenging control problem. To our
knowledge, no prior work has addressed these cable mode transitions in the
multi-UAV context, instead relying on simplifying rigid-link assumptions. We
propose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for
multi-UAV cable-suspended payload transport. Simulation results demonstrate
that the learned policies can outperform classical decentralized controllers in
terms of disturbance rejection and tracking precision, achieving an 80%
recovery rate from harsh conditions compared to 44% for the baseline method. We
also achieve successful zero-shot sim-to-real transfer and demonstrate that our
policies are highly robust under harsh conditions, including wind, random
external disturbances, and transitions between slack and taut cable dynamics.
This work paves the way for autonomous, resilient UAV teams capable of
executing complex payload missions in unstructured environments.

</details>


### [75] [Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks](https://arxiv.org/abs/2509.14127)
*Alkesh K. Srivastava,Jared Michael Levin,Philip Dames*

Main category: cs.RO

TL;DR: 论文提出VCST-RCP框架，通过Steiner树优化构建稀疏中继主干，并结合机器人调度，显著提升多机器人配送效率。


<details>
  <summary>Details</summary>
Motivation: 传统配送方法依赖直接运输，而本文将中继作为协调核心，旨在解决有限运力下多机器人配送的效率和能耗问题。

Method: 采用Voronoi约束的Steiner树优化构建中继主干，并合成机器人级别的拾取、中继和交付调度。

Result: 实验显示，相比传统方法，VCST-RCP效率提升达34%，显著增强了多机器人配送的能源效率。

Conclusion: VCST-RCP为中继驱动的多机器人配送提供了可扩展的框架，适用于实际物流场景。

Abstract: We consider the problem of delivering multiple packages from a single pickup
depot to distinct goal locations using a homogeneous fleet of robots with
limited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner
Tree Relay Coordination Planning framework that constructs sparse relay trunks
using Steiner tree optimization and then synthesizes robot-level pickup, relay,
and delivery schedules. This framework reframes relays from incidental
byproducts into central elements of coordination, offering a contrast with
traditional delivery methods that rely on direct source-to-destination
transport. Extensive experiments show consistent improvements of up to 34%
compared to conventional baselines, underscoring the benefits of incorporating
relays into the delivery process. These improvements translate directly to
enhanced energy efficiency in multi-robot delivery under capacity constraints,
providing a scalable framework for real-world logistics.

</details>


### [76] [SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model](https://arxiv.org/abs/2509.14138)
*Ran Yang,Zijian An,Lifeng ZHou,Yiming Feng*

Main category: cs.RO

TL;DR: SeqVLA 是一种基于 $π_0$ 的完成感知扩展模型，通过轻量级检测头实现子任务完成检测，显著提升了多阶段任务的执行成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLA 模型（如 $π_0$）在连续低层次控制中表现出色，但缺乏子任务完成检测的内部信号，导致在顺序任务中表现脆弱。

Method: SeqVLA 采用双头设计，包含动作生成和子任务完成检测头，研究了四种微调策略，探讨联合优化与顺序优化以及预训练知识的保留方式。

Result: 在沙拉包装和糖果包装任务中，SeqVLA 显著优于基线模型 $π_0$，联合优化且不冻结主干网络的效果最佳。

Conclusion: 研究表明，将动作生成与子任务感知检测结合对于可扩展的顺序操作至关重要。

Abstract: Long-horizon robotic manipulation tasks require executing multiple
interdependent subtasks in strict sequence, where errors in detecting subtask
completion can cascade into downstream failures. Existing
Vision-Language-Action (VLA) models such as $\pi_0$ excel at continuous
low-level control but lack an internal signal for identifying when a subtask
has finished, making them brittle in sequential settings. We propose SeqVLA, a
completion-aware extension of $\pi_0$ that augments the base architecture with
a lightweight detection head perceiving whether the current subtask is
complete. This dual-head design enables SeqVLA not only to generate
manipulation actions but also to autonomously trigger transitions between
subtasks. We investigate four finetuning strategies that vary in how the action
and detection heads are optimized (joint vs. sequential finetuning) and how
pretrained knowledge is preserved (full finetuning vs. frozen backbone).
Experiments are performed on two multi-stage tasks: salad packing with seven
distinct subtasks and candy packing with four distinct subtasks. Results show
that SeqVLA significantly outperforms the baseline $\pi_0$ and other strong
baselines in overall success rate. In particular, joint finetuning with an
unfrozen backbone yields the most decisive and statistically reliable
completion predictions, eliminating sequence-related failures and enabling
robust long-horizon execution. Our results highlight the importance of coupling
action generation with subtask-aware detection for scalable sequential
manipulation.

</details>


### [77] [CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping](https://arxiv.org/abs/2509.14143)
*Zijian An,Ran Yang,Yiming Feng,Lifeng Zhou*

Main category: cs.RO

TL;DR: CLAW框架通过解耦条件评估与动作生成，结合符号化推理与视觉运动控制，提升了机器人执行精确任务的能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在满足精确任务约束（如基于数值阈值的停止）方面表现不佳，因为它们缺乏显式的条件监测机制。

Method: CLAW框架利用微调的CLIP模型生成离散指令，结合VLA策略进行高频视觉运动控制。

Result: 在单物体抓取和双臂操作任务中，CLAW表现优于原始和微调的VLA模型。

Conclusion: CLAW通过显式条件监测与符号化推理的结合，显著提升了机器人执行复杂任务的能力。

Abstract: Vision-language-action (VLA) models have recently emerged as a promising
paradigm for robotic control, enabling end-to-end policies that ground natural
language instructions into visuomotor actions. However, current VLAs often
struggle to satisfy precise task constraints, such as stopping based on numeric
thresholds, since their observation-to-action mappings are implicitly shaped by
training data and lack explicit mechanisms for condition monitoring. In this
work, we propose CLAW (CLIP-Language-Action for Weight), a framework that
decouples condition evaluation from action generation. CLAW leverages a
fine-tuned CLIP model as a lightweight prompt generator, which continuously
monitors the digital readout of a scale and produces discrete directives based
on task-specific weight thresholds. These prompts are then consumed by $\pi_0$,
a flow-based VLA policy, which integrates the prompts with multi-view camera
observations to produce continuous robot actions. This design enables CLAW to
combine symbolic weight reasoning with high-frequency visuomotor control. We
validate CLAW on three experimental setups: single-object grasping and
mixed-object tasks requiring dual-arm manipulation. Across all conditions, CLAW
reliably executes weight-aware behaviors and outperforms both raw-$\pi_0$ and
fine-tuned $\pi_0$ models. We have uploaded the videos as supplementary
materials.

</details>


### [78] [StableTracker: Learning to Stably Track Target via Differentiable Simulation](https://arxiv.org/abs/2509.14147)
*Fanxing Li,Shengyang Wang,Fangyu Sun,Shuyu Wu,Dexin Zuo,Wenxian Yu,Danping Zou*

Main category: cs.RO

TL;DR: StableTracker是一种基于学习的控制策略，通过可微分模拟训练，解决了FPV跟踪中硬件过载和累计误差的问题，显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统FPV目标跟踪方法依赖手工设计模块，导致硬件过载和累计误差，尤其在目标快速加减速时性能下降。

Method: 使用基于时间的反向传播和可微分模拟训练控制策略，保持目标在视野中心并固定相对距离。

Result: 仿真和真实实验表明，StableTracker在准确性、稳定性及泛化性上优于现有方法。

Conclusion: StableTracker在实际应用中表现出色，为解决FPV跟踪问题提供了新思路。

Abstract: FPV object tracking methods heavily rely on handcraft modular designs,
resulting in hardware overload and cumulative error, which seriously degrades
the tracking performance, especially for rapidly accelerating or decelerating
targets. To address these challenges, we present \textbf{StableTracker}, a
learning-based control policy that enables quadrotors to robustly follow the
moving target from arbitrary perspectives. The policy is trained using
backpropagation-through-time via differentiable simulation, allowing the
quadrotor to maintain the target at the center of the visual field in both
horizontal and vertical directions, while keeping a fixed relative distance,
thereby functioning as an autonomous aerial camera. We compare StableTracker
against both state-of-the-art traditional algorithms and learning baselines.
Simulation experiments demonstrate that our policy achieves superior accuracy,
stability and generalization across varying safe distances, trajectories, and
target velocities. Furthermore, a real-world experiment on a quadrotor with an
onboard computer validated practicality of the proposed approach.

</details>


### [79] [MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies](https://arxiv.org/abs/2509.14159)
*Dayi Dong,Maulik Bhatt,Seoyeon Choi,Negar Mehr*

Main category: cs.RO

TL;DR: 论文提出了一种基于扩散模型的去中心化执行方法MIMIC-D，用于解决多模态多智能体模仿学习中协调行为的问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在社会中的广泛应用，其在多模态任务中与其他机器人或人类协调的能力变得至关重要。目前的多模态模仿学习方法在处理多样化策略时存在困难。

Method: 提出MIMIC-D方法，采用集中训练去中心化执行的范式，利用扩散模型处理多模态轨迹分布，实现隐式协调。

Result: 实验表明，该方法在多种任务和环境中成功恢复了多智能体的协调行为，并优于现有方法。

Conclusion: MIMIC-D为多模态多智能体模仿学习提供了一种有效的解决方案，适用于无法直接通信的实际场景。

Abstract: As robots become more integrated in society, their ability to coordinate with
other robots and humans on multi-modal tasks (those with multiple valid
solutions) is crucial. We propose to learn such behaviors from expert
demonstrations via imitation learning (IL). However, when expert demonstrations
are multi-modal, standard IL approaches can struggle to capture the diverse
strategies, hindering effective coordination. Diffusion models are known to be
effective at handling complex multi-modal trajectory distributions in
single-agent systems. Diffusion models have also excelled in multi-agent
scenarios where multi-modality is more common and crucial to learning
coordinated behaviors. Typically, diffusion-based approaches require a
centralized planner or explicit communication among agents, but this assumption
can fail in real-world scenarios where robots must operate independently or
with agents like humans that they cannot directly communicate with. Therefore,
we propose MIMIC-D, a Centralized Training, Decentralized Execution (CTDE)
paradigm for multi-modal multi-agent imitation learning using diffusion
policies. Agents are trained jointly with full information, but execute
policies using only local information to achieve implicit coordination. We
demonstrate in both simulation and hardware experiments that our method
recovers multi-modal coordination behavior among agents in a variety of tasks
and environments, while improving upon state-of-the-art baselines.

</details>


### [80] [\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video](https://arxiv.org/abs/2509.14178)
*Kai Ye,Yuhang Wu,Shuyuan Hu,Junliang Li,Meng Liu,Yongquan Chen,Rui Huang*

Main category: cs.RO

TL;DR: 论文提出了一种名为Gen2Real的方法，通过生成视频而非人工演示来训练机器人抓取技能，成功率达到77.3%。


<details>
  <summary>Details</summary>
Motivation: 解决机器人灵巧操作中的演示数据收集难题，提出利用生成视频替代人工演示的方案。

Method: 结合视频生成、轨迹优化和基于锚点的残差PPO策略，生成并优化手-物体轨迹，再将其应用于机器人控制学习。

Result: 在仿真中成功率77.3%，并在真实机器人上验证了任务描述的灵活性和技能的泛化能力。

Conclusion: Gen2Real展示了从生成视频到真实执行的灵活性，为机器人技能学习提供了新思路。

Abstract: Dexterous manipulation remains a challenging robotics problem, largely due to
the difficulty of collecting extensive human demonstrations for learning. In
this paper, we introduce \textsc{Gen2Real}, which replaces costly human demos
with one generated video and drives robot skill from it: it combines
demonstration generation that leverages video generation with pose and depth
estimation to yield hand-object trajectories, trajectory optimization that uses
Physics-aware Interaction Optimization Model (PIOM) to impose physics
consistency, and demonstration learning that retargets human motions to a robot
hand and stabilizes control with an anchor-based residual Proximal Policy
Optimization (PPO) policy. Using only generated videos, the learned policy
achieves a 77.3\% success rate on grasping tasks in simulation and demonstrates
coherent executions on a real robot. We also conduct ablation studies to
validate the contribution of each component and demonstrate the ability to
directly specify tasks using natural language, highlighting the flexibility and
robustness of \textsc{Gen2Real} in generalizing grasping skills from imagined
videos to real-world execution.

</details>


### [81] [MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping](https://arxiv.org/abs/2509.14191)
*Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald*

Main category: cs.RO

TL;DR: MCGS-SLAM是基于3D高斯点云的首个纯RGB多摄像头SLAM系统，通过多视角稠密输入实现实时高精度建图，优于单目方案。


<details>
  <summary>Details</summary>
Motivation: 解决单目SLAM在鲁棒性和几何覆盖上的不足，提升自主驾驶等场景的安全性和重建效果。

Method: 使用多摄像头束调整（MCBA）联合优化位姿和深度，并通过尺度一致性模块确保多视图度量对齐。

Result: 在合成和真实数据集上表现优于单目基线，能重建单目系统遗漏的侧视区域。

Conclusion: 多摄像头高斯点云SLAM在高保真建图方面具有潜力，适合机器人和自动驾驶应用。

Abstract: Recent progress in dense SLAM has primarily targeted monocular setups, often
at the expense of robustness and geometric coverage. We present MCGS-SLAM, the
first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting
(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM
fuses dense RGB inputs from multiple viewpoints into a unified, continuously
optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines
poses and depths via dense photometric and geometric residuals, while a scale
consistency module enforces metric alignment across views using low-rank
priors. The system supports RGB input and maintains real-time performance at
large scale. Experiments on synthetic and real-world datasets show that
MCGS-SLAM consistently yields accurate trajectories and photorealistic
reconstructions, usually outperforming monocular baselines. Notably, the wide
field of view from multi-camera input enables reconstruction of side-view
regions that monocular setups miss, critical for safe autonomous operation.
These results highlight the promise of multi-camera Gaussian Splatting SLAM for
high-fidelity mapping in robotics and autonomous driving.

</details>


### [82] [GLIDE: A Coordinated Aerial-Ground Framework for Search and Rescue in Unknown Environments](https://arxiv.org/abs/2509.14210)
*Seth Farrell,Chenghao Li,Hongzhan Yu,Hesam Mojtahedi,Sicun Gao,Henrik I. Christensen*

Main category: cs.RO

TL;DR: 提出了一种协同空中-地面搜救框架GLIDE，通过无人机引导地面车辆实现快速受害者定位和障碍物感知导航。


<details>
  <summary>Details</summary>
Motivation: 提高时间紧迫的搜救任务中的效率和导航安全性。

Method: 使用两个无人机（目标搜索和地形侦察）与地面车辆协同工作，结合A*规划和实时重新规划。

Result: 实验证明，明确的角色分配和地形侦察提升了到达时间和导航安全性。

Conclusion: GLIDE框架在搜救任务中表现出高效和安全的特点。

Abstract: We present a cooperative aerial-ground search-and-rescue (SAR) framework that
pairs two unmanned aerial vehicles (UAVs) with an unmanned ground vehicle (UGV)
to achieve rapid victim localization and obstacle-aware navigation in unknown
environments. We dub this framework Guided Long-horizon Integrated Drone Escort
(GLIDE), highlighting the UGV's reliance on UAV guidance for long-horizon
planning. In our framework, a goal-searching UAV executes real-time onboard
victim detection and georeferencing to nominate goals for the ground platform,
while a terrain-scouting UAV flies ahead of the UGV's planned route to provide
mid-level traversability updates. The UGV fuses aerial cues with local sensing
to perform time-efficient A* planning and continuous replanning as information
arrives. Additionally, we present a hardware demonstration (using a GEM e6 golf
cart as the UGV and two X500 UAVs) to evaluate end-to-end SAR mission
performance and include simulation ablations to assess the planning stack in
isolation from detection. Empirical results demonstrate that explicit role
separation across UAVs, coupled with terrain scouting and guided planning,
improves reach time and navigation safety in time-critical SAR missions.

</details>


### [83] [Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models](https://arxiv.org/abs/2509.14228)
*Benjamin Shaffer,Victoria Edwards,Brooks Kinch,Nathaniel Trask,M. Ani Hsieh*

Main category: cs.RO

TL;DR: 论文提出了一种分布式移动传感框架，用于复杂流动环境中的源定位，通过机器学习的有限元模型和信息税控制策略，提高了定位速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂流动环境（如化学泄漏或油污扩散）中的源定位对多机器人团队具有挑战性，传统的计算密集型模型在有限的计算资源下难以实现。

Method: 每个机器人携带机器学习的有限元模型，利用近似互信息准则驱动信息税控制策略，选择预期信息量最大的采样区域。

Result: 相比基线传感策略和机器学习方法，该方法能更快降低误差并实现更准确的源定位。

Conclusion: 分布式机器学习框架在资源受限环境下有效提升复杂流动源定位的性能。

Abstract: Source localization in a complex flow poses a significant challenge for
multi-robot teams tasked with localizing the source of chemical leaks or
tracking the dispersion of an oil spill. The flow dynamics can be time-varying
and chaotic, resulting in sporadic and intermittent sensor readings, and
complex environmental geometries further complicate a team's ability to model
and predict the dispersion. To accurately account for the physical processes
that drive the dispersion dynamics, robots must have access to computationally
intensive numerical models, which can be difficult when onboard computation is
limited. We present a distributed mobile sensing framework for source
localization in which each robot carries a machine-learned, finite element
model of its environment to guide information-based sampling. The models are
used to evaluate an approximate mutual information criterion to drive an
infotaxis control strategy, which selects sensing regions that are expected to
maximize informativeness for the source localization objective. Our approach
achieves faster error reduction compared to baseline sensing strategies and
results in more accurate source localization compared to baseline machine
learning approaches.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [84] [Uplink-Downlink Duality for Beamforming in Integrated Sensing and Communications](https://arxiv.org/abs/2509.13661)
*Kareem M. Attiah,Wei Yu*

Main category: cs.IT

TL;DR: 本文研究了利用通信信号同时进行传感的集成传感与通信（ISAC）问题中的波束成形和功率优化，提出了最小化贝叶斯克拉美-罗界（BCRB）的框架，同时满足通信用户的信号干扰加噪声比约束。


<details>
  <summary>Details</summary>
Motivation: 解决ISAC系统中如何优化波束成形和功率分配，以同时实现高精度传感和高效通信的需求。

Method: 提出了基于BCRB最小化的优化框架，通过最大化沿特定传感方向的波束成形功率，并扩展经典的上行-下行对偶理论，设计了高效的迭代算法。

Result: 发现ISAC的双上行问题可能涉及负噪声功率，并提出上行波束成形器的额外条件，实现了波束成形和功率的联合优化。

Conclusion: 提出的对偶理论为ISAC系统提供了高效的优化算法，显著提升了传感和通信的联合性能。

Abstract: This paper considers the beamforming and power optimization problem for a
class of integrated sensing and communications (ISAC) problems that utilize the
communication signals simultaneously for sensing. We formulate the problem of
minimizing the Bayesian Cram\'er-Rao bound (BCRB) on the mean-squared error of
estimating a vector of parameters, while satisfying downlink
signal-to-interference-and-noise-ratio constraints for a set of communication
users at the same time. The proposed optimization framework comprises two key
new ingredients. First, we show that the BCRB minimization problem corresponds
to maximizing beamforming power along certain sensing directions of interest.
Second, the classical uplink-downlink duality for multiple-input
multiple-output communications can be extended to the ISAC setting, but unlike
the classical communication problem, the dual uplink problem for ISAC may
entail negative noise power and needs to include an extra condition on the
uplink beamformers. This new duality theory opens doors for an efficient
iterative algorithm for optimizing power and beamformers for ISAC.

</details>


### [85] [Asymptotic Analysis of Nonlinear One-Bit Precoding in Massive MIMO Systems via Approximate Message Passing](https://arxiv.org/abs/2509.13955)
*Zheyu Wu,Junjie Ma,Ya-Feng Liu,Bruno Clerckx*

Main category: cs.IT

TL;DR: 本文研究了一种基于凸松弛和量化的非线性符号级一位预编码方法，通过近似消息传递框架分析了其高维渐近性能，并推导了符号错误概率的闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统采用一位数模转换器可实现硬件高效的无线通信，但一位约束使预编码设计成为离散非凸优化问题，需有效解决方案。

Method: 采用"凸松弛后量化"方法，首先求解离散最小均方误差预编码问题的凸松弛，再量化解以满足一位约束；基于AMP框架分析高维渐近性能。

Result: 推导了大系统极限下接收端符号错误概率的闭式表达式，发现$ackslash ell_ackslash infty^2$正则器在最优参数下可实现最佳性能。

Conclusion: $ackslash ell_ackslash infty^2$正则器在混合正则函数类中最优，为理论支持提供了初步证明。

Abstract: Massive multiple-input multiple-output (MIMO) systems employing one-bit
digital-to-analog converters offer a hardware-efficient solution for wireless
communications. However, the one-bit constraint poses significant challenges
for precoding design, as it transforms the problem into a discrete and
nonconvex optimization task. In this paper, we investigate a widely adopted
``convex-relaxation-then-quantization" approach for nonlinear symbol-level
one-bit precoding. Specifically, we first solve a convex relaxation of the
discrete minimum mean square error precoding problem, and then quantize the
solution to satisfy the one-bit constraint. To analyze the high-dimensional
asymptotic performance of this scheme, we develop a novel analytical framework
based on approximate message passing (AMP). This framework enables us to derive
a closed-form expression for the symbol error probability (SEP) at the receiver
side in the large-system limit, which provides a quantitative characterization
of how model and system parameters affect the SEP performance. Our empirical
results suggest that the $\ell_\infty^2$ regularizer, when paired with an
optimally chosen regularization parameter, achieves optimal SEP performance
within a broad class of convex regularization functions. As a first step
towards a theoretical justification, we prove the optimality of the
$\ell_\infty^2$ regularizer within the mixed $\ell_\infty^2$-$\ell_2^2$
regularization functions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [86] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大型语言模型（LLM）的无人机框架（Agentic UAVs），通过五层架构增强无人机的感知、推理、行动和集成能力，显著提升了搜索与救援任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无人机系统在动态任务中适应性不足，缺乏上下文感知和自主决策能力，作者希望通过引入LLM驱动的推理和工具调用能力来解决这些问题。

Method: 提出五层架构（感知、推理、行动、集成、学习），结合ROS2、Gazebo、YOLOv11和GPT-4等技术实现原型系统。

Result: 在模拟任务中，Agentic UAVs在目标检测置信度（0.79 vs. 0.72）、人员检测率（91% vs. 75%）和行动推荐率（92% vs. 4.5%）上显著优于传统系统。

Conclusion: 该方法展示了如何在有限计算开销下实现更高水平的自主性和生态系统集成。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [87] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: 本文提出了一种名为EpiSMART的持续学习框架，用于个性化癫痫发作检测，解决了传统深度学习中遗忘问题，并在实际部署中表现出高效性。


<details>
  <summary>Details</summary>
Motivation: 提升癫痫发作检测的自动化水平，减少对专家分析和静态模型的依赖，适应患者个性化的脑电图信号变化。

Method: 采用带约束的重放缓冲区和智能样本选择策略，结合持续学习框架，逐步适应患者特异性脑电图信号。

Result: 在CHB-MIT数据集上，EpiSMART的F1分数比基线提升21%，且每日仅需6.46分钟标记数据和6.28次更新，适合可穿戴系统实时部署。

Conclusion: EpiSMART在资源受限条件下实现了鲁棒的个性化癫痫检测，有效整合新数据且不破坏历史知识。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [88] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 该论文提出了一种通过小波变换将纳米孔电流信号转换为尺度图图像的方法，以提升肽和蛋白质的实时分类准确率，为临床诊断提供了一种潜在的新技术。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在临床环境中实时分类蛋白质的设备，以实现低成本、快速的疾病诊断，纳米孔技术是实现这一目标的潜在候选方案。

Method: 将纳米孔电流信号通过小波变换转换为尺度图图像，从而捕捉振幅、频率和时间信息，并利用机器学习算法进行分类。

Result: 在42种肽的测试中，分类准确率达到约81%，并展示了模型迁移技术，为实际硬件部署提供了基础。

Conclusion: 该方法在肽和蛋白质实时分类中达到了新的最优性能，为临床应用提供了可能的解决方案。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [89] [AnyAccomp: Generalizable Accompaniment Generation via Quantized Melodic Bottleneck](https://arxiv.org/abs/2509.14052)
*Junan Zhang,Yunjia Zhang,Xueyao Zhang,Zhizheng Wu*

Main category: cs.SD

TL;DR: 本文提出AnyAccomp框架，通过解耦伴奏生成与源依赖伪影，解决了现有歌唱伴奏生成技术对分离伪影过拟合的问题。


<details>
  <summary>Details</summary>
Motivation: 现有歌唱伴奏生成技术依赖于源分离的人声输入，容易过拟合分离伪影，导致在真实干净的声乐输入上表现不佳。

Method: AnyAccomp采用量化旋律瓶颈（如色度图和VQ-VAE）提取离散且音色不变的核心旋律表示，随后通过流匹配模型生成伴奏。

Result: 实验表明，AnyAccomp在分离人声基准上表现优异，并在干净录音室人声和独奏乐器音轨的泛化测试中显著优于基线模型。

Conclusion: AnyAccomp实现了泛化的质的飞跃，能够为乐器生成伴奏，为更通用的音乐协同创作工具铺平了道路。

Abstract: Singing Accompaniment Generation (SAG) is the process of generating
instrumental music for a given clean vocal input. However, existing SAG
techniques use source-separated vocals as input and overfit to separation
artifacts. This creates a critical train-test mismatch, leading to failure on
clean, real-world vocal inputs. We introduce AnyAccomp, a framework that
resolves this by decoupling accompaniment generation from source-dependent
artifacts. AnyAccomp first employs a quantized melodic bottleneck, using a
chromagram and a VQ-VAE to extract a discrete and timbre-invariant
representation of the core melody. A subsequent flow-matching model then
generates the accompaniment conditioned on these robust codes. Experiments show
AnyAccomp achieves competitive performance on separated-vocal benchmarks while
significantly outperforming baselines on generalization test sets of clean
studio vocals and, notably, solo instrumental tracks. This demonstrates a
qualitative leap in generalization, enabling robust accompaniment for
instruments - a task where existing models completely fail - and paving the way
for more versatile music co-creation tools. Demo audio and code:
https://anyaccomp.github.io

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [90] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个基于Transformer的统一前馈模型，通过输入图像和可选几何信息，直接回归3D场景几何和相机参数，适用于多种3D视觉任务。


<details>
  <summary>Details</summary>
Motivation: 通过统一的模型解决多种3D视觉任务，避免为每个任务训练专用模型，提高效率和泛化能力。

Method: 使用分解表示方法处理多视角场景几何，结合标准化监督和灵活输入增强，实现单次前馈预测。

Result: 实验表明MapAnything在多个任务上表现优于或匹配专用模型，同时训练效率更高。

Conclusion: MapAnything为通用3D重建提供了可行的基础模型。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [91] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 该论文提出了一种用于自动驾驶车辆轨迹预测的自适应框架，以解决数据分布偏移问题，显著提升了检测延迟和误报率的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在实际部署中会遇到训练数据与真实场景之间的分布偏移问题，现有的OOD检测研究多集中于视觉任务，轨迹层面的OOD检测研究较少。

Method: 通过建模预测错误的模式依赖性分布，引入自适应机制，提出了一种新的框架以实现复杂驾驶环境中的鲁棒检测。

Result: 在多个真实数据集上的实验表明，该方法在检测延迟和误报率上均显著优于现有方法。

Conclusion: 该框架为自动驾驶提供了一条实用的路径，实现了更可靠且计算高效的轨迹预测OOD检测。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [92] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法是一种基于聚类的2D定位方法，以其抗噪性和鲁棒性著称，本文将其扩展至3D定位和图像拼接，并探讨了与其他方法的关联。


<details>
  <summary>Details</summary>
Motivation: 为了将CLAP算法的优势应用于更广泛的领域，扩展其适用范围并提升处理噪声和不确定性的能力。

Method: 将CLAP算法从2D定位推广到3D定位和图像拼接，同时分析其与RANSAC和Hough变换的关联。

Result: CLAP算法的广义化使其适用于多个领域，成为一种有效的噪声和不确定性处理工具。

Conclusion: CLAP的扩展框架展示了其在多领域的潜力，为相关研究提供了新的工具和思路。

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [93] [Multi-Attacker Single-Defender Target Defense in Conical Environments](https://arxiv.org/abs/2509.13564)
*Arman Pourghorban,Dipankar Maity*

Main category: eess.SY

TL;DR: 论文研究了在平面上圆锥环境中的目标防御问题，探讨了防御者如何拦截一系列攻击者以保护目标。通过分析博弈均衡策略，理论结果通过数值模拟验证。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决多攻击者序列下的目标防御问题，攻击者能根据防御者的位置动态调整策略，这对实际防御系统设计具有重要意义。

Method: 方法包括推导攻防双方的博弈均衡策略，特别是利用捕捉分布概念优化防御者的拦截效果，并通过蒙特卡罗模拟验证理论结果。

Result: 研究结果表明，攻防双方的最优策略能显著影响捕获率，理论分析与数值实验一致。

Conclusion: 结论指出，通过均衡策略设计和动态感知优化，防御者可以有效拦截攻击者序列，保护目标安全。

Abstract: We consider a variant of the target defense problem in a planar conical
environment where a single defender is tasked to capture a sequence of incoming
attackers. The attackers' objective is to breach the target boundary without
being captured by the defender. As soon as the current attacker breaches the
target or gets captured by the defender, the next attacker appears at the
boundary of the environment and moves radially toward the target with maximum
speed. Therefore, the defender's final location at the end of the current game
becomes its initial location for the next game. The attackers pick strategies
that are advantageous for the current as well as for future engagements between
the defender and the remaining attackers. The attackers have their own sensors
with limited range, using which they can perfectly detect if the defender is
within their sensing range. We derive equilibrium strategies for all the
players to optimize the capture percentage using the notions of capture
distribution. Finally, the theoretical results are verified through numerical
examples using Monte Carlo type random trials of experiments.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [94] [Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation](https://arxiv.org/abs/2509.13331)
*Reza Pirayeshshirazinezhad*

Main category: astro-ph.IM

TL;DR: 该论文提出了一种结合人工智能和自适应控制系统的精确航天器编队任务优化方法，用于实现X射线观测虚拟望远镜（VTXO）的高精度任务。


<details>
  <summary>Details</summary>
Motivation: 通过机器学习和鲁棒控制技术，提高VTXO空间任务中航天器编队的效率和精度，以观测高能X射线天体的高分辨率成像。

Method: 采用定时自动机进行监督控制，蒙特卡洛模拟评估稳定性和鲁棒性，并结合深度神经网络优化任务参数，满足高精度任务要求。

Result: 结果显示系统能够降低能耗并提高任务精度，有效应对动态不确定性和干扰。

Conclusion: 所提出的AI框架不仅实现了任务参数的优化和透明化决策，还显著提升了航天器编队任务的性能和可靠性。

Abstract: We use artificial intelligence (AI) and supervisory adaptive control systems
to plan and optimize the mission of precise spacecraft formation. Machine
learning and robust control enhance the efficiency of spacecraft precision
formation of the Virtual Telescope for X-ray Observation (VTXO) space mission.
VTXO is a precise formation of two separate spacecraft making a virtual
telescope with a one-kilometer focal length. One spacecraft carries the lens
and the other spacecraft holds the camera to observe high-energy space objects
in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed
automata for supervisory control, Monte Carlo simulations for stability and
robustness evaluation, and integration of deep neural networks for optimal
estimation of mission parameters, satisfy the high precision mission criteria.
We integrate deep neural networks with a constrained, non-convex dynamic
optimization pipeline to predict optimal mission parameters, ensuring precision
mission criteria are met. AI framework provides explainability by predicting
the resulting energy consumption and mission error for a given set of mission
parameters. It allows for transparent, justifiable, and real-time trade-offs, a
capability not present in traditional adaptive controllers. The results show
reductions in energy consumption and improved mission accuracy, demonstrating
the capability of the system to address dynamic uncertainties and disturbances.

</details>
