<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IT](#cs.IT) [Total: 3]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Demonstrating Superresolution in Radar Range Estimation Using a Denoising Autoencoder](https://arxiv.org/abs/2506.14906)
*Robert Czupryniak,Abhishek Chakraborty,Andrew N. Jordan,John C. Howell*

Main category: eess.SP

TL;DR: 利用机器学习方法在遥感雷达检测中实现了超分辨率，通过去噪自编码器估计亚波长区域内两个等强度散射体的距离。


<details>
  <summary>Details</summary>
Motivation: 研究目标是展示机器学习在提高雷达检测范围分辨率中的应用，特别是在亚波长区域内精确测量散射体间距。

Method: 使用去噪自编码器对带限波形进行训练，优化亚波长范围内的距离测量；研究了不同脉冲类型（sinc、三角波、Bessel函数）的性能。

Result: Bessel信号的性能最佳，其次是三角波，sinc信号表现最差；自编码器实现了有效的降维，瓶颈层与真实散射体间距有强相关性。

Conclusion: 信号设计在机器学习提升范围分辨率中起关键作用，Bessel函数脉冲表现最优。

Abstract: We apply machine learning methods to demonstrate range superresolution in
remote sensing radar detection. Specifically, we implement a denoising
autoencoder to estimate the distance between two equal intensity scatterers in
the subwavelength regime. The machine learning models are trained on waveforms
subject to a bandlimit constraint such that ranges much smaller than the
inverse bandlimit are optimized in their precision. The autoencoder achieves
effective dimensionality reduction, with the bottleneck layer exhibiting a
strong and consistent correlation with the true scatterer separation. We
confirm reproducibility across different training sessions and network
initializations by analyzing the scaled encoder outputs and their robustness to
noise. We investigate the behavior of the bottleneck layer for the following
types of pulses: a traditional sinc pulse, a bandlimited triangle-type pulse,
and a theoretically near-optimal pulse created from a spherical Bessel function
basis. The Bessel signal performs best, followed by the triangle wave, with the
sinc signal performing worst, highlighting the crucial role of signal design in
the success of machine-learning-based range resolution.

</details>


### [2] [Metasurfaces-Integrated Doubly-Dispersive MIMO: Channel Modeling and Optimization](https://arxiv.org/abs/2506.14985)
*Kuranage Roche Rayan Ranasinghe,Hyeon Seok Rou,Iván Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的多参数双色散（MPDD）信道模型，适用于MIMO系统，并集成了可重构智能表面（RIS）和堆叠智能超表面（SIM），同时讨论了其在OFDM、OTFS和AFDM等波形中的应用。


<details>
  <summary>Details</summary>
Motivation: 扩展双色散（DD）框架到MIMO系统，尤其是在RIS和SIM增强的环境中，是一个待解决的挑战。

Method: 提出了一种新型的MPDD信道模型，集成了多个RIS和SIM，并探讨了其在OFDM、OTFS和AFDM波形中的应用。

Result: 展示了该模型的可编程性，及其在SIM辅助的无线系统中提升波形性能的潜力。

Conclusion: MPDD模型为解决MIMO系统中的DD信道建模问题提供了新的方向，并显示出在RIS和SIM环境中的应用前景。

Abstract: The doubly-dispersive (DD) channel structure has played a pivotal role in
wireless communications, particularly in high-mobility scenarios and integrated
sensing and communications (ISAC), due to its ability to capture the key fading
effects experienced by a transmitted signal as it propagates through a dynamic
medium. However, extending the DD framework to multiple-input multiple-output
(MIMO) systems, especially in environments artificially enhanced by
reconfigurable intelligent surfaces (RISs) and stacked intelligent metasurfaces
(SIM), remains a challenging open problem. In this chapter, a novel
metasurfaces-parametrized DD (MPDD) channel model that integrates an arbitrary
number of RISs, while also incorporating SIM at both the transmitter and
receiver is introduced. Next, the application of this model to some key
waveforms optimized for DD environments -- namely orthogonal frequency division
multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine
frequency division multiplexing (AFDM) -- is discussed. Finally, the
programmability of the proposed model is highlighted through an illustrative
application, demonstrating its potential for enhancing waveform performance in
SIM-assisted wireless systems.

</details>


### [3] [Secure Time-Modulated Intelligent Reflecting Surface via Generative Flow Networks](https://arxiv.org/abs/2506.14992)
*Zhihao Tao,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 提出了一种基于生成式AI的时调制智能反射表面（TM-IRS）设计方法，用于多用户OFDM系统中的定向调制，旨在提高系统安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有TM-IRS设计方法通常面向单用户方向，且基于预定义的规则，不适合多用户场景。因此，需要一种高效且适应性强的设计方法。

Method: 采用生成式AI和GFlowNets建模TM-IRS参数选择问题，通过学习随机策略选择最优参数集，以最大化授权方向的累积速率。

Result: 实验表明，该方法显著提升了多用户OFDM系统的安全性，且GFlowNets在训练仅需极少量配置后即能收敛。

Conclusion: 所提出的方法在多用户定向调制中表现出高效性和有效性，为TM-IRS设计提供了新思路。

Abstract: We propose a novel directional modulation (DM) design for OFDM transmitters
aided by a time-modulated intelligent reflecting surface (TM-IRS). The TM-IRS
is configured to preserve the integrity of transmitted signals toward multiple
legitimate users while scrambling the signal in all other directions. Existing
TM-IRS design methods typically target a single user direction and follow
predefined rule-based procedures, making them unsuitable for multi-user
scenarios. Here, we propose a generative AI-based approach to design good sets
of TM-IRS parameters out of a set of all possible quantized ranges of
parameters. The design objective is to maximize the sum rate across the
authorized directions. We model the TM-IRS parameter selection as a
deterministic Markov decision process (MDP), where each terminal state
corresponds to a specific configuration of TM-IRS parameters. GFlowNets are
employed to learn a stochastic policy that samples TM-IRS parameter sets with
probability proportional to their associated sum rate reward. Experimental
results demonstrate that the proposed method effectively enhances the security
of the TM-IRS-aided OFDM systems with multi-users. Also, despite the vast size
of the TM-IRS configuration space, the GFlowNet is able to converge after
training on fewer than 0.000001% of all possible configurations, demonstrating
remarkable efficiency compared to exhaustive combinatorial search.
Implementation code is available at https://github.com/ZhihaoTao/GFN4TM-RIS to
facilitate reproducibility.

</details>


### [4] [Fiber Signal Denoising Algorithm using Hybrid Deep Learning Networks](https://arxiv.org/abs/2506.15125)
*Linlin Wang,Wei Wang,Dezhao Wang,Shanwen Wang*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合深度学习网络（HDLNet）的信号去噪算法，结合自编码器和LSTM，用于分布式声学传感系统的信号处理，并在高速公路隧道数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决分布式声学传感系统在智能交通系统中信号去噪的需求，本文提出了一种无需标注数据的自监督混合深度学习网络。

Method: 采用了混合深度学习网络（HDLNet），结合自编码器（DAE）去噪和长短时记忆网络（LSTM）进行序列处理，并引入了逐行匹配算法用于车辆检测与跟踪。

Result: 实验结果表明，所提出的混合网络在高速公路隧道数据集上的去噪性能优于传统空间域DAE。

Conclusion: 该混合网络为分布式声学传感系统的信号处理提供了一种高效的自监督解决方案，适用于智能交通系统的实际应用。

Abstract: With the applicability of optical fiber-based distributed acoustic sensing
(DAS) systems, effective signal processing and analysis approaches are needed
to promote its popularization in the field of intelligent transportation
systems (ITS). This paper presents a signal denoising algorithm using a hybrid
deep-learning network (HDLNet). Without annotated data and time-consuming
labeling, this self-supervised network runs in parallel, combining an
autoencoder for denoising (DAE) and a long short-term memory (LSTM) for
sequential processing. Additionally, a line-by-line matching algorithm for
vehicle detection and tracking is introduced, thus realizing the complete
processing of fiber signal denoising and feature extraction. Experiments were
carried out on a self-established real highway tunnel dataset, showing that our
proposed hybrid network yields more satisfactory denoising performance than
Spatial-domain DAE.

</details>


### [5] [Out-of-Band Modality Synergy Based Multi-User Beam Prediction and Proactive BS Selection with Zero Pilot Overhead](https://arxiv.org/abs/2506.15136)
*Kehui Li,Binggui Zhou,Jiajia Guo,Feifei Gao,Guanghua Yang,Shaodan Ma*

Main category: eess.SP

TL;DR: 提出基于视觉和位置反馈的OOB模态协同（OMS）方案，用于多用户波束预测和基站选择，减少信令开销并提高协调效率。


<details>
  <summary>Details</summary>
Motivation: 毫米波多用户通信中，多基站选择和波束跟踪导致高信令开销，现有OOB模态方案在多基站系统中协调效率低。

Method: 利用视觉和位置OOB模态协同，通过空间对齐和时间相关性跟踪用户，设计BEM-GBPN网络预测波束增益和最优波束。

Result: 模拟结果显示，方案在零导频开销下实现91%最优传输速率，并显著提高多基站协调效率。

Conclusion: OMS方案有效减少开销并提升性能，适用于密集基站部署场景。

Abstract: Multi-user millimeter-wave communication relies on narrow beams and dense
cell deployments to ensure reliable connectivity. However, tracking optimal
beams for multiple mobile users across multiple base stations (BSs) results in
significant signaling overhead. Recent works have explored the capability of
out-of-band (OOB) modalities in obtaining spatial characteristics of wireless
channels and reducing pilot overhead in single-BS single-user/multi-user
systems. However, applying OOB modalities for multi-BS selection towards dense
cell deployments leads to high coordination overhead, i.e, excessive computing
overhead and high latency in data exchange. How to leverage OOB modalities to
eliminate pilot overhead and achieve efficient multi-BS coordination in
multi-BS systems remains largely unexplored. In this paper, we propose a novel
OOB modality synergy (OMS) based mobility management scheme to realize
multi-user beam prediction and proactive BS selection by synergizing two OOB
modalities, i.e., vision and location. Specifically, mobile users are initially
identified via spatial alignment of visual sensing and location feedback, and
then tracked according to the temporal correlation in image sequence.
Subsequently, a binary encoding map based gain and beam prediction network
(BEM-GBPN) is designed to predict beamforming gains and optimal beams for
mobile users at each BS, such that a central unit can control the BSs to
perform user handoff and beam switching. Simulation results indicate that the
proposed OMS-based mobility management scheme enhances beam prediction and BS
selection accuracy and enables users to achieve 91% transmission rates of the
optimal with zero pilot overhead and significantly improve multi-BS
coordination efficiency compared to existing methods.

</details>


### [6] [Probabilistic Trajectory GOSPA: A Metric for Uncertainty-Aware Multi-Object Tracking Performance Evaluation](https://arxiv.org/abs/2506.15148)
*Yuxuan Xia,Ángel F. García-Fernández,Johan Karlsson,Yu Ge,Lennart Svensson,Ting Yuan*

Main category: eess.SP

TL;DR: 本文提出了一种用于评估多目标跟踪算法的轨迹广义最优子模式分配（GOSPA）度量的泛化方法，该算法考虑了轨迹级不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的TGOSPA度量无法充分处理多目标跟踪算法中轨迹级的不确定性，因此需要一种新的度量方法来综合考虑状态估计和目标存在的不确定性。

Method: 通过对概率GOSPA度量进行扩展，提出了一种新的度量方法，可以将其建模为多维分配问题，并通过线性规划松弛在多项式时间内计算。

Result: 新度量保留了TGOSPA的可解释性，并能够分解为直观的成本项，包括定位误差、存在概率不匹配误差、漏检和误检误差以及轨迹切换误差。仿真研究验证了其有效性。

Conclusion: 提出的新度量能够有效评估多目标跟踪算法的性能，尤其是在处理轨迹级不确定性时具有显著优势。

Abstract: This paper presents a generalization of the trajectory general optimal
sub-pattern assignment (GOSPA) metric for evaluating multi-object tracking
algorithms that provide trajectory estimates with track-level uncertainties.
This metric builds on the recently introduced probabilistic GOSPA metric to
account for both the existence and state estimation uncertainties of individual
object states. Similar to trajectory GOSPA (TGOSPA), it can be formulated as a
multidimensional assignment problem, and its linear programming
relaxation--also a valid metric--is computable in polynomial time.
Additionally, this metric retains the interpretability of TGOSPA, and we show
that its decomposition yields intuitive costs terms associated to expected
localization error and existence probability mismatch error for properly
detected objects, expected missed and false detection error, and track switch
error. The effectiveness of the proposed metric is demonstrated through a
simulation study.

</details>


### [7] [Enhancing eLoran Timing Accuracy via Machine Learning with Meteorological and Terrain Data](https://arxiv.org/abs/2506.15235)
*Taewon Kang,Seunghyeon Park,Pyo-Woong Son,Jiwon Seo*

Main category: eess.SP

TL;DR: 本文针对eLoran与GPS时间差的预测问题，提出了一种结合气象因素的WLR-AGRNN模型，通过加权线性回归和神经网络改进预测精度。


<details>
  <summary>Details</summary>
Motivation: 研究eLoran作为GNSS补充系统的可行性，并解决其信号传播延迟（ASF）对计时精度的影响。

Method: 使用时间间隔计数器测量GPS与eLoran时间差，分析其与11种气象因素的相关性，提出WLR-AGRNN模型。

Result: 实验表明，WLR-AGRNN模型在四个月数据上的表现优于其他方法，显著提高了预测精度。

Conclusion: WLR-AGRNN模型为eLoran系统的计时精度优化提供了有效工具。

Abstract: The vulnerabilities of global navigation satellite systems (GNSS) to signal
interference have increased the demand for complementary positioning,
navigation, and timing (PNT) systems. To address this, South Korea has decided
to deploy an enhanced long-range navigation (eLoran) system as a complementary
PNT solution. Similar to GNSS, eLoran provides highly accurate timing
information, which is essential for applications such as telecommunications,
financial systems, and power distribution. However, the primary sources of
error for GNSS and eLoran differ. For eLoran, the main source of error is
signal propagation delay over land, known as the additional secondary factor
(ASF). This delay, influenced by ground conductivity and weather conditions
along the signal path, is challenging to predict and mitigate. In this paper,
we measure the time difference (TD) between GPS and eLoran using a time
interval counter and analyze the correlations between eLoran/GPS TD and eleven
meteorological factors. Accurate estimation of eLoran/GPS TD could enable
eLoran to achieve timing accuracy comparable to that of GPS. We propose two
estimation models for eLoran/GPS TD and compare their performance with existing
TD estimation methods. The proposed WLR-AGRNN model captures the linear
relationships between meteorological factors and eLoran/GPS TD using weighted
linear regression (WLR) and models nonlinear relationships between outputs from
expert networks through an anisotropic general regression neural network
(AGRNN). The model incorporates terrain elevation to appropriately weight
meteorological data, as elevation influences signal propagation delay.
Experimental results based on four months of data demonstrate that the
WLR-AGRNN model outperforms other models, highlighting its effectiveness in
improving eLoran/GPS TD estimation accuracy.

</details>


### [8] [Reinforcement Learning-Based Policy Optimisation For Heterogeneous Radio Access](https://arxiv.org/abs/2506.15273)
*Anup Mishra,Čedomir Stefanović,Xiuqiang Xu,Petar Popovski,Israel Leyva-Mayorga*

Main category: eess.SP

TL;DR: 该论文研究了未来无线网络中异构服务间的无线资源共享，提出了一种基于强化学习的优化策略，显著提升了物联网设备的延迟性能，同时兼顾了宽带用户的吞吐量和能效。


<details>
  <summary>Details</summary>
Motivation: 探讨未来无线网络中异构服务（如IoT设备和宽带用户）的资源共享问题，以实现高效率且灵活的无线资源管理。

Method: 采用无授权访问框架，结合强化学习（基于双Q学习）优化物联网设备的重传策略，适应不同干扰水平并满足延迟目标。

Result: 提出的基于强化学习的访问策略显著改善了物联网用户的延迟性能，同时在RAN切片和共享场景下保持了宽带用户的吞吐量和能效。

Conclusion: 研究显示，RAN共享在低IoT流量时能效更优，而RAN切片在高IoT流量时表现更佳。

Abstract: Flexible and efficient wireless resource sharing across heterogeneous
services is a key objective for future wireless networks. In this context, we
investigate the performance of a system where latency-constrained
internet-of-things (IoT) devices coexist with a broadband user. The base
station adopts a grant-free access framework to manage resource allocation,
either through orthogonal radio access network (RAN) slicing or by allowing
shared access between services. For the IoT users, we propose a reinforcement
learning (RL) approach based on double Q-Learning (QL) to optimise their
repetition-based transmission strategy, allowing them to adapt to varying
levels of interference and meet a predefined latency target. We evaluate the
system's performance in terms of the cumulative distribution function of IoT
users' latency, as well as the broadband user's throughput and energy
efficiency (EE). Our results show that the proposed RL-based access policies
significantly enhance the latency performance of IoT users in both RAN Slicing
and RAN Sharing scenarios, while preserving desirable broadband throughput and
EE. Furthermore, the proposed policies enable RAN Sharing to be
energy-efficient at low IoT traffic levels, and RAN Slicing to be favourable
under high IoT traffic.

</details>


### [9] [Urban RIS-Assisted HAP Networks: Performance Analysis Using Stochastic Geometry](https://arxiv.org/abs/2506.15338)
*Islam M. Tanash,Ayush Kumar Dwivedi,Taneli Riihonen*

Main category: eess.SP

TL;DR: 本研究提出了一种由可重构智能表面（RIS）支持的高空平台（HAP）网络模型，分析了其在城市环境中的覆盖概率和容量表现，展示了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决城市环境中高空平台网络的连接性和干扰问题，通过RIS和统计信道建模优化性能。

Method: 采用泊松点过程建模HAP和RIS的不规则分布，矩形布尔方案模拟建筑遮挡，基于广义贝塔分布统计表征信道，分析覆盖概率和容量。

Result: 理论分析和仿真验证显示系统性能显著提升，遮挡效应有助于抑制同频干扰。

Conclusion: 该HAP-RIS系统可增强城市环境中的连接性并实现高效数据卸载，为未来网络设计提供新思路。

Abstract: This paper studies a high-altitude platform (HAP) network supported by
reconfigurable intelligent surfaces (RISs). The practical irregular placement
of HAPs and RISs is modeled using homogeneous Poisson point processes, while
buildings that cause blockages in urban areas are modeled as a Boolean scheme
of rectangles. We introduce a novel approach to characterize the statistical
channel based on generalized Beta prime distribution. Analytical expressions
for coverage probability and ergodic capacity in an interference-limited system
are derived and validated through Monte Carlo simulations. The findings show
notable performance improvements and reveal the impact of various system
parameters, including blockages effect which contribute in mitigating
interference from the other visible HAPs. This proposed system could enhance
connectivity and enable effective data offloading in urban environments.

</details>


### [10] [Effect of Signal Quantization on Performance Measures of a 1st Order One Dimensional Differential Microphone Array](https://arxiv.org/abs/2506.15463)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 论文研究了信号量化对一维一阶差分麦克风阵列性能的影响，发现量化主要影响零陷深度，而对波束方向图形状、指向性因子和前背比无明显影响。


<details>
  <summary>Details</summary>
Motivation: 量化是信号处理中的重要环节，但此前未研究其对一维一阶差分麦克风阵列性能的影响，尤其是对不同波束方向图的影响。

Method: 提出了一个解析表达式来描述量化后的波束形成输出，并研究了量化对波束方向图、指向性因子、前背比和零陷深度的影响。

Result: 仿真显示波束方向图形状不受量化位数影响，零陷深度随量化位数增加而提升；指向性因子和前背比保持不变。

Conclusion: 量化主要影响干扰抑制能力（零陷深度），而对其他性能指标影响较小，为差分麦克风阵列的量化设计提供了依据。

Abstract: In practical systems, recorded analog signals must be digitized for
processing, introducing quantization as a critical aspect of data acquisition.
While prior studies have examined quantization effects in various signal
processing contexts, its impact on differential microphone arrays (DMAs),
particularly in one-dimensional (1D) first-order configurations, remains
unexplored. This paper investigates the influence of signal quantization on
performance of first-order 1D DMAs across various beampatterns. An analytical
expression for quantized beamformed output for a first-order 1D DMA has been
formulated. The effect of signal quantization has been studied on array
performance measures such as the Beampattern, Directivity Factor (DF),
Front-to-Back Ratio (FBR), and null depth (ND). Simulation results reveal that
beampattern shape remains structurally invariant across quantization bit
depths, with quantization primarily affecting ND. DF and FBR remain constant
with the varying number of quantization bits. Additionally, ND is shown to be
frequency-independent; however, it increases with increasing quantization bit
depths, enhancing interference suppression. The study also examines the effect
of steering nulls across the azimuthal range, showing that ND degrades as the
null moves closer to the source look direction, indicating reduced interference
suppression.

</details>


### [11] [Analyzing URA Geometry for Enhanced Spatial Multiplexing and Extended Near-Field Coverage](https://arxiv.org/abs/2506.15470)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 本文研究了近场波束聚焦的局限性，提出了广义均匀矩形阵列的beamdepth概念，并分析了阵列几何形状对beamdepth和近场波束聚焦能力的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大规模天线阵列在高频段的部署，无线通信系统可能需要在辐射近场中操作，近场波束聚焦能实现空间多路复用，但现有研究未深入探讨其限制条件。

Method: 推导了广义均匀矩形阵列的beamdepth，定义了有效波束聚焦瑞利距离 (EBRD) 来量化近场边界，并分析了不同几何形状的阵列对EBRD和beamdepth的影响。

Result: 方形阵列的beamdepth最窄，但EBRD最小；而宽或高的阵列EBRD最大，能实现更高的多用户总速率（比方形阵列高3.5倍）。

Conclusion: 设计天线阵列时需权衡beamdepth和EBRD，宽或高的阵列在近场多用户通信中更具优势。

Abstract: With the deployment of large antenna arrays at high frequency bands, future
wireless communication systems are likely to operate in the radiative
near-field. Unlike far-field beam steering, near-field beams can be focused
within a spatial region of finite depth, enabling spatial multiplexing in both
the angular and range dimensions. This paper derives the beamdepth for a
generalized uniform rectangular array (URA) and investigates how array geometry
influences the near-field beamdepth and the limits where near-field
beamfocusing is achievable. To characterize the near-field boundary in terms of
beamfocusing and spatial multiplexing gains, we define the effective
beamfocusing Rayleigh distance (EBRD) for a generalized URA. Our analysis
reveals that while a square URA achieves the narrowest beamdepth, the EBRD is
maximized for a wide or tall URA. However, despite its narrow beamdepth, a
square URA may experience a reduction in multiuser sum rate due to its severely
constrained EBRD. Simulation results confirm that a wide or tall URA achieves a
sum rate of 3.5 X more than that of a square URA, benefiting from the extended
EBRD and improved spatial multiplexing capabilities.

</details>


### [12] [Near-Field SWIPT with gMIMO in the Upper Mid-Band: Opportunities, Challenges, and the Way Forward](https://arxiv.org/abs/2506.15670)
*Özlem Tugfe Demir,Mustafa Ozger,Ferdi Kara,Woong-Hee Lee,Emil Björnson*

Main category: eess.SP

TL;DR: 研究探讨了在7-24 GHz频段上结合SWIPT与gMIMO技术，利用近场传播实现高效能量和高速数据传输，支持6G网络需求。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络需要高容量和高效能源的通信系统，近场SWIPT结合gMIMO技术为此提供了独特解决方案。

Method: 利用球面波传播、波束聚焦和大规模空间复用技术，结合先进信道估计、预编码策略和动态阵列配置。

Result: 通过案例研究验证了在密集动态环境中优化能量收集和数据吞吐量的可行性。

Conclusion: 该研究为能源自治的IoE部署和智能工厂网络等6G应用提供了技术支持。

Abstract: This paper explores the integration of simultaneous wireless information and
power transfer (SWIPT) with gigantic multiple-input multiple-output (gMIMO)
technology operating in the upper mid-band frequency range (7-24 GHz). The
near-field propagation achieved by gMIMO introduces unique opportunities for
energy-efficient, high-capacity communication systems that cater to the demands
of 6G wireless networks. Exploiting spherical wave propagation, near-field
SWIPT with gMIMO enables precise energy and data delivery, enhancing spectral
efficiency through beamfocusing and massive spatial multiplexing. This paper
discusses theoretical principles, design challenges, and enabling solutions,
including advanced channel estimation techniques, precoding strategies, and
dynamic array configurations such as sparse and modular arrays. Through
analytical insights and a case study, this paper demonstrates the feasibility
of achieving optimized energy harvesting and data throughput in dense and
dynamic environments. These findings contribute to advancing energy-autonomous
Internet-of-Everything (IoE) deployments, smart factory networks, and other
energy-autonomous applications aligned with the goals of next-generation
wireless technologies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets](https://arxiv.org/abs/2506.15075)
*Samhita Kuili,Mohammadreza Amini,Burak Kantarci*

Main category: cs.CR

TL;DR: 文章研究5G-NR网络中针对空中干扰攻击的检测方法，通过卷积自编码器（CAE）在多种数据集上实现高效检测，并利用生成对抗网络（CWGAN-GP）平衡数据。CAE在检测性能上显著优于其他基准模型。


<details>
  <summary>Details</summary>
Motivation: 解决5G-NR网络中无线干扰攻击对信号质量的威胁，提升干扰检测的准确性和鲁棒性。

Method: 使用卷积自编码器（CAE）分析I/Q数据集，并结合CWGAN-GP平衡数据分布，对比CDAE和CSAE模型。

Result: CAE在干扰检测中表现出色，平均精度97.33%、召回率91.33%、F1-score 94.08%、准确率94.35%。

Conclusion: CAE在复杂数据集上具有更强的干扰检测能力，适合实际5G网络安全防护。

Abstract: In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [14] [An Integrated Sensing and Communication System for Time-Sensitive Targets with Random Arrivals](https://arxiv.org/abs/2506.15045)
*Homa Nikbakht,Yonina C. Eldar,H. Vincent Poor*

Main category: cs.IT

TL;DR: 该论文提出了一种双静态MIMO ISAC系统，用于在6G网络中实现超可靠低延迟通信（URLLC）和感知功能的联合优化。通过脏纸编码（DPC）技术减少干扰，同时平衡eMBB速率、URLLC可靠性和目标检测概率。


<details>
  <summary>Details</summary>
Motivation: 6G网络的集成感知与通信（ISAC）技术需要支持智能城市和自动驾驶等应用，这些应用对超可靠低延迟通信（URLLC）有严格要求。现有的功率共享和时间共享方案无法高效满足这些需求。

Method: 设计了一种双静态MIMO ISAC系统，利用DPC技术减少eMBB和感知信号的干扰。URLLC的传输通过感知接收器（SR）触发，同时采用噪声处理和连续干扰消除两种方法来解码eMBB消息。

Result: 数值分析表明，所提出的基于DPC的ISAC方案在有限块长度（FBL）下，显著优于传统功率共享和时间共享方案，能够同时提升eMBB传输速率并满足URLLC和感知约束。

Conclusion: 基于DPC的ISAC系统有效解决了6G网络中联合感知与通信的挑战，尤其适用于需要高可靠性和低延迟的应用场景。

Abstract: In 6G networks, integrated sensing and communication (ISAC) is envisioned as
a key technology that enables wireless systems to perform joint sensing and
communication using shared hardware, antennas and spectrum. ISAC designs
facilitate emerging applications such as smart cities and autonomous driving.
Such applications also demand ultra-reliable and low-latency communication
(URLLC). Thus, an ISAC-enabled URLLC system can prioritize time-sensitive
targets and ensure information delivery under strict latency and reliability
constraints. We propose a bi-static MIMO ISAC system to detect the arrival of
URLLC messages and prioritize their delivery. In this system, a base station
(BS) communicates with a user equipment (UE) and a sensing receiver (SR) is
deployed to collect echo signals reflected from a target of interest. The BS
regularly transmits messages of enhanced mobile broadband (eMBB) services to
the UE. During each eMBB transmission, if the SR senses the presence of a
target of interest, it immediately triggers the transmission of an additional
URLLC message. To reinforce URLLC transmissions, we propose a dirty-paper
coding (DPC)-based technique that mitigates the interference of both eMBB and
sensing signals. To decode the eMBB message, we consider two approaches for
handling the URLLC interference: treating interference as noise and successive
interference cancellation. For this system, we formulate the
rate-reliability-detection trade-off in the finite blocklength (FBL) regime by
evaluating the communication rate of the eMBB transmissions, the reliability of
the URLLC transmissions and the probability of the target detection. Our
numerical analysis show that our proposed DPC-based ISAC scheme significantly
outperforms power-sharing and traditional time-sharing schemes. In particular,
it achieves higher eMBB transmission rate while satisfying both URLLC and
sensing constraints.

</details>


### [15] [MIMO Systems Aided by Microwave Linear Analog Computers: Capacity-Achieving Architectures with Reduced Circuit Complexity](https://arxiv.org/abs/2506.15052)
*Matteo Nerini,Bruno Clerckx*

Main category: cs.IT

TL;DR: 提出了基于图论的MiLAC模型，设计低复杂度且性能优异的stem-connected MiLAC架构，解决了传统MiLAC电路复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 为满足未来无线网络对大规模天线阵列的需求，需解决巨型MIMO系统中的硬件和计算成本问题。

Method: 利用图论模型设计低复杂度的stem-connected MiLAC架构，并提供闭式容量优化方案。

Result: 理论分析和数值模拟表明，stem-connected MiLAC在保持高容量的同时，复杂度与天线数量成线性关系。

Conclusion: stem-connected MiLAC是一种高性能、可扩展的巨型MIMO解决方案。

Abstract: To meet the demands of future wireless networks, antenna arrays must scale
from massive multiple-input multiple-output (MIMO) to gigantic MIMO, involving
even larger numbers of antennas. To address the hardware and computational cost
of gigantic MIMO, several strategies are available that shift processing from
the digital to the analog domain. Among them, microwave linear analog computers
(MiLACs) offer a compelling solution by enabling fully analog beamforming
through reconfigurable microwave networks. Prior work has focused on
fully-connected MiLACs, whose ports are all interconnected to each other via
tunable impedance components. Although such MiLACs are capacity-achieving,
their circuit complexity, given by the number of required impedance components,
scales quadratically with the number of antennas, limiting their practicality.
To solve this issue, in this paper, we propose a graph theoretical model of
MiLAC facilitating the systematic design of lower-complexity MiLAC
architectures. Leveraging this model, we propose stem-connected MiLACs as a
family of MiLAC architectures maintaining capacity-achieving performance while
drastically reducing the circuit complexity. Besides, we optimize
stem-connected MiLACs with a closed-form capacity-achieving solution. Our
theoretical analysis, confirmed by numerical simulations, shows that
stem-connected MiLACs are capacity-achieving, but with circuit complexity that
scales linearly with the number of antennas, enabling high-performance,
scalable, gigantic MIMO.

</details>


### [16] [In-Context Learning for Gradient-Free Receiver Adaptation: Principles, Applications, and Theory](https://arxiv.org/abs/2506.15176)
*Matteo Zecchin,Tomer Raviv,Dileep Kalathil,Krishna Narayanan,Nir Shlezinger,Osvaldo Simeone*

Main category: cs.IT

TL;DR: 该论文提出了一种基于上下文学习（ICL）的无梯度自适应技术，用于无线接收器的动态适应，避免在线重新训练的需求。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统自适应策略（如联合训练、元学习等）在灵活性和梯度优化需求方面的局限性。

Method: 采用基于Transformer和结构化状态空间模型（SSM）的ICL框架，利用上下文信息实现自适应。

Result: 研究表明，ICL是一种高效且理论基础扎实的实时接收器自适应方法，适用于大规模MIMO网络。

Conclusion: ICL提供了一种无需在线训练的实时自适应解决方案，拓展了无线接收器的应用潜力。

Abstract: In recent years, deep learning has facilitated the creation of wireless
receivers capable of functioning effectively in conditions that challenge
traditional model-based designs. Leveraging programmable hardware
architectures, deep learning-based receivers offer the potential to dynamically
adapt to varying channel environments. However, current adaptation strategies,
including joint training, hypernetwork-based methods, and meta-learning, either
demonstrate limited flexibility or necessitate explicit optimization through
gradient descent. This paper presents gradient-free adaptation techniques
rooted in the emerging paradigm of in-context learning (ICL). We review
architectural frameworks for ICL based on Transformer models and structured
state-space models (SSMs), alongside theoretical insights into how sequence
models effectively learn adaptation from contextual information. Further, we
explore the application of ICL to cell-free massive MIMO networks, providing
both theoretical analyses and empirical evidence. Our findings indicate that
ICL represents a principled and efficient approach to real-time receiver
adaptation using pilot signals and auxiliary contextual information-without
requiring online retraining.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [17] [Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models](https://arxiv.org/abs/2506.15530)
*Teysir Baoueb,Xiaoyu Bie,Xi Wang,Gaël Richard*

Main category: cs.SD

TL;DR: 论文探讨了如何利用现有的文本到音乐扩散模型进行乐器编辑，通过选择合适的时间步长实现内容保留与音色调整的平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到音乐生成模型为音乐创作提供了创新工具，但对生成过程的精确控制仍是一大挑战。本文旨在解决如何在保留音频内容的同时编辑乐器音色的问题。

Method: 基于预训练的文本到音乐扩散模型，通过选择由乐器分类器确定的中间时间步长，在不额外训练模型或影响生成速度的前提下进行乐器编辑。

Result: 方法能够在保留原始音频内容的同时有效地实现乐器音色的编辑，展示了模型在乐器编辑任务中的潜力。

Conclusion: 通过巧妙选择时间步长，预训练的文本到音乐扩散模型可用于乐器编辑，为音乐创作提供了新的工具和可能性。

Abstract: Breakthroughs in text-to-music generation models are transforming the
creative landscape, equipping musicians with innovative tools for composition
and experimentation like never before. However, controlling the generation
process to achieve a specific desired outcome remains a significant challenge.
Even a minor change in the text prompt, combined with the same random seed, can
drastically alter the generated piece. In this paper, we explore the
application of existing text-to-music diffusion models for instrument editing.
Specifically, for an existing audio track, we aim to leverage a pretrained
text-to-music diffusion model to edit the instrument while preserving the
underlying content. Based on the insight that the model first focuses on the
overall structure or content of the audio, then adds instrument information,
and finally refines the quality, we show that selecting a well-chosen
intermediate timestep, identified through an instrument classifier, yields a
balance between preserving the original piece's content and achieving the
desired timbre. Our method does not require additional training of the
text-to-music diffusion model, nor does it compromise the generation process's
speed.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.AI

TL;DR: 论文提出了一种基于无人机和船只协作的海上计算卸载与资源分配方法，利用Lyapunov优化和异构智能体强化学习解决不确定任务问题。


<details>
  <summary>Details</summary>
Motivation: 海上物联网（MIoT）的计算需求迅速增长，但其任务的不确定性导致计算卸载和资源分配效率低下，需通过无人机和船只协作解决。

Method: 提出协作MEC框架，结合Lyapunov优化处理任务不确定性，并通过异构智能体软演员-评论家方法（HASAC）解决马尔可夫游戏问题。

Result: 仿真实验验证了所提方法在计算卸载和资源分配中的有效性。

Conclusion: 通过无人机与船只协作及强化学习，能高效解决海上物联网的不确定任务问题。

Abstract: The computation demands from the maritime Internet of Things (MIoT) increase
rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels
based multi-access edge computing (MEC) can fulfill these MIoT requirements.
However, the uncertain maritime tasks present significant challenges of
inefficient computation offloading and resource allocation. In this paper, we
focus on the maritime computation offloading and resource allocation through
the cooperation of UAVs and vessels, with consideration of uncertain tasks.
Specifically, we propose a cooperative MEC framework for computation offloading
and resource allocation, including MIoT devices, UAVs and vessels. Then, we
formulate the optimization problem to minimize the total execution time. As for
the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the
unpredictable task arrivals and varying computational resource availability. By
converting the long-term constraints into short-term constraints, we obtain a
set of small-scale optimization problems. Further, considering the
heterogeneity of actions and resources of UAVs and vessels, we reformulate the
small-scale optimization problem into a Markov game (MG). Moreover, a
heterogeneous-agent soft actor-critic is proposed to sequentially update
various neural networks and effectively solve the MG problem. Finally,
simulations are conducted to verify the effectiveness in addressing
computational offloading and resource allocation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [19] [Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations](https://arxiv.org/abs/2506.14795)
*Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu*

Main category: quant-ph

TL;DR: 该研究通过评估量子神经网络（QNNs）的性能，展示了其在风力能源预测中相较于传统方法的优势。


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习（QML）的实际应用潜力，尤其是对现有NISQ设备限制的质疑。

Method: 构建并评估12种QNN配置，结合两种量子特征映射和六种纠缠策略进行实验。

Result: QNNs在风力预测任务中达到93%的准确率，显示其优于传统方法。

Conclusion: QNNs展示了QML在现实应用中的潜力，为未来研究提供了方向。

Abstract: Quantum Machine Learning (QML) is an emerging field at the intersection of
quantum computing and machine learning, aiming to enhance classical machine
learning methods by leveraging quantum mechanics principles such as
entanglement and superposition. However, skepticism persists regarding the
practical advantages of QML, mainly due to the current limitations of noisy
intermediate-scale quantum (NISQ) devices. This study addresses these concerns
by extensively assessing Quantum Neural Networks (QNNs)-quantum-inspired
counterparts of Artificial Neural Networks (ANNs), demonstrating their
effectiveness compared to classical methods. We systematically construct and
evaluate twelve distinct QNN configurations, utilizing two unique quantum
feature maps combined with six different entanglement strategies for ansatz
design. Experiments conducted on a wind energy dataset reveal that QNNs
employing the Z feature map achieve up to 93% prediction accuracy when
forecasting wind power output using only four input parameters. Our findings
show that QNNs outperform classical methods in predictive tasks, underscoring
the potential of QML in real-world applications.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [20] [Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels](https://arxiv.org/abs/2506.15105)
*David Nozadze,Zurab Kiguradze,Amendra Koul,Mike Sapozhnikov*

Main category: eess.SY

TL;DR: 提出两种新指标（SILD和FOM_SILD）用于量化P/N skew对超高速互连性能的影响，并通过实验和仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI工作负载和数据中心需求的增长，超高速互连的需求日益迫切，传统方法在量化P/N skew影响方面不足。

Method: 开发了Skew-Induced Insertion Loss Deviation (SILD)及其互补指标Figure of Merit (FOM_SILD)，并通过测量S参数和仿真224G PAM4 SerDes验证。

Result: 测量和仿真结果显示FOM_SILD具有互易性，并与误码率趋势强相关。

Conclusion: 该方法为下一代超高速互连中的P/N skew分析提供了鲁棒框架。

Abstract: The rise of AI workloads and growing data center demands have driven the need
for ultra-high-speed interconnects exceeding 200 Gb/s. As unit intervals (UI)
shrink, even a few picoseconds of P/N skew can degrade serializer-deserializer
(SerDes) performance. Traditional methods for quantifying skew fall short in
capturing its impact. We introduce two new metrics: 1) Skew-Induced Insertion
Loss Deviation (SILD) and 2) its complementary Figure of Merit (FOM_SILD),
analytically developed to assess P/N skew effects. Measured S-parameters
confirm FOM_SILD reciprocity, while simulations of 224G PAM4 SerDes show strong
correlation with bit error rate (BER) trends. This approach offers a robust
framework for analyzing skew in next-generation ultra-high-speed interconnects.

</details>
