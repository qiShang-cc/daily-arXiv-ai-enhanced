<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 33]
- [cs.RO](#cs.RO) [Total: 54]
- [cs.AI](#cs.AI) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.NE](#cs.NE) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [stat.ML](#stat.ML) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.CV](#cs.CV) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Development of AI-integrated infrastructure with biomedical device and mobile app for neonatal vital monitoring during and in between kangaroo care sessions](https://arxiv.org/abs/2509.10489)
*Saptarshi Purkayastha,Hrishikesh Bhagwat,Keerthika Sunchu,Orlando Hoilett,Eddy Odari,Reuben Thuo,Martin Wafula,Celia Kariuki,Sherri Bucher*

Main category: eess.SP

TL;DR: 该论文提出了一种集成系统，结合了新型生物医学设备NeoWarm、移动应用NeoRoo和机器学习基础设施NeoSmartML，用于在袋鼠式母亲护理中实现全面的生命体征监测。


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家中，早产儿死亡率仍是一个严峻问题，持续的生命体征监测对早期发现致命状况至关重要。

Method: 系统通过优化功耗的设备、离线优先的移动应用及机器学习基础设施，实现对生命体征的全面监测。

Result: 实验验证表明系统在资源受限环境中具有可行性，但心率和温度检测及风险分类模型还需进一步优化。

Conclusion: 该集成系统为解决早产儿死亡率问题提供了实用解决方案，但仍需技术优化以适应更广泛的应用场景。

Abstract: Premature infant mortality remains a critical challenge in low- and
middle-income countries (LMICs), with continuous vital sign monitoring being
essential for early detection of life-threatening conditions. This paper
presents an integrated system combining NeoWarm, a novel biomedical device,
with NeoRoo, a mobile application, and NeoSmartML, a machine learning
infrastructure, to enable comprehensive vital sign monitoring during Kangaroo
Mother Care (KMC). Our power-optimized device achieves 6-6.5 days of continuous
operation on a single charge, while the mobile application implements an
offline-first architecture with efficient data synchronization. The optical
character recognition pipeline demonstrates promising accuracy (F1 scores
0.78-0.875) for automated vital sign extraction from existing NICU monitors.
Experimental validation shows the system's feasibility for deployment in
resource-constrained settings, though further optimization of heart rate and
temperature detection, along with the risk classification foundation model is
needed.

</details>


### [2] [Distributed Gossip-GAN for Low-overhead CSI Feedback Training in FDD mMIMO-OFDM Systems](https://arxiv.org/abs/2509.10490)
*Yuwen Cao,Guijun Liu,Tomoaki Ohtsuki,Howard H. Yang,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 本文提出了一种基于Gossip-GAN的低开销、保护隐私的CSI反馈训练框架，解决了现有方法在大规模数据依赖、隐私问题和移动场景下的灾难性遗忘等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度自编码器的CSI反馈方法依赖大规模数据训练，导致带宽占用高和隐私问题，且在移动场景和新环境中表现不佳。

Method: 提出Gossip-GAN框架，用户通过少量数据训练GAN模型，并结合分布式gossip学习策略避免过拟合并加速训练。

Result: 仿真结果表明，Gossip-GAN在真实数据集上达到与集中式训练相似的精度，解决灾难性遗忘问题，并显著减少上行带宽占用。

Conclusion: Gossip-GAN是一种高效、隐私保护的CSI反馈训练框架，同时在移动场景中表现出鲁棒性。

Abstract: The deep autoencoder (DAE) framework has turned out to be efficient in
reducing the channel state information (CSI) feedback overhead in massive
multiple-input multipleoutput (mMIMO) systems. However, these DAE approaches
presented in prior works rely heavily on large-scale data collected through the
base station (BS) for model training, thus rendering excessive bandwidth usage
and data privacy issues, particularly for mMIMO systems. When considering
users' mobility and encountering new channel environments, the existing CSI
feedback models may often need to be retrained. Returning back to previous
environments, however, will make these models perform poorly and face the risk
of catastrophic forgetting. To solve the above challenging problems, we propose
a novel gossiping generative adversarial network (Gossip-GAN)-aided CSI
feedback training framework. Notably, Gossip-GAN enables the CSI feedback
training with low-overhead while preserving users' privacy. Specially, each
user collects a small amount of data to train a GAN model. Meanwhile, a fully
distributed gossip-learning strategy is exploited to avoid model overfitting,
and to accelerate the model training as well. Simulation results demonstrate
that Gossip-GAN can i) achieve a similar CSI feedback accuracy as centralized
training with real-world datasets, ii) address catastrophic forgetting
challenges in mobile scenarios, and iii) greatly reduce the uplink bandwidth
usage. Besides, our results show that the proposed approach possesses an
inherent robustness.

</details>


### [3] [FlowECG: Using Flow Matching to Create a More Efficient ECG Signal Generator](https://arxiv.org/abs/2509.10491)
*Vitalii Bondar,Serhii Semenov,Vira Babenko,Dmytro Holovniak*

Main category: eess.SP

TL;DR: FlowECG是一种基于流匹配的合成心电图生成方法，相比传统扩散方法，计算效率显著提升，适合临床部署。


<details>
  <summary>Details</summary>
Motivation: 解决当前扩散方法在合成心电图中计算开销大的问题，以满足隐私保护数据共享和训练数据增强的需求。

Method: 采用流匹配方法替代扩散过程，通过常微分方程求解直接从噪声分布到数据分布的传输路径。

Result: FlowECG性能与SSSD-ECG相当，但计算量减少一个数量级（10-25次评估vs.200次）。

Conclusion: FlowECG在保持生成质量的同时大幅提升效率，适合资源有限的临床环境。

Abstract: Synthetic electrocardiogram generation serves medical AI applications
requiring privacy-preserving data sharing and training dataset augmentation.
Current diffusion-based methods achieve high generation quality but require
hundreds of neural network evaluations during sampling, creating computational
bottlenecks for clinical deployment. We propose FlowECG, a flow matching
approach that adapts the SSSD-ECG architecture by replacing the iterative
diffusion process with continuous flow dynamics. Flow matching learns direct
transport paths from noise to data distributions through ordinary differential
equation solving. We evaluate our method on the PTB-XL dataset using Dynamic
Time Warping, Wasserstein distance, Maximum Mean Discrepancy, and spectral
similarity metrics. FlowECG matches SSSD-ECG performance at 200 neural function
evaluations, outperforming the baseline on three metrics. The key finding shows
that FlowECG maintains generation quality with substantially fewer sampling
steps, achieving comparable results with 10-25 evaluations compared to 200 for
diffusion methods. This efficiency improvement reduces computational
requirements by an order of magnitude while preserving physiologically
realistic 12-lead ECG characteristics. The approach enables practical
deployment in resource-limited clinical settings where real-time generation or
large-scale synthetic data creation is needed.

</details>


### [4] [Uplink and Downlink Communications in Segmented Waveguide-Enabled Pinching-Antenna Systems (SWANs)](https://arxiv.org/abs/2509.10666)
*Chongjun Ouyang,Hao Jiang,Zhaolin Wang,Yuanwei Liu,Zhiguo Ding*

Main category: eess.SP

TL;DR: 提出了分段波导夹持天线系统（SWAN），通过分段波导和多天线协议提升信号传输性能，优于传统单波导系统。


<details>
  <summary>Details</summary>
Motivation: 解决传统单波导夹持天线系统中信号重辐射和传播损耗问题，提升上行和下行的信号质量。

Method: 采用分段波导和多天线协议（SS、SA、SM），提出天线布局算法，优化信噪比（SNR）。

Result: 分段结构减少了传播损耗和路径损耗，SM协议性能最优，SWAN系统SNR高于传统系统。

Conclusion: SWAN系统通过分段设计和多协议优化，显著提升了通信性能，适用于上下行场景。

Abstract: A segmented waveguide-enabled pinching-antenna system (SWAN) is proposed, in
which a segmented waveguide composed of multiple short dielectric waveguide
segments is employed to radiate or receive signals through the pinching
antennas (PAs) deployed on each segment. Based on this architecture, three
practical operating protocols are proposed: segment selection (SS), segment
aggregation (SA), and segment multiplexing (SM). For uplink SWAN
communications, where one PA is activated per segment, the segmented structure
eliminates the inter-antenna radiation effect, i.e., signals captured by one PA
may re-radiate through other PAs along the same waveguide. This yields a
tractable and physically consistent uplink signal model for a multi-PA
pinching-antenna system (PASS), which has not been established for conventional
PASS using a single long waveguide. Building on this model, PA placement
algorithms are proposed to maximize the uplink signal-to-noise ratio (SNR).
Closed-form expressions for the received SNR under the three protocols are
derived, and the corresponding scaling laws with respect to the number of
segments are analyzed. It is proven that the segmented architecture reduces
both the average PA-to-user distance and the PA-to-feed distance, thereby
mitigating both large-scale path loss and in-waveguide propagation loss. These
results are extended to downlink SWAN communications, where multiple PAs are
activated per segment, and PA placement methods are proposed to maximize the
downlink received SNR under the three protocols. Numerical results demonstrate
that: \romannumeral1) among the three protocols, SM achieves the best
performance, followed by SA and then SS; and \romannumeral2) for all protocols,
the proposed SWAN achieves a higher SNR than conventional PASS with a single
long waveguide in both uplink and downlink scenarios.

</details>


### [5] [Quasi-Deterministic Modeling of Sub-THz Band Access Channels in Street Canyon Environments](https://arxiv.org/abs/2509.10752)
*Minseok Kim,Masato Yomoda,Minghe Mao,Nobuaki Kuno,Koshiro Kitao,Satoshi Suyama*

Main category: eess.SP

TL;DR: 该论文通过双方向信道测量，研究了城市街道峡谷中154 GHz和300 GHz的信道传播特性，提出了结合确定性和随机分量的准确定性信道模型。


<details>
  <summary>Details</summary>
Motivation: 研究亚太赫兹频段（100-300 GHz）在6G移动网络中的传播特性，填补现有信道模型的不足。

Method: 在户外街道峡谷环境中进行双方向信道测量，分析LOS和NLOS条件下的信道特性，并提出准确定性信道模型。

Result: 揭示了多径簇的共同与差异特性及其频率依赖性，提供了路径损耗、延迟扩展等大尺度参数。

Conclusion: 结果为未来6G系统的准确信道模型开发提供了重要参考。

Abstract: Sub-terahertz (sub-THz) frequencies (100--300 GHz) are expected to play a key
role in beyond-5G and 6G mobile networks. However, their quasi-optical
propagation characteristics require new channel models beyond sub-100 GHz
extrapolations. This paper presents an extensive double-directional (D-D)
channel measurement campaign conducted in an outdoor street-canyon environment
at 154 GHz and 300 GHz under both line-of-sight (LoS) and non-line-of-sight
(NLoS) conditions using an in-house-developed channel sounder. Based on these
measurements, clustering with merged datasets across the two frequencies
enables comparative analyses that identify both common and distinct multipath
clusters, as well as the frequency dependence of cluster-level characteristics.
A quasi-deterministic (QD) channel model is then proposed, combining
deterministic components, such as LoS and single-bounce reflections from side
walls, with random components. Large-scale parameters (path loss, delay spread,
angular spread, and Rician K-factor) are also evaluated. These results provide
valuable insights into sub-THz propagation in urban street canyons and
contribute toward the development of accurate, channel models for future 6G
systems.

</details>


### [6] [Hybrid Atomic Norm Sparse/Diffuse Channel Estimation](https://arxiv.org/abs/2509.10770)
*Lei Lyu,Urbashi Mitra*

Main category: eess.SP

TL;DR: 本文提出了一种频域混合稀疏/扩散(HSD)信道模型，设计了HALS算法用于稀疏/扩散成分的估计，并进行了理论分析，验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究如何有效估计信道中的稀疏和扩散成分，以提升信道估计性能。

Method: 提出了混合原子最小二乘(HALS)算法，结合原子和l2正则化进行稀疏/扩散成分估计，并分析了拉格朗日对偶问题及频率支持估计。

Result: 仿真和实验数据验证了方法的有效性，并揭示了信道性能与稀疏路径和扩散成分能量之间的权衡。

Conclusion: 该方法在信道估计中表现出色，但对稀疏路径和扩散成分的能量有明确权衡。

Abstract: In this paper, the hybrid sparse/diffuse (HSD) channel model in frequency
domain is proposed. Based on the structural analysis on the resolvable paths
and diffuse scattering statistics in the channel, the Hybrid
Atomic-Least-Squares (HALS) algorithm is designed to estimate sparse/diffuse
components with a combined atomic and l2 regularization. A theoretical analysis
is conducted on the Lagrangian dual problem and the conditions needed to be
satisfied by primal and dual solutions are provided. This analysis, in turn,
suggests an algorithm for optimal frequency support estimation. Debiased
methods for improved channel estimation are provided. Given differing amounts
of side information, performance bounds are derived in terms of a genie-aided
estimator and constrained Cramer-Rao lower bounds (CRLB). Numerical results via
simulations on synthetic data as well as real experimental data validate the
efficacy of the proposed method. There are clear tradeoffs with respect to the
properties of the channel with respect to performance: sparsity of specular
paths and relative energy of diffuse components.

</details>


### [7] [Self-Calibrating Integrate-and-Fire Time Encoding Machine](https://arxiv.org/abs/2509.10831)
*Maya Mekel,Vered Karp,Satish Mulleti,Alejandro Cohen*

Main category: eess.SP

TL;DR: 论文提出了一种新型自校准积分-放电时间编码机（S-IF-TEM），能够在采样过程中同时进行参数估计和信号重建，有效减少失配效应。


<details>
  <summary>Details</summary>
Motivation: 现有IF-TEM模型未考虑设备失配和非线性效应，导致重建误差大。论文提出P-IF-TEM框架以解决这些问题。

Method: 开发了P-IF-TEM模型，扩展经典模型，涵盖参数未知/时变、放电时间可变及非线性工作区情况。推导了采样率和重建条件。

Result: 自校准条件下实现完美重建，性能提升超过59dB。

Conclusion: S-IF-TEM框架显著提高了信号重建精度，适用于实际应用中复杂场景。

Abstract: In this paper, we introduce a novel self-calibrating integrate-and-fire time
encoding machine (S-IF-TEM) that enables simultaneous parameter estimation and
signal reconstruction during sampling, thereby effectively mitigating mismatch
effects. The proposed framework is developed over a new practical IF-TEM
(P-IF-TEM) setting, which extends classical models by incorporating device
mismatches and imperfections that can otherwise lead to significant
reconstruction errors. Unlike existing IF-TEM settings, P-IF-TEM accounts for
scenarios where (i) system parameters are inaccurately known and may vary over
time, (ii) the integrator discharge time after firings can vary, and (iii) the
sampler may operate in its nonlinear region under large input dynamic ranges.
For this practical model, we derive sampling rate bounds and reconstruction
conditions that ensure perfect recovery. Analytical results establish the
conditions for perfect reconstruction under self-calibration, and evaluation
studies demonstrate substantial improvements - exceeding 59dB - highlighting
the effectiveness of the proposed approach.

</details>


### [8] [Landscape Analysis of Simultaneous Blind Deconvolution and Phase Retrieval via Structured Low-Rank Tensor Recovery](https://arxiv.org/abs/2509.10834)
*Xiao Liang,Zhen Qin,Zhihui Zhu,Shuang Li*

Main category: eess.SP

TL;DR: 该论文通过结构化低秩张量恢复框架，对同时盲去卷积和相位恢复（BDPR）问题进行了几何分析。为了避免直接处理复杂的高维张量问题，提出了一个更易分析的张量感知问题。作者研究了其全局优化特性，并证明了Riemannian梯度下降的线性收敛性。


<details>
  <summary>Details</summary>
Motivation: 研究BDPR问题时，直接分析高维张量的优化景观十分困难。因此，作者希望通过引入一个更易分析的张量感知问题，保留原问题的核心结构特征，从而为BDPR问题的解决提供理论基础。

Method: 作者提出了一种张量感知问题作为替代模型，通过分析其全局优化景观和Riemannian梯度下降（RGD）的性能，证明了其在单位球上的线性收敛性，并将其结果扩展到测量噪声下的鲁棒性分析。

Result: 理论分析和数值实验表明，RGD在张量感知问题上具有线性收敛性，并且在噪声情况下表现出鲁棒性。这为解决原始BDPR问题提供了理论支持。

Conclusion: 通过结构化低秩张量恢复框架，论文为BDPR问题提供了一个理论分析工具，证明了RGD的有效性，并为解决实际问题提供了指导。

Abstract: This paper presents a geometric analysis of the simultaneous blind
deconvolution and phase retrieval (BDPR) problem via a structured low-rank
tensor recovery framework. Due to the highly complicated structure of the
associated sensing tensor, directly characterizing its optimization landscape
is intractable. To address this, we introduce a tensor sensing problem as a
tractable surrogate that preserves the essential structural features of the
target low-rank tensor while enabling rigorous theoretical analysis. As a first
step toward understanding this surrogate model, we study the corresponding
population risk, which captures key aspects of the underlying low-rank tensor
structure. We characterize the global landscape of the population risk on the
unit sphere and show that Riemannian gradient descent (RGD) converges linearly
under mild conditions. We then extend the analysis to the tensor sensing
problem, establishing local geometric properties, proving convergence
guarantees for RGD, and quantifying robustness under measurement noise. Our
theoretical results are further supported by extensive numerical experiments.
These findings offer foundational insights into the optimization landscape of
the structured low-rank tensor recovery problem, which equivalently
characterizes the original BDPR problem, thereby providing principled guidance
for solving the original BDPR problem.

</details>


### [9] [Online simplex-structured matrix factorization](https://arxiv.org/abs/2509.10857)
*Hugues Kouakou,José Henrique de Morais Goulart,Raffaele Vitale,Thomas Oberlin,David Rousseau,Cyril Ruckebusch,Nicolas Dobigeon*

Main category: eess.SP

TL;DR: 该论文提出了一种改进的在线处理方法，用于优化最小体积约束解混（MVCU）算法，通过仅在必要时更新解决方案，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 尽管MVCU算法在离线场景中表现良好，但在线应用时因计算和内存需求限制其扩展性。论文旨在解决这一问题。

Method: 基于现有MVCU算法，通过在线检查优化问题约束，仅在必要时更新解决方案，并仅处理和存储对SSMF几何约束有信息量的观测数据。

Result: 该方法在合成和真实数据集上表现出色，估计精度与离线MVCU相当，同时显著降低计算成本。

Conclusion: 论文提出的在线方法有效解决了MVCU算法在实时应用中的扩展性问题，同时保持了高精度。

Abstract: Simplex-structured matrix factorization (SSMF) is a common task encountered
in signal processing and machine learning. Minimum-volume constrained unmixing
(MVCU) algorithms are among the most widely used methods to perform this task.
While MVCU algorithms generally perform well in an offline setting, their
direct application to online scenarios suffers from scalability limitations due
to memory and computational demands. To overcome these limitations, this paper
proposes an approach which can build upon any off-the-shelf MVCU algorithm to
operate sequentially, i.e., to handle one observation at a time. The key idea
of the proposed method consists in updating the solution of MVCU only when
necessary, guided by an online check of the corresponding optimization problem
constraints. It only stores and processes observations identified as
informative with respect to the geometrical constraints underlying SSMF. We
demonstrate the effectiveness of the approach when analyzing synthetic and real
datasets, showing that it achieves estimation accuracy comparable to the
offline MVCU method upon which it relies, while significantly reducing the
computational cost.

</details>


### [10] [On the Impact of Downstream Tasks on Sampling and Reconstructing Noisy Graph Signals](https://arxiv.org/abs/2509.10874)
*Baskaran Sripathmanathan,Xiaowen Dong,Michael Bronstein*

Main category: eess.SP

TL;DR: 研究了图信号重建和分类任务中的样本选择，提出了适用于多种常见重建方法的分类误差通用理论特征，并与经典重建误差进行了比较。


<details>
  <summary>Details</summary>
Motivation: 探索图信号重建和分类任务中的优化方法，特别是针对样本选择和重建误差的理论分析与应用。

Method: 提出了适用于多种常见重建方法的分类误差通用理论特征，并将其应用于线性化图卷积网络的优化采样方法。

Result: 展示了新方法在图信号处理中的优势，优于其他基于图信号处理的方法。

Conclusion: 研究成果为图信号重建和分类任务提供了新的理论支持和实际应用优化方向。

Abstract: We investigate graph signal reconstruction and sample selection for
classification tasks. We present general theoretical characterisations of
classification error applicable to multiple commonly used reconstruction
methods, and compare that to the classical reconstruction error. We demonstrate
the applicability of our results by using them to derive new optimal sampling
methods for linearized graph convolutional networks, and show improvement over
other graph signal processing based methods.

</details>


### [11] [Forecasting Self-Similar User Traffic Demand Using Transformers in LEO Satellite Networks](https://arxiv.org/abs/2509.10917)
*Yekta Demirci,Guillaume Mantelet,Stéphane Martel,Jean-François Frigon,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 论文提出了一种基于Transformer的模型，用于预测新一代低地球轨道(LEO)卫星网络的用户流量需求，相比传统FARIMA模型，新模型在特定流量条件下实现了更高的预测精度。


<details>
  <summary>Details</summary>
Motivation: LEO卫星星座需要高精度的动态波束跳频，传统FARIMA模型因其计算复杂性和需为每个输入序列重新拟合的限制，无法满足需求。

Method: 提出了一种预训练的概率时间序列模型，利用Transformer和Prob-Sparse自注意力机制，在不同时间粒度和序列长度下进行预测。

Result: 基于Transformer的模型在特定流量条件下，预测精度比FARIMA模型提高了6%（以均方误差为指标）。

Conclusion: Transformer模型在LEO卫星网络流量预测中表现优于传统FARIMA模型，更具应用潜力。

Abstract: In this paper, we propose the use of a transformer-based model to address the
need for forecasting user traffic demand in the next generation Low Earth Orbit
(LEO) satellite networks. Considering a LEO satellite constellation, we present
the need to forecast the demand for the satellites in-orbit to utilize dynamic
beam-hopping in high granularity. We adopt a traffic dataset with second-order
self-similar characteristics. Given this traffic dataset, the Fractional
Auto-regressive Integrated Moving Average (FARIMA) model is considered a
benchmark forecasting solution. However, the constrained on-board processing
capabilities of LEO satellites, combined with the need to fit a new model for
each input sequence due to the nature of FARIMA, motivate the investigation of
alternative solutions. As an alternative, a pretrained probabilistic time
series model that utilizes transformers with a Prob-Sparse self-attention
mechanism is considered. The considered solution is investigated under
different time granularities with varying sequence and prediction lengths.
Concluding this paper, we provide extensive simulation results where the
transformer-based solution achieved up to six percent better forecasting
accuracy on certain traffic conditions using mean squared error as the
performance indicator.

</details>


### [12] [Design and Validation of a MATLAB-based GUI for Coarray Domain Analysis of Sparse Linear Arrays](https://arxiv.org/abs/2509.10926)
*Ashish Patwari,Ananya Pandey,Aditya Dabade,Priyadarshini Raiguru*

Main category: eess.SP

TL;DR: 该研究首次提出基于MATLAB App designer的GUI模拟器，用于分析稀疏线性阵列（SLAs）在差共线阵列（DCA）域的行为，填补了传统模拟器在共线阵列视角下的空白。


<details>
  <summary>Details</summary>
Motivation: 稀疏传感器阵列在无线通信、雷达、声纳等领域展现出显著优势，如降低系统复杂性和部署成本。然而，传统模拟器仅关注辐射模式可视化，缺乏对其在共线阵列域行为的分析工具。

Method: 通过MATLAB App designer开发GUI模拟器，用户可输入阵列配置、计算DCA、可视化权重函数图，并评估阵列的无空洞状态。

Result: 数值验证表明该工具的正确性和有效性，并展示了其在稀疏阵列研究中的潜力。

Conclusion: 该模拟器不仅支持进一步研究，还可作为教学工具，吸引年轻学者投身稀疏阵列设计领域。

Abstract: This work presents a first-of-its-kind graphical user interface (GUI)-based
simulator developed using MATLAB App designer for the comprehensive analysis of
sparse linear arrays (SLAs) in the difference coarray (DCA) domain. Sparse
sensor arrays have emerged as a critical solution in enhancing signal
detection, direction of arrival (DOA) estimation, and beamforming in fields
such as wireless communication, radar, sonar, and integrated sensing systems.
They offer several advantages over traditional uniform arrays, including
reduced system complexity, lower deployment costs, and improved mitigation of
mutual coupling effects. The tool enables users to input array configurations,
compute DCAs, visualize weight function graphs, and assess the hole-free status
of arrays, as applicable for coarray processing. Unlike conventional simulators
that focus on radiation pattern visualization (array pattern, main lobe and
sidelobe characteristics, azimuth cut, rectangular view, polar view etc.), this
tool addresses the behavior of SLAs from a coarray domain perspective.
Numerical validations demonstrate the tool's correctness, effectiveness, and
its potential to foster further research in sparse arrays. This simulator could
also be used as a teaching aid to drive home complicated topics and attract
young minds towards the fascinating field of sparse array design.

</details>


### [13] [Experimental Demonstration of Rate-Adaptation via Hybrid Polar-BCH Product Code for Flexible PON](https://arxiv.org/abs/2509.11081)
*Yifan Ye,Bin Chen,Xiang Li,Yi Lei,Zhiwei Liang,Qingqing Hu,Can Zhao,Yanni Ou*

Main category: eess.SP

TL;DR: 首次在16QAM相干无源光网络系统中验证了灵活速率的Polar-BCH乘积码，通过新型软硬判决混合解码器，在48公里传输后比传统BCH-BCH乘积码获得1.75 dB的功率增益。


<details>
  <summary>Details</summary>
Motivation: 研究灵活速率的Polar-BCH乘积码在16QAM相干无源光网络系统中的性能表现。

Method: 采用新型的软硬判决混合解码器，与传统的BCH-BCH乘积码进行对比。

Result: 在48公里传输后，新方法实现了1.75 dB的功率增益。

Conclusion: 灵活速率的Polar-BCH乘积码与新型解码器结合，显著提升了系统性能。

Abstract: The flexible-rate Polar-BCH product codes are experimentally demonstrated in
a coherent passive optical network system with 16QAM for the first time. Using
a new hybrid soft- and hard-decision decoder, we achieve a power gain of upto
1.75 dB over traditional BCH-BCH product codes after 48 km transmission.

</details>


### [14] [Nonreciprocal RIS-Aided Covert Channel Reciprocity Attacks and Countermeasures](https://arxiv.org/abs/2509.11117)
*Haoyu Wang,Jiawei Hu,Jiaqi Xu,Ying Ju,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 论文研究了在多天线无线系统中，可重构智能表面（RIS）技术可能导致的信道互易性攻击（CRACK）及其影响。通过提出一种基于深度强化学习的框架SecureCoder，论文展示了如何有效对抗CRACK，提升系统性能与安全性。


<details>
  <summary>Details</summary>
Motivation: RIS技术虽能提升无线通信性能，但其非互易性特性可能被利用进行CRACK攻击，导致通信速率下降和被动窃听风险。论文旨在揭示这种新型威胁并开发防御方案。

Method: 基于深度强化学习的框架SecureCoder，利用估计的上行信道状态信息（CSI）和用户速率反馈，优化下行预编码矩阵以抵御CRACK攻击。

Result: 仿真结果表明，NR-RIS CRACK会显著降低系统性能，而SecureCoder能有效提升吞吐量并减少安全威胁，增强系统稳健性。

Conclusion: 论文揭示了RIS技术潜在的安全漏洞，并提出了一种可行的防御框架SecureCoder，为未来RIS系统的安全设计提供了重要参考。

Abstract: Reconfigurable intelligent surface (RIS) technology enhances wireless
communication performance, but it also introduces new vulnerabilities that can
be exploited by adversaries. This paper investigates channel reciprocity attack
(CRACK) threats in multi-antenna wireless systems operating in time-division
duplexing mode using a physically consistent non-reciprocal RIS (NR-RIS) model.
CRACK can degrade communication rate and facilitate passive eavesdropping
behavior by distorting the downlink precoding, without requiring any additional
signal transmission or channel state information (CSI). Unlike conventional RIS
jamming strategies, the NR-RIS does not need synchronization with the
legitimate system and thus can operate with slow or fixed configurations to
implement CRACK, obscuring the distinction between the direct and RIS-induced
channels and thereby complicating corresponding defensive precoding designs. To
counter the CRACK threat posed by NR-RIS, we develop ``SecureCoder,'' a deep
reinforcement learning-based framework that can mitigate CRACK and determine an
improved downlink precoder matrix using the estimated uplink CSI and rate
feedback from the users. Simulation results demonstrate the severe performance
degradation caused by NR-RIS CRACK and validate the effectiveness of
SecureCoder in improving both throughput and reducing security threats, thereby
enhancing system robustness.

</details>


### [15] [Holographic interference surface: A proof of concept based on the principle of interferometry](https://arxiv.org/abs/2509.11193)
*Haifan Yin,Jindiao Huang,Ruikun Zhang,Jiwang Wu,Li Tan*

Main category: eess.SP

TL;DR: 提出了一种基于干涉测量原理的全息通信系统（HIS），通过电磁波干涉效应处理功率信息以估计信道状态信息（CSI），替代传统RF链，降低硬件复杂度和功耗。


<details>
  <summary>Details</summary>
Motivation: 传统无线通信架构依赖昂贵且高功耗的RF链，限制了超大规模阵列的实际部署，需寻求更高效的解决方案。

Method: 采用全息干涉面（HIS）技术，利用电磁波干涉效应处理功率信息，替代传统RF链，完成射频信号处理。

Result: 实验结果表明，HIS与理论预测一致，验证了其实用性及有效性。

Conclusion: 该研究为构建更具成本效益的无线通信架构提供了新范式。

Abstract: Revolutionizing communication architectures to achieve a balance between
enhanced performance and improved efficiency is becoming increasingly critical
for wireless communications as the era of ultra-large-scale arrays approaches.
In traditional communication architectures, radio frequency (RF) signals are
typically converted to baseband for subsequent processing through operations
such as filtering, analog-to-digital conversion and down-conversion, all of
which depend on expensive and power-intensive RF chains. The increased hardware
complexity and escalated power consumption resulting from this dependency
significantly limit the practical deployment of ultra-large-scale arrays. To
address these limitations, we propose a holographic communication system based
on the principle of interferometry, designated as holographic interference
surfaces (HIS). Utilizing the interference effect of electromagnetic waves, HIS
estimates the channel state information (CSI) by dealing solely with power
information, which enables the replacement of RF chains with power sensors and
completes the signal processing in radio frequency. As proof-of-concept
demonstrations, we implemented a prototype system based on principles of
holographic interference. Experimental results align well with theoretical
predictions, confirming the practical viability and effectiveness of the
proposed HIS. This work provides a new paradigm for building a more
cost-effective wireless communication architecture.

</details>


### [16] [Synesthesia of Machines (SoM)-Empowered Wireless Image Transmission over Complex Dynamic Channel](https://arxiv.org/abs/2509.11243)
*Haozhen Li,Ruide Zhang,Rongqing Zhang,Xiang Cheng*

Main category: eess.SP

TL;DR: 论文提出了一种基于机器联觉的动态信道自适应传输方案（DCAT），用于解决现有深度学习联合信源信道编码在无线图像传输中简化信道动态的问题，通过Swin Transformer骨干网络实现对信道特性的自适应。


<details>
  <summary>Details</summary>
Motivation: 现有研究将通信系统简化为带噪声的管道，忽视了无线信道的复杂动态和物理层传输过程，导致性能受限。

Method: 基于Swin Transformer骨干网络，设计了一种动态信道自适应传输方案（DCAT），利用物理层传输特性适应信道变化。

Result: 实验证实DCAT在所有条件下均优于基线方法，具有高可扩展性和实际部署潜力。

Conclusion: DCAT方案通过自适应信道动态提升了无线图像传输性能，为实际应用提供了高效解决方案。

Abstract: Wireless image transmission underpins diverse networked intelligent services
and becomes an increasingly critical issue. Existing works have shown that deep
learning-based joint source-channel coding (JSCC) is an effective framework to
balance image transmission fidelity and data overhead. However, these studies
oversimplify the communication system as a mere pipeline with noise, failing to
account for the complex dynamics of wireless channels and concrete
physical-layer transmission process. To address these limitations, we propose a
Synesthesia of Machines (SoM)-empowered Dynamic Channel Adaptive Transmission
(DCAT) scheme, designed for practical implementation in real communication
scenarios. Building upon the Swin Transformer backbone, our DCAT scheme
demonstrates robust adaptability to time-selective fading and channel aging
effects by effectively utilizing the physical-layer transmission
characteristics of wireless channels. Comprehensive experimental results
confirm that DCAT consistently achieves superior performance compared with JSCC
baseline approaches across all conditions. Furthermore, our neural network
architecture demonstrates high scalability due to its interpretable design,
offering substantial potential for cost-efficient deployment in practical
applications.

</details>


### [17] [Resistor Hopping KLJN Noise Communication Using Small Bias Voltages Supported by ML and Optimum Threshold-Based Detectors](https://arxiv.org/abs/2509.11373)
*Hadi Zayyani,Felipe A. P. de Figueiredo,Mohammad Salman,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 提出了一种带有偏置的电阻跳跃（RH）方案，用于安全的基尔霍夫定律约翰逊噪声（KLJN）通信，提高了比特率并保持了无条件安全性。


<details>
  <summary>Details</summary>
Motivation: 为了提高KLJN通信的比特率，同时确保其固有的无条件安全性。

Method: 采用电阻跳跃（RH）方案并加入偏置，通过均值区分高斯分布噪声，最小化偏置以提高功率效率，并使用最大似然（ML）检测器进行信号检测。

Result: 仿真结果表明，与经典KLJN方案相比，提出的方案具有更高的数据率和更低的误码率，但复杂度有所增加。

Conclusion: 提出的RH-KLJN方案在保持安全性的同时提升了通信性能，尽管复杂度增加，但其高数据率和低误码率使其具有应用潜力。

Abstract: In this paper, a Resistor Hopping (RH) scheme with the addition of biases is
proposed for secure Kirchhoff Law Johnson-Noise (KLJN) communication. The RH
approach enables us to increase the bit rate of secure communication between
Alice and Bob, while also ensuring that the inherent unconditional security of
KLJN is satisfied. The biases are added to the proposed scheme to better
distinguish between Gaussian distributed noises in terms of their means, rather
than just using variances. Throughout the paper, we strive to minimize biases
to achieve a power-efficient scheme. For the detection part of the proposed
algorithm, a Maximum-Likelihood (ML) detector is derived. The separability
condition of Gaussian distributions is investigated, along with the provision
of a threshold-based detector that offers both simple and optimal thresholds in
terms of minimizing the error probability. Some analysis of the proposed
RH-KLJN communication scheme is provided, including Physical Layer Security
(PLS) equations. Simulation results demonstrate the advantages of the proposed
scheme over the classical KLJN scheme, offering a higher data rate and lower
bit error probability at the expense of increased complexity.

</details>


### [18] [A Generalized Framework for Quadratic Noise Modulation Using Non-Gaussian Distributions](https://arxiv.org/abs/2509.11378)
*Hadi Zayyani,Mohammad Salman,Felipe A. P. de Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 该论文提出了一种广义噪声调制方法（GQNM），通过引入两种电压偏差和非高斯噪声分布，如混合高斯（MoG）和拉普拉斯分布，实现数据速率翻倍。


<details>
  <summary>Details</summary>
Motivation: 传统的高斯噪声调制在低功耗和安全通信系统中的性能有限，因此需要一种更通用的调制方法以适应非高斯噪声环境。

Method: 提出了广义二次噪声调制（GQNM），利用非高斯噪声分布（如MoG和拉普拉斯）和两种电压偏差，支持对噪声符号的均值和方差进行区分。

Result: 推导了广义高斯（GG）和高斯混合双高斯（GMoTG）情况下的比特错误概率（BEP）闭式表达式，并通过仿真验证了非高斯噪声假设下其性能优势。

Conclusion: GQNM在低功耗和安全通信系统中具有潜在的性能提升，特别是在非高斯噪声环境下表现更优。

Abstract: This letter generalizes noise modulation by introducing two voltage biases
and employing non-Gaussian noise distributions, such as Mixture of Gaussian
(MoG) and Laplacian, in addition to traditional Gaussian noise. The proposed
framework doubles the data rate by enabling discrimination in both the mean and
variance of transmitted noise symbols. This novel modulation scheme is referred
to as Generalized Quadratic Noise Modulation (GQNM). Closed-form expressions
for the Bit Error Probability (BEP) are derived for the Generalized Gaussian
(GG) and Gaussian Mixture of Two Gaussians (GMoTG) cases. Simulation results
demonstrate the advantages of the generalized modulation scheme, particularly
under non-Gaussian noise assumptions, highlighting its potential for enhanced
performance in low-power and secure communication systems.

</details>


### [19] [Solving ill-conditioned polynomial equations using score-based priors with application to multi-target detection](https://arxiv.org/abs/2509.11397)
*Rafi Beinhorn,Shay Kreymer,Amnon Balanov,Michael Cohen,Alon Zabatani,Tamir Bendory*

Main category: eess.SP

TL;DR: 论文提出了一种结合基于分数的扩散先验和矩估计的新框架，用于解决非线性逆问题中的多项式方程恢复问题，特别是在多目标检测模型中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决从低阶矩恢复信号这一困难的逆问题，尤其是如何在噪声环境下稳定多项式恢复。

Method: 提出了一种将基于分数的扩散先验与矩估计相结合的新框架，用于正则化和求解非线性逆问题。

Result: 扩散先验显著改善了从三阶矩的恢复效果，并使原本不适定的超分辨率多目标检测问题变得可行。

Conclusion: 该研究为结合生成先验与非线性多项式逆问题提供了一个有前景的新方向。

Abstract: Recovering signals from low-order moments is a fundamental yet notoriously
difficult task in inverse problems. This recovery process often reduces to
solving ill-conditioned systems of polynomial equations. In this work, we
propose a new framework that integrates score-based diffusion priors with
moment-based estimators to regularize and solve these nonlinear inverse
problems. This introduces a new role for generative models: stabilizing
polynomial recovery from noisy statistical features. As a concrete application,
we study the multi-target detection (MTD) model in the high-noise regime. We
demonstrate two main results: (i) diffusion priors substantially improve
recovery from third-order moments, and (ii) they make the super-resolution MTD
problem, otherwise ill-posed, feasible. Numerical experiments on MNIST data
confirm consistent gains in reconstruction accuracy across SNR levels. Our
results suggest a promising new direction for combining generative priors with
nonlinear polynomial inverse problems.

</details>


### [20] [Knowledge Distillation for Sensing-Assisted Long-Term Beam Tracking in mmWave Communications](https://arxiv.org/abs/2509.11419)
*Mengyuan Ma,Nhan Thanh Nguyen,Nir Shlezinger,Yonina C. Eldar,A. Lee Swindlehurst,Markku Juntti*

Main category: eess.SP

TL;DR: 论文提出了一种高效的传感辅助长期波束跟踪框架，通过知识蒸馏训练轻量级学生网络，显著提升了数据效率、降低了延迟和功耗。


<details>
  <summary>Details</summary>
Motivation: 利用基础设施安装的传感器捕捉环境信息，以增强毫米波系统的通信和波束成形能力。

Method: 设计了一个大注意力增强神经网络（教师网络）进行波束跟踪，并通过知识蒸馏训练一个轻量级学生网络。学生网络在输入序列更短的情况下仍能保持长期预测能力。

Result: 教师网络在当前和未来六个时间槽的Top-5准确率超过93%，复杂度降低90%；学生网络性能接近教师网络，复杂度进一步降低90%，输入序列缩短60%。

Conclusion: 提出的框架显著提升了数据效率，降低了延迟和功耗，为毫米波系统的波束跟踪提供了高效的解决方案。

Abstract: Infrastructure-mounted sensors can capture rich environmental information to
enhance communications and facilitate beamforming in millimeter-wave systems.
This work presents an efficient sensing-assisted long-term beam tracking
framework that selects optimal beams from a codebook for current and multiple
future time slots. We first design a large attention-enhanced neural network
(NN) to fully exploit past visual observations for beam tracking. A
convolutional NN extracts compact image features, while gated recurrent units
with attention capture the temporal dependencies within sequences. The large NN
then acts as the teacher to guide the training of a lightweight student NN via
knowledge distillation. The student requires shorter input sequences yet
preserves long-term beam prediction ability. Numerical results demonstrate that
the teacher achieves Top-5 accuracies exceeding 93% for current and six future
time slots, approaching state-of-the-art performance with a 90% complexity
reduction. The student closely matches the teacher's performance while cutting
complexity by another 90%, despite operating with 60% shorter input sequences.
This improvement significantly enhances data efficiency, reduces latency, and
lowers power consumption in sensing and processing.

</details>


### [21] [Dynamic Length FSK Waveforms for Joint Communications and Radar](https://arxiv.org/abs/2509.11500)
*Tian Han,Peter J Smith,Urbashi Mitra,Jamie S Evans,Robin Evans,Rajitha Senanayake*

Main category: eess.SP

TL;DR: 提出了一种基于FSK的动态子脉冲数量联合通信与雷达波形设计方法，通过监控频谱平坦性动态形成雷达波形，确保延时估计准确性，避免了波形过长问题。


<details>
  <summary>Details</summary>
Motivation: 利用FSK波形的恒模特性和增加子脉冲数量对雷达性能的稳定性，设计动态子脉冲数量的联合通信与雷达波形。

Method: 基于传统FSK调制，动态生成雷达波形；通过监控频谱平坦性和其他约束条件，确保延时估计准确性及波形长度合理。

Result: 通过布朗运动近似子脉冲数量分布，验证了波形设计的延时和多普勒频移估计性能以及模糊函数旁瓣水平。

Conclusion: 该方法有效平衡了通信与雷达性能，同时避免了波形过长问题。

Abstract: Motivated by the constant modulus property of frequency shift keying (FSK)
based waveforms and the stabilisation of its radar performance with an increase
in the number of subpulses, in this paper an FSK-based dynamic subpulse number
joint communications and radar waveform design is proposed. From a
communications point of view, the system operates based on traditional FSK
modulation. From a sensing point of view, although the subpulses are
continuously generated and transmitted, radar waveforms are dynamically formed
by monitoring the flatness of the spectrum which in turn guarantees the
accuracy of the delay estimation. Other constraints on the waveform length are
used to ensure satisfactory values of the root mean square time duration,
ambiguity function sidelobe levels and prevent overly long waveforms. To
provide an estimation of the probability of generating extremely long
waveforms, the distribution of the number of subpulses is approximated using a
Brownian motion process and an existing result on its one-sided exit density.
Numerical examples are provided to evaluate the accuracy of the approximate
distribution, as well as the ambiguity function sidelobe levels and the delay
and Doppler shift estimation performance of the transmitted waveforms.

</details>


### [22] [Radio Frequency Amplitude-Modulation to Frequency-Modulation Signal Converter](https://arxiv.org/abs/2509.11510)
*Rishab Parthasarathy,Michael Popik,Noah Haefner*

Main category: eess.SP

TL;DR: 开发了一种拓扑结构，将AM信号转换为FM信号，保持音频高保真，并成功应用于RF频段。


<details>
  <summary>Details</summary>
Motivation: 探索一种有效的模拟拓扑结构，实现AM信号到FM信号的转换，同时确保信号在各自RF频段内。

Method: 设计并测试了一个结合AM解调电路和电压控制振荡器(VCO)的系统，以转换信号频率。

Result: 成功开发出功能系统，实现了AM到FM的转换，并保持了音频质量。

Conclusion: 该项目不仅实现了目标系统，还为未来模拟电子项目提供了宝贵的设计和分析经验。

Abstract: In this project, we wanted to discover an analog topology that could
effectively convert amplitude-modulated (AM) signals to frequency-modulated
(FM) signals, while also ensuring that both sets of signals were within their
respective radio frequency (RF) bands. To that end, an effective topology for
doing so was developed, characterized, and demonstrated, requiring the ability
to de-modulate incoming signals from the AM radio band--spanning from 530 kHz
to 1700 kHz--and re-modulate these signals into the FM radio band--spanning
from 88 MHz to 108 MHz. These bands are separated by roughly 86 MHz, presenting
the need for the topology to radically alter the incoming frequency before
re-broadcasting. At its simplest implementation, this required an AM
demodulation circuit coupled to a voltage controlled oscillator (VCO).
Together, these two circuits translated variations in the incoming envelope
signal to variations in the output frequency while still maintaining
high-fidelity audio, similar to how existing radio receiving and broadcasting
are done. Altogether, the project not only developed a working system but also
provided valuable instruction in the design, analysis, and construction of
effective RF circuits--invaluable to future endeavors within analog
electronics.

</details>


### [23] [Cooperative UAV-mounted RISs-assisted Energy-efficient Communications](https://arxiv.org/abs/2509.11533)
*Hongyang Pan,Yanheng Liu,Geng Sun,Qingqing Wu,Tierui Gong,Pengfei Wang,Dusit Niyato,Chau Yuen*

Main category: eess.SP

TL;DR: 本文研究了基于无人机载RIS的协作网络，提出了一种多目标优化框架（EEComm-MOF），以同时最大化用户可用速率并最小化系统能耗，并通过改进的遗传算法（INSGA-II-CDC）有效解决了这一NP难问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决6G网络中多用户支持的问题，提升通信性能和能量效率，通过无人机载RIS实现三维移动和灵活部署。

Method: 采用多目标优化框架（EEComm-MOF），结合改进的遗传算法（INSGA-II-CDC）联合优化基站波束成形、RIS部署和离散相移。

Result: 仿真结果表明，提出的算法在多个性能指标上优于基准方法，验证了其稳定性和改进机制的有效性。

Conclusion: 无人机载RIS协作网络和多目标优化框架能显著提升6G网络的能量效率和通信性能，INSGA-II-CDC在实际应用中具有可行性。

Abstract: Cooperative reconfigurable intelligent surfaces (RISs) are promising
technologies for 6G networks to support a great number of users. Compared with
the fixed RISs, the properly deployed RISs may improve the communication
performance with less communication energy consumption, thereby improving the
energy efficiency. In this paper, we consider a cooperative unmanned aerial
vehicle-mounted RISs (UAV-RISs)-assisted cellular network, where multiple RISs
are carried and enhanced by UAVs to serve multiple ground users (GUs)
simultaneously such that achieving the three-dimensional (3D) mobility and
opportunistic deployment. Specifically, we formulate an energy-efficient
communication problem based on multi-objective optimization framework
(EEComm-MOF) to jointly consider the beamforming vector of base station (BS),
the location deployment and the discrete phase shifts of UAV-RIS system so as
to simultaneously maximize the minimum available rate over all GUs, maximize
the total available rate of all GUs, and minimize the total energy consumption
of the system, while the transmit power constraint of BS is considered. To
comprehensively solve EEComm-MOF which is an NP-hard and non-convex problem
with constraints, a non-dominated sorting genetic algorithm-II with a
continuous solution processing mechanism, a discrete solution processing
mechanism, and a complex solution processing mechanism (INSGA-II-CDC) is
proposed. Simulations results demonstrate that the proposed INSGA-II-CDC can
solve EEComm-MOF effectively and outperforms other benchmarks under different
parameter settings. Moreover, the stability of INSGA-II-CDC and the
effectiveness of the improved mechanisms are verified. Finally, the
implementability analysis of the algorithm is given.

</details>


### [24] [Simplified Design Approach for Via Transitions up to 67 GHz](https://arxiv.org/abs/2509.11542)
*Giorgi Tsintsadze,Reza Vahdani,James L. Drewniak,Richard Zai*

Main category: eess.SP

TL;DR: 提出了一种系统化的高速过孔过渡设计方法，分析了过孔参数对带宽的影响，并提供了优化指南。


<details>
  <summary>Details</summary>
Motivation: 解决高速过孔设计中参数优化复杂的问题，降低对昂贵3D FEM工具的依赖。

Method: 通过分析过孔半径、反焊盘尺寸及相邻接地过孔距离对带宽的影响，利用3D FEM仿真与实测数据验证设计指南。

Result: 方法有效优化设计参数，支持带宽高达67 GHz的过孔设计，且简化了工程实现。

Conclusion: 该框架为工程师提供了直观的设计优化工具，显著提升了高速过孔设计的效率与可行性。

Abstract: A systematic approach for high-speed via transition design is proposed. The
effects of via barrel radius, anti-pad size, and the distance from adjacent
stitching (GND) vias on bandwidth are analyzed and characterized. Guidelines
for selecting parameter values are provided and validated by correlating 3D
full-wave FEM simulation results with actual measurements of the coupon board.
When a sufficient number of stitching vias are used, the via structure can be
approximated as a coaxial transmission line. The proposed methodology builds on
this approximation and also considers high-order modes. With this framework,
engineers can easily optimize design parameters while intuitively understanding
how geometry affects bandwidth. This approach also allows engineers with
limited access to expensive and computationally intensive 3D FEM tools to
design high bandwidth vias up to 67 GHz.

</details>


### [25] [Stacked Intelligent Metasurface for End-to-End OFDM System](https://arxiv.org/abs/2509.11551)
*Yida Zhang,Qiuyan Liu,Hongtao Luo,Yuqi Xia,Qiang Wang*

Main category: eess.SP

TL;DR: 论文提出了一种基于堆叠智能超表面（SIM/DPSIM）的端到端OFDM系统，通过电磁神经网络（EMNN）实现通信任务的全链路优化，展示其在复杂信道条件下的稳健性能。


<details>
  <summary>Details</summary>
Motivation: 现有SIM/DPSIM架构仅支持单一通信功能（如预编码或组合），研究旨在通过端到端联合优化提升系统整体性能。

Method: 利用SIM/DPSIM在执行OFDM任务（如调制、预编码、解调）的同时进行电磁前向传播，并通过抽象超表面为神经网络隐藏层设计EMNN框架，引入迁移学习优化训练。

Result: 仿真表明，SIM/DPSIM辅助的端到端OFDM系统在复杂信道下能实现稳健的比特流传输。

Conclusion: 研究展示了EMNN和SIM/DPSIM辅助OFDM系统在未来收发器设计中的应用潜力。

Abstract: Stacked intelligent metasurface (SIM) and dual-polarized SIM (DPSIM) enabled
wave-domain signal processing have emerged as promising research directions for
offloading baseband digital processing tasks and efficiently simplifying
transceiver design. However, existing architectures are limited to employing
SIM (DPSIM) for a single communication function, such as precoding or
combining. To further enhance the overall performance of SIM (DPSIM)-assisted
systems and achieve end-to-end (E2E) joint optimization from the transmitted
bitstream to the received bitstream, we propose an SIM (DPSIM)- assisted E2E
orthogonal frequency-division multiplexing (OFDM) system, where traditional
communication tasks such as modulation, precoding, combining, and demodulation
are performed simultaneously during electromagnetic (EM) forward propagation.
Furthermore, inspired by the idea of abstracting real metasurfaces as hidden
layers of a neural network, we propose the electromagnetic neural network
(EMNN) to enable the control of the E2E OFDM communication system. In addition,
transfer learning is introduced into the model training, and a training and
deployment framework for the EMNN is designed. Simulation results demonstrate
that both SIM-assisted E2E OFDM systems and DPSIM-assisted E2E OFDM systems can
achieve robust bitstream transmission under complex channel conditions. Our
study highlights the application potential of EMNN and SIM (DPSIM)-assisted E2E
OFDM systems in the design of next-generation transceivers.

</details>


### [26] [RadioLAM: A Large AI Model for Fine-Grained 3D Radio Map Estimation](https://arxiv.org/abs/2509.11571)
*Zhiyuan Liu,Qingyu Liu,Shuhang Zhang,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 该论文提出了一种名为RadioLAM的大型人工智能模型，用于解决三维无线电地图估计问题，特别是在超稀疏采样条件下的高分辨率地图生成问题。


<details>
  <summary>Details</summary>
Motivation: 随着低空经济的快速发展，无人机等设备对三维空间频谱管理需求增加，但超稀疏采样问题使得高分辨率无线电地图的估计极具挑战性。

Method: RadioLAM由三个关键模块组成：1）增强模块，利用无线电传播模型将不同高度采集的样本投影到目标高度的二维区域；2）生成模块，基于混合专家架构（MoE）的大型AI模型生成候选无线电地图；3）选举模块，通过无线电传播模型选出最佳地图。

Result: 实验表明，RadioLAM能在采样率低至0.1%的情况下高效解决问题，并显著优于现有技术。

Conclusion: RadioLAM为解决超稀疏采样条件下的三维无线电地图估计问题提供了一种创新且高效的方法。

Abstract: A radio map captures the spatial distribution of wireless channel parameters,
such as the strength of the signal received, across a geographic area. The
problem of fine-grained three-dimensional (3D) radio map estimation involves
inferring a high-resolution radio map for the two-dimensional (2D) area at an
arbitrary target height within a 3D region of interest, using radio samples
collected by sensors sparsely distributed in that 3D region. Solutions to the
problem are crucial for efficient spectrum management in 3D spaces,
particularly for drones in the rapidly developing low-altitude economy.
However, this problem is challenging due to ultra-sparse sampling, where the
number of collected radio samples is far fewer than the desired resolution of
the radio map to be estimated. In this paper, we design a Large Artificial
Intelligence Model (LAM) called RadioLAM for the problem. RadioLAM employs the
creative power and the strong generalization capability of LAM to address the
ultra-sparse sampling challenge. It consists of three key blocks: 1) an
augmentation block, using the radio propagation model to project the radio
samples collected at different heights to the 2D area at the target height; 2)
a generation block, leveraging an LAM under an Mixture of Experts (MoE)
architecture to generate a candidate set of fine-grained radio maps for the
target 2D area; and 3) an election block, utilizing the radio propagation model
as a guide to find the best map from the candidate set. Extensive simulations
show that RadioLAM is able to solve the fine-grained 3D radio map estimation
problem efficiently from an ultra-low sampling rate of 0.1%, and significantly
outperforms the state-of-the-art.

</details>


### [27] [Low-Altitude Wireless Networks: A Survey](https://arxiv.org/abs/2509.11607)
*Jun Wu,Yaoqi Yang,Weijie Yuan,Wenchao Liu,Jiacheng Wang,Tianqi Mao,Lin Zhou,Yuanhao Cui,Fan Liu,Geng Sun,Nan Wu,Dezhi Zheng,Jindan Xu,Nan Ma,Zhiyong Feng,Wei Xu,Dusit Niyato,Chau Yuen,Xiaojun Jing,Zhiguo Shi,Yingchang Liang,Shi Jin,Dong In Kim,Jiangzhou Wang,Ping Zhang,Hao Yin,Jun Zhang*

Main category: eess.SP

TL;DR: 本文介绍了低空无线网络（LAWN）的综合框架，旨在解决当前低空经济需求与传统空中系统局限性之间的矛盾，强调了其在通信、感知、计算、控制和空中交通管理中的一体化设计。


<details>
  <summary>Details</summary>
Motivation: 低空经济的快速发展对无线基础设施提出了前所未有的需求，但目前传统空中系统未能整合多功能服务，且缺乏系统性的低空空域规划，导致性能与可扩展性问题。

Method: 提出低空无线网络（LAWN）框架，将通信、感知、计算、控制和空中交通管理统一整合，并对其性能评估、隐私安全及实际部署进行了探讨。

Result: LAWN框架为动态空域环境中的无人机大规模部署和智能服务提供了系统性解决方案，并推动了低空空域结构化与空中交通管理的前沿发展。

Conclusion: LAWN框架通过一体化设计解决了低空经济的多维度需求，具有广阔的应用前景，但隐私与安全问题仍需进一步研究。

Abstract: The rapid development of the low-altitude economy has imposed unprecedented
demands on wireless infrastructure to accommodate large-scale drone deployments
and facilitate intelligent services in dynamic airspace environments. However,
unlocking its full potential in practical applications presents significant
challenges. Traditional aerial systems predominantly focus on air-ground
communication services, often neglecting the integration of sensing,
computation, control, and energy-delivering functions, which hinders the
ability to meet diverse mission-critical demands. Besides, the absence of
systematic low-altitude airspace planning and management exacerbates issues
regarding dynamic interference in three-dimensional space, coverage
instability, and scalability. To overcome these challenges, a comprehensive
framework, termed low-altitude wireless network (LAWN), has emerged to
seamlessly integrate communication, sensing, computation, control, and air
traffic management into a unified design. This article provides a comprehensive
overview of LAWN systems, introducing LAWN system fundamentals and the
evolution of functional designs. Subsequently, we delve into performance
evaluation metrics and review critical concerns surrounding privacy and
security in the open-air network environment. Finally, we present the
cutting-edge developments in airspace structuring and air traffic management,
providing insights to facilitate the practical deployment of LAWNs.

</details>


### [28] [Attention-Enhanced Learning for Sensing-Assisted Long-Term Beam Tracking in mmWave Communications](https://arxiv.org/abs/2509.11725)
*Mengyuan Ma,Nhan Thanh Nguyen,Nir Shlezinger,Yonina C. Eldar,Markku Juntti*

Main category: eess.SP

TL;DR: 该论文提出了一种基于注意力增强的机器学习模型，用于毫米波通信中的波束追踪，通过结合CNN和GRU以及时间注意力机制，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信中波束训练和预测因快速变化的信道和对阻塞及移动的敏感性而极具挑战性。利用基础设施摄像头捕获的环境信息可辅助波束跟踪设计。

Method: 开发了基于卷积神经网络（CNN）和门控循环单元（GRU）的注意力增强模型，用于从过去的观测图像中预测当前和未来的波束。

Result: 提出的设计在Top-5波束预测准确率上超过90%，显著减少了波束训练的感知和处理开销，且仅用3%的计算复杂度达到97%的SOTA性能。

Conclusion: 该模型高效且性能优越，为毫米波通信中的波束追踪提供了一种实用解决方案。

Abstract: Beam training and prediction in millimeter-wave communications are highly
challenging due to fast time-varying channels and sensitivity to blockages and
mobility. In this context, infrastructure-mounted cameras can capture rich
environmental information that can facilitate beam tracking design. In this
work, we develop an efficient attention-enhanced machine learning model for
long-term beam tracking built upon convolutional neural networks and gated
recurrent units to predict both current and future beams from past observed
images. The integrated temporal attention mechanism substantially improves its
predictive performance. Numerical results demonstrate that the proposed design
achieves Top-5 beam prediction accuracies exceeding 90% across both current and
six future time slots, significantly reducing overhead arising from sensing and
processing for beam training. It further attains 97% of state-of-the-art
performance with only 3% of the computational complexity.

</details>


### [29] [Multi-Stage Location Optimization Through Power Delay Profile Alignment Using Site-Specific Wireless Ray Tracing](https://arxiv.org/abs/2509.11923)
*Mingjun Ying,Peijie Ma,Dipankar Shakya,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: 本文提出了一种多阶段TX/RX位置校准框架，用于纠正GPS定位误差，提高射线追踪仿真与实测数据的对齐度，优化无线传播行为分析。


<details>
  <summary>Details</summary>
Motivation: GPS定位误差导致射线追踪仿真与实测数据不一致，影响无线信道预测的准确性，亟需校准方法。

Method: 采用多阶段网格搜索和Powell方法优化TX/RX位置，校准实测与仿真全向功率延迟剖面。

Result: 在校正位置误差后，LOS和NLOS场景的复合损失函数分别减少42.3%和13.5%，峰值功率预测精度平均提高1 dB。

Conclusion: 该框架显著提升了信道预测的准确性，对下一代无线网络的波束管理和基础设施部署至关重要。

Abstract: Ray tracing (RT) simulations require accurate transmitter (TX) and receiver
(RX) location information from real-world measurements to accurately
characterize wireless propagation behavior in an environment. Such wireless
propagation measurements typically employ GPS-based logging for TX/RX
locations, which can produce meter-level errors that lead to unreliable RT
calibration and validation. These location misalignments cause inaccurate
interactions between RT-generated multipath components (MPCs) and the modeled
3D environment, which lead to erroneous channel predictions, and severe
discrepancies between simulated and measured power delay profiles (PDPs) and
channel characteristics. Moreover, the same RT-generated PDPs using inaccurate
locations result in calibration errors when adjusting material properties such
as conductivity and permittivity.
  This paper presents a systematic multi-stage TX/RX location calibration
framework to correct location errors and consequently align measured and
simulated omnidirectional PDPs.
  Optimization is performed using a computationally efficient multi-stage grid
search and the Powell method. Applying the location calibration framework to
NYU WIRELESS urban-microcell (UMi) measurements at 6.75 GHz and 16.95 GHz
corrected TX/RX location errors of up to 7 m. The framework reduced the
composite loss function by 42.3\% for line-of-sight (LOS) and 13.5\% for
non-line-of-sight (NLOS) scenarios. Furthermore, peak power prediction accuracy
improved by approximately 1 dB on average. Such improved geometric alignment
enables accurate channel prediction, vital for beam management and
infrastructure deployment for next-generation wireless networks.

</details>


### [30] [Optimized Sparse Network Coverage via L1-norm Minimization](https://arxiv.org/abs/2509.11994)
*Souvik Paul,Iván Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 提出了一种基于凸松弛优化的新型框架，用于在分布式网络中高效选择关键节点以实现全覆盖并最小化成本。


<details>
  <summary>Details</summary>
Motivation: 解决分布式传感器和通信网络中关键节点选择的复杂性和成本问题。

Method: 将问题建模为NP难集合覆盖问题的凸松弛，结合节点度和介数中心性，通过L1范数最小化优化。

Result: 在各种图和动态条件下，该方法比贪心和遗传算法更快、更稀疏且成本更低。

Conclusion: 该方法提供了分布式、高效且低成本的节点选择解决方案。

Abstract: The selection of nodes that can serve as cluster heads, local sinks and
gateways is a critical challenge in distributed sensor and communication
networks. This paper presents a novel framework for identifying a minimal set
of nexus nodes to ensure full network coverage while minimizing cost. By
formulating the problem as a convex relaxation of the NP-hard set cover
problem, we integrate the graph theoretic centrality measures of node degree
and betweenness centrality into a cost function optimized via a relaxed L1-norm
minimization. The proposed approach is applicable to static and dynamic network
scenarios and does not require location or distance estimation. Through
simulations across various graph models and dynamic conditions, it is shown
that the method achieves faster execution times (lower complexity) and
competitive sparsity compared to classical greedy and genetic algorithms (GA),
offering a robust, distributed, and cost-efficient node selection solution.

</details>


### [31] [Meta Fluid Antenna: Architecture Design, Performance Analysis, Experimental Examination](https://arxiv.org/abs/2509.12032)
*Baiyang Liu,Jiewei Huang,Tuo Wu,Huan Meng,Fengcheng Mei,Lei Ning,Kai-Kit Wong,Hang Wong,Kin-Fai Tong,Kwai-Man Luk*

Main category: eess.SP

TL;DR: 多激活流体天线多址（FAMA）利用单射频链结构实现多用户复用，显著提升信号干扰比（SIR），适用于快速变化的无线环境。


<details>
  <summary>Details</summary>
Motivation: 传统6G超密集连接需要解决干扰和频谱效率问题，而无需依赖信道状态信息（CSI）。

Method: 通过单射频链结构实现多激活，扩展独立辐射状态集，无需额外信号处理。

Result: 仿真显示，多激活FAMA在多用户Rayleigh衰落环境下显著提升SIR，并在15μs内优化性能。

Conclusion: 多激活FAMA为高容量无线网络提供了可扩展的CSI免多用户通信方案。

Abstract: Fluid antenna systems (FAS) have recently emerged as a promising solution for
sixth-generation (6G) ultra-dense connectivity. These systems utilize dynamic
radiating and/or shaping techniques to mitigate interference and improve
spectral efficiency without relying on channel state information (CSI). The
reported improvements achieved by employing a single dynamically activated
radiating position in fluid antenna multiple access (FAMA) are significant. To
fully realize the potential of FAMA in multi-user multiplexing, we propose
leveraging the unique fast-switching capabilities of a single radio-frequency
(RF)-chain meta-fluid antenna structure to achieve multi-activation. This
allows for a significantly larger set of independent radiating states without
requiring additional signal processing. Simulations demonstrate that
multi-activation FAMA enables robust multi-user multiplexing with a higher
signal-to-interference ratio (SIR) under various Rayleigh-fading environments
compared to other single RF-chain technologies. We further show that the SIR
can be optimized within a 15~$\mu s$ timeframe under a multi-user
Rayleigh-fading channel, making the proposed scheme highly suitable for
fast-changing wireless environments. Verified through the theoretical Jakes'
model, full three-dimensional (3D) electromagnetic (EM) simulations and
experimental validation, multi-activation FAMA enables effective CSI-free,
multi-user communication, offering a scalable solution for high-capacity
wireless networks.

</details>


### [32] [RadarLLM: Adapting Pretrained Large Language Models for Marine Radar Target Detection with Preference-aware Loss](https://arxiv.org/abs/2509.12089)
*Qiying Hu*

Main category: eess.SP

TL;DR: 该论文提出了一种名为RadarLLM的新框架，用于优化预训练大语言模型（LLM）在海洋目标检测任务中对雷达信号特征的分析能力，通过选择性损失函数有效解决了过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型（LLM）在捕获通用知识方面表现出色，但其直接应用于海洋目标检测任务时容易过拟合，尤其是在低信噪比（SCR）场景中。论文旨在解决这一问题。

Method: 提出RadarLLM框架，采用偏好感知损失函数，选择性优化不同特征块（feature patches）的学习值，引导模型专注于最具泛化性的模式。

Result: 实验表明，RadarLLM在低SCR场景下表现显著优于原始方法，且在训练数据有限的情况下也能持续超越现有基线方法。

Conclusion: RadarLLM通过选择性优化策略有效提升了预训练LLM在海洋目标检测中的性能，尤其在低SCR和有限数据条件下表现突出。

Abstract: Recent advances in pre-trained large language models (LLMs) have demonstrated
their capacities to capture universal knowledge, making them promising
general-purpose optimization solvers for wireless signal processing. Motivated
by these findings, we take the first step towards fine-tuning pre-trained LLMs
for the effective analysis of radar signal features in marine target detection
tasks. Nevertheless, directly fine-tuning pre-trained LLMs on marine target
detection tasks tends to suffer from pronounced overfitting, particularly in
challenging low signal-to-clutter ratio (SCR) scenarios. This overfitting
primarily stems from the model's tendency to memorize spurious or noisy feature
patterns rather than learning discriminative structures that generalize well to
unseen data. To address this challenge, we introduce RadarLLM, a novel
fine-tuning framework that utilizes an effective preference-aware loss. Unlike
conventional training strategies that uniformly optimize all feature tokens,
this loss function selectively optimizes different feature patches based on
their online evaluated learning values, thus guiding the model to focus on the
most generalizable patterns during optimization. We theoretically demonstrate
the effectiveness of the evaluated learning values by transforming the problem
as selecting useful feature tokens. Extensive experiments on real-world marine
radar datasets show that 1) the proposed loss function is much better than the
original one, with particularly significant gains in challenging low SCR
scenarios and 2) RadarLLM consistently outperforms state-of-the-art baselines
across diverse detection scenarios, with particularly notable gains under
limited training data conditions.

</details>


### [33] [When marine radar target detection meets pretrained large language models](https://arxiv.org/abs/2509.12110)
*Qiying Hu,Linping Zhang,Xueqian Wang,Gang Li,Yu Liu,Xiao-Ping Zhang*

Main category: eess.SP

TL;DR: 该论文提出了一种结合特征预处理与大语言模型（LLM）的框架，用于改进雷达回波信号的高维模式提取。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法在特征冗余和模型大小限制方面的挑战。

Method: 通过预处理模块对雷达序列特征进行标记化，并应用补丁选择算法过滤无信息段，随后将所选补丁投影到预训练LLM的特征空间嵌入中，仅微调归一化层以减轻训练负担。

Result: 在实测数据集上的实验表明，该方法在监督学习测试中显著优于现有基线。

Conclusion: 结合预训练LLM的特征预处理框架能有效提升雷达信号分析的性能。

Abstract: Deep learning (DL) methods are widely used to extract high-dimensional
patterns from the sequence features of radar echo signals. However,
conventional DL algorithms face challenges such as redundant feature segments,
and constraints from restricted model sizes. To address these issues, we
propose a framework that integrates feature preprocessing with large language
models (LLMs). Our preprocessing module tokenizes radar sequence features,
applies a patch selection algorithm to filter out uninformative segments, and
projects the selected patches into embeddings compatible with the feature space
of pre-trained LLMs. Leveraging these refined embeddings, we incorporate a
pre-trained LLM, fine-tuning only the normalization layers to reduce training
burdens while enhancing performance. Experiments on measured datasets
demonstrate that the proposed method significantly outperforms the
state-of-the-art baselines on supervised learning tests.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [34] [Large Foundation Models for Trajectory Prediction in Autonomous Driving: A Comprehensive Survey](https://arxiv.org/abs/2509.10570)
*Wei Dai,Shengen Wu,Wei Wu,Zhenhao Wang,Sisuo Lyu,Haicheng Liao,Limin Yu,Weiping Ding,Runwei Guan,Yutao Yue*

Main category: cs.RO

TL;DR: 该论文综述了轨迹预测领域的最新进展，特别是大型基础模型（LFMs）的应用，包括大语言模型（LLMs）和多模态大语言模型（MLLMs），并探讨了核心方法、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在轨迹预测中因缺乏可解释性、依赖大量标注数据和长尾场景泛化能力不足而受限，LFMs的兴起为解决这些问题提供了新思路。

Method: 论文提出了三种核心方法：轨迹-语言映射、多模态融合和基于约束的推理，结合语言和场景语义提升预测安全性和泛化能力。

Result: LFMs通过整合上下文推理，显著提高了复杂环境中的轨迹预测性能。

Conclusion: 论文总结了当前挑战（如计算延迟、数据稀缺和鲁棒性），并展望了未来研究方向（如低延迟推理、因果感知建模和运动基础模型）。

Abstract: Trajectory prediction serves as a critical functionality in autonomous
driving, enabling the anticipation of future motion paths for traffic
participants such as vehicles and pedestrians, which is essential for driving
safety. Although conventional deep learning methods have improved accuracy,
they remain hindered by inherent limitations, including lack of
interpretability, heavy reliance on large-scale annotated data, and weak
generalization in long-tail scenarios. The rise of Large Foundation Models
(LFMs) is transforming the research paradigm of trajectory prediction. This
survey offers a systematic review of recent advances in LFMs, particularly
Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) for
trajectory prediction. By integrating linguistic and scene semantics, LFMs
facilitate interpretable contextual reasoning, significantly enhancing
prediction safety and generalization in complex environments. The article
highlights three core methodologies: trajectory-language mapping, multimodal
fusion, and constraint-based reasoning. It covers prediction tasks for both
vehicles and pedestrians, evaluation metrics, and dataset analyses. Key
challenges such as computational latency, data scarcity, and real-world
robustness are discussed, along with future research directions including
low-latency inference, causality-aware modeling, and motion foundation models.

</details>


### [35] [STL-Based Motion Planning and Uncertainty-Aware Risk Analysis for Human-Robot Collaboration with a Multi-Rotor Aerial Vehicle](https://arxiv.org/abs/2509.10692)
*Giuseppe Silano,Amr Afifi,Martin Saska,Antonio Franchi*

Main category: cs.RO

TL;DR: 提出了一种基于信号时序逻辑（STL）的无人机运动规划与风险分析方法，用于增强人机协作。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在人机协作任务中的安全性、时效性和符合人机工程学需求的问题。

Method: 使用STL编码任务目标，通过优化框架生成可行轨迹，并利用平滑近似和梯度技术处理非线性问题，同时引入不确定性风险分析和事件触发重规划。

Result: 在模拟实验中验证了该方法的安全性和效率。

Conclusion: 该方法能有效提升人机协作的安全性和适应性。

Abstract: This paper presents a novel approach to motion planning and risk analysis for
enhancing human-robot collaboration using a Multi-Rotor Aerial Vehicle (MRAV).
The proposed method uses Signal Temporal Logic (STL) to encode key mission
objectives, such as safety, timing, and human preferences, with a strong focus
on ergonomics and comfort. An optimization framework generates dynamically
feasible trajectories while considering the MRAV's physical constraints. Given
the nonlinear and non-convex nature of the problem, smooth approximations and
gradient-based techniques assist in handling the problem's computational
complexity. Additionally, an uncertainty-aware risk analysis is incorporated to
assess potential deviations from the mission specifications, providing insights
into the likelihood of mission success under uncertain conditions. Further, an
event-triggered replanning strategy is implemented to respond to unforeseen
events and external disturbances. The approach is validated through MATLAB and
Gazebo simulations, using an object handover task in a mock-up environment
inspired by power line maintenance scenarios. The results highlight the
method's effectiveness in achieving safe, efficient, and resilient human-robot
collaboration.

</details>


### [36] [A Survey on LiDAR-based Autonomous Aerial Vehicles](https://arxiv.org/abs/2509.10730)
*Yunfan Ren,Yixi Cai,Haotian Li,Nan Chen,Fangcheng Zhu,Longji Yin,Fanze Kong,Rundong Li,Fu Zhang*

Main category: cs.RO

TL;DR: 该综述全面回顾了基于LiDAR的自主无人机（UAV）的最新进展，涵盖设计、感知、规划和控制策略。LiDAR技术的发展显著提升了无人机在无GPS环境中的导航能力，推动了其在高难度任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索LiDAR技术如何提升无人机的自主性和适应性，尤其是在复杂和挑战性环境中。

Method: 通过分析LiDAR传感器的进化及其优势，结合感知、规划和控制技术的软件组件，讨论其在无人机中的应用。

Result: LiDAR与无人机的结合增强了其在多样化任务中的性能，如工业操作和无人机集群部署。

Conclusion: 尽管存在挑战，未来研究方向包括多无人机协作和技术的进一步发展，以扩展LiDAR无人机的应用潜力。

Abstract: This survey offers a comprehensive overview of recent advancements in
LiDAR-based autonomous Unmanned Aerial Vehicles (UAVs), covering their design,
perception, planning, and control strategies. Over the past decade, LiDAR
technology has become a crucial enabler for high-speed, agile, and reliable UAV
navigation, especially in GPS-denied environments. The paper begins by
examining the evolution of LiDAR sensors, emphasizing their unique advantages
such as high accuracy, long-range depth measurements, and robust performance
under various lighting conditions, making them particularly well-suited for UAV
applications. The integration of LiDAR with UAVs has significantly enhanced
their autonomy, enabling complex missions in diverse and challenging
environments. Subsequently, we explore essential software components, including
perception technologies for state estimation and mapping, as well as trajectory
planning and control methodologies, and discuss their adoption in LiDAR-based
UAVs. Additionally, we analyze various practical applications of the
LiDAR-based UAVs, ranging from industrial operations to supporting different
aerial platforms and UAV swarm deployments. The survey concludes by discussing
existing challenges and proposing future research directions to advance
LiDAR-based UAVs and enhance multi-UAV collaboration. By synthesizing recent
developments, this paper aims to provide a valuable resource for researchers
and practitioners working to push the boundaries of LiDAR-based UAV systems.

</details>


### [37] [Analytical Design and Development of a Modular and Intuitive Framework for Robotizing and Enhancing the Existing Endoscopic Procedures](https://arxiv.org/abs/2509.10735)
*Mohammad Rafiee Javazm,Yash Kulkarni,Jiaqi Xue,Naruhiko Ikoma,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 论文提出了一种模块化、易安装的机电框架，用于解决内窥镜手动操作的挑战，包括新型夹持机制、进给机制和直观用户界面，并通过数学建模和实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 由于手动控制内窥镜设备存在操作困难、工作量大和疲劳等问题，研究旨在通过机电框架优化操作流程。

Method: 设计了嵌套夹持机制和进给机制，结合直观用户界面，并通过数学建模优化参数选择。

Result: 仿真和实验验证了数学模型和机器人框架的有效性。

Conclusion: 提出的框架显著提升了内窥镜操作的便捷性和效率，为临床实践提供了实用解决方案。

Abstract: Despite the widespread adoption of endoscopic devices for several cancer
screening procedures, manual control of these devices still remains challenging
for clinicians, leading to several critical issues such as increased workload,
fatigue, and distractions. To address these issues, in this paper, we introduce
the design and development of an intuitive, modular, and easily installable
mechatronic framework. This framework includes (i) a novel nested collet-chuck
gripping mechanism that can readily be integrated and assembled with the
existing endoscopic devices and control their bending degrees-of-freedom
(DoFs); (ii) a feeder mechanism that can control the insertion/retraction DoF
of a colonoscope, and (iii) a complementary and intuitive user interface that
enables simultaneous control of all DoFs during the procedure. To analyze the
design of the proposed mechanisms, we also introduce a mathematical modeling
approach and a design space for optimal selection of the parameters involved in
the design of gripping and feeder mechanisms. Our simulation and experimental
studies thoroughly demonstrate the performance of the proposed mathematical
modeling and robotic framework.

</details>


### [38] [FastTrack: GPU-Accelerated Tracking for Visual SLAM](https://arxiv.org/abs/2509.10757)
*Kimia Khabiri,Parsa Hosseininejad,Shishir Gopinath,Karthik Dantu,Steven Y. Ko*

Main category: cs.RO

TL;DR: 利用GPU加速视觉-惯性SLAM系统的跟踪模块，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 为避免定位不准或跟踪丢失，需要及时完成每帧跟踪。

Method: 利用GPU加速跟踪中耗时的组件（如立体特征匹配和局部地图跟踪），并在ORB-SLAM3中用CUDA实现。

Result: 在桌面和Jetson Xavier NX板上，立体惯性模式下跟踪性能提升高达2.8倍。

Conclusion: GPU加速有效提升了SLAM系统的跟踪性能。

Abstract: The tracking module of a visual-inertial SLAM system processes incoming image
frames and IMU data to estimate the position of the frame in relation to the
map. It is important for the tracking to complete in a timely manner for each
frame to avoid poor localization or tracking loss. We therefore present a new
approach which leverages GPU computing power to accelerate time-consuming
components of tracking in order to improve its performance. These components
include stereo feature matching and local map tracking. We implement our design
inside the ORB-SLAM3 tracking process using CUDA. Our evaluation demonstrates
an overall improvement in tracking performance of up to 2.8x on a desktop and
Jetson Xavier NX board in stereo-inertial mode, using the well-known SLAM
datasets EuRoC and TUM-VI.

</details>


### [39] [RSL-RL: A Learning Library for Robotics Research](https://arxiv.org/abs/2509.10771)
*Clemens Schwarke,Mayank Mittal,Nikita Rudin,David Hoeller,Marco Hutter*

Main category: cs.RO

TL;DR: RSL-RL是一个专为机器人社区设计的开源强化学习库，强调紧凑性和易修改性，支持GPU高效训练，适用于大规模仿真和实际机器人实验。



<details>
  <summary>Details</summary>
Motivation: 机器人领域需要一种轻量级、可扩展的强化学习框架，能够快速适应和扩展算法，满足机器人特定的挑战需求。


Method: 设计了紧凑且易修改的代码库，专注于机器人领域广泛采用的算法及辅助技术，并优化了GPU训练性能。


Result: 在仿真基准测试和实际机器人实验中验证了其高效性，展示了其作为轻量级实用框架的潜力。


Conclusion: RSL-RL是一个适用于机器人研究的轻量级、可扩展且高效的强化学习库。


Abstract: RSL-RL is an open-source Reinforcement Learning library tailored to the
specific needs of the robotics community. Unlike broad general-purpose
frameworks, its design philosophy prioritizes a compact and easily modifiable
codebase, allowing researchers to adapt and extend algorithms with minimal
overhead. The library focuses on algorithms most widely adopted in robotics,
together with auxiliary techniques that address robotics-specific challenges.
Optimized for GPU-only training, RSL-RL achieves high-throughput performance in
large-scale simulation environments. Its effectiveness has been validated in
both simulation benchmarks and in real-world robotic experiments, demonstrating
its utility as a lightweight, extensible, and practical framework to develop
learning-based robotic controllers. The library is open-sourced at:
https://github.com/leggedrobotics/rsl_rl.

</details>


### [40] [Follow-Bench: A Unified Motion Planning Benchmark for Socially-Aware Robot Person Following](https://arxiv.org/abs/2509.10796)
*Hanjing Ye,Weixi Situ,Jianwei Peng,Yu Zhan,Bingyi Xia,Kuanqi Cai,Hong Zhang*

Main category: cs.RO

TL;DR: 该论文首次提出了机器人跟随（RPF）的端到端研究，包括场景调查、基准测试和实验评估，重点关注安全性和舒适性。


<details>
  <summary>Details</summary>
Motivation: RPF在个人助理、安防巡逻、老年护理和物流等领域有潜在应用，但需兼顾目标跟随的安全性和舒适性。

Method: 论文提出Follow-Bench基准测试，涵盖多样化场景，并重新实现了六种流行RPF规划器。

Result: 实验揭示了现有规划器在安全性与舒适性间的权衡，并为实际部署提供了见解。

Conclusion: 研究指出了RPF领域的开放挑战和未来方向。

Abstract: Robot person following (RPF) -- mobile robots that follow and assist a
specific person -- has emerging applications in personal assistance, security
patrols, eldercare, and logistics. To be effective, such robots must follow the
target while ensuring safety and comfort for both the target and surrounding
people. In this work, we present the first end-to-end study of RPF, which (i)
surveys representative scenarios, motion-planning methods, and evaluation
metrics with a focus on safety and comfort; (ii) introduces Follow-Bench, a
unified benchmark simulating diverse scenarios, including various target
trajectory patterns, dynamic-crowd flows, and environmental layouts; and (iii)
re-implements six popular RPF planners, ensuring that both safety and comfort
are systematically considered. Moreover, we evaluate the two highest-performing
planners from our benchmark on a differential-drive robot to provide insights
into real-world deployment. Extensive simulation and real-world experiments
provide quantitative insights into the safety-comfort trade-offs of existing
planners, while revealing open challenges and future research directions.

</details>


### [41] [A Universal Wire Testing Machine for Enhancing the Performance of Wire-Driven Robots](https://arxiv.org/abs/2509.10862)
*Temma Suzuki,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 该研究开发了一种通用线缆测试机，用于测量和调整线缆特性，以提高线缆驱动机构的性能，并成功应用于实际机器人的力控制。


<details>
  <summary>Details</summary>
Motivation: 尽管线缆是一种轻量、低摩擦的传动机制，但其柔性特性导致建模误差较大，限制了其在工业和科研机器人中的应用。

Method: 研究者构建了一台通用线缆测试机，用于去除初始线缆拉伸、测量不同直径被动滑轮的张紧传输效率以及测量可变长度线缆的动态行为。

Result: 测试机获得的数据成功应用于实际线缆驱动机器人的力控制，有效减少了末端执行器的力误差。

Conclusion: 该研究表明，通过精确测量和调整线缆特性，可以提升线缆驱动机构的性能，为其在机器人领域的应用提供了可行方案。

Abstract: Compared with gears and linkages, wires constitute a lightweight,
low-friction transmission mechanism. However, because wires are flexible
materials, they tend to introduce large modeling errors, and their adoption in
industrial and research robots remains limited.In this study, we built a
Universal Wire Testing Machine that enables measurement and adjustment of wire
characteristics to improve the performance of wire-driven mechanisms. Using
this testing machine, we carried out removal of initial wire stretch,
measurement of tension transmission efficiency for eight different diameters of
passive pulleys, and measurement of the dynamic behavior of variable-length
wires. Finally, we applied the data obtained from this testing machine to the
force control of an actual wire-driven robot, reducing the end-effector force
error.

</details>


### [42] [Nav-R1: Reasoning and Navigation in Embodied Scenes](https://arxiv.org/abs/2509.10884)
*Qingxiang Liu,Ting Huang,Zeyu Zhang,Hao Tang*

Main category: cs.RO

TL;DR: Nav-R1是一种统一推理的嵌入式基础模型，通过Nav-CoT-110K数据集和GRPO强化学习框架，提升了导航任务的推理和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂3D环境中推理不一致和实时导航困难的问题。

Method: 构建大规模Nav-CoT-110K数据集，设计GRPO强化学习框架，并采用Fast-in-Slow推理范式。

Result: 在嵌入式AI基准测试中平均提升8%，并在实际机器人部署中验证了鲁棒性。

Conclusion: Nav-R1在推理和导航性能上表现优越，适用于资源受限的实时应用。

Abstract: Embodied navigation requires agents to integrate perception, reasoning, and
action for robust interaction in complex 3D environments. Existing approaches
often suffer from incoherent and unstable reasoning traces that hinder
generalization across diverse environments, and difficulty balancing
long-horizon semantic reasoning with low-latency control for real-time
navigation. To address these challenges, we propose Nav-R1, an embodied
foundation model that unifies reasoning in embodied environments. We first
construct Nav-CoT-110K, a large-scale dataset of step-by-step Chains-of-Thought
(CoT) for embodied tasks, which enables cold-start initialization with
structured reasoning. Building on this foundation, we design a GRPO-based
reinforcement learning framework with three complementary rewards: format,
understanding, and navigation, to improve structural adherence, semantic
grounding, and path fidelity. Furthermore, we introduce a Fast-in-Slow
reasoning paradigm, decoupling deliberate semantic reasoning from low-latency
reactive control for efficient yet coherent navigation. Extensive evaluations
on embodied AI benchmarks demonstrate that Nav-R1 consistently outperforms
strong baselines, with over 8% average improvement in reasoning and navigation
performance. Real-world deployment on a mobile robot further validates its
robustness under limited onboard resources. Code:
https://github.com/AIGeeksGroup/Nav-R1. Website:
https://aigeeksgroup.github.io/Nav-R1.

</details>


### [43] [Design of scalable orthogonal digital encoding architecture for large-area flexible tactile sensing in robotics](https://arxiv.org/abs/2509.10888)
*Weijie Liu,Ziyi Qiu,Shihang Wang,Deqing Mei,Yancheng Wang*

Main category: cs.RO

TL;DR: 提出了一种基于正交数字编码的新架构，解决柔性触觉传感器编码效率和布线复杂性瓶颈，实现高灵敏度和快速响应的大面积覆盖。


<details>
  <summary>Details</summary>
Motivation: 实现类似人类皮肤的大面积、高灵敏度、快速响应的触觉感知，但现有柔性触觉传感器因编码效率和布线复杂性问题难以实现。

Method: 采用码分多址启发的正交数字编码策略，通过分布式传感节点的能量正交基码并行叠加，显著减少布线需求并提高数据吞吐量。

Result: 在16节点传感阵列中验证，仅用单根传输线实现12.8毫秒的时间分辨率，且节点数变化时仍能保持低于20毫秒的延迟。

Conclusion: 该架构为开发具有人类感官能力的可扩展智能系统开辟了新途径。

Abstract: Human-like embodied tactile perception is crucial for the next-generation
intelligent robotics. Achieving large-area, full-body soft coverage with high
sensitivity and rapid response, akin to human skin, remains a formidable
challenge due to critical bottlenecks in encoding efficiency and wiring
complexity in existing flexible tactile sensors, thus significantly hinder the
scalability and real-time performance required for human skin-level tactile
perception. Herein, we present a new architecture employing code division
multiple access-inspired orthogonal digital encoding to overcome these
challenges. Our decentralized encoding strategy transforms conventional serial
signal transmission by enabling parallel superposition of energy-orthogonal
base codes from distributed sensing nodes, drastically reducing wiring
requirements and increasing data throughput. We implemented and validated this
strategy with off-the-shelf 16-node sensing array to reconstruct the pressure
distribution, achieving a temporal resolution of 12.8 ms using only a single
transmission wire. Crucially, the architecture can maintain sub-20ms latency
across orders-of-magnitude variations in node number (to thousands of nodes).
By fundamentally redefining signal encoding paradigms in soft electronics, this
work opens new frontiers in developing scalable embodied intelligent systems
with human-like sensory capabilities.

</details>


### [44] [ViSTR-GP: Online Cyberattack Detection via Vision-to-State Tensor Regression and Gaussian Processes in Automated Robotic Operations](https://arxiv.org/abs/2509.10948)
*Navid Aftabi,Philip Samaha,Jin Ma,Long Cheng,Ramy Harik,Dan Li*

Main category: cs.RO

TL;DR: 该论文提出了一种名为ViSTR-GP的在线检测框架，通过利用外部摄像头和编码器数据的交叉验证，检测机器人制造过程中的数据完整性攻击。


<details>
  <summary>Details</summary>
Motivation: 工业机器人系统在智能制造中至关重要，但其面临的数据完整性攻击难以通过传统入侵检测或基于模型的方法发现，因此需要新的解决方案。

Method: 开发了ViSTR-GP框架，结合SAM-Track的交互式分割、低秩张量回归和矩阵变异高斯过程，生成在线检测器。

Result: 实验表明，ViSTR-GP能更早且更频繁地检测到攻击，尤其在细微攻击中表现突出。

Conclusion: 通过添加独立物理通道，工厂无需复杂仪器即可有效检测数据完整性攻击。

Abstract: Industrial robotic systems are central to automating smart manufacturing
operations. Connected and automated factories face growing cybersecurity risks
that can potentially cause interruptions and damages to physical operations.
Among these attacks, data-integrity attacks often involve sophisticated
exploitation of vulnerabilities that enable an attacker to access and
manipulate the operational data and are hence difficult to detect with only
existing intrusion detection or model-based detection. This paper addresses the
challenges in utilizing existing side-channels to detect data-integrity attacks
in robotic manufacturing processes by developing an online detection framework,
ViSTR-GP, that cross-checks encoder-reported measurements against a
vision-based estimate from an overhead camera outside the controller's
authority. In this framework, a one-time interactive segmentation initializes
SAM-Track to generate per-frame masks. A low-rank tensor-regression surrogate
maps each mask to measurements, while a matrix-variate Gaussian process models
nominal residuals, capturing temporal structure and cross-joint correlations. A
frame-wise test statistic derived from the predictive distribution provides an
online detector with interpretable thresholds. We validate the framework on a
real-world robotic testbed with synchronized video frame and encoder data,
collecting multiple nominal cycles and constructing replay attack scenarios
with graded end-effector deviations. Results on the testbed indicate that the
proposed framework recovers joint angles accurately and detects data-integrity
attacks earlier with more frequent alarms than all baselines. These
improvements are most evident in the most subtle attacks. These results show
that plants can detect data-integrity attacks by adding an independent physical
channel, bypassing the controller's authority, without needing complex
instrumentation.

</details>


### [45] [ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation](https://arxiv.org/abs/2509.10952)
*Yangcen Liu,Woo Chul Shin,Yunhai Han,Zhenyang Chen,Harish Ravichandar,Danfei Xu*

Main category: cs.RO

TL;DR: ImMimic框架通过结合人类视频和少量机器人演示，利用动态时间规整和插值方法，有效解决了机器人模仿学习中的领域差距问题，显著提升了任务成功率和执行流畅度。


<details>
  <summary>Details</summary>
Motivation: 通过人类视频学习机器人操作可以节省成本，但视觉、形态和物理领域的差异阻碍了直接模仿。

Method: 提出ImMimic框架，动态时间规整+插值方法连接人类和机器人轨迹，创建中间域以平滑适应。

Result: 在四种任务和四种机器人上测试，显著提高任务成功率和流畅度。

Conclusion: ImMimic能有效缩小领域差距，实现鲁棒的机器人操作。

Abstract: Learning robot manipulation from abundant human videos offers a scalable
alternative to costly robot-specific data collection. However, domain gaps
across visual, morphological, and physical aspects hinder direct imitation. To
effectively bridge the domain gap, we propose ImMimic, an embodiment-agnostic
co-training framework that leverages both human videos and a small amount of
teleoperated robot demonstrations. ImMimic uses Dynamic Time Warping (DTW) with
either action- or visual-based mapping to map retargeted human hand poses to
robot joints, followed by MixUp interpolation between paired human and robot
trajectories. Our key insights are (1) retargeted human hand trajectories
provide informative action labels, and (2) interpolation over the mapped data
creates intermediate domains that facilitate smooth domain adaptation during
co-training. Evaluations on four real-world manipulation tasks (Pick and Place,
Push, Hammer, Flip) across four robotic embodiments (Robotiq, Fin Ray, Allegro,
Ability) show that ImMimic improves task success rates and execution
smoothness, highlighting its efficacy to bridge the domain gap for robust robot
manipulation. The project website can be found at
https://sites.google.com/view/immimic.

</details>


### [46] [Pogosim -- a Simulator for Pogobot robots](https://arxiv.org/abs/2509.10968)
*Leo Cazenille,Loona Macabre,Nicolas Bredeche*

Main category: cs.RO

TL;DR: Pogobots是一种专为群体机器人研究设计的低成本、模块化机器人，Pogosim是为其开发的快速、可扩展的模拟器，旨在降低算法开发成本。


<details>
  <summary>Details</summary>
Motivation: 研究群体机器人算法时，直接在机器人上测试成本高且耗费资源，因此需要一种高效模拟器来简化开发流程。

Method: 开发了Pogosim模拟器，支持与真实机器人相同的代码，提供并行模拟、结果分析与参数优化功能。

Result: Pogosim能够显著降低算法开发成本，并支持复杂问题的模拟和参数校准。

Conclusion: Pogosim为群体机器人研究提供了高效的工具，同一代码适用于模拟和真实实验，推动了研究的可扩展性。

Abstract: Pogobots are a new type of open-source/open-hardware robots specifically
designed for swarm robotics research. Their cost-effective and modular design,
complemented by vibration-based and wheel-based locomotion, fast infrared
communication and extensive software architecture facilitate the implementation
of swarm intelligence algorithms. However, testing even simple distributed
algorithms directly on robots is particularly labor-intensive. Scaling to more
complex problems or calibrate user code parameters will have a prohibitively
high strain on available resources. In this article we present Pogosim, a fast
and scalable simulator for Pogobots, designed to reduce as much as possible
algorithm development costs. The exact same code will be used in both
simulation and to experimentally drive real robots. This article details the
software architecture of Pogosim, explain how to write configuration files and
user programs and how simulations approximate or differ from experiments. We
describe how a large set of simulations can be launched in parallel, how to
retrieve and analyze the simulation results, and how to optimize user code
parameters using optimization algorithms.

</details>


### [47] [Autonomous Close-Proximity Photovoltaic Panel Coating Using a Quadcopter](https://arxiv.org/abs/2509.10979)
*Dimitri Jacquemont,Carlo Bosio,Teaya Yang,Ruiqi Zhang,Ozgur Orun,Shuai Li,Reza Alam,Thomas M. Schutzius,Simo A. Makiharju,Mark W. Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种基于四旋翼无人机的光伏面板保护涂层自动喷涂系统，利用机载传感器和视觉惯性里程计实现定位，并通过模型控制器优化喷涂过程，验证了其室内外自主能力。


<details>
  <summary>Details</summary>
Motivation: 光伏面板在可再生能源领域应用广泛，小幅效率提升可带来显著效果。防反射和自清洁涂层虽能提升性能，但易降解需定期重涂，传统手动方法成本高。

Method: 设计了搭载液体分散机制的四旋翼无人机系统，依赖机载传感器和视觉惯性里程计定位，结合模型控制器处理地面效应和质量变化。

Result: 通过广泛的室内外实验验证了系统的自主能力。

Conclusion: 该系统提供了一种灵活且低成本的光伏面板保护涂层自动化解决方案。

Abstract: Photovoltaic (PV) panels are becoming increasingly widespread in the domain
of renewable energy, and thus, small efficiency gains can have massive effects.
Anti-reflective and self-cleaning coatings enhance panel performance but
degrade over time, requiring periodic reapplication. Uncrewed Aerial Vehicles
(UAVs) offer a flexible and autonomous way to apply protective coatings more
often and at lower cost compared to traditional manual coating methods. In this
letter, we propose a quadcopter-based system, equipped with a liquid dispersion
mechanism, designed to automate such tasks. The localization stack only uses
onboard sensors, relying on visual-inertial odometry and the relative position
of the PV panel detected with respect to the quadcopter. The control relies on
a model-based controller that accounts for the ground effect and the mass
decrease of the quadcopter during liquid dispersion. We validate the autonomy
capabilities of our system through extensive indoor and outdoor experiments.

</details>


### [48] [Multi-objective task allocation for electric harvesting robots: a hierarchical route reconstruction approach](https://arxiv.org/abs/2509.11025)
*Peng Chen,Jing Liang,Hui Song,Kang-Jia Qiao,Cai-Tong Yue,Kun-Jie Yu,Ponnuthurai Nagaratnam Suganthan,Witold Pedrycz*

Main category: cs.RO

TL;DR: 本文定义了农业多电机机器人任务分配问题（AMERTA），提出了混合层次路由重建算法（HRRA），并通过实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 农业劳动力成本上升促使多机器人系统在果园采摘中的应用，但高效协调这些系统面临复杂的时间和能源消耗约束。

Method: 提出HRRA算法，结合层次编码结构、双相初始化方法、任务序列优化器和专用路由重建算子。

Result: 在45个测试实例中，HRRA表现优于七种先进算法，并通过统计分析验证其竞争力。

Conclusion: 研究为多机器人协调提供了新的问题定义和有效算法，推动了农业自动化实践。

Abstract: The increasing labor costs in agriculture have accelerated the adoption of
multi-robot systems for orchard harvesting. However, efficiently coordinating
these systems is challenging due to the complex interplay between makespan and
energy consumption, particularly under practical constraints like
load-dependent speed variations and battery limitations. This paper defines the
multi-objective agricultural multi-electrical-robot task allocation (AMERTA)
problem, which systematically incorporates these often-overlooked real-world
constraints. To address this problem, we propose a hybrid hierarchical route
reconstruction algorithm (HRRA) that integrates several innovative mechanisms,
including a hierarchical encoding structure, a dual-phase initialization
method, task sequence optimizers, and specialized route reconstruction
operators. Extensive experiments on 45 test instances demonstrate HRRA's
superior performance against seven state-of-the-art algorithms. Statistical
analysis, including the Wilcoxon signed-rank and Friedman tests, empirically
validates HRRA's competitiveness and its unique ability to explore previously
inaccessible regions of the solution space. In general, this research
contributes to the theoretical understanding of multi-robot coordination by
offering a novel problem formulation and an effective algorithm, thereby also
providing practical insights for agricultural automation.

</details>


### [49] [FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers](https://arxiv.org/abs/2509.11109)
*Jiaxin Huang,Hanyu Liu,Yunsheng Ma,Jian Shen,Yilin Zheng,Jiayi Wen,Baishu Wan,Pan Li,Zhigong Song*

Main category: cs.RO

TL;DR: 该研究开发了一个人形机器人和外骨骼式远程操作舱的硬件平台，并提出了一种名为FEWT的模仿学习框架，显著提升了人形机器人的感知表现。


<details>
  <summary>Details</summary>
Motivation: 通过机器人学习算法，人形机器人在连接物理世界和信息空间方面展现出巨大潜力，但需要更高效的感知和操作能力。

Method: 研究开发了硬件平台和FEWT框架，结合多尺度小波分解与残差网络，动态融合时域和频域特征。

Result: FEWT在仿真中将最先进算法（ACT基线）的成功率提高了30%，在现实世界提高了6-12%。

Conclusion: FEWT显著提升了人形机器人的感知表现，为机器人学习提供了新方法。

Abstract: The embodied intelligence bridges the physical world and information space.
As its typical physical embodiment, humanoid robots have shown great promise
through robot learning algorithms in recent years. In this study, a hardware
platform, including humanoid robot and exoskeleton-style teleoperation cabin,
was developed to realize intuitive remote manipulation and efficient collection
of anthropomorphic action data. To improve the perception representation of
humanoid robot, an imitation learning framework, termed Frequency-Enhanced
Wavelet-based Transformer (FEWT), was proposed, which consists of two primary
modules: Frequency-Enhanced Efficient Multi-Scale Attention (FE-EMA) and
Time-Series Discrete Wavelet Transform (TS-DWT). By combining multi-scale
wavelet decomposition with the residual network, FE-EMA can dynamically fuse
features from both time-domain and frequency-domain. This fusion is able to
capture feature information across various scales effectively, thereby
enhancing model robustness. Experimental performance demonstrates that FEWT
improves the success rate of the state-of-the-art algorithm (Action Chunking
with Transformers, ACT baseline) by up to 30% in simulation and by 6-12% in
real-world.

</details>


### [50] [ManiVID-3D: Generalizable View-Invariant Reinforcement Learning for Robotic Manipulation via Disentangled 3D Representations](https://arxiv.org/abs/2509.11125)
*Zheng Li,Pei Qu,Yufei Jia,Shihui Zhou,Haizhou Ge,Jiahang Cao,Jinni Zhou,Guyue Zhou,Jun Ma*

Main category: cs.RO

TL;DR: 论文提出了一种名为ManiVID-3D的新型3D强化学习架构，通过自监督解耦特征学习实现视点不变表示，解决了视觉强化学习策略在真实世界操纵中因摄像机视角变化而失效的问题。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的机器人操纵常因摄像机视角变化导致策略失效，现有方法依赖精确的摄像机标定或难以应对大视角变化，亟需一种更鲁棒的解决方案。

Method: 通过ViewNet模块自动对齐任意视角的点云观测到统一空间坐标系，无需外部标定；开发高效的GPU加速批量渲染模块，支持大规模3D视觉强化学习训练。

Result: 在10个模拟和5个真实任务中，该方法在视点变化下成功率比现有技术高44.7%，且参数减少80%。

Conclusion: 学习几何一致的表示对于非结构化环境中的可扩展机器人操纵具有显著效果，ManiVID-3D的鲁棒性和高效的批处理渲染展示了其实际应用潜力。

Abstract: Deploying visual reinforcement learning (RL) policies in real-world
manipulation is often hindered by camera viewpoint changes. A policy trained
from a fixed front-facing camera may fail when the camera is shifted--an
unavoidable situation in real-world settings where sensor placement is hard to
manage appropriately. Existing methods often rely on precise camera calibration
or struggle with large perspective changes. To address these limitations, we
propose ManiVID-3D, a novel 3D RL architecture designed for robotic
manipulation, which learns view-invariant representations through
self-supervised disentangled feature learning. The framework incorporates
ViewNet, a lightweight yet effective module that automatically aligns point
cloud observations from arbitrary viewpoints into a unified spatial coordinate
system without the need for extrinsic calibration. Additionally, we develop an
efficient GPU-accelerated batch rendering module capable of processing over
5000 frames per second, enabling large-scale training for 3D visual RL at
unprecedented speeds. Extensive evaluation across 10 simulated and 5 real-world
tasks demonstrates that our approach achieves a 44.7% higher success rate than
state-of-the-art methods under viewpoint variations while using 80% fewer
parameters. The system's robustness to severe perspective changes and strong
sim-to-real performance highlight the effectiveness of learning geometrically
consistent representations for scalable robotic manipulation in unstructured
environments. Our project website can be found in
https://zheng-joe-lee.github.io/manivid3d/.

</details>


### [51] [RoVerFly: Robust and Versatile Learning-based Control of Quadrotor Across Payload Configurations](https://arxiv.org/abs/2509.11149)
*Mintae Kim,Jiaze Cai,Koushil Sreenath*

Main category: cs.RO

TL;DR: 论文提出了RoVerFly，一个基于强化学习的统一控制框架，用于解决四旋翼无人机在携带或不携带柔性缆绳悬挂载荷时的精确轨迹跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 由于四旋翼的非线性动力学和欠驱动特性，尤其是携带柔性缆绳载荷时引入的额外自由度，传统模型控制方法需要大量调参且难以适应配置变化。

Method: 采用任务和领域随机化的强化学习（RL）策略，训练一个鲁棒的跟踪控制器，适用于不同载荷配置。

Result: 控制器在零样本泛化测试中表现出色，无需切换或重调即可适应不同载荷质量或缆绳长度，同时保持了反馈跟踪控制器的可解释性。

Conclusion: RoVerFly提供了一种自适应性强且鲁棒的解决方案，适用于多变载荷情况下的四旋翼精确控制。

Abstract: Designing robust controllers for precise, arbitrary trajectory tracking with
quadrotors is challenging due to nonlinear dynamics and underactuation, and
becomes harder with flexible cable-suspended payloads that introduce extra
degrees of freedom and hybridness. Classical model-based methods offer
stability guarantees but require extensive tuning and often do not adapt when
the configuration changes, such as when a payload is added or removed, or when
the payload mass or cable length varies. We present RoVerFly, a unified
learning-based control framework in which a reinforcement learning (RL) policy
serves as a robust and versatile tracking controller for standard quadrotors
and for cable-suspended payload systems across a range of configurations.
Trained with task and domain randomization, the controller is resilient to
disturbances and varying dynamics. It achieves strong zero-shot generalization
across payload settings, including no payload as well as varying mass and cable
length, without controller switching or re-tuning, while retaining the
interpretability and structure of a feedback tracking controller. Code and
supplementary materials are available at
https://github.com/mintaeshkim/roverfly

</details>


### [52] [SAMP: Spatial Anchor-based Motion Policy for Collision-Aware Robotic Manipulators](https://arxiv.org/abs/2509.11185)
*Kai Chen,Zhihai Bi,Guoyang Zhao,Chunxin Zheng,Yulin Li,Hang Zhao,Jun Ma*

Main category: cs.RO

TL;DR: 该论文提出了一种名为SAMP的统一框架，通过共享空间网格上的有符号距离场（SDF）同时编码环境和机械臂，解决了现有方法在碰撞检测和密集场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有神经运动规划方法常依赖简化的机器人模型或主要关注障碍物表示，导致碰撞检测不完整，且在复杂场景中性能下降。

Method: 提出SAMP框架，使用SDF编码环境和机械臂几何，结合机器人SDF网络和空间锚点，训练生成无碰撞轨迹的神经运动策略。

Result: 在仿真和真实环境实验中，SAMP成功率提高11%，碰撞率降低7%。

Conclusion: 研究表明，联合建模机器人和环境几何在复杂实际环境中具有显著优势。

Abstract: Neural-based motion planning methods have achieved remarkable progress for
robotic manipulators, yet a fundamental challenge lies in simultaneously
accounting for both the robot's physical shape and the surrounding environment
when generating safe and feasible motions. Moreover, existing approaches often
rely on simplified robot models or focus primarily on obstacle representation,
which can lead to incomplete collision detection and degraded performance in
cluttered scenes. To address these limitations, we propose spatial anchor-based
motion policy (SAMP), a unified framework that simultaneously encodes the
environment and the manipulator using signed distance field (SDF) anchored on a
shared spatial grid. SAMP incorporates a dedicated robot SDF network that
captures the manipulator's precise geometry, enabling collision-aware reasoning
beyond coarse link approximations. These representations are fused on spatial
anchors and used to train a neural motion policy that generates smooth,
collision-free trajectories in the proposed efficient feature alignment
strategy. Experiments conducted in both simulated and real-world environments
consistently show that SAMP outperforms existing methods, delivering an 11%
increase in success rate and a 7% reduction in collision rate. These results
highlight the benefits of jointly modelling robot and environment geometry,
demonstrating its practical value in challenging real-world environments.

</details>


### [53] [DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2509.11197)
*Yunheng Wang,Yuetong Fang,Taowen Wang,Yixiao Feng,Yawen Tan,Shuning Zhang,Peiran Liu,Yiding Ji,Renjing Xu*

Main category: cs.RO

TL;DR: DreamNav提出了一种零样本视觉与语言导航（VLN-CE）方法，通过轨迹级规划和主动想象能力，显著提升了导航性能，并在实验中取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本VLN方法依赖高成本的感知和被动的场景理解，导致控制局限于点级选择，存在部署成本高、动作语义不一致和规划短视的问题。

Method: DreamNav通过EgoView Corrector减少感知成本，Trajectory Predictor实现轨迹级规划，Imagination Predictor赋予主动想象能力。

Result: 在VLN-CE和真实世界测试中，DreamNav在SR和SPL指标上分别提升7.49%和18.15%，达到零样本SOTA。

Conclusion: DreamNav首次将轨迹级规划和主动想象结合，仅依赖自我中心输入，显著提升了零样本VLN的性能和实用性。

Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE), which
links language instructions to perception and control in the real world, is a
core capability of embodied robots. Recently, large-scale pretrained foundation
models have been leveraged as shared priors for perception, reasoning, and
action, enabling zero-shot VLN without task-specific training. However,
existing zero-shot VLN methods depend on costly perception and passive scene
understanding, collapsing control to point-level choices. As a result, they are
expensive to deploy, misaligned in action semantics, and short-sighted in
planning. To address these issues, we present DreamNav that focuses on the
following three aspects: (1) for reducing sensory cost, our EgoView Corrector
aligns viewpoints and stabilizes egocentric perception; (2) instead of
point-level actions, our Trajectory Predictor favors global trajectory-level
planning to better align with instruction semantics; and (3) to enable
anticipatory and long-horizon planning, we propose an Imagination Predictor to
endow the agent with proactive thinking capability. On VLN-CE and real-world
tests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the
strongest egocentric baseline with extra information by up to 7.49\% and
18.15\% in terms of SR and SPL metrics. To our knowledge, this is the first
zero-shot VLN method to unify trajectory-level planning and active imagination
while using only egocentric inputs.

</details>


### [54] [MEMBOT: Memory-Based Robot in Intermittent POMDP](https://arxiv.org/abs/2509.11225)
*Youzhi Liang,Eyan Noronha*

Main category: cs.RO

TL;DR: MEMBOT是一种模块化记忆架构，用于解决机器人控制任务中的间歇性部分可观测性问题，通过两阶段训练过程（离线预训练和任务特定微调）实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法假设全状态可观测，无法应对现实环境中传感器输入噪声、遮挡或缺失的挑战。

Method: MEMBOT采用两阶段训练：离线多任务预训练学习鲁棒的任务无关潜在信念编码器，随后通过行为克隆微调任务特定策略。

Result: 在10个机器人操作任务中，MEMBOT表现优于无记忆和简单循环基线，观测可用率50%时仍保持80%性能。

Conclusion: 显式信念建模对实现鲁棒、可迁移且数据高效的机器人控制策略有效。

Abstract: Robotic systems deployed in real-world environments often operate under
conditions of partial and often intermittent observability, where sensor inputs
may be noisy, occluded, or entirely unavailable due to failures or
environmental constraints. Traditional reinforcement learning (RL) approaches
that assume full state observability are ill-equipped for such challenges. In
this work, we introduce MEMBOT, a modular memory-based architecture designed to
address intermittent partial observability in robotic control tasks. MEMBOT
decouples belief inference from policy learning through a two-phase training
process: an offline multi-task learning pretraining stage that learns a robust
task-agnostic latent belief encoder using a reconstruction losses, followed by
fine-tuning of task-specific policies using behavior cloning. The belief
encoder, implemented as a state-space model (SSM) and a LSTM, integrates
temporal sequences of observations and actions to infer latent state
representations that persist even when observations are dropped. We train and
evaluate MEMBOT on 10 robotic manipulation benchmark tasks from MetaWorld and
Robomimic under varying rates of observation dropout. Results show that MEMBOT
consistently outperforms both memoryless and naively recurrent baselines,
maintaining up to 80% of peak performance under 50% observation availability.
These findings highlight the effectiveness of explicit belief modeling in
achieving robust, transferable, and data-efficient policies for real-world
partially observable robotic systems.

</details>


### [55] [CORB-Planner: Corridor as Observations for RL Planning in High-Speed Flight](https://arxiv.org/abs/2509.11240)
*Yechen Zhang,Bin Gao,Gang Wang,Jian Sun,Zhuo Li*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的无人机轨迹规划框架CORB-Planner，通过结合B样条轨迹生成和紧凑的安全飞行走廊表示，实现跨平台高速自主飞行。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在无人机上的应用受限于精确动态模型和平台特定传感，难以实现跨平台迁移。

Method: 结合B样条轨迹生成与强化学习策略，利用启发式搜索获取紧凑安全飞行走廊，采用渐进式模拟训练和SDCQ算法。

Result: 在仿真和实际测试中，CORB-Planner实现了实时规划，支持最大8.2m/s的飞行速度，且适用于多种无人机配置。

Conclusion: CORB-Planner通过抽象障碍信息和跨平台兼容性，为无人机高速自主飞行提供了实用且鲁棒的解决方案。

Abstract: Reinforcement learning (RL) has shown promise in a large number of robotic
control tasks. Nevertheless, its deployment on unmanned aerial vehicles (UAVs)
remains challenging, mainly because of reliance on accurate dynamic models and
platform-specific sensing, which hinders cross-platform transfer. This paper
presents the CORB-Planner (Corridor-as-Observations for RL B-spline planner), a
real-time, RL-based trajectory planning framework for high-speed autonomous UAV
flight across heterogeneous platforms. The key idea is to combine B-spline
trajectory generation with the RL policy producing successive control points
with a compact safe flight corridor (SFC) representation obtained via heuristic
search. The SFC abstracts obstacle information in a low-dimensional form,
mitigating overfitting to platform-specific details and reducing sensitivity to
model inaccuracies. To narrow the sim-to-real gap, we adopt an easy-to-hard
progressive training pipeline in simulation. A value-based soft
decomposed-critic Q (SDCQ) algorithm is used to learn effective policies within
approximately ten minutes of training. Benchmarks in simulation and real-world
tests demonstrate real-time planning on lightweight onboard hardware and
support maximum flight speeds up to 8.2m/s in dense, cluttered environments
without external positioning. Compatibility with various UAV configurations
(quadrotors, hexarotors) and modest onboard compute underlines the generality
and robustness of CORB-Planner for practical deployment.

</details>


### [56] [Embodied Intelligence in Disassembly: Multimodal Perception Cross-validation and Continual Learning in Neuro-Symbolic TAMP](https://arxiv.org/abs/2509.11270)
*Ziwen He,Zhigang Wang,Yanlong Peng,Pengxu Chang,Hong Yang,Ming Chen*

Main category: cs.RO

TL;DR: 论文提出了一种基于神经符号任务与运动规划的持续学习框架，用于提升动态环境中具身智能系统的适应性，并在动力电池拆解任务中取得了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 随着新能源汽车行业的快速发展，动力电池的高效拆解与回收成为循环经济的关键挑战。动态环境下的非结构化拆解场景限制了机器人感知的鲁棒性，阻碍了工业应用中的自主拆解。

Method: 提出了一种结合多模态感知交叉验证机制的双向推理流程：前向工作流动态优化动作策略，后向学习流自主收集历史任务数据以支持持续学习与自优化。

Result: 实验显示，该框架在动态拆解场景中的任务成功率从81.68%提升至100%，感知误判次数从3.389降至1.128。

Conclusion: 研究为复杂工业环境中具身智能的鲁棒性和适应性提升提供了新范式。

Abstract: With the rapid development of the new energy vehicle industry, the efficient
disassembly and recycling of power batteries have become a critical challenge
for the circular economy. In current unstructured disassembly scenarios, the
dynamic nature of the environment severely limits the robustness of robotic
perception, posing a significant barrier to autonomous disassembly in
industrial applications. This paper proposes a continual learning framework
based on Neuro-Symbolic task and motion planning (TAMP) to enhance the
adaptability of embodied intelligence systems in dynamic environments. Our
approach integrates a multimodal perception cross-validation mechanism into a
bidirectional reasoning flow: the forward working flow dynamically refines and
optimizes action strategies, while the backward learning flow autonomously
collects effective data from historical task executions to facilitate continual
system learning, enabling self-optimization. Experimental results show that the
proposed framework improves the task success rate in dynamic disassembly
scenarios from 81.68% to 100%, while reducing the average number of perception
misjudgments from 3.389 to 1.128. This research provides a new paradigm for
enhancing the robustness and adaptability of embodied intelligence in complex
industrial environments.

</details>


### [57] [Policy Learning for Social Robot-Led Physiotherapy](https://arxiv.org/abs/2509.11297)
*Carl Bettosi,Lynne Ballie,Susan Shenkin,Marta Romeo*

Main category: cs.RO

TL;DR: 社会机器人通过强化学习策略，基于专家代理数据生成的患者行为模型，实现了对患者个性化运动指导和适应性调整。


<details>
  <summary>Details</summary>
Motivation: 解决社会机器人在物理治疗中因患者行为数据不足而无法有效决策的问题，通过专家代理数据建模患者行为。

Method: 利用33名医疗专家作为患者代理，模拟患者行为并生成运动表现指标和主观疲劳评分，基于此训练强化学习策略。

Result: 策略能根据患者耐力和表现动态调整运动指令，并适用于不同康复阶段和运动计划。

Conclusion: 专家代理数据建模结合强化学习，为社会机器人个性化物理治疗指导提供了可行方案。

Abstract: Social robots offer a promising solution for autonomously guiding patients
through physiotherapy exercise sessions, but effective deployment requires
advanced decision-making to adapt to patient needs. A key challenge is the
scarcity of patient behavior data for developing robust policies. To address
this, we engaged 33 expert healthcare practitioners as patient proxies, using
their interactions with our robot to inform a patient behavior model capable of
generating exercise performance metrics and subjective scores on perceived
exertion. We trained a reinforcement learning-based policy in simulation,
demonstrating that it can adapt exercise instructions to individual exertion
tolerances and fluctuating performance, while also being applicable to patients
at different recovery stages with varying exercise plans.

</details>


### [58] [Brain-Robot Interface for Exercise Mimicry](https://arxiv.org/abs/2509.11306)
*Carl Bettosi,Emilyann Nault,Lynne Baillie,Markus Garschall,Marta Romeo,Beatrix Wais-Zechmann,Nicole Binderlehner,Theodoros Georgio*

Main category: cs.RO

TL;DR: 开发了一种新型脑机器人接口（BRI），使社交机器人能够通过患者的意图实时模仿其运动，用于康复训练，初步实验显示效果良好。


<details>
  <summary>Details</summary>
Motivation: 为了提升社交机器人作为运动指导的长期参与度，研究了通过模仿患者动作来建立情感连接的方法。

Method: 利用脑机器人接口（BRI）技术，根据患者意图生成指令，让机器人实时模仿患者运动。

Result: 在14名参与者（包括3名物理治疗师和11名中风患者）的探索性研究中，系统成功展示了运动模仿，但准确性不一；参与者对机器人指导者持积极态度。

Conclusion: BRI技术未影响患者对机器人指导者的信任和接受度，系统展现潜力，但需进一步提升准确性。

Abstract: For social robots to maintain long-term engagement as exercise instructors,
rapport-building is essential. Motor mimicry--imitating one's physical
actions--during social interaction has long been recognized as a powerful tool
for fostering rapport, and it is widely used in rehabilitation exercises where
patients mirror a physiotherapist or video demonstration. We developed a novel
Brain-Robot Interface (BRI) that allows a social robot instructor to mimic a
patient's exercise movements in real-time, using mental commands derived from
the patient's intention. The system was evaluated in an exploratory study with
14 participants (3 physiotherapists and 11 hemiparetic patients recovering from
stroke or other injuries). We found our system successfully demonstrated
exercise mimicry in 12 sessions; however, accuracy varied. Participants had
positive perceptions of the robot instructor, with high trust and acceptance
levels, which were not affected by the introduction of BRI technology.

</details>


### [59] [ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation](https://arxiv.org/abs/2509.11364)
*Sheng Liu,Zhe Li,Weiheng Wang,Han Sun,Heng Zhang,Hongpeng Chen,Yusen Qin,Arash Ajoudani,Yizhao Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种结合视觉语言模型（VLM）和机器人想象力的主动位姿估计与追踪方法，解决了零样本方法和固定摄像头在视角变换和物体遮挡时的局限性，显著优于传统基线方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决零样本方法在视角变换下的模糊性和固定摄像头在物体移动或自遮挡时的不足，作者提出了一种动态检测并解决实时模糊性的主动位姿估计方法。

Method: 方法分为离线阶段和运行时阶段：离线阶段通过渲染CAD模型的密集视图并计算熵值构建几何感知提示；运行时阶段通过VLM查询模糊性分数，结合虚拟视图渲染选择最佳视角，并引入扩散策略进行主动追踪。

Result: 实验结果表明，该方法在仿真和实际场景中显著优于传统基线方法。

Conclusion: 该方法通过结合VLM和机器人想象力，动态解决了位姿估计中的模糊性问题，并提高了追踪的鲁棒性。

Abstract: Accurate 6-DoF object pose estimation and tracking are critical for reliable
robotic manipulation. However, zero-shot methods often fail under
viewpoint-induced ambiguities and fixed-camera setups struggle when objects
move or become self-occluded. To address these challenges, we propose an active
pose estimation pipeline that combines a Vision-Language Model (VLM) with
"robotic imagination" to dynamically detect and resolve ambiguities in real
time. In an offline stage, we render a dense set of views of the CAD model,
compute the FoundationPose entropy for each view, and construct a
geometric-aware prompt that includes low-entropy (unambiguous) and high-entropy
(ambiguous) examples. At runtime, the system: (1) queries the VLM on the live
image for an ambiguity score; (2) if ambiguity is detected, imagines a discrete
set of candidate camera poses by rendering virtual views, scores each based on
a weighted combination of VLM ambiguity probability and FoundationPose entropy,
and then moves the camera to the Next-Best-View (NBV) to obtain a disambiguated
pose estimation. Furthermore, since moving objects may leave the camera's field
of view, we introduce an active pose tracking module: a diffusion-policy
trained via imitation learning, which generates camera trajectories that
preserve object visibility and minimize pose ambiguity. Experiments in
simulation and real-world show that our approach significantly outperforms
classical baselines.

</details>


### [60] [Quantum deep reinforcement learning for humanoid robot navigation task](https://arxiv.org/abs/2509.11388)
*Romerik Lokossou,Birhanu Shimelis Girma,Ozan K. Tonguz,Ahmed Biyabani*

Main category: cs.RO

TL;DR: 该研究提出量子深度强化学习（QDRL）用于高效训练人形机器人，通过量子计算加速学习，在复杂环境中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在复杂高维环境中表现不佳，参数需求大且难以应对随机性。QDRL旨在通过量子计算提升效率。

Method: 使用参数化量子电路的混合量子-经典设置，直接在MuJoCo人形机器人（Humanoid-v4和Walker2d-v4）等高维环境中训练，并与经典的Soft Actor-Critic（SAC）对比。

Result: 量子SAC的平均回报（246.40）比经典SAC（228.36）高8%，且学习步数减少92%。

Conclusion: 量子计算在强化学习中具有显著加速潜力，尤其适用于复杂的人形机器人任务。

Abstract: Classical reinforcement learning (RL) methods often struggle in complex,
high-dimensional environments because of their extensive parameter requirements
and challenges posed by stochastic, non-deterministic settings. This study
introduces quantum deep reinforcement learning (QDRL) to train humanoid agents
efficiently. While previous quantum RL models focused on smaller environments,
such as wheeled robots and robotic arms, our work pioneers the application of
QDRL to humanoid robotics, specifically in environments with substantial
observation and action spaces, such as MuJoCo's Humanoid-v4 and Walker2d-v4.
Using parameterized quantum circuits, we explored a hybrid quantum-classical
setup to directly navigate high-dimensional state spaces, bypassing traditional
mapping and planning. By integrating quantum computing with deep RL, we aim to
develop models that can efficiently learn complex navigation tasks in humanoid
robots. We evaluated the performance of the Soft Actor-Critic (SAC) in
classical RL against its quantum implementation. The results show that the
quantum SAC achieves an 8% higher average return (246.40) than the classical
SAC (228.36) after 92% fewer steps, highlighting the accelerated learning
potential of quantum computing in RL tasks.

</details>


### [61] [TRUST 2025: SCRITA and RTSS @ RO-MAN 2025](https://arxiv.org/abs/2509.11402)
*Alessandra Rossi,Patrick Holthaus,Gabriella Lakatos,Sílvia Moros,Ali Fallahi,Murat Kirtay,Marie Postma,Erhan Oztop*

Main category: cs.RO

TL;DR: TRUST工作坊是SCRITA和RTSS两个工作坊的联合成果，旨在从人类和机器人两个角度推进信任研究。


<details>
  <summary>Details</summary>
Motivation: 通过整合SCRITA和RTSS的互补目标，促进从人类和机器人双重视角的信任研究进展。

Method: 联合两个已建立的工作坊，结合各自的研究方向与成果。

Result: TRUST工作坊成功整合了两个工作坊的资源与目标。

Conclusion: TRUST工作坊为人类与机器人交互中的信任研究提供了新的合作平台。

Abstract: The TRUST workshop is the result of a collaboration between two established
workshops in the field of Human-Robot Interaction: SCRITA (Trust, Acceptance
and Social Cues in Human-Robot Interaction) and RTSS (Robot Trust for Symbiotic
Societies). This joint initiative brings together the complementary goals of
these workshops to advance research on trust from both the human and robot
perspectives.
  Website: https://scrita.herts.ac.uk/2025/

</details>


### [62] [Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations](https://arxiv.org/abs/2509.11417)
*Shresth Grover,Akshay Gopalkrishnan,Bo Ai,Henrik I. Christensen,Hao Su,Xuanlin Li*

Main category: cs.RO

TL;DR: 该论文提出了一种通过双重编码器设计、字符串动作分词器和共同训练策略，保留预训练视觉语言模型特征并适应机器人任务的方法，提高了机器人任务的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 直接从视觉语言模型（VLMs）微调得到的视觉语言动作（VLA）模型在处理机器人任务时可能会破坏预训练的表征并限制泛化能力，因此需要一种方法来更好地保留特征并适应机器人任务。

Method: 采用了三种主要方法：（i）双重编码器设计，一个冻结的视觉编码器保留预训练特征，另一个可训练的编码器适应任务；（ii）将连续动作转换为字符序列的字符串动作分词器；（iii）结合机器人演示和视觉语言数据集的共同训练策略。

Result: 在仿真和真实机器人上的评估表明，该方法在视觉扰动下的鲁棒性、对新指令和环境的泛化能力以及任务成功率方面均优于基线方法。

Conclusion: 该论文提出的框架在保留预训练特征的同时成功适应了机器人任务，显著提升了机器人任务的性能和泛化能力。

Abstract: Vision-language-action (VLA) models finetuned from vision-language models
(VLMs) hold the promise of leveraging rich pretrained representations to build
generalist robots across diverse tasks and environments. However, direct
fine-tuning on robot data often disrupts these representations and limits
generalization. We present a framework that better preserves pretrained
features while adapting them for robot manipulation. Our approach introduces
three components: (i) a dual-encoder design with one frozen vision encoder to
retain pretrained features and another trainable for task adaptation, (ii) a
string-based action tokenizer that casts continuous actions into character
sequences aligned with the model's pretraining domain, and (iii) a co-training
strategy that combines robot demonstrations with vision-language datasets
emphasizing spatial reasoning and affordances. Evaluations in simulation and on
real robots show that our method improves robustness to visual perturbations,
generalization to novel instructions and environments, and overall task success
compared to baselines.

</details>


### [63] [A Software-Only Post-Processor for Indexed Rotary Machining on GRBL-Based CNCs](https://arxiv.org/abs/2509.11433)
*Pedro Portugal,Damian D. Venghaus,Diego Lopez*

Main category: cs.RO

TL;DR: 提出一种软件框架，使GRBL数控机床实现低成本旋转加工，无需硬件改造或商业CAM软件。


<details>
  <summary>Details</summary>
Motivation: 解决教育、原型设计和创客空间中桌面CNC机床缺乏旋转轴的问题，降低技术和成本门槛。

Method: 开发定制后处理器将平面刀具路径转换为离散旋转步骤，通过浏览器界面执行。

Result: 实现了用标准硬件进行旋转加工，无需固件修改，适用于教学和快速原型制作。

Conclusion: 该框架扩展了多轴加工的可及性，支持教育和创客的实践需求。

Abstract: Affordable desktop CNC routers are common in education, prototyping, and
makerspaces, but most lack a rotary axis, limiting fabrication of rotationally
symmetric or multi-sided parts. Existing solutions often require hardware
retrofits, alternative controllers, or commercial CAM software, raising cost
and complexity. This work presents a software-only framework for indexed rotary
machining on GRBL-based CNCs. A custom post-processor converts planar toolpaths
into discrete rotary steps, executed through a browser-based interface. While
not equivalent to continuous 4-axis machining, the method enables practical
rotary-axis fabrication using only standard, off-the-shelf mechanics, without
firmware modification. By reducing technical and financial barriers, the
framework expands access to multi-axis machining in classrooms, makerspaces,
and small workshops, supporting hands-on learning and rapid prototyping.

</details>


### [64] [RAPTOR: A Foundation Policy for Quadrotor Control](https://arxiv.org/abs/2509.11481)
*Jonas Eschmann,Dario Albani,Giuseppe Loianno*

Main category: cs.RO

TL;DR: 本文提出了一种名为RAPTOR的方法，用于训练高度自适应的基础策略，以控制多种不同的四旋翼无人机，适应性强且零样本高效。


<details>
  <summary>Details</summary>
Motivation: 人类在面对新环境时能高效适应，而现有机器人控制策略（如强化学习训练的网络策略）容易过拟合，难以适应变化。本文旨在解决这一问题。

Method: 采用Meta-Imitation Learning算法，通过训练1000个教师策略并将其知识蒸馏为一个自适应学生策略，实现零样本适应。

Result: 实验表明，仅2084参数的极小策略能在毫秒级内适应10种不同四旋翼无人机，并在多种条件下表现优异。

Conclusion: RAPTOR方法展示了高度自适应基础策略的潜力，为机器人控制的泛化性提供了新方向。

Abstract: Humans are remarkably data-efficient when adapting to new unseen conditions,
like driving a new car. In contrast, modern robotic control systems, like
neural network policies trained using Reinforcement Learning (RL), are highly
specialized for single environments. Because of this overfitting, they are
known to break down even under small differences like the Simulation-to-Reality
(Sim2Real) gap and require system identification and retraining for even
minimal changes to the system. In this work, we present RAPTOR, a method for
training a highly adaptive foundation policy for quadrotor control. Our method
enables training a single, end-to-end neural-network policy to control a wide
variety of quadrotors. We test 10 different real quadrotors from 32 g to 2.4 kg
that also differ in motor type (brushed vs. brushless), frame type (soft vs.
rigid), propeller type (2/3/4-blade), and flight controller
(PX4/Betaflight/Crazyflie/M5StampFly). We find that a tiny, three-layer policy
with only 2084 parameters is sufficient for zero-shot adaptation to a wide
variety of platforms. The adaptation through In-Context Learning is made
possible by using a recurrence in the hidden layer. The policy is trained
through a novel Meta-Imitation Learning algorithm, where we sample 1000
quadrotors and train a teacher policy for each of them using Reinforcement
Learning. Subsequently, the 1000 teachers are distilled into a single, adaptive
student policy. We find that within milliseconds, the resulting foundation
policy adapts zero-shot to unseen quadrotors. We extensively test the
capabilities of the foundation policy under numerous conditions (trajectory
tracking, indoor/outdoor, wind disturbance, poking, different propellers).

</details>


### [65] [FR-Net: Learning Robust Quadrupedal Fall Recovery on Challenging Terrains through Mass-Contact Prediction](https://arxiv.org/abs/2509.11504)
*Yidan Lu,Yinzhao Dong,Jiahui Zhang,Ji Ma,Peng Lu*

Main category: cs.RO

TL;DR: FR-Net框架通过学习预测质量和接触状态，实现四足机器人在复杂地形上的稳定跌倒恢复。


<details>
  <summary>Details</summary>
Motivation: 在复杂地形上，传统控制器因感知不完整和交互不确定而失败，需开发更鲁棒的跌倒恢复方法。

Method: 使用Mass-Contact Predictor网络从有限传感器输入预测质量和接触状态，结合奖励函数训练策略。

Result: 在仿真和真实实验中验证了FR-Net在多种场景中的泛化能力，成功恢复且避免危险滚动动作。

Conclusion: 明确的质量-接触预测是鲁棒跌倒恢复的关键，为四足机器人技能泛化提供了新方向。

Abstract: Fall recovery for legged robots remains challenging, particularly on complex
terrains where traditional controllers fail due to incomplete terrain
perception and uncertain interactions. We present \textbf{FR-Net}, a
learning-based framework that enables quadrupedal robots to recover from
arbitrary fall poses across diverse environments. Central to our approach is a
Mass-Contact Predictor network that estimates the robot's mass distribution and
contact states from limited sensory inputs, facilitating effective recovery
strategies. Our carefully designed reward functions ensure safe recovery even
on steep stairs without dangerous rolling motions common to existing methods.
Trained entirely in simulation using privileged learning, our framework guides
policy learning without requiring explicit terrain data during deployment. We
demonstrate the generalization capabilities of \textbf{FR-Net} across different
quadrupedal platforms in simulation and validate its performance through
extensive real-world experiments on the Go2 robot in 10 challenging scenarios.
Our results indicate that explicit mass-contact prediction is key to robust
fall recovery, offering a promising direction for generalizable quadrupedal
skills.

</details>


### [66] [Design and Development of a Remotely Wire-Driven Walking Robot](https://arxiv.org/abs/2509.11506)
*Takahiro Hattori,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种名为Remote Wire Drive的新型机制，通过电线远程驱动移动机器人。


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣环境中电子设备易受损的问题，同时克服无电子自主机器人决策能力有限的问题。

Method: 采用解耦关节的串联连接机制，适配电线驱动的机器人，开发了一种电线驱动的四足机器人。

Result: 实验验证了Remote Wire Drive的可行性，成功驱动了四足机器人。

Conclusion: Remote Wire Drive为恶劣环境中的移动机器人提供了一种可行的远程驱动方案。

Abstract: Operating in environments too harsh or inaccessible for humans is one of the
critical roles expected of robots. However, such environments often pose risks
to electronic components as well. To overcome this, various approaches have
been developed, including autonomous mobile robots without electronics,
hydraulic remotely actuated mobile robots, and long-reach robot arms driven by
wires. Among these, electronics-free autonomous robots cannot make complex
decisions, while hydraulically actuated mobile robots and wire-driven robot
arms are used in harsh environments such as nuclear power plants. Mobile robots
offer greater reach and obstacle avoidance than robot arms, and wire mechanisms
offer broader environmental applicability than hydraulics. However, wire-driven
systems have not been used for remote actuation of mobile robots. In this
study, we propose a novel mechanism called Remote Wire Drive that enables
remote actuation of mobile robots via wires. This mechanism is a series
connection of decoupled joints, a mechanism used in wire-driven robot arms,
adapted for power transmission. We experimentally validated its feasibility by
actuating a wire-driven quadruped robot, which we also developed in this study,
through Remote Wire Drive.

</details>


### [67] [PaiP: An Operational Aware Interactive Planner for Unknown Cabinet Environments](https://arxiv.org/abs/2509.11516)
*Chengjin Wang,Zheng Yan,Yanmin Zhou,Runjie Shen,Zhipeng Wang,Bin Cheng,Bin He*

Main category: cs.RO

TL;DR: 论文提出了一种基于多模态触觉感知的实时闭环规划框架（PaiP），用于解决狭窄空间中的机器人运动规划问题。


<details>
  <summary>Details</summary>
Motivation: 狭窄空间中堆叠物体的视觉遮挡和自由空间受限给机器人运动带来挑战，传统碰撞避免方法在无可行路径时可能失败或引发碰撞。

Method: PaiP通过感知交互界面的运动效应推断物体交互特征，并将其融入栅格地图生成操作成本图，扩展采样规划方法以优化路径和操作成本。

Result: 实验表明，PaiP在狭窄空间中的运动表现鲁棒。

Conclusion: PaiP通过结合交互特征优化，有效解决了狭窄空间中的机器人运动规划问题。

Abstract: Box/cabinet scenarios with stacked objects pose significant challenges for
robotic motion due to visual occlusions and constrained free space. Traditional
collision-free trajectory planning methods often fail when no collision-free
paths exist, and may even lead to catastrophic collisions caused by invisible
objects. To overcome these challenges, we propose an operational aware
interactive motion planner (PaiP) a real-time closed-loop planning framework
utilizing multimodal tactile perception. This framework autonomously infers
object interaction features by perceiving motion effects at interaction
interfaces. These interaction features are incorporated into grid maps to
generate operational cost maps. Building upon this representation, we extend
sampling-based planning methods to interactive planning by optimizing both path
cost and operational cost. Experimental results demonstrate that PaiP achieves
robust motion in narrow spaces.

</details>


### [68] [Shape control of simulated multi-segment continuum robots via Koopman operators with per-segment projection](https://arxiv.org/abs/2509.11567)
*Eron Ristich,Jiahe Wang,Lei Zhang,Sultan Haidar Ali,Wanxin Jin,Yi Ren,Jiefeng Sun*

Main category: cs.RO

TL;DR: 提出了一种基于数据驱动的Koopman算子方法，用于模拟多段肌腱驱动软体连续机器人的形状控制，实现了高效的闭环控制。


<details>
  <summary>Details</summary>
Motivation: 当前连续机器人的研究仅限于实时任务空间控制（如尖端控制），无法实现全形状控制，主要原因是其无限自由度高计算成本。

Method: 使用Kirchhoff杆模型模拟软体机器人，通过每段投影方案识别控制仿射Koopman模型，并利用线性模型预测控制（MPC）实现形状控制。

Result: 方法实现了计算高效的闭环控制，并展示了软体机器人实时形状控制的可行性。

Conclusion: 这项研究为软体连续机器人的实际形状控制奠定了基础。

Abstract: Soft continuum robots can allow for biocompatible yet compliant motions, such
as the ability of octopus arms to swim, crawl, and manipulate objects. However,
current state-of-the-art continuum robots can only achieve real-time task-space
control (i.e., tip control) but not whole-shape control, mainly due to the high
computational cost from its infinite degrees of freedom. In this paper, we
present a data-driven Koopman operator-based approach for the shape control of
simulated multi-segment tendon-driven soft continuum robots with the Kirchhoff
rod model. Using data collected from these simulated soft robots, we conduct a
per-segment projection scheme on the state of the robots allowing for the
identification of control-affine Koopman models that are an order of magnitude
more accurate than without the projection scheme. Using these learned Koopman
models, we use a linear model predictive control (MPC) to control the robots to
a collection of target shapes of varying complexity. Our method realizes
computationally efficient closed-loop control, and demonstrates the feasibility
of real-time shape control for soft robots. We envision this work can pave the
way for practical shape control of soft continuum robots.

</details>


### [69] [GBPP: Grasp-Aware Base Placement Prediction for Robots via Two-Stage Learning](https://arxiv.org/abs/2509.11594)
*Jizhuo Chen,Diwen Liu,Jiaming Wang,Harold Soh*

Main category: cs.RO

TL;DR: GBPP是一种基于快速学习的评分器，用于从单个RGB-D快照中选择机器人抓取的基本姿态，通过两阶段课程学习实现高效数据标注和模型优化。


<details>
  <summary>Details</summary>
Motivation: 为解决机器人抓取任务中基位姿态选择的高成本和低效问题，提出一种数据高效、几何感知的方法。

Method: 采用两阶段课程学习：先用简单距离-可见性规则自动标注大量数据，再用高保真模拟试验优化模型；使用PointNet++风格点云编码器和MLP评分候选姿态。

Result: 在仿真和真实移动机械臂上，GBPP优于仅依赖接近度和几何的基线方法，选择更安全、可达的基位，错误时表现稳健。

Conclusion: GBPP提供了一种实用方法：先使用低成本启发式覆盖，再通过目标模拟校准，实现数据高效和几何感知的基位放置。

Abstract: GBPP is a fast learning based scorer that selects a robot base pose for
grasping from a single RGB-D snapshot. The method uses a two stage curriculum:
(1) a simple distance-visibility rule auto-labels a large dataset at low cost;
and (2) a smaller set of high fidelity simulation trials refines the model to
match true grasp outcomes. A PointNet++ style point cloud encoder with an MLP
scores dense grids of candidate poses, enabling rapid online selection without
full task-and-motion optimization. In simulation and on a real mobile
manipulator, GBPP outperforms proximity and geometry only baselines, choosing
safer and more reachable stances and degrading gracefully when wrong. The
results offer a practical recipe for data efficient, geometry aware base
placement: use inexpensive heuristics for coverage, then calibrate with
targeted simulation.

</details>


### [70] [AssemMate: Graph-Based LLM for Robotic Assembly Assistance](https://arxiv.org/abs/2509.11617)
*Qi Zheng,Chaoran Zhang,Zijian Liang,EnTe Lin,Shubo Cui,Qinghongbing Xie,Zhaobo Xu,Long Zeng*

Main category: cs.RO

TL;DR: AssemMate利用图结构作为知识表示形式，通过图卷积网络（GCN）和LLM结合，提升了机器人装配任务中的实时性和精确推理能力，同时在准确率和推理速度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于自然语言的知识表示方法在机器人装配任务中存在实时性和精确推理的不足，AssemMate旨在通过图结构解决这一问题。

Method: AssemMate使用GCN将知识图编码为表示空间，并与LLM对齐，同时采用视觉增强策略处理堆叠场景。

Result: AssemMate在准确率上提高了6.4%，推理速度快了3倍，上下文长度缩短了28倍，并在模拟和现实中表现出优越的泛化能力。

Conclusion: AssemMate通过图结构和LLM的结合，显著提升了机器人装配任务的性能，具备广泛的应用潜力。

Abstract: Large Language Model (LLM)-based robotic assembly assistance has gained
significant research attention. It requires the injection of domain-specific
knowledge to guide the assembly process through natural language interaction
with humans. Despite some progress, existing methods represent knowledge in the
form of natural language text. Due to the long context and redundant content,
they struggle to meet the robots' requirements for real-time and precise
reasoning. In order to bridge this gap, we present AssemMate, which utilizes
the graph\textemdash a concise and accurate form of knowledge
representation\textemdash as input. This graph-based LLM enables knowledge
graph question answering (KGQA), supporting human-robot interaction and
assembly task planning for specific products. Beyond interactive QA, AssemMate
also supports sensing stacked scenes and executing grasping to assist with
assembly. Specifically, a self-supervised Graph Convolutional Network (GCN)
encodes knowledge graph entities and relations into a latent space and aligns
them with LLM's representation, enabling the LLM to understand graph
information. In addition, a vision-enhanced strategy is employed to address
stacked scenes in grasping. Through training and evaluation, AssemMate
outperforms existing methods, achieving 6.4\% higher accuracy, 3 times faster
inference, and 28 times shorter context length, while demonstrating strong
generalization ability on random graphs. And our approach further demonstrates
superiority through robotic grasping experiments in both simulated and
real-world settings. More details can be found on the project page:
https://github.com/cristina304/AssemMate.git

</details>


### [71] [Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios](https://arxiv.org/abs/2509.11621)
*Xiangtong Yao,Yirui Zhou,Yuan Meng,Yanwen Liu,Liangyu Dong,Zitao Zhang,Zhenshan Bing,Kai Huang,Fuchun Sun,Alois Knoll*

Main category: cs.RO

TL;DR: 该论文提出了一种零样本适应方法，通过SE(3)空间训练的扩散策略和在线轨迹投影，解决机械臂和任务需求的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在未见过的机械臂或任务需求下泛化能力差，需重新收集数据和训练，成本高。

Method: 采用SE(3)空间训练基机械臂策略，在线投影生成轨迹以满足新硬件和任务约束。

Result: 在多种机械臂和末端执行器上验证了高成功率，如Franka Panda和Kuka iiwa 14。

Conclusion: 该策略在零样本适应中表现优异，实际应用中效果显著。

Abstract: Diffusion policies are powerful visuomotor models for robotic manipulation,
yet they often fail to generalize to manipulators or end-effectors unseen
during training and struggle to accommodate new task requirements at inference
time. Addressing this typically requires costly data recollection and policy
retraining for each new hardware or task configuration. To overcome this, we
introduce an adaptation-projection strategy that enables a diffusion policy to
perform zero-shot adaptation to novel manipulators and dynamic task settings,
entirely at inference time and without any retraining. Our method first trains
a diffusion policy in SE(3) space using demonstrations from a base manipulator.
During online deployment, it projects the policy's generated trajectories to
satisfy the kinematic and task-specific constraints imposed by the new hardware
and objectives. Moreover, this projection dynamically adapts to physical
differences (e.g., tool-center-point offsets, jaw widths) and task requirements
(e.g., obstacle heights), ensuring robust and successful execution. We validate
our approach on real-world pick-and-place, pushing, and pouring tasks across
multiple manipulators, including the Franka Panda and Kuka iiwa 14, equipped
with a diverse array of end-effectors like flexible grippers, Robotiq 2F/3F
grippers, and various 3D-printed designs. Our results demonstrate consistently
high success rates in these cross-manipulator scenarios, proving the
effectiveness and practicality of our adaptation-projection strategy. The code
will be released after peer review.

</details>


### [72] [ParaEQsA: Parallel and Asynchronous Embodied Questions Scheduling and Answering](https://arxiv.org/abs/2509.11663)
*Haisheng Wang,Weiming Zhi*

Main category: cs.RO

TL;DR: 本文提出了并行、紧迫性感知的Embodied Questions Answering (EQsA)问题，并介绍了ParaEQsA框架和PAEQs基准测试，展示了其在多问题场景下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统Embodied Question Answering (EQA)仅处理单问题，而实际应用中需处理异步到达且紧迫性不同的多问题，因此需要新的解决方案。

Method: 提出了ParaEQsA框架，包含共享组内存模块以减少冗余探索，和动态调度问题的优先级规划模块。

Result: ParaEQsA性能优于强基线，减少了探索和延迟，并通过PAEQs基准测试验证了其有效性。

Conclusion: 紧迫性感知的并行调度是提升多问题场景下智能体响应性和效率的关键。

Abstract: This paper formulates the Embodied Questions Answering (EQsA) problem,
introduces a corresponding benchmark, and proposes a system to tackle the
problem. Classical Embodied Question Answering (EQA) is typically formulated as
answering one single question by actively exploring a 3D environment. Real
deployments, however, often demand handling multiple questions that may arrive
asynchronously and carry different urgencies. We formalize this setting as
Embodied Questions Answering (EQsA) and present ParaEQsA, a framework for
parallel, urgency-aware scheduling and answering. ParaEQsA leverages a group
memory module shared among questions to reduce redundant exploration, and a
priority-planning module to dynamically schedule questions. To evaluate this
setting, we contribute the Parallel Asynchronous Embodied Questions (PAEQs)
benchmark containing 40 indoor scenes and five questions per scene (200 in
total), featuring asynchronous follow-up questions and urgency labels. We
further propose metrics for EQsA performance: Direct Answer Rate (DAR), and
Normalized Urgency-Weighted Latency (NUWL), which jointly measure efficiency
and responsiveness of this system. ParaEQsA consistently outperforms strong
sequential baselines adapted from recent EQA systems, while reducing
exploration and delay. Empirical evaluations investigate the relative
contributions of priority, urgency modeling, spatial scope, reward estimation,
and dependency reasoning within our framework. Together, these results
demonstrate that urgency-aware, parallel scheduling is key to making embodied
agents responsive and efficient under realistic, multi-question workloads.

</details>


### [73] [Tensor Invariant Data-Assisted Control and Dynamic Decomposition of Multibody Systems](https://arxiv.org/abs/2509.11688)
*Mostafa Eslami,Maryam Babazadeh*

Main category: cs.RO

TL;DR: 论文提出了一种基于张量力学和无坐标多体动力学模型的框架，结合数据辅助控制架构，解决了机器人系统在共享协作空间中因依赖坐标系模型导致的数据效率低下问题，提升了学习的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人控制方法依赖坐标系模型，导致数据效率低下，难以在不同参考框架中通用化物理交互，需要重复学习物理原理，增加了任务复杂性。

Method: 提出了一种无坐标、非递归的牛顿-欧拉模型，基于张量力学设计，结合数据辅助控制架构，将系统分解为物理确定部分和交互不确定部分，并通过虚拟端口变量连接。

Result: 框架通过李雅普诺夫分析证明了稳定性，并通过仿真验证了模型和闭环系统的有效性，为数据高效的、框架不变的学习算法（如等变学习）提供了理想输入。

Conclusion: 该框架解决了数据效率低下问题，提高了可解释性和泛化能力，为交互环境中的机器人控制提供了更鲁棒和通用的解决方案。

Abstract: The control of robotic systems in complex, shared collaborative workspaces
presents significant challenges in achieving robust performance and safety when
learning from experienced or simulated data is employed in the pipeline. A
primary bottleneck is the reliance on coordinate-dependent models, which leads
to profound data inefficiency by failing to generalize physical interactions
across different frames of reference. This forces learning algorithms to
rediscover fundamental physical principles in every new orientation,
artificially inflating the complexity of the learning task. This paper
introduces a novel framework that synergizes a coordinate-free, unreduced
multibody dynamics and kinematics model based on tensor mechanics with a
Data-Assisted Control (DAC) architecture. A non-recursive, closed-form
Newton-Euler model in an augmented matrix form is derived that is optimized for
tensor-based control design. This structure enables a principled decomposition
of the system into a structurally certain, physically grounded part and an
uncertain, empirical, and interaction-focused part, mediated by a virtual port
variable. Then, a complete, end-to-end tensor-invariant pipeline for modeling,
control, and learning is proposed. The coordinate-free control laws for the
structurally certain part provide a stable and abstract command interface,
proven via Lyapunov analysis. Eventually, the model and closed-loop system are
validated through simulations. This work provides a naturally ideal input for
data-efficient, frame-invariant learning algorithms, such as equivariant
learning, designed to learn the uncertain interaction. The synergy directly
addresses the data-inefficiency problem, increases explainability and
interpretability, and paves the way for more robust and generalizable robotic
control in interactive environments.

</details>


### [74] [From Pixels to Shelf: End-to-End Algorithmic Control of a Mobile Manipulator for Supermarket Stocking and Fronting](https://arxiv.org/abs/2509.11740)
*Davide Peron,Victor Nan Fernandez-Ayala,Lukas Segelmark*

Main category: cs.RO

TL;DR: 本文提出了一种用于超市货架自主补货的端到端机器人系统，整合了商用硬件和可扩展算法架构，实验表现可靠但成本效益仍不及人工。


<details>
  <summary>Details</summary>
Motivation: 超市环境中的自主补货因动态人流、狭窄空间和多样商品形态而具有挑战性，现有自动化系统性能与成本效益不及人工，亟需改进。

Method: 系统结合商用硬件、ROS2框架、行为树任务规划、优化视觉模型和两步模型预测控制，利用ArUco标记进行精确导航。

Result: 实验室模拟实验中完成700多次补货操作，成功率超过98%，但对比显示性能和成本效益仍低于人工。

Conclusion: 系统表现可靠但需进一步优化性能和成本，才能实现商业化广泛应用。

Abstract: Autonomous stocking in retail environments, particularly supermarkets,
presents challenges due to dynamic human interactions, constrained spaces, and
diverse product geometries. This paper introduces an efficient end-to-end
robotic system for autonomous shelf stocking and fronting, integrating
commercially available hardware with a scalable algorithmic architecture. A
major contribution of this work is the system integration of off-the-shelf
hardware and ROS2-based perception, planning, and control into a single
deployable platform for retail environments. Our solution leverages Behavior
Trees (BTs) for task planning, fine-tuned vision models for object detection,
and a two-step Model Predictive Control (MPC) framework for precise shelf
navigation using ArUco markers. Laboratory experiments replicating realistic
supermarket conditions demonstrate reliable performance, achieving over 98%
success in pick-and-place operations across a total of more than 700 stocking
events. However, our comparative benchmarks indicate that the performance and
cost-effectiveness of current autonomous systems remain inferior to that of
human workers, which we use to highlight key improvement areas and quantify the
progress still required before widespread commercial deployment can
realistically be achieved.

</details>


### [75] [Adaptive Motorized LiDAR Scanning Control for Robust Localization with OpenStreetMap](https://arxiv.org/abs/2509.11742)
*Jianping Li,Kaisong Zhu,Zhongyuan Liu,Rui Jin,Xinhang Xu,Pengfei Wan,Lihua Xie*

Main category: cs.RO

TL;DR: 提出了一种基于OSM引导的自适应LiDAR扫描框架，结合全局先验和局部可观测性预测，提升复杂环境下的定位鲁棒性。


<details>
  <summary>Details</summary>
Motivation: OSM提供轻量级全局先验（如建筑轮廓），但存在不完整或过时问题；LiDAR因固定视场和扫描方式，导致资源浪费和定位精度下降。

Method: 引入不确定性感知的模型预测控制，结合OSM感知项，根据场景可观测性和OSM特征分布自适应分配扫描资源。

Result: 在校园、室内走廊和城市环境中，轨迹误差显著降低，同时保持扫描完整性。

Conclusion: 结合开源地图与自适应LiDAR扫描，能在复杂环境中实现高效且鲁棒的定位。

Abstract: LiDAR-to-OpenStreetMap (OSM) localization has gained increasing attention, as
OSM provides lightweight global priors such as building footprints. These
priors enhance global consistency for robot navigation, but OSM is often
incomplete or outdated, limiting its reliability in real-world deployment.
Meanwhile, LiDAR itself suffers from a limited field of view (FoV), where
motorized rotation is commonly used to achieve panoramic coverage. Existing
motorized LiDAR systems, however, typically employ constant-speed scanning that
disregards both scene structure and map priors, leading to wasted effort in
feature-sparse regions and degraded localization accuracy. To address these
challenges, we propose Adaptive LiDAR Scanning with OSM guidance, a framework
that integrates global priors with local observability prediction to improve
localization robustness. Specifically, we augment uncertainty-aware model
predictive control with an OSM-aware term that adaptively allocates scanning
effort according to both scene-dependent observability and the spatial
distribution of OSM features. The method is implemented in ROS with a motorized
LiDAR odometry backend and evaluated in both simulation and real-world
experiments. Results on campus roads, indoor corridors, and urban environments
demonstrate significant reductions in trajectory error compared to
constant-speed baselines, while maintaining scan completeness. These findings
highlight the potential of coupling open-source maps with adaptive LiDAR
scanning to achieve robust and efficient localization in complex environments.

</details>


### [76] [Igniting VLMs toward the Embodied Space](https://arxiv.org/abs/2509.11766)
*Andy Zhai,Brae Liu,Bruno Fang,Chalse Cai,Ellie Ma,Ethan Yin,Hao Wang,Hugo Zhou,James Wang,Lights Shi,Lucy Liang,Make Wang,Qian Wang,Roy Gan,Ryan Yu,Shalfun Li,Starrick Liu,Sylas Chen,Vincent Chen,Zach Xu*

Main category: cs.RO

TL;DR: 本文提出了WALL-OSS模型，通过多模态预训练解决了现有视觉语言模型在空间和具身理解上的不足，实现了高效的具身智能任务。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在空间和具身理解上存在局限性，影响了其在具身智能中的应用。

Method: 采用紧密耦合的架构和多策略训练课程，实现了指令推理、子目标分解和细粒度动作合成的统一框架。

Result: WALL-OSS在复杂长程操作中表现出色，具备强大的指令跟随能力和复杂推理能力，超越了现有基线模型。

Conclusion: WALL-OSS为从视觉语言模型到具身基础模型提供了可靠且可扩展的路径。

Abstract: While foundation models show remarkable progress in language and vision,
existing vision-language models (VLMs) still have limited spatial and
embodiment understanding. Transferring VLMs to embodied domains reveals
fundamental mismatches between modalities, pretraining distributions, and
training objectives, leaving action comprehension and generation as a central
bottleneck on the path to AGI.
  We introduce WALL-OSS, an end-to-end embodied foundation model that leverages
large-scale multimodal pretraining to achieve (1) embodiment-aware
vision-language understanding, (2) strong language-action association, and (3)
robust manipulation capability.
  Our approach employs a tightly coupled architecture and multi-strategies
training curriculum that enables Unified Cross-Level CoT-seamlessly unifying
instruction reasoning, subgoal decomposition, and fine-grained action synthesis
within a single differentiable framework.
  Our results show that WALL-OSS attains high success on complex long-horizon
manipulations, demonstrates strong instruction-following capabilities, complex
understanding and reasoning, and outperforms strong baselines, thereby
providing a reliable and scalable path from VLMs to embodied foundation models.

</details>


### [77] [Augmented Reality-Enhanced Robot Teleoperation for Collecting User Demonstrations](https://arxiv.org/abs/2509.11783)
*Shiqi Gong,Sebastian Zudaire,Chi Zhang,Zhen Li*

Main category: cs.RO

TL;DR: 提出了一个增强现实（AR）辅助的机器人遥操作系统，通过AR控制和空间点云渲染实现直观、无接触的演示，显著提升了任务性能和用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统工业机器人编程复杂且耗时，编程演示（PbD）虽提供了替代方案，但直观的机器人控制和演示收集界面仍具挑战性。

Method: 设计了AR增强的机器人遥操作系统，结合AR控制和点云渲染，实现对机器人的远程无接触控制，并在ABB机器人平台上验证。

Result: 实时环境感知（点云渲染）显著提高了任务完成准确性（28%提升）和用户体验（SUS评分提高12%）。

Conclusion: 该工作推动了直观机器人遥操作、AR界面设计、环境感知及工业演示收集的安全性，收集的演示数据可用于机器学习训练。

Abstract: Traditional industrial robot programming is often complex and time-consuming,
typically requiring weeks or even months of effort from expert programmers.
Although Programming by Demonstration (PbD) offers a more accessible
alternative, intuitive interfaces for robot control and demonstration
collection remain challenging. To address this, we propose an Augmented Reality
(AR)-enhanced robot teleoperation system that integrates AR-based control with
spatial point cloud rendering, enabling intuitive, contact-free demonstrations.
This approach allows operators to control robots remotely without entering the
workspace or using conventional tools like the teach pendant. The proposed
system is generally applicable and has been demonstrated on ABB robot
platforms, specifically validated with the IRB 1200 industrial robot and the
GoFa 5 collaborative robot. A user study evaluates the impact of real-time
environmental perception, specifically with and without point cloud rendering,
on task completion accuracy, efficiency, and user confidence. Results indicate
that enhanced perception significantly improves task performance by 28% and
enhances user experience, as reflected by a 12% increase in the System
Usability Scale (SUS) score. This work contributes to the advancement of
intuitive robot teleoperation, AR interface design, environmental perception,
and teleoperation safety mechanisms in industrial settings for demonstration
collection. The collected demonstrations may serve as valuable training data
for machine learning applications.

</details>


### [78] [Synthetic vs. Real Training Data for Visual Navigation](https://arxiv.org/abs/2509.11791)
*Lauri Suomela,Sasanka Kuruppu Arachchige,German F. Torres,Harry Edelman,Joni-Kristian Kämäräinen*

Main category: cs.RO

TL;DR: 研究表明，通过合理的架构设计，仿真训练的视觉导航策略可以超越真实数据训练的性能，成功填补仿真与现实的差距。


<details>
  <summary>Details</summary>
Motivation: 解决仿真训练策略在现实世界中性能下降的问题，探索如何通过架构改进使其性能超越真实数据训练的策略。

Method: 提出了一种利用预训练视觉表示并能在机器人硬件上实时运行的导航策略架构。

Result: 仿真训练的策略在导航成功率上比真实数据训练版本高31%，比现有最佳方法高50%。

Conclusion: 预训练图像编码器的多样性对仿真到现实的泛化至关重要，仿真训练具有实时策略学习的优势。

Abstract: This paper investigates how the performance of visual navigation policies
trained in simulation compares to policies trained with real-world data.
Performance degradation of simulator-trained policies is often significant when
they are evaluated in the real world. However, despite this well-known
sim-to-real gap, we demonstrate that simulator-trained policies can match the
performance of their real-world-trained counterparts.
  Central to our approach is a navigation policy architecture that bridges the
sim-to-real appearance gap by leveraging pretrained visual representations and
runs real-time on robot hardware. Evaluations on a wheeled mobile robot show
that the proposed policy, when trained in simulation, outperforms its
real-world-trained version by 31% and the prior state-of-the-art methods by 50%
in navigation success rate. Policy generalization is verified by deploying the
same model onboard a drone.
  Our results highlight the importance of diverse image encoder pretraining for
sim-to-real generalization, and identify on-policy learning as a key advantage
of simulated training over training with real data.

</details>


### [79] [UniPilot: Enabling GPS-Denied Autonomy Across Embodiments](https://arxiv.org/abs/2509.11793)
*Mihir Kulkarni,Mihir Dharmadhikari,Nikhil Khedekar,Morten Nissov,Mohit Singh,Philipp Weiss,Kostas Alexis*

Main category: cs.RO

TL;DR: UniPilot是一种硬件-软件结合的自主负载，可在GPS缺失环境中为多样机器人提供自主操作能力。


<details>
  <summary>Details</summary>
Motivation: 解决在GPS缺失环境中，单一模态传感器无法保证机器人稳健运行的问题，提供多模态感知和自主导航能力。

Method: 整合LiDAR、雷达、视觉和惯性传感的多模态感知套件，结合自主软件（感知、路径规划、导航策略），实现定位、建图、规划和安全控制功能。

Result: 通过大量实验验证，UniPilot能在多样环境和机器人平台上实现稳健的建图、规划和安全导航。

Conclusion: UniPilot是一种便携且通用的自主负载，适用于多种机器人，在复杂环境中表现优异。

Abstract: This paper presents UniPilot, a compact hardware-software autonomy payload
that can be integrated across diverse robot embodiments to enable autonomous
operation in GPS-denied environments. The system integrates a multi-modal
sensing suite including LiDAR, radar, vision, and inertial sensing for robust
operation in conditions where uni-modal approaches may fail. UniPilot runs a
complete autonomy software comprising multi-modal perception, exploration and
inspection path planning, and learning-based navigation policies. The payload
provides robust localization, mapping, planning, and safety and control
capabilities in a single unit that can be deployed across a wide range of
platforms. A large number of experiments are conducted across diverse
environments and on a variety of robot platforms to validate the mapping,
planning, and safe navigation capabilities enabled by the payload.

</details>


### [80] [TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning](https://arxiv.org/abs/2509.11839)
*Jiacheng Liu,Pengxiang Ding,Qihang Zhou,Yuxuan Wu,Da Huang,Zimian Peng,Wei Xiao,Weinan Zhang,Lixin Yang,Cewu Lu,Donglin Wang*

Main category: cs.RO

TL;DR: KORR结合Koopman算子理论改进模仿学习，通过全局动态建模提升长期任务和高精度控制的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习在长期任务和高精度控制中因误差累积而表现不佳的问题，引入全局动态建模以提高性能。

Method: 提出KORR框架，利用Koopman算子理论在隐含空间中建立线性不变结构，指导残差策略的全局优化。

Result: 在长期、精细的机器人装配任务中，KORR表现优于基线方法，展现了更好的性能、鲁棒性和泛化能力。

Conclusion: Koopman基础的建模方法为现代学习技术与经典控制理论架设桥梁，具有广泛潜力。

Abstract: Imitation learning (IL) enables efficient skill acquisition from
demonstrations but often struggles with long-horizon tasks and high-precision
control due to compounding errors. Residual policy learning offers a promising,
model-agnostic solution by refining a base policy through closed-loop
corrections. However, existing approaches primarily focus on local corrections
to the base policy, lacking a global understanding of state evolution, which
limits robustness and generalization to unseen scenarios. To address this, we
propose incorporating global dynamics modeling to guide residual policy
updates. Specifically, we leverage Koopman operator theory to impose linear
time-invariant structure in a learned latent space, enabling reliable state
transitions and improved extrapolation for long-horizon prediction and unseen
environments. We introduce KORR (Koopman-guided Online Residual Refinement), a
simple yet effective framework that conditions residual corrections on
Koopman-predicted latent states, enabling globally informed and stable action
refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture
assembly tasks under various perturbations. Results demonstrate consistent
gains in performance, robustness, and generalization over strong baselines. Our
findings further highlight the potential of Koopman-based modeling to bridge
modern learning methods with classical control theory. For more details, please
refer to https://jiachengliu3.github.io/TrajBooster.

</details>


### [81] [Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer](https://arxiv.org/abs/2509.11865)
*Travis Davies,Yiqi Huang,Yunxin Liu,Xiang Chen,Huxian Liu,Luhui Hu*

Main category: cs.RO

TL;DR: Tenma是一个轻量级的扩散-Transformer策略，用于双臂控制，通过跨实例学习在异构、多模态机器人数据中表现出色，平均成功率88.95%，远超基线。


<details>
  <summary>Details</summary>
Motivation: 探索如何在轻量级跨实例学习设置中结合Transformer和扩散模型，以提升机器人操作的稳定性和性能。

Method: Tenma采用了跨实例归一化器、联合状态-时间编码器和优化的扩散动作解码器，整合多视图RGB、本体感知和语言信息。

Result: Tenma在基准测试中表现优异，平均成功率88.95%，且在对象和场景变化下保持强性能，远超基线（18.12%）。

Conclusion: Tenma展示了多模态和跨实例学习策略在提升基于Transformer的模仿学习策略能力上的巨大潜力。

Abstract: Scaling Transformer policies and diffusion models has advanced robotic
manipulation, yet combining these techniques in lightweight, cross-embodiment
learning settings remains challenging. We study design choices that most affect
stability and performance for diffusion-transformer policies trained on
heterogeneous, multimodal robot data, and introduce Tenma, a lightweight
diffusion-transformer for bi-manual arm control. Tenma integrates multiview
RGB, proprioception, and language via a cross-embodiment normalizer that maps
disparate state/action spaces into a shared latent space; a Joint State-Time
encoder for temporally aligned observation learning with inference speed
boosts; and a diffusion action decoder optimized for training stability and
learning capacity. Across benchmarks and under matched compute, Tenma achieves
an average success rate of 88.95% in-distribution and maintains strong
performance under object and scene shifts, substantially exceeding baseline
policies whose best in-distribution average is 18.12%. Despite using moderate
data scale, Tenma delivers robust manipulation and generalization, indicating
the great potential for multimodal and cross-embodiment learning strategies for
further augmenting the capacity of transformer-based imitation learning
policies.

</details>


### [82] [VH-Diffuser: Variable Horizon Diffusion Planner for Time-Aware Goal-Conditioned Trajectory Planning](https://arxiv.org/abs/2509.11930)
*Ruijia Liu,Ancheng Hou,Shaoyuan Li,Xiang Yin*

Main category: cs.RO

TL;DR: 论文提出了一种名为VHD的框架，通过学习预测可变时间范围来解决传统扩散规划器中固定时间范围导致的性能问题，提高了路径规划和机器人控制的成功率与效率。


<details>
  <summary>Details</summary>
Motivation: 传统扩散规划器在训练和推断中依赖于固定的时间范围，导致轨迹长度不匹配和性能脆弱性。VHD旨在通过学习可变时间范围来提升规划的鲁棒性和适应性。

Method: VHD框架通过学习的时间范围预测模型（Length Predictor）为每个任务实例预测合适的时间范围，并通过初始噪声调整和随机裁剪子轨迹的方式进行训练，无需修改现有扩散规划器的架构。

Result: VHD在迷宫导航和机器人控制任务中显著提高了成功率和路径效率，对时间范围不匹配和未见长度的任务表现出更强的鲁棒性。

Conclusion: VHD通过动态调整时间范围，解决了传统扩散规划器的局限性，同时保持了训练的简单性和离线特性，适用于复杂的长时任务。

Abstract: Diffusion-based planners have gained significant recent attention for their
robustness and performance in long-horizon tasks. However, most existing
planners rely on a fixed, pre-specified horizon during both training and
inference. This rigidity often produces length-mismatch (trajectories that are
too short or too long) and brittle performance across instances with varying
geometric or dynamical difficulty. In this paper, we introduce the Variable
Horizon Diffuser (VHD) framework, which treats the horizon as a learned
variable rather than a fixed hyperparameter. Given a start-goal pair, we first
predict an instance-specific horizon using a learned Length Predictor model,
which guides a Diffusion Planner to generate a trajectory of the desired
length. Our design maintains compatibility with existing diffusion planners by
controlling trajectory length through initial noise shaping and training on
randomly cropped sub-trajectories, without requiring architectural changes.
Empirically, VHD improves success rates and path efficiency in maze-navigation
and robot-arm control benchmarks, showing greater robustness to horizon
mismatch and unseen lengths, while keeping training simple and offline-only.

</details>


### [83] [E2-BKI: Evidential Ellipsoidal Bayesian Kernel Inference for Uncertainty-aware Gaussian Semantic Mapping](https://arxiv.org/abs/2509.11964)
*Junyoung Kim,Minsik Jeon,Jihong Min,Kiho Kwak,Junwon Seo*

Main category: cs.RO

TL;DR: 该论文提出了一种不确定性感知的语义映射框架，通过结合证据深度学习和贝叶斯核推断，解决了复杂户外环境中语义映射的多源不确定性问题，显著提升了映射质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的语义映射方法在复杂户外环境中因多种不确定性源导致性能下降，特别是稀疏传感器数据的不连续性问题。

Method: 提出的框架使用证据深度学习估计语义预测的不确定性，并将其融入贝叶斯核推断；同时通过高斯表示聚合噪声观测，并使用几何对齐核适应复杂场景结构。

Result: 在多样化的户外环境测试中，该方法在映射质量、不确定性校准、表示灵活性和鲁棒性上表现一致提升，同时保持实时效率。

Conclusion: 该框架通过多源不确定性处理和高斯基元融合几何与语义信息，为复杂户外环境提供了稳健的语义映射解决方案。

Abstract: Semantic mapping aims to construct a 3D semantic representation of the
environment, providing essential knowledge for robots operating in complex
outdoor settings. While Bayesian Kernel Inference (BKI) addresses
discontinuities of map inference from sparse sensor data, existing semantic
mapping methods suffer from various sources of uncertainties in challenging
outdoor environments. To address these issues, we propose an uncertainty-aware
semantic mapping framework that handles multiple sources of uncertainties,
which significantly degrade mapping performance. Our method estimates
uncertainties in semantic predictions using Evidential Deep Learning and
incorporates them into BKI for robust semantic inference. It further aggregates
noisy observations into coherent Gaussian representations to mitigate the
impact of unreliable points, while employing geometry-aligned kernels that
adapt to complex scene structures. These Gaussian primitives effectively fuse
local geometric and semantic information, enabling robust, uncertainty-aware
mapping in complex outdoor scenarios. Comprehensive evaluation across diverse
off-road and urban outdoor environments demonstrates consistent improvements in
mapping quality, uncertainty calibration, representational flexibility, and
robustness, while maintaining real-time efficiency.

</details>


### [84] [Time-Constrained Intelligent Adversaries for Automation Vulnerability Testing: A Multi-Robot Patrol Case Study](https://arxiv.org/abs/2509.11971)
*James C. Ward,Alex Bott,Connor York,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 论文提出了一种基于机器学习的对手模型，用于模拟对多机器人巡逻系统的攻击，以评估系统在有限时间内阻止入侵的能力。相比现有基线模型，新模型表现更优，可用于优化未来巡逻策略设计。


<details>
  <summary>Details</summary>
Motivation: 通过模拟对物理自主系统的敌对攻击，可以评估其抗攻击鲁棒性，并为漏洞感知设计提供参考。本文以多机器人巡逻为例，研究如何利用机器学习模型观察巡逻行为并尝试在限定时间内未被检测地入侵安全环境。

Method: 提出了一种基于机器学习的对手模型，该模型通过观察机器人巡逻行为来预测最佳入侵路径，并在有限时间内尝试未被检测地进入安全环境。

Result: 实验表明，新模型在性能上优于现有基线，为巡逻系统提供了更严格的测试。同时，该模型被用于评估多种领先的分布式多机器人巡逻策略。

Conclusion: 该研究为多机器人巡逻系统的安全性评估提供了一种有效工具，通过更严格的对手模型揭示了潜在漏洞，有助于未来巡逻策略的优化设计。

Abstract: Simulating hostile attacks of physical autonomous systems can be a useful
tool to examine their robustness to attack and inform vulnerability-aware
design. In this work, we examine this through the lens of multi-robot patrol,
by presenting a machine learning-based adversary model that observes robot
patrol behavior in order to attempt to gain undetected access to a secure
environment within a limited time duration. Such a model allows for evaluation
of a patrol system against a realistic potential adversary, offering insight
into future patrol strategy design. We show that our new model outperforms
existing baselines, thus providing a more stringent test, and examine its
performance against multiple leading decentralized multi-robot patrol
strategies.

</details>


### [85] [Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees](https://arxiv.org/abs/2509.12008)
*Yuqing Song,Cesare Tonola,Stefano Savazzi,Sanaz Kianoush,Nicola Pedrocchi,Stephan Sigg*

Main category: cs.RO

TL;DR: 论文摘要讨论了通过毫米波雷达实现手势控制的机器人手臂，解决了摄像头系统的隐私和复杂环境问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在家庭和工业中的普及，需要一种直观且非接触式的人机交互方式。

Method: 使用毫米波雷达识别九种手势，并将其映射为实时控制命令，结合手势识别与机器人控制。

Result: 系统展示了在实际应用中的性能、可靠性和实用性，实现了无缝的非接触式交互。

Conclusion: 毫米波雷达手势控制是一种高效、隐私友好的机器人交互解决方案。

Abstract: As robots become increasingly prevalent in both homes and industrial
settings, the demand for intuitive and efficient human-machine interaction
continues to rise. Gesture recognition offers an intuitive control method that
does not require physical contact with devices and can be implemented using
various sensing technologies. Wireless solutions are particularly flexible and
minimally invasive. While camera-based vision systems are commonly used, they
often raise privacy concerns and can struggle in complex or poorly lit
environments. In contrast, radar sensing preserves privacy, is robust to
occlusions and lighting, and provides rich spatial data such as distance,
relative velocity, and angle. We present a gesture-controlled robotic arm using
mm-wave radar for reliable, contactless motion recognition. Nine gestures are
recognized and mapped to real-time commands with precision. Case studies are
conducted to demonstrate the system practicality, performance and reliability
for gesture-based robotic manipulation. Unlike prior work that treats gesture
recognition and robotic control separately, our system unifies both into a
real-time pipeline for seamless, contactless human-robot interaction.

</details>


### [86] [Embodied Navigation Foundation Model](https://arxiv.org/abs/2509.12129)
*Jiazhao Zhang,Anqi Li,Yunpeng Qi,Minghan Li,Jiahang Liu,Shaoan Wang,Haoran Liu,Gengze Zhou,Yuze Wu,Xingxing Li,Yuxin Fan,Wenjun Li,Zhibo Chen,Fei Gao,Qi Wu,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: 提出跨任务和跨实体的导航基础模型NavFoM，统一处理多模态输入并在多种导航任务中实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型在一般任务中表现出色，但在具身导航中的泛化能力有限，需要适应不同实体配置和任务。

Method: 采用统一架构，引入标识符嵌入相机视图和时间信息，动态调整观测令牌以优化处理。

Result: 在多个公开基准测试中取得最优或接近最优性能，无需任务特定微调。

Conclusion: NavFoM展现强大泛化能力和实际应用潜力，为导航领域提供通用解决方案。

Abstract: Navigation is a fundamental capability in embodied AI, representing the
intelligence required to perceive and interact within physical environments
following language instructions. Despite significant progress in large
Vision-Language Models (VLMs), which exhibit remarkable zero-shot performance
on general vision-language tasks, their generalization ability in embodied
navigation remains largely confined to narrow task settings and
embodiment-specific architectures. In this work, we introduce a
cross-embodiment and cross-task Navigation Foundation Model (NavFoM), trained
on eight million navigation samples that encompass quadrupeds, drones, wheeled
robots, and vehicles, and spanning diverse tasks such as vision-and-language
navigation, object searching, target tracking, and autonomous driving. NavFoM
employs a unified architecture that processes multimodal navigation inputs from
varying camera configurations and navigation horizons. To accommodate diverse
camera setups and temporal horizons, NavFoM incorporates identifier tokens that
embed camera view information of embodiments and the temporal context of tasks.
Furthermore, to meet the demands of real-world deployment, NavFoM controls all
observation tokens using a dynamically adjusted sampling strategy under a
limited token length budget. Extensive evaluations on public benchmarks
demonstrate that our model achieves state-of-the-art or highly competitive
performance across multiple navigation tasks and embodiments without requiring
task-specific fine-tuning. Additional real-world experiments further confirm
the strong generalization capability and practical applicability of our
approach.

</details>


### [87] [Learning Contact Dynamics for Control with Action-conditioned Face Interaction Graph Networks](https://arxiv.org/abs/2509.12151)
*Zongyao Yi,Joachim Hertzberg,Martin Atzmueller*

Main category: cs.RO

TL;DR: 提出了一种可学习的物理模拟器，改进现有的GNN模拟器（FIGNet），在机器人末端执行器的运动和力-力矩预测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决接触密集型操作中机器人末端执行器的运动和力-力矩预测问题。

Method: 扩展FIGNet模型，引入新的节点和边类型，支持动作条件预测。

Result: 在仿真中，MPC控制器表现与真实动态模型相当；实际实验中，运动和力-力矩预测准确度显著提升。

Conclusion: 该模型在仿真和实际应用中均表现出色，为机器人控制提供了高效工具。

Abstract: We present a learnable physics simulator that provides accurate motion and
force-torque prediction of robot end effectors in contact-rich manipulation.
The proposed model extends the state-of-the-art GNN-based simulator (FIGNet)
with novel node and edge types, enabling action-conditional predictions for
control and state estimation tasks. In simulation, the MPC agent using our
model matches the performance of the same controller with the ground truth
dynamics model in a challenging peg-in-hole task, while in the real-world
experiment, our model achieves a 50% improvement in motion prediction accuracy
and 3$\times$ increase in force-torque prediction precision over the baseline
physics simulator. Source code and data are publicly available.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [88] [Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs](https://arxiv.org/abs/2509.11480)
*Amir Taherin,Juyi Lin,Arash Akbari,Arman Akbari,Pu Zhao,Weiwei Chen,David Kaeli,Yanzhi Wang*

Main category: cs.AI

TL;DR: 本文评估了五种Vision-Language-Action（VLA）模型在边缘和数据中心GPU平台上的性能表现，揭示了不同架构选择和硬件配置对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在机器人控制中表现优异，但其在不同架构和硬件上的性能扩展及功耗预算尚不明确，需要深入研究。

Method: 使用LIBERO基准测试五种VLA模型（包括新提出的两种架构），在边缘和数据中心GPU平台上测量了准确性、延迟、吞吐量和峰值内存使用等指标。

Result: 结果显示：(1)架构选择显著影响吞吐量和内存占用；(2)边缘设备在功耗限制下表现出非线性性能下降；(3)高吞吐量变体可实现几乎不损失准确性。

Conclusion: 研究结果挑战了数据中心硬件在机器人推断中的优越性假设，为在不同部署约束下选择和优化VLA模型提供了实用建议。

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist
policies for robotic control, yet their performance scaling across model
architectures and hardware platforms, as well as their associated power
budgets, remain poorly understood. This work presents an evaluation of five
representative VLA models -- spanning state-of-the-art baselines and two newly
proposed architectures -- targeting edge and datacenter GPU platforms. Using
the LIBERO benchmark, we measure accuracy alongside system-level metrics,
including latency, throughput, and peak memory usage, under varying edge power
constraints and high-performance datacenter GPU configurations. Our results
identify distinct scaling trends: (1) architectural choices, such as action
tokenization and model backbone size, strongly influence throughput and memory
footprint; (2) power-constrained edge devices exhibit non-linear performance
degradation, with some configurations matching or exceeding older datacenter
GPUs; and (3) high-throughput variants can be achieved without significant
accuracy loss. These findings provide actionable insights when selecting and
optimizing VLAs across a range of deployment constraints. Our work challenges
current assumptions about the superiority of datacenter hardware for robotic
inference.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [89] [Real-Time Defense Against Coordinated Cyber-Physical Attacks: A Robust Constrained Reinforcement Learning Approach](https://arxiv.org/abs/2509.10999)
*Saman Mazaheri Khamaneh,Tong Wu,Wei Sun,Cong Chen*

Main category: eess.SY

TL;DR: 提出了一种基于强化学习的三层框架（RCRL），用于快速识别和应对电网中的N-K攻击，提高系统的实时恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统面临传统N-1框架无法应对的复杂网络-物理攻击，现有方法在识别最坏情况和协调防御响应时存在计算和延迟问题。

Method: 通过AC-OPF生成多样系统状态，识别N-K攻击场景，利用Beta混合投影和拉格朗日优化训练策略，实现实时攻击控制。

Result: 在IEEE系统上的验证表明，RCRL能快速恢复系统约束，推理时间仅0.21毫秒，有效抵御网络级联故障。

Conclusion: RCRL框架为关键基础设施提供了更强的实时恢复能力，解决了传统方法的计算瓶颈。

Abstract: Modern power systems face increasing vulnerability to sophisticated
cyber-physical attacks beyond traditional N-1 contingency frameworks. Existing
security paradigms face a critical bottleneck: efficiently identifying
worst-case scenarios and rapidly coordinating defensive responses are hindered
by intensive computation and time delays, during which cascading failures can
propagate. This paper presents a novel tri-level robust constrained
reinforcement learning (RCRL) framework for robust power system security. The
framework generates diverse system states through AC-OPF formulations,
identifies worst-case N-K attack scenarios for each state, and trains policies
to mitigate these scenarios across all operating conditions without requiring
predefined attack patterns. The framework addresses constraint satisfaction
through Beta-blending projection-based feasible action mapping techniques
during training and primal-dual augmented Lagrangian optimization for
deployment. Once trained, the RCRL policy learns how to control observed
cyber-physical attacks in real time. Validation on IEEE benchmark systems
demonstrates effectiveness against coordinated N-K attacks, causing widespread
cascading failures throughout the network. The learned policy can successfully
respond rapidly to recover system-wide constraints back to normal within 0.21
ms inference times, establishing superior resilience for critical
infrastructure protection.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [90] [RJD-BASE: Multi-Modal Spectral Clustering via Randomized Joint Diagonalization](https://arxiv.org/abs/2509.11981)
*Haoze He,Artemis Pados,Daniel Kressner*

Main category: math.NA

TL;DR: 本文提出了一种名为RJD-BASE的随机化联合对角化方法，结合BASE选择规则，用于多模态谱聚类，计算高效且性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统多模态聚类方法依赖迭代细化且未直接针对聚类目标的谱子空间，存在计算成本高和性能局限的问题。

Method: 采用随机凸组合Laplacian矩阵和基于Bottom-k聚合谱能量（BASE）的选择规则，提出RJD-BASE方法。

Result: 实验表明，RJD-BASE在合成和真实数据集上能可靠选择高质量嵌入，性能优于传统方法且计算成本低。

Conclusion: RJD-BASE为多模态谱聚类提供了一种简单、高效且与聚类目标一致的新方法。

Abstract: We revisit the problem of spectral clustering in multimodal settings, where
each data modality is encoded as a graph Laplacian. While classical
approaches--including joint diagonalization, spectral co-regularization, and
multiview clustering--attempt to align embeddings across modalities, they often
rely on costly iterative refinement and may fail to directly target the
spectral subspace relevant for clustering. In this work, we introduce two key
innovations. First, we bring the power of randomization to this setting by
sampling random convex combinations of Laplacians as a simple and scalable
alternative to explicit eigenspace alignment. Second, we propose a principled
selection rule based on Bottom-$k$ Aggregated Spectral Energy (BASE)--a
$k$-dimensional extension of the directional smoothness objective from recent
minimax formulations--which we uniquely apply as a selection mechanism rather
than an optimization target. The result is Randomized Joint Diagonalization
with BASE Selection (RJD-BASE), a method that is easily implementable,
computationally efficient, aligned with the clustering objective, and grounded
in decades of progress in standard eigensolvers. Through experiments on
synthetic and real-world datasets, we show that RJD-BASE reliably selects
high-quality embeddings, outperforming classical multimodal clustering methods
at low computational cost.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [91] [Asynchronous Gathering of Opaque Robots with Mobility Faults](https://arxiv.org/abs/2509.10711)
*Subhajit Pramanick,Saswata Jana,Partha Sarathi Mandal,Gokarna Sharma*

Main category: cs.DC

TL;DR: 论文研究了在异步环境下具有(N,f)-故障系统的机器人聚集问题，提出了一种新的移动故障模型，并展示了四种结果，包括不可能性和确定性算法。


<details>
  <summary>Details</summary>
Motivation: 解决在异步环境中机器人系统中存在移动故障时的聚集问题，探索不同颜色灯光和算法对时间和效率的影响。

Method: 使用LUMI模型（带灯光机器人）和移动故障模型，分析了不同故障系统和不同颜色灯光下的聚集可能性，并提出了两种确定性算法。

Result: 证明了在(2,1)-移动故障系统中使用2色灯光无法实现聚集，但使用3色灯光可行。同时提出了两种算法，分别具有7色和26色灯光，展示了时间与颜色的折衷。

Conclusion: 在移动故障模型下，聚集问题的最优解依赖于灯光的颜色数量和时间复杂度，特别是在故障数量有限时，算法的效率最优。

Abstract: We consider the fundamental benchmarking problem of gathering in an
$(N,f)$-fault system consisting of $N$ robots, of which at most $f$ might fail
at any execution, under asynchrony. Two seminal results established
impossibility of a solution in the oblivious robot (OBLOT) model in a
$(2,0)$-fault system under semi-synchrony and in a $(3,1)$-Byzantine fault
system under asynchrony. Recently, a breakthrough result circumvented the first
impossibility result by giving a deterministic algorithm in a $(2,0)$-fault
system under asynchrony in the luminous robot (LUMI) model using 2-colored
lights. However, a breakthrough result established impossibility of gathering
in a $(2,1)$-crash system in the LUMI model under semi-synchrony. In this
paper, we consider a {\em mobility fault} model in which a robot crash only
impacts it mobility but not the operation of the light.
  We establish four results under asynchrony in LUMI with the mobility fault
model. We show that it is impossible to solve gathering in a $(2,1)$-mobility
fault system using 2-colored lights, and then give a solution using 3-colored
lights, which is optimal w.r.t. the number of colors. We then consider an
$(N,f)$-mobility fault system, $f<N$, both $N,f$ not known, and give two
deterministic algorithms that exhibit a nice time-color trade-off: The first
with time $O(N)$ using 7-colored lights and the second with time
$O(\max\{\ell,f\})$ using 26-colored lights, where $\ell< N$ is the number of
distinct convex layers of robot positions in the initial configuration.
Interestingly, for $l, f = O(1)$, our result is optimal. Our algorithms for an
$(N,f)$-mobility fault system are the first to be analysed time complexity, can
withstand obstructed visibility (opaque robot model) and asynchronous
scheduling.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [92] [Scaling to Multimodal and Multichannel Heart Sound Classification: Fine-Tuning Wav2Vec 2.0 with Synthetic and Augmented Biosignals](https://arxiv.org/abs/2509.11606)
*Milan Marocchi,Matthew Fynn,Kayapanda Mandana,Yue Rong*

Main category: cs.SD

TL;DR: 论文提出了一种结合信号处理与扩散模型的方法，通过数据增强训练Wav2Vec 2.0分类器，在多模态心音数据上实现高性能的心血管疾病检测


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，早期检测需求迫切。现有深度学习模型因同步和多通道数据集有限而未能充分发挥性能。

Method: 结合传统信号处理与WaveGrad和DiffWave扩散模型，生成增强数据集，并微调基于Wav2Vec 2.0的分类器。

Result: 在单通道PCG数据集上准确率达92.48%，同步PCG和ECG信号达93.14%，可穿戴设备数据集上表现稍逊但仍有潜力。

Conclusion: 增强数据集支持下的Transformer模型在多模态心音分类中表现优异，有望推动心血管疾病检测技术的发展。

Abstract: Cardiovascular diseases (CVDs) are the leading cause of death worldwide,
accounting for approximately 17.9 million deaths each year. Early detection is
critical, creating a demand for accurate and inexpensive pre-screening methods.
Deep learning has recently been applied to classify abnormal heart sounds
indicative of CVDs using synchronised phonocardiogram (PCG) and
electrocardiogram (ECG) signals, as well as multichannel PCG (mPCG). However,
state-of-the-art architectures remain underutilised due to the limited
availability of synchronised and multichannel datasets. Augmented datasets and
pre-trained models provide a pathway to overcome these limitations, enabling
transformer-based architectures to be trained effectively. This work combines
traditional signal processing with denoising diffusion models, WaveGrad and
DiffWave, to create an augmented dataset to fine-tune a Wav2Vec 2.0-based
classifier on multimodal and multichannel heart sound datasets. The approach
achieves state-of-the-art performance. On the Computing in Cardiology (CinC)
2016 dataset of single channel PCG, accuracy, unweighted average recall (UAR),
sensitivity, specificity and Matthew's correlation coefficient (MCC) reach
92.48\%, 93.05\%, 93.63\%, 92.48\%, 94.93\% and 0.8283, respectively. Using the
synchronised PCG and ECG signals of the training-a dataset from CinC, 93.14\%,
92.21\%, 94.35\%, 90.10\%, 95.12\% and 0.8380 are achieved for accuracy, UAR,
sensitivity, specificity and MCC, respectively. Using a wearable vest dataset
consisting of mPCG data, the model achieves 77.13\% accuracy, 74.25\% UAR,
86.47\% sensitivity, 62.04\% specificity, and 0.5082 MCC. These results
demonstrate the effectiveness of transformer-based models for CVD detection
when supported by augmented datasets, highlighting their potential to advance
multimodal and multichannel heart sound classification.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [93] [Synergetic Empowerment: Wireless Communications Meets Embodied Intelligence](https://arxiv.org/abs/2509.10481)
*Hongtao Liang,Yihe Diao,YuHang Wu,Fuhui Zhou,Qihui Wu*

Main category: cs.NI

TL;DR: 该论文讨论了无线通信与具身智能的结合，将其视为一种协同进化的过程，强调了这一结合如何提升集体智能和系统的整体优化。


<details>
  <summary>Details</summary>
Motivation: 通过将无线通信与具身智能结合，可以将其从简单的工具转变为集体智能的数字神经系统，同时提升单个代理的能力。

Method: 论文从感知-认知-执行（PCE）循环的角度，分析了具身智能与无线通信如何相互促进和挑战网络容量。

Result: 研究揭示了两者的相互依赖性，并为系统级优化提供了新的机会。

Conclusion: 论文指出了未来的开放问题和研究方向，强调了这一领域的潜力。

Abstract: Wireless communication is evolving into an agent era, where large-scale
agents with inherent embodied intelligence are not just users but active
participants. The perfect combination of wireless communication and embodied
intelligence can achieve a synergetic empowerment and greatly facilitate the
development of agent communication. An overview of this synergetic empowerment
is presented, framing it as a co-evolutionary process that transforms wireless
communication from a simple utility into the digital nervous system of a
collective intelligence, while simultaneously elevating isolated agents into a
unified superorganism with emergent capabilities far exceeding individual
contributions. Moreover, we elaborate how embodied intelligence and wireless
communication mutually benefit each other through the lens of the
perception-cognition-execution (PCE) loop, revealing a fundamental duality
where each PCE stage both challenges network capacity and creates unprecedented
opportunities for system-wide optimization. Furthermore, critical open issues
and future research directions are identified.

</details>


### [94] [CAR-BRAINet: Sub-6GHz Aided Spatial Adaptive Beam Prediction with Multi Head Attention for Heterogeneous Vehicular Networks](https://arxiv.org/abs/2509.10508)
*Aathira G Menon,Prabu Krishnan,Shyam Lal*

Main category: cs.NI

TL;DR: 论文提出了CAR-BRAINet，一种轻量级深度学习模型，通过多注意力机制优化异构车载网络的波束预测，适用于复杂实时场景，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 异构车载网络（HetVNets）在5G/B5G网络中扮演重要角色，但高度移动和复杂环境下的稳定连接仍具挑战性。现有研究缺乏专用于HetVNets的波束预测解决方案，因此需开发可靠方法。

Method: 提出CAR-BRAINet，结合卷积神经网络和多头注意力机制，模拟真实驾驶场景，考虑MAC协议、多普勒效应和信噪比等因素，生成动态数据集。

Result: CAR-BRAINet在所有车载场景中表现优异，波束预测准确且开销低，频谱效率提升17.9422%，且不依赖用户位置和天线维度。

Conclusion: CAR-BRAINet有效解决了复杂HetVNets中的波束预测问题，减少了冗余传感器延迟，性能优越。

Abstract: Heterogeneous Vehicular Networks (HetVNets) play a key role by stacking
different communication technologies such as sub-6GHz, mm-wave and DSRC to meet
diverse connectivity needs of 5G/B5G vehicular networks. HetVNet helps address
the humongous user demands-but maintaining a steady connection in a highly
mobile, real-world conditions remain a challenge. Though there has been ample
of studies on beam prediction models a dedicated solution for HetVNets is
sparsely explored. Hence, it is the need of the hour to develop a reliable beam
prediction solution, specifically for HetVNets. This paper introduces a
lightweight deep learning-based solution termed-"CAR-BRAINet" which consists of
convolutional neural networks with a powerful multi-head attention (MHA)
mechanism. Existing literature on beam prediction is largely studied under a
limited, idealised vehicular scenario, often overlooking the real-time
complexities and intricacies of vehicular networks. Therefore, this study aims
to mimic the complexities of a real-time driving scenario by incorporating key
factors such as prominent MAC protocols-3GPP-C-V2X and IEEE 802.11BD, the
effect of Doppler shifts under high velocity and varying distance and SNR
levels into three high-quality dynamic datasets pertaining to urban, rural and
highway vehicular networks. CAR-BRAINet performs effectively across all the
vehicular scenarios, demonstrating precise beam prediction with minimal beam
overhead and a steady improvement of 17.9422% on the spectral efficiency over
the existing methods. Thus, this study justifies the effectiveness of
CAR-BRAINet in complex HetVNets, offering promising performance without relying
on the location angle and antenna dimensions of the mobile users, and thereby
reducing the redundant sensor-latency.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [95] [Growing Perspectives: Modelling Embodied Perspective Taking and Inner Narrative Development Using Large Language Models](https://arxiv.org/abs/2509.11868)
*Sabrina Patania,Luca Annese,Anna Lambiase,Anita Pellegrini,Tom Foulsham,Azzurra Ruggeri,Silvia Rossi,Silvia Serino,Dimitri Ognibene*

Main category: cs.CL

TL;DR: PerspAct系统结合ReAct范式和LLMs，模拟视角采样的发展阶段，评估GPT生成符合发展阶段内部叙事的能力及其对协作任务表现的影响。


<details>
  <summary>Details</summary>
Motivation: 语言和具身视角采样对人类协作至关重要，但现有计算模型很少同时考虑两者。本研究旨在填补这一空白。

Method: 使用扩展导演任务，评估GPT生成发展一致叙事后任务执行的效果，从动作选择和任务效率两方面分析。

Result: GPT能生成发展一致的叙事，但互动中会向高级阶段转变，高级阶段协作更有效，低级阶段在复杂情境中效果不一。

Conclusion: 结合具身视角采样和语言能更好模拟发展动态，内部言语评估在语言与具身任务结合中很重要。

Abstract: Language and embodied perspective taking are essential for human
collaboration, yet few computational models address both simultaneously. This
work investigates the PerspAct system [1], which integrates the ReAct (Reason
and Act) paradigm with Large Language Models (LLMs) to simulate developmental
stages of perspective taking, grounded in Selman's theory [2]. Using an
extended director task, we evaluate GPT's ability to generate internal
narratives aligned with specified developmental stages, and assess how these
influence collaborative performance both qualitatively (action selection) and
quantitatively (task efficiency). Results show that GPT reliably produces
developmentally-consistent narratives before task execution but often shifts
towards more advanced stages during interaction, suggesting that language
exchanges help refine internal representations. Higher developmental stages
generally enhance collaborative effectiveness, while earlier stages yield more
variable outcomes in complex contexts. These findings highlight the potential
of integrating embodied perspective taking and language in LLMs to better model
developmental dynamics and stress the importance of evaluating internal speech
during combined linguistic and embodied tasks.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [96] [Agent-based Simulation for Drone Charging in an Internet of Things Environment System](https://arxiv.org/abs/2509.10867)
*Leonardo Grando,José Roberto Emiliano Leite,Edson Luiz Ursini*

Main category: cs.MA

TL;DR: 本文提出了一种基于代理的模拟模型，用于协调无人机群的电池充电，重点应用于物联网和工业4.0环境。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模无人机部署中电池使用和任务效率的优化问题。

Method: 采用了基于代理的模拟方法，详细描述了模拟方法、系统架构和实现。

Result: 通过机器学习技术分析了模拟敏感性分析的输出结果，展示了在智能农业中的实际应用。

Conclusion: 该模型证明了自主协调策略在优化无人机电池使用和任务效率方面的有效性。

Abstract: This paper presents an agent-based simulation model for coordinating battery
recharging in drone swarms, focusing on applications in Internet of Things
(IoT) and Industry 4.0 environments. The proposed model includes a detailed
description of the simulation methodology, system architecture, and
implementation. One practical use case is explored: Smart Farming, highlighting
how autonomous coordination strategies can optimize battery usage and mission
efficiency in large-scale drone deployments. This work uses a machine learning
technique to analyze the agent-based simulation sensitivity analysis output
results.

</details>


### [97] [SafeDiver: Cooperative AUV-USV Assisted Diver Communication via Multi-agent Reinforcement Learning Approach](https://arxiv.org/abs/2509.11508)
*Tinglong Deng,Hang Tao,Xinxiang Wang,Yinyan Wang,Hanjiang Luo*

Main category: cs.MA

TL;DR: 提出了一种利用海上无人系统辅助潜水员实现高速可靠通信的方案，通过多AUV和多USV协同工作。


<details>
  <summary>Details</summary>
Motivation: 随着水下人类活动增加，传统水下通信方法面临环境和设备固有的劣势，亟需新型通信方案。

Method: 采用多AUV装备光声多模态通信设备作为中继节点，结合MARL控制AUV协同移动；利用USV协调AUV信息转发，实现潜水员与水面平台通信。

Result: 仿真验证表明，该方案能有效实现潜水员间及潜水员与水面平台间的高速可靠通信。

Conclusion: 该方案通过多无人系统协同和自适应中继选择，解决了水下通信的挑战。

Abstract: As underwater human activities are increasing, the demand for underwater
communication service presents a significant challenge. Existing underwater
diver communication methods face hurdles due to inherent disadvantages and
complex underwater environments. To address this issue, we propose a scheme
that utilizes maritime unmanned systems to assist divers with reliable and
high-speed communication. Multiple AUVs are equipped with optical and acoustic
multimodal communication devices as relay nodes, providing adaptive
communication services based on changes in the diver's activity area. By using
a multi-agent reinforcement learning (MARL) approach to control the cooperative
movement of AUVs, high-speed and reliable data transmission between divers can
be achieved. At the same time, utilizing the advantages of on-demand deployment
and wide coverage of unmanned surface vehicles (USVs) as surface relay nodes to
coordinate and forward information from AUVs, and controlling AUVs to
adaptively select relay USV nodes for data transmission, high-quality
communication between divers and surface platform can be achieved. Through
simulation verification, the proposed scheme can effectively achieve reliable
and high-speed communication for divers.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [98] [Time to Play: Simulating Early-Life Animal Dynamics Enhances Robotics Locomotion Discovery](https://arxiv.org/abs/2509.11755)
*Paul Templier,Hannah Janmohamed,David Labonte,Antoine Cully*

Main category: cs.NE

TL;DR: 论文提出了一种名为SMOL的动态调整机器人执行器强度的新方法，模拟生物生长过程中的功率-重量比变化，以提升机器人的运动表现和多样性。


<details>
  <summary>Details</summary>
Motivation: 受生物生长过程中肌肉功率变化的启发，研究旨在解决现有机器人通常在静态物理参数下训练的局限性。

Method: 通过将SMOL整合到MAP-Elites质量-多样性框架中，动态调整机器人扭矩以模拟动物生长过程中力量的变化。

Result: SMOL方案显著提升了机器人在不同控制场景下的运动表现和行为多样性。

Conclusion: 动态调整机器人执行器强度的SMOL方法为机器人训练提供了新思路，特别是在模拟生物生长过程中取得了显著效果。

Abstract: Developmental changes in body morphology profoundly shape locomotion in
animals, yet artificial agents and robots are typically trained under static
physical parameters. Inspired by ontogenetic scaling of muscle power in
biology, we propose Scaling Mechanical Output over Lifetime (SMOL), a novel
curriculum that dynamically modulates robot actuator strength to mimic natural
variations in power-to-weight ratio during growth and ageing. Integrating SMOL
into the MAP-Elites quality-diversity framework, we vary the torque in standard
robotics tasks to mimic the evolution of strength in animals as they grow up
and as their body changes. Through comprehensive empirical evaluation, we show
that the SMOL schedule consistently elevates both performance and diversity of
locomotion behaviours across varied control scenarios, by allowing agents to
leverage advantageous physics early on to discover skills that act as stepping
stones when they reach their final standard body properties. Based on studies
of the total power output in humans, we also implement the SMOL-Human schedule
that models isometric body variations due to non-linear changes like puberty,
and study its impact on robotics locomotion.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [99] [WAFER: A new method to retrieve sun-induced fluorescence based on spectral wavelet decompositions](https://arxiv.org/abs/2509.11829)
*Veronika Oehl,Alexander Damm*

Main category: physics.geo-ph

TL;DR: 该论文提出了一种新的荧光反演方法WAFER，基于小波分解技术，无需大量训练数据或复杂的反射率模型假设，适用于任意波段的宽泛波长窗口。


<details>
  <summary>Details</summary>
Motivation: 太阳诱导荧光（SIF）是监测植被光合作用的重要指标，现有反演方法存在光谱形状假设或训练数据依赖性强的问题，需要更灵活高效的技术。

Method: WAFER方法通过小波分解反射光谱和参考光谱的绝对值吸收线深度，独立于荧光提取相对反射率，荧光信号通过剩余偏移量获取。

Result: 在合成数据集和实地测量数据中，WAFER与iFLD和SFM等方法表现一致，同时提供了荧光信号真实光谱形状的探索可能性。

Conclusion: WAFER是一种灵活、高效且假设限制少的新方法，适用于不同测量场景，并能避免现有模型的偏差。

Abstract: Sun-induced fluorescence (SIF) as a close remote sensing based proxy for
photosynthesis is accepted as a useful measure to remotely monitor vegetation
health and gross primary productivity. In this work we present the new
retrieval method WAFER (WAvelet decomposition FluorEscence Retrieval) based on
wavelet decompositions of the measured spectra of reflected radiance as well as
a reference radiance not containing fluorescence. By comparing absolute
absorption line depths by means of the corresponding wavelet coefficients, a
relative reflectance is retrieved independently of the fluorescence, i.e.
without introducing a coupling between reflectance and fluorescence. The
fluorescence can then be derived as the remaining offset. This method can be
applied to arbitrary chosen wavelength windows in the whole spectral range,
such that all the spectral data available is exploited, including the
separation into several frequency (i.e. width of absorption lines) levels and
without the need of extensive training datasets. At the same time, the
assumptions about the reflectance shape are minimal and no spectral shape
assumptions are imposed on the fluorescence, which not only avoids biases
arising from wrong or differing fluorescence models across different spatial
scales and retrieval methods but also allows for the exploration of this
spectral shape for different measurement setups. WAFER is tested on a synthetic
dataset as well as several diurnal datasets acquired with a field spectrometer
(FloX) over an agricultural site. We compare the WAFER method to two
established retrieval methods, namely the improved Fraunhofer line
discrimination (iFLD) method and spectral fitting method (SFM) and find a good
agreement with the added possibility of exploring the true spectral shape of
the offset signal and free choice of the retrieval window. (abbreviated)

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [100] [Early Detection of Branched Broomrape (Phelipanche ramosa) Infestation in Tomato Crops Using Leaf Spectral Analysis and Machine Learning](https://arxiv.org/abs/2509.12074)
*Mohammadreza Narimani,Alireza Pourreza,Ali Moghimi,Parastoo Farajpoor,Hamid Jafarbiglu,Mohsen B. Mesgaran*

Main category: cs.LG

TL;DR: 研究通过叶片光谱反射和集成机器学习方法，实现了对分支黑穗病的早期检测，准确率高达89%。


<details>
  <summary>Details</summary>
Motivation: 分支黑穗病是一种寄生性杂草，威胁番茄生产，早期检测可减少产量损失。

Method: 使用便携式光谱仪采集叶片反射数据，结合预处理和集成机器学习模型（如随机森林、XGBoost等）。

Result: 在585 GDD时检测准确率达89%，但随着生长阶段推进，准确率下降至69%。

Conclusion: 近端传感结合集成学习能在肉眼可见症状前及时检测分支黑穗病，有助于针对性干预。

Abstract: Branched broomrape (Phelipanche ramosa) is a chlorophyll-deficient parasitic
weed that threatens tomato production by extracting nutrients from the host. We
investigate early detection using leaf-level spectral reflectance (400-2500 nm)
and ensemble machine learning. In a field experiment in Woodland, California,
we tracked 300 tomato plants across growth stages defined by growing degree
days (GDD). Leaf reflectance was acquired with a portable spectrometer and
preprocessed (band denoising, 1 nm interpolation, Savitzky-Golay smoothing,
correlation-based band reduction). Clear class differences were observed near
1500 nm and 2000 nm water absorption features, consistent with reduced leaf
water content in infected plants at early stages. An ensemble combining Random
Forest, XGBoost, SVM with RBF kernel, and Naive Bayes achieved 89% accuracy at
585 GDD, with recalls of 0.86 (infected) and 0.93 (noninfected). Accuracy
declined at later stages (e.g., 69% at 1568 GDD), likely due to senescence and
weed interference. Despite the small number of infected plants and
environmental confounders, results show that proximal sensing with ensemble
learning enables timely detection of broomrape before canopy symptoms are
visible, supporting targeted interventions and reduced yield losses.

</details>


### [101] [Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors](https://arxiv.org/abs/2509.12081)
*Anirudha Majumdar*

Main category: cs.LG

TL;DR: 论文提出了一种通过欺骗机制实现分布外泛化的方法（DRM），通过学习使训练数据对观察者呈现独立同分布的数据表示，以消除虚假相关性并泛化到未见领域。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要访问测试数据或将训练数据划分为有限的数据生成域，限制了其适用性。DRM旨在无需这些条件即可实现稳定特征学习和泛化。

Method: 提出欺骗性风险最小化（DRM），通过可微分目标同时学习消除分布变化的特征并最小化任务特定损失，利用基于共形鞅的检测器。

Result: 在概念偏移和协变量偏移的模拟环境中，DRM表现出有效性，特别是在机器人部署环境中。

Conclusion: DRM是一种无需测试数据或域划分的新方法，能够有效实现分布外泛化，适用于多种场景。

Abstract: This paper proposes deception as a mechanism for out-of-distribution (OOD)
generalization: by learning data representations that make training data appear
independent and identically distributed (iid) to an observer, we can identify
stable features that eliminate spurious correlations and generalize to unseen
domains. We refer to this principle as deceptive risk minimization (DRM) and
instantiate it with a practical differentiable objective that simultaneously
learns features that eliminate distribution shifts from the perspective of a
detector based on conformal martingales while minimizing a task-specific loss.
In contrast to domain adaptation or prior invariant representation learning
methods, DRM does not require access to test data or a partitioning of training
data into a finite number of data-generating domains. We demonstrate the
efficacy of DRM on numerical experiments with concept shift and a simulated
imitation learning setting with covariate shift in environments that a robot is
deployed in.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [102] [Maximum diversity, weighting and invariants of time series](https://arxiv.org/abs/2509.11146)
*Byungchang So*

Main category: stat.ML

TL;DR: 论文探讨了度量空间大小的概念——magnitude，并研究了其连续性及其在时间序列分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 通过分析magnitude的连续性和权重分布，探索其在数据分析和机器学习中的实际应用价值。

Method: 基于已有的连续性和最大多样性结果，研究了权重的连续性及其变化；并将magnitude理论应用于周期性时间序列，提出新的不变量。

Result: 通过实际数据的机器学习实验验证，提出的不变量能够提升模型性能。

Conclusion: magnitude的连续性研究及其在时间序列分析中的应用展现了其理论和实际价值。

Abstract: Magnitude, obtained as a special case of Euler characteristic of enriched
category, represents a sense of the size of metric spaces and is related to
classical notions such as cardinality, dimension, and volume. While the studies
have explained the meaning of magnitude from various perspectives, continuity
also gives a valuable view of magnitude. Based on established results about
continuity of magnitude and maximum diversity, this article focuses on
continuity of weighting, a distribution whose totality is magnitude, and its
variation corresponding to maximum diversity. Meanwhile, recent studies also
illuminated the connection between magnitude and data analysis by applying
magnitude theory to point clouds representing the data or the set of model
parameters. This article will also provide an application for time series
analysis by introducing a new kind of invariants of periodic time series, where
the invariance follows directly from the continuity results. As a use-case, a
simple machine learning experiment is conducted with real-world data, in which
the suggested invariants improved the performance.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [103] [The Microwave Rainbow: How Geometry Paints Colours in Microwave Vision](https://arxiv.org/abs/2509.11099)
*Huizhang Yang*

Main category: eess.IV

TL;DR: 该论文通过几何物理模型解释了SAR图像中人造结构呈现多彩现象（微波彩虹）的物理起源，并将其从视觉伪影转化为物理形态的精确测量工具。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示SAR图像中人造结构多彩现象的物理起源，并将其发展为一种新的遥感模式。

Method: 提出了一种几何物理模型，将目标的几何形状与其观测到的彩色特征直接联系起来。

Result: 模型定量解释了从曲面上的连续颜色梯度到周期性结构的高阶衍射模式的完整现象。

Conclusion: 微波色彩视觉为SAR遥感开辟了新途径，能够直接从空间映射物理形态。

Abstract: Microwave vision from spaceborne synthetic aperture radar (SAR) provides an
all-weather, day-and-night capability to observe Earth, yet much of the
information encoded in its signals remains undeciphered. Recent high-resolution
imagery has revealed a striking phenomenon: man-made structures systematically
appear in a spectrum of colours, the physical origin of which has been an open
question. Here we show that this effect, which we term the microwave rainbow,
is a form of geometric dispersion arising from structures acting as intrinsic
diffraction gratings. We introduce a geometric-physical model that provides a
direct analytical link between a target's geometry and its observed colour
signature. This model quantitatively explains the full range of signatures,
from continuous colour gradients on curved surfaces (zero-order diffraction) to
repeating spectral patterns from periodic structures (high-order diffraction).
This work transforms colour from a visual artefact into a precise measure of
physical form, enabling the geometry of both critical infrastructure and
natural phenomena to be mapped directly from space. Our findings establish the
physical basis for a new remote sensing modality: microwave colour vision, and
open a new frontier in how we perceive our world.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [104] [A Deep Learning Framework for Joint Channel Acquisition and Communication Optimization in Movable Antenna Systems](https://arxiv.org/abs/2509.10487)
*Ruizhi Zhang,Yuchen Zhang,Lipeng Zhu,Ying Zhang,Rui Zhang*

Main category: cs.IT

TL;DR: 本文提出了一种基于可移动天线（MA）多用户通信系统的端到端深度学习框架，解决了传统方法在完美信道状态信息（CSI）假设下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常假设完美CSI，但在实际系统中CSI获取存在误差，影响系统性能。本文旨在通过联合优化信道估计、天线布置和预编码设计，解决这一问题。

Method: 提出一个端到端深度学习框架，设计导频信号和量化CSI反馈机制，并能基于统计CSI优化天线布置。

Result: 仿真表明，该方法在用户可达到总速率上优于传统基准，尤其在有限反馈和稀疏信道环境下表现突出，性能接近完美CSI的梯度方法，同时显著降低反馈开销。

Conclusion: 基于学习的MA系统设计在无线通信中展现出高效性和适应性，为未来无线系统提供了新思路。

Abstract: This paper presents an end-to-end deep learning framework in a movable
antenna (MA)-enabled multiuser communication system. In contrast to the
conventional works assuming perfect channel state information (CSI), we address
the practical CSI acquisition issue through the design of pilot signals and
quantized CSI feedback, and further incorporate the joint optimization of
channel estimation, MA placement, and precoding design. The proposed mechanism
enables the system to learn an optimized transmission strategy from imperfect
channel data, overcoming the limitations of conventional methods that conduct
channel estimation and antenna position optimization separately. To balance the
performance and overhead, we further extend the proposed framework to optimize
the antenna placement based on the statistical CSI. Simulation results
demonstrate that the proposed approach consistently outperforms traditional
benchmarks in terms of achievable sum-rate of users, especially under limited
feedback and sparse channel environments. Notably, it achieves a performance
comparable to the widely-adopted gradient-based methods with perfect CSI, while
maintaining significantly lower CSI feedback overhead. These results highlight
the effectiveness and adaptability of learning-based MA system design for
future wireless systems.

</details>


### [105] [A Broadcast Channel Framework for MIMO-OFDM Integrated Sensing and Communication](https://arxiv.org/abs/2509.10878)
*Homa Nikbakht,Husheng Li,Zhu Han,H. Vincent Poor*

Main category: cs.IT

TL;DR: 本文提出了一种统一的集成感知与通信（ISAC）框架，将其视为广播信道，并应用现有的复用方案进行优化。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络中需要同时实现通信和感知功能，但目前缺乏统一的框架来整合这两种功能。

Method: 通过将ISAC视为广播信道，提出了一种统一框架，并在此基础上提出了不同的叠加编码方案和波形优化算法。

Result: 在MIMO环境下，通过数值评估验证了所提框架在不同性能指标下的有效性。

Conclusion: 该研究为6G网络中ISAC的设计与分析提供了统一的解决方案。

Abstract: Integrated sensing and communication (ISAC) is expected to be one of the
major features of 6G wireless networks. In an ISAC system, communications and
sensing functionalities are jointly performed using the same waveform,
frequency band and hardware, thereby enabling various use cases such as in
cyber physical systems, digital twin and smart cities. A major challenge to the
design and analysis of ISAC is a unified framework that incorporates the two
distinct functions. By viewing ISAC as a type of broadcast channel, in this
paper, we propose a unified ISAC framework in which communication and sensing
signals are broadcast to the actual communication users and virtual sensing
users. This framework allows the application of existing multiplexing schemes,
such as dirty paper coding (DPC) and frequency division multiplexing (FDM) that
have been intensively studied in data communications and information theory.
Within this framework, we propose different superposition coding schemes, for
cases when the sensing waveform is known or unknown to the communication
receiver. We propose the waveform optimization algorithms in a multiple-input
multiple-output (MIMO) setting accounting for the effects of clutter and
Doppler shift. The proposed framework is numerically evaluated for different
schemes under various sensing and communications performance metrics.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [106] [InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts](https://arxiv.org/abs/2509.10813)
*Weipeng Zhong,Peizhou Cao,Yichen Jin,Li Luo,Wenzhe Cai,Jingli Lin,Hanqing Wang,Zhaoyang Lyu,Tai Wang,Bo Dai,Xudong Xu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 提出了一个名为InternScenes的大规模可模拟室内场景数据集，解决了现有数据集的局限性，如数据规模不足、布局简单、对象碰撞严重等问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集在数据规模、多样性和布局真实性方面的不足，以推动Embodied AI的发展。

Method: 整合了三种不同的场景来源（真实扫描、程序生成、设计师创建），并通过数据管道处理确保可模拟性和交互性。

Result: 构建了包含约40,000个场景、1.96M个3D对象的数据集，支持复杂场景布局生成和导航任务。

Conclusion: InternScenes为复杂场景的研究提供了重要资源，推动了模型训练的规模化，并承诺开源数据和工具以促进社区发展。

Abstract: The advancement of Embodied AI heavily relies on large-scale, simulatable 3D
scene datasets characterized by scene diversity and realistic layouts. However,
existing datasets typically suffer from limitations in data scale or diversity,
sanitized layouts lacking small items, and severe object collisions. To address
these shortcomings, we introduce \textbf{InternScenes}, a novel large-scale
simulatable indoor scene dataset comprising approximately 40,000 diverse scenes
by integrating three disparate scene sources, real-world scans, procedurally
generated scenes, and designer-created scenes, including 1.96M 3D objects and
covering 15 common scene types and 288 object classes. We particularly preserve
massive small items in the scenes, resulting in realistic and complex layouts
with an average of 41.5 objects per region. Our comprehensive data processing
pipeline ensures simulatability by creating real-to-sim replicas for real-world
scans, enhances interactivity by incorporating interactive objects into these
scenes, and resolves object collisions by physical simulations. We demonstrate
the value of InternScenes with two benchmark applications: scene layout
generation and point-goal navigation. Both show the new challenges posed by the
complex and realistic layouts. More importantly, InternScenes paves the way for
scaling up the model training for both tasks, making the generation and
navigation in such complex scenes possible. We commit to open-sourcing the
data, models, and benchmarks to benefit the whole community.

</details>


### [107] [Point-Plane Projections for Accurate LiDAR Semantic Segmentation in Small Data Scenarios](https://arxiv.org/abs/2509.10841)
*Simone Mosco,Daniel Fusaro,Wanmeng Li,Emanuele Menegatti,Alberto Pretto*

Main category: cs.CV

TL;DR: 该论文提出了一种通过点平面投影从2D表示中学习特征的方法，提升了LiDAR点云语义分割在数据稀缺场景的性能，并引入了几何感知的数据增强技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高计算复杂性和大数据需求方面存在局限性，限制了在数据稀缺场景的泛化能力。

Method: 利用点平面投影从2D表示中提取特征，并引入几何感知的数据增强技术。

Result: 在数据稀缺场景中表现显著提升，同时在标准数据集上达到竞争性结果。

Conclusion: 该方法高效且无需依赖额外数据或传感器，适用于多种LiDAR点云语义分割任务。

Abstract: LiDAR point cloud semantic segmentation is essential for interpreting 3D
environments in applications such as autonomous driving and robotics. Recent
methods achieve strong performance by exploiting different point cloud
representations or incorporating data from other sensors, such as cameras or
external datasets. However, these approaches often suffer from high
computational complexity and require large amounts of training data, limiting
their generalization in data-scarce scenarios. In this paper, we improve the
performance of point-based methods by effectively learning features from 2D
representations through point-plane projections, enabling the extraction of
complementary information while relying solely on LiDAR data. Additionally, we
introduce a geometry-aware technique for data augmentation that aligns with
LiDAR sensor properties and mitigates class imbalance. We implemented and
evaluated our method that applies point-plane projections onto multiple
informative 2D representations of the point cloud. Experiments demonstrate that
this approach leads to significant improvements in limited-data scenarios,
while also achieving competitive results on two publicly available standard
datasets, as SemanticKITTI and PandaSet. The code of our method is available at
https://github.com/SiMoM0/3PNet

</details>


### [108] [Mars Traversability Prediction: A Multi-modal Self-supervised Approach for Costmap Generation](https://arxiv.org/abs/2509.11082)
*Zongwu Xie,Kaijie Yun,Yang Liu,Yiming Ji,Han Li*

Main category: cs.CV

TL;DR: 提出了一种鲁棒的多模态框架，用于预测行星探测车的可通行性成本地图，融合相机和LiDAR数据，并通过自监督学习优化。


<details>
  <summary>Details</summary>
Motivation: 解决行星探测车在地形复杂环境中的可通行性问题，提高多模态数据融合的鲁棒性和预测精度。

Method: 结合DINOv3图像编码器和FiLM传感器融合技术，自监督训练使用IMU生成标签，优化损失函数结合Huber和平滑项。

Result: 实验表明模型对输入干扰（如LiDAR稀疏化）具有高度鲁棒性，MAE仅小幅增加（0.0775到0.0915）。

Conclusion: 模型以几何信息为主导，贡献包括高保真仿真环境、自监督标签生成和多模态预测模型，未来需改进领域泛化和数据集扩展。

Abstract: We present a robust multi-modal framework for predicting traversability
costmaps for planetary rovers. Our model fuses camera and LiDAR data to produce
a bird's-eye-view (BEV) terrain costmap, trained self-supervised using
IMU-derived labels. Key updates include a DINOv3-based image encoder,
FiLM-based sensor fusion, and an optimization loss combining Huber and
smoothness terms. Experimental ablations (removing image color, occluding
inputs, adding noise) show only minor changes in MAE/MSE (e.g. MAE increases
from ~0.0775 to 0.0915 when LiDAR is sparsified), indicating that geometry
dominates the learned cost and the model is highly robust. We attribute the
small performance differences to the IMU labeling primarily reflecting terrain
geometry rather than semantics and to limited data diversity. Unlike prior work
claiming large gains, we emphasize our contributions: (1) a high-fidelity,
reproducible simulation environment; (2) a self-supervised IMU-based labeling
pipeline; and (3) a strong multi-modal BEV costmap prediction model. We discuss
limitations and future work such as domain generalization and dataset
expansion.

</details>


### [109] [Beyond Frame-wise Tracking: A Trajectory-based Paradigm for Efficient Point Cloud Tracking](https://arxiv.org/abs/2509.11453)
*BaiChen Fan,Sifan Zhou,Jian Li,Shibo Zhao,Muqing Cao,Qin Wang*

Main category: cs.CV

TL;DR: TrajTrack 是一种基于轨迹的 3D 单目标跟踪框架，通过历史轨迹隐式学习运动连续性，显著提升了跟踪精度并保持了高效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在稀疏或遮挡场景中性能不足的问题，同时避免高计算成本。

Method: 结合显式运动提议和隐式运动建模模块，利用历史轨迹预测未来运动轨迹。

Result: 在 NuScenes 基准测试中精度提升 4.48%，运行速度为 56 FPS。

Conclusion: TrajTrack 在性能和效率上均优于现有方法，并具有强泛化能力。

Abstract: LiDAR-based 3D single object tracking (3D SOT) is a critical task in robotics
and autonomous systems. Existing methods typically follow frame-wise motion
estimation or a sequence-based paradigm. However, the two-frame methods are
efficient but lack long-term temporal context, making them vulnerable in sparse
or occluded scenes, while sequence-based methods that process multiple point
clouds gain robustness at a significant computational cost. To resolve this
dilemma, we propose a novel trajectory-based paradigm and its instantiation,
TrajTrack. TrajTrack is a lightweight framework that enhances a base two-frame
tracker by implicitly learning motion continuity from historical bounding box
trajectories alone-without requiring additional, costly point cloud inputs. It
first generates a fast, explicit motion proposal and then uses an implicit
motion modeling module to predict the future trajectory, which in turn refines
and corrects the initial proposal. Extensive experiments on the large-scale
NuScenes benchmark show that TrajTrack achieves new state-of-the-art
performance, dramatically improving tracking precision by 4.48% over a strong
baseline while running at 56 FPS. Besides, we also demonstrate the strong
generalizability of TrajTrack across different base trackers. Video is
available at https://www.bilibili.com/video/BV1ahYgzmEWP.

</details>


### [110] [Learning to Generate 4D LiDAR Sequences](https://arxiv.org/abs/2509.11959)
*Ao Liang,Youquan Liu,Yu Yang,Dongyue Lu,Linfeng Li,Lingdong Kong,Huaici Zhao,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: LiDARCrafter是一个统一的框架，能将自由格式语言转化为可编辑的LiDAR序列，解决了4D LiDAR数据生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LiDAR在精确3D感知中的重要性很高，但LiDAR生成仍未被充分探索，特别是在4D数据中的可控性、时间稳定性和评估方面存在挑战。

Method: 提出了LiDARCrafter框架，将指令解析为以自我为中心的场景图，通过三支扩散模型生成对象布局、轨迹和形状，并使用基于范围图像的扩散模型和自回归模块生成时间一致的序列。

Result: 在nuScenes数据集上，LiDARCrafter在保真度、可控性和时间一致性方面达到了最先进的性能。

Conclusion: LiDARCrafter为基于LiDAR的模拟和数据增强提供了基础，并提供了EvalSuite作为公平评估的基准。

Abstract: While generative world models have advanced video and occupancy-based data
synthesis, LiDAR generation remains underexplored despite its importance for
accurate 3D perception. Extending generation to 4D LiDAR data introduces
challenges in controllability, temporal stability, and evaluation. We present
LiDARCrafter, a unified framework that converts free-form language into
editable LiDAR sequences. Instructions are parsed into ego-centric scene
graphs, which a tri-branch diffusion model transforms into object layouts,
trajectories, and shapes. A range-image diffusion model generates the initial
scan, and an autoregressive module extends it into a temporally coherent
sequence. The explicit layout design further supports object-level editing,
such as insertion or relocation. To enable fair assessment, we provide
EvalSuite, a benchmark spanning scene-, object-, and sequence-level metrics. On
nuScenes, LiDARCrafter achieves state-of-the-art fidelity, controllability, and
temporal consistency, offering a foundation for LiDAR-based simulation and data
augmentation.

</details>
