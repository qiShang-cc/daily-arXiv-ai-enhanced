{"id": "2506.22448", "pdf": "https://arxiv.org/pdf/2506.22448", "abs": "https://arxiv.org/abs/2506.22448", "authors": ["Yu Ma", "Xingyu Zhou", "Xiao Li", "Le Liang", "Shi Jin"], "title": "Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "summary": "Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless\nsystems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA\nsystem, addressing resource allocation challenges. A two-stage unsupervised\nlearning-based framework is proposed to jointly design RIS phase shifts, BS\nbeamforming, and resource block (RB) allocation. The framework includes\nBeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which\nallocates RBs using equivalent CSI derived from BeamNet outputs. Active\nbeamforming is implemented via maximum ratio transmission and water-filling. To\nhandle discrete constraints while ensuring differentiability, quantization and\nthe Gumbel-softmax trick are adopted. A customized loss and phased training\nenhance performance under QoS constraints. Simulations show the method achieves\n99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and\nit remains robust across varying channel and user conditions.", "AI": {"tldr": "\u4e24\u9636\u6bb5\u65e0\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u4f18\u5316RIS\u8f85\u52a9\u7cfb\u7edf\u7684\u8d44\u6e90\u5206\u914d\uff0c\u9ad8\u6548\u4e14\u9c81\u68d2\u3002", "motivation": "\u7814\u7a76RIS\u8f85\u52a9\u7684MISO-OFDMA\u7cfb\u7edf\u4e2d\u7684\u4e0b\u884c\u94fe\u8def\u4f20\u8f93\uff0c\u89e3\u51b3\u8d44\u6e90\u5206\u914d\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e24\u9636\u6bb5\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u8054\u5408\u8bbe\u8ba1RIS\u76f8\u4f4d\u504f\u79fb\u3001\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\u548c\u8d44\u6e90\u5757\u5206\u914d\u3002\u6846\u67b6\u5305\u62ecBeamNet\u548cAllocationNet\uff0c\u5206\u522b\u9884\u6d4bRIS\u76f8\u4f4d\u504f\u79fb\u548c\u5206\u914d\u8d44\u6e90\u5757\u3002\u91c7\u7528\u6700\u5927\u6bd4\u4f20\u8f93\u548c\u6ce8\u6c34\u7b97\u6cd5\u5b9e\u73b0\u4e3b\u52a8\u6ce2\u675f\u6210\u5f62\uff0c\u5e76\u4f7f\u7528\u91cf\u5316\u548cGumbel-softmax\u6280\u5de7\u5904\u7406\u79bb\u6563\u7ea6\u675f\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e8699.93%\u7684SCA\u57fa\u7ebf\u603b\u548c\u901f\u7387\uff0c\u4ec5\u6d88\u8017\u5176\u8fd0\u884c\u65f6\u95f4\u76840.036%\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u4fe1\u9053\u548c\u7528\u6237\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e6G\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002"}}
{"id": "2506.22454", "pdf": "https://arxiv.org/pdf/2506.22454", "abs": "https://arxiv.org/abs/2506.22454", "authors": ["Ana Luiza S. Tavares", "Artur Pedro M. Neto", "Francinaldo L. Gomes", "Paul Rodrigo dos Reis", "Arthur G. da Silva", "Antonio P. Junior", "Bruno D. Gomes"], "title": "Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach", "categories": ["eess.SP", "cs.LG"], "comment": "8 pages, 5 figures", "summary": "Accurate intraoperative localization of the subthalamic nucleus (STN) is\nessential for the efficacy of Deep Brain Stimulation (DBS) in patients with\nParkinson's disease. While microelectrode recordings (MERs) provide rich\nelectrophysiological information during DBS electrode implantation, current\nlocalization practices often rely on subjective interpretation of signal\nfeatures. In this study, we propose a quantitative framework that leverages\nnonlinear dynamics and entropy-based metrics to classify neural activity\nrecorded inside versus outside the STN. MER data from three patients were\npreprocessed using a robust artifact correction pipeline, segmented, and\nlabelled based on surgical annotations. A comprehensive set of recurrence\nquantification analysis, nonlinear, and entropy features were extracted from\neach segment. Multiple supervised classifiers were trained on every combination\nof feature domains using stratified 10-fold cross-validation, followed by\nstatistical comparison using paired Wilcoxon signed-rank tests with\nHolm-Bonferroni correction. The combination of entropy and nonlinear features\nyielded the highest discriminative power, and the Extra Trees classifier\nemerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and\nROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed\nrobust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the\npotential of nonlinear and entropy signal descriptors in supporting real-time,\ndata-driven decision-making during DBS surgeries", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.22455", "pdf": "https://arxiv.org/pdf/2506.22455", "abs": "https://arxiv.org/abs/2506.22455", "authors": ["Dung Truong", "Arnaud Delorme"], "title": "Data Normalization Strategies for EEG Deep Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Normalization is a critical yet often overlooked component in the\npreprocessing pipeline for EEG deep learning applications. The rise of\nlarge-scale pretraining paradigms such as self-supervised learning (SSL)\nintroduces a new set of tasks whose nature is substantially different from\nsupervised training common in EEG deep learning applications. This raises new\nquestions about optimal normalization strategies for the applicable task. In\nthis study, we systematically evaluate the impact of normalization granularity\n(recording vs. window level) and scope (cross-channel vs. within-channel) on\nboth supervised (age and gender prediction) and self-supervised (Contrastive\nPredictive Coding) tasks. Using high-density resting-state EEG from 2,836\nsubjects in the Healthy Brain Network dataset, we show that optimal\nnormalization strategies differ significantly between training paradigms.\nWindow-level within-channel normalization yields the best performance in\nsupervised tasks, while minimal or cross-channel normalization at the window\nlevel is more effective for SSL. These results underscore the necessity of\ntask-specific normalization choices and challenge the assumption that a\nuniversal normalization strategy can generalize across learning settings. Our\nfindings provide practical insights for developing robust EEG deep learning\npipelines as the field shifts toward large-scale, foundation model training.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86EEG\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5f52\u4e00\u5316\u7b56\u7565\u5bf9\u76d1\u7763\u5b66\u4e60\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u540c\u4efb\u52a1\u9700\u8981\u4e0d\u540c\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\u3002", "motivation": "EEG\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5f52\u4e00\u5316\u7b56\u7565\u901a\u5e38\u88ab\u5ffd\u89c6\uff0c\u800c\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff08\u5982\u81ea\u76d1\u7763\u5b66\u4e60\uff09\u7684\u51fa\u73b0\u5e26\u6765\u4e86\u65b0\u7684\u4efb\u52a1\u7c7b\u578b\uff0c\u9700\u8981\u7814\u7a76\u6700\u4f18\u7684\u5f52\u4e00\u5316\u7b56\u7565\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5f52\u4e00\u5316\u7c92\u5ea6\uff08\u8bb0\u5f55\u7ea7\u522bvs.\u7a97\u53e3\u7ea7\u522b\uff09\u548c\u8303\u56f4\uff08\u8de8\u901a\u9053vs.\u901a\u9053\u5185\uff09\u5bf9\u76d1\u7763\u4efb\u52a1\uff08\u5e74\u9f84\u548c\u6027\u522b\u9884\u6d4b\uff09\u548c\u81ea\u76d1\u7763\u4efb\u52a1\uff08\u5bf9\u6bd4\u9884\u6d4b\u7f16\u7801\uff09\u7684\u5f71\u54cd\u3002\u4f7f\u7528\u4e862,836\u540d\u53d7\u8bd5\u8005\u7684\u9ad8\u5bc6\u5ea6\u9759\u606f\u6001EEG\u6570\u636e\u3002", "result": "\u76d1\u7763\u4efb\u52a1\u4e2d\uff0c\u7a97\u53e3\u7ea7\u522b\u901a\u9053\u5185\u5f52\u4e00\u5316\u6548\u679c\u6700\u4f73\uff1b\u800c\u81ea\u76d1\u7763\u4efb\u52a1\u4e2d\uff0c\u7a97\u53e3\u7ea7\u522b\u7684\u8de8\u901a\u9053\u6216\u65e0\u5f52\u4e00\u5316\u66f4\u6709\u6548\u3002", "conclusion": "\u5f52\u4e00\u5316\u7b56\u7565\u9700\u8981\u6839\u636e\u4efb\u52a1\u7c7b\u578b\u5b9a\u5236\uff0c\u6ca1\u6709\u901a\u7528\u7684\u65b9\u6cd5\u53ef\u4ee5\u9002\u7528\u4e8e\u6240\u6709\u5b66\u4e60\u8bbe\u7f6e\u3002\u8fd9\u5bf9EEG\u6df1\u5ea6\u5b66\u4e60\u7ba1\u9053\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2506.22456", "pdf": "https://arxiv.org/pdf/2506.22456", "abs": "https://arxiv.org/abs/2506.22456", "authors": ["Rahul Gulia", "Amlan Ganguly", "Andres Kwasinski", "Michael E. Kuhl", "Ehsan Rashedi", "Clark Hochgraf"], "title": "WISVA: Generative AI for 5G Network Optimization in Smart Warehouses", "categories": ["eess.SP", "eess.IV"], "comment": null, "summary": "The next decade will usher in a profound transformation of wireless\ncommunication, driven by the ever-increasing demand for data-intensive\napplications and the rapid adoption of emerging technologies. To fully unlock\nthe potential of 5G and beyond, substantial advancements are required in signal\nprocessing techniques, innovative network architectures, and efficient spectrum\nutilization strategies. These advancements facilitate seamless integration of\nemerging technologies, driving industrial digital transformation and\nconnectivity. This paper introduces a novel Variational Autoencoder (VAE)-based\nframework, Wireless Infrastructure for Smart Warehouses using VAE (WISVA),\ndesigned for accurate indoor radio propagation modeling in automated Industry\n4.0 environments such as warehouses and factory floors operating within 5G\nwireless bands. The research delves into the meticulous creation of training\ndata tensors, capturing complex electromagnetic (EM) wave behaviors influenced\nby diverse obstacles, and outlines the architecture and training methodology of\nthe proposed VAE model. The model's robustness and adaptability are showcased\nthrough its ability to predict signal-to-interference-plus-noise ratio (SINR)\nheatmaps across various scenarios, including denoising tasks, validation\ndatasets, extrapolation to unseen configurations, and previously unencountered\nwarehouse layouts. Compelling reconstruction error heatmaps are presented,\nhighlighting the superior accuracy of WISVA compared to traditional autoencoder\nmodels. The paper also analyzes the model's performance in handling complex\nsmart warehouse environments, demonstrating its potential as a key enabler for\noptimizing wireless infrastructure in Industry 4.0.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u65b0\u6846\u67b6WISVA\uff0c\u7528\u4e8e5G\u65e0\u7ebf\u9891\u6bb5\u4e0b\u7684\u667a\u80fd\u4ed3\u5e93\u5ba4\u5185\u65e0\u7ebf\u7535\u4f20\u64ad\u5efa\u6a21\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u573a\u666f\u4e0b\u7684\u9ad8\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u968f\u77405G\u53ca\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u6280\u672f\u7684\u53d1\u5c55\uff0c\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u521b\u65b0\u7684\u4fe1\u53f7\u5904\u7406\u6280\u672f\u548c\u7f51\u7edc\u67b6\u6784\u4ee5\u9002\u5e94\u5de5\u4e1a\u6570\u5b57\u5316\u3002\u5ba4\u5185\u65e0\u7ebf\u7535\u4f20\u64ad\u5efa\u6a21\u5bf9\u4e8e\u667a\u80fd\u4ed3\u5e93\u7b49\u573a\u666f\u7684\u65e0\u7ebf\u57fa\u7840\u8bbe\u65bd\u4f18\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faWISVA\u6846\u67b6\uff0c\u5229\u7528VAE\u6a21\u578b\u8fdb\u884c\u5ba4\u5185\u65e0\u7ebf\u7535\u4f20\u64ad\u5efa\u6a21\u3002\u901a\u8fc7\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u5f20\u91cf\u6355\u6349\u590d\u6742\u7535\u78c1\u6ce2\u884c\u4e3a\uff0c\u5e76\u8be6\u7ec6\u63cf\u8ff0\u4e86VAE\u7684\u67b6\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "WISVA\u5728\u591a\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u9884\u6d4bSINR\u70ed\u56fe\u5e76\u5904\u7406\u53bb\u566a\u4efb\u52a1\u3001\u9a8c\u8bc1\u6570\u636e\u96c6\u4ee5\u53ca\u672a\u77e5\u5e03\u5c40\u3002\u4e0e\u4f20\u7edf\u81ea\u7f16\u7801\u5668\u76f8\u6bd4\uff0cWISVA\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "WISVA\u4f5c\u4e3a\u4f18\u5316\u5de5\u4e1a4.0\u65e0\u7ebf\u57fa\u7840\u8bbe\u65bd\u7684\u5173\u952e\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u5176\u5728\u590d\u6742\u667a\u80fd\u4ed3\u5e93\u73af\u5883\u4e2d\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
