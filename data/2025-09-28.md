<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 10]
- [cs.RO](#cs.RO) [Total: 49]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.CV](#cs.CV) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Real-Time Markov Modeling for Single-Photon LiDAR: $1000 \times$ Acceleration and Convergence Analysis](https://arxiv.org/abs/2509.20500)
*Weijian Zhang,Hashan K. Weerasooriya,Prateek Chennuri,Stanley H. Chan*

Main category: eess.SP

TL;DR: 论文提出了一种非时序马尔可夫建模方法，用于解决单光子LiDAR在死区时间存在下时间戳分布建模的计算效率问题，实现了比现有方法高达1000倍的加速，并揭示了第二大特征值的幅值和相位对收敛的关键影响。


<details>
  <summary>Details</summary>
Motivation: 单光子LiDAR在高品质3D应用和导航中的重要性，但现有方法在死区时间存在下建模时间戳分布的计算成本高昂，成为未解决的挑战。

Method: 提出了一种非时序马尔可夫建模方法，通过重新参数化积分边界并分离死区时间的影响，实现高效向量化矩阵构造。

Result: 新模型在计算效率上实现了高达1000倍的加速，并生成了与蒙特卡洛模拟几乎完全一致的稳态分布。

Conclusion: 论文不仅解决了建模效率问题，还通过理论分析揭示了第二大特征值的幅值和相位对收敛的关键影响，填补了文献中的空白。

Abstract: Asynchronous single-photon LiDAR (SP-LiDAR) is an important imaging modality
for high-quality 3D applications and navigation, but the modeling of the
timestamp distributions of a SP-LiDAR in the presence of dead time remains a
very challenging open problem. Prior works have shown that timestamps form a
discrete-time Markov chain, whose stationary distribution can be computed as
the leading left eigenvector of a large transition matrix. However,
constructing this matrix is known to be computationally expensive because of
the coupling between states and the dead time. This paper presents the first
non-sequential Markov modeling for the timestamp distribution. The key
innovation is an equivalent formulation that reparameterizes the integral
bounds and separates the effect of dead time as a deterministic row permutation
of a base matrix. This decoupling enables efficient vectorized matrix
construction, yielding up to $1000 \times$ acceleration over existing methods.
The new model produces a nearly exact stationary distribution when compared
with the gold standard Monte Carlo simulations, yet using a fraction of the
time. In addition, a new theoretical analysis reveals the impact of the
magnitude and phase of the second-largest eigenvalue, which are overlooked in
the literature but are critical to the convergence.

</details>


### [2] [Wireless Powered MEC Systems via Discrete Pinching Antennas: TDMA versus NOMA](https://arxiv.org/abs/2509.20908)
*Peng Liu,Zesong Fei,Meng Hua,Guangji Chen,Xinyi Wang,Ruiqi Liu*

Main category: eess.SP

TL;DR: 摘要提出了一种离散式捏合天线辅助的无线供电移动边缘计算框架，考虑了TDMA和NOMA两种多址接入方式，并通过双层算法优化计算性能。


<details>
  <summary>Details</summary>
Motivation: 整合捏合天线到无线供电移动边缘计算系统，以提升能量传输和任务卸载效率。

Method: 研究离散式捏合天线辅助框架，采用部分卸载模式，提出结合KKT条件和交叉熵学习的双层算法优化问题。

Result: 数值结果表明，该设计在能量收集和计算性能上表现优越，且在精细激活粒度下TDMA优于NOMA。

Conclusion: 离散式捏合天线框架在无线供电移动边缘计算系统中具有实际应用潜力，不同多址接入方式的性能与激活粒度密切相关。

Abstract: Pinching antennas (PAs), a new type of reconfigurable and flexible antenna
structures, have recently attracted significant research interest due to their
ability to create line-of-sight links and mitigate large-scale path loss. Owing
to their potential benefits, integrating PAs into wireless powered mobile edge
computing (MEC) systems is regarded as a viable solution to enhance both energy
transfer and task offloading efficiency. Unlike prior studies that assume ideal
continuous PA placement along waveguides, this paper investigates a practical
discrete PA-assisted wireless powered MEC framework, where devices first
harvest energy from PA-emitted radio-frequency signals and then adopt a partial
offloading mode, allocating part of the harvested energy to local computing and
the remainder to uplink offloading. The uplink phase considers both the
time-division multiple access (TDMA) and non-orthogonal multiple access (NOMA),
each examined under three levels of PA activation flexibility. For each
configuration, we formulate a joint optimization problem to maximize the total
computational bits and conduct a theoretical performance comparison between the
TDMA and NOMA schemes. To address the resulting mixed-integer nonlinear
problems, we develop a two-layer algorithm that combines closed-form solutions
based on Karush-Kuhn-Tucker (KKT) conditions with a cross-entropy-based
learning method. Numerical results validate the superiority of the proposed
design in terms of the harvested energy and computation performance, revealing
that TDMA and NOMA achieve comparable performance under coarser PA activation
levels, whereas finer activation granularity enables TDMA to achieve superior
computation performance over NOMA.

</details>


### [3] [A General Optimization Framework for Movable Antenna Systems via Discrete Sampling](https://arxiv.org/abs/2509.20987)
*Changhao Liu,Weidong Mei,Zhi Chen,Jun Fang,Boyu Ning*

Main category: eess.SP

TL;DR: 该论文提出了一种低复杂度的优化框架，通过离散化天线移动区域并引入吉布斯采样，解决了移动天线系统中位置优化的挑战。


<details>
  <summary>Details</summary>
Motivation: 移动天线（MA）系统因其能够通过局部天线移动重塑无线信道而受到关注，但优化天线位置因高度非线性问题具有挑战性。

Method: 将天线移动区域离散化为采样点，转化为离散点选择问题，并引入吉布斯采样避免局部最优。

Result: 数值结果表明，该算法性能接近最优，并显著优于现有基准方法。

Conclusion: 该框架有效解决了MA系统的优化问题，为实际应用提供了高效解决方案。

Abstract: Movable antenna (MA) systems have attracted growing interest in wireless
communications due to their ability to reshape wireless channels via local
antenna movement within a confined region. However, optimizing antenna
positions to enhance communication performance turns out to be challenging due
to the highly nonlinear relationship between wireless channels and antenna
positions. Existing approaches, such as gradient-based and heuristic
algorithms, often suffer from high computational complexity or undesired local
optima. To address the above challenge, this letter proposes a general and
low-complexity optimization framework for MA position optimization.
Specifically, we discretize the antenna movement region into a set of sampling
points, thereby transforming the continuous optimization problem into a
discrete point selection problem. Next, we sequentially update the optimal
sampling point for each MA over multiple rounds. To avoid convergence to poor
local optima, a Gibbs sampling (GS) phase is introduced between rounds to
explore adjacent and randomly generated candidate solutions. As a case study,
we investigate joint precoding and antenna position optimization for an
MA-enhanced broadcast system by applying the proposed framework. Numerical
results demonstrate that the proposed algorithm achieves near-optimal
performance and significantly outperforms existing benchmarks.

</details>


### [4] [Shapley Features for Robust Signal Prediction in Tactile Internet](https://arxiv.org/abs/2509.21032)
*Mohammad Ali Vahedifar,Qi Zhang*

Main category: eess.SP

TL;DR: 该论文提出了一种结合高斯过程（GP）和残差神经网络（ResNet）的新预测框架，并引入Shapley特征值（SFV）优化性能，显著提升了触觉信号传输的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 触觉互联网对超低延迟和高可靠性的信号传输有严格要求，但数据包丢失和延迟问题尚未解决。

Method: 通过结合高斯过程（GP）和残差神经网络（ResNet）构建预测框架，并利用Shapley特征值（SFV）进行特征选择。

Result: 该方法准确率达到95.72%，比现有方法LeFo提升了11.1%，同时降低了延迟约束；与LeFo或GP结合时，推理时间分别减少27%和72%。

Conclusion: GP+SFV框架为触觉互联网提供了高精度和高效率的解决方案，推动了可靠触觉通信的实用化。

Abstract: The Tactile Internet (TI) requires ultra-low latency and reliable haptic
signal transmission, yet packet loss and delay remain unresolved challenges. We
present a novel prediction framework that integrates Gaussian Processes (GP)
with a ResNet-based Neural Network, where GP acts as an oracle to recover
signals lost or heavily delayed. To further optimize performance, we introduce
Shapley Feature Values (SFV), a principled feature selection mechanism that
isolates the most informative inputs for prediction. This GP+SFV framework
achieves 95.72% accuracy, surpassing the state-of-the-art LeFo method by 11.1%,
while simultaneously relaxing TI's rigid delay constraints. Beyond accuracy,
SFV operates as a modular accelerator: when paired with LeFo, it reduces
inference time by 27%, and when paired with GP, by 72%. These results establish
GP+SFV as both a high-accuracy and high-efficiency solution, paving the way for
practical and reliable haptic communications in TI systems.

</details>


### [5] [Neural Integrated Sensing and Communication for the MIMO-OFDM Downlink](https://arxiv.org/abs/2509.21118)
*Ziyi Wang,Frederik Zumegen,Christoph Studer*

Main category: eess.SP

TL;DR: 论文提出了一种基于神经网络的ISAC信号处理框架，通过MIMO-OFDM下行链路实现感知功能，无需修改通信链路，并在复杂环境中有效生成场景地图。


<details>
  <summary>Details</summary>
Motivation: 无线感知与通信需求的融合推动了ISAC的发展，本文旨在通过数据驱动技术增强现有通信基础设施的感知能力。

Method: 基于MIMO-OFDM下行链路，设计神经网络ISAC框架，利用反射信号生成空间占用的离散地图，并通过专用特征提升复杂环境中的感知性能。

Result: 仿真实验显示，该框架能在不改变通信链路或降低数据速率的情况下，可靠重建场景地图。

Conclusion: 神经ISAC框架为下一代网络中的集成感知与通信提供了高效解决方案。

Abstract: The ongoing convergence of spectrum and hardware requirements for wireless
sensing and communication applications has fueled the integrated sensing and
communication (ISAC) paradigm in next-generation networks. Neural-network-based
ISAC leverages data-driven learning techniques to add sensing capabilities to
existing communication infrastructure. This paper presents a novel
signal-processing framework for such neural ISAC systems based on the
multiple-input multiple-output (MIMO) and orthogonal frequency-division
multiplexing (OFDM) downlink. Our approach enables generalized sensing
functionality without modifying the MIMO-OFDM communication link. Specifically,
our neural ISAC pipeline measures the backscattered communication signals to
generate discrete map representations of spatial occupancy, formulated as
multiclass or multilabel classification problems, which can then be utilized by
specialized downstream tasks. To improve sensing performance in closed or
cluttered environments, our neural ISAC pipeline relies on features
specifically designed to mitigate strong reflective paths. Extensive
simulations using ray-tracing models demonstrate that our neural ISAC framework
reliably reconstructs scene maps without altering the MIMO-OFDM communication
pipeline or reducing data rates.

</details>


### [6] [A Secure ISAC Waveform Design Framework via Random Frequency and PRI Agility](https://arxiv.org/abs/2509.21162)
*Ali Khandan Boroujeni,Hyeon Seok Rou,Ghazal Bagheri,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Kuranage Roche Rayan Ranasinghe,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 提出了一种新型框架，通过随机频率和脉冲重复间隔（PRI）敏捷性（RFPA）方法增强集成感知与通信（ISAC）系统的安全性、数据速率和感知性能。


<details>
  <summary>Details</summary>
Motivation: 提升ISAC系统的安全性、数据速率和感知性能，抵御被动敌手的侦察。

Method: 采用RFPA方法设计波形，结合共享密钥生成随机序列，并通过混合信息嵌入方案（ASK、PSK、IM和SM）提高数据吞吐量。

Result: 通过模糊函数（AF）分析证实了优异的距离-速度分辨率和杂波抑制能力。

Conclusion: 该框架在ISAC系统中表现出高效的性能和安全性。

Abstract: This paper presents a novel framework for enhancing the security, data rate,
and sensing performance of integrated sensing and communications (ISAC)
systems. We employ a random frequency and pulse repetition interval (PRI)
agility (RFPA) method for the waveform design, where the necessary random
sequences are governed by shared secrets. These secrets, which can be
pre-shared or generated via channel reciprocity, obfuscate critical radar
parameters like Doppler frequency and pulse start times, thereby significantly
impeding the ability to perform reconnaissance from a passive adversary without
the secret key. To further introduce enhanced data throughput, we also
introduce a hybrid information embedding scheme that integrates amplitude shift
keying (ASK), phase shift keying (PSK), index modulation (IM), and spatial
modulation (SM), for which a low-complexity sparse-matched filter receiver is
proposed for accurate decoding with practical complexity. Finally, the
excellent range-velocity resolution and clutter suppression of the proposed
waveform are analyzed via the ambiguity function (AF).

</details>


### [7] [Adversarially Robust MIMO Physical Layer Authentication for Non-Stationary Channels](https://arxiv.org/abs/2509.21171)
*Ali Khandan Boroujeni,Ghazal Bagheri,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 提出了一个针对非平稳MIMO无线信道的对抗性鲁棒物理层认证框架（AR-PLA），整合了序列贝叶斯决策、对比学习的深度特征提取和对抗生成模型，显著提升了对动态欺骗策略的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对非平稳MIMO信道中传统方法假设信道平稳或观测独立的问题，提出了一个能够处理时空相关性、视距阻塞和动态欺骗策略的认证框架。

Method: 结合序列贝叶斯决策、对比学习和对抗生成模型，利用2态和3态隐马尔可夫模型（HMM）进行性能分析，并提供在线适应的移动平均方法。

Result: 提出了对数似然比、检测概率和稳态近似的闭式递推公式，证明了该方法比传统序列认证方案具有显著的鲁棒性提升。

Conclusion: AR-PLA框架在动态MIMO环境中表现出卓越的鲁棒性，且计算效率高，适合实际部署。

Abstract: We propose an adversarially robust physical layer authentication (AR-PLA)
framework tailored for non-stationary multiple-input multiple-output (MIMO)
wireless channels. The framework integrates sequential Bayesian
decision-making, deep feature extraction via contrastive learning, and
generative adversarial modeling to simulate adaptive spoofers. Unlike
conventional methods that assume stationary channels or independent
observations, our approach explicitly accounts for temporal and spatial
correlations, line-of-sight (LoS) blockages, and dynamic spoofing strategies. A
comprehensive analytical characterization of the authentication performance
using both 2-state and 3-state hidden Markov models (HMMs) with moving-average
online adaptation is also provided, with closed-form recursions for
loglikelihood ratios, detection probabilities, and steady-state approximations,
which demonstrate significant robustness improvement over classical sequential
authentication schemes.

</details>


### [8] [An enhanced statistical feature fusion approach using an improved distance evaluation algorithm and weighted K-nearest neighbor for bearing fault diagnosis](https://arxiv.org/abs/2509.21219)
*Amir Eshaghi Chaleshtori,Abdollah Aghaie*

Main category: eess.SP

TL;DR: 提出了一种结合改进距离评估算法和加权KNN分类器的方法，用于在噪声环境中准确诊断轴承故障。


<details>
  <summary>Details</summary>
Motivation: 轴承是旋转机械中最易损坏的部件，其状态直接影响整体性能，因此在噪声环境中准确诊断轴承故障至关重要。

Method: 首先提取并整合时域、频域和时频域的振动统计特征，然后用改进的距离评估算法对特征加权并筛选出最具信息量的特征，最后用加权KNN分类器进行分类。

Result: 使用渥太华大学的轴承数据进行验证，结果显示该方法能有效识别轴承故障。

Conclusion: 提出的方法在噪声环境下能够准确诊断轴承故障，具有实际应用价值。

Abstract: Bearings are among the most failure-prone components in rotating machinery,
and their condition directly impacts overall performance. Therefore, accurately
diagnosing bearing faults is essential for ensuring system stability. However,
detecting such malfunctions in noisy environments, where data is collected from
multiple sensors, necessitates the extraction and selection of informative
features. This paper proposes an improved distance evaluation algorithm
combined with a weighted K-nearest neighbor (KNN) classifier for bearing fault
diagnosis. The process begins with extracting and integrating statistical
features of vibration across the time, frequency, and time-frequency domains.
Next, the improved distance evaluation algorithm assigns weights to the
extracted features, retaining only the most informative ones by eliminating
insensitive features. Finally, the selected features are used to train the
weighted KNN classifier. To validate the proposed method, we employ bearing
data from the University of Ottawa. The results demonstrate the effectiveness
of our approach in accurately identifying bearing faults.

</details>


### [9] [Vision-Intelligence-Enabled Beam Tracking for Cross-Interface Water-Air Optical Wireless Communications](https://arxiv.org/abs/2509.21290)
*Tianqi Mao,Jiayue Liu,Weijie Liu,Dezhi Zheng,Zhaocheng Wang*

Main category: eess.SP

TL;DR: 该论文针对水-空光无线通信中因波动海面导致的光束对准问题，建立了一个数学模型，并提出了一种基于AI的视觉光束跟踪算法，结合CNN和Bi-LSTM以及注意力机制，有效提取关键时空特征，显著提升了信号强度和抗噪能力。


<details>
  <summary>Details</summary>
Motivation: 随着海洋应用的快速发展（如水下监测和矿产勘探），实时无线回传大量观测数据的需求日益迫切。窄带声学方法难以满足，而光无线通信（OWC）因其宽带潜力成为有前景的替代方案。但水-空界面的波动导致信号动态折射，引发光束不对准问题，亟需能够适应复杂海洋环境的实时对准方案。

Method: 论文建立了波动海面下水-空光无线传输的数学模型，并提出了一种基于AI的视觉光束跟踪算法。该算法结合CNN和Bi-LSTM，并引入注意力机制，从视觉数据中高效提取关键时空特征，预测动态信道变化。

Result: 数值模拟结果表明，该算法在保持接收信号强度和抑制视觉噪声方面优于传统方法，证明了其对水-空OWC系统恶劣条件的鲁棒性。

Conclusion: 该研究为水-空光无线通信中光束对准问题提供了创新的解决方案，通过AI驱动的动态预测和跟踪，显著提升了系统性能，为未来海洋应用的实时数据传输奠定了基础。

Abstract: The escalating development of oceanic applications like underwater
surveillance and mineral exploration, is motivating real-time wireless backhaul
of the considerable observation data. Such prospects can be hardly realized by
the narrowband acoustic approach. Alternatively, optical wireless communication
(OWC) has emerged as a promising solution for maritime and underwater
applications due to its great potential for broadband underwater transmission.
However, the implementations of water-air OWC can be rather challenging,
especially when penetrating the fluctuating interface, where the direction of
refracted signals changes dynamically, causing severe beam misalignment with
airborne stations. This has necessitated real-time transceiver alignment
adaptable to the sophisticated oceanic environment, which has yet to be
addressed. Against this background, this paper establishes a mathematical
channel model for water-air optical wireless transmission across the
fluctuating sea surface. Based on the model, we propose a vision-based beam
tracking algorithm that leverages artificial intelligence (AI) methods for
dynamic channel prediction. The proposed algorithm integrates a convolutional
neural network (CNN) with bi-directional long short-term memory (Bi-LSTM),
which further incorporates the attention mechanism to effectively extract
critical spatio-temporal features from the vision data. The numerical
simulation results show that the proposed algorithm can outperform its
classical counterparts in maintaining receiving signal strength and supressing
the vision noises, which demonstrates its robustness against the the harsh
conditions of water-air OWC systems.

</details>


### [10] [Efficient Digital Methods to Quantify Sensor Output Uncertainty](https://arxiv.org/abs/2509.21311)
*Orestis Kaparounakis,Phillip Stanley-Marbell*

Main category: eess.SP

TL;DR: 该论文研究了传感器输出不确定性的表征及其对测量精度的影响，特别关注校准参数量化导致的不确定性传播。通过实验展示了校准相关量的认知不确定性对传感器输出的显著影响，并提出了一种在嵌入式传感器系统中实际应用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，准确表征传感器输出不确定性对数据可靠性至关重要。本文旨在探讨由于传感器组件精度限制导致的测量不确定性对整体传感器测量精度的影响。

Method: 作者以热电堆传感器为例，分析了校准和转换方程在传播校准参数量化不确定性中的作用。同时，通过实验在两种商业化硬件平台上验证了方法的可行性和效率。

Result: 实验结果表明，校准相关量的认知不确定性可能导致高达5.3°C的绝对误差和25.7%的相对误差。提出的方法在边缘检测中显著降低了误报，并在嵌入式系统中实现了显著的功耗和速度优化。

Conclusion: 该研究为实时应用中传感器不确定性的跟踪和处理提供了实用且高效的解决方案，展示了在嵌入式系统中实际部署的可行性。

Abstract: Accurate characterization of sensor output uncertainty is important for
reliable data interpretation in many applications. Here, we investigate the
impact of transducer-level measurement uncertainty on overall sensor
measurement accuracy due to limited-precision information about sensor
components. We explain our method using thermopile-based sensors as an example
class of sensors. We show how sensor calibration and conversion equations,
which are an essential part of all sensing systems, propagate uncertainties
resulting from the quantization of calibration parameters, to the final,
compensated sensor output. The experimental results show that the epistemic
uncertainty of calibration-related quantities leads to absolute error in the
sensor output as high as 5.3 {\deg}C (and relative error as high as 25.7%) for
one commonly-used thermopile sensor. In one instance of using the epistemic
uncertainty information in edge detection, we show reduction of false-positives
edges to zero for the conventional Canny operator, while maintaining accuracy.
We show these ideas are practical and possible on actual embedded sensor
systems by prototyping them on two commercially-available uncertainty tracking
hardware platforms, one with average power dissipation 16.7 mW and 42.9x
speedup compared to the equal-confidence Monte Carlo computation (the status
quo), and the other with average power dissipation 147.15 mW and 94.4x speedup,
paving the way for use in real time.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [11] [Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation](https://arxiv.org/abs/2509.20486)
*Sven Ochs,Philip Schörner,Marc René Zofka,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 本文提出了一种将语义相机数据与LiDAR分割相结合的方法，以提高LiDAR定位的精度和鲁棒性。通过验证，该方法在复杂环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多样化的传感器类型和配置给LiDAR数据的语义分割带来了挑战，但融入语义信息可以显著提升LiDAR定位的准确性和鲁棒性。

Method: 提出了一种将LiDAR点投影到相机语义分割空间的方法，并利用CoCar NextGen平台进行验证，结合Depth-Anything网络和自适应分割网络。

Result: 在55公里的复杂环境中测试，该方法显著提升了LiDAR定位的可靠性和精度。

Conclusion: 多模态方法为复杂现实环境中的自主导航系统提供了更可靠和精确的解决方案。

Abstract: Semantic segmentation of LiDAR data presents considerable challenges,
particularly when dealing with diverse sensor types and configurations.
However, incorporating semantic information can significantly enhance the
accuracy and robustness of LiDAR-based localization techniques for autonomous
mobile systems. We propose an approach that integrates semantic camera data
with LiDAR segmentation to address this challenge. By projecting LiDAR points
into the semantic segmentation space of the camera, our method enhances the
precision and reliability of the LiDAR-based localization pipeline.
  For validation, we utilize the CoCar NextGen platform from the FZI Research
Center for Information Technology, which offers diverse sensor modalities and
configurations. The sensor setup of CoCar NextGen enables a thorough analysis
of different sensor types. Our evaluation leverages the state-of-the-art
Depth-Anything network for camera image segmentation and an adaptive
segmentation network for LiDAR segmentation. To establish a reliable ground
truth for LiDAR-based localization, we make us of a Global Navigation Satellite
System (GNSS) solution with Real-Time Kinematic corrections (RTK).
Additionally, we conduct an extensive 55 km drive through the city of
Karlsruhe, Germany, covering a variety of environments, including urban areas,
multi-lane roads, and rural highways. This multimodal approach paves the way
for more reliable and precise autonomous navigation systems, particularly in
complex real-world environments.

</details>


### [12] [Revisiting Formal Methods for Autonomous Robots: A Structured Survey](https://arxiv.org/abs/2509.20488)
*Atef Azaiez,David A. Anisi,Marie Farrell,Matt Luckcuck*

Main category: cs.RO

TL;DR: 本文通过结构化文献综述方法，研究了形式化方法（FM）在机器人自主系统（RAS）中的应用，重点分析了FM的分类、形式主义及其随时间发展的趋势，并补充了现有研究的不足。


<details>
  <summary>Details</summary>
Motivation: 研究形式化方法在机器人自主系统中的应用现状及其随时间的发展趋势，填补现有文献综述的不足，识别新的研究方向和技术趋势。

Method: 采用结构化文献综述方法，包括数据库选择、搜索字符串设计、筛选过滤和协作评审，对形式化方法在RAS中的应用进行了分类和统计。

Result: 研究发现了一些与先前调查一致的长期趋势，同时也识别了新的趋势，如形式化合成方法和概率验证技术的采用显著增加。

Conclusion: 研究表明形式化方法在机器人自主系统中的应用领域不断扩展和成熟，新的技术和方法正在被引入，为该领域的未来研究提供了方向。

Abstract: This paper presents the initial results from our structured literature review
on applications of Formal Methods (FM) to Robotic Autonomous Systems (RAS). We
describe our structured survey methodology; including database selection and
associated search strings, search filters and collaborative review of
identified papers. We categorise and enumerate the FM approaches and formalisms
that have been used for specification and verification of RAS. We investigate
FM in the context of sub-symbolic AI-enabled RAS and examine the evolution of
how FM is used over time in this field. This work complements a pre-existing
survey in this area and we examine how this research area has matured over
time. Specifically, our survey demonstrates that some trends have persisted as
observed in a previous survey. Additionally, it recognized new trends that were
not considered previously including a noticeable increase in adopting Formal
Synthesis approaches as well as Probabilistic Verification Techniques.

</details>


### [13] [Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting](https://arxiv.org/abs/2509.20499)
*Boqi Li,Siyuan Li,Weiyi Wang,Anran Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: 本文提出了一种零样本框架，结合简化的路径预测器和多模态大语言模型（MLLM），在连续环境中实现视觉语言导航（VLN），实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型和机器人技术的快速发展，视觉语言导航（VLN）成为具身智能体的关键任务。本文旨在解决连续环境中的VLN问题，其中智能体需同时理解自然语言指令、感知环境并规划低级动作。

Method: 提出一种零样本框架，包含一个基于抽象障碍地图的路径预测器，生成线性可达的路标点，并动态更新拓扑图和访问记录。通过将图和访问信息编码到提示中，结合MLLM进行推理，支持错误校正。

Result: 在R2R-CE和RxR-CE数据集上的实验显示，该方法分别达到41%和36%的成功率，优于现有零样本方法。

Conclusion: 本文方法通过结合路径预测器和MLLM，在连续环境中实现了高效的视觉语言导航，为零样本VLN任务提供了新思路。

Abstract: With the rapid progress of foundation models and robotics, vision-language
navigation (VLN) has emerged as a key task for embodied agents with broad
practical applications. We address VLN in continuous environments, a
particularly challenging setting where an agent must jointly interpret natural
language instructions, perceive its surroundings, and plan low-level actions.
We propose a zero-shot framework that integrates a simplified yet effective
waypoint predictor with a multimodal large language model (MLLM). The predictor
operates on an abstract obstacle map, producing linearly reachable waypoints,
which are incorporated into a dynamically updated topological graph with
explicit visitation records. The graph and visitation information are encoded
into the prompt, enabling reasoning over both spatial structure and exploration
history to encourage exploration and equip MLLM with local path planning for
error correction. Extensive experiments on R2R-CE and RxR-CE show that our
method achieves state-of-the-art zero-shot performance, with success rates of
41% and 36%, respectively, outperforming prior state-of-the-art methods.

</details>


### [14] [MELEGROS: Monolithic Elephant-inspired Gripper with Optical Sensors](https://arxiv.org/abs/2509.20510)
*Petr Trunin,Diana Cafiso,Anderson Brazil Nardin,Trevor Exley,Lucia Beccai*

Main category: cs.RO

TL;DR: MELEGROS是一种受大象鼻子启发的单片式软体抓取器，通过光学传感器实现多功能感知，具备连续结构和完全嵌入式感知能力。


<details>
  <summary>Details</summary>
Motivation: 受非洲大象鼻子结构与功能的启发，研究旨在开发一种集成传感、驱动和结构的软体抓取器，减少机械不匹配和模型不确定性。

Method: 采用单种软树脂和一次连续3D打印，将六个光学波导传感器和五个气动腔集成到气动驱动的晶格结构中，实现传感与结构的无缝集成。

Result: MELEGROS重量132克，可举起超过自身两倍的重量，完成多种仿生动作（如捏取、舀取和伸展），并能轻柔抓取易碎物品；光学传感器能够区分触摸、弯曲和气动腔变形信号。

Conclusion: MELEGROS展示了软体机器人领域的新范式，通过完全嵌入式传感和连续结构支持多功能仿生操作。

Abstract: The elephant trunk exemplifies a natural gripper where structure, actuation,
and sensing are seamlessly integrated. Inspired by the distal morphology of the
African elephant trunk, we present MELEGROS, a Monolithic ELEphant-inspired
GRipper with Optical Sensors, emphasizing sensing as an intrinsic,
co-fabricated capability. Unlike multi-material or tendon-based approaches,
MELEGROS directly integrates six optical waveguide sensors and five pneumatic
chambers into a pneumatically actuated lattice structure (12.5 mm cell size)
using a single soft resin and one continuous 3D print. This eliminates
mechanical mismatches between sensors, actuators, and body, reducing model
uncertainty and enabling simulation-guided sensor design and placement. Only
four iterations were required to achieve the final prototype, which features a
continuous structure capable of elongation, compression, and bending while
decoupling tactile and proprioceptive signals. MELEGROS (132 g) lifts more than
twice its weight, performs bioinspired actions such as pinching, scooping, and
reaching, and delicately grasps fragile items like grapes. The integrated
optical sensors provide distinct responses to touch, bending, and chamber
deformation, enabling multifunctional perception. MELEGROS demonstrates a new
paradigm for soft robotics where fully embedded sensing and continuous
structures inherently support versatile, bioinspired manipulation.

</details>


### [15] [Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation](https://arxiv.org/abs/2509.20516)
*Prasanna Sriganesh,Barath Satheeshkumar,Anushree Sabnis,Matthew Travers*

Main category: cs.RO

TL;DR: 本文提出了一种用于四足机器人在密集杂乱环境中安全推动物体的感知-行动框架，通过交互感知状态估计解决物体被遮挡时的跟踪问题，并展示了在波士顿动力Spot机器人上的成功应用。


<details>
  <summary>Details</summary>
Motivation: 在密集杂乱环境中，机器人需与障碍物互动以清理路径，但物理动作（如单腿推）可能引发难以预测的约束。本文旨在解决物体在推过程中因遮挡而无法被传感器感知的问题。

Method: 提出了一种紧密耦合的感知-行动框架，利用本体感知反馈（如脚部接触和腿部位置）预测被推物体的位移，并在物体重新出现后重新检测以闭环跟踪。

Result: 在波士顿动力Spot机器人上的实验表明，该方法在楼梯推物任务中比开环基线方法具有更高的成功率和跟踪精度。

Conclusion: 通过交互感知状态估计和闭环反馈，本文方法显著提高了机器人在复杂环境中推物任务的性能，证明了物理交互中感知与行动紧密耦合的重要性。

Abstract: For robots to operate autonomously in densely cluttered environments, they
must reason about and potentially physically interact with obstacles to clear a
path. Safely clearing a path on challenging terrain, such as a cluttered
staircase, requires controlled interaction. For example, a quadrupedal robot
that pushes objects out of the way with one leg while maintaining a stable
stance with its three other legs. However, tightly coupled physical actions,
such as one-legged pushing, create new constraints on the system that can be
difficult to predict at design time. In this work, we present a new method that
addresses one such constraint, wherein the object being pushed by a quadrupedal
robot with one of its legs becomes occluded from the robot's sensors during
manipulation. To address this challenge, we present a tightly coupled
perception-action framework that enables the robot to perceive clutter, reason
about feasible push paths, and execute the clearing maneuver. Our core
contribution is an interaction-aware state estimation loop that uses
proprioceptive feedback regarding foot contact and leg position to predict an
object's displacement during the occlusion. This prediction guides the
perception system to robustly re-detect the object after the interaction,
closing the loop between action and sensing to enable accurate tracking even
after partial pushes. Using this feedback allows the robot to learn from
physical outcomes, reclassifying an object as immovable if a push fails due to
it being too heavy. We present results of implementing our approach on a Boston
Dynamics Spot robot that show our interaction-aware approach achieves higher
task success rates and tracking accuracy in pushing objects on stairs compared
to open-loop baselines.

</details>


### [16] [Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning](https://arxiv.org/abs/2509.20541)
*Anujith Muraleedharan,Anamika J H*

Main category: cs.RO

TL;DR: SPARQ是一种基于学习进度的查询策略，通过仅在学习停滞或退步时请求反馈，减少不必要的反馈调用，显著提高了人机交互强化学习的效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的人类反馈成本高昂且有限，现有HiL-RL方法假设反馈充足，限制了在物理机器人部署中的实用性。

Method: 引入SPARQ策略，仅在学习停滞或退步时请求反馈；在模拟UR5立方体拾取任务中与三种基线方法（无反馈、随机查询、始终查询）进行比较。

Result: SPARQ在任务成功率上接近始终查询的性能，同时仅消耗约一半的反馈预算；相比随机查询和无反馈，学习更稳定高效。

Conclusion: 选择性、基于进度的查询策略可以提升HiL-RL在现实人类努力约束下的效率和可扩展性。

Abstract: Human feedback can greatly accelerate robot learning, but in real-world
settings, such feedback is costly and limited. Existing human-in-the-loop
reinforcement learning (HiL-RL) methods often assume abundant feedback,
limiting their practicality for physical robot deployment. In this work, we
introduce SPARQ, a progress-aware query policy that requests feedback only when
learning stagnates or worsens, thereby reducing unnecessary oracle calls. We
evaluate SPARQ on a simulated UR5 cube-picking task in PyBullet, comparing
against three baselines: no feedback, random querying, and always querying. Our
experiments show that SPARQ achieves near-perfect task success, matching the
performance of always querying while consuming about half the feedback budget.
It also provides more stable and efficient learning than random querying, and
significantly improves over training without feedback. These findings suggest
that selective, progress-based query strategies can make HiL-RL more efficient
and scalable for robots operating under realistic human effort constraints.

</details>


### [17] [GraspFactory: A Large Object-Centric Grasping Dataset](https://arxiv.org/abs/2509.20550)
*Srinidhi Kalgundi Srinivas,Yash Shukla,Adam Arnold,Sachin Chitta*

Main category: cs.RO

TL;DR: 论文介绍了GraspFactory数据集，包含超过1.09亿个6自由度抓取数据，用于训练通用机器人抓取模型。


<details>
  <summary>Details</summary>
Motivation: 解决机器人抓取模型在有限数据集训练后难以适应新物体的问题。

Method: 创建大规模、几何多样化的数据集GraspFactory，并训练数据密集型模型。

Result: 在仿真和实际环境中验证模型的泛化能力。

Conclusion: GraspFactory数据集和工具公开提供，促进机器人抓取研究。

Abstract: Robotic grasping is a crucial task in industrial automation, where robots are
increasingly expected to handle a wide range of objects. However, a significant
challenge arises when robot grasping models trained on limited datasets
encounter novel objects. In real-world environments such as warehouses or
manufacturing plants, the diversity of objects can be vast, and grasping models
need to generalize to this diversity. Training large, generalizable
robot-grasping models requires geometrically diverse datasets. In this paper,
we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps
collectively for the Franka Panda (with 14,690 objects) and Robotiq 2F-85
grippers (with 33,710 objects). GraspFactory is designed for training
data-intensive models, and we demonstrate the generalization capabilities of
one such model trained on a subset of GraspFactory in both simulated and
real-world settings. The dataset and tools are made available for download at
https://graspfactory.github.io/.

</details>


### [18] [Uncertainty-Aware Active Source Tracking of Marine Pollution using Unmanned Surface Vehicles](https://arxiv.org/abs/2509.20593)
*Song Ma,Richard Bucknall,Yuanchang Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于无人水面艇（USV）的不确定性感知海洋污染源追踪框架，通过结合高保真污染扩散模拟和信息路径规划技术，实现了对海洋污染源的有效定位。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种全自主的环境监测能力，以应对海洋污染事件的快速响应。

Method: 基于ROS实现，整合高保真污染扩散模拟和信息路径规划技术，实时处理传感器数据以更新污染源位置的概率估计。

Result: 在模拟环境中进行的实验表明，该方法能够高效且准确地定位污染源，并提供预测的不确定性量化。

Conclusion: 该方法为海洋污染源的快速定位提供了一种可靠且高效的解决方案，推动了全自主环境监测技术的发展。

Abstract: This paper proposes an uncertainty-aware marine pollution source tracking
framework for unmanned surface vehicles (USVs). By integrating high-fidelity
marine pollution dispersion simulation with informative path planning
techniques, we demonstrate effective identification of pollution sources in
marine environments. The proposed approach is implemented based on Robot
Operating System (ROS), processing real-time sensor data to update
probabilistic source location estimates. The system progressively refines the
estimation of source location while quantifying uncertainty levels in its
predictions. Experiments conducted in simulated environments with varying
source locations, flow conditions, and starting positions demonstrate the
framework's ability to localise pollution sources with high accuracy. Results
show that the proposed approach achieves reliable source localisation
efficiently. This work contributes to the development of full autonomous
environmental monitoring capabilities essential for rapid response to marine
pollution incidents.

</details>


### [19] [Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation](https://arxiv.org/abs/2509.20623)
*Satyajeet Das,Darren Chiu,Zhehui Huang,Lars Lindemann,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 本文提出了一种名为LAE的框架，通过在不修改预训练策略的情况下编辑潜在激活来提升多四旋翼无人机导航的安全性，显著减少了碰撞。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在复杂任务中取得进展，但预训练策略在障碍物密集环境中仍容易发生碰撞。直接重新训练或微调成本高且可能影响已有技能。受大语言模型激活导向和计算机视觉潜在编辑启发，本文旨在通过推理时间潜在激活编辑提升安全性。

Method: LAE框架分为两部分：在线分类器监测激活状态以检测危险，编辑模块选择性修改危险状态的激活以促进行为安全。研究中通过潜在碰撞世界模型预测未来碰撞前的激活，引导更早规避。

Result: 模拟和真实实验表明，LAE显著减少了近90%的碰撞，提高了无碰撞轨迹比例，同时任务完成率不受影响。

Conclusion: LAE是一种轻量级方法，可在资源受限硬件上优化已部署机器人策略，提升安全性。

Abstract: Reinforcement learning has enabled significant progress in complex domains
such as coordinating and navigating multiple quadrotors. However, even
well-trained policies remain vulnerable to collisions in obstacle-rich
environments. Addressing these infrequent but critical safety failures through
retraining or fine-tuning is costly and risks degrading previously learned
skills. Inspired by activation steering in large language models and latent
editing in computer vision, we introduce a framework for inference-time Latent
Activation Editing (LAE) that refines the behavior of pre-trained policies
without modifying their weights or architecture. The framework operates in two
stages: (i) an online classifier monitors intermediate activations to detect
states associated with undesired behaviors, and (ii) an activation editing
module that selectively modifies flagged activations to shift the policy
towards safer regimes. In this work, we focus on improving safety in
multi-quadrotor navigation. We hypothesize that amplifying a policy's internal
perception of risk can induce safer behaviors. We instantiate this idea through
a latent collision world model trained to predict future pre-collision
activations, thereby prompting earlier and more cautious avoidance responses.
Extensive simulations and real-world Crazyflie experiments demonstrate that LAE
achieves statistically significant reduction in collisions (nearly 90% fewer
cumulative collisions compared to the unedited baseline) and substantially
increases the fraction of collision-free trajectories, while preserving task
completion. More broadly, our results establish LAE as a lightweight paradigm,
feasible on resource-constrained hardware, for post-deployment refinement of
learned robot policies.

</details>


### [20] [Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments](https://arxiv.org/abs/2509.20635)
*Matheus P. Angarola,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种层次化强化学习框架，通过地形专精策略和课程学习提升在复杂环境中的运动性能。


<details>
  <summary>Details</summary>
Motivation: 增强四足机器人在未知地形下的鲁棒性和敏捷性。

Method: 采用层次化强化学习框架，结合地形专精策略和课程学习。

Result: 仿真实验表明，该方法比通用策略成功率提高16%，并在复杂地形中表现更优。

Conclusion: 层次化强化学习能显著提升机器人在混合地形中的适应性和鲁棒性。

Abstract: Legged robots must exhibit robust and agile locomotion across diverse,
unstructured terrains, a challenge exacerbated under blind locomotion settings
where terrain information is unavailable. This work introduces a hierarchical
reinforcement learning framework that leverages terrain-specialized policies
and curriculum learning to enhance agility and tracking performance in complex
environments. We validated our method on simulation, where our approach
outperforms a generalist policy by up to 16% in success rate and achieves lower
tracking errors as the velocity target increases, particularly on low-friction
and discontinuous terrains, demonstrating superior adaptability and robustness
across mixed-terrain scenarios.

</details>


### [21] [Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation](https://arxiv.org/abs/2509.20646)
*Sun Zhaole,Xiaofeng Mao,Jihong Zhu,Yuanlong Zhang,Robert B. Fisher*

Main category: cs.RO

TL;DR: 示文提出了一种新的手势设计SLeap Hand，通过吸盘替代传统力闭合技术，基本上简化了操作和数据收集，并开启了人手无法实现的新技能。


<details>
  <summary>Details</summary>
Motivation: 传统的人手仿真方式导致操作不稳定和数据收集困难，所以需要新的设计来突破这些限制。

Method: 提出SLeap Hand，采用挂结吸盘替代力闭合技术，减少了复杂性并提高稳定性。

Result: 新设计简化了操作和数据收集，同时开启了人手无法实现的新技能。

Conclusion: 超越人手仿真的设计既降低了数据收集门槛，又扩展了操作的可能性。

Abstract: Dexterous in-hand manipulation remains a foundational challenge in robotics,
with progress often constrained by the prevailing paradigm of imitating the
human hand. This anthropomorphic approach creates two critical barriers: 1) it
limits robotic capabilities to tasks humans can already perform, and 2) it
makes data collection for learning-based methods exceedingly difficult. Both
challenges are caused by traditional force-closure which requires coordinating
complex, multi-point contacts based on friction, normal force, and gravity to
grasp an object. This makes teleoperated demonstrations unstable and amplifies
the sim-to-real gap for reinforcement learning. In this work, we propose a
paradigm shift: moving away from replicating human mechanics toward the design
of novel robotic embodiments. We introduce the \textbf{S}uction
\textbf{Leap}-Hand (SLeap Hand), a multi-fingered hand featuring integrated
fingertip suction cups that realize a new form of suction-enabled dexterity. By
replacing complex force-closure grasps with stable, single-point adhesion, our
design fundamentally simplifies in-hand teleoperation and facilitates the
collection of high-quality demonstration data. More importantly, this
suction-based embodiment unlocks a new class of dexterous skills that are
difficult or even impossible for the human hand, such as one-handed paper
cutting and in-hand writing. Our work demonstrates that by moving beyond
anthropomorphic constraints, novel embodiments can not only lower the barrier
for collecting robust manipulation data but also enable the stable,
single-handed completion of tasks that would typically require two human hands.
Our webpage is https://sites.google.com/view/sleaphand.

</details>


### [22] [Cyber Racing Coach: A Haptic Shared Control Framework for Teaching Advanced Driving Skills](https://arxiv.org/abs/2509.20653)
*Congkai Shen,Siyuan Yu,Yifan Weng,Haoran Ma,Chen Li,Hiroshi Yasuda,James Dallas,Michael Thompson,John Subosits,Tulga Ersal*

Main category: cs.RO

TL;DR: 研究提出了一种基于触觉共享控制的框架，用于教授人类驾驶员高级驾驶技能，并通过实验验证其效果优于无辅助和全辅助训练。


<details>
  <summary>Details</summary>
Motivation: 填补现有共享控制方案在复杂高要求任务技能获取方面评估的不足，探索触觉共享控制在高级驾驶技能培训中的应用。

Method: 开发了一种基于触觉共享控制的赛车教练框架，包括自主驾驶系统合作机制和逐渐减少辅助的褪色方案。

Result: 实验显示，该框架帮助驾驶员在高性能赛车技能上表现更优，性能和一致性均优于基准。

Conclusion: 触觉共享控制框架能有效提升人类驾驶员在复杂任务中的技能获取和表现。

Abstract: This study introduces a haptic shared control framework designed to teach
human drivers advanced driving skills. In this context, shared control refers
to a driving mode where the human driver collaborates with an autonomous
driving system to control the steering of a vehicle simultaneously. Advanced
driving skills are those necessary to safely push the vehicle to its handling
limits in high-performance driving such as racing and emergency obstacle
avoidance. Previous research has demonstrated the performance and safety
benefits of shared control schemes using both subjective and objective
evaluations. However, these schemes have not been assessed for their impact on
skill acquisition on complex and demanding tasks. Prior research on long-term
skill acquisition either applies haptic shared control to simple tasks or
employs other feedback methods like visual and auditory aids. To bridge this
gap, this study creates a cyber racing coach framework based on the haptic
shared control paradigm and evaluates its performance in helping human drivers
acquire high-performance driving skills. The framework introduces (1) an
autonomous driving system that is capable of cooperating with humans in a
highly performant driving scenario; and (2) a haptic shared control mechanism
along with a fading scheme to gradually reduce the steering assistance from
autonomy based on the human driver's performance during training. Two
benchmarks are considered: self-learning (no assistance) and full assistance
during training. Results from a human subject study indicate that the proposed
framework helps human drivers develop superior racing skills compared to the
benchmarks, resulting in better performance and consistency.

</details>


### [23] [EEG-Driven AR-Robot System for Zero-Touch Grasping Manipulation](https://arxiv.org/abs/2509.20656)
*Junzhe Wang,Jiarui Xie,Pengfei Hao,Zheng Li,Yi Cai*

Main category: cs.RO

TL;DR: 论文提出了一种闭环BCI-AR-机器人系统，结合EEG解码、AR神经反馈和机器人抓取，解决了现有BCI-机器人系统的噪声、不灵活和缺乏闭环验证问题。实验结果显示该系统在控制稳定性和抓取成功率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有BCI-机器人系统因EEG信号噪声大、目标选择不灵活及缺乏闭环验证而难以在现实辅助场景中部署的问题。

Method: 采用14通道EEG耳机进行个性化运动想象(MI)校准，智能手机AR界面支持多目标导航并提供方向一致的反馈，结合机器人视觉姿态估计实现自主抓取。

Result: MI训练准确率达93.1%，平均信息传输率(ITR)为14.8比特/分钟；AR神经反馈显著提升控制稳定性(SCI=0.210)，最高ITR达21.3比特/分钟；闭环抓取成功率为97.2%。

Conclusion: AR反馈显著增强EEG控制的稳定性，所提系统为辅助机器人和人机交互提供了新方向。

Abstract: Reliable brain-computer interface (BCI) control of robots provides an
intuitive and accessible means of human-robot interaction, particularly
valuable for individuals with motor impairments. However, existing BCI-Robot
systems face major limitations: electroencephalography (EEG) signals are noisy
and unstable, target selection is often predefined and inflexible, and most
studies remain restricted to simulation without closed-loop validation. These
issues hinder real-world deployment in assistive scenarios. To address them, we
propose a closed-loop BCI-AR-Robot system that integrates motor imagery
(MI)-based EEG decoding, augmented reality (AR) neurofeedback, and robotic
grasping for zero-touch operation. A 14-channel EEG headset enabled
individualized MI calibration, a smartphone-based AR interface supported
multi-target navigation with direction-congruent feedback to enhance stability,
and the robotic arm combined decision outputs with vision-based pose estimation
for autonomous grasping. Experiments are conducted to validate the framework:
MI training achieved 93.1 percent accuracy with an average information transfer
rate (ITR) of 14.8 bit/min; AR neurofeedback significantly improved sustained
control (SCI = 0.210) and achieved the highest ITR (21.3 bit/min) compared with
static, sham, and no-AR baselines; and closed-loop grasping achieved a 97.2
percent success rate with good efficiency and strong user-reported control.
These results show that AR feedback substantially stabilizes EEG-based control
and that the proposed framework enables robust zero-touch grasping, advancing
assistive robotic applications and future modes of human-robot interaction.

</details>


### [24] [Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks](https://arxiv.org/abs/2509.20674)
*Zeyu Han,Shuocheng Yang,Minghan Zhu,Fang Zhang,Shaobing Xu,Maani Ghaffari,Jianqiang Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种名为Equi-RO的4D毫米波雷达里程计框架，基于等变网络，通过预处理多普勒速度和图结构提升了稀疏雷达数据的特征聚合和帧间对应，相比现有方法在精度和鲁棒性上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在GPS信号缺失的极端天气环境中，LiDAR和相机性能受限，而4D毫米波雷达具有全天候工作和速度测量的优势，因此需要一种更鲁棒的里程计估计方法。

Method: 提出Equi-RO框架，将多普勒速度预处理为图中的不变节点和边特征，并利用独立的网络处理等变和不变特征，通过图结构增强稀疏雷达数据的特征聚合。

Result: 在公开数据集和自采数据集的实验中，Equi-RO在平移和旋转精度上分别比最优基线方法提升了10.7%和20.0%。

Conclusion: Equi-RO在4D毫米波雷达里程计任务中表现出更高的准确性和鲁棒性，为GPS缺失环境下的导航提供了可靠的解决方案。

Abstract: Autonomous vehicles and robots rely on accurate odometry estimation in
GPS-denied environments. While LiDARs and cameras struggle under extreme
weather, 4D mmWave radar emerges as a robust alternative with all-weather
operability and velocity measurement. In this paper, we introduce Equi-RO, an
equivariant network-based framework for 4D radar odometry. Our algorithm
pre-processes Doppler velocity into invariant node and edge features in the
graph, and employs separate networks for equivariant and invariant feature
processing. A graph-based architecture enhances feature aggregation in sparse
radar data, improving inter-frame correspondence. Experiments on the
open-source dataset and self-collected dataset show Equi-RO outperforms
state-of-the-art algorithms in accuracy and robustness. Overall, our method
achieves 10.7% and 20.0% relative improvements in translation and rotation
accuracy, respectively, compared to the best baseline on the open-source
dataset.

</details>


### [25] [Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation](https://arxiv.org/abs/2509.20681)
*Wei-Teng Chu,Tianyi Zhang,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 本文提出了一种名为FINS的轻量级框架，用于从单张或少量的RGB图像快速重建高保真表面和SDF场，显著提高了训练速度和精度。


<details>
  <summary>Details</summary>
Motivation: 提升隐式距离表示从单张图像的构建效率，减少对多视角图像和高训练时间的依赖。

Method: FINS整合了多分辨率哈希网格编码器和轻量级几何与颜色头，采用近似二阶优化器进行高效训练，并利用预训练基础模型估计图像几何信息。

Result: 实验表明，FINS在收敛速度和表面重建/SDF场估计精度上均优于现有基线，且适用于机器人表面跟随任务。

Conclusion: FINS是一种高效、精确的单图像神经表面重建方法，具有广泛的应用前景。

Abstract: Implicit representations have been widely applied in robotics for obstacle
avoidance and path planning. In this paper, we explore the problem of
constructing an implicit distance representation from a single image. Past
methods for implicit surface reconstruction, such as \emph{NeuS} and its
variants generally require a large set of multi-view images as input, and
require long training times. In this work, we propose Fast Image-to-Neural
Surface (FINS), a lightweight framework that can reconstruct high-fidelity
surfaces and SDF fields based on a single or a small set of images. FINS
integrates a multi-resolution hash grid encoder with lightweight geometry and
color heads, making the training via an approximate second-order optimizer
highly efficient and capable of converging within a few seconds. Additionally,
we achieve the construction of a neural surface requiring only a single RGB
image, by leveraging pre-trained foundation models to estimate the geometry
inherent in the image. Our experiments demonstrate that under the same
conditions, our method outperforms state-of-the-art baselines in both
convergence speed and accuracy on surface reconstruction and SDF field
estimation. Moreover, we demonstrate the applicability of FINS for robot
surface following tasks and show its scalability to a variety of benchmark
datasets.

</details>


### [26] [RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks](https://arxiv.org/abs/2509.20688)
*Shouren Mao,Minghao Qin,Wei Dong,Huajian Liu,Yongzhuo Gao*

Main category: cs.RO

TL;DR: 提出RAM-NAS，一种资源感知的多目标神经架构搜索方法，专注于优化超网络预训练和机器人硬件资源利用，通过子网互蒸馏和DKD损失提升性能，并利用延迟代理预测器加速搜索，显著降低边缘硬件推理延迟。


<details>
  <summary>Details</summary>
Motivation: 解决传统NAS方法在超网络训练和硬件资源利用上的不足，特别是机器人硬件资源。

Method: 引入子网互蒸馏和DKD损失优化性能，使用延迟代理预测器加速多目标进化搜索。

Result: RAM-NAS模型在ImageNet上准确率76.7%-81.4%，显著降低边缘硬件推理延迟。

Conclusion: RAM-NAS填补了NAS在机器人硬件资源感知上的空白，并在下游任务中验证了其可扩展性。

Abstract: Neural architecture search (NAS) has shown great promise in automatically
designing lightweight models. However, conventional approaches are insufficient
in training the supernet and pay little attention to actual robot hardware
resources. To meet such challenges, we propose RAM-NAS, a resource-aware
multi-objective NAS method that focuses on improving the supernet pretrain and
resource-awareness on robot hardware devices. We introduce the concept of
subnets mutual distillation, which refers to mutually distilling all subnets
sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge
Distillation (DKD) loss to enhance logits distillation performance. To expedite
the search process with consideration for hardware resources, we used data from
three types of robotic edge hardware to train Latency Surrogate predictors.
These predictors facilitated the estimation of hardware inference latency
during the search phase, enabling a unified multi-objective evolutionary search
to balance model accuracy and latency trade-offs. Our discovered model family,
RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on
ImageNet. In addition, the resource-aware multi-objective NAS we employ
significantly reduces the model's inference latency on edge hardware for
robots. We conducted experiments on downstream tasks to verify the scalability
of our methods. The inference time for detection and segmentation is reduced on
all three hardware types compared to MobileNetv3-based methods. Our work fills
the gap in NAS for robot hardware resource-aware.

</details>


### [27] [Incorporating Human-Inspired Ankle Characteristics in a Forced-Oscillation-Based Reduced-Order Model for Walking](https://arxiv.org/abs/2509.20689)
*Chathura Semasinghe,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 本文通过引入脚踝和足的力学模型，扩展了基于强制振荡的行走简化模型，提出了一种受人类启发的脚踝动力学设计，显著改善了步态特性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过引入脚踝和足的模型，提高行走模型的稳定性和自然性，从而更好地模拟和理解人类行走机制。

Method: 设计了一种受人类启发的脚踝动力学范式，并与足部放置策略结合，以稳定行走模型。

Result: 新模型在大范围初始条件误差下通过足部放置和脚踝策略稳定行走，而小扰动下仅通过脚踝方案即可实现稳定。

Conclusion: 这种新特性不仅模拟了人类行走的稳定机制，还为理解类似行走的稳定机制提供了新视角。

Abstract: This paper extends the forced-oscillation-based reduced-order model of
walking to a model with ankles and feet. A human-inspired paradigm was designed
for the ankle dynamics, which results in improved gait characteristics compared
to the point-foot model. In addition, it was shown that while the proposed
model can stabilize against large errors in initial conditions through
combination of foot placement and ankle strategies, the model is able to
stabilize against small perturbations without relying on the foot placement
control and solely through the designed proprioceptive ankle scheme. This novel
property, which is also observed in humans, can help in better understanding of
anthropomorphic walking and its stabilization mechanisms.

</details>


### [28] [RuN: Residual Policy for Natural Humanoid Locomotion](https://arxiv.org/abs/2509.20696)
*Qingpeng Li,Chengrui Zhu,Yanming Wu,Xin Yuan,Zhen Zhang,Jian Yang,Yong Liu*

Main category: cs.RO

TL;DR: RuN框架通过解耦学习方法，结合预训练的运动生成器和强化学习策略，实现了人形机器人在多种速度下的稳定、自然步态和步态转换。


<details>
  <summary>Details</summary>
Motivation: 解决当前深度强化学习方法在实现人形机器人自然动态步态和速度转换时，需同时学习运动模仿、速度跟踪和稳定性维护的挑战。

Method: 提出RuN框架，通过预训练条件运动生成器提供运动先验，结合强化学习策略学习轻量级残差修正，处理动力学交互。

Result: 在仿真和现实中，RuN在Unitree G1人形机器人上实现了0-2.5 m/s速度范围内的稳定自然步态和步态转换，优于现有方法。

Conclusion: RuN框架在训练效率和最终性能上均优于现有方法，为人形机器人动态步态控制提供了有效解决方案。

Abstract: Enabling humanoid robots to achieve natural and dynamic locomotion across a
wide range of speeds, including smooth transitions from walking to running,
presents a significant challenge. Existing deep reinforcement learning methods
typically require the policy to directly track a reference motion, forcing a
single policy to simultaneously learn motion imitation, velocity tracking, and
stability maintenance. To address this, we introduce RuN, a novel decoupled
residual learning framework. RuN decomposes the control task by pairing a
pre-trained Conditional Motion Generator, which provides a kinematically
natural motion prior, with a reinforcement learning policy that learns a
lightweight residual correction to handle dynamical interactions. Experiments
in simulation and reality on the Unitree G1 humanoid robot demonstrate that RuN
achieves stable, natural gaits and smooth walk-run transitions across a broad
velocity range (0-2.5 m/s), outperforming state-of-the-art methods in both
training efficiency and final performance.

</details>


### [29] [Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations](https://arxiv.org/abs/2509.20703)
*Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 论文提出了一种名为JFTO的框架，通过优化抓取姿势和物体轨迹模仿，解决从人类视频演示中学习机器人操作的可行性问题。


<details>
  <summary>Details</summary>
Motivation: 传统的遥操作或手把手教学难以规模化，而直接从人类视频中学习机器人操作存在本体差异和关节可行性约束的挑战。

Method: 提出JFTO框架，将演示视为物体中心指导，平衡抓取姿势可行性、物体轨迹一致性和无碰撞执行，并通过SE(3)流匹配实现概率建模。

Result: 在仿真和真实世界的多样化操作任务中进行验证，证明了方法的有效性。

Conclusion: JFTO框架成功解决了从视频中学习机器人操作的挑战，实现了高效且可行的模仿学习。

Abstract: Learning from human video demonstrations offers a scalable alternative to
teleoperation or kinesthetic teaching, but poses challenges for robot
manipulators due to embodiment differences and joint feasibility constraints.
We address this problem by proposing the Joint Flow Trajectory Optimization
(JFTO) framework for grasp pose generation and object trajectory imitation
under the video-based Learning-from-Demonstration (LfD) paradigm. Rather than
directly imitating human hand motions, our method treats demonstrations as
object-centric guides, balancing three objectives: (i) selecting a feasible
grasp pose, (ii) generating object trajectories consistent with demonstrated
motions, and (iii) ensuring collision-free execution within robot kinematics.
To capture the multimodal nature of demonstrations, we extend flow matching to
$\SE(3)$ for probabilistic modeling of object trajectories, enabling
density-aware imitation that avoids mode collapse. The resulting optimization
integrates grasp similarity, trajectory likelihood, and collision penalties
into a unified differentiable objective. We validate our approach in both
simulation and real-world experiments across diverse real-world manipulation
tasks.

</details>


### [30] [Building Information Models to Robot-Ready Site Digital Twins (BIM2RDT): An Agentic AI Safety-First Framework](https://arxiv.org/abs/2509.20705)
*Reza Akhavian,Mani Amani,Johannes Mootz,Robert Ashe,Behrad Beheshti*

Main category: cs.RO

TL;DR: 该论文提出了BIM2RDT框架，将静态BIM转化为动态、机器人可用的数字孪生体，提升施工行业的安全性和效率。通过结合BIM数据、物联网传感器和机器人采集的视觉空间数据，以及创新的Semantic-Gravity ICP算法，显著提高了点云对齐精度。


<details>
  <summary>Details</summary>
Motivation: 施工行业需要更高效、安全的数字化管理方法，现有的BIM数据与实时现场条件之间存在鸿沟，迫切需要动态数字孪生技术优化决策和执行。

Method: 提出了BIM2RDT框架，整合了BIM的几何语义信息、物联网传感器数据和机器人视觉数据。创新性地使用Semantic-Gravity ICP算法，利用LLM推理提升点云对齐精度，并结合YOLOE和Shi-Tomasi技术实现元素检测与跟踪。

Result: 实验表明，SG-ICP算法相比标准ICP显著提高了对齐精度（RMSE降低64.3%--88.3%）。实时HAV监测确保了安全事件的及时干预。

Conclusion: BIM2RDT通过动态数字孪生体和智能算法，有效提升了施工行业的安全性和效率，未来可进一步推广应用于其他工业场景。

Abstract: The adoption of cyber-physical systems and jobsite intelligence that connects
design models, real-time site sensing, and autonomous field operations can
dramatically enhance digital management in the construction industry. This
paper introduces BIM2RDT (Building Information Models to Robot-Ready Site
Digital Twins), an agentic artificial intelligence (AI) framework designed to
transform static Building Information Modeling (BIM) into dynamic, robot-ready
digital twins (DTs) that prioritize safety during execution. The framework
bridges the gap between pre-existing BIM data and real-time site conditions by
integrating three key data streams: geometric and semantic information from BIM
models, activity data from IoT sensor networks, and visual-spatial data
collected by robots during site traversal. The methodology introduces
Semantic-Gravity ICP (SG-ICP), a point cloud registration algorithm that
leverages large language model (LLM) reasoning. Unlike traditional methods,
SG-ICP utilizes an LLM to infer object-specific, plausible orientation priors
based on BIM semantics, improving alignment accuracy by avoiding convergence on
local minima. This creates a feedback loop where robot-collected data updates
the DT, which in turn optimizes paths for missions. The framework employs YOLOE
object detection and Shi-Tomasi corner detection to identify and track
construction elements while using BIM geometry as a priori maps. The framework
also integrates real-time Hand-Arm Vibration (HAV) monitoring, mapping
sensor-detected safety events to the digital twin using IFC standards for
intervention. Experiments demonstrate SG-ICP's superiority over standard ICP,
achieving RMSE reductions of 64.3%--88.3% in alignment across scenarios with
occluded features, ensuring plausible orientations. HAV integration triggers
warnings upon exceeding exposure limits, enhancing compliance with ISO 5349-1.

</details>


### [31] [Digital Twin-Guided Robot Path Planning: A Beta-Bernoulli Fusion with Large Language Model as a Sensor](https://arxiv.org/abs/2509.20709)
*Mani Amani,Reza Akhavian*

Main category: cs.RO

TL;DR: 提出了一种结合自然语言指令与BIM语义地图的新框架，通过Beta-Bernoulli贝叶斯融合提升机器人路径规划的鲁棒性和上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 将自然语言提示融入机器人任务规划，尤其在建筑领域，BIM模型提供了丰富的环境描述。目标是开发一种上下文感知的方法，提升路径规划的安全性和适应性。

Method: 采用Beta-Bernoulli贝叶斯融合，将LLM（语言模型）视为传感器，通过更新Beta分布参数来动态调整障碍物的排斥系数，结合情感和上下文分析生成连续增益，增强基于欧氏距离的势场启发式。

Result: 仿真结果表明，该方法在路径鲁棒性和有效性上实现了定性和定量的双重提升。

Conclusion: 该框架为多自然语言指令的链式处理提供了数值稳定的解决方案，可无缝集成到各类学习或经典AI框架中，显著提升了路径规划的上下文感知能力。

Abstract: Integrating natural language (NL) prompts into robotic mission planning has
attracted significant interest in recent years. In the construction domain,
Building Information Models (BIM) encapsulate rich NL descriptions of the
environment. We present a novel framework that fuses NL directives with
BIM-derived semantic maps via a Beta-Bernoulli Bayesian fusion by interpreting
the LLM as a sensor: each obstacle's design-time repulsive coefficient is
treated as a Beta(alpha, beta) random variable and LLM-returned danger scores
are incorporated as pseudo-counts to update alpha and beta. The resulting
posterior mean yields a continuous, context-aware repulsive gain that augments
a Euclidean-distance-based potential field for cost heuristics. By adjusting
gains based on sentiment and context inferred from user prompts, our method
guides robots along safer, more context-aware paths. This provides a
numerically stable method that can chain multiple natural commands and prompts
from construction workers and foreman to enable planning while giving
flexibility to be integrated in any learned or classical AI framework.
Simulation results demonstrate that this Beta-Bernoulli fusion yields both
qualitative and quantitative improvements in path robustness and validity.

</details>


### [32] [RobotDancing: Residual-Action Reinforcement Learning Enables Robust Long-Horizon Humanoid Motion Tracking](https://arxiv.org/abs/2509.20717)
*Zhenguo Sun,Yibo Peng,Yuan Meng,Xukun Li,Bo-Sheng Huang,Zhenshan Bing,Xinlong Wang,Alois Knoll*

Main category: cs.RO

TL;DR: RobotDancing是一个简化且可扩展的框架，旨在通过预测残余关节目标来纠正动力学偏差，实现长时程、高动态的运动跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决由于模型与实物不匹配导致的误差累积问题，提高人形机器人运动跟踪的稳健性。

Method: 使用端到端的强化学习管道，包括训练、模拟验证和零样本模拟到真实迁移，统一的观测、奖励和超参数配置。

Result: 在Unitree G1上成功跟踪多分钟的高能量舞蹈动作（如跳跃、旋转），并零样本迁移到硬件上，展现出高质量的运动跟踪。

Conclusion: RobotDancing有效地解决了长时程运动跟踪中的动力学偏差问题，展现了其在复杂动作中的广泛应用潜力。

Abstract: Long-horizon, high-dynamic motion tracking on humanoids remains brittle
because absolute joint commands cannot compensate model-plant mismatch, leading
to error accumulation. We propose RobotDancing, a simple, scalable framework
that predicts residual joint targets to explicitly correct dynamics
discrepancies. The pipeline is end-to-end--training, sim-to-sim validation, and
zero-shot sim-to-real--and uses a single-stage reinforcement learning (RL)
setup with a unified observation, reward, and hyperparameter configuration. We
evaluate primarily on Unitree G1 with retargeted LAFAN1 dance sequences and
validate transfer on H1/H1-2. RobotDancing can track multi-minute, high-energy
behaviors (jumps, spins, cartwheels) and deploys zero-shot to hardware with
high motion tracking quality.

</details>


### [33] [SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning](https://arxiv.org/abs/2509.20739)
*Guoyang Zhao,Yudong Li,Weiqing Qi,Kai Zhang,Bonan Liu,Kai Chen,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种基于语义推理和轻量拓扑表示的视觉导航框架，替代了传统的SLAM密集型几何方法，提升了导航的语义准确性和成功率。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法在快速运动、校准需求和高传感器漂移下表现脆弱，且缺乏任务驱动的语义推理能力。

Method: 采用视觉语言感知模块和语义概率拓扑地图，结合LLM全局推理和视觉局部规划，实现分层导航。

Result: 实验显示该框架在语义准确性、规划质量和导航成功率上均有显著提升。

Conclusion: 该工作为无SLAM的视觉语言导航提供了新范式，将机器人探索从几何映射转向语义驱动决策。

Abstract: Conventional SLAM pipelines for legged robot navigation are fragile under
rapid motion, calibration demands, and sensor drift, while offering limited
semantic reasoning for task-driven exploration. To deal with these issues, we
propose a vision-only, SLAM-free navigation framework that replaces dense
geometry with semantic reasoning and lightweight topological representations. A
hierarchical vision-language perception module fuses scene-level context with
object-level cues for robust semantic inference. And a semantic-probabilistic
topological map supports coarse-to-fine planning: LLM-based global reasoning
for subgoal selection and vision-based local planning for obstacle avoidance.
Integrated with reinforcement-learning locomotion controllers, the framework is
deployable across diverse legged robot platforms. Experiments in simulation and
real-world settings demonstrate consistent improvements in semantic accuracy,
planning quality, and navigation success, while ablation studies further
showcase the necessity of both hierarchical perception and fine local planning.
This work introduces a new paradigm for SLAM-free, vision-language-driven
navigation, shifting robotic exploration from geometry-centric mapping to
semantics-driven decision making.

</details>


### [34] [MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM](https://arxiv.org/abs/2509.20757)
*Yuxuan Zhou,Xingxing Li,Shengyu Li,Zhuohao Yan,Chunxi Xia,Shaoquan Feng*

Main category: cs.RO

TL;DR: 论文提出了MASt3R-Fusion框架，结合前馈点云回归与多传感器数据，提升视觉SLAM在低纹理环境和复杂视觉条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统视觉SLAM在低纹理环境和复杂视觉条件下表现不佳，现有的神经网络方法未充分利用多传感器融合的优势。

Method: 引入Sim(3)视觉对齐约束和分层因子图设计，结合惯性测量和GNSS数据，实现实时优化与全局一致性重建。

Result: 在公共和自采集数据集上，系统在准确性和鲁棒性上显著优于现有方法。

Conclusion: MASt3R-Fusion通过多传感器融合提升了视觉SLAM性能，代码开源以促进研究。

Abstract: Visual SLAM is a cornerstone technique in robotics, autonomous driving and
extended reality (XR), yet classical systems often struggle with low-texture
environments, scale ambiguity, and degraded performance under challenging
visual conditions. Recent advancements in feed-forward neural network-based
pointmap regression have demonstrated the potential to recover high-fidelity 3D
scene geometry directly from images, leveraging learned spatial priors to
overcome limitations of traditional multi-view geometry methods. However, the
widely validated advantages of probabilistic multi-sensor information fusion
are often discarded in these pipelines. In this work, we propose
MASt3R-Fusion,a multi-sensor-assisted visual SLAM framework that tightly
integrates feed-forward pointmap regression with complementary sensor
information, including inertial measurements and GNSS data. The system
introduces Sim(3)-based visualalignment constraints (in the Hessian form) into
a universal metric-scale SE(3) factor graph for effective information fusion. A
hierarchical factor graph design is developed, which allows both real-time
sliding-window optimization and global optimization with aggressive loop
closures, enabling real-time pose tracking, metric-scale structure perception
and globally consistent mapping. We evaluate our approach on both public
benchmarks and self-collected datasets, demonstrating substantial improvements
in accuracy and robustness over existing visual-centered multi-sensor SLAM
systems. The code will be released open-source to support reproducibility and
further research (https://github.com/GREAT-WHU/MASt3R-Fusion).

</details>


### [35] [Leveraging Temporally Extended Behavior Sharing for Multi-task Reinforcement Learning](https://arxiv.org/abs/2509.20766)
*Gawon Lee,Daesol Cho,H. Jin Kim*

Main category: cs.RO

TL;DR: 该论文提出了MT-L\'evy，一种结合行为共享和L\'evy启发的探索策略，以提高机器人多任务强化学习的样本效率。


<details>
  <summary>Details</summary>
Motivation: 多任务强化学习（MTRL）在机器人应用中面临数据收集成本高的问题，需要通过创新探索策略提升样本效率和实用性。

Method: MT-L\'evy通过结合跨任务的行为共享和动态调整的探索策略，优化状态空间覆盖。

Result: 实验证明MT-L\'evy显著提升了探索效率和样本利用率，并通过消融研究验证了各组件的贡献。

Conclusion: 结合行为共享和自适应探索策略可显著提升MTRL在机器人应用中的实用性。

Abstract: Multi-task reinforcement learning (MTRL) offers a promising approach to
improve sample efficiency and generalization by training agents across multiple
tasks, enabling knowledge sharing between them. However, applying MTRL to
robotics remains challenging due to the high cost of collecting diverse task
data. To address this, we propose MT-L\'evy, a novel exploration strategy that
enhances sample efficiency in MTRL environments by combining behavior sharing
across tasks with temporally extended exploration inspired by L\'evy flight.
MT-L\'evy leverages policies trained on related tasks to guide exploration
towards key states, while dynamically adjusting exploration levels based on
task success ratios. This approach enables more efficient state-space coverage,
even in complex robotics environments. Empirical results demonstrate that
MT-L\'evy significantly improves exploration and sample efficiency, supported
by quantitative and qualitative analyses. Ablation studies further highlight
the contribution of each component, showing that combining behavior sharing
with adaptive exploration strategies can significantly improve the practicality
of MTRL in robotics applications.

</details>


### [36] [SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation](https://arxiv.org/abs/2509.20839)
*Jiaxuan He,Jiamei Ren,Chongshang Yan,Wenjie Song*

Main category: cs.RO

TL;DR: SemSight是一种多级场景语义的概率鸟瞰图预测模型，通过联合推断结构布局、全局场景上下文和目标区域分布，提升未知区域的语义预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常专注于单一对象或几何占据图，缺乏对房间级语义结构的建模能力。

Method: 提出SemSight模型，采用编码器-解码器网络架构，并引入掩码约束监督策略，专注于未知区域的预测。

Result: 实验表明，SemSight在未探索区域的关键功能类别预测上表现更优，并在导航效率上有所提升。

Conclusion: SemSight不仅提高了语义预测的准确性，还在实际导航中减少了搜索步骤。

Abstract: In target-driven navigation and autonomous exploration, reasonable prediction
of unknown regions is crucial for efficient navigation and environment
understanding. Existing methods mostly focus on single objects or geometric
occupancy maps, lacking the ability to model room-level semantic structures. We
propose SemSight, a probabilistic bird's-eye-view prediction model for
multi-level scene semantics. The model jointly infers structural layouts,
global scene context, and target area distributions, completing semantic maps
of unexplored areas while estimating probability maps for target categories. To
train SemSight, we simulate frontier-driven exploration on 2,000 indoor layout
graphs, constructing a diverse dataset of 40,000 sequential egocentric
observations paired with complete semantic maps. We adopt an encoder-decoder
network as the core architecture and introduce a mask-constrained supervision
strategy. This strategy applies a binary mask of unexplored areas so that
supervision focuses only on unknown regions, forcing the model to infer
semantic structures from the observed context. Experimental results show that
SemSight improves prediction performance for key functional categories in
unexplored regions and outperforms non-mask-supervised approaches on metrics
such as Structural Consistency (SC) and Region Recognition Accuracy (PA). It
also enhances navigation efficiency in closed-loop simulations, reducing the
number of search steps when guiding robots toward target areas.

</details>


### [37] [ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation](https://arxiv.org/abs/2509.20841)
*Dekun Lu,Wei Gao,Kui Jia*

Main category: cs.RO

TL;DR: 本文提出了一种称为链式移动导向关键点（CoMOK）的方法，用于端到端的机器人操作策略，以提高通用性、精确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端学习在机器人操作中具有避免模块间信息丢失和特征对齐问题的优势，但现有方法（包括基于大模型的神经网络）在大规模实际应用中仍表现不佳。

Method: 提出了CoMOK动作表示方法，支持多样化的操作任务，并通过导向关键点实现自然泛化。

Result: 在模拟和硬件实验中证明了该方法的有效性，能够实现亚厘米级精度，并处理多模态行为和可变形物体。

Conclusion: CoMOK是一种通用且高效的端到端操作方法，适用于复杂任务和多样化对象。

Abstract: End-to-end robot manipulation policies offer significant potential for
enabling embodied agents to understand and interact with the world. Unlike
traditional modular pipelines, end-to-end learning mitigates key limitations
such as information loss between modules and feature misalignment caused by
isolated optimization targets. Despite these advantages, existing end-to-end
neural networks for robotic manipulation--including those based on large
VLM/VLA models--remain insufficiently performant for large-scale practical
deployment. In this paper, we take a step towards an end-to-end manipulation
policy that is generalizable, accurate and reliable. To achieve this goal, we
propose a novel Chain of Moving Oriented Keypoints (CoMOK) formulation for
robotic manipulation. Our formulation is used as the action representation of a
neural policy, which can be trained in an end-to-end fashion. Such an action
representation is general, as it extends the standard end-effector pose action
representation and supports a diverse set of manipulation tasks in a unified
manner. The oriented keypoint in our method enables natural generalization to
objects with different shapes and sizes, while achieving sub-centimeter
accuracy. Moreover, our formulation can easily handle multi-stage tasks,
multi-modal robot behaviors, and deformable objects. Extensive simulated and
hardware experiments demonstrate the effectiveness of our method.

</details>


### [38] [MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases](https://arxiv.org/abs/2509.20843)
*Ziang Luo,Kangan Qian,Jiahua Wang,Yuechen Luo,Jinyu Miao,Zheng Fu,Yunlong Wang,Sicong Jiang,Zilin Huang,Yifei Hu,Yuhao Yang,Hao Ye,Mengmeng Yang,Xiaojian Dong,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: MTRDrive框架通过结合记忆检索和动态工具包，提升VLMs在自动驾驶中的泛化能力和决策能力，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在自动驾驶中存在泛化能力不足和可靠性问题，需要一种新框架来提升其实用性。

Method: MTRDrive采用闭环系统，结合记忆检索机制和动态工具包，实现协同推理。

Result: 在NAVSIM和Roadwork-VLM基准测试中，MTRDrive表现卓越，尤其是在零样本泛化测试中。

Conclusion: MTRDrive显著提升了自动驾驶系统的安全性和可靠性，展示了其实际应用潜力。

Abstract: Vision-Language Models(VLMs) have demonstrated significant potential for
end-to-end autonomous driving, yet a substantial gap remains between their
current capabilities and the reliability necessary for real-world deployment. A
critical challenge is their fragility, characterized by hallucinations and poor
generalization in out-of-distribution (OOD) scenarios. To bridge this gap, we
introduce MTRDrive, a novel framework that integrates procedural driving
experiences with a dynamic toolkit to enhance generalization and proactive
decision-making.
  MTRDrive addresses these limitations through a closed-loop system that
combines a memory-based experience retrieval mechanism with dynamic toolkits.
This synergy enables the model to interact more effectively with its
environment, improving both reasoning and decision-making capabilities with the
help of our memory-tool synergistic reasoning. Additionally, we introduce a new
benchmark based on complex Roadwork construction scenarios to rigorously
evaluate zero-shot generalization.
  Extensive experiments demonstrate the superior effectiveness of our approach.
On the public NAVSIM benchmark, our 3B-parameter MTRDrive model achieves an
exceptional PDMS of 88.3 without chain-of-thought and sets a state-of-the-art
performance bar on high-level planning, with a driving metric score of 79.8\%
and a planning accuracy of 82.6\%. Rigorous zero-shot evaluation on the new
Roadwork-VLM benchmark shows a strong ability to reason robustly in unseen
scenarios, achieving a driving metric score of 80.2\%. These results highlight
MTRDrive's potential to advance autonomous driving toward safer and more
reliable systems.

</details>


### [39] [Efficient Differentiable Contact Model with Long-range Influence](https://arxiv.org/abs/2509.20917)
*Xiaohan Ye,Kui Wu,Zherong Pan,Taku Komura*

Main category: cs.RO

TL;DR: 论文探讨了可微分物理中因接触模型设计导致梯度信息异常的问题，并提出了满足特定属性的接触模型，以改善梯度信息的行为，最终在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 可微分物理在多领域应用中的重要性日益增加，但梯度信息的异常问题阻碍了基于梯度的优化器的收敛，尤其是接触模型的设计对此有显著影响。

Method: 研究分析了梯度信息异常与接触模型设计的关系，提出了一组接触模型需满足的属性，并设计了一种计算高效的接触模型。

Result: 实验表明，新接触模型能从简单初始化中生成复杂的接触丰富控制信号，成功应用于多种运动和控制任务。

Conclusion: 论文提出的接触模型有效解决了梯度信息异常问题，为可微分物理的应用提供了更稳定的基础。

Abstract: With the maturation of differentiable physics, its role in various downstream
applications: such as model predictive control, robotic design optimization,
and neural PDE solvers, has become increasingly important. However, the
derivative information provided by differentiable simulators can exhibit abrupt
changes or vanish altogether, impeding the convergence of gradient-based
optimizers. In this work, we demonstrate that such erratic gradient behavior is
closely tied to the design of contact models. We further introduce a set of
properties that a contact model must satisfy to ensure well-behaved gradient
information. Lastly, we present a practical contact model for differentiable
rigid-body simulators that satisfies all of these properties while maintaining
computational efficiency. Our experiments show that, even from simple
initializations, our contact model can discover complex, contact-rich control
signals, enabling the successful execution of a range of downstream locomotion
and manipulation tasks.

</details>


### [40] [Autoregressive End-to-End Planning with Time-Invariant Spatial Alignment and Multi-Objective Policy Refinement](https://arxiv.org/abs/2509.20938)
*Jianbo Zhao,Taiyu Ban,Xiangjie Li,Xingtai Gui,Hangning Zhou,Lei Liu,Hongwei Zhao,Bin Li*

Main category: cs.RO

TL;DR: 提出了一种时间不变空间对齐（TISA）模块，解决自回归模型在自动驾驶规划中的时空不一致问题，结合运动学动作预测和多目标训练，达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在自动驾驶规划中表现有限，主要原因是时空不一致性导致的世界观不一致问题。

Method: 采用TISA模块学习将初始环境特征投影到一致的自我中心帧中，并结合运动学动作预测和多目标DPO训练。

Result: 在NAVSIM数据集上达到89.8 PDMS，是目前自回归模型中的最佳表现。

Conclusion: TISA模块和多目标训练显著提升了自动驾驶规划的性能。

Abstract: The inherent sequential modeling capabilities of autoregressive models make
them a formidable baseline for end-to-end planning in autonomous driving.
Nevertheless, their performance is constrained by a spatio-temporal
misalignment, as the planner must condition future actions on past sensory
data. This creates an inconsistent worldview, limiting the upper bound of
performance for an otherwise powerful approach. To address this, we propose a
Time-Invariant Spatial Alignment (TISA) module that learns to project initial
environmental features into a consistent ego-centric frame for each future time
step, effectively correcting the agent's worldview without explicit future
scene prediction. In addition, we employ a kinematic action prediction head
(i.e., acceleration and yaw rate) to ensure physically feasible trajectories.
Finally, we introduce a multi-objective post-training stage using Direct
Preference Optimization (DPO) to move beyond pure imitation. Our approach
provides targeted feedback on specific driving behaviors, offering a more
fine-grained learning signal than the single, overall objective used in
standard DPO. Our model achieves a state-of-the-art 89.8 PDMS on the NAVSIM
dataset among autoregressive models. The video document is available at
https://tisa-dpo-e2e.github.io/.

</details>


### [41] [BactoBot: A Low-Cost, Bacteria-Inspired Soft Underwater Robot for Marine Exploration](https://arxiv.org/abs/2509.20964)
*Rubaiyat Tasnim Chowdhury,Nayan Bala,Ronojoy Roy,Tarek Mahmud*

Main category: cs.RO

TL;DR: BactoBot是一款低成本、柔软的水下机器人，旨在安全探索海洋环境，灵感来源于细菌鞭毛推进机制，展示了可行性和环保潜力。


<details>
  <summary>Details</summary>
Motivation: 传统刚性水下机器人对海洋生态系统有害，因此需要设计一种更安全的替代方案。

Method: 采用12条柔性硅胶臂和3D打印框架，通过DIY方法制作原型，并优化防水和浮力校准。

Result: 在受控水箱中测试成功，实现了前进和转向功能，验证了低成本复现复杂生物运动的可行性。

Conclusion: BactoBot为环保机器人工具奠定了基础，尤其适用于资源受限的海洋科学研究，未来可探索自主操作和实地部署。

Abstract: Traditional rigid underwater vehicles pose risks to delicate marine
ecosystems. This paper presents BactoBot, a low-cost, soft underwater robot
designed for safe and gentle marine exploration. Inspired by bacterial
flagellar propulsion, BactoBot features 12 flexible, silicone-based arms
arranged on a 3D-printed dodecahedral frame. The design provides inherent
compliance, redundancy, and the potential for omnidirectional movement. The
prototype was fabricated using accessible DIY methods, including food-grade
silicone molding, 3D printing, and off-the-shelf microcontrollers.
Waterproofing and buoyancy calibration protocols were developed, and the robot
was successfully tested in a controlled water tank, demonstrating forward
motion and turning. The results validate the feasibility of replicating complex
biological locomotion at low cost. The project lays a foundation for
environmentally conscious robotic tools, particularly for marine science in
resource-constrained settings, and identifies pathways toward autonomous
operation and field deployment.

</details>


### [42] [AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation](https://arxiv.org/abs/2509.21006)
*Konstantin Gubernatorov,Artem Voronov,Roman Voronov,Sergei Pasynkov,Stepan Perminov,Ziang Guo,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: AnywhereVLA 是一个模块化框架，用于在未知室内环境中进行自然语言控制的拾取与放置任务，结合了基于几何的导航与语言条件操纵的优点。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在不可预测的室内环境中，通过自然语言指令实现可靠的拾取与放置任务。

Method: 方法包括解析用户文本为任务图、结合经典SLAM与LiDAR、语义映射、任务感知探索策略，以及一个微调的紧凑操纵头（SmolVLA）。

Result: 系统在嵌入式硬件上实现了46%的任务成功率，并保持实时操作。

Conclusion: 通过结合经典导航与微调的视觉语言操纵，系统既可靠又具备任务泛化能力。

Abstract: We address natural language pick-and-place in unseen, unpredictable indoor
environments with AnywhereVLA, a modular framework for mobile manipulation. A
user text prompt serves as an entry point and is parsed into a structured task
graph that conditions classical SLAM with LiDAR and cameras, metric semantic
mapping, and a task-aware frontier exploration policy. An approach planner then
selects visibility and reachability aware pre grasp base poses. For
interaction, a compact SmolVLA manipulation head is fine tuned on platform pick
and place trajectories for the SO-101 by TheRobotStudio, grounding local visual
context and sub-goals into grasp and place proposals. The full system runs
fully onboard on consumer-level hardware, with Jetson Orin NX for perception
and VLA and an Intel NUC for SLAM, exploration, and control, sustaining
real-time operation. We evaluated AnywhereVLA in a multi-room lab under static
scenes and normal human motion. In this setting, the system achieves a $46\%$
overall task success rate while maintaining throughput on embedded compute. By
combining a classical stack with a fine-tuned VLA manipulation, the system
inherits the reliability of geometry-based navigation with the agility and task
generalization of language-conditioned manipulation.

</details>


### [43] [Multi-Robot Vision-Based Task and Motion Planning for EV Battery Disassembly and Sorting](https://arxiv.org/abs/2509.21020)
*Abdelaziz Shaarawy,Cansu Erdogan,Rustam Stolkin,Alireza Rastegarpanah*

Main category: cs.RO

TL;DR: 论文提出了一种四层任务与运动规划（TAMP）框架，用于多机器人协同拆卸电动汽车电池，结合了符号任务规划和基于演示学习的运动规划，提升了路径紧凑性和安全性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车电池拆卸需要多机器人精确协同、短而可靠的运动以及在杂乱动态场景中的碰撞安全，传统方法难以满足这些需求。

Method: 采用四层TAMP框架，结合符号任务规划、成本与可达性分配，以及基于TP-GMM的运动规划；通过立体视觉和YOLOv8实时定位组件，利用OctoMap和FCL进行碰撞检测。

Result: 实验表明，与基线RRTConnect相比，该方法使末端执行器路径长度平均减少63.3%，任务完成时间缩短8.1%，且机器人间的碰撞体积减少47%。

Conclusion: 该方法显著提升了多机器人在非结构化和动态环境中拆卸电池的自主性、精确性和安全性。

Abstract: Electric-vehicle (EV) battery disassembly requires precise multi-robot
coordination, short and reliable motions, and robust collision safety in
cluttered, dynamic scenes. We propose a four-layer task-and-motion planning
(TAMP) framework that couples symbolic task planning and cost- and
accessibility-aware allocation with a TP-GMM-guided motion planner learned from
demonstrations. Stereo vision with YOLOv8 provides real-time component
localization, while OctoMap-based 3D mapping and FCL(Flexible Collision
Library) checks in MoveIt unify predictive digital-twin collision checking with
reactive, vision-based avoidance. Validated on two UR10e robots across cable,
busbar, service plug, and three leaf-cell removals, the approach yields
substantially more compact and safer motions than a default RRTConnect baseline
under identical perception and task assignments: average end-effector path
length drops by $-63.3\%$ and makespan by $-8.1\%$; per-arm swept volumes
shrink (R1: $0.583\rightarrow0.139\,\mathrm{m}^3$; R2:
$0.696\rightarrow0.252\,\mathrm{m}^3$), and mutual overlap decreases by $47\%$
($0.064\rightarrow0.034\,\mathrm{m}^3$). These results highlight improved
autonomy, precision, and safety for multi-robot EV battery disassembly in
unstructured, dynamic environments.

</details>


### [44] [KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models](https://arxiv.org/abs/2509.21027)
*Sibo Li,Qianyue Hao,Yu Shang,Yong Li*

Main category: cs.RO

TL;DR: KeyWorld通过专注于语义关键帧和轻量级插值，提升了机器人世界模型的推理速度和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人世界模型在推理速度与生成轨迹的物理合理性上存在瓶颈，限制了实际应用。

Method: 提出KeyWorld框架，通过Transformer聚焦关键帧与轻量卷积模型填充中间帧，优化生成效率与物理合理性。

Result: 在LIBERO基准测试中，KeyWorld实现了5.68倍的加速，并提升了生成视频的物理有效性。

Conclusion: KeyWorld为实时机器人控制等领域的实际应用提供了高效且有效的世界模型解决方案。

Abstract: Robotic world models are a promising paradigm for forecasting future
environment states, yet their inference speed and the physical plausibility of
generated trajectories remain critical bottlenecks, limiting their real-world
applications. This stems from the redundancy of the prevailing frame-to-frame
generation approach, where the model conducts costly computation on similar
frames, as well as neglecting the semantic importance of key transitions. To
address this inefficiency, we propose KeyWorld, a framework that improves
text-conditioned robotic world models by concentrating transformers computation
on a few semantic key frames while employing a lightweight convolutional model
to fill the intermediate frames. Specifically, KeyWorld first identifies
significant transitions by iteratively simplifying the robot's motion
trajectories, obtaining the ground truth key frames. Then, a DiT model is
trained to reason and generate these physically meaningful key frames from
textual task descriptions. Finally, a lightweight interpolator efficiently
reconstructs the full video by inpainting all intermediate frames. Evaluations
on the LIBERO benchmark demonstrate that KeyWorld achieves a 5.68$\times$
acceleration compared to the frame-to-frame generation baseline, and focusing
on the motion-aware key frames further contributes to the physical validity of
the generated videos, especially on complex tasks. Our approach highlights a
practical path toward deploying world models in real-time robotic control and
other domains requiring both efficient and effective world models. Code is
released at https://anonymous.4open.science/r/Keyworld-E43D.

</details>


### [45] [MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation](https://arxiv.org/abs/2509.21045)
*Mahya Ramezani,M. Amin Alandihallaj,Barış Can Yalçın,Miguel Angel Olivares Mendez,Holger Voos*

Main category: cs.RO

TL;DR: 该论文提出了一种结合强化学习（RL）和模型预测控制（MPC）的框架，用于解决部分填充燃料箱的卫星自主对接问题。通过整合PPO和SAC强化学习算法与MPC，该方法显著提升了控制鲁棒性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 卫星对接过程中燃料晃动在微重力环境下会导致不可预测的力，影响稳定性，传统控制方法难以应对这一挑战。

Method: 结合Proximal Policy Optimization（PPO）和Soft Actor-Critic（SAC）强化学习算法与模型预测控制（MPC），利用MPC的预测能力加速RL训练并提升控制稳定性。

Result: 仿真实验表明，SAC-MPC方法在对接精度、成功率和控制效率上均优于独立的RL和PPO-MPC方法。

Conclusion: 该研究为燃料高效和抗干扰的卫星对接提供了新方案，提升了在轨燃料补给和维护任务的可行性。

Abstract: This paper presents an integrated Reinforcement Learning (RL) and Model
Predictive Control (MPC) framework for autonomous satellite docking with a
partially filled fuel tank. Traditional docking control faces challenges due to
fuel sloshing in microgravity, which induces unpredictable forces affecting
stability. To address this, we integrate Proximal Policy Optimization (PPO) and
Soft Actor-Critic (SAC) RL algorithms with MPC, leveraging MPC's predictive
capabilities to accelerate RL training and improve control robustness. The
proposed approach is validated through Zero-G Lab of SnT experiments for planar
stabilization and high-fidelity numerical simulations for 6-DOF docking with
fuel sloshing dynamics. Simulation results demonstrate that SAC-MPC achieves
superior docking accuracy, higher success rates, and lower control effort,
outperforming standalone RL and PPO-MPC methods. This study advances
fuel-efficient and disturbance-resilient satellite docking, enhancing the
feasibility of on-orbit refueling and servicing missions.

</details>


### [46] [Normalizing Flows are Capable Visuomotor Policy Learning Models](https://arxiv.org/abs/2509.21073)
*Simon Kristoffersson Lind,Jialong Li,Maj Stenmark,Volker Krüger*

Main category: cs.RO

TL;DR: 本文提出了一种基于Normalizing Flows的新型视觉运动策略学习模型，解决了扩散模型在计算成本和不确定性量化方面的不足，并在性能和效率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散模型在机器人领域中高计算成本和无法量化输出不确定性的问题，作者提出了一种基于Normalizing Flows的模型，以提高模型的可信度和效率。

Method: 作者引入了一种名为Normalizing Flows Policy的新模型，利用Normalizing Flows作为扩散模型的替代方案，提供了统计上可靠的置信度测量和高效推理。

Result: 在四个模拟机器人任务中，Normalizing Flows Policy性能优于或持平Diffusion Policy，且推理速度提升高达30倍。

Conclusion: Normalizing Flows Policy在机器人任务中表现出色，提供了更高的样本效率和更快的推理速度，为可靠、通用的机器人技术提供了有力工具。

Abstract: The field of general purpose robotics has recently embraced powerful
probabilistic models, such as diffusion models, to model and learn complex
behaviors. However, these models often come with significant trade-offs, namely
high computational costs for inference and a fundamental inability to quantify
output uncertainty. We argue that a model's trustworthiness, a critical factor
for reliable, general-purpose robotics, is inherently linked to its ability to
provide confidence measures.
  In this work, we introduce Normalizing Flows Policy, a novel visuomotor
policy learning model based on Normalizing Flows. We show that Normalizing
Flows are a natural and powerful alternative to diffusion models, providing
both a statistically sound measure of confidence and a highly efficient
inference process. Through comprehensive experiments across four distinct
simulated robotic tasks, we demonstrate that Normalizing Flows Policy achieves
performance comparable to, and often surpassing, Diffusion Policy, and it does
so not only with improved sample efficiency but also with up to 30 times faster
inference. Additionally, our ablation study validates several key architectural
and training techniques that enable Normalizing Flows to perform well in this
domain.

</details>


### [47] [Flight Dynamics to Sensing Modalities: Exploiting Drone Ground Effect for Accurate Edge Detection](https://arxiv.org/abs/2509.21085)
*Chenyu Zhao,Jingao Xu,Ciyu Ruan,Haoyang Wang,Shengbo Wang,Jiaqi Li,Jirong Zha,Weijie Hong,Zheng Yang,Yunhao Liu,Xiao-Ping Zhang,Xinlei Chen*

Main category: cs.RO

TL;DR: AirTouch系统利用地面效应变化进行高效边缘检测，准确率高且能耗低。


<details>
  <summary>Details</summary>
Motivation: 传统方法（雷达或相机）部署成本高且计算需求大，不适用于轻量化无人机。

Method: 系统通过分析无人机姿态传感器数据和飞行指令，检测地面效应变化，实现边缘检测。

Result: 平均检测距离误差为0.051m，性能优于基线方法86%，仅需43mW功耗。

Conclusion: AirTouch为低成本高效边缘检测提供了新的传感模式。

Abstract: Drone-based rapid and accurate environmental edge detection is highly
advantageous for tasks such as disaster relief and autonomous navigation.
Current methods, using radars or cameras, raise deployment costs and burden
lightweight drones with high computational demands. In this paper, we propose
AirTouch, a system that transforms the ground effect from a stability "foe" in
traditional flight control views, into a "friend" for accurate and efficient
edge detection. Our key insight is that analyzing drone basic attitude sensor
readings and flight commands allows us to detect ground effect changes. Such
changes typically indicate the drone flying over a boundary of two materials,
making this information valuable for edge detection. We approach this insight
through theoretical analysis, algorithm design, and implementation, fully
leveraging the ground effect as a new sensing modality without compromising
drone flight stability, thereby achieving accurate and efficient scene edge
detection. We also compare this new sensing modality with vision-based methods
to clarify its exclusive advantages in resource efficiency and detection
capability. Extensive evaluations demonstrate that our system achieves a high
detection accuracy with mean detection distance errors of 0.051m, outperforming
the baseline method performance by 86%. With such detection performance, our
system requires only 43 mW power consumption, contributing to this new sensing
modality for low-cost and highly efficient edge detection.

</details>


### [48] [Cross-Modal Instructions for Robot Motion Generation](https://arxiv.org/abs/2509.21107)
*William Barron,Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 提出了CrossInstruct框架，利用跨模态指令（如文本标签）代替物理演示来指导机器人行为，结合大模型推理与小模型精准指向，生成可执行的机器人行为。


<details>
  <summary>Details</summary>
Motivation: 传统机器人行为学习依赖物理演示，数据收集困难且难以扩展，因此寻求替代方式，即通过跨模态指令（如文本标注）来指导机器人。

Method: 采用CrossInstruct框架，将跨模态指令输入基础视觉语言模型（VLM），结合小模型精准指向，迭代生成2D视图并融合为3D运动轨迹，最后通过强化学习优化策略。

Result: 在仿真和实际硬件任务中验证了有效性，无需额外微调即能生成可执行的泛化行为，并为强化学习提供了良好的初始化策略。

Conclusion: CrossInstruct通过跨模态指令实现了高效的机器人行为学习，展示了无需物理演示的可行性，并为后续强化学习提供了基础。

Abstract: Teaching robots novel behaviors typically requires motion demonstrations via
teleoperation or kinaesthetic teaching, that is, physically guiding the robot.
While recent work has explored using human sketches to specify desired
behaviors, data collection remains cumbersome, and demonstration datasets are
difficult to scale. In this paper, we introduce an alternative paradigm,
Learning from Cross-Modal Instructions, where robots are shaped by
demonstrations in the form of rough annotations, which can contain free-form
text labels, and are used in lieu of physical motion. We introduce the
CrossInstruct framework, which integrates cross-modal instructions as examples
into the context input to a foundational vision-language model (VLM). The VLM
then iteratively queries a smaller, fine-tuned model, and synthesizes the
desired motion over multiple 2D views. These are then subsequently fused into a
coherent distribution over 3D motion trajectories in the robot's workspace. By
incorporating the reasoning of the large VLM with a fine-grained pointing
model, CrossInstruct produces executable robot behaviors that generalize beyond
the environment of in the limited set of instruction examples. We then
introduce a downstream reinforcement learning pipeline that leverages
CrossInstruct outputs to efficiently learn policies to complete fine-grained
tasks. We rigorously evaluate CrossInstruct on benchmark simulation tasks and
real hardware, demonstrating effectiveness without additional fine-tuning and
providing a strong initialization for policies subsequently refined via
reinforcement learning.

</details>


### [49] [Rich State Observations Empower Reinforcement Learning to Surpass PID: A Drone Ball Balancing Study](https://arxiv.org/abs/2509.21122)
*Mingjiang Liu,Hailong Huang*

Main category: cs.RO

TL;DR: 论文研究了无人机通过缆绳交互平衡球的任务，提出了一种分层控制框架，并通过强化学习训练高层策略。结果显示强化学习优于PID控制器，主要得益于其利用更丰富的状态观测信息的能力。


<details>
  <summary>Details</summary>
Motivation: 探讨无人机在复杂交互任务中如何通过分层控制和强化学习实现更好的性能，尤其是平衡球任务中的表现。

Method: 提出分层控制框架，将高层平衡策略与底层无人机控制解耦，并通过强化学习训练高层策略进行决策。

Result: 强化学习策略在仿真中表现优于精心调优的PID控制器，其优势源于能够有效利用更全面的状态观测信息，而非非线性映射能力或参数调优。

Conclusion: 研究表明，全面的状态表征在学习型系统中至关重要，提升感知能力可能显著改善控制器性能。

Abstract: This paper addresses a drone ball-balancing task, in which a drone stabilizes
a ball atop a movable beam through cable-based interaction. We propose a
hierarchical control framework that decouples high-level balancing policy from
low-level drone control, and train a reinforcement learning (RL) policy to
handle the high-level decision-making. Simulation results show that the RL
policy achieves superior performance compared to carefully tuned PID
controllers within the same hierarchical structure. Through systematic
comparative analysis, we demonstrate that RL's advantage stems not from
improved parameter tuning or inherent nonlinear mapping capabilities, but from
its ability to effectively utilize richer state observations. These findings
underscore the critical role of comprehensive state representation in
learning-based systems and suggest that enhanced sensing could be instrumental
in improving controller performance.

</details>


### [50] [Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems](https://arxiv.org/abs/2509.21143)
*Junfeng Yan,Biao Wu,Meng Fang,Ling Chen*

Main category: cs.RO

TL;DR: 论文介绍了一个针对汽车GUI的新型基准测试平台Automotive-ENV和一种名为ASURADA的地理感知多模态代理，强调了基于位置的情境在提高任务成功率中的重要性。


<details>
  <summary>Details</summary>
Motivation: 探索多模态代理在汽车系统中的适应性，解决车内GUI面临的驾驶员注意力有限、安全要求严格和复杂的位置交互问题。

Method: 提出了Automotive-ENV基准测试平台，包含185项参数化任务，并开发了ASURADA代理，利用GPS信息动态调整行为。

Result: 实验表明地理感知信息显著提高了安全任务的成功率。

Conclusion: Automotive-ENV和ASURADA展示了位置情境对汽车系统中多模态代理的重要性，平台将被公开发布以促进研究。

Abstract: Multimodal agents have demonstrated strong performance in general GUI
interactions, but their application in automotive systems has been largely
unexplored. In-vehicle GUIs present distinct challenges: drivers' limited
attention, strict safety requirements, and complex location-based interaction
patterns. To address these challenges, we introduce Automotive-ENV, the first
high-fidelity benchmark and interaction environment tailored for vehicle GUIs.
This platform defines 185 parameterized tasks spanning explicit control,
implicit intent understanding, and safety-aware tasks, and provides structured
multimodal observations with precise programmatic checks for reproducible
evaluation. Building on this benchmark, we propose ASURADA, a geo-aware
multimodal agent that integrates GPS-informed context to dynamically adjust
actions based on location, environmental conditions, and regional driving
norms. Experiments show that geo-aware information significantly improves
success on safety-aware tasks, highlighting the importance of location-based
context in automotive environments. We will release Automotive-ENV, complete
with all tasks and benchmarking tools, to further the development of safe and
adaptive in-vehicle agents.

</details>


### [51] [DAGDiff: Guiding Dual-Arm Grasp Diffusion to Stable and Collision-Free Grasps](https://arxiv.org/abs/2509.21145)
*Md Faizal Karim,Vignesh Vembar,Keshab Patra,Gaurav Singh,K Madhava Krishna*

Main category: cs.RO

TL;DR: DAGDiff是一个端到端框架，通过在SE(3) x SE(3)空间中直接去噪生成双臂抓取对，利用分类器信号引导扩散过程，实现了更稳定的抓取。


<details>
  <summary>Details</summary>
Motivation: 传统方法将双臂抓取任务分解为两个独立的抓取提议，依赖区域先验或启发式方法，限制了泛化能力且无法保证稳定性。

Method: DAGDiff通过几何、稳定性和碰撞感知的引导项，直接在SE(3) x SE(3)空间中生成抓取对。

Result: DAGDiff在力闭合检查、碰撞分析和大规模物理仿真中表现优异，相比之前的方法有显著提升。

Conclusion: DAGDiff能够直接在真实点云上生成双臂抓取，并在异构双臂系统中成功执行抓取和举升任务。

Abstract: Reliable dual-arm grasping is essential for manipulating large and complex
objects but remains a challenging problem due to stability, collision, and
generalization requirements. Prior methods typically decompose the task into
two independent grasp proposals, relying on region priors or heuristics that
limit generalization and provide no principled guarantee of stability. We
propose DAGDiff, an end-to-end framework that directly denoises to grasp pairs
in the SE(3) x SE(3) space. Our key insight is that stability and collision can
be enforced more effectively by guiding the diffusion process with classifier
signals, rather than relying on explicit region detection or object priors. To
this end, DAGDiff integrates geometry-, stability-, and collision-aware
guidance terms that steer the generative process toward grasps that are
physically valid and force-closure compliant. We comprehensively evaluate
DAGDiff through analytical force-closure checks, collision analysis, and
large-scale physics-based simulations, showing consistent improvements over
previous work on these metrics. Finally, we demonstrate that our framework
generates dual-arm grasps directly on real-world point clouds of previously
unseen objects, which are executed on a heterogeneous dual-arm setup where two
manipulators reliably grasp and lift them.

</details>


### [52] [Human-like Navigation in a World Built for Humans](https://arxiv.org/abs/2509.21189)
*Bhargav Chandaka,Gloria X. Wang,Haozhe Chen,Henry Che,Albert J. Zhai,Shenlong Wang*

Main category: cs.RO

TL;DR: ReasonNav利用视觉语言模型的推理能力，模仿人类导航行为，提高机器人在大型建筑中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航系统在陌生环境中缺乏人类的高效导航行为（如阅读标志、询问方向），导致效率低下。

Method: 设计基于导航地标的紧凑输入输出抽象，利用视觉语言模型进行语言理解和推理。

Result: 在真实和模拟导航任务中，ReasonNav成功通过高阶推理实现了高效导航。

Conclusion: ReasonNav通过整合人类导航行为，显著提升了机器人在复杂环境中的导航能力。

Abstract: When navigating in a man-made environment they haven't visited before--like
an office building--humans employ behaviors such as reading signs and asking
others for directions. These behaviors help humans reach their destinations
efficiently by reducing the need to search through large areas. Existing robot
navigation systems lack the ability to execute such behaviors and are thus
highly inefficient at navigating within large environments. We present
ReasonNav, a modular navigation system which integrates these human-like
navigation skills by leveraging the reasoning capabilities of a vision-language
model (VLM). We design compact input and output abstractions based on
navigation landmarks, allowing the VLM to focus on language understanding and
reasoning. We evaluate ReasonNav on real and simulated navigation tasks and
show that the agent successfully employs higher-order reasoning to navigate
efficiently in large, complex buildings.

</details>


### [53] [Next-Generation Aerial Robots -- Omniorientational Strategies: Dynamic Modeling, Control, and Comparative Analysis](https://arxiv.org/abs/2509.21210)
*Ali Kafili Gavgani,Amin Talaeizadeh,Aria Alasty,Hossein Nejat Pishkenari,Esmaeil Najafi*

Main category: cs.RO

TL;DR: 本研究提出多种多旋翼配置，通过增加控制输入实现全向控制，解决了传统系统的欠驱动问题。设计了两种控制器，并通过仿真验证其性能和能耗。


<details>
  <summary>Details</summary>
Motivation: 解决传统多旋翼系统无法独立控制姿态和位置的欠驱动问题，以实现全向控制。

Method: 引入多种配置，建立动力学模型，设计滑模控制器和新型PID控制器，并通过Simscape Multibody仿真验证。

Result: 控制器能有效处理干扰和不确定性，仿真结果表明配置和控制器在能耗方面表现良好。

Conclusion: 研究为未来全向无人机设计提供了配置选择和控制器设计的实用指南。

Abstract: Conventional multi-rotors are under-actuated systems, hindering them from
independently controlling attitude from position. In this study, we present
several distinct configurations that incorporate additional control inputs for
manipulating the angles of the propeller axes. This addresses the mentioned
limitations, making the systems "omniorientational". We comprehensively derived
detailed dynamic models for all introduced configurations and validated by a
methodology using Simscape Multibody simulations. Two controllers are designed:
a sliding mode controller for robust handling of disturbances and a novel
PID-based controller with gravity compensation integrating linear and
non-linear allocators, designed for computational efficiency. A custom control
allocation strategy is implemented to manage the input-non-affine nature of
these systems, seeking to maximize battery life by minimizing the "Power
Consumption Factor" defined in this study. Moreover, the controllers
effectively managed harsh disturbances and uncertainties. Simulations compare
and analyze the proposed configurations and controllers, majorly considering
their power consumption. Furthermore, we conduct a qualitative comparison to
evaluate the impact of different types of uncertainties on the control system,
highlighting areas for potential model or hardware improvements. The analysis
in this study provides a roadmap for future researchers to design
omniorientational drones based on their design objectives, offering practical
insights into configuration selection and controller design. This research
aligns with the project SAC-1, one of the objectives of Sharif AgRoLab.

</details>


### [54] [SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation](https://arxiv.org/abs/2509.21231)
*Jaehwi Jang,Zhuoheng Wang,Ziyi Zhou,Feiyang Wu,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种名为SEEC的新框架，结合模型增强的强化学习，用于解决双足机器人手臂末端执行器的稳定问题。


<details>
  <summary>Details</summary>
Motivation: 双足机器人由于其高自由度和动态不稳定性，手臂末端执行器的稳定仍具挑战性。传统模型方法依赖精确建模但难以适应实际因素（如摩擦和间隙），而学习方法虽能缓和这些问题却容易过拟合且难以适应新场景。

Method: SEEC框架通过模型引导的强化学习和扰动生成器，学习对下半身扰动的精确补偿，无需额外训练即可适应未知的运动控制器。

Result: 在不同模拟器和Booster T1机器人上的实验表明，SEEC优于基线方法，并能稳健处理多样且高要求的移动-操作任务。

Conclusion: SEEC框架显著提升了末端执行器的稳定性和适应性，展现了在复杂环境中的实用性。

Abstract: Arm end-effector stabilization is essential for humanoid loco-manipulation
tasks, yet it remains challenging due to the high degrees of freedom and
inherent dynamic instability of bipedal robot structures. Previous model-based
controllers achieve precise end-effector control but rely on precise dynamics
modeling and estimation, which often struggle to capture real-world factors
(e.g., friction and backlash) and thus degrade in practice. On the other hand,
learning-based methods can better mitigate these factors via exploration and
domain randomization, and have shown potential in real-world use. However, they
often overfit to training conditions, requiring retraining with the entire
body, and still struggle to adapt to unseen scenarios. To address these
challenges, we propose a novel stable end-effector control (SEEC) framework
with model-enhanced residual learning that learns to achieve precise and robust
end-effector compensation for lower-body induced disturbances through
model-guided reinforcement learning (RL) with a perturbation generator. This
design allows the upper-body policy to achieve accurate end-effector
stabilization as well as adapt to unseen locomotion controllers with no
additional training. We validate our framework in different simulators and
transfer trained policies to the Booster T1 humanoid robot. Experiments
demonstrate that our method consistently outperforms baselines and robustly
handles diverse and demanding loco-manipulation tasks.

</details>


### [55] [FSGlove: An Inertial-Based Hand Tracking System with Shape-Aware Calibration](https://arxiv.org/abs/2509.21242)
*Yutong Li,Jieyi Zhang,Wenqiang Xu,Tutian Tang,Cewu Lu*

Main category: cs.RO

TL;DR: 摘要介绍了FSGlove系统，这是一款基于惯性的手势捕捉系统，能同时追踪48个自由度并重建个性化手部形状，通过DiffHCal校准方法实现高精度运动捕捉。


<details>
  <summary>Details</summary>
Motivation: 现有商业手套在捕捉高自由度和个性化手部形状方面存在不足，尤其是在复杂操作和接触任务中。

Method: FSGlove结合惯性测量单元（IMUs）和DiffHCal校准方法，通过可微分优化与MANO模型集成，实现关节运动学、形状参数和传感器偏差的校准。

Result: 系统在关节角度误差（小于2.7度）、形状重建和接触保真度方面优于商业产品，并通过开源设计兼容现有VR和机器人生态系统。

Conclusion: FSGlove在手部追踪中统一了运动学和接触保真度，填补了人类灵巧性与机器人模仿之间的差距。

Abstract: Accurate hand motion capture (MoCap) is vital for applications in robotics,
virtual reality, and biomechanics, yet existing systems face limitations in
capturing high-degree-of-freedom (DoF) joint kinematics and personalized hand
shape. Commercial gloves offer up to 21 DoFs, which are insufficient for
complex manipulations while neglecting shape variations that are critical for
contact-rich tasks. We present FSGlove, an inertial-based system that
simultaneously tracks up to 48 DoFs and reconstructs personalized hand shapes
via DiffHCal, a novel calibration method. Each finger joint and the dorsum are
equipped with IMUs, enabling high-resolution motion sensing. DiffHCal
integrates with the parametric MANO model through differentiable optimization,
resolving joint kinematics, shape parameters, and sensor misalignment during a
single streamlined calibration. The system achieves state-of-the-art accuracy,
with joint angle errors of less than 2.7 degree, and outperforms commercial
alternatives in shape reconstruction and contact fidelity. FSGlove's
open-source hardware and software design ensures compatibility with current VR
and robotics ecosystems, while its ability to capture subtle motions (e.g.,
fingertip rubbing) bridges the gap between human dexterity and robotic
imitation. Evaluated against Nokov optical MoCap, FSGlove advances hand
tracking by unifying the kinematic and contact fidelity. Hardware design,
software, and more results are available at:
https://sites.google.com/view/fsglove.

</details>


### [56] [RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models](https://arxiv.org/abs/2509.21243)
*Jiyeon Koo,Taewan Cho,Hyunjoon Kang,Eunseom Pyo,Tae Gyun Oh,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: RetoVLA通过重用Vision Transformers中的Register Tokens，提升了轻量级VLA模型的空间推理能力，并在复杂任务中实现了17.1%的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因体积和计算成本高而难以实际部署，且传统的轻量化方法牺牲了关键能力（如空间推理）。RetoVLA试图通过重用Register Tokens解决这一矛盾。

Method: RetoVLA重用Vision Transformers中本被丢弃的Register Tokens，将其注入Action Expert模块，以保留关键的上下文信息。

Result: 在7-DOF机器人手臂上的实验中，RetoVLA在复杂任务中的成功率提升了17.1%。

Conclusion: Register Tokens是未被充分利用的资源，RetoVLA的成功表明其在提升轻量模型空间推理能力方面的潜力。

Abstract: Recent Vision-Language-Action (VLA) models demonstrate remarkable
generalization in robotics but are restricted by their substantial size and
computational cost, limiting real-world deployment. However, conventional
lightweighting methods often sacrifice critical capabilities, particularly
spatial reasoning. This creates a trade-off between efficiency and performance.
To address this challenge, our work reuses Register Tokens, which were
introduced for artifact removal in Vision Transformers but subsequently
discarded. We suppose that these tokens contain essential spatial information
and propose RetoVLA, a novel architecture that reuses them directly by
injecting them into the Action Expert.
  RetoVLA maintains a lightweight structure while leveraging this repurposed
spatial context to enhance reasoning. We demonstrate RetoVLA's effectiveness
through a series of comprehensive experiments. On our custom-built 7-DOF robot
arm, the model achieves a 17.1%p absolute improvement in success rates for
complex manipulation tasks. Our results confirm that reusing Register Tokens
directly enhances spatial reasoning, demonstrating that what was previously
discarded as an artifact is in fact a valuable, unexplored resource for robotic
intelligence. A video demonstration is available at:
https://youtu.be/2CseBR-snZg

</details>


### [57] [BiNoMaP: Learning Category-Level Bimanual Non-Prehensile Manipulation Primitives](https://arxiv.org/abs/2509.21256)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: 该论文提出了一种双机械臂非抓取操作框架BiNoMaP，通过几何感知的后优化算法，从视频演示中提取并优化可执行的操作技能，实现了高效、通用和强泛化能力的操作。


<details>
  <summary>Details</summary>
Motivation: 非抓取操作在机器人领域是一个关键但研究较少的领域，因为其接触多且难以分析。传统方法依赖单臂和外部辅助条件，本文旨在提出一种通用的双机械臂解决方案。

Method: 作者提出了一个三阶段的RL-free框架：1)从视频中提取双机械臂运动轨迹；2)通过几何感知后优化算法将其转化为可行的操作技能；3)参数化这些技能以支持跨类别泛化。

Result: 在多种双机械臂任务和物体类别上验证了BiNoMaP的有效性，展示了其高效性、通用性和强大的泛化能力。

Conclusion: BiNoMaP为非抓取操作提供了一种可行的解决方案，摆脱了对RL和外部条件的依赖，实现了跨类别的泛化能力。

Abstract: Non-prehensile manipulation, encompassing ungraspable actions such as
pushing, poking, and pivoting, represents a critical yet underexplored domain
in robotics due to its contact-rich and analytically intractable nature. In
this work, we revisit this problem from two novel perspectives. First, we move
beyond the usual single-arm setup and the strong assumption of favorable
external dexterity such as walls, ramps, or edges. Instead, we advocate a
generalizable dual-arm configuration and establish a suite of Bimanual
Non-prehensile Manipulation Primitives (BiNoMaP). Second, we depart from the
prevailing RL-based paradigm and propose a three-stage, RL-free framework to
learn non-prehensile skills. Specifically, we begin by extracting bimanual hand
motion trajectories from video demonstrations. Due to visual inaccuracies and
morphological gaps, these coarse trajectories are difficult to transfer
directly to robotic end-effectors. To address this, we propose a geometry-aware
post-optimization algorithm that refines raw motions into executable
manipulation primitives that conform to specific motion patterns. Beyond
instance-level reproduction, we further enable category-level generalization by
parameterizing the learned primitives with object-relevant geometric
attributes, particularly size, resulting in adaptable and general parameterized
manipulation primitives. We validate BiNoMaP across a range of representative
bimanual tasks and diverse object categories, demonstrating its effectiveness,
efficiency, versatility, and superior generalization capability.

</details>


### [58] [\LARGE GMP$^{3}$: Learning-Driven, Bellman-Guided Trajectory Planning for UAVs in Real-Time on SE(3)](https://arxiv.org/abs/2509.21264)
*Babak Salamat,Dominik Mattern,Sebastian-Sven Olzem,Gerhard Elsbacher,Christian Seidel,Andrea M. Tonello*

Main category: cs.RO

TL;DR: ‘​GMP³’是一个多阶段全局路径规划框架，为无人机在复杂环境中生成动态可行的三维轨迹，扩展了传统路径规划到SE(3)李群，并引入改进的Bellman算子支持强化学习策略更新。分布式框架允许代理协同优化路径，并通过DroneManager软件实现实时部署。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决无人机在复杂三维环境中路径规划的挑战，特别是如何同时优化平移运动和旋转动力学，并实现分布式协同规划。

Method: 提出了基于SE(3)李群的路径规划框架‘​GMP³’，改进Bellman算子支持强化学习策略更新，并通过分布式代理共享策略信息；开发DroneManager软件实现与真实无人机的实时交互。

Result: 仿真和实验验证了框架在受限3D环境中的有效性，实现了可靠的避障和平滑可行的轨迹。

Conclusion: ‘​GMP³’能够高效解决无人机在复杂环境中的动态路径规划问题，并通过开源工具促进实际应用。

Abstract: We propose $\text{GMP}^{3}$, a multiphase global path planning framework that
generates dynamically feasible three-dimensional trajectories for unmanned
aerial vehicles (UAVs) operating in cluttered environments. The framework
extends traditional path planning from Euclidean position spaces to the Lie
group $\mathrm{SE}(3)$, allowing joint learning of translational motion and
rotational dynamics. A modified Bellman-based operator is introduced to support
reinforcement learning (RL) policy updates while leveraging prior trajectory
information for improved convergence. $\text{GMP}^{3}$ is designed as a
distributed framework in which agents influence each other and share policy
information along the trajectory: each agent refines its assigned segment and
shares with its neighbors via a consensus-based scheme, enabling cooperative
policy updates and convergence toward a path shaped globally even under
kinematic constraints. We also propose DroneManager, a modular ground control
software that interfaces the planner with real UAV platforms via the MAVLink
protocol, supporting real-time deployment and feedback. Simulation studies and
indoor flight experiments validate the effectiveness of the proposed method in
constrained 3D environments, demonstrating reliable obstacle avoidance and
smooth, feasible trajectories across both position and orientation. The
open-source implementation is available at
https://github.com/Domattee/DroneManager

</details>


### [59] [Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds](https://arxiv.org/abs/2509.21281)
*Luis Augenstein,Noémie Jaquier,Tamim Asfour,Leonel Rozo*

Main category: cs.RO

TL;DR: 论文提出了一种名为GPHDM的新方法，通过结合双曲空间中的动态先验和分类学感知的归纳偏置，生成具有层次结构和时间动态一致性的机器人运动。实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人运动生成模型常忽视运动的层次结构信息，导致生成的运动与底层结构脱节。论文旨在解决这一问题。

Method: 扩展GPDM的动态先验到双曲流形，结合分类学感知的归纳偏置，提出三种新机制：两种概率递归方法和一种基于拉回度量测地线的方法。

Result: 在手抓取分类学的实验中，GPHDM成功编码了底层分类学和时间动态，生成了物理一致的新运动轨迹。

Conclusion: GPHDM有效结合了几何和分类学感知框架，生成的运动既符合层次结构又保持物理一致性。

Abstract: Human-like motion generation for robots often draws inspiration from
biomechanical studies, which often categorize complex human motions into
hierarchical taxonomies. While these taxonomies provide rich structural
information about how movements relate to one another, this information is
frequently overlooked in motion generation models, leading to a disconnect
between the generated motions and their underlying hierarchical structure. This
paper introduces the \ac{gphdm}, a novel approach that learns latent
representations preserving both the hierarchical structure of motions and their
temporal dynamics to ensure physical consistency. Our model achieves this by
extending the dynamics prior of the Gaussian Process Dynamical Model (GPDM) to
the hyperbolic manifold and integrating it with taxonomy-aware inductive
biases. Building on this geometry- and taxonomy-aware frameworks, we propose
three novel mechanisms for generating motions that are both
taxonomically-structured and physically-consistent: two probabilistic recursive
approaches and a method based on pullback-metric geodesics. Experiments on
generating realistic motion sequences on the hand grasping taxonomy show that
the proposed GPHDM faithfully encodes the underlying taxonomy and temporal
dynamics, and generates novel physically-consistent trajectories.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [60] [Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning](https://arxiv.org/abs/2509.20754)
*Yufan Mao,Hanjing Ye,Wenlong Dong,Chengjie Zhang,Hong Zhang*

Main category: cs.AI

TL;DR: Meta-Memory是一种基于大语言模型的机器人记忆系统，能够通过语义和空间模态联合推理高效检索和整合记忆，显著提升了机器人回答空间查询的能力，并在实际环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在复杂环境中高效存储和检索观察记忆，并用于回答人类空间查询的研究挑战。

Method: 提出Meta-Memory，利用大语言模型构建高密度环境记忆表示，并通过语义和空间模态联合推理实现记忆检索和整合。

Result: 在SpaceLocQA和NaVQA基准测试中显著优于现有方法，并在实际机器人平台上验证了其实用性。

Conclusion: Meta-Memory展示了在复杂环境中提升机器人空间推理能力的潜力，并具有实际应用价值。

Abstract: Navigating complex environments requires robots to effectively store
observations as memories and leverage them to answer human queries about
spatial locations, which is a critical yet underexplored research challenge.
While prior work has made progress in constructing robotic memory, few have
addressed the principled mechanisms needed for efficient memory retrieval and
integration. To bridge this gap, we propose Meta-Memory, a large language model
(LLM)-driven agent that constructs a high-density memory representation of the
environment. The key innovation of Meta-Memory lies in its capacity to retrieve
and integrate relevant memories through joint reasoning over semantic and
spatial modalities in response to natural language location queries, thereby
empowering robots with robust and accurate spatial reasoning capabilities. To
evaluate its performance, we introduce SpaceLocQA, a large-scale dataset
encompassing diverse real-world spatial question-answering scenarios.
Experimental results show that Meta-Memory significantly outperforms
state-of-the-art methods on both the SpaceLocQA and the public NaVQA
benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world
robotic platforms, demonstrating its practical utility in complex environments.
Project page: https://itsbaymax.github.io/meta-memory.github.io/ .

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [61] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: SGAligner++是一种基于跨模态和语言辅助的3D场景图对齐方法，通过联合嵌入空间解决异构模态对齐问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D场景图对齐方法在单模态点云数据和不完整/噪声输入下的局限性。

Method: 采用轻量级单模态编码器和基于注意力的融合技术，学习统一的联合嵌入空间。

Result: 在真实数据集上表现优于现有方法40%，且在低重叠和噪声条件下仍能准确对齐。

Conclusion: SGAligner++为视觉定位、3D重建和导航等任务提供了高效且可扩展的解决方案。

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [62] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: SceneWeaver提出了一个基于工具迭代优化的框架，通过语言模型规划和多工具协作，提升室内场景合成的物理合理性、视觉真实性和语义对齐能力。


<details>
  <summary>Details</summary>
Motivation: 现有室内场景合成方法在视觉逼真度、物理一致性和复杂用户指令对齐方面存在不足，需要一种更灵活、通用的解决方案。

Method: 采用语言模型规划器选择生成工具，通过闭环的“推理-行动-反思”设计实现多工具协同优化场景。

Result: 在物理、视觉和语义指标上优于现有方法，并能泛化到复杂场景和多样指令。

Conclusion: SceneWeaver为通用3D环境生成提供了有效框架，具有广泛的应用潜力。

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [63] [4D Computational Ultrasound Imaging of Carotid Artery Flow](https://arxiv.org/abs/2509.20963)
*Yuyang Hu,Michael Brown,Didem Dogan,Mahé Bulot,Maxime Cheppe,Guillaume Ferin,Geert Leus,Antonius F. W. van der Steen,Pieter Kruizinga,Johannes G. Bosch*

Main category: physics.med-ph

TL;DR: 该研究扩展了计算超声成像（cUSi）在4D颈动脉血流成像中的应用，使用240元素矩阵探头，验证了系统在模拟和人体实验中的成像能力。


<details>
  <summary>Details</summary>
Motivation: 探索大孔径、少元素的计算超声成像系统在4D颈动脉血流评估中的可行性。

Method: 采用频率带匹配滤波策略，结合240元素矩阵探头，进行模拟和人体颈动脉实验。

Result: 系统成功重建了颈动脉分叉处的血流结构和局部脉动动力学，验证了其成像能力。

Conclusion: 证明了少元素cUSi系统在4D血流评估中的潜力。

Abstract: Computational ultrasound imaging (cUSi) with few elements and spatial field
encoding can provide high-resolution volumetric B-mode imaging. In this work,
we extend its application to 4D carotid artery (CA) flow imaging using a custom
large-aperture 240-element matrix probe. We implemented a frequency band-based
matched filtering strategy that balances resolution and contrast. The system's
inherent imaging capabilities were evaluated and validated in flow phantom and
human CA experiments. In the phantom study, 3D/4D power Doppler image and
speckle-tracking analyses confirmed the system's ability to resolve flow
structures and hemodynamics. In the human study, the CA bifurcation flow
structure and its local pulsatile flow dynamics were successfully
reconstructed. These results demonstrate the feasibility of using a
large-footprint, few-element cUSi system for 4D CA flow assessment.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [64] [Lightweight MobileNetV1+GRU for ECG Biometric Authentication: Federated and Adversarial Evaluation](https://arxiv.org/abs/2509.20382)
*Dilli Hang Rai,Sabin Kafley*

Main category: cs.CR

TL;DR: 论文提出了一种轻量级深度学习模型（MobileNetV1+GRU）用于ECG生物认证，在模拟可穿戴设备的条件下实现了高精度，但对抗性攻击会导致性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 心电图生物识别技术具有独特性，但在可穿戴设备上的部署面临实时性、隐私和欺骗漏洞等挑战，需要一种高效且安全的解决方案。

Method: 采用MobileNetV1+GRU模型，结合高斯噪声注入和自定义预处理，模拟可穿戴设备的环境和边缘部署。

Result: 在多个数据集上实现了高准确率（最高99.34%），但对抗性攻击下准确率显著下降至0.80%。

Conclusion: 研究强调了联邦学习、对抗性测试以及多样化数据集的重要性，以确保生物识别的安全性和可扩展性。

Abstract: ECG biometrics offer a unique, secure authentication method, yet their
deployment on wearable devices faces real-time processing, privacy, and
spoofing vulnerability challenges. This paper proposes a lightweight deep
learning model (MobileNetV1+GRU) for ECG-based authentication, injection of
20dB Gaussian noise & custom preprocessing. We simulate wearable conditions and
edge deployment using the ECGID, MIT-BIH, CYBHi, and PTB datasets, achieving
accuracies of 99.34%, 99.31%, 91.74%, and 98.49%, F1-scores of 0.9869, 0.9923,
0.9125, and 0.9771, Precision of 0.9866, 0.9924, 0.9180 and 0.9845, Recall of
0.9878, 0.9923, 0.9129, and 0.9756, equal error rates (EER) of 0.0009, 0.00013,
0.0091, and 0.0009, and ROC-AUC values of 0.9999, 0.9999, 0.9985, and 0.9998,
while under FGSM adversarial attacks, accuracy drops from 96.82% to as low as
0.80%. This paper highlights federated learning, adversarial testing, and the
need for diverse wearable physiological datasets to ensure secure and scalable
biometrics.

</details>


### [65] [Differential Privacy of Network Parameters from a System Identification Perspective](https://arxiv.org/abs/2509.20460)
*Andrew Campbell,Anna Scaglione,Hang Liu,Victor Elvira,Sean Peisert,Daniel Arnold*

Main category: cs.CR

TL;DR: 本文研究了在网络信息共享中如何保护隐私免受系统识别攻击，通过差分隐私机制为图滤波器提供隐私保障。


<details>
  <summary>Details</summary>
Motivation: 解决在网络物理系统模拟中共享信息时的隐私保护问题，防止系统识别攻击推断出底层图结构。

Method: 使用差分隐私机制对节点激励进行处理，并将其建模为图滤波器的时间序列输出，分析其谱特性对隐私保障的影响。

Result: 研究表明，差分隐私机制的隐私界限与图滤波器和噪声协方差的谱特性相关，平滑滤波器和低条件数协方差可提供更强的隐私保护。

Conclusion: 通过差分隐私机制可以有效保护图结构的隐私性，同时保持信息的实用性，谱特性是隐私保障的关键因素。

Abstract: This paper addresses the problem of protecting network information from
privacy system identification (SI) attacks when sharing cyber-physical system
simulations. We model analyst observations of networked states as time-series
outputs of a graph filter driven by differentially private (DP) nodal
excitations, with the analyst aiming to infer the underlying graph shift
operator (GSO). Unlike traditional SI, which estimates system parameters, we
study the inverse problem: what assumptions prevent adversaries from
identifying the GSO while preserving utility for legitimate analysis. We show
that applying DP mechanisms to inputs provides formal privacy guarantees for
the GSO, linking the $(\epsilon,\delta)$-DP bound to the spectral properties of
the graph filter and noise covariance. More precisely, for DP Gaussian signals,
the spectral characteristics of both the filter and noise covariance determine
the privacy bound, with smooth filters and low-condition-number covariance
yielding greater privacy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [66] [A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm](https://arxiv.org/abs/2509.20511)
*Oscar Leong,Yann Traonmilin*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架，用于分析基于确定性扩散模型的逆问题算法，证明了其在低维模型集上的收敛性，并应用于低维凸集和低秩高斯混合模型。


<details>
  <summary>Details</summary>
Motivation: 目前生成扩散模型在逆问题中表现出色，但缺乏严格的恢复保证。

Method: 开发理论框架分析确定性扩散算法，将其视为广义投影梯度下降。

Result: 在受限等距性质下，定量收敛速率依赖噪声调度；在低维凸集和非凸低秩高斯混合模型中均能收敛。

Conclusion: 该框架为扩散模型在逆问题中的应用提供了理论支持，适用于非凸问题。

Abstract: Recovering high-dimensional signals from corrupted measurements is a central
challenge in inverse problems. Recent advances in generative diffusion models
have shown remarkable empirical success in providing strong data-driven priors,
but rigorous recovery guarantees remain limited. In this work, we develop a
theoretical framework for analyzing deterministic diffusion-based algorithms
for inverse problems, focusing on a deterministic version of the algorithm
proposed by Kadkhodaie \& Simoncelli \cite{kadkhodaie2021stochastic}. First, we
show that when the underlying data distribution concentrates on a
low-dimensional model set, the associated noise-convolved scores can be
interpreted as time-varying projections onto such a set. This leads to
interpreting previous algorithms using diffusion priors for inverse problems as
generalized projected gradient descent methods with varying projections. When
the sensing matrix satisfies a restricted isometry property over the model set,
we can derive quantitative convergence rates that depend explicitly on the
noise schedule. We apply our framework to two instructive data distributions:
uniform distributions over low-dimensional compact, convex sets and low-rank
Gaussian mixture models. In the latter setting, we can establish global
convergence guarantees despite the nonconvexity of the underlying model set.

</details>


### [67] [Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration](https://arxiv.org/abs/2509.20648)
*Yiyuan Pan,Zhe Liu,Hesheng Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为CERMIC的新方法，通过动态校准内在好奇心与多智能体上下文，增强多智能体探索能力，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有内在好奇心机制在稀疏奖励的多智能体强化学习（MARL）中表现不佳，常混淆环境随机性与有意义的新颖性，且忽略了同伴行为的新颖性。

Method: CERMIC框架通过动态校准内在好奇心与多智能体上下文，过滤噪声信号并生成理论驱动的内在奖励。

Result: 在VMAS、Meltingpot和SMACv2基准测试中，CERMIC显著优于现有算法。

Conclusion: CERMIC通过结合多智能体上下文和理论驱动奖励，有效提升了稀疏奖励环境中的探索性能。

Abstract: Autonomous exploration in complex multi-agent reinforcement learning (MARL)
with sparse rewards critically depends on providing agents with effective
intrinsic motivation. While artificial curiosity offers a powerful
self-supervised signal, it often confuses environmental stochasticity with
meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform
novelty bias, treating all unexpected observations equally. However, peer
behavior novelty, which encode latent task dynamics, are often overlooked,
resulting in suboptimal exploration in decentralized, communication-free MARL
settings. To this end, inspired by how human children adaptively calibrate
their own exploratory behaviors via observing peers, we propose a novel
approach to enhance multi-agent exploration. We introduce CERMIC, a principled
framework that empowers agents to robustly filter noisy surprise signals and
guide exploration by dynamically calibrating their intrinsic curiosity with
inferred multi-agent context. Additionally, CERMIC generates
theoretically-grounded intrinsic rewards, encouraging agents to explore state
transitions with high information gain. We evaluate CERMIC on benchmark suites
including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that
exploration with CERMIC significantly outperforms SoTA algorithms in
sparse-reward environments.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [68] [UAV-Enabled ISAC Systems with Fluid Antennas](https://arxiv.org/abs/2509.21105)
*Wenchao Liu,Xuhui Zhang,Jinke Ren,Weijie Yuan,Changsheng You,Shuangyang Li*

Main category: cs.IT

TL;DR: 该论文提出了一种基于流体天线阵列的无人机集成传感与通信框架，通过优化天线位置、波束形成和无人机轨迹，显著提升了通信和传感性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定天线阵列限制了无人机在集成传感与通信中的潜力，而流体天线技术通过引入空间自由度可以同时提升通信和传感表现。

Method: 论文构建了一个基于流体天线阵列的无人机框架，并通过多目标优化问题最大化通信速率和最小化角度估计误差。采用三时间尺度优化框架，交替优化算法解决非凸问题。

Result: 数值结果表明，该方案显著优于多种基准方案，验证了流体天线技术对无人机集成传感与通信系统的有效性。

Conclusion: 流体天线阵列的引入为无人机集成传感与通信系统提供了显著的性能提升，具有重要的应用前景。

Abstract: Unmanned aerial vehicle (UAV)-enabled integrated sensing and communication
(ISAC) is regarded as a key enabler for next-generation wireless systems.
However, conventional fixed antenna arrays limit the ability of UAVs to fully
exploit their inherent potential. To overcome this limitation, we propose a
UAV-enabled ISAC framework equipped with fluid antenna (FA) arrays, where the
mobility of antenna elements introduces additional spatial degrees of freedom
to simultaneously enhance communication and sensing performance. A
multi-objective optimization problem is formulated to maximize the
communication rates of multiple users while minimizing the Cram\'er-Rao bound
(CRB) for single-target angle estimation. Due to excessively frequent updates
of FA positions may lead to response delays, a three-timescale optimization
framework is developed to jointly design transmit beamforming, FA positions,
and UAV trajectory based on their characteristics. To solve the non-convexity
of the problem, an alternating optimization-based algorithm is developed to
obtain a sub-optimal solution. Numerical results show that the proposed scheme
significantly outperforms various benchmark schemes, validating the
effectiveness of integrating the FA technology into the UAV-enabled ISAC
systems.

</details>


### [69] [Adapt or Regress: Rate-Memory-Compatible Spatially-Coupled Codes](https://arxiv.org/abs/2509.21112)
*Bade Aksoy,Doğukan Özbayrak,Ahmed Hareedy*

Main category: cs.IT

TL;DR: 本文提出了一种名为RMC-SC的可重构SC码，通过概率设计和梯度下降算法优化其性能，显著减少了循环计数并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 在不同的系统中，需要支持多种纠错编码方案以适应不同的信道条件和数据速率。自适应编码设计能够在需要时切换编码，确保可靠性并降低硬件成本。

Method: 通过增加SC码的记忆深度实现速率兼容性，使用梯度下降算法找到新组件的局部最优分布。此外，采用MC$^2$方法进行有限长度优化。

Result: 实验结果表明，与现有方案相比，RMC-SC码显著减少了循环计数并实现了显著的性能提升。

Conclusion: RMC-SC码通过自适应设计和优化算法，在多场景下表现出优异的性能和灵活性。

Abstract: Spatially-coupled (SC) codes are a class of low-density parity-check (LDPC)
codes that have excellent performance thanks to the degrees of freedom they
offer. An SC code is designed by partitioning a base matrix into components,
the number of which implies the code memory, then coupling and lifting them. In
the same system, various error-correction coding schemes are typically needed.
For example, in wireless communication standards, several channel conditions
and data rates should be supported. In storage and computing systems, stronger
codes should be adopted as the device ages. Adaptive code design enables
switching from one code to another when needed, ensuring reliability while
reducing hardware cost. In this paper, we introduce a class of reconfigurable
SC codes named rate-memory-compatible SC (RMC-SC) codes, which we design
probabilistically. In particular, rate compatibility in RMC-SC codes is
achieved via increasing the SC code memory, which also makes the codes
memory-compatible and improves performance. We express the expected number of
short cycles in the SC code protograph as a function of the fixed probability
distribution characterizing the already-designed SC code as well as the unknown
distribution characterizing the additional components. We use the
gradient-descent algorithm to find a locally-optimal distribution, in terms of
cycle count, for the new components. The method can be recursively used to
design any number of SC codes needed, and we show how to extend it to other
cases. Next, we perform the finite-length optimization using a Markov chain
Monte Carlo (MC$^2$) approach that we update to design the proposed RMC-SC
codes. Experimental results demonstrate significant reductions in cycle counts
and remarkable performance gains achieved by RMC-SC codes compared with a
literature-based straightforward scheme.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [70] [Large Pre-Trained Models for Bimanual Manipulation in 3D](https://arxiv.org/abs/2509.20579)
*Hanna Yurchyk,Wei-Di Chang,Gregory Dudek,David Meger*

Main category: cs.CV

TL;DR: 将预训练Vision Transformer的注意力图整合到体素表示中，以提升双手机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 利用自监督ViT模型的注意力图作为像素级显著性分数，为3D体素网格提供语义线索，改进机器人操作策略。

Method: 从DINOv2提取注意力图，将其转化为3D体素网格的语义线索，并整合到行为克隆策略中。

Result: 在RLBench双手机器人基准测试中，实现了8.2%的绝对提升和21.9%的相对增益。

Conclusion: 注意力引导的特征化能够显著提升基于体素的策略性能。

Abstract: We investigate the integration of attention maps from a pre-trained Vision
Transformer into voxel representations to enhance bimanual robotic
manipulation. Specifically, we extract attention maps from DINOv2, a
self-supervised ViT model, and interpret them as pixel-level saliency scores
over RGB images. These maps are lifted into a 3D voxel grid, resulting in
voxel-level semantic cues that are incorporated into a behavior cloning policy.
When integrated into a state-of-the-art voxel-based policy, our
attention-guided featurization yields an average absolute improvement of 8.2%
and a relative gain of 21.9% across all tasks in the RLBench bimanual
benchmark.

</details>


### [71] [Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences](https://arxiv.org/abs/2509.20906)
*Julius Pesonen,Arno Solin,Eija Honkavaara*

Main category: cs.CV

TL;DR: 论文提出了一种基于粒子滤波的3D物体定位方法，适用于远距离或计算资源受限的场景，并在无人机野火监测中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对远距离物体或计算资源受限的任务，传统的密集深度估计或3D场景重建方法不可行，因此需要一种更灵活的解决方案。

Method: 使用粒子滤波技术，结合相机位姿和图像分割数据，适用于单目标和多目标场景。

Result: 通过3D模拟和无人机图像分割序列的实验，验证了粒子滤波在这些场景中的有效性，并展示了其在无人机野火监测中的应用潜力。

Conclusion: 粒子滤波方法具有灵活性，能够在不依赖特定检测方法的情况下解决实际定位问题，为无人机监测任务提供了可行的技术方案。

Abstract: 3D object localisation based on a sequence of camera measurements is
essential for safety-critical surveillance tasks, such as drone-based wildfire
monitoring. Localisation of objects detected with a camera can typically be
solved with dense depth estimation or 3D scene reconstruction. However, in the
context of distant objects or tasks limited by the amount of available
computational resources, neither solution is feasible. In this paper, we show
that the task can be solved using particle filters for both single and multiple
target scenarios. The method was studied using a 3D simulation and a
drone-based image segmentation sequence with global navigation satellite system
(GNSS)-based camera pose estimates. The results showed that a particle filter
can be used to solve practical localisation tasks based on camera poses and
image segments in these situations where other solutions fail. The particle
filter is independent of the detection method, making it flexible for new
tasks. The study also demonstrates that drone-based wildfire monitoring can be
conducted using the proposed method paired with a pre-existing image
segmentation model.

</details>
