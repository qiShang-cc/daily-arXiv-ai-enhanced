{"id": "2507.07239", "pdf": "https://arxiv.org/pdf/2507.07239", "abs": "https://arxiv.org/abs/2507.07239", "authors": ["Jorge R. Colon-Berrios", "Jason M. Merlo", "Jeffrey A. Nanzer"], "title": "Three-Dimensional Millimeter-Wave Imaging Using Active Incoherent Fourier Processing and Pulse Compression", "categories": ["eess.SP"], "comment": null, "summary": "We present a novel three-dimensional (3D) imaging approach that combines\ntwo-dimensional spatial Fourier-domain imaging techniques with traditional\nradar pulse compression to recover both cross-range and down-range scene\ninformation. The imaging system employs four transmitters, three of which emit\nspatially and temporally incoherent noise signals, while the fourth transmits a\nknown linear frequency modulated (LFM) pulsed signal. The spatial incoherence\nof the noise signals enables sampling of the 2D spatial Fourier spectrum of the\nscene from which two-dimensional cross-range (azimuth and elevation) images can\nbe formed via interferometric processing. Simultaneously, the LFM signal\nenables high-resolution downrange imaging through matched filtering. The\nreceived signals consist of a superposition of the noise sources and the known\npulse allowing for joint recovery of all three dimensions. We describe the\nsystem architecture and waveform design, and demonstrate the imaging technique\nusing both simulations with a linear array and experimental data from a 38 GHz\nactive incoherent millimeter-wave imaging system with 23-element randomized\narray. Results show the reconstruction of targets in three dimensions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e8c\u7ef4\u7a7a\u95f4\u5085\u91cc\u53f6\u57df\u6210\u50cf\u6280\u672f\u548c\u4f20\u7edf\u96f7\u8fbe\u8109\u51b2\u538b\u7f29\u7684\u4e09\u7ef4\u6210\u50cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a7a\u95f4\u4e0d\u76f8\u5e72\u566a\u58f0\u4fe1\u53f7\u548c\u5df2\u77e5\u7684\u7ebf\u6027\u8c03\u9891\u8109\u51b2\u4fe1\u53f7\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u4e09\u7ef4\u76ee\u6807\u91cd\u5efa\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u83b7\u53d6\u9ad8\u5206\u8fa8\u7387\u7684\u8de8\u8303\u56f4\u548c\u4e0b\u8303\u56f4\u573a\u666f\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u4e09\u7ef4\u6210\u50cf\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u56db\u79cd\u53d1\u5c04\u5668\uff0c\u5176\u4e2d\u4e09\u4e2a\u53d1\u5c04\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0d\u76f8\u5e72\u7684\u566a\u58f0\u4fe1\u53f7\uff0c\u7b2c\u56db\u4e2a\u53d1\u5c04\u5df2\u77e5\u7684\u7ebf\u6027\u8c03\u9891\u8109\u51b2\u4fe1\u53f7\u3002\u901a\u8fc7\u5e72\u6d89\u5904\u7406\u548c\u5339\u914d\u6ee4\u6ce2\u5b9e\u73b0\u4e8c\u7ef4\u8de8\u8303\u56f4\u548c\u4e00\u7ef4\u4e0b\u8303\u56f4\u7684\u8054\u5408\u6210\u50cf\u3002", "result": "\u4eff\u771f\u548c\u5b9e\u9a8c\u6570\u636e\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6210\u529f\u91cd\u5efa\u4e09\u7ef4\u76ee\u6807\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6280\u672f\u4e3a\u4e09\u7ef4\u6210\u50cf\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.07285", "pdf": "https://arxiv.org/pdf/2507.07285", "abs": "https://arxiv.org/abs/2507.07285", "authors": ["Kavian Zirak", "Mohammadreza F. Imani"], "title": "A RIS-Enabled Computational Radar Coincidence Imaging", "categories": ["eess.SP"], "comment": null, "summary": "This paper introduces an innovative imaging method using reconfigurable\nintelligent surfaces (RISs) by combining radar coincidence imaging (RCI) and\ncomputational imaging techniques. In the proposed framework, RISs\nsimultaneously redirect beams toward a desired region of interest (ROI). The\ninterference of these beams forms spatially diverse speckle patterns that carry\ninformation about the entire ROI. As a result, this method can take advantage\nof the benefits of both random patterns and spotlight imaging. Since the\nspeckle pattern is formed by directive beams (instead of random patterns\ntypically used in computational imaging), this approach results in a higher\nsignal-to-noise ratio (SNR) and reduced clutter. In contrast to raster\nscanning, which requires the number of measurements to be at least equal to the\nnumber of unknowns, our proposed approach follows a computational imaging\nframework and can obtain high-quality images even when only a few measurements\nare taken. Using numerical simulation, we demonstrate this method's\ncapabilities and contrast it against other conventional techniques. The\nproposed imaging approach can be applied to security screening, wireless user\ntracking, and activity recognition.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408RCI\u548c\u8ba1\u7b97\u6210\u50cf\u6280\u672f\u7684RIS\u6210\u50cf\u65b9\u6cd5\uff0c\u5229\u7528\u5b9a\u5411\u6ce2\u675f\u751f\u6210\u7a7a\u95f4\u591a\u6837\u7684\u6563\u6591\u56fe\u6848\uff0c\u5b9e\u73b0\u9ad8\u4fe1\u566a\u6bd4\u548c\u4f4e\u6742\u6ce2\u7684\u6210\u50cf\u6548\u679c\u3002", "motivation": "\u65e8\u5728\u7ed3\u5408RIS\u548c\u8ba1\u7b97\u6210\u50cf\u6280\u672f\uff0c\u89e3\u51b3\u4f20\u7edf\u6210\u50cf\u65b9\u6cd5\u4e2d\u6d4b\u91cf\u6b21\u6570\u591a\u3001\u4fe1\u566a\u6bd4\u4f4e\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6210\u50cf\u3002", "method": "\u901a\u8fc7RIS\u540c\u65f6\u5c06\u6ce2\u675f\u91cd\u5b9a\u5411\u5230\u76ee\u6807\u533a\u57df\uff0c\u5229\u7528\u6ce2\u675f\u5e72\u6d89\u751f\u6210\u6563\u6591\u56fe\u6848\uff0c\u7ed3\u5408\u8ba1\u7b97\u6210\u50cf\u6846\u67b6\u8fdb\u884c\u56fe\u50cf\u91cd\u5efa\u3002", "result": "\u6570\u503c\u6a21\u62df\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5c11\u91cf\u6d4b\u91cf\u4e0b\u5373\u53ef\u83b7\u5f97\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u4e14\u4fe1\u566a\u6bd4\u9ad8\u3001\u6742\u6ce2\u5c11\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5b89\u5168\u7b5b\u67e5\u3001\u65e0\u7ebf\u7528\u6237\u8ddf\u8e2a\u548c\u6d3b\u52a8\u8bc6\u522b\u7b49\u9886\u57df\uff0c\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.07331", "pdf": "https://arxiv.org/pdf/2507.07331", "abs": "https://arxiv.org/abs/2507.07331", "authors": ["Anurag Pallaprolu", "Winston Hurst", "Yasamin Mostofi"], "title": "mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "In this paper, we present a novel framework for extracting underlying crowd\nmotion patterns and inferring crowd semantics using mmWave radar. First, our\nproposed signal processing pipeline combines optical flow estimation concepts\nfrom vision with novel statistical and morphological noise filtering to\ngenerate high-fidelity mmWave flow fields - compact 2D vector representations\nof crowd motion. We then introduce a novel approach that transforms these\nfields into directed geometric graphs, where edges capture dominant flow\ncurrents, vertices mark crowd splitting or merging, and flow distribution is\nquantified across edges. Finally, we show that by analyzing the local Jacobian\nand computing the corresponding curl and divergence, we can extract key crowd\nsemantics for both structured and diffused crowds. We conduct 21 experiments on\ncrowds of up to (and including) 20 people across 3 areas, using commodity\nmmWave radar. Our framework achieves high-fidelity graph reconstruction of the\nunderlying flow structure, even for complex crowd patterns, demonstrating\nstrong spatial alignment and precise quantitative characterization of flow\nsplit ratios. Finally, our curl and divergence analysis accurately infers key\ncrowd semantics, e.g., abrupt turns, boundaries where flow directions shift,\ndispersions, and gatherings. Overall, these findings validate our framework,\nunderscoring its potential for various crowd analytics applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6beb\u7c73\u6ce2\u96f7\u8fbe\u63d0\u53d6\u4eba\u7fa4\u8fd0\u52a8\u6a21\u5f0f\u548c\u63a8\u65ad\u8bed\u4e49\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u4fe1\u53f7\u5904\u7406\u548c\u51e0\u4f55\u56fe\u5206\u6790\u6280\u672f\uff0c\u6210\u529f\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6beb\u7c73\u6ce2\u96f7\u8fbe\u6280\u672f\uff0c\u9ad8\u6548\u63d0\u53d6\u548c\u5206\u6790\u4eba\u7fa4\u8fd0\u52a8\u6a21\u5f0f\u53ca\u5176\u8bed\u4e49\u4fe1\u606f\uff0c\u4e3a\u4eba\u7fa4\u5206\u6790\u5e94\u7528\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5149\u6d41\u4f30\u8ba1\u548c\u566a\u58f0\u8fc7\u6ee4\u7684\u4fe1\u53f7\u5904\u7406\u6d41\u7a0b\uff0c\u751f\u6210\u9ad8\u4fdd\u771f\u7684\u6beb\u7c73\u6ce2\u6d41\u573a\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u6709\u5411\u51e0\u4f55\u56fe\uff0c\u901a\u8fc7\u96c5\u53ef\u6bd4\u5206\u6790\u63d0\u53d6\u8bed\u4e49\u3002", "result": "\u5728\u591a\u8fbe20\u4eba\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6846\u67b6\u6210\u529f\u91cd\u5efa\u4e86\u590d\u6742\u7684\u6d41\u7ed3\u6784\uff0c\u5e76\u80fd\u51c6\u786e\u63a8\u65ad\u4eba\u7fa4\u8bed\u4e49\uff08\u5982\u6025\u8f6c\u5f2f\u3001\u5206\u6563\u7b49\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4eba\u7fa4\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.07474", "pdf": "https://arxiv.org/pdf/2507.07474", "abs": "https://arxiv.org/abs/2507.07474", "authors": ["Ruhui Zhang", "Wei Lin", "Binbin Chen"], "title": "Featureless Wireless Communications using Enhanced Autoencoder", "categories": ["eess.SP"], "comment": null, "summary": "Artificial intelligence (AI) techniques, particularly autoencoders (AEs),\nhave gained significant attention in wireless communication systems. This paper\ninvestigates using an AE to generate featureless signals with a low probability\nof detection and interception (LPD/LPI). Firstly, we introduce a novel loss\nfunction that adds a KL divergence term to the categorical cross entropy,\nenhancing the noise like characteristics of AE-generated signals while\npreserving block error rate (BLER). Secondly, to support long source message\nblocks for the AE's inputs, we replace one-hot inputs of source blocks with\nbinary inputs pre-encoded by conventional error correction coding schemes. The\nAE's outputs are then decoded back to the source blocks using the same scheme.\nThis design enables the AE to learn the coding structure, yielding superior\nBLER performance on coded blocks and the BLER of the source blocks is further\ndecreased by the error correction decoder. Moreover, we also validate the AE\nbased communication system in the over-the-air communication. Experimental\nresults demonstrate that our proposed methods improve the featureless\nproperties of AE signals and significantly reduce the BLER of message blocks,\nunderscoring the promise of our AE-based approach for secure and reliable\nwireless communication systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5229\u7528\u81ea\u52a8\u7f16\u7801\u5668\uff08AE\uff09\u751f\u6210\u65e0\u7279\u5f81\u4fe1\u53f7\u4ee5\u5b9e\u73b0\u4f4e\u68c0\u6d4b\u548c\u62e6\u622a\u6982\u7387\uff08LPD/LPI\uff09\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u635f\u5931\u51fd\u6570\u548c\u4e8c\u8fdb\u5236\u8f93\u5165\u8bbe\u8ba1\uff0cAE\u4fe1\u53f7\u7684\u7279\u5f81\u6a21\u7cca\u6027\u548c\u8bef\u7801\u7387\uff08BLER\uff09\u6027\u80fd\u5f97\u5230\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5728\u5b9e\u9645\u901a\u4fe1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u751f\u6210\u96be\u4ee5\u68c0\u6d4b\u548c\u62e6\u622a\u7684\u4fe1\u53f7\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u81ea\u52a8\u7f16\u7801\u5668\uff08AE\uff09\u56e0\u5176\u5728\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u6f5c\u529b\uff0c\u6210\u4e3a\u7814\u7a76\u7684\u7126\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408KL\u6563\u5ea6\u7684\u65b0\u635f\u5931\u51fd\u6570\uff0c\u589e\u5f3a\u4e86\u4fe1\u53f7\u7684\u566a\u58f0\u7279\u6027\uff1b\u91c7\u7528\u4e8c\u8fdb\u5236\u8f93\u5165\u4ee3\u66ff\u72ec\u70ed\u7f16\u7801\uff0c\u652f\u6301\u957f\u6e90\u6d88\u606f\u5757\u7684\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4fe1\u53f7\u7684\u65e0\u7279\u5f81\u6027\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86BLER\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b89\u5168\u548c\u53ef\u9760\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8eAE\u7684\u65b9\u6cd5\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u7684LPD/LPI\u6027\u80fd\u548cBLER\u8868\u73b0\uff0c\u4e3a\u5b89\u5168\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.07567", "pdf": "https://arxiv.org/pdf/2507.07567", "abs": "https://arxiv.org/abs/2507.07567", "authors": ["Reza Ghasemi Alavicheh", "Thomas Feys", "MD Arifur Rahman", "Fran\u00e7ois Rottenberg"], "title": "Leveraging Power Amplifier Distortion for Physical Layer Security", "categories": ["eess.SP"], "comment": null, "summary": "This paper introduces a new approach to physical layer security (PLS) by\nleveraging power amplifier (PA) nonlinear distortion through distortion-aware\nprecoding. While some conventional PLS techniques inject artificial noise\northogonal to legitimate channels, we demonstrate that inherent PA\nnonlinearities typically considered undesirable can be exploited to enhance\nsecurity. The zero 3rd order (Z3RO) precoder applies a negative polarity to\nseveral antennas to cancel the PA distortion at the user location, resulting in\ndistortion being transmitted in non-user locations. Redirecting the distortion\nto non-user locations creates interference for potential eavesdroppers,\nlowering their signal-to-noise-and-distortion ratio (SNDR). Numerical\nsimulations reveal that the Z3RO precoder achieves up to a $2.5\\times$\nimprovement in secrecy rate compared to conventional maximum ratio transmission\n(MRT) precoding under a $10\\%$ outage probability, SNR of $32$ dB and $-5$ dB\ninput back-off (IBO) where the PAs enter the saturation regime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u529f\u7387\u653e\u5927\u5668\u975e\u7ebf\u6027\u5931\u771f\u7684\u7269\u7406\u5c42\u5b89\u5168\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7Z3RO\u9884\u7f16\u7801\u5668\u663e\u8457\u63d0\u5347\u4fdd\u5bc6\u7387\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u5c42\u5b89\u5168\u6280\u672f\u4f9d\u8d56\u4eba\u5de5\u566a\u58f0\u6ce8\u5165\uff0c\u800c\u672c\u6587\u63d0\u51fa\u5229\u7528\u901a\u5e38\u88ab\u8ba4\u4e3a\u6709\u5bb3\u7684\u529f\u7387\u653e\u5927\u5668\u975e\u7ebf\u6027\u5931\u771f\u6765\u589e\u5f3a\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528Z3RO\u9884\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5bf9\u591a\u4e2a\u5929\u7ebf\u65bd\u52a0\u8d1f\u6781\u6027\u4ee5\u6d88\u9664\u7528\u6237\u4f4d\u7f6e\u7684\u5931\u771f\uff0c\u5c06\u5931\u771f\u5bfc\u5411\u975e\u7528\u6237\u4f4d\u7f6e\u4ee5\u5e72\u6270\u6f5c\u5728\u7a83\u542c\u8005\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0cZ3RO\u9884\u7f16\u7801\u5668\u6bd4\u4f20\u7edfMRT\u9884\u7f16\u7801\u4fdd\u5bc6\u7387\u63d0\u53472.5\u500d\u3002", "conclusion": "\u529f\u7387\u653e\u5927\u5668\u7684\u975e\u7ebf\u6027\u7279\u6027\u53ef\u4ee5\u88ab\u6709\u6548\u5229\u7528\u4ee5\u589e\u5f3a\u7269\u7406\u5c42\u5b89\u5168\u6027\u3002"}}
{"id": "2507.07643", "pdf": "https://arxiv.org/pdf/2507.07643", "abs": "https://arxiv.org/abs/2507.07643", "authors": ["Seonghoon Yoo", "Jaemin Jung", "Seongah Jeong", "Jinkyu Kang", "Markku Juntti", "Joonhyuk Kang"], "title": "RIS-assisted ISAC Systems for Industrial Revolution 6.0: Exploring the Near-field and Far-field Coexistence", "categories": ["eess.SP"], "comment": null, "summary": "The Industrial Internet of Things (IIoT) has emerged as a key technology for\nrealizing the vision of Industry 6.0, requiring the seamless integration of\ndiverse connected devices. In particular, integrated sensing and communication\n(ISAC) plays a critical role in supporting real-time control and automation\nwithin IIoT systems. In this paper, we explore reconfigurable intelligent\nsurface (RIS)-assisted ISAC systems for IIoT in the coexistence of near-field\nand far-field regions. The system consists of a full-duplex access point (AP),\na RIS and multiple IIoT devices, where the near-field devices simultaneously\nperform sensing and communication, while the far-field devices rely on a\nRIS-assisted communication. To enhance spectral efficiency for both sensing and\ncommunication functionalities, we consider the use of both traditional\nsensing-only (SO) and ISAC frequency bands. Moreover, uplink non-orthogonal\nmultiple access (NOMA) is employed to facilitate the sequential decoding of\nsuperimposed communication and sensing signals from IIoT devices. To maximize\nsensing accuracy in terms of Cram${\\Grave{\\textrm{e}}}$r-Rao bound (CRB), we\nformulate a joint optimization of RIS phase shift, bandwidth splitting ratio\nand receive beamforming vector subject to the minimum data rate requirements of\nIIoT devices and resource budget constraints. The algorithmic solution is\ndeveloped via the successive convex approximation (SCA)-based alternating\noptimization (AO) method with the semi-definite relaxation (SDR) technique.\nNumerical results demonstrate that the proposed method significantly\noutperforms conventional methods relying solely on either ISAC or SO band by\nachieving superior performance across RIS and device configurations, while\nensuring robust ISAC performance under the near-field and far-field coexistence\nscenarios.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u5de5\u4e1a\u7269\u8054\u7f51\u4e2d\u5229\u7528\u667a\u80fd\u53ef\u91cd\u6784\u8868\u9762\u8f85\u52a9\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\uff0c\u4f18\u5316\u9891\u8c31\u6548\u7387\u5e76\u63d0\u5347\u611f\u77e5\u51c6\u786e\u6027\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u9700\u8981\u9ad8\u6548\u7387\u548c\u5b9e\u65f6\u63a7\u5236\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6280\u672f\uff0c\u4ee5\u652f\u6301\u8fdc\u573a\u548c\u8fd1\u573a\u8bbe\u5907\u7684\u540c\u65f6\u8fd0\u884c\u3002", "method": "\u5229\u7528\u667a\u80fd\u53ef\u91cd\u6784\u8868\u9762\u3001\u9891\u8c31\u5171\u4eab\u548cNOMA\u6280\u672f\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8d44\u6e90\u5206\u914d\u548c\u63a5\u6536\u6ce2\u675f\u6210\u5f62\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u611f\u77e5\u51c6\u786e\u6027\u548c\u901a\u4fe1\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u5e94\u591a\u79cd\u8bbe\u5907\u914d\u7f6e\u3002", "conclusion": "\u667a\u80fd\u53ef\u91cd\u6784\u8868\u9762\u8f85\u52a9\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u5728\u5de5\u4e1a\u7269\u8054\u7f51\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u8fdc\u573a\u548c\u8fd1\u573a\u5171\u5b58\u573a\u666f\u3002"}}
{"id": "2507.07647", "pdf": "https://arxiv.org/pdf/2507.07647", "abs": "https://arxiv.org/abs/2507.07647", "authors": ["Shenghua Hu", "Guangyang Zeng", "Wenchao Xue", "Haitao Fang", "Biqiang Mu"], "title": "Consistent and Asymptotically Efficient Localization from Bearing-only Measurements", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": null, "summary": "We study the problem of signal source localization using bearing-only\nmeasurements. Initially, we present easily verifiable geometric conditions for\nsensor deployment to ensure the asymptotic identifiability of the model and\ndemonstrate the consistency and asymptotic efficiency of the maximum likelihood\n(ML) estimator. However, obtaining the ML estimator is challenging due to its\nassociation with a non-convex optimization problem. To address this, we propose\na two-step estimator that shares the same asymptotic properties as the ML\nestimator while offering low computational complexity, linear in the number of\nmeasurements. The primary challenge lies in obtaining a preliminary consistent\nestimator in the first step. To achieve this, we construct a linear\nleast-squares problem through algebraic operations on the measurement nonlinear\nmodel to first obtain a biased closed-form solution. We then eliminate the bias\nusing the data to yield an asymptotically unbiased and consistent estimator.\nThe key to this process is obtaining a consistent estimator of the variance of\nthe sine of the noise by taking the reciprocal of the maximum eigenvalue of a\nspecially constructed matrix from the data. In the second step, we perform a\nsingle Gauss-Newton iteration using the preliminary consistent estimator as the\ninitial value, achieving the same asymptotic properties as the ML estimator.\nFinally, simulation results demonstrate the superior performance of the\nproposed two-step estimator for large sample sizes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u65b9\u4f4d\u89d2\u6d4b\u91cf\u7684\u4fe1\u53f7\u6e90\u5b9a\u4f4d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u6b65\u4f30\u8ba1\u5668\uff0c\u5177\u6709\u4e0e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u76f8\u540c\u7684\u6e10\u8fd1\u6027\u8d28\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\u3002", "motivation": "\u89e3\u51b3\u4fe1\u53f7\u6e90\u5b9a\u4f4d\u95ee\u9898\u4e2d\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u7684\u975e\u51f8\u4f18\u5316\u96be\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u9ad8\u6548\u4e14\u8ba1\u7b97\u7b80\u5355\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e24\u6b65\u4f30\u8ba1\u5668\uff1a\u7b2c\u4e00\u6b65\u901a\u8fc7\u4ee3\u6570\u64cd\u4f5c\u6784\u5efa\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u5f97\u5230\u504f\u7f6e\u7684\u95ed\u5f0f\u89e3\u5e76\u6d88\u9664\u504f\u7f6e\uff1b\u7b2c\u4e8c\u6b65\u4ee5\u8be5\u89e3\u4e3a\u521d\u59cb\u503c\u8fdb\u884c\u5355\u6b21\u9ad8\u65af-\u725b\u987f\u8fed\u4ee3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u4e24\u6b65\u4f30\u8ba1\u5668\u5728\u5927\u6837\u672c\u91cf\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u6e10\u8fd1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.07692", "pdf": "https://arxiv.org/pdf/2507.07692", "abs": "https://arxiv.org/abs/2507.07692", "authors": ["Mohammad Ali Vahedifar", "Qi Zhang"], "title": "Signal Prediction for Loss Mitigation in Tactile Internet: A Leader-Follower Game-Theoretic Approach", "categories": ["eess.SP"], "comment": "This work has been accepted for publication in the IEEE Machine\n  Learning and Signal Processing Conference (MLSP 2025)", "summary": "Tactile Internet (TI) requires achieving ultra-low latency and highly\nreliable packet delivery for haptic signals. In the presence of packet loss and\ndelay, the signal prediction method provides a viable solution for recovering\nthe missing signals. To this end, we introduce the Leader-Follower (LeFo)\napproach based on a cooperative Stackelberg game, which enables both users and\nrobots to learn and predict actions. With accurate prediction, the\nteleoperation system can safely relax its strict delay requirements. Our method\nachieves high prediction accuracy, ranging from 80.62% to 95.03% for remote\nrobot signals at the Human ($H$) side and from 70.44% to 89.77% for human\noperation signals at the remote Robot ($R$) side. We also establish an upper\nbound for maximum signal loss using Taylor Expansion, ensuring robustness.", "AI": {"tldr": "\u901a\u8fc7\u57fa\u4e8eStackelberg\u535a\u5f08\u7684Leader-Follower\u65b9\u6cd5\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u89e6\u89c9\u4fe1\u53f7\u9884\u6d4b\uff0c\u964d\u4f4e\u5ef6\u8fdf\u8981\u6c42\u3002", "motivation": "\u5728\u5b58\u5728\u6570\u636e\u5305\u4e22\u5931\u548c\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u9760\u7684\u4fe1\u53f7\u9884\u6d4b\u65b9\u6cd5\u4ee5\u6062\u590d\u4e22\u5931\u7684\u4fe1\u53f7\u3002", "method": "\u63d0\u51faLeader-Follower (LeFo)\u65b9\u6cd5\uff0c\u57fa\u4e8e\u534f\u4f5cStackelberg\u535a\u5f08\uff0c\u4f7f\u53cc\u65b9\u7528\u6237\u548c\u673a\u5668\u4eba\u5b66\u4e60\u548c\u9884\u6d4b\u52a8\u4f5c\u3002", "result": "\u9884\u6d4b\u51c6\u786e\u7387\u5728\u4eba\u7c7b\u7aef\u4e3a80.62%-95.03%\uff0c\u673a\u5668\u4eba\u7aef\u4e3a70.44%-89.77%\u3002\u901a\u8fc7\u6cf0\u52d2\u5c55\u5f00\u5efa\u7acb\u4e86\u4fe1\u53f7\u4e22\u5931\u7684\u4e0a\u9650\u3002", "conclusion": "LeFo\u65b9\u6cd5\u901a\u8fc7\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u89e6\u89c9\u4fe1\u53f7\u6062\u590d\u65b9\u6848\uff0c\u964d\u4f4e\u4e86\u7cfb\u7edf\u7684\u5ef6\u8fdf\u8981\u6c42\u3002"}}
{"id": "2507.07832", "pdf": "https://arxiv.org/pdf/2507.07832", "abs": "https://arxiv.org/abs/2507.07832", "authors": ["Xinyi Lin", "Peizheng Li", "Adnan Aijaz"], "title": "Flying Base Stations for Offshore Wind Farm Monitoring and Control: Holistic Performance Evaluation and Optimization", "categories": ["eess.SP"], "comment": "Accepted by PIMRC 2025", "summary": "Ensuring reliable and low-latency communication in offshore wind farms is\ncritical for efficient monitoring and control, yet remains challenging due to\nthe harsh environment and lack of infrastructure. This paper investigates a\nflying base station (FBS) approach for wide-area monitoring and control in the\nUK Hornsea offshore wind farm project. By leveraging mobile, flexible FBS\nplatforms in the remote and harsh offshore environment, the proposed system\noffers real-time connectivity for turbines without the need for deploying\npermanent infrastructure at the sea. We develop a detailed and practical\nend-to-end latency model accounting for five key factors: flight duration,\nconnection establishment, turbine state information upload, computational\ndelay, and control transmission, to provide a holistic perspective often\nmissing in prior studies. Furthermore, we combine trajectory planning,\nbeamforming, and resource allocation into a multi-objective optimization\nframework for the overall latency minimization, specifically designed for\nlarge-scale offshore wind farm deployments. Simulation results verify the\neffectiveness of our proposed method in minimizing latency and enhancing\nefficiency in FBS-assisted offshore monitoring across various power levels,\nwhile consistently outperforming baseline designs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u6076\u52a3\u7684\u79bb\u5cb8\u98ce\u7535\u573a\u73af\u5883\u4e2d\u4f7f\u7528\u98de\u884c\u57fa\u7ad9\uff08FBS\uff09\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u4ee5\u51cf\u5c11\u5ef6\u8fdf\uff0c\u5e76\u5728\u6a21\u62df\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u79bb\u5cb8\u98ce\u7535\u573a\u9700\u8981\u53ef\u9760\u7684\u5b9e\u65f6\u901a\u4fe1\u4ee5\u5b9e\u73b0\u9ad8\u6548\u76d1\u63a7\uff0c\u4f46\u7531\u4e8e\u73af\u5883\u6076\u52a3\u4e14\u7f3a\u4e4f\u57fa\u7840\u8bbe\u65bd\uff0c\u8fd9\u4e00\u9700\u6c42\u96be\u4ee5\u6ee1\u8db3\u3002", "method": "\u901a\u8fc7\u98de\u884c\u57fa\u7ad9\uff08FBS\uff09\u5e73\u53f0\uff0c\u7ed3\u5408\u8f68\u8ff9\u89c4\u5212\u3001\u6ce2\u675f\u6210\u5f62\u548c\u8d44\u6e90\u5206\u914d\u7684\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u51cf\u5c11\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u529f\u7387\u6c34\u5e73\u4e0b\u5747\u80fd\u6709\u6548\u51cf\u5c11\u5ef6\u8fdf\u5e76\u63d0\u5347\u6548\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u8bbe\u8ba1\u3002", "conclusion": "FBS\u8f85\u52a9\u7684\u79bb\u5cb8\u76d1\u63a7\u7cfb\u7edf\u662f\u89e3\u51b3\u6076\u52a3\u73af\u5883\u4e0b\u901a\u4fe1\u95ee\u9898\u7684\u53ef\u884c\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.05683", "pdf": "https://arxiv.org/pdf/2507.05683", "abs": "https://arxiv.org/abs/2507.05683", "authors": ["Steven Duplij", "Qiang Guo"], "title": "Polyadic encryption", "categories": ["cs.CR", "cs.IT", "eess.SP", "math-ph", "math.IT", "math.MP", "math.RA"], "comment": "revtex 4.2, 9 pages", "summary": "A novel original procedure of encryption/decryption based on the polyadic\nalgebraic structures and on signal processing methods is proposed. First, we\nuse signals with integer amplitudes to send information. Then we use polyadic\ntechniques to transfer the plaintext into series of special integers. The\nreceiver restores the plaintext using special rules and systems of equations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5143\u4ee3\u6570\u7ed3\u6784\u548c\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u7684\u52a0\u5bc6/\u89e3\u5bc6\u65b0\u65b9\u6cd5\u3002", "motivation": "\u901a\u8fc7\u591a\u5143\u4ee3\u6570\u6280\u672f\u548c\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e00\u79cd\u65b0\u7684\u52a0\u5bc6/\u89e3\u5bc6\u6d41\u7a0b\u3002", "method": "\u5229\u7528\u6574\u6570\u632f\u5e45\u4fe1\u53f7\u4f20\u8f93\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u591a\u5143\u6280\u672f\u5c06\u660e\u6587\u8f6c\u6362\u4e3a\u7279\u6b8a\u6574\u6570\u5e8f\u5217\u3002\u63a5\u6536\u65b9\u901a\u8fc7\u7279\u5b9a\u89c4\u5219\u548c\u65b9\u7a0b\u7ec4\u6062\u590d\u660e\u6587\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u52a0\u5bc6/\u89e3\u5bc6\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4ee3\u6570\u7ed3\u6784\u4e0e\u4fe1\u53f7\u5904\u7406\uff0c\u4e3a\u52a0\u5bc6\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2507.07157", "pdf": "https://arxiv.org/pdf/2507.07157", "abs": "https://arxiv.org/abs/2507.07157", "authors": ["Arshak Rezvani", "Ali Akbari", "Kosar Sanjar Arani", "Maryam Mirian", "Emad Arasteh", "Martin J. McKeown"], "title": "Interpretable EEG-to-Image Generation with Semantic Prompts", "categories": ["cs.CV", "cs.LG", "eess.SP"], "comment": "Actionable Interpretability Workshop (non-archival) at the 42\n  International Conference on Machine Learning", "summary": "Decoding visual experience from brain signals offers exciting possibilities\nfor neuroscience and interpretable AI. While EEG is accessible and temporally\nprecise, its limitations in spatial detail hinder image reconstruction. Our\nmodel bypasses direct EEG-to-image generation by aligning EEG signals with\nmultilevel semantic captions -- ranging from object-level to abstract themes --\ngenerated by a large language model. A transformer-based EEG encoder maps brain\nactivity to these captions through contrastive learning. During inference,\ncaption embeddings retrieved via projection heads condition a pretrained latent\ndiffusion model for image generation. This text-mediated framework yields\nstate-of-the-art visual decoding on the EEGCVPR dataset, with interpretable\nalignment to known neurocognitive pathways. Dominant EEG-caption associations\nreflected the importance of different semantic levels extracted from perceived\nimages. Saliency maps and t-SNE projections reveal semantic topography across\nthe scalp. Our model demonstrates how structured semantic mediation enables\ncognitively aligned visual decoding from EEG.", "AI": {"tldr": "\u901a\u8fc7\u5c06EEG\u4fe1\u53f7\u4e0e\u591a\u7ea7\u8bed\u4e49\u63cf\u8ff0\u5bf9\u9f50\uff0c\u751f\u6210\u56fe\u50cf\uff0c\u8be5\u65b9\u6cd5\u5728EEGCVPR\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u89e3\u7801\u6548\u679c\u3002", "motivation": "EEG\u5728\u89c6\u89c9\u89e3\u7801\u4e2d\u5177\u6709\u65f6\u95f4\u7cbe\u786e\u6027\u4f46\u7a7a\u95f4\u7ec6\u8282\u4e0d\u8db3\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8bed\u4e49\u4e2d\u4ecb\u6539\u5584EEG\u7684\u56fe\u50cf\u91cd\u5efa\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u7ea7\u8bed\u4e49\u63cf\u8ff0\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684EEG\u7f16\u7801\u5668\uff0c\u6700\u7ec8\u5229\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\u751f\u6210\u56fe\u50cf\u3002", "result": "\u5728EEGCVPR\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u7801\u7ed3\u679c\u4e0e\u795e\u7ecf\u8ba4\u77e5\u901a\u8def\u4e00\u81f4\uff0cEEG\u4e0e\u8bed\u4e49\u63cf\u8ff0\u7684\u5173\u8054\u63ed\u793a\u4e86\u4e0d\u540c\u8bed\u4e49\u5c42\u6b21\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u8bed\u4e49\u4e2d\u4ecb\u5b9e\u73b0\u4e86\u4e0e\u8ba4\u77e5\u5bf9\u9f50\u7684EEG\u89c6\u89c9\u89e3\u7801\uff0c\u4e3a\u795e\u7ecf\u79d1\u5b66\u548c\u53ef\u89e3\u91caAI\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.07241", "pdf": "https://arxiv.org/pdf/2507.07241", "abs": "https://arxiv.org/abs/2507.07241", "authors": ["Robert Kuku Fotock", "Agbotiname Lucky Imoize", "Alessio Zappone", "Marco Di Renzo", "Roberto Garello"], "title": "Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?", "categories": ["math.OC", "cs.IT", "eess.SP", "math.IT", "49M20 (Primary) 49M05, 94A05 (Secondary)", "F.2.1; F.2.3; I.6.8; G.1.6"], "comment": "16 pages, 11 figures, IEEE TRANSACTIONS ON INFORMATION FORENSICS AND\n  SECURITY", "summary": "This work addresses the problem of secrecy energy efficiency (SEE)\nmaximization in RIS-aided wireless networks. The use of active and\nnearly-passive RISs are compared and their trade-off in terms of SEE is\nanalyzed. Considering both perfect and statistical channel state information,\ntwo SEE maximization algorithms are developed to optimize the transmit powers\nof the mobile users, the RIS reflection coefficients, and the base station\nreceive filters. Numerical results quantify the trade-off between active and\nnearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values\nas the static power consumed by each reflecting element increases.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86RIS\u8f85\u52a9\u65e0\u7ebf\u7f51\u7edc\u4e2d\u4fdd\u5bc6\u80fd\u91cf\u6548\u7387\uff08SEE\uff09\u6700\u5927\u5316\u95ee\u9898\uff0c\u5bf9\u6bd4\u4e86\u4e3b\u52a8\u548c\u8fd1\u88ab\u52a8RIS\u7684\u4f7f\u7528\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u5728SEE\u4e0a\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u51b3RIS\u8f85\u52a9\u65e0\u7ebf\u7f51\u7edc\u4e2dSEE\u6700\u5927\u5316\u95ee\u9898\uff0c\u63a2\u8ba8\u4e3b\u52a8\u548c\u8fd1\u88ab\u52a8RIS\u7684\u6027\u80fd\u5dee\u5f02\u53ca\u5176\u5bf9SEE\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cdSEE\u6700\u5927\u5316\u7b97\u6cd5\uff0c\u4f18\u5316\u79fb\u52a8\u7528\u6237\u7684\u53d1\u5c04\u529f\u7387\u3001RIS\u53cd\u5c04\u7cfb\u6570\u548c\u57fa\u7ad9\u63a5\u6536\u6ee4\u6ce2\u5668\uff0c\u8003\u8651\u4e86\u5b8c\u7f8e\u548c\u7edf\u8ba1\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u4e3b\u52a8RIS\u5728SEE\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u5c24\u5176\u662f\u968f\u7740\u6bcf\u4e2a\u53cd\u5c04\u5143\u4ef6\u9759\u6001\u529f\u8017\u589e\u52a0\u65f6\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4e3b\u52a8\u548c\u8fd1\u88ab\u52a8RIS\u5728SEE\u4e0a\u7684\u6027\u80fd\u6743\u8861\uff0c\u4e3a\u5b9e\u9645\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.07261", "pdf": "https://arxiv.org/pdf/2507.07261", "abs": "https://arxiv.org/abs/2507.07261", "authors": ["Chunzhuo Wang", "Hans Hallez", "Bart Vanrumste"], "title": "Robust Multimodal Learning Framework For Intake Gesture Detection Using Contactless Radar and Wearable IMU Sensors", "categories": ["cs.LG", "eess.SP"], "comment": "This manuscript has been submitted to a peer-reviewed journal and is\n  currently under review", "summary": "Automated food intake gesture detection plays a vital role in dietary\nmonitoring, enabling objective and continuous tracking of eating behaviors to\nsupport better health outcomes. Wrist-worn inertial measurement units (IMUs)\nhave been widely used for this task with promising results. More recently,\ncontactless radar sensors have also shown potential. This study explores\nwhether combining wearable and contactless sensing modalities through\nmultimodal learning can further improve detection performance. We also address\na major challenge in multimodal learning: reduced robustness when one modality\nis missing. To this end, we propose a robust multimodal temporal convolutional\nnetwork with cross-modal attention (MM-TCN-CMA), designed to integrate IMU and\nradar data, enhance gesture detection, and maintain performance under missing\nmodality conditions. A new dataset comprising 52 meal sessions (3,050 eating\ngestures and 797 drinking gestures) from 52 participants is developed and made\npublicly available. Experimental results show that the proposed framework\nimproves the segmental F1-score by 4.3% and 5.2% over unimodal Radar and IMU\nmodels, respectively. Under missing modality scenarios, the framework still\nachieves gains of 1.3% and 2.4% for missing radar and missing IMU inputs. This\nis the first study to demonstrate a robust multimodal learning framework that\neffectively fuses IMU and radar data for food intake gesture detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7a7f\u6234\u5f0f\u548c\u63a5\u89e6\u5f0f\u4f20\u611f\u5668\u7684\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\uff08MM-TCN-CMA\uff09\uff0c\u7528\u4e8e\u996e\u98df\u52a8\u4f5c\u68c0\u6d4b\uff0c\u5e76\u5728\u6a21\u6001\u7f3a\u5931\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u901a\u8fc7\u591a\u6a21\u6001\u5b66\u4e60\u7ed3\u5408IMU\u548c\u96f7\u8fbe\u4f20\u611f\u5668\uff0c\u63d0\u5347\u996e\u98df\u52a8\u4f5c\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u89e3\u51b3\u6a21\u6001\u7f3a\u5931\u65f6\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5e26\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\uff08MM-TCN-CMA\uff09\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b52\u540d\u53c2\u4e0e\u8005\u7684\u65b0\u6570\u636e\u96c6\u3002", "result": "\u4e0e\u5355\u6a21\u6001\u6a21\u578b\u76f8\u6bd4\uff0cF1\u5206\u6570\u5206\u522b\u63d0\u9ad8\u4e864.3%\uff08\u96f7\u8fbe\uff09\u548c5.2%\uff08IMU\uff09\uff1b\u5728\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u4ecd\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b\u3002", "conclusion": "\u9996\u6b21\u5c55\u793a\u4e86\u878d\u5408IMU\u548c\u96f7\u8fbe\u6570\u636e\u7684\u9c81\u68d2\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u996e\u98df\u76d1\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.07342", "pdf": "https://arxiv.org/pdf/2507.07342", "abs": "https://arxiv.org/abs/2507.07342", "authors": ["Dogan Kutay Pekcan", "Hongyi Liao", "Ender Ayanoglu"], "title": "Discrete Beamforming Optimization for RISs with a Limited Phase Range and Amplitude Attenuation", "categories": ["eess.SP", "cs.ET"], "comment": "13 pages, 17 figures, 2 tables", "summary": "This paper addresses the problem of maximizing the received power at a user\nequipment via reconfigurable intelligent surface (RIS) characterized by\nphase-dependent amplitude (PDA) and discrete phase shifts over a limited phase\nrange. Given complex RIS coefficients, that is, discrete phase shifts and PDAs,\nwe derive the necessary and sufficient conditions to achieve the optimal\nsolution. To this end, we propose an optimal search algorithm that is proven to\nconverge in linear time within at most NK steps, significantly outperforming\nthe exhaustive search approach that would otherwise be needed for RISs with\namplitude attenuation. Furthermore, we introduce a practical quantization\nframework for PDA-introduced RISs termed amplitude-introduced polar\nquantization (APQ), and extend it to a novel algorithm named extended\namplitude-introduced polar quantization (EAPQ) that works with geometric\nprojections. We derive closed-form expressions to assess how closely the\nperformance of the proposed RIS configuration can approximate the ideal case\nwith continuous phases and no attenuation. Our analysis reveals that increasing\nthe number of discrete phases beyond K = 4 yields only marginal gains,\nregardless of attenuation levels, provided the RIS has a sufficiently wide\nphase range R. Furthermore, we also show and quantify that when the phase range\nR is limited, the performance is sensitive to attenuation for larger R, and\nsensitive to R when there is less attenuation. Finally, the proposed optimal\nalgorithm provides a generic upper bound that could serve as a benchmark for\ndiscrete beamforming in RISs with amplitude constraints.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u5177\u6709\u76f8\u4f4d\u76f8\u5173\u5e45\u5ea6\uff08PDA\uff09\u548c\u6709\u9650\u76f8\u4f4d\u8303\u56f4\u5185\u79bb\u6563\u76f8\u4f4d\u7684\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u6700\u5927\u5316\u7528\u6237\u8bbe\u5907\u63a5\u6536\u529f\u7387\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ebf\u6027\u65f6\u95f4\u6536\u655b\u7684\u6700\u4f18\u641c\u7d22\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u91cf\u5316\u6846\u67b6\u548c\u6269\u5c55\u7b97\u6cd5\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3RIS\u5728\u79bb\u6563\u76f8\u4f4d\u548cPDA\u7ea6\u675f\u4e0b\u7684\u529f\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u5347\u7b97\u6cd5\u6548\u7387\u5e76\u91cf\u5316\u6027\u80fd\u63a5\u8fd1\u7406\u60f3\u60c5\u51b5\u7684\u7a0b\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u6700\u4f18\u641c\u7d22\u7b97\u6cd5\u548c\u91cf\u5316\u6846\u67b6APQ\u53ca\u6269\u5c55\u7b97\u6cd5EAPQ\uff0c\u901a\u8fc7\u51e0\u4f55\u6295\u5f71\u548c\u95ed\u5f0f\u8868\u8fbe\u5f0f\u5206\u6790\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u79bb\u6563\u76f8\u4f4d\u8d85\u8fc7K=4\u65f6\u589e\u76ca\u8fb9\u9645\uff0c\u6027\u80fd\u5bf9\u76f8\u4f4d\u8303\u56f4\u548c\u8870\u51cf\u654f\u611f\uff0c\u7b97\u6cd5\u63d0\u4f9b\u4e86\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u7684\u6027\u80fd\u4e0a\u9650\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3aRIS\u7684\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u63d0\u4f9b\u4e86\u6027\u80fd\u57fa\u51c6\uff0c\u4e14\u5728\u76f8\u4f4d\u8303\u56f4\u8db3\u591f\u5bbd\u65f6\uff0c\u589e\u52a0\u79bb\u6563\u76f8\u4f4d\u6570\u7684\u6536\u76ca\u6709\u9650\u3002"}}
{"id": "2507.07507", "pdf": "https://arxiv.org/pdf/2507.07507", "abs": "https://arxiv.org/abs/2507.07507", "authors": ["Thanh V. Pham", "Susumu Ishihara"], "title": "Optimization of Probabilistic Constellation Shaping for Optical OFDM Systems with Clipping Distortion", "categories": ["eess.SY", "cs.IT", "cs.SY", "eess.SP", "math.IT"], "comment": null, "summary": "Optical orthogonal frequency-division multiplexing (OFDM) and probabilistic\nconstellation shaping (PCS) have emerged as powerful techniques to enhance the\nperformance of optical wireless communications (OWC) systems. While PCS\nimproves spectral efficiency and adaptability, we show that its integration\nwith optical OFDM can inadvertently increase the peak-to-average power ratio\n(PAPR) of the signal, exacerbating clipping distortion due to signal clipping.\nThis letter investigates the impact of PCS on the PAPR of direct current-biased\noptical OFDM (DCO-OFDM) waveforms and proposes an optimization of PCS that\nmaximizes channel capacity, considering clipping distortion. The optimization\nproblem is shown to be complex and non-convex. We thus present a suboptimal yet\nefficient solving approach based on projected gradient descent to solve the\nproblem. Simulation results demonstrate the superiority of the proposed\napproach over the conventional uniform signaling, particularly under severe\nclipping distortion conditions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6982\u7387\u661f\u5ea7\u6210\u5f62\uff08PCS\uff09\u5bf9\u76f4\u6d41\u504f\u7f6e\u5149\u5b66OFDM\uff08DCO-OFDM\uff09\u4fe1\u53f7\u7684\u5cf0\u5747\u529f\u7387\u6bd4\uff08PAPR\uff09\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316PCS\u7684\u65b9\u6cd5\uff0c\u4ee5\u6700\u5927\u5316\u4fe1\u9053\u5bb9\u91cf\u5e76\u51cf\u5c11\u4fe1\u53f7\u524a\u6ce2\u5931\u771f\u3002", "motivation": "PCS\u867d\u7136\u80fd\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u548c\u9002\u5e94\u6027\uff0c\u4f46\u4e0e\u5149\u5b66OFDM\u7ed3\u5408\u65f6\u4f1a\u589e\u52a0\u4fe1\u53f7\u7684PAPR\uff0c\u5bfc\u81f4\u524a\u6ce2\u5931\u771f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4f18\u5316PCS\u4ee5\u51cf\u5c11\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u7684\u6b21\u4f18\u4f46\u9ad8\u6548\u7684\u6c42\u89e3\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u975e\u51f8\u7684\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e25\u91cd\u524a\u6ce2\u5931\u771f\u6761\u4ef6\u4e0b\u4f18\u4e8e\u4f20\u7edf\u7684\u5747\u5300\u4fe1\u4ee4\u65b9\u6cd5\u3002", "conclusion": "\u4f18\u5316\u540e\u7684PCS\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u4fe1\u9053\u5bb9\u91cf\u5e76\u51cf\u5c11\u4fe1\u53f7\u524a\u6ce2\u5931\u771f\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.07559", "pdf": "https://arxiv.org/pdf/2507.07559", "abs": "https://arxiv.org/abs/2507.07559", "authors": ["Amirhossein Sadough", "Mahyar Shahsavari", "Mark Wijtvliet", "Marcel van Gerven"], "title": "Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "Anomaly detection (AD) plays a vital role across a wide range of real-world\ndomains by identifying data instances that deviate from expected patterns,\npotentially signaling critical events such as system failures, fraudulent\nactivities, or rare medical conditions. The demand for real-time AD has surged\nwith the rise of the (Industrial) Internet of Things, where massive volumes of\nmultivariate sensor data must be processed instantaneously. Real-time AD\nrequires methods that not only handle high-dimensional streaming data but also\noperate in a single-pass manner, without the burden of storing historical\ninstances, thereby ensuring minimal memory usage and fast decision-making. We\npropose DAD, a novel real-time decorrelation-based anomaly detection method for\nmultivariate time series, based on an online decorrelation learning approach.\nUnlike traditional proximity-based or reconstruction-based detectors that\nprocess entire data or windowed instances, DAD dynamically learns and monitors\nthe correlation structure of data sample by sample in a single pass, enabling\nefficient and effective detection. To support more realistic benchmarking\npractices, we also introduce a practical hyperparameter tuning strategy\ntailored for real-time anomaly detection scenarios. Extensive experiments on\nwidely used benchmark datasets demonstrate that DAD achieves the most\nconsistent and superior performance across diverse anomaly types compared to\nstate-of-the-art methods. Crucially, its robustness to increasing\ndimensionality makes it particularly well-suited for real-time,\nhigh-dimensional data streams. Ultimately, DAD not only strikes an optimal\nbalance between detection efficacy and computational efficiency but also sets a\nnew standard for real-time, memory-constrained anomaly detection.", "AI": {"tldr": "DAD\u662f\u4e00\u79cd\u57fa\u4e8e\u5728\u7ebf\u53bb\u76f8\u5173\u5b66\u4e60\u7684\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u80fd\u591f\u5728\u5355\u6b21\u5904\u7406\u4e2d\u52a8\u6001\u5b66\u4e60\u6570\u636e\u76f8\u5173\u6027\uff0c\u9ad8\u6548\u68c0\u6d4b\u5f02\u5e38\u3002", "motivation": "\u968f\u7740\u5de5\u4e1a\u7269\u8054\u7f51\u7684\u5174\u8d77\uff0c\u5bf9\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u9ad8\u6548\u5904\u7406\u9ad8\u7ef4\u6d41\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "DAD\u91c7\u7528\u5728\u7ebf\u53bb\u76f8\u5173\u5b66\u4e60\u65b9\u6cd5\uff0c\u52a8\u6001\u76d1\u63a7\u6570\u636e\u7684\u76f8\u5173\u6027\u7ed3\u6784\uff0c\u65e0\u9700\u5b58\u50a8\u5386\u53f2\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDAD\u5728\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u9ad8\u7ef4\u6570\u636e\u6d41\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "DAD\u5728\u68c0\u6d4b\u6548\u679c\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u4e3a\u5b9e\u65f6\u3001\u5185\u5b58\u53d7\u9650\u7684\u5f02\u5e38\u68c0\u6d4b\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2507.07631", "pdf": "https://arxiv.org/pdf/2507.07631", "abs": "https://arxiv.org/abs/2507.07631", "authors": ["Hiroshi Sato", "Tsubasa Ochiai", "Marc Delcroix", "Takafumi Moriya", "Takanori Ashihara", "Ryo Masumura"], "title": "Generic Speech Enhancement with Self-Supervised Representation Space Loss", "categories": ["eess.AS", "cs.SD", "eess.SP"], "comment": "22 pages, 3 figures. Accepted for Frontiers in signal processing", "summary": "Single-channel speech enhancement is utilized in various tasks to mitigate\nthe effect of interfering signals. Conventionally, to ensure the speech\nenhancement performs optimally, the speech enhancement has needed to be tuned\nfor each task. Thus, generalizing speech enhancement models to unknown\ndownstream tasks has been challenging. This study aims to construct a generic\nspeech enhancement front-end that can improve the performance of back-ends to\nsolve multiple downstream tasks. To this end, we propose a novel training\ncriterion that minimizes the distance between the enhanced and the ground truth\nclean signal in the feature representation domain of self-supervised learning\nmodels. Since self-supervised learning feature representations effectively\nexpress high-level speech information useful for solving various downstream\ntasks, the proposal is expected to make speech enhancement models preserve such\ninformation. Experimental validation demonstrates that the proposal improves\nthe performance of multiple speech tasks while maintaining the perceptual\nquality of the enhanced signal.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u8bed\u97f3\u589e\u5f3a\u524d\u7aef\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u51c6\u5219\uff0c\u63d0\u9ad8\u4e86\u540e\u7aef\u5904\u7406\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u901a\u7528\u7684\u8bed\u97f3\u589e\u5f3a\u524d\u7aef\uff0c\u4ee5\u63d0\u9ad8\u540e\u7aef\u5904\u7406\u591a\u79cd\u672a\u77e5\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u51c6\u5219\uff0c\u5728\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u7279\u5f81\u8868\u793a\u57df\u4e2d\u6700\u5c0f\u5316\u589e\u5f3a\u4fe1\u53f7\u4e0e\u5e72\u51c0\u4fe1\u53f7\u7684\u8ddd\u79bb\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u589e\u5f3a\u4fe1\u53f7\u611f\u77e5\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u591a\u79cd\u8bed\u97f3\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5b9e\u73b0\u4e86\u901a\u7528\u7684\u8bed\u97f3\u589e\u5f3a\u524d\u7aef\uff0c\u63d0\u5347\u4e86\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
