<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.CR](#cs.CR) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.IT](#cs.IT) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Demonstrating Superresolution in Radar Range Estimation Using a Denoising Autoencoder](https://arxiv.org/abs/2506.14906)
*Robert Czupryniak,Abhishek Chakraborty,Andrew N. Jordan,John C. Howell*

Main category: eess.SP

TL;DR: 该论文利用机器学习中的去噪自编码器，在受限带宽条件下实现遥感雷达中的超分辨率距离估计。


<details>
  <summary>Details</summary>
Motivation: 研究目的是通过机器学习方法突破传统雷达检测的物理限制（如带宽约束），实现亚波长范围内的精确距离测量。

Method: 采用去噪自编码器模型，训练基于不同脉冲波形（sinc、三角波、球面贝塞尔函数基底）的数据，优化其瓶颈层以关联散射体间距。

Result: 球面贝塞尔信号表现最佳，其次是三角波，sinc信号最差；瓶颈层输出与真实距离具有强相关性且对噪声鲁棒。

Conclusion: 信号设计对基于机器学习的超分辨率至关重要，球面贝塞尔脉冲为最优选择。

Abstract: We apply machine learning methods to demonstrate range superresolution in
remote sensing radar detection. Specifically, we implement a denoising
autoencoder to estimate the distance between two equal intensity scatterers in
the subwavelength regime. The machine learning models are trained on waveforms
subject to a bandlimit constraint such that ranges much smaller than the
inverse bandlimit are optimized in their precision. The autoencoder achieves
effective dimensionality reduction, with the bottleneck layer exhibiting a
strong and consistent correlation with the true scatterer separation. We
confirm reproducibility across different training sessions and network
initializations by analyzing the scaled encoder outputs and their robustness to
noise. We investigate the behavior of the bottleneck layer for the following
types of pulses: a traditional sinc pulse, a bandlimited triangle-type pulse,
and a theoretically near-optimal pulse created from a spherical Bessel function
basis. The Bessel signal performs best, followed by the triangle wave, with the
sinc signal performing worst, highlighting the crucial role of signal design in
the success of machine-learning-based range resolution.

</details>


### [2] [Metasurfaces-Integrated Doubly-Dispersive MIMO: Channel Modeling and Optimization](https://arxiv.org/abs/2506.14985)
*Kuranage Roche Rayan Ranasinghe,Hyeon Seok Rou,Iván Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 提出了一种新型的多RIS集成的DD信道模型（MPDD），并讨论了其在OFDM、OTFS和AFDM等波形优化中的应用，展示了其在SIM辅助无线系统中的潜力。


<details>
  <summary>Details</summary>
Motivation: 扩展DD框架到MIMO系统，特别是在RIS和SIM增强的环境中，解决现有模型的局限性。

Method: 提出了MPDD信道模型，集成多RIS和SIM，并将其应用于优化波形。

Result: 展示了模型的可编程性和在SIM辅助系统中提升波形性能的潜力。

Conclusion: MPDD模型为高机动性和ISAC场景下的MIMO系统提供了新的解决方案。

Abstract: The doubly-dispersive (DD) channel structure has played a pivotal role in
wireless communications, particularly in high-mobility scenarios and integrated
sensing and communications (ISAC), due to its ability to capture the key fading
effects experienced by a transmitted signal as it propagates through a dynamic
medium. However, extending the DD framework to multiple-input multiple-output
(MIMO) systems, especially in environments artificially enhanced by
reconfigurable intelligent surfaces (RISs) and stacked intelligent metasurfaces
(SIM), remains a challenging open problem. In this chapter, a novel
metasurfaces-parametrized DD (MPDD) channel model that integrates an arbitrary
number of RISs, while also incorporating SIM at both the transmitter and
receiver is introduced. Next, the application of this model to some key
waveforms optimized for DD environments -- namely orthogonal frequency division
multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine
frequency division multiplexing (AFDM) -- is discussed. Finally, the
programmability of the proposed model is highlighted through an illustrative
application, demonstrating its potential for enhancing waveform performance in
SIM-assisted wireless systems.

</details>


### [3] [Secure Time-Modulated Intelligent Reflecting Surface via Generative Flow Networks](https://arxiv.org/abs/2506.14992)
*Zhihao Tao,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 提出了一种基于生成式AI的时间调制智能反射面（TM-IRS）方向调制设计方法，用于OFDM发射机，优化多用户场景下的安全性和通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有TM-IRS设计方法仅适用于单用户方向，无法满足多用户场景需求，因此提出一种新方法以支持多用户并增强安全性。

Method: 将TM-IRS参数选择建模为确定性马尔可夫决策过程（MDP），利用GFlowNets学习随机策略，按奖励比例采样参数集。

Result: 实验显示该方法显著提升了多用户OFDM系统的安全性，且GFlowNets在训练极少配置（<0.000001%）后即可收敛。

Conclusion: 该方法高效且可扩展，适用于实际多用户通信系统，代码开源以便复现。

Abstract: We propose a novel directional modulation (DM) design for OFDM transmitters
aided by a time-modulated intelligent reflecting surface (TM-IRS). The TM-IRS
is configured to preserve the integrity of transmitted signals toward multiple
legitimate users while scrambling the signal in all other directions. Existing
TM-IRS design methods typically target a single user direction and follow
predefined rule-based procedures, making them unsuitable for multi-user
scenarios. Here, we propose a generative AI-based approach to design good sets
of TM-IRS parameters out of a set of all possible quantized ranges of
parameters. The design objective is to maximize the sum rate across the
authorized directions. We model the TM-IRS parameter selection as a
deterministic Markov decision process (MDP), where each terminal state
corresponds to a specific configuration of TM-IRS parameters. GFlowNets are
employed to learn a stochastic policy that samples TM-IRS parameter sets with
probability proportional to their associated sum rate reward. Experimental
results demonstrate that the proposed method effectively enhances the security
of the TM-IRS-aided OFDM systems with multi-users. Also, despite the vast size
of the TM-IRS configuration space, the GFlowNet is able to converge after
training on fewer than 0.000001% of all possible configurations, demonstrating
remarkable efficiency compared to exhaustive combinatorial search.
Implementation code is available at https://github.com/ZhihaoTao/GFN4TM-RIS to
facilitate reproducibility.

</details>


### [4] [Fiber Signal Denoising Algorithm using Hybrid Deep Learning Networks](https://arxiv.org/abs/2506.15125)
*Linlin Wang,Wei Wang,Dezhao Wang,Shanwen Wang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于混合深度学习网络（HDLNet）的光纤分布式声学传感（DAS）信号去噪算法，结合自编码器和LSTM，并引入车辆检测与跟踪算法，实验表明其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决光纤DAS系统在智能交通系统中信号处理的需求，提高去噪效果并减少人工标注成本。

Method: 采用自监督的混合深度学习网络（HDLNet），结合自编码器（DAE）和长短期记忆网络（LSTM），并引入车辆检测与跟踪算法。

Result: 实验表明，HDLNet在真实高速公路隧道数据集上的去噪性能优于传统空间域DAE方法。

Conclusion: 提出的HDLNet方法为光纤DAS信号去噪和特征提取提供了有效解决方案，具有实际应用潜力。

Abstract: With the applicability of optical fiber-based distributed acoustic sensing
(DAS) systems, effective signal processing and analysis approaches are needed
to promote its popularization in the field of intelligent transportation
systems (ITS). This paper presents a signal denoising algorithm using a hybrid
deep-learning network (HDLNet). Without annotated data and time-consuming
labeling, this self-supervised network runs in parallel, combining an
autoencoder for denoising (DAE) and a long short-term memory (LSTM) for
sequential processing. Additionally, a line-by-line matching algorithm for
vehicle detection and tracking is introduced, thus realizing the complete
processing of fiber signal denoising and feature extraction. Experiments were
carried out on a self-established real highway tunnel dataset, showing that our
proposed hybrid network yields more satisfactory denoising performance than
Spatial-domain DAE.

</details>


### [5] [Out-of-Band Modality Synergy Based Multi-User Beam Prediction and Proactive BS Selection with Zero Pilot Overhead](https://arxiv.org/abs/2506.15136)
*Kehui Li,Binggui Zhou,Jiajia Guo,Feifei Gao,Guanghua Yang,Shaodan Ma*

Main category: eess.SP

TL;DR: 提出了一种基于OOB模态协同（OMS）的移动管理方案，通过结合视觉和位置信息实现多用户波束预测和主动基站选择，显著降低信令开销并提高协调效率。


<details>
  <summary>Details</summary>
Motivation: 多用户毫米波通信中的多基站选择和波束跟踪会导致高信令开销和高协调延迟，现有方法尚未解决这一问题。

Method: 通过视觉和位置协同实现用户初始识别和跟踪，设计BEM-GBPN网络预测波束增益和最优波束，中央单元控制基站切换和波束调整。

Result: 仿真表明，方案在零导频开销下实现91%的最优传输速率，显著提升多基站协调效率。

Conclusion: OMS方案有效解决了多基站系统中的波束预测和协调问题。

Abstract: Multi-user millimeter-wave communication relies on narrow beams and dense
cell deployments to ensure reliable connectivity. However, tracking optimal
beams for multiple mobile users across multiple base stations (BSs) results in
significant signaling overhead. Recent works have explored the capability of
out-of-band (OOB) modalities in obtaining spatial characteristics of wireless
channels and reducing pilot overhead in single-BS single-user/multi-user
systems. However, applying OOB modalities for multi-BS selection towards dense
cell deployments leads to high coordination overhead, i.e, excessive computing
overhead and high latency in data exchange. How to leverage OOB modalities to
eliminate pilot overhead and achieve efficient multi-BS coordination in
multi-BS systems remains largely unexplored. In this paper, we propose a novel
OOB modality synergy (OMS) based mobility management scheme to realize
multi-user beam prediction and proactive BS selection by synergizing two OOB
modalities, i.e., vision and location. Specifically, mobile users are initially
identified via spatial alignment of visual sensing and location feedback, and
then tracked according to the temporal correlation in image sequence.
Subsequently, a binary encoding map based gain and beam prediction network
(BEM-GBPN) is designed to predict beamforming gains and optimal beams for
mobile users at each BS, such that a central unit can control the BSs to
perform user handoff and beam switching. Simulation results indicate that the
proposed OMS-based mobility management scheme enhances beam prediction and BS
selection accuracy and enables users to achieve 91% transmission rates of the
optimal with zero pilot overhead and significantly improve multi-BS
coordination efficiency compared to existing methods.

</details>


### [6] [Probabilistic Trajectory GOSPA: A Metric for Uncertainty-Aware Multi-Object Tracking Performance Evaluation](https://arxiv.org/abs/2506.15148)
*Yuxuan Xia,Ángel F. García-Fernández,Johan Karlsson,Yu Ge,Lennart Svensson,Ting Yuan*

Main category: eess.SP

TL;DR: 本文提出了一种广义的轨迹最优子模式分配（GOSPA）度量，用于评估提供轨迹估计的不确定性的多目标跟踪算法。


<details>
  <summary>Details</summary>
Motivation: 为了综合考虑目标状态的存在不确定性和估计不确定性，改进现有的轨迹GOSPA度量。

Method: 基于概率GOSPA度量，将其表述为多维分配问题，并展示了其线性规划松弛版本的多项式时间可计算性。

Result: 该度量保持了TGOSPA的可解释性，并将其分解为直观的成本项，如预期的定位误差、存在概率不匹配误差等。

Conclusion: 通过仿真研究验证了所提出度量的有效性。

Abstract: This paper presents a generalization of the trajectory general optimal
sub-pattern assignment (GOSPA) metric for evaluating multi-object tracking
algorithms that provide trajectory estimates with track-level uncertainties.
This metric builds on the recently introduced probabilistic GOSPA metric to
account for both the existence and state estimation uncertainties of individual
object states. Similar to trajectory GOSPA (TGOSPA), it can be formulated as a
multidimensional assignment problem, and its linear programming
relaxation--also a valid metric--is computable in polynomial time.
Additionally, this metric retains the interpretability of TGOSPA, and we show
that its decomposition yields intuitive costs terms associated to expected
localization error and existence probability mismatch error for properly
detected objects, expected missed and false detection error, and track switch
error. The effectiveness of the proposed metric is demonstrated through a
simulation study.

</details>


### [7] [Enhancing eLoran Timing Accuracy via Machine Learning with Meteorological and Terrain Data](https://arxiv.org/abs/2506.15235)
*Taewon Kang,Seunghyeon Park,Pyo-Woong Son,Jiwon Seo*

Main category: eess.SP

TL;DR: 论文提出了一种名为WLR-AGRNN的模型，通过结合加权线性回归和各向异性广义回归神经网络，提高了eLoran/GPS时间差的估计精度。


<details>
  <summary>Details</summary>
Motivation: 全球导航卫星系统（GNSS）易受信号干扰，eLoran作为补充定位、导航和计时（PNT）方案需提高计时精度，尤其是在面对传播延迟（ASF）的挑战时。

Method: 使用时间间隔计数器测量GPS和eLoran的时间差（TD），分析其与11种气象因素的相关性，提出WLR-AGRNN模型，结合地形高度加权气象数据。

Result: 基于四个月数据的实验表明，WLR-AGRNN模型优于其他方法，显著提高了eLoran/GPS时间差估计的准确性。

Conclusion: WLR-AGRNN模型有效解决了eLoran信号传播延迟问题，为eLoran计时精度提升提供了可行方案。

Abstract: The vulnerabilities of global navigation satellite systems (GNSS) to signal
interference have increased the demand for complementary positioning,
navigation, and timing (PNT) systems. To address this, South Korea has decided
to deploy an enhanced long-range navigation (eLoran) system as a complementary
PNT solution. Similar to GNSS, eLoran provides highly accurate timing
information, which is essential for applications such as telecommunications,
financial systems, and power distribution. However, the primary sources of
error for GNSS and eLoran differ. For eLoran, the main source of error is
signal propagation delay over land, known as the additional secondary factor
(ASF). This delay, influenced by ground conductivity and weather conditions
along the signal path, is challenging to predict and mitigate. In this paper,
we measure the time difference (TD) between GPS and eLoran using a time
interval counter and analyze the correlations between eLoran/GPS TD and eleven
meteorological factors. Accurate estimation of eLoran/GPS TD could enable
eLoran to achieve timing accuracy comparable to that of GPS. We propose two
estimation models for eLoran/GPS TD and compare their performance with existing
TD estimation methods. The proposed WLR-AGRNN model captures the linear
relationships between meteorological factors and eLoran/GPS TD using weighted
linear regression (WLR) and models nonlinear relationships between outputs from
expert networks through an anisotropic general regression neural network
(AGRNN). The model incorporates terrain elevation to appropriately weight
meteorological data, as elevation influences signal propagation delay.
Experimental results based on four months of data demonstrate that the
WLR-AGRNN model outperforms other models, highlighting its effectiveness in
improving eLoran/GPS TD estimation accuracy.

</details>


### [8] [Reinforcement Learning-Based Policy Optimisation For Heterogeneous Radio Access](https://arxiv.org/abs/2506.15273)
*Anup Mishra,Čedomir Stefanović,Xiuqiang Xu,Petar Popovski,Israel Leyva-Mayorga*

Main category: eess.SP

TL;DR: 论文探讨了在异构服务中共享无线资源的效率问题，提出了一种基于强化学习的IoT设备传输策略优化方案，显著提升了IoT用户的延迟性能，同时保持宽带用户的吞吐量和能效。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要灵活高效地共享无线资源，尤其是在IoT设备和宽带用户共存的环境中。

Method: 采用无授权访问框架，提出基于双Q学习的强化学习方法，优化IoT设备的重复传输策略，以适应干扰变化并满足延迟目标。

Result: RL策略显著改善了IoT用户的延迟性能，同时保持了宽带用户的吞吐量和能效；RAN共享在低IoT流量下能效更高，RAN切片在高流量下效果更好。

Conclusion: 提出的RL方法在不同流量场景下均能有效优化资源分配，为未来无线网络的异构服务共存提供了可行方案。

Abstract: Flexible and efficient wireless resource sharing across heterogeneous
services is a key objective for future wireless networks. In this context, we
investigate the performance of a system where latency-constrained
internet-of-things (IoT) devices coexist with a broadband user. The base
station adopts a grant-free access framework to manage resource allocation,
either through orthogonal radio access network (RAN) slicing or by allowing
shared access between services. For the IoT users, we propose a reinforcement
learning (RL) approach based on double Q-Learning (QL) to optimise their
repetition-based transmission strategy, allowing them to adapt to varying
levels of interference and meet a predefined latency target. We evaluate the
system's performance in terms of the cumulative distribution function of IoT
users' latency, as well as the broadband user's throughput and energy
efficiency (EE). Our results show that the proposed RL-based access policies
significantly enhance the latency performance of IoT users in both RAN Slicing
and RAN Sharing scenarios, while preserving desirable broadband throughput and
EE. Furthermore, the proposed policies enable RAN Sharing to be
energy-efficient at low IoT traffic levels, and RAN Slicing to be favourable
under high IoT traffic.

</details>


### [9] [Urban RIS-Assisted HAP Networks: Performance Analysis Using Stochastic Geometry](https://arxiv.org/abs/2506.15338)
*Islam M. Tanash,Ayush Kumar Dwivedi,Taneli Riihonen*

Main category: eess.SP

TL;DR: 研究利用可重构智能表面（RIS）支持的高空平台（HAP）网络，通过泊松点过程和布尔矩形模型分析其性能，提出基于广义Beta prime分布的统计信道表征方法，显著提升覆盖概率和容量。


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中HAP网络的干扰问题，提升连接性和数据卸载效率。

Method: 采用泊松点过程建模HAP和RIS的分布，布尔矩形模型模拟建筑物遮挡，并提出基于广义Beta prime分布的统计信道分析方法。

Result: 分析结果显示系统性能显著提升，且干扰因遮挡效应得到缓解。

Conclusion: 所提系统能有效增强城市环境中的连接性，支持高效数据卸载。

Abstract: This paper studies a high-altitude platform (HAP) network supported by
reconfigurable intelligent surfaces (RISs). The practical irregular placement
of HAPs and RISs is modeled using homogeneous Poisson point processes, while
buildings that cause blockages in urban areas are modeled as a Boolean scheme
of rectangles. We introduce a novel approach to characterize the statistical
channel based on generalized Beta prime distribution. Analytical expressions
for coverage probability and ergodic capacity in an interference-limited system
are derived and validated through Monte Carlo simulations. The findings show
notable performance improvements and reveal the impact of various system
parameters, including blockages effect which contribute in mitigating
interference from the other visible HAPs. This proposed system could enhance
connectivity and enable effective data offloading in urban environments.

</details>


### [10] [Effect of Signal Quantization on Performance Measures of a 1st Order One Dimensional Differential Microphone Array](https://arxiv.org/abs/2506.15463)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 本文研究了信号量化对一维一阶差分麦克风阵列（DMA）性能的影响，特别是对波束图、方向性因子（DF）、前后比（FBR）和零点深度（ND）的影响。结果显示，量化对波束图形状结构无显著影响，但对ND有直接影响。


<details>
  <summary>Details</summary>
Motivation: 量化是数据采集中的关键环节，但现有研究尚未探索其对一维一阶DMA的影响，因此本文旨在填补这一空白。

Method: 通过分析一维一阶DMA的量化波束形成输出表达式，研究量化对波束图、DF、FBR和ND的影响。

Result: 量化位数变化下，波束图形状结构保持不变，DF和FBR不受影响；ND随量化位数的增加而提高，但随零点接近源方向而降低。

Conclusion: 量化主要影响DMA的零点深度，干扰抑制能力受量化位数和零点位置的共同影响，为实际系统设计提供了重要参考。

Abstract: In practical systems, recorded analog signals must be digitized for
processing, introducing quantization as a critical aspect of data acquisition.
While prior studies have examined quantization effects in various signal
processing contexts, its impact on differential microphone arrays (DMAs),
particularly in one-dimensional (1D) first-order configurations, remains
unexplored. This paper investigates the influence of signal quantization on
performance of first-order 1D DMAs across various beampatterns. An analytical
expression for quantized beamformed output for a first-order 1D DMA has been
formulated. The effect of signal quantization has been studied on array
performance measures such as the Beampattern, Directivity Factor (DF),
Front-to-Back Ratio (FBR), and null depth (ND). Simulation results reveal that
beampattern shape remains structurally invariant across quantization bit
depths, with quantization primarily affecting ND. DF and FBR remain constant
with the varying number of quantization bits. Additionally, ND is shown to be
frequency-independent; however, it increases with increasing quantization bit
depths, enhancing interference suppression. The study also examines the effect
of steering nulls across the azimuthal range, showing that ND degrades as the
null moves closer to the source look direction, indicating reduced interference
suppression.

</details>


### [11] [Analyzing URA Geometry for Enhanced Spatial Multiplexing and Extended Near-Field Coverage](https://arxiv.org/abs/2506.15470)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 这篇论文研究了大型天线阵列在近场区域的波束聚焦性能，分析了不同阵列几何形状对波束深度和空间复用能力的影响，并提出了有效波束聚焦瑞利距离（EBRD）的概念。


<details>
  <summary>Details</summary>
Motivation: 随着高频段大型天线阵列的使用，未来无线通信系统可能在辐射近场区域运行。研究近场波束聚焦的性能及其对空间复用的影响具有重要意义。

Method: 论文推导了广义均匀矩形阵列（URA）的波束深度，并探讨了阵列几何形状如何影响近场波束深度和波束聚焦的实现极限。通过定义EBRD，表征了近场边界在波束聚焦和空间复用增益方面的表现。

Result: 研究发现，尽管方形URA实现了最窄的波束深度，但其EBRD受到严重限制。相比之下，宽或高的URA虽然在波束深度上略逊，但EBRD更大，从而显著提高了多用户和速率（3.5倍）。

Conclusion: 论文得出结论，宽或高的URA因其扩展的EBRD和更强的空间复用能力，在近场通信中比方形URA更具优势。

Abstract: With the deployment of large antenna arrays at high frequency bands, future
wireless communication systems are likely to operate in the radiative
near-field. Unlike far-field beam steering, near-field beams can be focused
within a spatial region of finite depth, enabling spatial multiplexing in both
the angular and range dimensions. This paper derives the beamdepth for a
generalized uniform rectangular array (URA) and investigates how array geometry
influences the near-field beamdepth and the limits where near-field
beamfocusing is achievable. To characterize the near-field boundary in terms of
beamfocusing and spatial multiplexing gains, we define the effective
beamfocusing Rayleigh distance (EBRD) for a generalized URA. Our analysis
reveals that while a square URA achieves the narrowest beamdepth, the EBRD is
maximized for a wide or tall URA. However, despite its narrow beamdepth, a
square URA may experience a reduction in multiuser sum rate due to its severely
constrained EBRD. Simulation results confirm that a wide or tall URA achieves a
sum rate of 3.5 X more than that of a square URA, benefiting from the extended
EBRD and improved spatial multiplexing capabilities.

</details>


### [12] [Near-Field SWIPT with gMIMO in the Upper Mid-Band: Opportunities, Challenges, and the Way Forward](https://arxiv.org/abs/2506.15670)
*Özlem Tugfe Demir,Mustafa Ozger,Ferdi Kara,Woong-Hee Lee,Emil Björnson*

Main category: eess.SP

TL;DR: 探讨了在7-24 GHz频段的上中频范围内，将SWIPT技术与gMIMO集成的潜在优势，提出了近场传播下能效高、大容量的6G通信系统。


<details>
  <summary>Details</summary>
Motivation: 为了满足6G无线网络对高能效和大容量通信的需求，研究团队探索了SWIPT与gMIMO技术的结合，利用近场传播特性实现精准的能量和数据传输。

Method: 结合球形波传播理论，设计先进的信道估计技术、预编码策略以及动态阵列配置（如稀疏和模块化阵列），以优化能量收集和数据吞吐量。

Result: 通过理论分析和案例研究，验证了在密集和动态环境中实现优化的能量收集和高数据吞吐量的可行性。

Conclusion: 该研究为能源自给自足的物联网应用和智能工厂网络提供了技术支持，推动下一代无线技术目标的实现。

Abstract: This paper explores the integration of simultaneous wireless information and
power transfer (SWIPT) with gigantic multiple-input multiple-output (gMIMO)
technology operating in the upper mid-band frequency range (7-24 GHz). The
near-field propagation achieved by gMIMO introduces unique opportunities for
energy-efficient, high-capacity communication systems that cater to the demands
of 6G wireless networks. Exploiting spherical wave propagation, near-field
SWIPT with gMIMO enables precise energy and data delivery, enhancing spectral
efficiency through beamfocusing and massive spatial multiplexing. This paper
discusses theoretical principles, design challenges, and enabling solutions,
including advanced channel estimation techniques, precoding strategies, and
dynamic array configurations such as sparse and modular arrays. Through
analytical insights and a case study, this paper demonstrates the feasibility
of achieving optimized energy harvesting and data throughput in dense and
dynamic environments. These findings contribute to advancing energy-autonomous
Internet-of-Everything (IoE) deployments, smart factory networks, and other
energy-autonomous applications aligned with the goals of next-generation
wireless technologies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets](https://arxiv.org/abs/2506.15075)
*Samhita Kuili,Mohammadreza Amini,Burak Kantarci*

Main category: cs.CR

TL;DR: 论文提出了一种基于卷积自编码器（CAE）的方法，用于检测5G-NR网络中的干扰攻击，并通过生成对抗网络（CWGAN-GP）平衡数据集。CAE在检测性能上优于其他基准模型。


<details>
  <summary>Details</summary>
Motivation: 5G-NR无线蜂窝网络中，空中干扰攻击日益普遍，严重影响信号质量，因此需要有效的干扰检测方法。

Method: 研究通过添加高斯噪声模拟干扰环境，利用CAE进行干扰检测，并采用CWGAN-GP平衡数据集。

Result: CAE在精度（97.33%）、召回率（91.33%）、F1分数（94.08%）和准确率（94.35%）上均优于基准模型。

Conclusion: CAE在复杂数据环境下表现出强大的干扰检测能力，为5G-NR网络安全提供了有效解决方案。

Abstract: In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [14] [Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations](https://arxiv.org/abs/2506.14795)
*Batuhan Hangun,Emine Akpinar,Oguz Altun,Onder Eyecioglu*

Main category: quant-ph

TL;DR: 该研究通过评估量子神经网络（QNNs）表现，证明其在风力预测任务中优于经典方法，准确率达93%，展示了量子机器学习（QML）的潜力。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习（QML）旨在通过量子力学原理增强经典机器学习方法，但目前对其实际优势的质疑因NISQ设备的限制而存在。

Method: 研究者构建并评估了12种不同配置的QNN，结合两种量子特征映射和六种纠缠策略，在风力能源数据集上进行实验。

Result: 实验结果显示，使用Z特征映射的QNN在风力预测任务中达到93%的准确率，优于经典方法。

Conclusion: 研究表明QNN在预测任务中具有显著优势，支持QML在实际应用中的潜力。

Abstract: Quantum Machine Learning (QML) is an emerging field at the intersection of
quantum computing and machine learning, aiming to enhance classical machine
learning methods by leveraging quantum mechanics principles such as
entanglement and superposition. However, skepticism persists regarding the
practical advantages of QML, mainly due to the current limitations of noisy
intermediate-scale quantum (NISQ) devices. This study addresses these concerns
by extensively assessing Quantum Neural Networks (QNNs)-quantum-inspired
counterparts of Artificial Neural Networks (ANNs), demonstrating their
effectiveness compared to classical methods. We systematically construct and
evaluate twelve distinct QNN configurations, utilizing two unique quantum
feature maps combined with six different entanglement strategies for ansatz
design. Experiments conducted on a wind energy dataset reveal that QNNs
employing the Z feature map achieve up to 93% prediction accuracy when
forecasting wind power output using only four input parameters. Our findings
show that QNNs outperform classical methods in predictive tasks, underscoring
the potential of QML in real-world applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels](https://arxiv.org/abs/2506.15225)
*Jiahao You,Ziye Jia,Chao Dong,Qihui Wu,Zhu Han*

Main category: cs.AI

TL;DR: 提出了一个基于无人机和船舶协作的海上多接入边缘计算（MEC）框架，用于解决海上物联网（MIoT）中的计算卸载和资源分配问题，并通过Lyapunov优化和马尔可夫博弈方法优化任务执行时间。


<details>
  <summary>Details</summary>
Motivation: 随着海上物联网（MIoT）计算需求的快速增长，现有的无人机（UAVs）和船舶组成的多接入边缘计算（MEC）系统面临计算卸载和资源分配的低效问题，特别是在任务不确定的情况下。

Method: 提出了一个协作的MEC框架，结合Lyapunov优化处理任务不确定性，将问题转化为小型优化问题，并通过马尔可夫博弈（MG）和异构智能体软角色-批评（Heterogeneous-agent soft actor-critic）算法解决资源分配问题。

Result: 通过仿真验证了所提框架在计算卸载和资源分配方面的有效性。

Conclusion: 该方法能够高效处理海上物联网中的不确定任务，优化计算卸载和资源分配。

Abstract: The computation demands from the maritime Internet of Things (MIoT) increase
rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels
based multi-access edge computing (MEC) can fulfill these MIoT requirements.
However, the uncertain maritime tasks present significant challenges of
inefficient computation offloading and resource allocation. In this paper, we
focus on the maritime computation offloading and resource allocation through
the cooperation of UAVs and vessels, with consideration of uncertain tasks.
Specifically, we propose a cooperative MEC framework for computation offloading
and resource allocation, including MIoT devices, UAVs and vessels. Then, we
formulate the optimization problem to minimize the total execution time. As for
the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the
unpredictable task arrivals and varying computational resource availability. By
converting the long-term constraints into short-term constraints, we obtain a
set of small-scale optimization problems. Further, considering the
heterogeneity of actions and resources of UAVs and vessels, we reformulate the
small-scale optimization problem into a Markov game (MG). Moreover, a
heterogeneous-agent soft actor-critic is proposed to sequentially update
various neural networks and effectively solve the MG problem. Finally,
simulations are conducted to verify the effectiveness in addressing
computational offloading and resource allocation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models](https://arxiv.org/abs/2506.15530)
*Teysir Baoueb,Xiaoyu Bie,Xi Wang,Gaël Richard*

Main category: cs.SD

TL;DR: 本文探讨了如何利用现有的文本到音乐扩散模型进行乐器编辑，通过在生成过程中选择适当的时间步长来平衡保留原始音频内容和实现目标音色。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到音乐生成模型为音乐创作提供了新的工具，但如何在生成过程中精确控制以实现特定效果仍然是一个挑战。本文旨在解决这一问题，特别是在乐器编辑方面。

Method: 通过分析模型生成音频的过程（先关注整体结构，再添加乐器信息，最后细化质量），选择合适的时间步长（通过乐器分类器确定），以编辑乐器而不影响原始内容。

Result: 该方法在不需额外训练或影响生成速度的情况下，成功实现了乐器编辑的平衡效果。

Conclusion: 本研究为文本到音乐模型的精细控制提供了一种新方法，能够在无需额外训练的情况下实现高效的乐器编辑。

Abstract: Breakthroughs in text-to-music generation models are transforming the
creative landscape, equipping musicians with innovative tools for composition
and experimentation like never before. However, controlling the generation
process to achieve a specific desired outcome remains a significant challenge.
Even a minor change in the text prompt, combined with the same random seed, can
drastically alter the generated piece. In this paper, we explore the
application of existing text-to-music diffusion models for instrument editing.
Specifically, for an existing audio track, we aim to leverage a pretrained
text-to-music diffusion model to edit the instrument while preserving the
underlying content. Based on the insight that the model first focuses on the
overall structure or content of the audio, then adds instrument information,
and finally refines the quality, we show that selecting a well-chosen
intermediate timestep, identified through an instrument classifier, yields a
balance between preserving the original piece's content and achieving the
desired timbre. Our method does not require additional training of the
text-to-music diffusion model, nor does it compromise the generation process's
speed.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [17] [Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels](https://arxiv.org/abs/2506.15105)
*David Nozadze,Zurab Kiguradze,Amendra Koul,Mike Sapozhnikov*

Main category: eess.SY

TL;DR: 论文提出两种新指标（SILD和FOM_SILD）以量化P/N偏斜对高速互连性能的影响，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI工作负载和数据中心需求的增加，对超过200 Gb/s的超高速互连的需求日益迫切，但P/N偏斜的微小变化会影响性能，传统量化方法不足。

Method: 引入两种新指标：SILD（偏斜引起的插入损耗偏差）和FOM_SILD（互补的优值指标），通过理论分析和实验测量（S参数）验证其有效性。

Result: 实验表明FOM_SILD具有互易性，且对224G PAM4 SerDes的模拟结果与误码率趋势高度相关。

Conclusion: 该方法为下一代超高速互连中的偏斜分析提供了稳健框架。

Abstract: The rise of AI workloads and growing data center demands have driven the need
for ultra-high-speed interconnects exceeding 200 Gb/s. As unit intervals (UI)
shrink, even a few picoseconds of P/N skew can degrade serializer-deserializer
(SerDes) performance. Traditional methods for quantifying skew fall short in
capturing its impact. We introduce two new metrics: 1) Skew-Induced Insertion
Loss Deviation (SILD) and 2) its complementary Figure of Merit (FOM_SILD),
analytically developed to assess P/N skew effects. Measured S-parameters
confirm FOM_SILD reciprocity, while simulations of 224G PAM4 SerDes show strong
correlation with bit error rate (BER) trends. This approach offers a robust
framework for analyzing skew in next-generation ultra-high-speed interconnects.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [18] [An Integrated Sensing and Communication System for Time-Sensitive Targets with Random Arrivals](https://arxiv.org/abs/2506.15045)
*Homa Nikbakht,Yonina C. Eldar,H. Vincent Poor*

Main category: cs.IT

TL;DR: 6G网络中，ISAC与URLLC结合的双静态MIMO系统通过DPC技术提升性能，优于传统方案。


<details>
  <summary>Details</summary>
Motivation: 支持智能城市和自动驾驶等应用，需同时满足高可靠低延迟通信（URLLC）和感知需求。

Method: 提出双静态MIMO ISAC系统，利用DPC技术减少干扰，并评估FBL下的性能权衡。

Result: DPC方案在满足URLLC和感知约束的同时，提升了eMBB传输速率。

Conclusion: DPC-based ISAC系统在性能上优于传统方案，适合未来6G网络需求。

Abstract: In 6G networks, integrated sensing and communication (ISAC) is envisioned as
a key technology that enables wireless systems to perform joint sensing and
communication using shared hardware, antennas and spectrum. ISAC designs
facilitate emerging applications such as smart cities and autonomous driving.
Such applications also demand ultra-reliable and low-latency communication
(URLLC). Thus, an ISAC-enabled URLLC system can prioritize time-sensitive
targets and ensure information delivery under strict latency and reliability
constraints. We propose a bi-static MIMO ISAC system to detect the arrival of
URLLC messages and prioritize their delivery. In this system, a base station
(BS) communicates with a user equipment (UE) and a sensing receiver (SR) is
deployed to collect echo signals reflected from a target of interest. The BS
regularly transmits messages of enhanced mobile broadband (eMBB) services to
the UE. During each eMBB transmission, if the SR senses the presence of a
target of interest, it immediately triggers the transmission of an additional
URLLC message. To reinforce URLLC transmissions, we propose a dirty-paper
coding (DPC)-based technique that mitigates the interference of both eMBB and
sensing signals. To decode the eMBB message, we consider two approaches for
handling the URLLC interference: treating interference as noise and successive
interference cancellation. For this system, we formulate the
rate-reliability-detection trade-off in the finite blocklength (FBL) regime by
evaluating the communication rate of the eMBB transmissions, the reliability of
the URLLC transmissions and the probability of the target detection. Our
numerical analysis show that our proposed DPC-based ISAC scheme significantly
outperforms power-sharing and traditional time-sharing schemes. In particular,
it achieves higher eMBB transmission rate while satisfying both URLLC and
sensing constraints.

</details>


### [19] [MIMO Systems Aided by Microwave Linear Analog Computers: Capacity-Achieving Architectures with Reduced Circuit Complexity](https://arxiv.org/abs/2506.15052)
*Matteo Nerini,Bruno Clerckx*

Main category: cs.IT

TL;DR: 提出了一种基于图论模型的stem-connected MiLAC架构，显著降低了电路复杂度，同时保持了容量优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统MiLAC架构因完全连接导致的电路复杂度高、难以实际应用的问题。

Method: 利用图论模型设计stem-connected MiLAC，并通过闭式解优化其性能。

Result: stem-connected MiLAC实现了容量优化，且电路复杂度与天线数量呈线性关系。

Conclusion: 该架构为高性能、可扩展的超大规模MIMO提供了实用解决方案。

Abstract: To meet the demands of future wireless networks, antenna arrays must scale
from massive multiple-input multiple-output (MIMO) to gigantic MIMO, involving
even larger numbers of antennas. To address the hardware and computational cost
of gigantic MIMO, several strategies are available that shift processing from
the digital to the analog domain. Among them, microwave linear analog computers
(MiLACs) offer a compelling solution by enabling fully analog beamforming
through reconfigurable microwave networks. Prior work has focused on
fully-connected MiLACs, whose ports are all interconnected to each other via
tunable impedance components. Although such MiLACs are capacity-achieving,
their circuit complexity, given by the number of required impedance components,
scales quadratically with the number of antennas, limiting their practicality.
To solve this issue, in this paper, we propose a graph theoretical model of
MiLAC facilitating the systematic design of lower-complexity MiLAC
architectures. Leveraging this model, we propose stem-connected MiLACs as a
family of MiLAC architectures maintaining capacity-achieving performance while
drastically reducing the circuit complexity. Besides, we optimize
stem-connected MiLACs with a closed-form capacity-achieving solution. Our
theoretical analysis, confirmed by numerical simulations, shows that
stem-connected MiLACs are capacity-achieving, but with circuit complexity that
scales linearly with the number of antennas, enabling high-performance,
scalable, gigantic MIMO.

</details>


### [20] [In-Context Learning for Gradient-Free Receiver Adaptation: Principles, Applications, and Theory](https://arxiv.org/abs/2506.15176)
*Matteo Zecchin,Tomer Raviv,Dileep Kalathil,Krishna Narayanan,Nir Shlezinger,Osvaldo Simeone*

Main category: cs.IT

TL;DR: 本文介绍了基于上下文学习的无梯度自适应技术，用于无线接收器的实时适应，无需在线重新训练。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在无线接收器自适应上存在灵活性不足或需显式优化的问题，本文提出更高效的解决方案。

Method: 利用Transformer和结构化状态空间模型（SSMs）的架构框架，结合上下文学习理论，提出无梯度自适应技术。

Result: 在蜂窝自由大规模MIMO网络中应用上下文学习，理论和实验结果均显示其高效性。

Conclusion: 上下文学习为无线接收器的实时自适应提供了一种原则性强且高效的途径。

Abstract: In recent years, deep learning has facilitated the creation of wireless
receivers capable of functioning effectively in conditions that challenge
traditional model-based designs. Leveraging programmable hardware
architectures, deep learning-based receivers offer the potential to dynamically
adapt to varying channel environments. However, current adaptation strategies,
including joint training, hypernetwork-based methods, and meta-learning, either
demonstrate limited flexibility or necessitate explicit optimization through
gradient descent. This paper presents gradient-free adaptation techniques
rooted in the emerging paradigm of in-context learning (ICL). We review
architectural frameworks for ICL based on Transformer models and structured
state-space models (SSMs), alongside theoretical insights into how sequence
models effectively learn adaptation from contextual information. Further, we
explore the application of ICL to cell-free massive MIMO networks, providing
both theoretical analyses and empirical evidence. Our findings indicate that
ICL represents a principled and efficient approach to real-time receiver
adaptation using pilot signals and auxiliary contextual information-without
requiring online retraining.

</details>
