{"id": "2510.15114", "pdf": "https://arxiv.org/pdf/2510.15114", "abs": "https://arxiv.org/abs/2510.15114", "authors": ["Marios-Nektarios Stamatopoulos", "Elias Small", "Shridhar Velhal", "Avijit Banerjee", "George Nikolakopoulos"], "title": "Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration", "categories": ["cs.RO"], "comment": null, "summary": "This article presents a fully autonomous aerial masonry construction\nframework using heterogeneous unmanned aerial vehicles (UAVs), supported by\nexperimental validation. Two specialized UAVs were developed for the task: (i)\na brick-carrier UAV equipped with a ball-joint actuation mechanism for precise\nbrick manipulation, and (ii) an adhesion UAV integrating a servo-controlled\nvalve and extruder nozzle for accurate adhesion application. The proposed\nframework employs a reactive mission planning unit that combines a dependency\ngraph of the construction layout with a conflict graph to manage simultaneous\ntask execution, while hierarchical state machines ensure robust operation and\nsafe transitions during task execution. Dynamic task allocation allows\nreal-time adaptation to environmental feedback, while minimum-jerk trajectory\ngeneration ensures smooth and precise UAV motion during brick pickup and\nplacement. Additionally, the brick-carrier UAV employs an onboard vision system\nthat estimates brick poses in real time using ArUco markers and a least-squares\noptimization filter, enabling accurate alignment during construction. To the\nbest of the authors' knowledge, this work represents the first experimental\ndemonstration of fully autonomous aerial masonry construction using\nheterogeneous UAVs, where one UAV precisely places the bricks while another\nautonomously applies adhesion material between them. The experimental results\nsupported by the video showcase the effectiveness of the proposed framework and\ndemonstrate its potential to serve as a foundation for future developments in\nautonomous aerial robotic construction."}
{"id": "2510.15189", "pdf": "https://arxiv.org/pdf/2510.15189", "abs": "https://arxiv.org/abs/2510.15189", "authors": ["Xiangyu Chen", "Chuhao Zhou", "Yuxi Liu", "Jianfei Yang"], "title": "RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Precise robot manipulation is critical for fine-grained applications such as\nchemical and biological experiments, where even small errors (e.g., reagent\nspillage) can invalidate an entire task. Existing approaches often rely on\npre-collected expert demonstrations and train policies via imitation learning\n(IL) or offline reinforcement learning (RL). However, obtaining high-quality\ndemonstrations for precision tasks is difficult and time-consuming, while\noffline RL commonly suffers from distribution shifts and low data efficiency.\nWe introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies\nonline and offline training in real-world environments. The key idea is a\nrole-model strategy that automatically generates labels for online training\ndata using approximately optimal actions, eliminating the need for human\ndemonstrations. RM-RL reformulates policy learning as supervised training,\nreducing instability from distribution mismatch and improving efficiency. A\nhybrid training scheme further leverages online role-model data for offline\nreuse, enhancing data efficiency through repeated sampling. Extensive\nexperiments show that RM-RL converges faster and more stably than existing RL\nmethods, yielding significant gains in real-world manipulation: 53% improvement\nin translation accuracy and 20% in rotation accuracy. Finally, we demonstrate\nthe successful execution of a challenging task, precisely placing a cell plate\nonto a shelf, highlighting the framework's effectiveness where prior methods\nfail."}
{"id": "2510.15199", "pdf": "https://arxiv.org/pdf/2510.15199", "abs": "https://arxiv.org/abs/2510.15199", "authors": ["Borna Monazzah Moghaddam", "Robin Chhabra"], "title": "Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit", "categories": ["cs.RO"], "comment": null, "summary": "This article presents an extension of the Lagrange-Poincare Equations (LPE)\nto model the dynamics of spacecraft-manipulator systems operating within a\nnon-inertial orbital reference frame. Building upon prior formulations of LPE\nfor vehicle-manipulator systems, the proposed framework, termed the\nLagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between\nspacecraft attitude dynamics, orbital motion, and manipulator kinematics. The\nformalism combines the Euler-Poincare equations for the base spacecraft,\nKeplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange\nequations for the manipulator's shape space, using an exponential joint\nparametrization. Leveraging the Lagrange-d'Alembert principle on principal\nbundles, we derive novel closed-form structural matrices that explicitly\ncapture the effects of orbital disturbances and their dynamic coupling with the\nmanipulator system. The LPKE framework also systematically includes externally\napplied, symmetry-breaking wrenches, allowing for immediate integration into\nhardware-in-the-loop simulations and model-based control architectures for\nautonomous robotic operations in the orbital environment. To illustrate the\neffectiveness of the proposed model and its numerical superiority, we present a\nsimulation study analyzing orbital effects on a 7-degree-of-freedom manipulator\nmounted on a spacecraft."}
{"id": "2510.15220", "pdf": "https://arxiv.org/pdf/2510.15220", "abs": "https://arxiv.org/abs/2510.15220", "authors": ["Kevin Christiansen Marsim", "Minho Oh", "Byeongho Yu", "Seungjae Lee", "I Made Aswin Nahrendra", "Hyungtae Lim", "Hyun Myung"], "title": "LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization", "categories": ["cs.RO"], "comment": "8 Pages, 9 Figures", "summary": "Autonomous navigation for legged robots in complex and dynamic environments\nrelies on robust simultaneous localization and mapping (SLAM) systems to\naccurately map surroundings and localize the robot, ensuring safe and efficient\noperation. While prior sensor fusion-based SLAM approaches have integrated\nvarious sensor modalities to improve their robustness, these algorithms are\nstill susceptible to estimation drift in challenging environments due to their\nreliance on unsuitable fusion strategies. Therefore, we propose a robust\nLiDAR-visual-inertial-kinematic odometry system that integrates information\nfrom multiple sensors, such as a camera, LiDAR, inertial measurement unit\n(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our\nsystem employs a fusion-based pose estimation approach that runs\noptimization-based visual-inertial-kinematic odometry (VIKO) and filter-based\nLiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In\nVIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth\nconsistency using superpixel clusters in a sliding window optimization. In\nLIKO, we incorporate foot kinematics and employ a point-toplane residual in an\nerror-state iterative Kalman filter (ESIKF). Compared with other sensor\nfusion-based SLAM algorithms, our approach shows robust performance across\npublic and longterm datasets."}
{"id": "2510.15070", "pdf": "https://arxiv.org/pdf/2510.15070", "abs": "https://arxiv.org/abs/2510.15070", "authors": ["Álvaro Pendás-Recondo", "Enrique Pendás-Recondo"], "title": "A Structured Family of Grassmannian Constellations via Geodesic Mapping for MIMO Noncoherent Communications", "categories": ["eess.SP", "math.DG", "94A14, 94A12, 14M15, 53C22"], "comment": "13 pages, 7 figures", "summary": "This work presents a novel structured family of Grassmannian constellations\nfor multiple-input multiple-output (MIMO) noncoherent communications over\nRayleigh block-fading channels, where neither the transmitter nor the receiver\nhas channel state information (CSI). The proposed constellation design is built\nupon the geodesic curves of the Grassmann manifold, thereby exploiting its\nunderlying geometric structure. The resulting solution is limited in spectral\nefficiency (with a maximum constellation size of $4M^2$ points, where $M$ is\nthe number of transmit antennas), targeting a rate in the range of $0.25$-$1$\nbps/Hz. However, all space-time matrices resulting from this design exhibit the\nremarkable property of having a single nonzero entry per row, meaning that only\none transmit antenna is active per time slot. This property significantly\nreduces hardware complexity and implementation cost, while also lowering power\nconsumption, as only a single power amplifier is required for transmission.\nFurthermore, within the constellation size limits, the proposed design achieves\nerror performance comparable to state-of-the-art optimization-based\nunstructured designs, as validated through symbol error rate (SER) numerical\nresults. It also enables simple yet effective bit labeling, confirmed by\ncomparisons of bit error rate (BER) and SER, and reduces the computational\ncomplexity of the maximum-likelihood (ML) detector for Grassmannian\nconstellations by a factor of $M$."}
{"id": "2510.15226", "pdf": "https://arxiv.org/pdf/2510.15226", "abs": "https://arxiv.org/abs/2510.15226", "authors": ["Mrunal Sarvaiya", "Guanrui Li", "Giuseppe Loianno"], "title": "PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation", "categories": ["cs.RO"], "comment": null, "summary": "Aerial transportation robots using suspended cables have emerged as versatile\nplatforms for disaster response and rescue operations. To maximize the\ncapabilities of these systems, robots need to aggressively fly through tightly\nconstrained environments, such as dense forests and structurally unsafe\nbuildings, while minimizing flight time and avoiding obstacles. Existing\nmethods geometrically over-approximate the vehicle and obstacles, leading to\nconservative maneuvers and increased flight times. We eliminate these\nrestrictions by proposing PolyFly, an optimal global planner which considers a\nnon-conservative representation for aerial transportation by modeling each\nphysical component of the environment, and the robot (quadrotor, cable and\npayload), as independent polytopes. We further increase the model accuracy by\nincorporating the attitude of the physical components by constructing\norientation-aware polytopes. The resulting optimal control problem is\nefficiently solved by converting the polytope constraints into smooth\ndifferentiable constraints via duality theory. We compare our method against\nthe existing state-of-the-art approach in eight maze-like environments and show\nthat PolyFly produces faster trajectories in each scenario. We also\nexperimentally validate our proposed approach on a real quadrotor with a\nsuspended payload, demonstrating the practical reliability and accuracy of our\nmethod."}
{"id": "2510.15195", "pdf": "https://arxiv.org/pdf/2510.15195", "abs": "https://arxiv.org/abs/2510.15195", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Robert Calderbank"], "title": "Pulse Shaping Filter Design for Integrated Sensing & Communication with Zak-OTFS", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": "6 pages, 3 figures, to be submitted to IEEE for possible publication", "summary": "Zak-OTFS is an emerging framework for integrated sensing & communication\n(ISAC) in high delay and Doppler spread environments. A critical enabler for\nISAC with Zak-OTFS is the design of pulse shaping filters. For sensing, a\nlocalized pulse shaping filter enables ideal input-output (I/O) relation\nestimates close to the physical scattering channel. For communication,\northogonality of the pulse shape on the information lattice prevents\ninter-symbol interference, and no time and bandwidth expansion enables full\nspectral efficiency. A filter simultaneously meeting all three objectives is\nideal for ISAC. Existing filter designs achieve two of the above objectives,\nbut not all three simultaneously. For instance, the sinc filter is orthogonal\nand bandwidth/time-limited, but is not localized. The Gaussian filter is\nlocalized and bandwidth/time-limited, but not orthogonal. The RRC filter is\nlocalized and orthogonal, but not bandwidth/time-limited. A recently proposed\nhybrid Gaussian-sinc filter is more localized than the sinc filter and\nbandwidth/time-limited, but is not orthogonal. In this work, we design optimal\npulse shaping filters meeting all three objectives via the Isotropic Orthogonal\nTransform Algorithm. The proposed pulse shaping filters offer improved data\ndetection (communication) and I/O relation estimation (sensing) performance\ncompared to existing filter choices in the literature."}
{"id": "2510.15229", "pdf": "https://arxiv.org/pdf/2510.15229", "abs": "https://arxiv.org/abs/2510.15229", "authors": ["Sina Kazemdehbashi", "Yanchao Liu", "Boris S. Mordukhovich"], "title": "A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs", "categories": ["cs.RO", "math.OC"], "comment": null, "summary": "Natural and human-made disasters can cause severe devastation and claim\nthousands of lives worldwide. Therefore, developing efficient methods for\ndisaster response and management is a critical task for relief teams. One of\nthe most essential components of effective response is the rapid collection of\ninformation about affected areas, damages, and victims. More data translates\ninto better coordination, faster rescue operations, and ultimately, more lives\nsaved. However, in some disasters, such as earthquakes, the communication\ninfrastructure is often partially or completely destroyed, making it extremely\ndifficult for victims to send distress signals and for rescue teams to locate\nand assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as\nvaluable tools in such scenarios. In particular, a fleet of UAVs can be\ndispatched from a mobile station to the affected area to facilitate data\ncollection and establish temporary communication networks. Nevertheless,\nreal-world deployment of UAVs faces several challenges, with adverse weather\nconditions--especially wind--being among the most significant. To address this,\nwe develop a novel mathematical framework to determine the optimal location of\na mobile UAV station while explicitly accounting for the heterogeneity of the\nUAVs and the effect of wind. In particular, we generalize the Sylvester problem\nto introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures\ncomplex factors such as wind influence, UAV heterogeneity, and back-and-forth\nmotion within a unified framework. The proposed framework enhances the\npracticality of UAV-based disaster response planning by accounting for\nreal-world factors such as wind and UAV heterogeneity. Experimental results\ndemonstrate that it can reduce wasted operational time by up to 84%, making\npost-disaster missions significantly more efficient and effective."}
{"id": "2510.15278", "pdf": "https://arxiv.org/pdf/2510.15278", "abs": "https://arxiv.org/abs/2510.15278", "authors": ["Heyao Zhu", "Yimeng Zhao", "Zirui Zhang", "Huansheng Yi", "Chenbin Gao", "Canhua Xu", "Jianqi Wang", "Fugui Qi"], "title": "Multidimensional Physiology-Inspired Enhanced Vital Sign Monitoring Using MIMO mmWave Bio-radar", "categories": ["eess.SP"], "comment": null, "summary": "With the intensiffcation of population aging and increasing burden of chronic\ndiseases, the demand for vital signs monitoring is becoming increasingly\nurgent. A key challenge facing current non-contact detection technologies using\nmillimeter wave (mmWave) radar is the low efffciency of multi-channel signal\nfusion in array radar systems based on equal weighting. To address this\nchallenge, this paper proposes a vital sign enhancement detection method for\nmultiple input and multiple output (MIMO) bio-radar, driven by multidimensional\nphysiological characteristics, which overcomes traditional limitations through\na two-stage fusion strategy. Stage 1: Enhanced Vital Sign Detection Using\nSingle-Channel Signals Based on Physiological Characteristics. First, a chest\nwall multi-scattering point model is constructed. For single channel\ntime-distance two-dimensional echo signals, effective range bins are selected\nbased on the respiratory/cardiac physiological frequency band energy ratio, and\nthe signal-to-noise ratio (SNR) of respiration/heart signals is enhanced using\nphase-aligned maximal ratio combining (MRC). Stage 2: Multi-Channel Fusion\nBased on Organ Radiation Spatial Distribution Characteristics. The spatial\nradiation characteristics of cardiopulmonary organs are introduced for the\nffrst time as the theoretical foundation for SNR-based channel screening,\nchannel attribute identiffcation, and multi-channel weighted fusion. Then, we\npropose a template matching method to extract respiratory rate (RR) and heart\nrate (HR) by adopting physical models of respiration and cardiac activities.\nThe experimental results demonstrate the existence of the spatial distribution\ncharacteristics of organ radiation. In addition, we analyzed the impact of\ndistance and state on the algorithm from these two aspects."}
{"id": "2510.15319", "pdf": "https://arxiv.org/pdf/2510.15319", "abs": "https://arxiv.org/abs/2510.15319", "authors": ["Jeewon Kim", "Minho Oh", "Hyun Myung"], "title": "Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping", "categories": ["cs.RO"], "comment": "Accepted by RiTA 2024", "summary": "Scene graphs enhance 3D mapping capabilities in robotics by understanding the\nrelationships between different spatial elements, such as rooms and objects.\nRecent research extends scene graphs to hierarchical layers, adding and\nleveraging constraints across these levels. This approach is tightly integrated\nwith pose-graph optimization, improving both localization and mapping accuracy\nsimultaneously. However, when segmenting spatial characteristics, consistently\nrecognizing rooms becomes challenging due to variations in viewpoints and\nlimited field of view (FOV) of sensors. For example, existing real-time\napproaches often over-segment large rooms into smaller, non-functional spaces\nthat are not useful for localization and mapping due to the time-dependent\nmethod. Conversely, their voxel-based room segmentation method often\nunder-segment in complex cases like not fully enclosed 3D space that are\nnon-traversable for ground robots or humans, leading to false constraints in\npose-graph optimization. We propose a traversability-aware room segmentation\nmethod that considers the interaction between robots and surroundings, with\nconsistent feasibility of traversability information. This enhances both the\nsemantic coherence and computational efficiency of pose-graph optimization.\nImproved performance is demonstrated through the re-detection frequency of the\nsame rooms in a dataset involving repeated traversals of the same space along\nthe same path, as well as the optimization time consumption."}
{"id": "2510.15457", "pdf": "https://arxiv.org/pdf/2510.15457", "abs": "https://arxiv.org/abs/2510.15457", "authors": ["Chunhui Li", "Chengrui Wang", "Zhiqiang Yuan", "Wei Fan"], "title": "Multi-Target Flexible Angular Emulation for ISAC Base Station Testing Using a Conductive Amplitude and Phase Matrix Setup: Framework and Experimental Validation", "categories": ["eess.SP"], "comment": null, "summary": "Comprehensive evaluation of the functionalities, algorithms, hardware\ncomponents, and performance characteristics of future integrated sensing and\ncommunication (ISAC) base stations (BSs) under realistic deployment scenarios\nin controlled laboratory environments represents a critical requirement for\nISAC technology advancement. A primary challenge in achieving this objective\ninvolves the emulation of multiple targets with arbitrary radar cross-section\n(RCS), range, angle, and Doppler profiles for ISAC BS equipped with large-scale\nantenna arrays using radar target simulator (RTS) with limited interface ports.\nIn this work, we introduce a simple yet highly effective and practical\nconductive amplitude and phase matrix framework to address this fundamental\nchallenge. The core concept involves introducing a tunable conductive amplitude\nand phase modulation network in the test configuration between the ISAC BS\nunder test and a RTS. Based on this structure, we subsequently investigate the\ncorresponding configurations for different sensing operational modes of ISAC\nBSs, specifically the array duplex transmission and reception (ADTR) mode and\nthe split-array transmission and reception (SATR) mode. For experimental\nvalidation, we design two distinct monostatic sensing scenarios to demonstrate\nthe framework capabilities across both operational modes. The first scenario\ninvolves dynamic multi-drone sensing validation for ADTR mode operation, while\nthe second scenario addresses static single-drone sensing for SATR mode\nvalidation. The experimental results demonstrate that the proposed framework\ncan accurately emulate the joint RCS, range, velocity, and angular\ncharacteristics of multiple sensing targets within the conductive test\nenvironment, highlighting its significant potential for testing applications in\nsub-6 GHz ISAC BS development and validation."}
{"id": "2510.15331", "pdf": "https://arxiv.org/pdf/2510.15331", "abs": "https://arxiv.org/abs/2510.15331", "authors": ["Gahee Kim", "Takamitsu Matsubara"], "title": "ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Black-box simulators are widely used in robotics, but optimizing their\nparameters remains challenging due to inaccessible likelihoods.\nSimulation-Based Inference (SBI) tackles this issue using simulation-driven\napproaches, estimating the posterior from offline real observations and forward\nsimulations. However, in black-box scenarios, preparing observations that\ncontain sufficient information for parameter estimation is difficult due to the\nunknown relationship between parameters and observations. In this work, we\npresent Active Simulation-Based Inference (ASBI), a parameter estimation\nframework that uses robots to actively collect real-world online data to\nachieve accurate black-box simulator tuning. Our framework optimizes robot\nactions to collect informative observations by maximizing information gain,\nwhich is defined as the expected reduction in Shannon entropy between the\nposterior and the prior. While calculating information gain requires the\nlikelihood, which is inaccessible in black-box simulators, our method solves\nthis problem by leveraging Neural Posterior Estimation (NPE), which leverages a\nneural network to learn the posterior estimator. Three simulation experiments\nquantitatively verify that our method achieves accurate parameter estimation,\nwith posteriors sharply concentrated around the true parameters. Moreover, we\nshow a practical application using a real robot to estimate the simulation\nparameters of cubic particles corresponding to two real objects, beads and\ngravel, with a bucket pouring action."}
{"id": "2510.15575", "pdf": "https://arxiv.org/pdf/2510.15575", "abs": "https://arxiv.org/abs/2510.15575", "authors": ["Yi Tao", "Zhen Gao", "Zhuoran Li", "Ziwei Wan", "Tuan Li", "Chunli Zhu", "Lei Chen", "Guanghui Wen", "Dezhi Zheng", "Dusit Niyato"], "title": "Pseudo-Random TDM-MIMO FMCW Based Millimeter-Wave Sensing and Communication Integration for UAV Swarm", "categories": ["eess.SP"], "comment": null, "summary": "The integrated sensing and communications (ISAC) can achieve the sharing of\nhardware and spectrum resources, enabling efficient data transmission and\nenvironmental sensing. This fusion is particularly important for unmanned\naerial vehicle (UAV) swarms, as it enhances the overall performance,\nflexibility, and efficiency of such systems. To facilitate the collaborative\noperations among UAVs, this paper proposes an ISAC solution based on the\npseudo-random time-division multiplexing (TDM)-multiple input multiple output\n(MIMO) millimeter-wave (mmWave) frequency modulated continuous wave (FMCW).\nSpecifically, a novel ISAC chirp waveform is proposed to modulate data in both\nthe delay domain and complex amplitude, while also possessing high-precision\nsensing capabilities. To address challenges in the TDM-MIMO, we utilize the\npseudo-random antenna selection and compressed sensing algorithms, ensuring\nthat the maximum unambiguous velocity is not compromised. Moreover, by\nemploying a chirp-division multiple access scheme, we propose an\ninterference-free multiple antenna transmission scheme to achieve dynamic\nallocation of time-frequency resources and multi-user transmission. Finally, we\npropose a communication and sensing fusion-based dynamic iterative computation\nscheme, simultaneously achieving data demodulation and sensing parameter\nestimation. Simulation results show that the proposed scheme can achieve ISAC\nunder the dynamic flight scenarios of UAVs. Meanwhile, the scheme outperforms\nthe mmWave-LoRadar in communication and sensing performance, yet its sensing\nperformance is slightly lower than that of the traditional FMCW. Under the\nurban clutter modeling, the scheme still maintains favorable robustness despite\na certain degree of performance degradation."}
{"id": "2510.15336", "pdf": "https://arxiv.org/pdf/2510.15336", "abs": "https://arxiv.org/abs/2510.15336", "authors": ["Liviu-Mihai Stan", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Masashi Konyo", "Kazunori Ohno"], "title": "Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Reliable navigation in disaster-response and other unstructured indoor\nsettings requires robots not only to avoid obstacles but also to recognise when\nthose obstacles can be pushed aside. We present an adaptive, LiDAR and\nodometry-based path-planning framework that embeds this capability into the\nROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing\nfrom a prior static map as tentatively movable and assigns a reduced traversal\ncost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to\nactual velocity; when the robot slows appreciably, the local cost is raised\nfrom light to heavy, and on a stall to lethal, prompting the global planner to\nback out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated\nobjects and cluttered corridors, show higher goal-reach rates and fewer\ndeadlocks than a no-layer baseline, with traversal times broadly comparable.\nBecause the method relies only on planar scans and CPU-level computation, it\nsuits resource-constrained search and rescue robots and integrates into\nheterogeneous platforms with minimal engineering. Overall, the results indicate\nthat interaction-aware cost maps are a lightweight, ROS2-native extension for\nnavigating among potentially movable obstacles in unstructured settings. The\nfull implementation will be released as open source\nathttps://costmap-namo.github.io."}
{"id": "2510.15689", "pdf": "https://arxiv.org/pdf/2510.15689", "abs": "https://arxiv.org/abs/2510.15689", "authors": ["Gebreslassie atsbha weldegebrial", "hunduma legesse geleta"], "title": "More on Boundary Behavior of Univalent Harmonic Mappings", "categories": ["eess.SP"], "comment": "10 pages and 3 figures", "summary": "Many authors have examined various boundary behaviors of injective harmonic\nmappings in the open unit disk. Building on Laugesen's work, Bshouty and others\nexplored the boundary behavior of harmonic mappings under different conditions.\nIn this paper, we extend their work and find out the angular limits of the\narguments and logarithms of analytic functions under various conditions. We\nalso examined the dilatation possesses only a finite set of zeros within any\nstolz angle if the first derivative of harmonic function $f$ at the boundary is\npositive infinity."}
{"id": "2510.15350", "pdf": "https://arxiv.org/pdf/2510.15350", "abs": "https://arxiv.org/abs/2510.15350", "authors": ["Shyalan Ramesh", "Scott Mann", "Alex Stumpf"], "title": "Nauplius Optimisation for Autonomous Hydrodynamics", "categories": ["cs.RO", "cs.NE"], "comment": null, "summary": "Autonomous Underwater vehicles must operate in strong currents, limited\nacoustic bandwidth, and persistent sensing requirements where conventional\nswarm optimisation methods are unreliable. This paper presents NOAH, a novel\nnature-inspired swarm optimisation algorithm that combines current-aware drift,\nirreversible settlement in persistent sensing nodes, and colony-based\ncommunication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH\naddresses the critical limitations of existing swarm algorithms by providing\nhydrodynamic awareness, irreversible anchoring mechanisms, and colony-based\ncommunication capabilities essential for underwater exploration missions. The\nalgorithm establishes a comprehensive foundation for scalable and\nenergy-efficient underwater swarm robotics with validated performance analysis.\nValidation studies demonstrate an 86% success rate for permanent anchoring\nscenarios, providing a unified formulation for hydrodynamic constraints and\nirreversible settlement behaviours with an empirical study under flow."}
{"id": "2510.15717", "pdf": "https://arxiv.org/pdf/2510.15717", "abs": "https://arxiv.org/abs/2510.15717", "authors": ["Mehdi Zekriyapanah Gashti", "Mostafa Mohammadpour", "Hassan Eshkiki"], "title": "Detection Seizure Onset Zone Using Circadian Fluctuating Epileptic Biomarkers: A Signal Processing and Machine Learning Approach", "categories": ["eess.SP", "68T05, 92C55", "I.5.1; I.2.6"], "comment": null, "summary": "Epileptic biomarkers play a crucial role in identifying the origin of\nseizures, an essential aspect of pre-surgical planning for epilepsy treatment.\nThese biomarkers can vary significantly over time. By studying these temporal\nfluctuations, we can enhance their effectiveness in guiding surgical planning.\nThis research focuses on examining how circadian rhythms influence epilepsy\nbiomarkers and aims to determine the optimal times for their analysis. To\ninvestigate the relationship between epilepsy biomarkers and circadian rhythm,\nthe sleep/wake states first need to be classified. After the biomarkers are\nidentified, they are compared across these states. A retrospective analysis was\nconducted on intracranial electroencephalography data from patients with focal\nepilepsy. The biomarkers spike, sequence of spikes, high-frequency oscillations\n(HFOs), and pathological HFOs were identified through automatic detection. The\nalpha/delta ratio was also calculated to distinguish between asleep and awake\nstages. Data from 9 patients were analyzed, and the classification of sleep and\nwake states was achieved with an area under the curve of 84%. All biomarker\nrates were higher during the sleep stage compared to the wake stage.\nPathological HFOs and the sequence of spikes proved to be more precise\nindicators regarding distance to seizure onset than spikes or HFOs. Unlike\nprevious studies that relied predominantly on long-term spike biomarker\nanalysis, this study is the first to utilize a comprehensive set of biomarkers,\nincluding HFOs, spike sequences, and pathological HFOs, to enhance seizure\nonset zone prediction. The rates of epilepsy biomarkers during sleep vary\nconsiderably from those seen while awake, making sleep data analysis more\neffective for accurately predicting the seizure onset zone."}
{"id": "2510.15352", "pdf": "https://arxiv.org/pdf/2510.15352", "abs": "https://arxiv.org/abs/2510.15352", "authors": ["Alejandro Escontrela", "Justin Kerr", "Arthur Allshire", "Jonas Frey", "Rocky Duan", "Carmelo Sferrazza", "Pieter Abbeel"], "title": "GaussGym: An open-source real-to-sim framework for learning locomotion from pixels", "categories": ["cs.RO", "cs.AI", "cs.GR"], "comment": null, "summary": "We present a novel approach for photorealistic robot simulation that\nintegrates 3D Gaussian Splatting as a drop-in renderer within vectorized\nphysics simulators such as IsaacGym. This enables unprecedented speed --\nexceeding 100,000 steps per second on consumer GPUs -- while maintaining high\nvisual fidelity, which we showcase across diverse tasks. We additionally\ndemonstrate its applicability in a sim-to-real robotics setting. Beyond\ndepth-based sensing, our results highlight how rich visual semantics improve\nnavigation and decision-making, such as avoiding undesirable regions. We\nfurther showcase the ease of incorporating thousands of environments from\niPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs\nfrom generative video models like Veo, enabling rapid creation of realistic\ntraining worlds. This work bridges high-throughput simulation and high-fidelity\nperception, advancing scalable and generalizable robot learning. All code and\ndata will be open-sourced for the community to build upon. Videos, code, and\ndata available at https://escontrela.me/gauss_gym/."}
{"id": "2510.15759", "pdf": "https://arxiv.org/pdf/2510.15759", "abs": "https://arxiv.org/abs/2510.15759", "authors": ["Ishan Rangajith Koralege", "Nurul Huda Mahmood", "Arthur Sousa de Sena", "Italo Atzeni"], "title": "On the Impact of Electromagnetic Interference and Inter-RIS Reflections in Indoor Factory Local 6G Networks", "categories": ["eess.SP"], "comment": null, "summary": "The Sixth Generation (6G) radio technology is expected to include local 6G\nnetworks as a special use case, extending the capabilities of `generic' 6G\nnetworks towards more demanding performance requirements. Reconfigurable\nintelligent surfaces (RISs) offer a novel paradigm for next-generation wireless\ncommunications, especially in the context of local 6G networks, enabling\nadvanced signal propagation control through intelligent phase-shift\nconfigurations. However, in practical deployments, their performance can be\nadversely affected by electromagnetic interference (EMI) from external sources\nand inter-RIS reflections (IRR) caused by signal reflections between multiple\ncolocated RIS units. This paper presents a comprehensive analysis of the joint\nimpact of EMI and IRR in a multi-RIS multi-cell system deployed within an\nindoor factory environment. A detailed evaluation study is first carried out to\ninvestigate their impact on system performance. System-level simulations\ndemonstrate that the joint impact of EMI and IRR degrades system performance\nmore significantly than their individual effects, particularly as RIS\ndimensions and transmit power increase. To address these adverse effects, an\nalternate optimization algorithm using the Riemannian conjugate gradient method\nis then proposed. The novel algorithm optimizes the phase shifts of the RIS\nelements considering the spatial correlation among their associated channels,\nand is found to provide up to several orders of magnitude gains in terms of the\nsystem sum rate and the outage probability."}
{"id": "2510.15376", "pdf": "https://arxiv.org/pdf/2510.15376", "abs": "https://arxiv.org/abs/2510.15376", "authors": ["Zhaodong Yang", "Ai-Ping Hu", "Harish Ravichandar"], "title": "Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting", "categories": ["cs.RO"], "comment": "8 Pages, 8 figures", "summary": "Automating chicken shoulder deboning requires precise 6-DoF cutting through a\npartially occluded, deformable, multi-material joint, since contact with the\nbones presents serious health and safety risks. Our work makes both\nsystems-level and algorithmic contributions to train and deploy a reactive\nforce-feedback cutting policy that dynamically adapts a nominal trajectory and\nenables full 6-DoF knife control to traverse the narrow joint gap while\navoiding contact with the bones. First, we introduce an open-source\ncustom-built simulator for multi-material cutting that models coupling,\nfracture, and cutting forces, and supports reinforcement learning, enabling\nefficient training and rapid prototyping. Second, we design a reusable physical\ntestbed to emulate the chicken shoulder: two rigid \"bone\" spheres with\ncontrollable pose embedded in a softer block, enabling rigorous and repeatable\nevaluation while preserving essential multi-material characteristics of the\ntarget problem. Third, we train and deploy a residual RL policy, with\ndiscretized force observations and domain randomization, enabling robust\nzero-shot sim-to-real transfer and the first demonstration of a learned policy\nthat debones a real chicken shoulder. Our experiments in our simulator, on our\nphysical testbed, and on real chicken shoulders show that our learned policy\nreliably navigates the joint gap and reduces undesired bone/cartilage contact,\nresulting in up to a 4x improvement over existing open-loop cutting baselines\nin terms of success rate and bone avoidance. Our results also illustrate the\nnecessity of force feedback for safe and effective multi-material cutting. The\nproject website is at https://sites.google.com/view/chickendeboning-2026."}
{"id": "2510.15763", "pdf": "https://arxiv.org/pdf/2510.15763", "abs": "https://arxiv.org/abs/2510.15763", "authors": ["Qihao Peng", "Jiuyu Liu", "Qu Luo", "Yi Ma", "Pei Xiao", "Maged Elkashlan", "George K. Karagiannidis"], "title": "RIS-assisted Atomic MIMO Receiver", "categories": ["eess.SP"], "comment": "Submitted to IEEE journals", "summary": "In this paper, we propose a novel and low-complexity atomic multiple-input\nmultiple-output (MIMO) receiver architecture assisted by a reconfigurable\nintelligent surface (RIS). By introducing RIS and utilizing pulse amplitude\nmodulation (PAM), the phase of the transmitted signal is effectively aligned\nwith that of the local oscillator (LO), thereby mitigating phase ambiguity and\nsubstantially reducing both signal detection complexity and overall receiver\ncomplexity.To tackle the resulting non-convex optimization problem, we\nreformulate it into a tractable form by minimizing the Frobenius norm of an\nequivalent matrix, which is efficiently solved using an Adam-based gradient\ndescent algorithm."}
{"id": "2510.15446", "pdf": "https://arxiv.org/pdf/2510.15446", "abs": "https://arxiv.org/abs/2510.15446", "authors": ["Ziang Guo", "Zufeng Zhang"], "title": "VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving", "categories": ["cs.RO"], "comment": "1st version", "summary": "In autonomous driving, dynamic environment and corner cases pose significant\nchallenges to the robustness of ego vehicle's state understanding and decision\nmaking. We introduce VDRive, a novel pipeline for end-to-end autonomous driving\nthat explicitly models state-action mapping to address these challenges,\nenabling interpretable and robust decision making. By leveraging the\nadvancement of the state understanding of the Vision Language Action Model\n(VLA) with generative diffusion policy-based action head, our VDRive guides the\ndriving contextually and geometrically. Contextually, VLA predicts future\nobservations through token generation pre-training, where the observations are\nrepresented as discrete codes by a Conditional Vector Quantized Variational\nAutoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning\nfine-tuning of the VLA to predict future trajectories and actions based on\ncurrent driving conditions. VLA supplies the current state tokens and predicted\nstate tokens for the action policy head to generate hierarchical actions and\ntrajectories. During policy training, a learned critic evaluates the actions\ngenerated by the policy and provides gradient-based feedback, forming an\nactor-critic framework that enables a reinforcement-based policy learning\npipeline. Experiments show that our VDRive achieves state-of-the-art\nperformance in the Bench2Drive closed-loop benchmark and nuScenes open-loop\nplanning."}
{"id": "2510.15773", "pdf": "https://arxiv.org/pdf/2510.15773", "abs": "https://arxiv.org/abs/2510.15773", "authors": ["Qihao Peng Tierui Gong", "Zihang Song", "Qu Luo", "Cunhua Pan", "Pei Xiao", "Chau Yuen"], "title": "Rydberg Atomic Quantum Satellites for Enhanced Ground-to-Space Direct Uplink Access", "categories": ["eess.SP"], "comment": "Submitted to IEEE journals", "summary": "This paper investigates the performance advantages of Rydberg atomic quantum\n(RAQ)-based multiple-input multiple-output (MIMO) satellites for enhancing\ndirect ground-to-space uplink access.We analytically evaluate the impact of\nRydberg atoms on channel estimation by deriving closed-form expressions for the\nmean-square error (MSE) and normalized mean-square error (NMSE). Based on the\nestimated channels, we further derive lower bounds on the achievable data rates\nfor maximum ratio combining (MRC) and zero-forcing (ZF) detection schemes.\nRigorous analysis demonstrates that RAQ-MIMO outperforms conventional\nradio-frequency (RF) MIMO under both Rayleigh and satellite channel conditions.\nSpecifically, compared with conventional MIMO, RAQR achieves a ``squaring\" gain\nunder Rayleigh fading, especially in long-distance transmission scenarios with\nstringent power constraints. In contrast, under line-of-sight (LoS)-dominated\nsatellite channels, this gain saturates as channel-estimation benefits\ndiminish, with the remaining improvement primarily arising from the normalized\nnoise background. Monte Carlo simulations validate the analytical results and\nshow that the performance gains of RAQ-MIMO satellites translate into smaller\nantenna apertures, lower transmit power, and longer communication ranges,\nthereby paving the way for next-generation satellite networks."}
{"id": "2510.15505", "pdf": "https://arxiv.org/pdf/2510.15505", "abs": "https://arxiv.org/abs/2510.15505", "authors": ["Aron Distelzweig", "Faris Janjoš", "Oliver Scheel", "Sirish Reddy Varra", "Raghu Rajan", "Joschka Boedecker"], "title": "Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving", "categories": ["cs.RO"], "comment": "8 pages, 5 figures", "summary": "Traditionally, prediction and planning in autonomous driving (AD) have been\ntreated as separate, sequential modules. Recently, there has been a growing\nshift towards tighter integration of these components, known as Integrated\nPrediction and Planning (IPP), with the aim of enabling more informed and\nadaptive decision-making. However, it remains unclear to what extent this\nintegration actually improves planning performance. In this work, we\ninvestigate the role of prediction in IPP approaches, drawing on the widely\nadopted Val14 benchmark, which encompasses more common driving scenarios with\nrelatively low interaction complexity, and the interPlan benchmark, which\nincludes highly interactive and out-of-distribution driving situations. Our\nanalysis reveals that even access to perfect future predictions does not lead\nto better planning outcomes, indicating that current IPP methods often fail to\nfully exploit future behavior information. Instead, we focus on high-quality\nproposal generation, while using predictions primarily for collision checks. We\nfind that many imitation learning-based planners struggle to generate realistic\nand plausible proposals, performing worse than PDM - a simple lane-following\napproach. Motivated by this observation, we build on PDM with an enhanced\nproposal generation method, shifting the emphasis towards producing diverse but\nrealistic and high-quality proposals. This proposal-centric approach\nsignificantly outperforms existing methods, especially in out-of-distribution\nand highly interactive settings, where it sets new state-of-the-art results."}
{"id": "2510.15784", "pdf": "https://arxiv.org/pdf/2510.15784", "abs": "https://arxiv.org/abs/2510.15784", "authors": ["Qihao Peng", "Qu Luo", "Zheng Chu", "Neng Ye", "Hong Ren", "Cunhua Pan", "Lixia Xiao", "Pei Xiao"], "title": "From Active to Battery-Free: Rydberg Atomic Quantum Receivers for Self-Sustained SWIPT-MIMO Networks", "categories": ["eess.SP"], "comment": "Submitted to IEEE journals", "summary": "In this paper, we proposed a hybrid simultaneous wireless information and\npower transfer (SWIPT)-enabled multiple-input multiple-output (MIMO)\narchitecture, where the base station (BS) uses a conventional RF transmitter\nfor downlink transmission and a Rydberg atomic quantum receiver (RAQR) for\nreceiving uplink signal from Internet of Things (IoT) devices. To fully exploit\nthis integration, we jointly design the transmission scheme and the\npower-splitting strategy to maximize the sum rate, which leads to a non-convex\nproblem. To address this challenge, we first derive closed-form lower bounds on\nthe uplink achievable rates for maximum ratio combining (MRC) and zero-forcing\n(ZF), as well as on the downlink rate and harvested energy for maximum ratio\ntransmission (MRT) and ZF precoding. Building upon these bounds, we propose an\niterative algorithm relying on the best monomial approximation and geometric\nprogramming (GP) to solve the non-convex problem. Finally, simulations validate\nthe tightness of our derived lower bounds and demonstrate the superiority of\nthe proposed algorithm over benchmark schemes. Importantly, by integrating RAQR\nwith SWIPT-enabled MIMO, the BS can reliably detect weak uplink signals from\nIoT devices powered only by harvested energy, enabling battery-free\ncommunication."}
{"id": "2510.15530", "pdf": "https://arxiv.org/pdf/2510.15530", "abs": "https://arxiv.org/abs/2510.15530", "authors": ["Zehao Ni", "Yonghao He", "Lingfeng Qian", "Jilei Mao", "Fa Fu", "Wei Sui", "Hu Su", "Junran Peng", "Zhipeng Wang", "Bin He"], "title": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": null, "summary": "In the context of imitation learning, visuomotor-based diffusion policy\nlearning is one of the main directions in robotic manipulation. Most of these\napproaches rely on point clouds as observation inputs and construct scene\nrepresentations through point clouds feature learning, which enables them to\nachieve remarkable accuracy. However, the existing literature lacks an in-depth\nexploration of vision-only solutions that have significant potential. In this\npaper, we propose a Vision-Only and single-view Diffusion Policy learning\nmethod (VO-DP) that leverages pretrained visual foundation models to achieve\neffective fusion of semantic and geometric features. We utilize intermediate\nfeatures from VGGT incorporating semantic features from DINOv2 and geometric\nfeatures from Alternating Attention blocks. Features are fused via\ncross-attention and spatially compressed with a CNN to form the input to the\npolicy head. Extensive experiments demonstrate that VO-DP not only outperforms\nthe vision-only baseline DP significantly but also exhibits distinct\nperformance trends against the point cloud-based method DP3: in simulation\ntasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%\nand far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,\noutperforming both DP3 67.5% and DP 11.2% by a notable margin. Further\nrobustness evaluations confirm that VO-DP remains highly stable under varying\nconditions including color, size, background, and lighting. Lastly, we\nopen-source a training library for robotic manipulation. Built on Accelerate,\nthis library supports multi-machine and multi-GPU parallel training, as well as\nmixed precision training. It is compatible with visuomotor policies such as DP,\nDP3 and VO-DP, and also supports the RoboTwin simulator."}
{"id": "2510.15810", "pdf": "https://arxiv.org/pdf/2510.15810", "abs": "https://arxiv.org/abs/2510.15810", "authors": ["Luis F. Abanto-Leon", "Setareh Maghsudi"], "title": "Resilient Full-Duplex ISAC in the Face of Imperfect SI Cancellation: Globally Optimal Timeslot Allocation and Beam Selection", "categories": ["eess.SP", "cs.IT", "math.IT"], "comment": null, "summary": "This work addresses the radio resource management (RRM) design in downlink\nfull-duplex integrated sensing and communications (ISAC) systems, jointly\noptimizing timeslot allocation and beam selection under imperfect\nself-interference cancellation. Timeslot allocation governs the distribution of\ndiscrete channel uses between sensing and communication tasks, while beam\nselection determines transmit and receive directions along with adaptive\nbeamwidths. The joint design leads to a semi-infinite, nonconvex mixed-integer\nnonlinear program (MINLP), which is difficult to solve. To overcome this, we\ndevelop a tailored reformulation strategy that transforms the problem into a\ntractable mixed-integer linear program (MILP), enabling globally optimal\nsolutions. Our approach provides insights into the coordinated optimization of\ntimeslot allocation and beam selection, enhancing the efficiency of full-duplex\nISAC systems while ensuring resilience against residual self-interference."}
{"id": "2510.15533", "pdf": "https://arxiv.org/pdf/2510.15533", "abs": "https://arxiv.org/abs/2510.15533", "authors": ["Shilei Li", "Dawei Shi", "Makoto Iwasaki", "Yan Ning", "Hongpeng Zhou", "Ling Shi"], "title": "Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons", "categories": ["cs.RO"], "comment": null, "summary": "The nominal performance of mechanical systems is often degraded by unknown\ndisturbances. A two-degree-of-freedom control structure can decouple nominal\nperformance from disturbance rejection. However, perfect disturbance rejection\nis unattainable when the disturbance dynamic is unknown. In this work, we\nreveal an inherent trade-off in disturbance estimation subject to tracking\nspeed and tracking uncertainty. Then, we propose two novel methods to enhance\ndisturbance estimation: an interacting multiple model extended Kalman\nfilter-based disturbance observer and a multi-kernel correntropy extended\nKalman filter-based disturbance observer. Experiments on an exoskeleton verify\nthat the proposed two methods improve the tracking accuracy $36.3\\%$ and\n$16.2\\%$ in hip joint error, and $46.3\\%$ and $24.4\\%$ in knee joint error,\nrespectively, compared to the extended Kalman filter-based disturbance\nobserver, in a time-varying interaction force scenario, demonstrating the\nsuperiority of the proposed method."}
{"id": "2510.15109", "pdf": "https://arxiv.org/pdf/2510.15109", "abs": "https://arxiv.org/abs/2510.15109", "authors": ["Utku Demir", "Tugba Erpek", "Yalin E. Sagduyu", "Sastry Kompella", "Mengran Xue"], "title": "Targeted Attacks and Defenses for Distributed Federated Learning in Vehicular Networks", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG", "eess.SP"], "comment": null, "summary": "In emerging networked systems, mobile edge devices such as ground vehicles\nand unmanned aerial system (UAS) swarms collectively aggregate vast amounts of\ndata to make machine learning decisions such as threat detection in remote,\ndynamic, and infrastructure-constrained environments where power and bandwidth\nare scarce. Federated learning (FL) addresses these constraints and privacy\nconcerns by enabling nodes to share local model weights for deep neural\nnetworks instead of raw data, facilitating more reliable decision-making than\nindividual learning. However, conventional FL relies on a central server to\ncoordinate model updates in each learning round, which imposes significant\ncomputational burdens on the central node and may not be feasible due to the\nconnectivity constraints. By eliminating dependence on a central server,\ndistributed federated learning (DFL) offers scalability, resilience to node\nfailures, learning robustness, and more effective defense strategies. Despite\nthese advantages, DFL remains vulnerable to increasingly advanced and stealthy\ncyberattacks. In this paper, we design sophisticated targeted training data\npoisoning and backdoor (Trojan) attacks, and characterize the emerging\nvulnerabilities in a vehicular network. We analyze how DFL provides resilience\nagainst such attacks compared to individual learning and present effective\ndefense mechanisms to further strengthen DFL against the emerging cyber\nthreats."}
{"id": "2510.15626", "pdf": "https://arxiv.org/pdf/2510.15626", "abs": "https://arxiv.org/abs/2510.15626", "authors": ["Hongyu Zhou", "Xiaoyu Zhang", "Vasileios Tzoumas"], "title": "Adaptive Legged Locomotion via Online Learning for Model Predictive Control", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "9 pages", "summary": "We provide an algorithm for adaptive legged locomotion via online learning\nand model predictive control. The algorithm is composed of two interacting\nmodules: model predictive control (MPC) and online learning of residual\ndynamics. The residual dynamics can represent modeling errors and external\ndisturbances. We are motivated by the future of autonomy where quadrupeds will\nautonomously perform complex tasks despite real-world unknown uncertainty, such\nas unknown payload and uneven terrains. The algorithm uses random Fourier\nfeatures to approximate the residual dynamics in reproducing kernel Hilbert\nspaces. Then, it employs MPC based on the current learned model of the residual\ndynamics. The model is updated online in a self-supervised manner using least\nsquares based on the data collected while controlling the quadruped. The\nalgorithm enjoys sublinear \\textit{dynamic regret}, defined as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nresidual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,\nwhere the quadruped aims to track reference trajectories. The Gazebo\nsimulations include constant unknown external forces up to $12\\boldsymbol{g}$,\nwhere $\\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain\nwith $20\\degree$ inclination, and rough terrain with $0.25m$ height variation.\nThe MuJoCo simulations include time-varying unknown disturbances with payload\nup to $8~kg$ and time-varying ground friction coefficients in flat terrain."}
{"id": "2510.15150", "pdf": "https://arxiv.org/pdf/2510.15150", "abs": "https://arxiv.org/abs/2510.15150", "authors": ["Tina Gao", "Shimiao Li", "Lawrence Pileggi"], "title": "Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": "This manuscript has been submitted to PESGM2026", "summary": "Advances in leveraging Gaussian processes (GP) have enabled learning and\ninferring dynamic grid behavior from scarce PMU measurements. However, real\nmeasurements can be corrupted by various random and targeted threats, leading\nto inaccurate and meaningless results. This paper develops robust transient\nlearning to overcome this challenge by exploiting the sparse corruption\npatterns in the data flow. Specifically, we integrate sparse optimization with\nmethod of moments (MoM) to make learning robust to a sparse distribution of\ndata corruptions; then, we optimize sparse weights to identify corrupted meter\nlocations. To improve inference speed on large-scale systems, we further adopt\nK-medoid clustering of locations to develop dimension reduction (DR) and\naggregate representation (AR) heuristics. Experimental results demonstrate\nrobustness against random large errors, targeted false data injections, and\nlocal PMU clock drifts. On a 1354-bus system, inference turns out to be 18x\nfaster using DR and 400x faster when further combined with AR heuristics."}
{"id": "2510.15638", "pdf": "https://arxiv.org/pdf/2510.15638", "abs": "https://arxiv.org/abs/2510.15638", "authors": ["Jared K. Lepora", "Haoran Li", "Efi Psomopoulou", "Nathan F. Lepora"], "title": "Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS", "categories": ["cs.RO"], "comment": "6 pages. Accepted at IROS 2025", "summary": "This paper introduces an anthropomorphic robot hand built entirely using LEGO\nMINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated\nrobot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for\nan educational context, the design is constrained to use only standard LEGO\npieces with tests using common equipment available at home. The hand features\ndual motors driving an agonist/antagonist opposing pair of tendons on each\nfinger, which are shown to result in reactive fine control. The finger motions\nare synchonized through soft synergies, implemented with a differential\nmechanism using clutch gears. Altogether, this design results in an\nanthropomorphic hand that can adaptively grasp a broad range of objects using a\nsimple actuation and control mechanism. Since the hand can be constructed from\nLEGO pieces and uses state-of-the-art design concepts for robotic hands, it has\nthe potential to educate and inspire children to learn about the frontiers of\nmodern robotics."}
{"id": "2510.15380", "pdf": "https://arxiv.org/pdf/2510.15380", "abs": "https://arxiv.org/abs/2510.15380", "authors": ["Axel Flinth", "Hubert Orlicki", "Semira Einsele", "Gerhard Wunder"], "title": "Bilinear Compressive Security", "categories": ["cs.CR", "cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "Beyond its widespread application in signal and image processing,\n\\emph{compressed sensing} principles have been greatly applied to secure\ninformation transmission (often termed 'compressive security'). In this\nscenario, the measurement matrix $Q$ acts as a one time pad encryption key (in\ncomplex number domain) which can achieve perfect information-theoretic security\ntogether with other benefits such as reduced complexity and energy efficiency\nparticularly useful in IoT. However, unless the matrix is changed for every\nmessage it is vulnerable towards known plain text attacks: only $n$\nobservations suffices to recover a key $Q$ with $n$ columns. In this paper, we\ninvent and analyze a new method (termed 'Bilinear Compressive Security (BCS)')\naddressing these shortcomings: In addition to the linear encoding of the\nmessage $x$ with a matrix $Q$, the sender convolves the resulting vector with a\nrandomly generated filter $h$. Assuming that $h$ and $x$ are sparse, the\nreceiver can then recover $x$ without knowledge of $h$ from $y=h*Qx$ through\nblind deconvolution. We study a rather idealized known plaintext attack for\nrecovering $Q$ from repeated observations of $y$'s for different, known $x_k$,\nwith varying and unknown $h$ ,giving Eve a number of advantages not present in\npractice. Our main result for BCS states that under a weak symmetry condition\non the filter $h$, recovering $Q$ will require extensive sampling from\ntransmissions of $\\Omega\\left(\\max\\left(n,(n/s)^2\\right)\\right)$ messages $x_k$\nif they are $s$-sparse. Remarkably, with $s=1$ it is impossible to recover the\nkey. In this way, the scheme is much safer than standard compressed sensing\neven though our assumptions are much in favor towards a potential attacker."}
{"id": "2510.15639", "pdf": "https://arxiv.org/pdf/2510.15639", "abs": "https://arxiv.org/abs/2510.15639", "authors": ["Manuel J. Fernandez", "Alejandro Suarez", "Anibal Ollero", "Matteo Fumagalli"], "title": "Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents the integration of a Variable Stiffness Link (VSL) for\nlong-reach aerial manipulation, enabling adaptable mechanical coupling between\nan aerial multirotor platform and a dual-arm manipulator. Conventional\nlong-reach manipulation systems rely on rigid or cable connections, which limit\nprecision or transmit disturbances to the aerial vehicle. The proposed VSL\nintroduces an adjustable stiffness mechanism that allows the link to behave\neither as a flexible rope or as a rigid rod, depending on task requirements.\n  The system is mounted on a quadrotor equipped with the LiCAS dual-arm\nmanipulator and evaluated through teleoperated experiments, involving external\ndisturbances and parcel transportation tasks. Results demonstrate that varying\nthe link stiffness significantly modifies the dynamic interaction between the\nUAV and the payload. The flexible configuration attenuates external impacts and\naerodynamic perturbations, while the rigid configuration improves positional\naccuracy during manipulation phases.\n  These results confirm that VSL enhances versatility and safety, providing a\ncontrollable trade-off between compliance and precision. Future work will focus\non autonomous stiffness regulation, multi-rope configurations, cooperative\naerial manipulation and user studies to further assess its impact on\nteleoperated and semi-autonomous aerial tasks."}
{"id": "2510.15547", "pdf": "https://arxiv.org/pdf/2510.15547", "abs": "https://arxiv.org/abs/2510.15547", "authors": ["Usman Ali", "Ali Zia", "Waqas Ali", "Umer Ramzan", "Abdul Rehman", "Muhammad Tayyab Chaudhry", "Wei Xiang"], "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": "Submitted to IEEE Sensors Journal", "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety\nand operational continuity, mitigating costly unplanned downtime. Conventional\napproaches often struggle to capture complex multimodal signal relationships,\nare constrained to unimodal data or single fault types, and exhibit performance\ndegradation under noisy or cross-domain conditions. This paper proposes the\nMultimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified\nframework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is\nthe first to integrate contrastive learning within a hypergraph topology\nspecifically designed for multimodal sensor fusion, enabling the joint\nmodelling of intra- and inter-modal dependencies and enhancing generalisation\nbeyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis\nof bearing, stator, and rotor faults, addressing the engineering need for\nconsolidated di- agnostic capabilities. Evaluated on three real-world\nbenchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain\ngeneralisation and resilience to noise, demonstrating its suitability for\nreal-world deployment. An ablation study validates the contribution of each\ncomponent. MM-HCAN provides a scalable and robust solution for comprehensive\nmulti-fault diagnosis, supporting predictive maintenance and extended asset\nlongevity in industrial environments."}
{"id": "2510.15668", "pdf": "https://arxiv.org/pdf/2510.15668", "abs": "https://arxiv.org/abs/2510.15668", "authors": ["Yameng Zhang", "Dianye Huang", "Max Q. -H. Meng", "Nassir Navab", "Zhongliang Jiang"], "title": "Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Freehand 3D ultrasound (US) imaging using conventional 2D probes offers\nflexibility and accessibility for diverse clinical applications but faces\nchallenges in accurate probe pose estimation. Traditional methods depend on\ncostly tracking systems, while neural network-based methods struggle with image\nnoise and error accumulation, compromising reconstruction precision. We propose\na cost-effective and versatile solution that leverages lightweight cameras and\nvisual servoing in simulated environments for precise 3D US imaging. These\ncameras capture visual feedback from a textured planar workspace. To counter\nocclusions and lighting issues, we introduce an image restoration method that\nreconstructs occluded regions by matching surrounding texture patterns. For\npose estimation, we develop a simulation-in-the-loop approach, which replicates\nthe system setup in simulation and iteratively minimizes pose errors between\nsimulated and real-world observations. A visual servoing controller refines the\nalignment of camera views, improving translational estimation by optimizing\nimage alignment. Validations on a soft vascular phantom, a 3D-printed conical\nmodel, and a human arm demonstrate the robustness and accuracy of our approach,\nwith Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171\nmm, and 0.858 mm, respectively. These results confirm the method's potential\nfor reliable freehand 3D US reconstruction."}
{"id": "2510.15644", "pdf": "https://arxiv.org/pdf/2510.15644", "abs": "https://arxiv.org/abs/2510.15644", "authors": ["Tomas Ortega", "Hamid Jafarkhani"], "title": "Decentralized Parameter-Free Online Learning", "categories": ["cs.LG", "eess.SP", "math.OC", "68W10, 68W15, 68W40, 90C06, 90C35, 90C26", "G.1.6; F.2.1; E.4"], "comment": null, "summary": "We propose the first parameter-free decentralized online learning algorithms\nwith network regret guarantees, which achieve sublinear regret without\nrequiring hyperparameter tuning. This family of algorithms connects multi-agent\ncoin-betting and decentralized online learning via gossip steps. To enable our\ndecentralized analysis, we introduce a novel \"betting function\" formulation for\ncoin-betting that simplifies the multi-agent regret analysis. Our analysis\nshows sublinear network regret bounds and is validated through experiments on\nsynthetic and real datasets. This family of algorithms is applicable to\ndistributed sensing, decentralized optimization, and collaborative ML\napplications."}
{"id": "2510.15679", "pdf": "https://arxiv.org/pdf/2510.15679", "abs": "https://arxiv.org/abs/2510.15679", "authors": ["Yuhong Cao", "Yizhuo Wang", "Jingsong Liang", "Shuhao Liao", "Yifeng Zhang", "Peizhuo Li", "Guillaume Sartoretti"], "title": "HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward", "categories": ["cs.RO"], "comment": null, "summary": "This work pushes the boundaries of learning-based methods in autonomous robot\nexploration in terms of environmental scale and exploration efficiency. We\npresent HEADER, an attention-based reinforcement learning approach with\nhierarchical graphs for efficient exploration in large-scale environments.\nHEADER follows existing conventional methods to construct hierarchical\nrepresentations for the robot belief/map, but further designs a novel\ncommunity-based algorithm to construct and update a global graph, which remains\nfully incremental, shape-adaptive, and operates with linear complexity.\nBuilding upon attention-based networks, our planner finely reasons about the\nnearby belief within the local range while coarsely leveraging distant\ninformation at the global scale, enabling next-best-viewpoint decisions that\nconsider multi-scale spatial dependencies. Beyond novel map representation, we\nintroduce a parameter-free privileged reward that significantly improves model\nperformance and produces near-optimal exploration behaviors, by avoiding\ntraining objective bias caused by handcrafted reward shaping. In simulated\nchallenging, large-scale exploration scenarios, HEADER demonstrates better\nscalability than most existing learning and non-learning methods, while\nachieving a significant improvement in exploration efficiency (up to 20%) over\nstate-of-the-art baselines. We also deploy HEADER on hardware and validate it\nin complex, large-scale real-life scenarios, including a 300m*230m campus\nenvironment."}
{"id": "2510.15701", "pdf": "https://arxiv.org/pdf/2510.15701", "abs": "https://arxiv.org/abs/2510.15701", "authors": ["Binggui Zhou", "Bruno Clerckx"], "title": "Beyond-Diagonal RIS Under Non-Idealities: Learning-Based Architecture Discovery and Optimization", "categories": ["cs.IT", "cs.AI", "eess.SP", "math.IT"], "comment": "13 pages, 13 figures, 1 table. This paper has been submitted to IEEE\n  journal for possible publication", "summary": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has recently been\nintroduced to enable advanced control over electromagnetic waves to further\nincrease the benefits of traditional RIS in enhancing signal quality and\nimproving spectral and energy efficiency for next-generation wireless networks.\nA significant issue in designing and deploying BD-RIS is the tradeoff between\nits performance and circuit complexity. Despite some efforts in exploring\noptimal architectures with the lowest circuit complexities for ideal BD-RIS,\narchitecture discovery for non-ideal BD-RIS remains uninvestigated. Therefore,\nhow non-idealities and circuit complexity jointly affect the performance of\nBD-RIS remains unclear, making it difficult to achieve the performance -\ncircuit complexity tradeoff in the presence of non-idealities. Essentially,\narchitecture discovery for non-ideal BD-RIS faces challenges from both the\ncomputational complexity of global architecture search and the difficulty in\nachieving global optima. To tackle these challenges, we propose a\nlearning-based two-tier architecture discovery framework (LTTADF) consisting of\nan architecture generator and a performance optimizer to jointly discover\noptimal architectures of non-ideal BD-RIS given specific circuit complexities,\nwhich can effectively explore over a large architecture space while avoiding\ngetting trapped in poor local optima and thus achieving near-optimal solutions\nfor the performance optimization. Numerical results provide valuable insights\nfor deploying non-ideal BD-RIS considering the performance - circuit complexity\ntradeoff."}
{"id": "2510.15686", "pdf": "https://arxiv.org/pdf/2510.15686", "abs": "https://arxiv.org/abs/2510.15686", "authors": ["Taehyeon Kim", "Vishnunandan L. N. Venkatesh", "Byung-Cheol Min"], "title": "Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems", "categories": ["cs.RO"], "comment": null, "summary": "In this paper, we propose a novel few-shot learning framework for multi-robot\nsystems that integrate both spatial and temporal elements: Few-Shot\nDemonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our\napproach leverages temporal graph networks for learning task-agnostic temporal\nsequencing and Gaussian Processes for spatial trajectory modeling, ensuring\nmodularity and generalization across various tasks. By decoupling temporal and\nspatial aspects, DDACE requires only a small number of demonstrations,\nsignificantly reducing data requirements compared to traditional learning from\ndemonstration approaches. To validate our proposed framework, we conducted\nextensive experiments in task environments designed to assess various aspects\nof multi-robot coordination-such as multi-sequence execution, multi-action\ndynamics, complex trajectory generation, and heterogeneous configurations. The\nexperimental results demonstrate that our approach successfully achieves task\nexecution under few-shot learning conditions and generalizes effectively across\ndynamic and diverse settings. This work underscores the potential of modular\narchitectures in enhancing the practicality and scalability of multi-robot\nsystems in real-world applications. Additional materials are available at\nhttps://sites.google.com/view/ddace."}
{"id": "2510.15786", "pdf": "https://arxiv.org/pdf/2510.15786", "abs": "https://arxiv.org/abs/2510.15786", "authors": ["Xinyue Xu", "Jieqiang Sun", "Jing", "Dai", "Siyuan Chen", "Lanjie Ma", "Ke Sun", "Bin Zhao", "Jianbo Yuan", "Yiwen Lu"], "title": "DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present DexCanvas, a large-scale hybrid real-synthetic human manipulation\ndataset containing 7,000 hours of dexterous hand-object interactions seeded\nfrom 70 hours of real human demonstrations, organized across 21 fundamental\nmanipulation types based on the Cutkosky taxonomy. Each entry combines\nsynchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,\nand per-frame contact points with physically consistent force profiles. Our\nreal-to-sim pipeline uses reinforcement learning to train policies that control\nan actuated MANO hand in physics simulation, reproducing human demonstrations\nwhile discovering the underlying contact forces that generate the observed\nobject motion. DexCanvas is the first manipulation dataset to combine\nlarge-scale real demonstrations, systematic skill coverage based on established\ntaxonomies, and physics-validated contact annotations. The dataset can\nfacilitate research in robotic manipulation learning, contact-rich control, and\nskill transfer across different hand morphologies."}
{"id": "2510.15803", "pdf": "https://arxiv.org/pdf/2510.15803", "abs": "https://arxiv.org/abs/2510.15803", "authors": ["Zahra Arjmandi", "Gunho Sohn"], "title": "Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion", "categories": ["cs.RO"], "comment": "9 pages, 9 figures", "summary": "This paper presents a novel fusion technique for LiDAR Simultaneous\nLocalization and Mapping (SLAM), aimed at improving localization and 3D mapping\nusing LiDAR sensor. Our approach centers on the Inferred Attention Fusion\n(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI\ndataset's LiDAR data, INAF dynamically adjusts attention weights based on\nenvironmental feedback, enhancing the system's adaptability and measurement\naccuracy. This method advances the precision of both localization and 3D\nmapping, demonstrating the potential of our fusion technique to enhance\nautonomous navigation systems in complex scenarios."}
{"id": "2510.15018", "pdf": "https://arxiv.org/pdf/2510.15018", "abs": "https://arxiv.org/abs/2510.15018", "authors": ["Mingxuan Liu", "Honglin He", "Elisa Ricci", "Wayne Wu", "Bolei Zhou"], "title": "UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Technical report. Project page: https://urbanverseproject.github.io/", "summary": "Urban embodied AI agents, ranging from delivery robots to quadrupeds, are\nincreasingly populating our cities, navigating chaotic streets to provide\nlast-mile connectivity. Training such agents requires diverse, high-fidelity\nurban environments to scale, yet existing human-crafted or procedurally\ngenerated simulation scenes either lack scalability or fail to capture\nreal-world complexity. We introduce UrbanVerse, a data-driven real-to-sim\nsystem that converts crowd-sourced city-tour videos into physics-aware,\ninteractive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a\nrepository of 100k+ annotated urban 3D assets with semantic and physical\nattributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene\nlayouts from video and instantiates metric-scale 3D simulations using retrieved\nassets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed\nscenes from 24 countries, along with a curated benchmark of 10 artist-designed\ntest scenes. Experiments show that UrbanVerse scenes preserve real-world\nsemantics and layouts, achieving human-evaluated realism comparable to manually\ncrafted scenes. In urban navigation, policies trained in UrbanVerse exhibit\nscaling power laws and strong generalization, improving success by +6.3% in\nsimulation and +30.1% in zero-shot sim-to-real transfer comparing to prior\nmethods, accomplishing a 300 m real-world mission with only two interventions."}
{"id": "2510.15271", "pdf": "https://arxiv.org/pdf/2510.15271", "abs": "https://arxiv.org/abs/2510.15271", "authors": ["Jingrui Yu", "Jun Liu", "Kefei Ren", "Joydeep Biswas", "Rurui Ye", "Keqiang Wu", "Chirag Majithia", "Di Zeng"], "title": "CuSfM: CUDA-Accelerated Structure-from-Motion", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Efficient and accurate camera pose estimation forms the foundational\nrequirement for dense reconstruction in autonomous navigation, robotic\nperception, and virtual simulation systems. This paper addresses the challenge\nvia cuSfM, a CUDA-accelerated offline Structure-from-Motion system that\nleverages GPU parallelization to efficiently employ computationally intensive\nyet highly accurate feature extractors, generating comprehensive and\nnon-redundant data associations for precise camera pose estimation and globally\nconsistent mapping. The system supports pose optimization, mapping, prior-map\nlocalization, and extrinsic refinement. It is designed for offline processing,\nwhere computational resources can be fully utilized to maximize accuracy.\nExperimental results demonstrate that cuSfM achieves significantly improved\naccuracy and processing speed compared to the widely used COLMAP method across\nvarious testing scenarios, while maintaining the high precision and global\nconsistency essential for offline SfM applications. The system is released as\nan open-source Python wrapper implementation, PyCuSfM, available at\nhttps://github.com/nvidia-isaac/pyCuSFM, to facilitate research and\napplications in computer vision and robotics."}
{"id": "2510.15382", "pdf": "https://arxiv.org/pdf/2510.15382", "abs": "https://arxiv.org/abs/2510.15382", "authors": ["Kexin Zheng", "Lauriane Teyssier", "Yinan Zheng", "Yu Luo", "Xiayuan Zhan"], "title": "Towards Robust Zero-Shot Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Neurips 2025, 36 pages, 18 figures", "summary": "The recent development of zero-shot reinforcement learning (RL) has opened a\nnew avenue for learning pre-trained generalist policies that can adapt to\narbitrary new tasks in a zero-shot manner. While the popular Forward-Backward\nrepresentations (FB) and related methods have shown promise in zero-shot RL, we\nempirically found that their modeling lacks expressivity and that extrapolation\nerrors caused by out-of-distribution (OOD) actions during offline learning\nsometimes lead to biased representations, ultimately resulting in suboptimal\nperformance. To address these issues, we propose Behavior-REgularizEd Zero-shot\nRL with Expressivity enhancement (BREEZE), an upgraded FB-based framework that\nsimultaneously enhances learning stability, policy extraction capability, and\nrepresentation learning quality. BREEZE introduces behavioral regularization in\nzero-shot RL policy learning, transforming policy optimization into a stable\nin-sample learning paradigm. Additionally, BREEZE extracts the policy using a\ntask-conditioned diffusion model, enabling the generation of high-quality and\nmultimodal action distributions in zero-shot RL settings. Moreover, BREEZE\nemploys expressive attention-based architectures for representation modeling to\ncapture the complex relationships between environmental dynamics. Extensive\nexperiments on ExORL and D4RL Kitchen demonstrate that BREEZE achieves the best\nor near-the-best performance while exhibiting superior robustness compared to\nprior offline zero-shot RL methods. The official implementation is available\nat: https://github.com/Whiterrrrr/BREEZE."}
{"id": "2510.15510", "pdf": "https://arxiv.org/pdf/2510.15510", "abs": "https://arxiv.org/abs/2510.15510", "authors": ["Heeseong Shin", "Byeongho Heo", "Dongyoon Han", "Seungryong Kim", "Taekyung Kim"], "title": "Exploring Conditions for Diffusion models in Robotic Control", "categories": ["cs.CV", "cs.RO"], "comment": "Project page: https://orca-rc.github.io/", "summary": "While pre-trained visual representations have significantly advanced\nimitation learning, they are often task-agnostic as they remain frozen during\npolicy learning. In this work, we explore leveraging pre-trained text-to-image\ndiffusion models to obtain task-adaptive visual representations for robotic\ncontrol, without fine-tuning the model itself. However, we find that naively\napplying textual conditions - a successful strategy in other vision domains -\nyields minimal or even negative gains in control tasks. We attribute this to\nthe domain gap between the diffusion model's training data and robotic control\nenvironments, leading us to argue for conditions that consider the specific,\ndynamic visual information required for control. To this end, we propose ORCA,\nwhich introduces learnable task prompts that adapt to the control environment\nand visual prompts that capture fine-grained, frame-specific details. Through\nfacilitating task-adaptive representations with our newly devised conditions,\nour approach achieves state-of-the-art performance on various robotic control\nbenchmarks, significantly surpassing prior methods."}
