{"id": "2512.19702", "pdf": "https://arxiv.org/pdf/2512.19702", "abs": "https://arxiv.org/abs/2512.19702", "authors": ["Yufei Zhao", "Deyu Lin", "Qian Zhang", "Haoyang Shi", "Hong Niu", "Afkar Mohamed Ismail", "Yong Liang Guan", "Chau Yuen"], "title": "Enhanced Information Security via Wave-Field Selectivity and Structured Wavefront Manipulation", "categories": ["eess.SP", "physics.app-ph"], "comment": null, "summary": "In this paper, we propose a novel secure wireless transmission architecture that enables the co-existence of spatial field modulation (SFM) and digital bandpass modulation (DBM), utilizing multi-mode vortex waves and programmable meta-surfaces (PMS). Distinct from conventional joint modulation schemes, our approach establishes two logically independent transmission channels--SFM and DBM--thereby eliminating the need for joint signal design or time synchronization. Specifically, the orthogonality of vortex wave modes is exploited to construct a high-capacity multi-mode DBM channel, in which each mode carries modulated symbols independently. As the composite waveform passes through the PMS, energy from different vortex modes is spatially focused onto distinct positions, dynamically determined by the PMS configuration. This spatial mapping forms a unique lookup table that encodes additional information in the electro-magnetic (EM) field distribution, effectively enabling a second, concurrent SFM channel. To enhance physical-layer security, the DBM channel transmits encrypted symbols transformed via dynamic symbol-domain mapping, while the corresponding mapping relations--or key information--are carried by the SFM channel. This lightweight dual-channel encryption strategy provides strong confidentiality without requiring complex joint decoding. To validate the feasibility of the proposed architecture, we design and implement a proof-of-concept prototype system, and conduct experimental demonstrations under real-world wireless communication conditions. The experimental results confirm the effectiveness of the co-existent DBM-SFM design in achieving reliable and secure transmission. The proposed architecture offers a scalable, low-complexity, and secure transmission solution for future IoT networks, especially in scenarios demanding both spectral efficiency and physical-layer confidentiality."}
{"id": "2512.19963", "pdf": "https://arxiv.org/pdf/2512.19963", "abs": "https://arxiv.org/abs/2512.19963", "authors": ["Zar Chi Phyo", "Shreya Khisa", "Chadi Assi", "Sanaa Sharafaddine"], "title": "Joint Power Control and Antenna Positioning for Uplink RSMA in Pinching Antenna Systems", "categories": ["eess.SP"], "comment": null, "summary": "This paper investigates a rate-splitting multiple access (RSMA) for uplink pinching antenna system (PASS). Our objective is to maximize the uplink sum rate by jointly optimizing a continuous antenna positioning and user's transmission power. The formulated problem is highly non-convex and difficult to solve directly; to address this challenge, we propose an alternating optimization (AO) framework which decomposes the original problem into two tractable sub-problems, namely (i) power allocation optimization sub-problem and (ii) antenna position optimization sub-problem. Both sub-problems are solved using successive convex approximation (SCA)-based algorithm and solved alternatively until convergence. The RSMA access for PASS is compared with conventional non-orthogonal multiple access (NOMA) and space-division multiple access (SDMA) techniques. The performance of discrete antenna activation with PASS strategy is also examined. Simulation results demonstrate that our proposed framework significantly enhances the achievable sum rate compared to other multiple access methods."}
{"id": "2512.19974", "pdf": "https://arxiv.org/pdf/2512.19974", "abs": "https://arxiv.org/abs/2512.19974", "authors": ["Borui Du", "Kawon Han", "Christos Masouros"], "title": "Securing the Sensing Functionality in ISAC: KLD-Based Ambiguity Function Shaping", "categories": ["eess.SP"], "comment": null, "summary": "As integrated sensing and communication (ISAC) systems are deployed in next-generation wireless networks, a new security vulnerability emerges, particularly in terms of sensing privacy. Unauthorized sensing eavesdroppers (Eve) can potentially exploit the ISAC signal for their own independent passive sensing. However, solutions for sensing-secure ISAC remain largely unexplored to date. This work addresses sensing-security for OFDM- and OTFS-based ISAC waveforms from a target-detection perspective, aiming to prevent Eves from exploiting the ISAC signal for unauthorized passive sensing. We develop ISAC system models for the base station (BS), communication user equipment, and the sensing Eve, and define a Kullback-Leibler-divergence-based detection metric that accounts for mainlobe, sidelobe, and noise components in the ambiguity function and the resulting range-Doppler maps of the legitimate BS's and Eve's sensing. Building on this analysis, we formulate a sensing-secure ISAC signaling design problem that tunes a perturbation matrix to jointly control signal amplitude and phase in the time-frequency domain and solve it via simulated annealing. Simulation results show that the proposed scheme substantially degrades Eve's detection probability -- from 79.4% to 37.4% for OTFS and from 94.3% to 33.0% for OFDM -- while incurring only a small loss in BS sensing performance. In addition, it allows controllable trade-offs across sensing-security and communication performance."}
{"id": "2512.20008", "pdf": "https://arxiv.org/pdf/2512.20008", "abs": "https://arxiv.org/abs/2512.20008", "authors": ["Tuo Wu", "Xiazhi Lai", "Shihang Lu", "Zihao Chen", "Xiaotong Zhao", "Yuanhao Cui"], "title": "From Optimization to Learning: Dual-Approach Resource Allocation for Over-the-Air Edge Computing Under Execution Uncertainty", "categories": ["eess.SP"], "comment": null, "summary": "The exponential proliferation of mobile devices and data-intensive applications in future wireless networks imposes substantial computational burdens on resource-constrained devices, thereby fostering the emergence of over-the-air computation (AirComp) as a transformative paradigm for edge intelligence.} To enhance the efficiency and scalability of AirComp systems, this paper proposes a comprehensive dual-approach framework that systematically transitions from traditional mathematical optimization to deep reinforcement learning (DRL) for resource allocation under execution uncertainty. Specifically, we establish a rigorous system model capturing execution uncertainty via Gamma-distributed computational workloads, resulting in challenging nonlinear optimization problems involving complex Gamma functions. For single-user scenarios, we design advanced block coordinate descent (BCD) and majorization-maximization (MM) algorithms, which yield semi-closed-form solutions with provable performance guarantees. However, conventional optimization approaches become computationally intractable in dynamic multi-user environments due to inter-user interference and resource contention. To this end, we introduce a Deep Q-Network (DQN)-based DRL framework capable of adaptively learning optimal policies through environment interaction. Our dual methodology effectively bridges analytical tractability with adaptive intelligence, leveraging optimization for foundational insight and learning for real-time adaptability. Extensive numerical results corroborate the performance gains achieved via increased edge server density and validate the superiority of our optimization-to-learning paradigm in next-generation AirComp systems."}
{"id": "2512.19855", "pdf": "https://arxiv.org/pdf/2512.19855", "abs": "https://arxiv.org/abs/2512.19855", "authors": ["Andrew Stirling", "Mykola Lukashchuk", "Dmitry Bagaev", "Wouter Kouw", "James R. Forbes"], "title": "Gaussian Variational Inference with Non-Gaussian Factors for State Estimation: A UWB Localization Case Study", "categories": ["cs.RO", "stat.ML"], "comment": null, "summary": "This letter extends the exactly sparse Gaussian variational inference (ESGVI) algorithm for state estimation in two complementary directions. First, ESGVI is generalized to operate on matrix Lie groups, enabling the estimation of states with orientation components while respecting the underlying group structure. Second, factors are introduced to accommodate heavy-tailed and skewed noise distributions, as commonly encountered in ultra-wideband (UWB) localization due to non-line-of-sight (NLOS) and multipath effects. Both extensions are shown to integrate naturally within the ESGVI framework while preserving its sparse and derivative-free structure. The proposed approach is validated in a UWB localization experiment with NLOS-rich measurements, demonstrating improved accuracy and comparable consistency. Finally, a Python implementation within a factor-graph-based estimation framework is made open-source (https://github.com/decargroup/gvi_ws) to support broader research use."}
{"id": "2512.20010", "pdf": "https://arxiv.org/pdf/2512.20010", "abs": "https://arxiv.org/abs/2512.20010", "authors": ["Xiaobo Zeng", "Liangcai Chen", "Pan Liu", "Ruonan Deng"], "title": "PFA-NS: Power-Fading-Aware Noise Shaping Enabled C-Band IMDD System with Low Resolution DAC", "categories": ["eess.SP"], "comment": null, "summary": "We propose and demonstrate a power-fading-aware noise-shaping technique for C-band IMDD system with low resolution DAC, which shapes and concentrates quantization noise within the fading-induced notch areas, yielding 94% improvement in data-rate over traditional counterpart."}
{"id": "2512.19914", "pdf": "https://arxiv.org/pdf/2512.19914", "abs": "https://arxiv.org/abs/2512.19914", "authors": ["Sujan Warnakulasooriya", "Andreas Willig", "Xiaobing Wu"], "title": "A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": "35 pages", "summary": "Drone applications continue to expand across various domains, with flocking offering enhanced cooperative capabilities but introducing significant challenges during initial formation. Existing flocking algorithms often struggle with efficiency and scalability, particularly when potential collisions force drones into suboptimal trajectories. This paper presents a time-efficient prioritised scheduling algorithm that improves the initial formation process of drone flocks. The method assigns each drone a priority based on its number of potential collisions and its likelihood of reaching its target position without permanently obstructing other drones. Using this hierarchy, each drone computes an appropriate delay to ensure a collision-free path. Simulation results show that the proposed algorithm successfully generates collision-free trajectories for flocks of up to 5000 drones and outperforms the coupling-degree-based heuristic prioritised planning method (CDH-PP) in both performance and computational efficiency."}
{"id": "2512.20012", "pdf": "https://arxiv.org/pdf/2512.20012", "abs": "https://arxiv.org/abs/2512.20012", "authors": ["Qiushuo Hou", "Sangwoo Park", "Matteo Zecchin", "Yunlong Cai", "Guanding Yu", "Osvaldo Simeone", "Tommaso Melodia"], "title": "Reliable LLM-Based Edge-Cloud-Expert Cascades for Telecom Knowledge Systems", "categories": ["eess.SP", "cs.LG"], "comment": "This paper has been submitted to a journal", "summary": "Large language models (LLMs) are emerging as key enablers of automation in domains such as telecommunications, assisting with tasks including troubleshooting, standards interpretation, and network optimization. However, their deployment in practice must balance inference cost, latency, and reliability. In this work, we study an edge-cloud-expert cascaded LLM-based knowledge system that supports decision-making through a question-and-answer pipeline. In it, an efficient edge model handles routine queries, a more capable cloud model addresses complex cases, and human experts are involved only when necessary. We define a misalignment-cost constrained optimization problem, aiming to minimize average processing cost, while guaranteeing alignment of automated answers with expert judgments. We propose a statistically rigorous threshold selection method based on multiple hypothesis testing (MHT) for a query processing mechanism based on knowledge and confidence tests. The approach provides finite-sample guarantees on misalignment risk. Experiments on the TeleQnA dataset -- a telecom-specific benchmark -- demonstrate that the proposed method achieves superior cost-efficiency compared to conventional cascaded baselines, while ensuring reliability at prescribed confidence levels."}
{"id": "2512.20014", "pdf": "https://arxiv.org/pdf/2512.20014", "abs": "https://arxiv.org/abs/2512.20014", "authors": ["Sangoh Lee", "Sangwoo Mo", "Wook-Shin Han"], "title": "Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "While Vision-Language-Action (VLA) models generalize well to generic instructions, they struggle with personalized commands such as \"bring my cup\", where the robot must act on one specific instance among visually similar objects. We study this setting of manipulating personal objects, in which a VLA must identify and control a user-specific object unseen during training using only a few reference images. To address this challenge, we propose Visual Attentive Prompting (VAP), a simple-yet-effective training-free perceptual adapter that equips frozen VLAs with top-down selective attention. VAP treats the reference images as a non-parametric visual memory, grounds the personal object in the scene through open-vocabulary detection and embedding-based matching, and then injects this grounding as a visual prompt by highlighting the object and rewriting the instruction. We construct two simulation benchmarks, Personalized-SIMPLER and Personalized-VLABench, and a real-world tabletop benchmark to evaluate personalized manipulation across multiple robots and tasks. Experiments show that VAP consistently outperforms generic policies and token-learning baselines in both success rate and correct-object manipulation, helping to bridge the gap between semantic understanding and instance-level control."}
{"id": "2512.20018", "pdf": "https://arxiv.org/pdf/2512.20018", "abs": "https://arxiv.org/abs/2512.20018", "authors": ["Xiaobo Zeng", "Pan Liu", "Liangcai Chen", "Ruonan Deng"], "title": "EDA-RoF: Elastic Digital-Analog Radio-Over-Fiber (RoF) Modulation and Demodulation Architecture Enabling Seamless Transition Between Analog RoF and Digital RoF", "categories": ["eess.SP"], "comment": null, "summary": "We propose and demonstrate an elastic digital-analog radio-over-fiber (RoF) modulation and demodulation architecture, seamlessly bridging A-RoF and D-RoF solutions, achieving quasilinear SNR scaling with respect to 1/η, and evidenced by R^2=0.9908."}
{"id": "2512.20166", "pdf": "https://arxiv.org/pdf/2512.20166", "abs": "https://arxiv.org/abs/2512.20166", "authors": ["Xiaofan Wang", "Xingyu Gao", "Jianlong Fu", "Zuolei Li", "Dean Fortier", "Galen Mullins", "Andrey Kolobov", "Baining Guo"], "title": "LoLA: Long Horizon Latent Action Learning for General Robot Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "The capability of performing long-horizon, language-guided robotic manipulation tasks critically relies on leveraging historical information and generating coherent action sequences. However, such capabilities are often overlooked by existing Vision-Language-Action (VLA) models. To solve this challenge, we propose LoLA (Long Horizon Latent Action Learning), a framework designed for robot manipulation that integrates long-term multi-view observations and robot proprioception to enable multi-step reasoning and action generation. We first employ Vision-Language Models to encode rich contextual features from historical sequences and multi-view observations. We further introduces a key module, State-Aware Latent Re-representation, which transforms visual inputs and language commands into actionable robot motion space. Unlike existing VLA approaches that merely concatenate robot proprioception (e.g., joint angles) with VL embeddings, this module leverages such robot states to explicitly ground VL representations in physical scale through a learnable \"embodiment-anchored\" latent space. We trained LoLA on diverse robotic pre-training datasets and conducted extensive evaluations on simulation benchmarks (SIMPLER and LIBERO), as well as two real-world tasks on Franka and Bi-Manual Aloha robots. Results show that LoLA significantly outperforms prior state-of-the-art methods (e.g., pi0), particularly in long-horizon manipulation tasks."}
{"id": "2512.20071", "pdf": "https://arxiv.org/pdf/2512.20071", "abs": "https://arxiv.org/abs/2512.20071", "authors": ["Ling Zhuang", "Ximing Xie", "Fang Fang", "Ali Attaran", "Zhizhong Zhang"], "title": "Robust and Secure Transmission for Movable-RIS Assisted ISAC with Imperfect Sense Estimation", "categories": ["eess.SP"], "comment": "Part of the work was accepted by the IEEE GLOBECOM 2025 workshop", "summary": "Reconfigurable intelligent surfaces (RISs) have been extensively applied in integrated sensing and communication (ISAC) systems due to the capability of enhancing physical layer security (PLS). However, conventional static RIS architectures lack the flexibility required for adaptive beam control in multi-user and multifunctional scenarios. To address this issue without introducing additional hardware complexity and power consumption, in this paper, we exploit a movable RIS (MRIS) architecture, which consists of a large fixed sub-surface and a smaller movable sub-surface that slides on the fixed sub-surface to achieve dynamic beam reconfiguration with static phase shifts. This paper investigates an MRIS-assisted ISAC system under imperfect sensing estimation, where dedicated radar signals serve as artificial noise to enhance secure transmission against potential eavesdroppers (Eves). The transmit beamforming vectors, MRIS phase shifts, and relative positions of the two sub-surfaces are jointly optimized to maximize the minimum secrecy rate, ensuring robust secrecy performance for the weakest user under the uncertainty of the Eves' channels. To handle the non-convexity, a convex bound is derived for the Eve channel uncertainty, and the S-procedure is employed to reformulate semi-infinite constraints as linear matrix inequalities. An efficient alternating optimization and penalty dual decomposition-based algorithm is developed. Simulation results demonstrate that the proposed MRIS architecture substantially improves secrecy performance, especially when only a small number of elements are allocated to the movable sub-surface."}
{"id": "2512.20188", "pdf": "https://arxiv.org/pdf/2512.20188", "abs": "https://arxiv.org/abs/2512.20188", "authors": ["Teqiang Zou", "Hongliang Zeng", "Yuxuan Nong", "Yifan Li", "Kehui Liu", "Haotian Yang", "Xinyang Ling", "Xin Li", "Lianyang Ma"], "title": "Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Most Vision-Language-Action (VLA) systems integrate a Vision-Language Model (VLM) for semantic reasoning with an action expert generating continuous action signals, yet both typically run at a single unified frequency. As a result, policy performance is constrained by the low inference speed of large VLMs. This mandatory synchronous execution severely limits control stability and real-time performance in whole-body robotic manipulation, which involves more joints, larger motion spaces, and dynamically changing views. We introduce a truly asynchronous Fast-Slow VLA framework (DuoCore-FS), organizing the system into a fast pathway for high-frequency action generation and a slow pathway for rich VLM reasoning. The system is characterized by two key features. First, a latent representation buffer bridges the slow and fast systems. It stores instruction semantics and action-reasoning representation aligned with the scene-instruction context, providing high-level guidance to the fast pathway. Second, a whole-body action tokenizer provides a compact, unified representation of whole-body actions. Importantly, the VLM and action expert are still jointly trained end-to-end, preserving unified policy learning while enabling asynchronous execution. DuoCore-FS supports a 3B-parameter VLM while achieving 30 Hz whole-body action-chunk generation, approximately three times as fast as prior VLA models with comparable model sizes. Real-world whole-body manipulation experiments demonstrate improved task success rates and significantly enhanced responsiveness compared to synchronous Fast-Slow VLA baselines. The implementation of DuoCore-FS, including training, inference, and deployment, is provided to commercial users by Astribot as part of the Astribot robotic platform."}
{"id": "2512.20138", "pdf": "https://arxiv.org/pdf/2512.20138", "abs": "https://arxiv.org/abs/2512.20138", "authors": ["Masanori Nakamura", "Teruo Jyo", "Munehiko Nagatani", "Hitoshi Wakita", "Miwa Mutoh", "Yuta Shiratori", "Hiroki Taniguchi", "Akira Masuda", "Shuto Yamamoto", "Fukutaro Hamaoka", "Etsushi Yamazaki", "Hiroyuki Takahashi", "Takayuki Kobayashi", "Yutaka Miyamoto"], "title": "Net 582-Gb/s C-band and 4$\\times$526-Gb/s O-band IMDD Transmis-sion Using Ultra-broadband InP-DHBT-based Electrical Mixer", "categories": ["eess.SP"], "comment": "Published in 50th European Conference on Optical Communication (ECOC2024), Postdeadline paper Th3B.3", "summary": "We successfully transmitted a net 582-Gb/s probabilistically shaped PAM12 C-band signal over 11-km dispersion-shifted fibre and net 4$\\times$526-Gb/s uniform PAM8 O-band signals over 2-km four-core fibre using a single-carrier 216-GBd IMDD system based on a 150-GHz bandwidth InP-DHBT electrical mixer and a thin-film lithium-niobate modulator."}
{"id": "2512.20224", "pdf": "https://arxiv.org/pdf/2512.20224", "abs": "https://arxiv.org/abs/2512.20224", "authors": ["Qijun Qin", "Ziqi Zhang", "Yihan Zhong", "Feng Huang", "Xikun Liu", "Runzhi Hu", "Hang Chen", "Wei Hu", "Dongzhe Su", "Jun Zhang", "Hoi-Fung Ng", "Weisong Wen"], "title": "UrbanV2X: A Multisensory Vehicle-Infrastructure Dataset for Cooperative Navigation in Urban Areas", "categories": ["cs.RO"], "comment": "8 pages, 9 figures, IEEE ITSC 2025", "summary": "Due to the limitations of a single autonomous vehicle, Cellular Vehicle-to-Everything (C-V2X) technology opens a new window for achieving fully autonomous driving through sensor information sharing. However, real-world datasets supporting vehicle-infrastructure cooperative navigation in complex urban environments remain rare. To address this gap, we present UrbanV2X, a comprehensive multisensory dataset collected from vehicles and roadside infrastructure in the Hong Kong C-V2X testbed, designed to support research on smart mobility applications in dense urban areas. Our onboard platform provides synchronized data from multiple industrial cameras, LiDARs, 4D radar, ultra-wideband (UWB), IMU, and high-precision GNSS-RTK/INS navigation systems. Meanwhile, our roadside infrastructure provides LiDAR, GNSS, and UWB measurements. The entire vehicle-infrastructure platform is synchronized using the Precision Time Protocol (PTP), with sensor calibration data provided. We also benchmark various navigation algorithms to evaluate the collected cooperative data. The dataset is publicly available at https://polyu-taslab.github.io/UrbanV2X/."}
{"id": "2512.20154", "pdf": "https://arxiv.org/pdf/2512.20154", "abs": "https://arxiv.org/abs/2512.20154", "authors": ["Luca Barbieri", "Marcus Henninger", "Paolo Tosi", "Artjom Grudnitsky", "Mattia Brambilla", "Monica Nicoli", "Silvio Mandelli"], "title": "Target Classification for Integrated Sensing and Communication in Industrial Deployments", "categories": ["eess.SP"], "comment": null, "summary": "Integrated Sensing and Communication (ISAC) systems enable cellular networks to jointly operate as communication technology and sense the environment. While opportunities and potential performance have been largely investigated in simulations, few experimental works have showcased Automatic Target Recognition (ATR) effectiveness in a real-world deployment based on cellular radio units. To bridge this gap, this paper presents an initial study investigating the feasibility of ATR for ISAC. Our ATR solution uses a Deep Learning (DL)-based detector to infer the target class directly from the radar images generated by the ISAC system. The DL detector is evaluated with experimental data from a ISAC testbed based on commercially available mmWave radio units in the ARENA 2036 industrial research campus located in Stuttgart, Germany. Experimental results demonstrate accurate classification performance, demonstrating the feasibility of ATR ISAC with cellular hardware in our setup. We finally provide insights about the open generalization challenges, that will fuel future work on the topic."}
{"id": "2512.20299", "pdf": "https://arxiv.org/pdf/2512.20299", "abs": "https://arxiv.org/abs/2512.20299", "authors": ["Zhongyu Xia", "Wenhao Chen", "Yongtao Wang", "Ming-Hsuan Yang"], "title": "KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Visual-language reasoning, driving knowledge, and value alignment are essential for advanced autonomous driving systems. However, existing approaches largely rely on data-driven learning, making it difficult to capture the complex logic underlying decision-making through imitation or limited reinforcement rewards. To address this, we propose KnowVal, a new autonomous driving system that enables visual-language reasoning through the synergistic integration of open-world perception and knowledge retrieval. Specifically, we construct a comprehensive driving knowledge graph that encodes traffic laws, defensive driving principles, and ethical norms, complemented by an efficient LLM-based retrieval mechanism tailored for driving scenarios. Furthermore, we develop a human-preference dataset and train a Value Model to guide interpretable, value-aligned trajectory assessment. Experimental results show that our method substantially improves planning performance while remaining compatible with existing architectures. Notably, KnowVal achieves the lowest collision rate on nuScenes and state-of-the-art results on Bench2Drive."}
{"id": "2512.20246", "pdf": "https://arxiv.org/pdf/2512.20246", "abs": "https://arxiv.org/abs/2512.20246", "authors": ["Songnan Gu", "Hao Jiang", "Chongjun Ouyang", "Yuanwei Liu", "Dong In Kim"], "title": "Sum-Rate Maximization for Uplink Segmented Waveguide-Enabled Pinching-Antenna Systems", "categories": ["eess.SP"], "comment": "5 pages", "summary": "A multiuser uplink transmission framework based on the segmented waveguide-enabled pinching-antenna system (SWAN) is proposed under two operating protocols: segment selection (SS) and segment aggregation (SA). For each protocol, the achievable uplink sum-rate is characterized for both time-division multiple access (TDMA) and non-orthogonal multiple access (NOMA). Low-complexity placement methods for the pinching antennas (PAs) are developed for both protocols and for both multiple-access schemes. Numerical results validate the effectiveness of the proposed methods and show that SWAN achieves higher sum-rate performance than conventional pinching-antenna systems, while SA provides additional performance gains over SS."}
{"id": "2512.20322", "pdf": "https://arxiv.org/pdf/2512.20322", "abs": "https://arxiv.org/abs/2512.20322", "authors": ["Katsu Uchiyama", "Ryuma Niiyama"], "title": "Pneumatic bladder links with wide range of motion joints for articulated inflatable robots", "categories": ["cs.RO"], "comment": "Accepted at IROS2024 (IEEE/RSJ International Conference on Intelligent Robots and Systems)", "summary": "Exploration of various applications is the frontier of research on inflatable robots. We proposed an articulated robots consisting of multiple pneumatic bladder links connected by rolling contact joints called Hillberry joints. The bladder link is made of a double-layered structure of tarpaulin sheet and polyurethane sheet, which is both airtight and flexible in shape. The integration of the Hilberry joint into an inflatable robot is also a new approach. The rolling contact joint allows wide range of motion of $\\pm 150 ^{\\circ}$, the largest among the conventional inflatable joints. Using the proposed mechanism for inflatable robots, we demonstrated moving a 500 g payload with a 3-DoF arm and lifting 3.4 kg and 5 kg payloads with 2-DoF and 1-DoF arms, respectively. We also experimented with a single 3-DoF inflatable leg attached to a dolly to show that the proposed structure worked for legged locomotion."}
{"id": "2512.20354", "pdf": "https://arxiv.org/pdf/2512.20354", "abs": "https://arxiv.org/abs/2512.20354", "authors": ["Simon Hellmann", "Terrance Wilms", "Stefan Streif", "Sören Weinrich"], "title": "A Tutorial to Multirate Extended Kalman Filter Design for Monitoring of Agricultural Anaerobic Digestion Plants", "categories": ["eess.SP", "eess.SY"], "comment": "extended appendix", "summary": "In many applications of biotechnology, measurements are available at different sampling rates, e.g., due to online sensors and offline lab analysis. Offline measurements typically involve time delays that may be unknown a priori due to the underlying laboratory procedures. This multirate (MR) setting poses a challenge to Kalman filtering, where conventionally measurement data is assumed to be available on an equidistant time grid and without delays. The present study derives the MR version of an extended Kalman filter (EKF) based on sample state augmentation, and applies it to the anaerobic digestion (AD) process in a simulative agricultural setting. The performance of the MR-EKF is investigated for various scenarios, i.e., varying delay lengths, measurement noise levels, plant-model mismatch (PMM), and initial state error. Provided with an adequate tuning, the MR-EKF could be demonstrated to reliably estimate the process state, to appropriately fuse delayed offline measurements, and to smooth noisy online measurements well. Because of the sample state augmentation approach, the delay length of offline measurements does not critically impair state estimation performance, provided observability is not lost during the delays. Poor state initialization and PMM affect convergence more than measurement noise levels. Further, selecting an appropriate tuning was found to be critically important for successful application of the MR-EKF, for which a systematic approach is presented. This study provides implementation guidance for practitioners aiming at successfully applying state estimation for multirate systems. It thereby contributes to develop demand-driven operation of biogas plants, which may aid in stabilizing a renewable electricity grid."}
{"id": "2512.20355", "pdf": "https://arxiv.org/pdf/2512.20355", "abs": "https://arxiv.org/abs/2512.20355", "authors": ["Hao Wei", "Peiji Wang", "Qianhao Wang", "Tong Qin", "Fei Gao", "Yulin Si"], "title": "FAR-AVIO: Fast and Robust Schur-Complement Based Acoustic-Visual-Inertial Fusion Odometry with Sensor Calibration", "categories": ["cs.RO"], "comment": null, "summary": "Underwater environments impose severe challenges to visual-inertial odometry systems, as strong light attenuation, marine snow and turbidity, together with weakly exciting motions, degrade inertial observability and cause frequent tracking failures over long-term operation. While tightly coupled acoustic-visual-inertial fusion, typically implemented through an acoustic Doppler Velocity Log (DVL) integrated with visual-inertial measurements, can provide accurate state estimation, the associated graph-based optimization is often computationally prohibitive for real-time deployment on resource-constrained platforms. Here we present FAR-AVIO, a Schur-Complement based, tightly coupled acoustic-visual-inertial odometry framework tailored for underwater robots. FAR-AVIO embeds a Schur complement formulation into an Extended Kalman Filter(EKF), enabling joint pose-landmark optimization for accuracy while maintaining constant-time updates by efficiently marginalizing landmark states. On top of this backbone, we introduce Adaptive Weight Adjustment and Reliability Evaluation(AWARE), an online sensor health module that continuously assesses the reliability of visual, inertial and DVL measurements and adaptively regulates their sigma weights, and we develop an efficient online calibration scheme that jointly estimates DVL-IMU extrinsics, without dedicated calibration manoeuvres. Numerical simulations and real-world underwater experiments consistently show that FAR-AVIO outperforms state-of-the-art underwater SLAM baselines in both localization accuracy and computational efficiency, enabling robust operation on low-power embedded platforms. Our implementation has been released as open source software at https://far-vido.gitbook.io/far-vido-docs."}
{"id": "2512.20380", "pdf": "https://arxiv.org/pdf/2512.20380", "abs": "https://arxiv.org/abs/2512.20380", "authors": ["Lebin Chen", "Ming-Min Zhao", "Qingqing Wu", "Min-Jian Zhao", "Rui Zhang"], "title": "A Covariance-Surrogate Framework for Movable-Antenna Enabled Anti-Jamming with Unknown Jammers", "categories": ["eess.SP", "cs.IT"], "comment": "14 pages, 10 figures", "summary": "In this paper, we investigate a movable antenna (MA) enabled anti-jamming optimization problem, where a legitimate uplink system is exposed to multiple jammers with unknown jamming channels. To enhance the anti-jamming capability of the considered system, an MA array is deployed at the receiver, and the antenna positions and the minimum-variance distortionless-response (MVDR) receive beamformer are jointly optimized to maximize the output signal-to-interference-plus-noise ratio (SINR). The main challenge arises from the fact that the interference covariance matrix is unknown and nonlinearly dependent on the antenna positions. To overcome these issues, we propose a surrogate objective by replacing the unknown covariance with the sample covariance evaluated at the current antenna position anchor. Under a two-timescale framework, the surrogate objective is updated once per block (contains multiple snapshots) at the current anchor position, while the MVDR beamformer is adapted on a per-snapshot basis. We establish a local bound on the discrepancy between the surrogate and the true objective by leveraging matrix concentration inequalities, and further prove that a natural historical-averaging surrogate suffers from a non-vanishing geometric bias. Building on these insights, we develop a low-complexity projected trust-region (TR) surrogate optimization (PTRSO) algorithm that maintains the locality of each iteration via TR constraints and enforces feasibility through projection, which is guaranteed to converge to a stationary point near the anchor. Numerical results verify the effectiveness and robustness of the proposed PTRSO algorithm, which consistently achieves higher output SINR than existing baselines."}
{"id": "2512.20475", "pdf": "https://arxiv.org/pdf/2512.20475", "abs": "https://arxiv.org/abs/2512.20475", "authors": ["Maulana Bisyir Azhari", "Donghun Han", "Je In You", "Sungjun Park", "David Hyunchul Shim"], "title": "Drift-Corrected Monocular VIO and Perception-Aware Planning for Autonomous Drone Racing", "categories": ["cs.RO"], "comment": null, "summary": "The Abu Dhabi Autonomous Racing League(A2RL) x Drone Champions League competition(DCL) requires teams to perform high-speed autonomous drone racing using only a single camera and a low-quality inertial measurement unit -- a minimal sensor set that mirrors expert human drone racing pilots. This sensor limitation makes the system susceptible to drift from Visual-Inertial Odometry (VIO), particularly during long and fast flights with aggressive maneuvers. This paper presents the system developed for the championship, which achieved a competitive performance. Our approach corrected VIO drift by fusing its output with global position measurements derived from a YOLO-based gate detector using a Kalman filter. A perception-aware planner generated trajectories that balance speed with the need to keep gates visible for the perception system. The system demonstrated high performance, securing podium finishes across multiple categories: third place in the AI Grand Challenge with top speed of 43.2 km/h, second place in the AI Drag Race with over 59 km/h, and second place in the AI Multi-Drone Race. We detail the complete architecture and present a performance analysis based on experimental data from the competition, contributing our insights on building a successful system for monocular vision-based autonomous drone flight."}
{"id": "2512.20533", "pdf": "https://arxiv.org/pdf/2512.20533", "abs": "https://arxiv.org/abs/2512.20533", "authors": ["Kyriakos Stylianopoulos", "Paolo Di Lorenzo", "George C. Alexandropoulos"], "title": "Over-the-Air Goal-Oriented Communications", "categories": ["eess.SP", "cs.ET", "cs.IT", "cs.LG"], "comment": "35 pages, 9 figures. Book chapter", "summary": "Goal-oriented communications offer an attractive alternative to the Shannon-based communication paradigm, where the data is never reconstructed at the Receiver (RX) side. Rather, focusing on the case of edge inference, the Transmitter (TX) and the RX cooperate to exchange features of the input data that will be used to predict an unseen attribute of them, leveraging information from collected data sets. This chapter demonstrates that the wireless channel can be used to perform computations over the data, when equipped with programmable metasurfaces. The end-to-end system of the TX, RX, and MS-based channel is treated as a single deep neural network which is trained through backpropagation to perform inference on unseen data. Using Stacked Intelligent Metasurfaces (SIM), it is shown that this Metasurfaces-Integrated Neural Network (MINN) can achieve performance comparable to fully digital neural networks under various system parameters and data sets. By offloading computations onto the channel itself, important benefits may be achieved in terms of energy consumption, arising from reduced computations at the transceivers and smaller transmission power required for successful inference."}
{"id": "2512.20591", "pdf": "https://arxiv.org/pdf/2512.20591", "abs": "https://arxiv.org/abs/2512.20591", "authors": ["Changyi Lin", "Boda Huo", "Mingyang Yu", "Emily Ruppel", "Bingqing Chen", "Jonathan Francis", "Ding Zhao"], "title": "LightTact: A Visual-Tactile Fingertip Sensor for Deformation-Independent Contact Sensing", "categories": ["cs.RO"], "comment": null, "summary": "Contact often occurs without macroscopic surface deformation, such as during interaction with liquids, semi-liquids, or ultra-soft materials. Most existing tactile sensors rely on deformation to infer contact, making such light-contact interactions difficult to perceive robustly. To address this, we present LightTact, a visual-tactile fingertip sensor that makes contact directly visible via a deformation-independent, optics-based principle. LightTact uses an ambient-blocking optical configuration that suppresses both external light and internal illumination at non-contact regions, while transmitting only the diffuse light generated at true contacts. As a result, LightTact produces high-contrast raw images in which non-contact pixels remain near-black (mean gray value < 3) and contact pixels preserve the natural appearance of the contacting surface. Built on this, LightTact achieves accurate pixel-level contact segmentation that is robust to material properties, contact force, surface appearance, and environmental lighting. We further integrate LightTact on a robotic arm and demonstrate manipulation behaviors driven by extremely light contact, including water spreading, facial-cream dipping, and thin-film interaction. Finally, we show that LightTact's spatially aligned visual-tactile images can be directly interpreted by existing vision-language models, enabling resistor value reasoning for robotic sorting."}
{"id": "2512.19764", "pdf": "https://arxiv.org/pdf/2512.19764", "abs": "https://arxiv.org/abs/2512.19764", "authors": ["Chathuranga M. Wijerathna Basnayaka", "Haeyoung Lee", "Pandelis Kourtessis", "John M. Senior", "Vishalya P. Sooriarachchi", "Dushantha Nalin K. Jayakody", "Marko Beko", "Seokjoo Shin"], "title": "Visual Event Detection over AI-Edge LEO Satellites with AoI Awareness", "categories": ["cs.IT", "eess.SP", "physics.app-ph"], "comment": null, "summary": "Non terrestrial networks (NTNs), particularly low Earth orbit (LEO) satellite systems, play a vital role in supporting future mission critical applications such as disaster relief. Recent advances in artificial intelligence (AI)-native communications enable LEO satellites to act as intelligent edge nodes capable of on board learning and task oriented inference. However, the limited link budget, coupled with severe path loss and fading, significantly constrains reliable downlink transmission. This paper proposes a deep joint source-channel coding (DJSCC)-based downlink scheme for AI-native LEO networks, optimized for goal-oriented visual inference. In the DJSCC approach, only semantically meaningful features are extracted and transmitted, whereas conventional separate source-channel coding (SSCC) transmits the original image data. To evaluate information freshness and visual event detection performance, this work introduces the age of misclassified information (AoMI) metric and a threshold based AoI analysis that measures the proportion of users meeting application specific timeliness requirements. Simulation results show that the proposed DJSCC scheme provides higher inference accuracy, lower average AoMI, and greater threshold compliance than the conventional SSCC baseline, enabling semantic communication in AI native LEO satellite networks for 6G and beyond."}
{"id": "2512.19846", "pdf": "https://arxiv.org/pdf/2512.19846", "abs": "https://arxiv.org/abs/2512.19846", "authors": ["Francisco M. F. R. Gonçalves", "Ryan M. Bena", "Néstor O. Pérez-Arancibia"], "title": "A Class of Axis-Angle Attitude Control Laws for Rotational Systems", "categories": ["eess.SY", "cs.RO"], "comment": "6 pages, 4 figures. Accepted for publication in IEEE Control Systems Letters", "summary": "We introduce a new class of attitude control laws for rotational systems, which generalizes the use of the Euler axis-angle representation beyond quaternion-based formulations. Using basic Lyapunov's stability theory and the notion of extended $K_{\\infty}$ functions, we developed a method for determining and enforcing the global asymptotic stability of the single fixed point of the resulting closed-loop (CL) scheme. In contrast with traditional quaternion-based methods, the proposed generalized axis-angle approach enables greater flexibility in the design of the control law, which is of great utility when employed in combination with a switching scheme whose transition state depends on the angular velocity of the controlled rotational system. Through simulation and real-time experimental results, we demonstrate the effectiveness of the proposed approach. According to the recorded data, in the execution of high-speed tumble-recovery maneuvers, the new method consistently achieves shorter stabilization times and requires lower control effort relative to those corresponding to the quaternion-based and geometric-control methods used as benchmarks."}
{"id": "2512.19834", "pdf": "https://arxiv.org/pdf/2512.19834", "abs": "https://arxiv.org/abs/2512.19834", "authors": ["Davi Juvêncio Gomes de Sousa", "Nelson Alves Ferreira Neto", "Christiano M. S. Nascimento", "Lucas Q. Galvão", "Mauro Queiroz Nooblath Neto", "Micael Andrade Dias", "Cássio de Castro Silva", "Braian Pinheiro da Silva", "Alexandre B. Tacla", "Valéria Loureiro da Silva"], "title": "Towards a point-to-point CV-QKD system: Implementation challenges and perspectives", "categories": ["quant-ph", "cs.ET", "cs.IR", "cs.IT", "eess.SP"], "comment": "33 pages with 8 figures", "summary": "This article presents an analysis of the practical challenges and implementation perspectives of point-to-point continuous-variable quantum key distribution (CV-QKD) systems over optical fiber. The study addresses the physical layer, including the design of transmitters, quantum channels, and receivers, with emphasis on impairments such as attenuation, chromatic dispersion, polarization fluctuations, and coexistence with classical channels. We further examine the role of digital signal processing (DSP) as the bridge between quantum state transmission and classical post-processing, highlighting its impact on excess noise mitigation, covariance matrix estimation, and reconciliation efficiency. The post-processing pipeline is detailed with a focus on parameter estimation in the finite-size regime, information reconciliation using LDPC-based codes optimized for low-SNR conditions, and privacy amplification employing large-block universal hashing. From a hardware perspective, we discuss modular digital architectures that integrate dedicated accelerators with programmable processors, supported by a reference software framework (CV-QKD-ModSim) for algorithm validation and hardware co-design. Finally, we outline perspectives for the deployment of CV-QKD in Brazil, starting from metropolitan testbeds and extending toward hybrid fiber/FSO and space-based infrastructures. The work establishes the foundations for the first point-to-point CV-QKD system in Brazil, while providing a roadmap for scalable and interoperable quantum communication networks."}
{"id": "2512.20052", "pdf": "https://arxiv.org/pdf/2512.20052", "abs": "https://arxiv.org/abs/2512.20052", "authors": ["Hung-Chieh Fang", "Kuo-Han Hung", "Chu-Rong Chen", "Po-Jung Chou", "Chun-Kai Yang", "Po-Chen Ko", "Yu-Chiang Wang", "Yueh-Hua Wu", "Min-Hung Chen", "Shao-Hua Sun"], "title": "Learning Skills from Action-Free Videos", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data."}
{"id": "2512.20108", "pdf": "https://arxiv.org/pdf/2512.20108", "abs": "https://arxiv.org/abs/2512.20108", "authors": ["Yuntong Gu", "Xiangming meng", "Zhiyuan Lin", "Sheng Wu", "Linling Kuang"], "title": "Generative Bayesian Spectrum Cartography: Unified Reconstruction and Active Sensing via Diffusion Models", "categories": ["cs.IT", "eess.SP"], "comment": null, "summary": "High-fidelity spectrum cartography is pivotal for spectrum management and wireless situational awareness, yet it remains a challenging ill-posed inverse problem due to the sparsity and irregularity of observations. Furthermore, existing approaches often decouple reconstruction from sensing, lacking a principled mechanism for informative sampling. To address these limitations, this paper proposes a unified diffusion-based Bayesian framework that jointly addresses spectrum reconstruction and active sensing. We formulate the reconstruction task as a conditional generation process driven by a learned diffusion prior. Specifically, we derive tractable, closed-form posterior transition kernels for the reverse diffusion process, which enforce consistency with both linear Gaussian and non-linear quantized measurements. Leveraging the intrinsic probabilistic nature of diffusion models, we further develop an uncertainty-aware active sampling strategy. This strategy quantifies reconstruction uncertainty to adaptively guide sensing agents toward the most informative locations, thereby maximizing spectral efficiency. Extensive experiments demonstrate that the proposed framework significantly outperforms state-of-the-art interpolation, sparsity-based, and deep learning baselines in terms of reconstruction accuracy, sampling efficiency, and robustness to low-bit quantization."}
{"id": "2512.20083", "pdf": "https://arxiv.org/pdf/2512.20083", "abs": "https://arxiv.org/abs/2512.20083", "authors": ["Wenzhao Wu", "Yahui Tang", "Mingfei Cheng", "Wenbing Tang", "Yuan Zhou", "Yang Liu"], "title": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing", "categories": ["cs.SE", "cs.RO"], "comment": null, "summary": "As embodied agents advance toward real-world deployment, ensuring optimal decisions becomes critical for resource-constrained applications. Current evaluation methods focus primarily on functional correctness, overlooking the non-functional optimality of generated plans. This gap can lead to significant performance degradation and resource waste. We identify and formalize the problem of Non-optimal Decisions (NoDs), where agents complete tasks successfully but inefficiently. We present NoD-DGMT, a systematic framework for detecting NoDs in embodied agent task planning via diversity-guided metamorphic testing. Our key insight is that optimal planners should exhibit invariant behavioral properties under specific transformations. We design four novel metamorphic relations capturing fundamental optimality properties: position detour suboptimality, action optimality completeness, condition refinement monotonicity, and scene perturbation invariance. To maximize detection efficiency, we introduce a diversity-guided selection strategy that actively selects test cases exploring different violation categories, avoiding redundant evaluations while ensuring comprehensive diversity coverage. Extensive experiments on the AI2-THOR simulator with four state-of-the-art planning models demonstrate that NoD-DGMT achieves violation detection rates of 31.9% on average, with our diversity-guided filter improving rates by 4.3% and diversity scores by 3.3 on average. NoD-DGMT significantly outperforms six baseline methods, with 16.8% relative improvement over the best baseline, and demonstrates consistent superiority across different model architectures and task complexities."}
{"id": "2512.20198", "pdf": "https://arxiv.org/pdf/2512.20198", "abs": "https://arxiv.org/abs/2512.20198", "authors": ["Huizheng Wang", "Taiquan Wei", "Hongbin Wang", "Zichuan Wang", "Xinru Tang", "Zhiheng Yue", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling", "categories": ["cs.AR", "eess.SP"], "comment": "Accepted for publication in IEEE Transactions on Computers", "summary": "Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\\times$ speedup and 71.2$\\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\\times$ energy and 27.1$\\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\\times$ throughput improvement."}
{"id": "2512.20148", "pdf": "https://arxiv.org/pdf/2512.20148", "abs": "https://arxiv.org/abs/2512.20148", "authors": ["Robert van de Ven", "Trim Bresilla", "Bram Nelissen", "Ard Nieuwenhuizen", "Eldert J. van Henten", "Gert Kootstra"], "title": "Enhancing annotations for 5D apple pose estimation through 3D Gaussian Splatting (3DGS)", "categories": ["cs.CV", "cs.RO"], "comment": "33 pages, excluding appendices. 17 figures", "summary": "Automating tasks in orchards is challenging because of the large amount of variation in the environment and occlusions. One of the challenges is apple pose estimation, where key points, such as the calyx, are often occluded. Recently developed pose estimation methods no longer rely on these key points, but still require them for annotations, making annotating challenging and time-consuming. Due to the abovementioned occlusions, there can be conflicting and missing annotations of the same fruit between different images. Novel 3D reconstruction methods can be used to simplify annotating and enlarge datasets. We propose a novel pipeline consisting of 3D Gaussian Splatting to reconstruct an orchard scene, simplified annotations, automated projection of the annotations to images, and the training and evaluation of a pose estimation method. Using our pipeline, 105 manual annotations were required to obtain 28,191 training labels, a reduction of 99.6%. Experimental results indicated that training with labels of fruits that are $\\leq95\\%$ occluded resulted in the best performance, with a neutral F1 score of 0.927 on the original images and 0.970 on the rendered images. Adjusting the size of the training dataset had small effects on the model performance in terms of F1 score and pose estimation accuracy. It was found that the least occluded fruits had the best position estimation, which worsened as the fruits became more occluded. It was also found that the tested pose estimation method was unable to correctly learn the orientation estimation of apples."}
{"id": "2512.20211", "pdf": "https://arxiv.org/pdf/2512.20211", "abs": "https://arxiv.org/abs/2512.20211", "authors": ["Yicheng Gu", "Junan Zhang", "Chaoren Wang", "Jerry Li", "Zhizheng Wu", "Lauri Juvela"], "title": "Aliasing-Free Neural Audio Synthesis", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": "Submitted to TASLP", "summary": "Neural vocoders and codecs reconstruct waveforms from acoustic representations, which directly impact the audio quality. Among existing methods, upsampling-based time-domain models are superior in both inference speed and synthesis quality, achieving state-of-the-art performance. Still, despite their success in producing perceptually natural sound, their synthesis fidelity remains limited due to the aliasing artifacts brought by the inadequately designed model architectures. In particular, the unconstrained nonlinear activation generates an infinite number of harmonics that exceed the Nyquist frequency, resulting in ``folded-back'' aliasing artifacts. The widely used upsampling layer, ConvTranspose, copies the mirrored low-frequency parts to fill the empty high-frequency region, resulting in ``mirrored'' aliasing artifacts. Meanwhile, the combination of its inherent periodicity and the mirrored DC bias also brings ``tonal artifact,'' resulting in constant-frequency ringing. This paper aims to solve these issues from a signal processing perspective. Specifically, we apply oversampling and anti-derivative anti-aliasing to the activation function to obtain its anti-aliased form, and replace the problematic ConvTranspose layer with resampling to avoid the ``tonal artifact'' and eliminate aliased components. Based on our proposed anti-aliased modules, we introduce Pupu-Vocoder and Pupu-Codec, and release high-quality pre-trained checkpoints to facilitate audio generation research. We build a test signal benchmark to illustrate the effectiveness of the anti-aliased modules, and conduct experiments on speech, singing voice, music, and audio to validate our proposed models. Experimental results confirm that our lightweight Pupu-Vocoder and Pupu-Codec models can easily outperform existing systems on singing voice, music, and audio, while achieving comparable performance on speech."}
{"id": "2512.20229", "pdf": "https://arxiv.org/pdf/2512.20229", "abs": "https://arxiv.org/abs/2512.20229", "authors": ["Imtiaz Ur Rehman", "Moussa Labbadi", "Amine Abadi", "Lew Lew Yan Voon"], "title": "Finite-Time Control Based on Differential Flatness for Wheeled Mobile Robots with Experimental Validation", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "A robust tracking control strategy is designed to empower wheeled mobile robots (WMRs) to track predetermined routes while operating in diverse fields and encountering disturbances like strong winds or uneven path conditions, which affect tracking performance. Ensuring the applicability of this tracking method in real-world scenarios is essential. To accomplish this, the WMR model is initially transformed into a linear canonical form by leveraging the differential flatness of its kinematic model, facilitating controller design. Subsequently, a novel integral nonlinear hyperplane-based sliding mode control (INH-SMC) technique is proposed for WMR under disturbances. The stability of the technique is analyzed and verified. Finally, its practical viability is demonstrated through a comparative real-world indoor experiment on a TurtleBot3 WMR subjected to disturbances, confirming the feasibility and efficacy of the proposed approach."}
{"id": "2512.20332", "pdf": "https://arxiv.org/pdf/2512.20332", "abs": "https://arxiv.org/abs/2512.20332", "authors": ["Chaorong Zhang", "Benjamin K. Ng", "Hui Xu", "Chan-Tong Lam", "Halim Yanikomeroglu"], "title": "RIS-Empowered OTFS Modulation With Faster-than-Nyquist Signaling in High-Mobility Wireless Communications", "categories": ["cs.IT", "eess.SP"], "comment": "Submitted to IEEE Journal", "summary": "High-mobility wireless communication systems suffer from severe Doppler spread and multi-path delay, which degrade the reliability and spectral efficiency of conventional modulation schemes. Orthogonal time frequency space (OTFS) modulation offers strong robustness in such environments by representing symbols in the delay-Doppler (DD) domain, while faster-than-Nyquist (FTN) signaling can further enhance spectral efficiency through intentional symbol packing. Meanwhile, reconfigurable intelligent surfaces (RIS) provide a promising means to improve link quality via passive beamforming. Motivated by these advantages, we propose a novel RIS-empowered OTFS modulation with FTN signaling (RIS-OTFS-FTN) scheme. First, we establish a unified DD-domain input-output relationship that jointly accounts for RIS passive beamforming, FTN-induced inter-symbol interference, and DD-domain channel characteristics. Based on this model, we provide comprehensive analytical performance for the frame error rate, spectral efficiency, and peak-to-average power ratio (PAPR), etc. Furthermore, a practical RIS phase adjustment strategy with quantized phase selection is designed to maximize the effective channel gain. Extensive Monte Carlo simulations under a standardized extended vehicular A (EVA) channel model validate the theoretical results and provide key insights into the trade-offs among spectral efficiency, PAPR, input back-off (IBO), and error performance, with some interesting insights.The proposed RIS-OTFS-FTN scheme demonstrates notable performance gains in both reliability and spectral efficiency, offering a viable solution for future high-mobility and spectrum-constrained wireless systems."}
{"id": "2512.20276", "pdf": "https://arxiv.org/pdf/2512.20276", "abs": "https://arxiv.org/abs/2512.20276", "authors": ["Yuntao Dai", "Hang Gu", "Teng Wang", "Qianyu Cheng", "Yifei Zheng", "Zhiyong Qiu", "Lei Gong", "Wenqi Lou", "Xuehai Zhou"], "title": "ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47."}
{"id": "2512.20389", "pdf": "https://arxiv.org/pdf/2512.20389", "abs": "https://arxiv.org/abs/2512.20389", "authors": ["Victoria E. Galanopoulou", "Thrassos K. Oikonomou", "Odysseas G. Karagiannidis", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis"], "title": "Viterbi State Selection for Discrete Pinching Antenna Systems", "categories": ["cs.IT", "eess.SP"], "comment": null, "summary": "Pinching antennas enable dynamic control of electromagnetic wave propagation through reconfigurable radiating structures, but selecting an optimal subset of antennas remains a combinatorial problem with exponential complexity. This letter considers antenna subset selection for a waveguide-fed pinching antenna array serving ground users under a time-division access scheme. The achievable rate depends on the coherent superposition of the effective complex channel gains and is therefore highly sensitive to the relative phase alignment of the activated antennas. To address the prohibitive complexity of exhaustive search, we propose a Viterbi state selection (VSS) algorithm that exploits the phase structure of the combined received signal. The trellis state is defined by a quantized representation of the phase of the accumulated complex gain, and a Viterbi-based survivor rule is used to prune dominated antenna subsets across stages. Numerical results demonstrate that the proposed method achieves the same antenna selection and rate as exhaustive search, while reducing the computational complexity from exponential to polynomial in the number of available antennas."}
{"id": "2512.20342", "pdf": "https://arxiv.org/pdf/2512.20342", "abs": "https://arxiv.org/abs/2512.20342", "authors": ["Chanchan Xu", "Shuai Dong", "Xiaojie Wang"], "title": "Design and Modeling of a Simple-Structured Continuously Variable Transmission Utilizing Shape Memory Alloy Superelasticity for Twisted String Actuator", "categories": ["physics.ins-det", "cs.RO"], "comment": "15pages,Fig14", "summary": "Twisted String Actuators (TSAs) are widely used in robotics but suffer from a limited range of Transmission Ratio (TR) variation, restricting their efficiency under varying loads.To overcome this, we propose a novel lightweight, simple-structured Continuously Variable Transmission (CVT) mechanism for TSA utilizing Shape Memory Alloy (SMA) superelasticity. The CVT mechanism consists solely of a pair of highly lightweight superelastic SMA rods connecting the ends of twisted strings. These rods deform under external loads, adjusting the inter-string distance to enable continuous TR variation.We develop a comprehensive theoretical model that integrates three critical nonlinearities"}
{"id": "2512.20490", "pdf": "https://arxiv.org/pdf/2512.20490", "abs": "https://arxiv.org/abs/2512.20490", "authors": ["Callum Deakin", "Zichuan Zhou", "Ronit Sohanpal", "Zhixin Liu"], "title": "Dual optical frequency comb downconversion of D-band mm-wave signals", "categories": ["physics.optics", "eess.SP"], "comment": "2026 Optical Fiber Communications Conference and Exhibition (OFC)", "summary": "We demonstrate a dual optical frequency comb concept that down-converts arbitrary narrowband D-band (110-170 GHz) signals to baseband without any filter or optical/RF frequency tuning, using low frequency RF components."}
{"id": "2512.20391", "pdf": "https://arxiv.org/pdf/2512.20391", "abs": "https://arxiv.org/abs/2512.20391", "authors": ["Georg Schildbach"], "title": "Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms", "categories": ["math.OC", "cs.RO", "eess.SY"], "comment": null, "summary": "Cooperative collision avoidance between robots in swarm operations remains an open challenge. Assuming a decentralized architecture, each robot is responsible for making its own control decisions, including motion planning. To this end, most existing approaches mostly rely some form of (wireless) communication between the agents of the swarm. In reality, however, communication is brittle. It may be affected by latency, further delays and packet losses, transmission faults, and is subject to adversarial attacks, such as jamming or spoofing. This paper proposes Contingency Model-based Control (CMC) as a communicationless alternative. It follows the implicit cooperation paradigm, under which the design of the robots is based on consensual (offline) rules, similar to traffic rules. They include the definition of a contingency trajectory for each robot, and a method for construction of mutual collision avoidance constraints. The setup is shown to guarantee the recursive feasibility and collision avoidance between all swarm members in closed-loop operation. Moreover, CMC naturally satisfies the Plug \\& Play paradigm, i.e., for new robots entering the swarm. Two numerical examples demonstrate that the collision avoidance guarantee is intact and that the robot swarm operates smoothly under the CMC regime."}
{"id": "2512.20563", "pdf": "https://arxiv.org/pdf/2512.20563", "abs": "https://arxiv.org/abs/2512.20563", "authors": ["Long Nguyen", "Micha Fauth", "Bernhard Jaeger", "Daniel Dauner", "Maximilian Igl", "Andreas Geiger", "Kashyap Chitta"], "title": "LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly higher visibility (e.g., ignoring occlusions) and far lower uncertainty (e.g., knowing other vehicles' actions), making them difficult to imitate reliably. Furthermore, navigational intent (i.e., the route to follow) is under-specified in student models at test time via only a single target point. We demonstrate that these asymmetries can measurably limit driving performance in CARLA and offer practical interventions to address them. After careful modifications to narrow the gaps between expert and student, our TransFuser v6 (TFv6) student policy achieves a new state of the art on all major publicly available CARLA closed-loop benchmarks, reaching 95 DS on Bench2Drive and more than doubling prior performances on Longest6~v2 and Town13. Additionally, by integrating perception supervision from our dataset into a shared sim-to-real pipeline, we show consistent gains on the NAVSIM and Waymo Vision-Based End-to-End driving benchmarks. Our code, data, and models are publicly available at https://github.com/autonomousvision/lead."}
