<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.NE](#cs.NE) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
*Zijun Wang,Shawn Tsai,Rama Kiran,Rui Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种低复杂度的近场波束训练方案，利用远场用户的DFT码本，通过分析近场波束特性并改进距离估计方法，显著提升了单用户和多用户的信噪比（SNR）。


<details>
  <summary>Details</summary>
Motivation: 极大规模天线阵列（ELAAs）在高频段的近场通信需求推动了波束训练和信号处理设计的进步，而现有方案在复杂度和性能上存在挑战。

Method: 通过分析近场波束图案，推导出波束宽度和中心增益的闭式解，定义了角度相关的修正瑞利距离，并提出了一种复杂度为O(1)的距离估计方法，进一步结合MLE细化提升了精度。

Result: 仿真结果显示，该方案在单用户和多用户场景中分别实现了高达2.38 dB的SNR提升，且通过MLE细化后，性能接近理想信道状态信息的可达速率。

Conclusion: 论文提出的低复杂度近场波束训练方案高效且准确，为ELAAs在近场通信中的应用提供了实用解决方案。

Abstract: Extremely large antenna arrays (ELAAs) operating in high-frequency bands have
spurred the development of near-field communication, driving advancements in
beam training and signal processing design. In this work, we present a
low-complexity near-field beam training scheme that fully utilizes the
conventional discrete Fourier transform (DFT) codebook designed for far-field
users. We begin by analyzing the received beam pattern in the near field and
derive closed-form expressions for the beam width and central gain. These
analytical results enable the definition of an angle-dependent, modified
Rayleigh distance, which effectively distinguishes near-field and far-field
user regimes. Building on the analysis, we develop a direct and computationally
efficient method to estimate user distance, with a complexity of O(1), and
further improve its accuracy through a simple refinement. Simulation results
demonstrate significant gains in both single- and multi-user settings, with up
to 2.38 dB SNR improvement over exhaustive search. To further enhance
estimation accuracy, we additionally propose a maximum likelihood estimation
(MLE) based refinement method, leveraging the Rician distribution of signal
amplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).
Simulation shows the single-user and multi-user achievable rates can both
approach those obtained with ideal channel state information.

</details>


### [2] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
*Mohammad Taghi Dabiri,Mazen Hasna,Saif Al-Kuwari,Khalid Qaraqe*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Entanglement-based quantum key distribution (QKD) protocols, such as E91 and
BBM92, offer strong information-theoretic security and are naturally suited for
satellite-to-satellite QKD (SatQKD) links. However, implementing these
protocols over long-distance inter-satellite free-space optical (FSO) channels
poses critical physical-layer challenges that are not addressed in the existing
literature. In particular, photon losses due to beam divergence, pointing
errors, and background noise can severely degrade the key generation rate and
quantum bit error rate (QBER), especially under narrow receiver field-of-view
(FoV) constraints. This paper presents a comprehensive performance analysis of
entanglement-based inter-satellite QKD, focusing on photon-level modeling and
the impact of practical impairments. We develop analytical expressions for
signal detection probabilities, background photon influence, multi-pair
emissions, and QBER, incorporating key parameters such as link distance,
transmitter tracking jitter, receiver misalignment, and photon pair generation
rate. Simulation results reveal the nonlinear sensitivity of system performance
to tracking error and FoV limitations, and highlight optimal parameter regimes
that jointly maximize secret key rate while maintaining QBER below acceptable
thresholds. The proposed model provides actionable design insights for reliable
and efficient deployment of entanglement-based SatQKD systems.

</details>


### [3] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
*Mohammad Taghi Dabiri,Mazen Hasna*

Main category: eess.SP

TL;DR: 提出一个高效分析框架，用于评估轨道角动量（OAM）光束在瞄准误差下的卫星间通信系统性能，通过解析模型优化比特误码率（BER），相比传统蒙特卡罗方法显著降低计算时间并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 为解决动态低地球轨道（LEO）卫星网络中快速变化的拓扑和信道条件，需要实时链路适应，而传统方法计算复杂度高，因此提出高效分析框架。

Method: 开发解析模型描述OAM光束对准误差引起的模态间串扰，基于此推导BER分析和优化表达式，验证其高效性。

Result: 不对称OAM模式集在瞄准误差下显著优于对称配置，框架实现了高保真实时优化系统参数并验证其适用性。

Conclusion: 该框架为高动态光学无线系统（如LEO卫星网络）提供了高效准确的性能评估和优化工具。

Abstract: This paper presents an efficient analytical framework for evaluating the
performance of inter-satellite communication systems utilizing orbital angular
momentum (OAM) beams under pointing errors. An accurate analytical model is
first developed to characterize intermodal crosstalk caused by beam
misalignment in OAM-based inter-satellite links. Building upon this model, we
derive efficient expressions to analyze and optimize system performance in
terms of bit error rate (BER). Unlike traditional Monte Carlo-based methods
that are computationally intensive, the proposed approach offers accurate
performance predictions. This enables a substantial decrease in computation
time while maintaining high accuracy, thanks to the use of analytical
expressions for both crosstalk and BER. This fast and accurate evaluation
capability is particularly critical for dynamic low Earth orbit (LEO) satellite
constellations, where network topology and channel conditions change rapidly,
requiring real-time link adaptation. Furthermore, we systematically design and
evaluate asymmetric OAM mode sets, which significantly outperform symmetric
configurations in the presence of pointing errors. Our results also reveal key
insights into the interaction between beam divergence, tracking accuracy, and
link distance, demonstrating that the proposed framework enables real-time
optimization of system parameters with high fidelity. The analytical findings
are rigorously validated against extensive Monte Carlo simulations, confirming
their practical applicability for high-mobility optical wireless systems such
as LEO satellite networks.

</details>


### [4] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
*Jamil Farhat,Gianni Pasolini,Enrico Paolini,Muhammad Asad Ullah,Richard Demo Souza*

Main category: eess.SP

TL;DR: 该论文研究了LoRaWAN技术中LoRa调制在卫星物联网（DtS）中的应用，提出了四种多普勒效应估计和补偿框架，并分析了其性能与参数权衡。


<details>
  <summary>Details</summary>
Motivation: 由于低轨道卫星（LEO）的多普勒效应对LoRa DtS连接性能的显著影响，研究旨在解决这一问题。

Method: 提出了四种多普勒效应估计和补偿框架，并通过数值模拟与理想无多普勒场景进行性能比较。

Result: 分析了扩频因子等参数与多普勒效应的权衡关系，为LoRa DtS连接的鲁棒配置提供了见解。

Conclusion: 研究为LoRa在卫星物联网中的应用提供了有效的多普勒补偿方案，优化了连接性能。

Abstract: Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology
has garnered significant interest as a connectivity solution for IoT
applications due to its ability to offer low-cost, low-power, and long-range
communications. One emerging use case of LoRa is DtS connectivity, which
extends coverage to remote areas for supporting IoT operations. The satellite
IoT industry mainly prefers LEO because it has lower launch costs and less path
loss compared to Geostationary orbit. However, a major drawback of LEO
satellites is the impact of the Doppler effect caused by their mobility.
Earlier studies have confirmed that the Doppler effect significantly degrades
the LoRa DtS performance. In this paper, we propose four frameworks for Doppler
estimation and compensation in LoRa DtS connectivity and numerically compare
the performance against the ideal scenario without the Doppler effect.
Furthermore, we investigate the trade-offs among these frameworks by analyzing
the interplay between spreading factor, and other key parameters related to the
Doppler effect. The results provide insights into how to achieve robust LoRa
configurations for DtS connectivity.

</details>


### [5] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
*Naoki Ishikawa,Giuseppe Thadeu Freitas de Abreu,Petar Popovski,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: 量子计算有望重塑通信系统的算法基础，但如何利用量子叠加和纠缠的加速优势仍具挑战性。本文介绍了量子计算的基础，并揭示了量子与无线系统间的数学联系，旨在推动量子信息处理与未来通信系统的跨学科研究。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在通信系统中的潜在优势，并揭示量子与无线系统之间的数学联系，以激发跨学科研究。

Method: 通过系统回顾前沿研究，总结量子加速通信系统的设计趋势，并强调经典启发式方法对优化量子参数的作用。

Result: 发现经典启发式方法可以优化量子参数，展示了经典与量子计算的互补性。

Conclusion: 本文旨在推动量子信息处理与未来通信系统的跨学科研究，并强调了经典与量子计算的协同潜力。

Abstract: Quantum computing is poised to redefine the algorithmic foundations of
communication systems. While quantum superposition and entanglement enable
quadratic or exponential speedups for specific problems, identifying use cases
where these advantages yield engineering benefits is, however, still
nontrivial. This article presents the fundamentals of quantum computing in a
style familiar to the communications society, outlining the current limits of
fault-tolerant quantum computing and uncovering a mathematical harmony between
quantum and wireless systems, which makes the topic more enticing to wireless
researchers. Based on a systematic review of pioneering and state-of-the-art
studies, we distill common design trends for the research and development of
quantum-accelerated communication systems and highlight lessons learned. The
key insight is that classical heuristics can sharpen certain quantum
parameters, underscoring the complementary strengths of classical and quantum
computing. This article aims to catalyze interdisciplinary research at the
frontier of quantum information processing and future communication systems.

</details>


### [6] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
*Haijia Jin,Jun Wu,Weijie Yuan,Fan Liu,Yuanhao Cui*

Main category: eess.SP

TL;DR: 本文研究了6G环境下多无人机协同系统的感知、通信与控制一体化设计（SC²），通过联合优化资源配置、无人机部署和调度，提出了一种高效的近最优解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和6G的发展，无人机在低空无线网络中的作用日益重要。本文旨在通过一体化设计，解决无人机在有限块长传输下的协同感知与控制的挑战。

Method: 提出了一个加权优化问题，利用交替优化（AO）方法分解为非凸子问题，结合DC编程和投影梯度下降（PGD）方法求解。

Result: 仿真结果表明，所提方法在控制和感知性能之间取得了有效平衡，优于基准方案。

Conclusion: 研究为无人机协同系统的SC²设计提供了理论支持和实践指导，展示了在6G环境下的潜在应用价值。

Abstract: The rapid advancement of Internet of Things (IoT) services and the evolution
toward the sixth generation (6G) have positioned unmanned aerial vehicles
(UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This
work investigates the co-design of integrated sensing, communication, and
control ($\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite
blocklength (FBL) transmission. In particular, the UAVs continuously monitor
the state of the field robots and transmit their observations to the robot
controller to ensure stable control while cooperating to localize an unknown
sensing target (ST). To this end, a weighted optimization problem is first
formulated by jointly considering the control and localization performance in
terms of the linear quadratic regulator (LQR) cost and the determinant of the
Fisher information matrix (FIM), respectively. The resultant problem,
optimizing resource allocations, the UAVs' deployment positions, and multi-user
scheduling, is non-convex. To circumvent this challenge, we first derive a
closed-form expression of the LQR cost with respect to other variables.
Subsequently, the non-convex optimization problem is decomposed into a series
of sub-problems by leveraging the alternating optimization (AO) approach, in
which the difference of convex functions (DC) programming and projected
gradient descent (PGD) method are employed to obtain an efficient near-optimal
solution. Furthermore, the convergence and computational complexity of the
proposed algorithm are thoroughly analyzed. Extensive simulation results are
presented to validate the effectiveness of our proposed approach compared to
the benchmark schemes and reveal the trade-off between control and sensing
performance.

</details>


### [7] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 本文提出并评估了用于评估微分麦克风阵列（DMA）波束功率图案中零陷效力的新指标——零陷深度（ND）和零陷宽度（NW），并通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏直接评估零陷效力的指标，而微分麦克风阵列（DMA）在抑制干扰源方面具有潜力。本文旨在填补这一空白。

Method: 提出ND和NW作为零陷相关指标，研究了不同阶数（1阶、2阶、3阶）的线性DMA以及不同波束图案（偶极子、心形、超心形、超级心形）的信号量化效应，并推导了通用N阶DMA的量化波束输出表达式。

Result: 通过仿真和实验室实验验证了ND随量化比特数的变化以及NW随深度的变化，实验结果表明了显著的零陷深度，证明了方法的有效性。

Conclusion: 本文提出的指标有效评估了DMA的零陷性能，为实际应用提供了理论支持和实验验证。

Abstract: A differential microphone array (DMA) offers enhanced capabilities to obtain
sharp nulls at the cost of relatively broad peaks in the beam power pattern.
This can be used for applications that require nullification or attenuation of
interfering sources. To the best of our knowledge, the existing literature
lacks measures that directly assess the efficacy of nulls, and null-related
measures have not been investigated in the context of differential microphone
arrays (DMAs). This paper offers new insights about the utility of DMAs by
proposing measures that characterize the nulls in their beam power patterns. We
investigate the performance of differential beamformers by presenting and
evaluating null-related measures namely null depth (ND) and Null Width (NW) as
a function of depth level relative to the beam power pattern maxima. A study of
signal quantization effects due to data acquisition for 1st, 2nd and 3rd order
linear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid
and supercardioid is presented. An analytical expression for the quantized
beamformed output for any general $ N^{th} $ order DMA is formulated.
Simulation results of the variation of ND with number of quantization bits and
the variation of NW as a function of depth are also presented and inferences
are drawn. Lab experiments are conducted in a fully anechoic room to support
the simulation results. The measured beampattern exhibits a pronounced null
depth, confirming the effectiveness of the experimental setup.

</details>


### [8] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
*Yancheng Wang,Wei Guo,Guanying Chen,Ye Zhang,Shuguang Cui*

Main category: eess.SP

TL;DR: 该论文提出了一种结合模型和数据驱动的方法，利用点云环境数据和少量位置标记的信道信息构建信道知识图（CKM），显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方案采用过于简化的环境信息，导致准确性不足。本文旨在通过利用更丰富的环境数据减少信道状态信息（CSI）获取的开销。

Method: 方法包括设计点选择器识别相关点云子集，并通过神经网络学习这些子集与信道增益的映射关系。

Result: 实验结果显示，在构建功率延迟分布（PDP）和接收功率值的CKM时，新方法的均方根误差（RMSE）显著低于传统方法。

Conclusion: 提出的方法显著提升了CKM构建的准确性，为环境感知通信提供了更可靠的支持。

Abstract: Channel knowledge map (CKM) provides certain levels of channel state
information (CSI) for an area of interest, serving as a critical enabler for
environment-aware communications by reducing the overhead of frequent CSI
acquisition. However, existing CKM construction schemes adopt over-simplified
environment information, which significantly compromises their accuracy. To
address this issue, this work proposes a joint model- and data-driven approach
to construct CKM by leveraging point cloud environmental data along with a few
samples of location-tagged channel information. First, we propose a novel point
selector to identify subsets of point cloud that contain environmental
information relevant to multipath channel gains, by constructing a set of
co-focal ellipsoids based on different time of arrival (ToAs). Then, we trained
a neural channel gain estimator to learn the mapping between each selected
subset and its corresponding channel gain, using a real-world dataset we
collected through field measurements, comprising environmental point clouds and
corresponding channel data. Finally, experimental results demonstrate that: For
CKM construction of power delay profile (PDP), the proposed method achieves a
root mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB
achieved by the conventional ray-tracing method; for CKM construction of
received power values, i.e., radio map, it achieves an RMSE of 1.04 dB,
surpassing the Kriging interpolation method with an RMSE of 1.68 dB.

</details>


### [9] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
*Hao Wu,Chongwu Xie,Xinyuan Yao,Kang-Da Wu,Shanchi Wu,Rui Ni,Guo-Yong Xiang,Chen Gong*

Main category: eess.SP

TL;DR: 论文分析了Rydberg原子传感器在多重频率信号接收时的多用户干扰问题，提出了联合响应系数并验证了误码率和符号错误率。


<details>
  <summary>Details</summary>
Motivation: 解决Rydberg原子传感器在多频率信号接收时由于信号同时下变频导致的多用户干扰问题。

Method: 通过分析两个不同载频信号耦合不同能级的联合响应系数，研究其对彼此的干扰，并分析误码率和符号错误率。

Result: 实验验证了误码率和符号错误率的结果，为多用户通信提供了理论支持。

Conclusion: 研究为Rydberg原子传感器在多用户通信中的应用提供了干扰分析和性能评估方法。

Abstract: Rydberg atomic sensors have been adopted for novel radio frequency (RF)
measurement technique and the sensing capability for signals in multiple
frequencies makes it attractive for multi-user communication. However, unlike
traditional antennas where the signals in multiple frequencies are orthogonal,
the received signals of atomic sensors corresponding to different energy levels
will be downconverted to the baseband simultaneously, resulting in multi-user
interference. Thus, in this paper, we analyze the mutual interference
characteristics of two RF signals with different carrier frequencies coupling
different energy levels. We introduce the joint response coefficient based on
the receiver characteristics and analyze the interference of one user to
another. We analyze the bit-error rate (BER) and symbol-error rate (SER) for
two signals coupling two different energy levels. We also conduct experiments
to validate the BER and SER results.

</details>


### [10] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
*Shengjie Liu,Chenyang Yang*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep neural networks (DNNs) have widespread applications for optimizing
resource allocation. Yet, their performance is vulnerable to distribution
shifts between training and test data, say channels. In this letter, we resort
to adversarial training (AT) for enhancing out-of-distribution (OOD)
generalizability of DNNs trained in unsupervised manner. We reformulate AT to
capture the OOD degradation, and propose a one-step gradient ascent method for
AT. The proposed method is validated by optimizing hybrid precoding. Simulation
results showcase the enhanced OOD performance of multiple kinds of DNNs across
various channel distributions, when only Rayleigh fading channels are used for
training.

</details>


### [11] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
*Nima Mozaffarikhosravi,Prathapasinghe Dharmawansa,Italo Atzeni*

Main category: eess.SP

TL;DR: 论文提出了一种基于定位的波束聚焦策略，利用毫米波和亚太赫兹频率下的主导视距传播，并通过2D-MUSIC算法进行距离估计。结果显示该方法在LoS占主导、短相干块和高噪声功率下更有效。


<details>
  <summary>Details</summary>
Motivation: 随着6G及以上无线通信系统转向更高频段和使用大规模MIMO阵列，近场区域扩展将影响波束成形和用户定位方案。研究旨在解决这一问题。

Method: 提出了一种基于定位的波束聚焦策略，利用毫米波和亚太赫兹频率下的LoS传播；分析了2D-MUSIC算法在简化场景下的距离估计性能。

Result: 数值结果表明，该方法在高频段和大带宽下的LoS主导、短相干块和强噪声功率情况下更为有效。

Conclusion: 基于定位的波束聚焦策略在高频通信场景中表现优越，尤其在LoS主导的条件下。

Abstract: Shifting 6G-and-beyond wireless communication systems to higher frequency
bands and the utilization of massive multiple-input multiple-output arrays will
extend the near-field region, affecting beamforming and user localization
schemes. In this paper, we propose a localization-based beam-focusing strategy
that leverages the dominant line-of-sight (LoS) propagation arising at mmWave
and sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC
algorithm for distance estimation by examining its spectrum in simplified,
tractable setups with minimal numbers of antennas and users. Lastly, we compare
the proposed localization-based beam focusing, with locations estimated via
2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of
uplink sum spectral efficiency. Our numerical results show that the proposed
method becomes more effective under LoS-dominated propagation, short coherence
blocks, and strong noise power arising at high carrier frequencies and with
large bandwidths.

</details>


### [12] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
*Ying Gao,Qingqing Wu,Weidong Mei,Guangji Chen,Wen Chen,Ziyuan Zheng*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper investigates an intelligent reflecting surface (IRS)-aided movable
antenna (MA) system, where multiple IRSs cooperate with a multi-MA base station
to extend wireless coverage to multiple designated target areas. The objective
is to maximize the worst-case signal-to-noise ratio (SNR) across all locations
within these areas through joint optimization of MA positions, IRS reflection
coefficients, and transmit beamforming. To achieve this while balancing the
performance-cost trade-off, we propose three coverage-enhancement schemes: the
area-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared
MA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients
configured only once during installation. These schemes lead to challenging
non-convex optimization problems with implicit objective functions, which are
difficult to solve optimally. To address these problems, we propose a general
algorithmic framework that can be applied to solve each problem efficiently
albeit suboptimally. Simulation results demonstrate that: 1) the proposed
MA-based schemes consistently outperform their fixed-position antenna
(FPA)-based counterparts under both area-adaptive and static IRS
configurations, with the area-adaptive MA-IRS scheme achieving the best
worst-case SNR performance; 2) as transmit antennas are typically far fewer
than IRS elements, the area-adaptive MA-staIRS scheme may underperform the
baseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but
a modest increase in antenna number can reverse this trend; 3) under a fixed
total cost, the optimal MA-to-IRS-element ratio for the worst-case SNR
maximization is empirically found to be proportional to the reciprocal of their
unit cost ratio.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [13] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
*Maxime Leiber,Yosra Marnissi,Axel Barrau,Sylvain Meignen,Laurent Massoulié*

Main category: cs.SD

TL;DR: 提出了一种可微分的短时傅里叶变换（STFT）框架，通过梯度优化参数，克服传统手动调参的局限性，并与神经网络结合。


<details>
  <summary>Details</summary>
Motivation: 传统STFT参数调优依赖离散搜索或启发式方法，效果不佳且计算量大，需要一种更高效的优化方法。

Method: 提出统一的可微分STFT框架，支持基于任意准则的梯度优化，并与神经网络联合优化。

Result: 实验证明该方法能提升时频表示质量，并在下游任务中表现更优。

Conclusion: 可微分STFT提供了一种高效的参数优化途径，适用于复杂任务并与深度学习兼容。

Abstract: The short-time Fourier transform (STFT) is widely used for analyzing
non-stationary signals. However, its performance is highly sensitive to its
parameters, and manual or heuristic tuning often yields suboptimal results. To
overcome this limitation, we propose a unified differentiable formulation of
the STFT that enables gradient-based optimization of its parameters. This
approach addresses the limitations of traditional STFT parameter tuning
methods, which often rely on computationally intensive discrete searches. It
enables fine-tuning of the time-frequency representation (TFR) based on any
desired criterion. Moreover, our approach integrates seamlessly with neural
networks, allowing joint optimization of the STFT parameters and network
weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and
improving performance in downstream tasks is demonstrated through experiments
on both simulated and real-world data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [14] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
*Shashwat Khandelwal,Jakoba Petri-Koenig,Thomas B. Preußer,Michaela Blott,Shreejith Shanker*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recurrent neural networks (RNNs), particularly LSTMs, are effective for
time-series tasks like sentiment analysis and short-term stock prediction.
However, their computational complexity poses challenges for real-time
deployment in resource constrained environments. While FPGAs offer a promising
platform for energy-efficient AI acceleration, existing tools mainly target
feed-forward networks, and LSTM acceleration typically requires full custom
implementation. In this paper, we address this gap by leveraging the
open-source and extensible FINN framework to enable the generalized deployment
of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open
Neural Network Exchange (ONNX) specification to model the recurrent nature of
LSTM computations, enabling support for mixed quantisation within them and
functional verification of LSTM-based models. Furthermore, we introduce custom
transformations within the FINN compiler to map the quantised ONNX computation
graph to hardware blocks from the HLS kernel library of the FINN compiler and
Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM
model for a mid-price stock prediction task using the widely used dataset and
generating a corresponding hardware IP of the model using our flow, targeting
the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator
through our flow achieves a balance between performance (latency) and resource
consumption, while matching (or bettering) inference accuracy of
state-of-the-art models with reduced precision. We believe that the
generalisable nature of the proposed flow will pave the way for
resource-efficient RNN accelerator designs on FPGAs.

</details>


### [15] [Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management](https://arxiv.org/abs/2506.20853)
*Ziyang Lu,Subodh Kalia,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney*

Main category: cs.LG

TL;DR: 论文探讨了多功能认知雷达系统中的时间分配问题，通过深度强化学习比较DDPG和SAC算法，发现SAC在稳定性和样本效率上更优，同时使用NSGA-II算法估计帕累托前沿的上限。


<details>
  <summary>Details</summary>
Motivation: 解决认知雷达系统中新目标扫描与已检测目标跟踪之间的时间分配问题，提升系统在动态环境中的多目标平衡能力。

Method: 将问题建模为多目标优化问题，采用深度强化学习（DDPG和SAC），并用NSGA-II算法估计帕累托前沿。

Result: SAC算法在稳定性和样本效率上优于DDPG，NSGA-II算法提供了帕累托前沿的上限估计。

Conclusion: 研究为开发更高效、自适应的认知雷达系统提供了方法，支持动态环境中多竞争目标的平衡。

Abstract: The time allocation problem in multi-function cognitive radar systems focuses
on the trade-off between scanning for newly emerging targets and tracking the
previously detected targets. We formulate this as a multi-objective
optimization problem and employ deep reinforcement learning to find
Pareto-optimal solutions and compare deep deterministic policy gradient (DDPG)
and soft actor-critic (SAC) algorithms. Our results demonstrate the
effectiveness of both algorithms in adapting to various scenarios, with SAC
showing improved stability and sample efficiency compared to DDPG. We further
employ the NSGA-II algorithm to estimate an upper bound on the Pareto front of
the considered problem. This work contributes to the development of more
efficient and adaptive cognitive radar systems capable of balancing multiple
competing objectives in dynamic environments.

</details>


### [16] [Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection](https://arxiv.org/abs/2506.21093)
*Li Fan,Peng Wang,Jing Yang,Cong Shen*

Main category: cs.LG

TL;DR: 提出了一个名为CHOOSE的浅层Transformer框架，通过引入潜在推理步骤提升推理能力，使其在资源有限的设备上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有ICL-based Transformer模型因深度架构带来的存储和计算成本高的问题。

Method: 在浅层Transformer中引入自回归潜在推理步骤（CoT），提升推理能力而不增加模型深度。

Result: CHOOSE在性能和效率上优于传统浅层Transformer，并接近深度模型。

Conclusion: CHOOSE为资源有限的无线接收器部署Transformer算法提供了可行方案。

Abstract: Transformers have shown potential in solving wireless communication problems,
particularly via in-context learning (ICL), where models adapt to new tasks
through prompts without requiring model updates. However, prior ICL-based
Transformer models rely on deep architectures with many layers to achieve
satisfactory performance, resulting in substantial storage and computational
costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a
CoT-enhanced shallow Transformer framework for wireless symbol detection. By
introducing autoregressive latent reasoning steps within the hidden space,
CHOOSE significantly improves the reasoning capacity of shallow models (1-2
layers) without increasing model depth. This design enables lightweight
Transformers to achieve detection performance comparable to much deeper models,
making them well-suited for deployment on resource-constrained mobile devices.
Experimental results demonstrate that our approach outperforms conventional
shallow Transformers and achieves performance comparable to that of deep
Transformers, while maintaining storage and computational efficiency. This
represents a promising direction for implementing Transformer-based algorithms
in wireless receivers with limited computational resources.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [17] [Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing](https://arxiv.org/abs/2506.20782)
*Marc Bara*

Main category: cs.NE

TL;DR: 提出了首个将脉冲神经网络（SNN）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架，填补了当前方法中的空白，同时提供了潜在的节能优势。


<details>
  <summary>Details</summary>
Motivation: 随着地球观测数据量的激增（如NISAR任务预计两年内生成100PB数据），能效处理对可持续数据中心运营至关重要。SNN的事件驱动计算模型有望比传统方法节省30-100倍能源。

Method: 开发了针对相位解缠数据的脉冲编码方案，提出了利用相位解缠空间传播特性的SNN架构，并分析了计算复杂度和收敛性。

Result: SNN的时间动态特性自然地模拟了相位解缠的空间连续性约束，为大规模干涉SAR处理提供了可持续的补充方法。

Conclusion: 该研究开创了神经形态计算与SAR干涉测量结合的新方向，为现有算法提供了节能且高效的替代方案。

Abstract: We present the first theoretical framework for applying spiking neural
networks (SNNs) to synthetic aperture radar (SAR) interferometric phase
unwrapping. Despite extensive research in both domains, our comprehensive
literature review confirms that SNNs have never been applied to phase
unwrapping, representing a significant gap in current methodologies. As Earth
observation data volumes continue to grow exponentially (with missions like
NISAR expected to generate 100PB in two years) energy-efficient processing
becomes critical for sustainable data center operations. SNNs, with their
event-driven computation model, offer potential energy savings of 30-100x
compared to conventional approaches while maintaining comparable accuracy. We
develop spike encoding schemes specifically designed for wrapped phase data,
propose SNN architectures that leverage the spatial propagation nature of phase
unwrapping, and provide theoretical analysis of computational complexity and
convergence properties. Our framework demonstrates how the temporal dynamics
inherent in SNNs can naturally model the spatial continuity constraints
fundamental to phase unwrapping. This work opens a new research direction at
the intersection of neuromorphic computing and SAR interferometry, offering a
complementary approach to existing algorithms that could enable more
sustainable large-scale InSAR processing.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [18] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: 研究探讨了结合经典信号处理技术和深度学习架构的混合模型，用于低资源场景下的阿拉伯方言识别，其中MFCC + CNN表现最佳，准确率达91.2%。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言识别因语言多样性和标注数据稀缺而具有挑战性，尤其在资源受限环境中。

Method: 开发了两种混合模型：MFCC + CNN和DWT + RNN，并在Common Voice阿拉伯数据集上进行测试。

Result: MFCC + CNN模型表现最优（准确率91.2%），明显优于DWT + RNN（66.5%）。

Conclusion: 研究为低资源环境中的阿拉伯方言识别奠定了基础，建议未来采用更大标注数据集和自监督学习技术。

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [19] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
*Alexander Selivanov,Philip Müller,Özgün Turgut,Nil Stolt-Ansó,Daniel Rückert*

Main category: eess.IV

TL;DR: PTACL是一种多模态对比学习框架，通过整合CMR的时空信息增强ECG表示，提高了非侵入性心脏诊断的效果。


<details>
  <summary>Details</summary>
Motivation: ECG无法直接测量心室容积和射血分数等关键功能参数，而CMR虽为金标准但昂贵且难以普及，PTACL旨在填补这一差距。

Method: PTACL结合全局患者级和局部时间级对比损失，对齐ECG和CMR的表示，无需新增学习参数。

Result: 在UK Biobank的27,951名受试者数据上，PTACL在患者检索和预测CMR功能参数任务中优于基线方法。

Conclusion: PTACL展示了通过ECG提升心脏诊断的潜力，为非侵入性方法提供了新方向。

Abstract: An electrocardiogram (ECG) is a widely used, cost-effective tool for
detecting electrical abnormalities in the heart. However, it cannot directly
measure functional parameters, such as ventricular volumes and ejection
fraction, which are crucial for assessing cardiac function. Cardiac magnetic
resonance (CMR) is the gold standard for these measurements, providing detailed
structural and functional insights, but is expensive and less accessible. To
bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive
Learning), a multimodal contrastive learning framework that enhances ECG
representations by integrating spatio-temporal information from CMR. PTACL uses
global patient-level contrastive loss and local temporal-level contrastive
loss. The global loss aligns patient-level representations by pulling ECG and
CMR embeddings from the same patient closer together, while pushing apart
embeddings from different patients. Local loss enforces fine-grained temporal
alignment within each patient by contrasting encoded ECG segments with
corresponding encoded CMR frames. This approach enriches ECG representations
with diagnostic information beyond electrical activity and transfers more
insights between modalities than global alignment alone, all without
introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data
from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL
achieves better performance in two clinically relevant tasks: (1) retrieving
patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac
function parameters, such as ventricular volumes and ejection fraction. Our
results highlight the potential of PTACL to enhance non-invasive cardiac
diagnostics using ECG. The code is available at:
https://github.com/alsalivan/ecgcmr

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [20] [Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications](https://arxiv.org/abs/2506.21078)
*Tian Han,Shalanika Dayarathna,Rajitha Senanayake,Peter Smith,Aryan Kaushik,Alain Mourad,Richard A. Stirling-Gallacher,Jamie Evans*

Main category: cs.IT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Integrated sensing and communications (ISAC) is considered a key enabler to
support application scenarios such as the Internet-of-Things (IoT) in which
both communications and sensing play significant roles. Multi-carrier
waveforms, such as orthogonal frequency division multiplexing (OFDM), have been
considered as good candidates for ISAC due to their high communications data
rate and good time bandwidth property for sensing. Nevertheless, their high
peak-to-average-power-ratio (PAPR) values lead to either performance
degradation or an increase in system complexity. This can make OFDM unsuitable
for IoT applications with insufficient resources in terms of power, system
complexity, hardware size or cost. This article provides IoT-centric constant
modulus waveform designs that leverage the advantage of unit PAPR and thus are
more suitable in resource-limited scenarios. More specifically, several
single-carrier frequency and/or phase-modulated waveforms are considered. A
comprehensive discussion on their radar sensing and communications performance
is conducted based on performance metrics, including the radar ambiguity
function, the bandwidth property, the data rate, and the communications
receiver complexity.

</details>


### [21] [Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications](https://arxiv.org/abs/2506.21370)
*Jiuyu Liu,Yi Ma,Qihao Peng,Rahim Tafazolli*

Main category: cs.IT

TL;DR: 提出一种面向卫星通信的集群感知两阶段MIMO检测方法，通过利用用户地理集群特性提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 卫星MIMO信道中，同一地理集群的用户信道特性高度相关，传统迭代检测器收敛困难。

Method: 采用两阶段策略，先用小矩阵逆消除集群内干扰，再用预计算矩阵加速标准迭代检测器。

Result: 在完美信道信息下收敛速度提升12倍，信道误差下仍保持9倍加速。

Conclusion: 该方法对下一代卫星MIMO通信具有强鲁棒性和高效性。

Abstract: In this paper, a cluster-aware two-stage multiple-input multiple-output
(MIMO) detection method is proposed for direct-to-cell satellite
communications. The method achieves computational efficiency by exploiting a
distinctive property of satellite MIMO channels: users within the same
geographical cluster exhibit highly correlated channel characteristics due to
their physical proximity, which typically impedes convergence in conventional
iterative MIMO detectors. The proposed method implements a two-stage strategy
that first eliminates intra-cluster interference using computationally
efficient small matrix inversions, then utilizes these pre-computed matrices to
accelerate standard iterative MIMO detectors such as Gauss-Seidel (GS) and
symmetric successive over-relaxation (SSOR) for effective inter-cluster
interference cancellation. Computer simulations demonstrate that the proposed
method achieves more than 12 times faster convergence under perfect channel
state information. Even when accounting for channel estimation errors, the
method maintains 9 times faster convergence, demonstrating its robustness and
effectiveness for next-generation satellite MIMO communications.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [22] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
*Shadman Sobhan,Kazi Abrar Mahmud,Abduz Zami*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Current medical image analysis systems are typically task-specific, requiring
separate models for classification and segmentation, and lack the flexibility
to support user-defined workflows. To address these challenges, we introduce
MedPrompt, a unified framework that combines a few-shot prompted Large Language
Model (Llama-4-17B) for high-level task planning with a modular Convolutional
Neural Network (DeepFusionLab) for low-level image processing. The LLM
interprets user instructions and generates structured output to dynamically
route task-specific pretrained weights. This weight routing approach avoids
retraining the entire framework when adding new tasks-only task-specific
weights are required, enhancing scalability and deployment. We evaluated
MedPrompt across 19 public datasets, covering 12 tasks spanning 5 imaging
modalities. The system achieves a 97% end-to-end correctness in interpreting
and executing prompt-driven instructions, with an average inference latency of
2.5 seconds, making it suitable for near real-time applications. DeepFusionLab
achieves competitive segmentation accuracy (e.g., Dice 0.9856 on lungs) and
strong classification performance (F1 0.9744 on tuberculosis). Overall,
MedPrompt enables scalable, prompt-driven medical imaging by combining the
interpretability of LLMs with the efficiency of modular CNNs.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [23] [Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks](https://arxiv.org/abs/2506.20762)
*Shisheng Hu,Jie Gao,Xue Qin,Conghao Zhou,Xinyu Huang,Mushu Li,Mingcheng He,Xuemin Shen*

Main category: cs.NI

TL;DR: 提出了一种用于ISAC网络的漂移自适应切片资源管理方案，通过数字孪生和大-小时间尺度规划，提高了服务满意度和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 针对ISAC网络中移动设备和感知目标的非平稳空间分布问题，传统规划方法可能失效，需要一种自适应方案。

Method: 建立两个网络切片（感知和通信），大时间尺度规划分区感知区域并预留资源；利用数字孪生开发漂移自适应统计模型和仿真功能。

Result: 与基准方案相比，服务满意度提升18%，资源消耗降低13.1%。

Conclusion: 所提方案能有效应对分布漂移，优化资源管理。

Abstract: In this paper, we propose a novel drift-adaptive slicing-based resource
management scheme for cooperative integrated sensing and communication (ISAC)
networks. Particularly, we establish two network slices to provide sensing and
communication services, respectively. In the large-timescale planning for the
slices, we partition the sensing region of interest (RoI) of each mobile device
and reserve network resources accordingly, facilitating low-complexity
distance-based sensing target assignment in small timescales. To cope with the
non-stationary spatial distributions of mobile devices and sensing targets,
which can result in the drift in modeling the distributions and ineffective
planning decisions, we construct digital twins (DTs) of the slices. In each DT,
a drift-adaptive statistical model and an emulation function are developed for
the spatial distributions in the corresponding slice, which facilitates
closed-form decision-making and efficient validation of a planning decision,
respectively. Numerical results show that the proposed drift-adaptive
slicing-based resource management scheme can increase the service satisfaction
ratio by up to 18% and reduce resource consumption by up to 13.1% when compared
with benchmark schemes.

</details>
