<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [cs.RO](#cs.RO) [Total: 29]
- [eess.IV](#eess.IV) [Total: 1]
- [eess.SY](#eess.SY) [Total: 2]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.IT](#cs.IT) [Total: 2]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Synoptic Review of High-Frequency Oscillations as a Biomarker in Neurodegenerative Disease](https://arxiv.org/abs/2508.18712)
*Samin Yaser,Mahad Ali,Laura J. Brattain,Yang Jiang,VP Nguyen,Jing Xiang*

Main category: eess.SP

TL;DR: 该论文综述了高频振荡（HFOs）作为神经退行性疾病（如阿尔茨海默病）生物标志物的研究现状，分析了公开EEG数据集，并指出了方法学差异对研究的影响。


<details>
  <summary>Details</summary>
Motivation: 高频振荡（HFOs）被认为具有潜力成为非侵入性的早期诊断工具，尤其在阿尔茨海默病等领域。然而，数据集的方法学异质性限制了其应用。

Method: 通过对1,222篇文献的文献计量分析，以及对公开EEG数据集的系统比较，评估其技术适用性。

Result: 研究发现HFOs研究兴趣显著增长，但数据集在采样频率和记录范式上存在明显差异，影响跨研究验证。

Conclusion: 该综述为研究人员提供了利用公开数据推动HFOs作为跨疾病生物标志物的指导，并强调了方法学标准化的重要性。

Abstract: High Frequency Oscillations (HFOs), rapid bursts of brain activity above 80
Hz, have emerged as a highly specific biomarker for epileptogenic tissue.
Recent evidence suggests that HFOs are also present in Alzheimer's Disease
(AD), reflecting underlying network hyperexcitability and offering a promising,
noninvasive tool for early diagnosis and disease tracking. This synoptic review
provides a comprehensive analysis of publicly available electroencephalography
(EEG) datasets relevant to HFO research in neurodegenerative disorders. We
conducted a bibliometric analysis of 1,222 articles, revealing a significant
and growing research interest in HFOs, particularly within the last ten years.
We then systematically profile and compare key public datasets, evaluating
their participant cohorts, data acquisition parameters, and accessibility, with
a specific focus on their technical suitability for HFO analysis. Our
comparative synthesis highlights critical methodological heterogeneity across
datasets, particularly in sampling frequency and recording paradigms, which
poses challenges for cross-study validation, but also offers opportunities for
robustness testing. By consolidating disparate information, clarifying
nomenclature, and providing a detailed methodological framework, this review
serves as a guide for researchers aiming to leverage public data to advance the
role of HFOs as a cross-disease biomarker for AD and related conditions.

</details>


### [2] [SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus](https://arxiv.org/abs/2508.18735)
*Afan Ali,Irfanullah Khan*

Main category: eess.SP

TL;DR: 提出了一种结合区块链和联邦学习的动态信任评分调整机制DTSAM-EAC，以提升无人机非地面网络的安全性。


<details>
  <summary>Details</summary>
Motivation: 无人机非地面网络因其分布和动态特性易受攻击，需要安全、隐私保护且能源高效的安全机制。

Method: 整合Hyperledger Fabric区块链与联邦学习，通过动态信任评分和能源感知共识机制增强安全性和资源效率。

Result: 实验显示该框架在信任评分预测准确率和恶意无人机检测率上表现优异，优于现有方案。

Conclusion: DTSAM-EAC满足6G对分布式智能和可持续性的需求，是能源高效且可扩展的安全解决方案。

Abstract: Non-Terrestrial Networks (NTNs) based on Unmanned Aerial Vehicles (UAVs) as
base stations are extremely susceptible to security attacks due to their
distributed and dynamic nature, which makes them vulnerable to rogue nodes. In
this paper, a new Dynamic Trust Score Adjustment Mechanism with Energy-Aware
Consensus (DTSAM-EAC) is proposed to enhance security in UAV-based NTNs. The
proposed framework integrates a permissioned Hyperledger Fabric blockchain with
Federated Learning (FL) to support privacy-preserving trust evaluation. Trust
ratings are updated continuously through weighted aggregation of past trust,
present behavior, and energy contribution, thus making the system adaptive to
changing network conditions. An energy-aware consensus mechanism prioritizes
UAVs with greater available energy for block validation, ensuring efficient use
of resources under resource-constrained environments. FL aggregation with
trust-weighting further increases the resilience of the global trust model.
Simulation results verify the designed framework achieves 94\% trust score
prediction accuracy and 96\% rogue UAV detection rate while outperforming
centralized and static baselines of trust-based solutions on privacy, energy
efficiency, and reliability. It complies with 6G requirements in terms of
distributed intelligence and sustainability and is an energy-efficient and
scalable solution to secure NTNs.

</details>


### [3] [Near-Field Challenges in Ultra-Wideband ISAC: Beamforming Strategies and System Insights](https://arxiv.org/abs/2508.18810)
*Yonghwi Kim,Sang-Hyun Park,Siyun Yang,Kai-Kit Wong,Linglong Dai,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 论文探讨了6G网络中集成交感与通信（ISAC）的近场超宽带波束成形策略，解决了传统远场设计在近场传播和波束斜视中的局限，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着6G无线网络的发展，ISAC成为未来应用的核心，但近场传播效应和波束斜视对传统设计提出了挑战，需要新的解决方案。

Method: 研究提出了针对近场超宽带ISAC系统的波束成形策略，探索了模拟和数字领域的码本设计，并通过大规模系统级模拟验证。

Result: 结果表明，精心设计的波束成形可以在近场条件下平衡通信吞吐量和传感性能，实现可靠的覆盖和资源高效利用。

Conclusion: 论文指出了硬件、算法和系统集成方面的开放挑战，并展望了6G-ready ISAC网络的未来研究方向。

Abstract: The shift toward sixth-generation (6G) wireless networks places integrated
sensing and communications (ISAC) at the core of future applications such as
autonomous driving, extended reality, and smart manufacturing. However, the
combination of large antenna arrays and ultra-wide bandwidths brings near-field
propagation effects and beam squint to the forefront, fundamentally challenging
traditional far-field designs. True time delay units (TTDs) offer a potential
solution, but their cost and hardware complexity limit scalability. In this
article, we present practical beamforming strategies for near-field
ultra-wideband ISAC systems. We explore codebook designs across analog and
digital domains that mitigate beam squint, ensure reliable user coverage, and
enhance sensing accuracy. We further validate these approaches through
large-scale system-level simulations, including 3D map-based evaluations that
reflect real-world urban environments. Our results demonstrate how carefully
designed beamforming can balance communication throughput with sensing
performance, achieving reliable coverage and efficient resource use even under
severe near-field conditions. We conclude by highlighting open challenges in
hardware, algorithms, and system integration, pointing toward research
directions that will shape the deployment of 6G-ready ISAC networks.

</details>


### [4] [DIFNet: Decentralized Information Filtering Fusion Neural Network with Unknown Correlation in Sensor Measurement Noises](https://arxiv.org/abs/2508.18854)
*Ruifeng Dong,Ming Wang,Ning Liu,Tong Guo,Jiayi Kang,Xiaojing Shen,Yao Mao*

Main category: eess.SP

TL;DR: 提出了一种名为DIFNet的数据驱动方法，用于解决分散传感器网络中未知测量噪声相关性的问题，提升了融合性能。


<details>
  <summary>Details</summary>
Motivation: 在分散传感器网络中，测量噪声的未知相关性会影响融合精度，需要一种方法来学习和适应这些未知相关性。

Method: 通过结构化观测模型将全局状态估计问题分解为局部子问题，并使用DIFNet学习未知噪声相关性。

Result: 数值模拟显示，DIFNet在离散时间非线性状态空间模型中表现优于传统滤波方法，并在复杂场景中表现出鲁棒性。

Conclusion: DIFNet为分散传感器网络的噪声相关性学习提供了一种有效的数据驱动解决方案。

Abstract: In recent years, decentralized sensor networks have garnered significant
attention in the field of state estimation owing to enhanced robustness,
scalability, and fault tolerance. Optimal fusion performance can be achieved
under fully connected communication and known noise correlation structures. To
mitigate communication overhead, the global state estimation problem is
decomposed into local subproblems through structured observation model. This
ensures that even when the communication network is not fully connected, each
sensor can achieve locally optimal estimates of its observable state
components. To address the degradation of fusion accuracy induced by unknown
correlations in measurement noise, this paper proposes a data-driven method,
termed Decentralized Information Filter Neural Network (DIFNet), to learn
unknown noise correlations in data for discrete-time nonlinear state space
models with cross-correlated measurement noises. Numerical simulations
demonstrate that DIFNet achieves superior fusion performance compared to
conventional filtering methods and exhibits robust characteristics in more
complex scenarios, such as the presence of time-varying noise. The source code
used in our numerical experiment can be found online at
https://wisdom-estimation.github.io/DIFNet_Demonstrate/.

</details>


### [5] [Beyond-Diagonal RIS: Adversarial Channels and Optimality of Low-Complexity Architectures](https://arxiv.org/abs/2508.19000)
*Atso Iivanainen,Robin Rajamäki,Visa Koivunen*

Main category: eess.SP

TL;DR: 本文研究了‘对角线外可重构智能表面’(BD-RIS)的最坏情况性能，揭示了某些低复杂度架构在对抗性信道下的性能不足。


<details>
  <summary>Details</summary>
Motivation: 传统的RIS主要优化相位响应，而BD-RIS进一步优化幅度响应并通过可调耦合提升性能。然而，其最坏情况性能尚未充分研究。

Method: 分析两种低复杂度BD-RIS架构（组连接和树连接）在对抗性信道下的性能，推导其对抗性信道集。

Result: 对抗性信道会导致性能显著下降，并揭示两种架构之间的新联系。数值结果验证了分析。

Conclusion: 研究为设计鲁棒BD-RIS提供了方向，以应对对抗性传播条件和恶意攻击。

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) have recently
gained attention as an enhancement to conventional RISs. BD-RISs allow
optimizing not only the phase, but also the amplitude responses of their
discrete surface elements by introducing adjustable inter-element couplings.
Various BD-RIS architectures have been proposed to optimally trade off between
average performance and complexity of the architecture. However, little
attention has been paid to worst-case performance. This paper characterizes
novel sets of adversarial channels for which certain low-complexity BD-RIS
architectures have suboptimal performance in terms of received signal power at
an intended communications user. Specifically, we consider two recent BD-RIS
models: the so-called group-connected and tree-connected architecture. The
derived adversarial channel sets reveal new surprising connections between the
two architectures. We validate our analytical results numerically,
demonstrating that adversarial channels can cause a significant performance
loss. Our results pave the way towards efficient BD-RIS designs that are robust
to adversarial propagation conditions and malicious attacks.

</details>


### [6] [mmKey: Channel-Aware Beam Shaping for Reliable Key Generation in mmWave Wireless Networks](https://arxiv.org/abs/2508.19010)
*Poorya Mollahosseini,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: mmKey是一个新的物理层密钥生成（PLKG）框架，用于解决毫米波（mmWave）无线网络中因信道稀疏性、相位噪声和路径损耗导致的密钥生成安全问题，通过多天线注入随机性，并利用遗传算法优化波束形成。


<details>
  <summary>Details</summary>
Motivation: 毫米波无线网络中，由于信道稀疏、相位噪声高和路径损耗大，传统PLKG方法难以满足密钥生成的安全性和鲁棒性需求。

Method: mmKey利用多天线在毫米波通信中注入随机性，采用遗传算法逐步优化初始权重向量，抑制直视路径（LOS）并考虑信道稀疏性和信噪比（SNR）。

Result: 实验显示mmKey在保密性方面比随机波束形成和零波束形成分别提高了39.4%和34.0%。

Conclusion: mmKey在毫米波网络中有效平衡了密钥生成的安全性和鲁棒性，优于传统方法。

Abstract: Physical-layer key generation (PLKG) has emerged as a promising technique to
secure next-generation wireless networks by exploiting the inherent properties
of the wireless channel. However, PLKG faces fundamental challenges in the
millimeter wave (mmWave) regime due to channel sparsity, higher phase noise,
and higher path loss, which undermine both the randomness and reciprocity
required for secure key generation. In this paper, we present mmKey, a novel
PLKG framework that capitalizes on the availability of multiple antennas at
mmWave wireless nodes to inject randomness into an otherwise quasi-static
wireless channel. Different from prior works that sacrifice either the secrecy
of the key generation or the robustness, mmKey balances these two requirements.
In particular, mmKey leverages a genetic algorithm to gradually evolve the
initial weight vector population toward configurations that suppress the LOS
component while taking into account the channel conditions, specifically, the
sparsity and the signal-to-noise ratio (SNR). Extensive simulations show that
mmKey improves the secrecy gap by an average of 39.4% over random beamforming
and 34.0% over null beamforming, outperforming conventional schemes.

</details>


### [7] [Fast Vortex Beam Alignment for OAM Mode Multiplexing in LOS MIMO Networks](https://arxiv.org/abs/2508.19034)
*Poorya Mollahosseini,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: OrthoVortex 是一种新型框架，用于估计和校正基于轨道角动量（OAM）通信系统中的节点错位，以恢复模态正交性，从而提升数据复用增益。通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: OAM 通信系统在视距（LOS）场景中具有高容量复用能力，但对节点错位敏感，需要有效的错位估计和校正方法。

Method: 提出了 OrthoVortex 框架，通过交叉模态相位作为独特签名来识别错位角度，并应用相位校正恢复模态正交性。该方法为少样本对齐技术，适合实际应用。

Result: 在 120 GHz 下的模拟和实测中，OrthoVortex 实现了快速精确的错位估计（平均绝对误差为方位角 0.69° 和仰角 2.54°），显著抑制了模态间干扰。

Conclusion: OrthoVortex 能够高效校正节点错位，提升信号干扰比和链路容量，为 OAM 通信系统的实际应用提供了可行解决方案。

Abstract: Orbital Angular Momentum (OAM)-based communication systems offer
high-capacity multiplexing in line-of-sight (LOS) scenarios; yet, their
performance is sensitive to nodal misalignment, which disrupts modal
orthogonality, hindering the data multiplexing gain. To tackle this challenge,
we present OrthoVortex, a novel framework that estimates the misalignment
angles and applies the appropriate phase correction to restore orthogonality
between modes. Unlike purely theoretical prior efforts that rely on impractical
fully digital arrays or exhaustive beam scans, OrthoVortex introduces and
leverages the cross-modal phase, as a unique signature for identifying the
misalignment angles. OrthoVortex is a few-shot alignment technique, making it
feasible for real-world implementations. Our key contributions include: (i) a
robust angle estimation and phase correction framework based on the physics of
OAM propagation that estimates the misalignment and restores modal
orthogonality, (ii) the first-ever experimental validation of OAM beam
alignment with RF transceivers, and (iii) a comprehensive analysis of practical
constraints, including the impact of antenna count and bandwidth. Simulations
and over-the-air measurements using low-cost, rapidly prototyped metasurfaces
operating at 120 GHz demonstrate that OrthoVortex achieves fast and precise
misalignment estimation (mean absolute error of $0.69^{\circ}$ for azimuth and
$2.54^{\circ}$ for elevation angle). Further, OrthoVortex can mitigate the
inter-modal interference, yielding more than 12 dB increase in
signal-to-interference ratio and more than 4.5-fold improvement in link
capacity.

</details>


### [8] [Space-Time Coded RIS-Assisted Wireless Systems with Practical Reflection Models: Error Rate Analysis and Negative Moment-Based Optimization with Saddle Point Approximation](https://arxiv.org/abs/2508.19129)
*Tayfun Yilmaz,Haci Ilhan,Ibrahim Hokelek*

Main category: eess.SP

TL;DR: 该论文提出了一个理论框架，用于分析RIS辅助多天线系统在实用反射模型下的符号错误率（SER），通过Gramian结构和Saddle Point近似方法，适用于任意RIS规模和相位配置。


<details>
  <summary>Details</summary>
Motivation: 提升复杂环境中无线通信性能，并研究在实际硬件约束下RIS辅助系统的精确错误分析。

Method: 利用Gramian结构推导小规模RIS的精确MGF表达式，并通过Saddle Point近似处理大规模RIS的分布问题。

Result: 提出了统一的SER表达式，适用于不同RIS规模和配置，仿真验证了其准确性。

Conclusion: 所提框架为RIS辅助多天线系统提供了有效的SER分析工具，支持未来多天线系统设计。

Abstract: RIS-assisted communication has recently attracted significant attention for
enhancing wireless performance in challenging environments, making accurate
error analysis under practical hardware constraints crucial for future
multi-antenna systems. This paper presents a theoretical framework for SER
analysis of RIS-assisted multiple antenna systems employing OSTBC under
practical reflection models with amplitude-dependent and quantized phase
responses. By exploiting the Gramian structure of the cascaded channel f, we
derive exact MGF expressions of the nonzero eigenvalue of f'f for small RIS
sizes. For large-scale RIS deployments, where closed-form analysis becomes
intractable, we employ Saddle Point Approximation to approximate the eigenvalue
distribution. Using these results, we derive unified SER expressions using
exact and SPA-based MGF formulations, applicable to arbitrary RIS sizes, phase
configuration, and both identical and non-identical amplitude responses.
Extensive Monte Carlo simulations confirm the accuracy of the proposed SER
expressions, demonstrating very close agreement for all configurations.

</details>


### [9] [Instantaneous Polarimetry with Zak-OTFS](https://arxiv.org/abs/2508.19185)
*Nishant Mehrotra,Sandesh Rao Mattu,Robert Calderbank*

Main category: eess.SP

TL;DR: 该论文提出了一种利用Zak-OTFS调制实现瞬时偏振测量的新方法，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 偏振测量对增强无线通信和雷达系统性能至关重要，现有方法的计算复杂度较高，需要改进。

Method: 通过同时传输Zak-OTFS载波波形和与其相互无偏的扩展载波波形，接收端可以从单个帧中估计散射环境的全偏振响应。

Result: 数值模拟显示，该方法在偏振目标检测和参数估计上表现出色，性能和计算复杂度优于基线方法。

Conclusion: 提出的方法实现了计算复杂度仅为时间带宽乘积亚线性的瞬时偏振测量，性能和效率均有显著提升。

Abstract: Polarimetry, which is the ability to measure the scattering response of the
environment across orthogonal polarizations, is fundamental to enhancing
wireless communication and radar system performance. In this paper, we utilize
the Zak-OTFS modulation to enable instantaneous polarimetry within a single
transmission frame. We transmit a Zak-OTFS carrier waveform and a spread
carrier waveform mutually unbiased to it simultaneously over orthogonal
polarizations. The mutual unbiasedness of the two waveforms enables the
receiver to estimate the full polarimetric response of the scattering
environment from a single received frame. Unlike existing methods for
instantaneous polarimetry with computational complexity quadratic in the
time-bandwidth product, the proposed method enables instantaneous polarimetry
at complexity that is only sublinear in the time-bandwidth product. Via
numerical simulations, we show ideal polarimetric target detection and
parameter estimation results with the proposed method, with improvements in
performance and computational complexity over comparable baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [10] [Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](https://arxiv.org/abs/2508.18397)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 该论文研究了离线强化学习中数据不平衡问题，通过比较六种数据筛选方法，提升了自动驾驶规划策略的安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 大规模真实驾驶数据中存在数据不平衡问题，导致策略脆弱且不安全，需通过数据筛选方法优化学习。

Method: 采用三种类型（启发式、不确定性和行为基）的六种数据筛选方法，训练七种CQL智能体，并在Waymax模拟器中评估。

Result: 所有数据筛选方法均优于基线，基于模型不确定性的方法将碰撞率从16.0%降至5.5%，且时步级与场景级权重各有优势。

Conclusion: 智能非均匀采样是构建安全可靠自动驾驶的关键，论文为离线RL数据筛选提供了全面框架。

Abstract: Offline Reinforcement Learning (RL) presents a promising paradigm for
training autonomous vehicle (AV) planning policies from large-scale, real-world
driving logs. However, the extreme data imbalance in these logs, where mundane
scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe
policies when using standard uniform data sampling. In this work, we address
this challenge through a systematic, large-scale comparative study of data
curation strategies designed to focus the learning process on information-rich
samples. We investigate six distinct criticality weighting schemes which are
categorized into three families: heuristic-based, uncertainty-based, and
behavior-based. These are evaluated at two temporal scales, the individual
timestep and the complete scenario. We train seven goal-conditioned
Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based
architecture and evaluate them in the high-fidelity Waymax simulator. Our
results demonstrate that all data curation methods significantly outperform the
baseline. Notably, data-driven curation using model uncertainty as a signal
achieves the most significant safety improvements, reducing the collision rate
by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear
trade-off where timestep-level weighting excels at reactive safety while
scenario-level weighting improves long-horizon planning. Our work provides a
comprehensive framework for data curation in Offline RL and underscores that
intelligent, non-uniform sampling is a critical component for building safe and
reliable autonomous agents.

</details>


### [11] [Maintenance automation: methods for robotics manipulation planning and execution](https://arxiv.org/abs/2508.18399)
*Christian Friedrich,Ralf Gulde,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 这篇论文提出了一种完整的机器人系统，用于自动化维护任务，包括在环境不确定性下的拆卸和组装操作。系统基于规划方法（使用CAD和RGBD数据），并将符号计划转换为可执行指令。通过真实应用进行实验评估，展示了理论成果向实际机器人解决方案的初步转化。


<details>
  <summary>Details</summary>
Motivation: 自动化复杂任务需要解决规划、控制和执行问题。本文旨在开发一种机器人系统，能够在环境不确定性下完成维护任务，推动理论成果的实际应用。

Method: 系统结合CAD和RGBD数据进行规划，提出一种方法将符号计划转化为可执行的机器人指令。

Result: 实验评估表明，系统能够在真实应用中有效完成自动化维护任务，包括拆卸和组装操作。

Conclusion: 该研究展示了从理论到实践的初步成功，为机器人自动化维护提供了可行方案。

Abstract: Automating complex tasks using robotic systems requires skills for planning,
control and execution. This paper proposes a complete robotic system for
maintenance automation, which can automate disassembly and assembly operations
under environmental uncertainties (e.g. deviations between prior plan
information). The cognition of the robotic system is based on a planning
approach (using CAD and RGBD data) and includes a method to interpret a
symbolic plan and transform it to a set of executable robot instructions. The
complete system is experimentally evaluated using real-world applications. This
work shows the first step to transfer these theoretical results into a
practical robotic solution.

</details>


### [12] [Efficient task and path planning for maintenance automation using a robot system](https://arxiv.org/abs/2508.18400)
*Christian Friedrich,Akos Csiszar,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 智能自动化解决方案的研发是未来工厂的关键。本文提出了一种结合离线CAD数据和在线RGBD视觉系统的方法，用于维护任务自动化。


<details>
  <summary>Details</summary>
Motivation: 利用自主机器人系统进行维护任务自动化是一个具有挑战性的目标，需要低计算复杂度的算法和应对环境不确定性的能力。

Method: 结合离线CAD数据和在线RGBD视觉系统，通过概率滤波补偿不确定性；利用符号描述和采样方法计算拆卸空间；采用全局路径规划算法并自适应调整搜索步长以减少规划时间。

Result: 所有方法均经过实验验证，展示了其在实际应用中的有效性。

Conclusion: 本文提出的方法为维护任务自动化提供了有效的解决方案，尤其适用于不确定环境中的任务规划与路径规划。

Abstract: The research and development of intelligent automation solutions is a
ground-breaking point for the factory of the future. A promising and
challenging mission is the use of autonomous robot systems to automate tasks in
the field of maintenance. For this purpose, the robot system must be able to
plan autonomously the different manipulation tasks and the corresponding paths.
Basic requirements are the development of algorithms with a low computational
complexity and the possibility to deal with environmental uncertainties. In
this work, an approach is presented, which is especially suited to solve the
problem of maintenance automation. For this purpose, offline data from CAD is
combined with online data from an RGBD vision system via a probabilistic
filter, to compensate uncertainties from offline data. For planning the
different tasks, a method is explained, which use a symbolic description,
founded on a novel sampling-based method to compute the disassembly space. For
path planning we use global state-of-the art algorithms with a method that
allows the adaption of the exploration stepsize in order to reduce the planning
time. Every method is experimentally validated and discussed.

</details>


### [13] [PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing](https://arxiv.org/abs/2508.18443)
*Ruohan Zhang,Uksang Yoo,Yichen Li,Arpit Argawal,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 提出了一种新型视觉驱动的软机器人传感方法PneuGelSight，并结合仿真优化其性能，实现从仿真到现实的零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 软气动机器人因其柔性和灵活性在工业和人机交互中广泛应用，但其在现实场景中的部署需要高级的触觉反馈和本体感知传感技术。

Method: 设计了PneuGelSight软气动机械手，利用嵌入式摄像头实现高分辨率的本体感知和触觉传感，并提出了一套完整的仿真管道优化传感器性能。

Result: PneuGelSight及其仿真管道提供了一种易于实现且鲁棒的软机器人传感方法，提升了软机器人的感知能力。

Conclusion: 该研究为开发具有更高级感官能力的软机器人铺平了道路。

Abstract: Soft pneumatic robot manipulators are popular in industrial and
human-interactive applications due to their compliance and flexibility.
However, deploying them in real-world scenarios requires advanced sensing for
tactile feedback and proprioception. Our work presents a novel vision-based
approach for sensorizing soft robots. We demonstrate our approach on
PneuGelSight, a pioneering pneumatic manipulator featuring high-resolution
proprioception and tactile sensing via an embedded camera. To optimize the
sensor's performance, we introduce a comprehensive pipeline that accurately
simulates its optical and dynamic properties, facilitating a zero-shot
knowledge transition from simulation to real-world applications. PneuGelSight
and our sim-to-real pipeline provide a novel, easily implementable, and robust
sensing methodology for soft robots, paving the way for the development of more
advanced soft robots with enhanced sensory capabilities.

</details>


### [14] [Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models](https://arxiv.org/abs/2508.18460)
*Tianze Liu,Md Abu Bakr Siddique,Hongyu An*

Main category: cs.RO

TL;DR: 论文提出通过模拟动物的联想学习能力，提升智能机器人在动态环境中的自主适应能力，以减少对大数据和高功耗的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统AI方法依赖大数据和高功耗，限制了在资源受限场景（如行星探索）中的应用。模拟动物的联想学习能力可以解决这些问题。

Method: 研究通过神经形态机器人模拟啮齿类动物在开放迷宫环境中的联想学习机制，结合空间细胞（如位置细胞和网格细胞）的模型。

Result: 目标是通过在线联想学习实现实时空间任务处理，缩小生物空间认知与机器人技术之间的差距。

Conclusion: 模拟生物联想学习机制为神经形态机器人在动态环境中实现自主适应提供了新方向。

Abstract: Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable
prowess across various cognitive tasks using extensive training data. However,
the reliance on large datasets and neural networks presents challenges such as
highpower consumption and limited adaptability, particularly in
SWaP-constrained applications like planetary exploration. To address these
issues, we propose enhancing the autonomous capabilities of intelligent robots
by emulating the associative learning observed in animals. Associative learning
enables animals to adapt to their environment by memorizing concurrent events.
By replicating this mechanism, neuromorphic robots can navigate dynamic
environments autonomously, learning from interactions to optimize performance.
This paper explores the emulation of associative learning in rodents using
neuromorphic robots within open-field maze environments, leveraging insights
from spatial cells such as place and grid cells. By integrating these models,
we aim to enable online associative learning for spatial tasks in real-time
scenarios, bridging the gap between biological spatial cognition and robotics
for advancements in autonomous systems.

</details>


### [15] [SignLoc: Robust Localization using Navigation Signs and Public Maps](https://arxiv.org/abs/2508.18606)
*Nicky Zimmerman,Joel Loo,Ayush Agrawal,David Hsu*

Main category: cs.RO

TL;DR: SignLoc是一种利用导航标志在公开地图（如平面图和OpenStreetMap）上进行机器人全局定位的方法，无需预先的传感器地图。


<details>
  <summary>Details</summary>
Motivation: 导航标志和地图在人类环境中广泛使用，但机器人系统很少利用这些资源进行定位。

Method: SignLoc从输入地图中提取导航图，使用概率观察模型将检测到的标志与图匹配，实现基于蒙特卡洛框架的语义定位。

Result: 在校园、购物中心和医院等多种环境中测试表明，SignLoc仅需观测一到两个标志即可可靠定位机器人。

Conclusion: SignLoc提供了一种高效利用公开地图资源实现机器人定位的解决方案。

Abstract: Navigation signs and maps, such as floor plans and street maps, are widely
available and serve as ubiquitous aids for way-finding in human environments.
Yet, they are rarely used by robot systems. This paper presents SignLoc, a
global localization method that leverages navigation signs to localize the
robot on publicly available maps -- specifically floor plans and OpenStreetMap
(OSM) graphs -- without prior sensor-based mapping. SignLoc first extracts a
navigation graph from the input map. It then employs a probabilistic
observation model to match directional and locational cues from the detected
signs to the graph, enabling robust topo-semantic localization within a Monte
Carlo framework. We evaluated SignLoc in diverse large-scale environments: part
of a university campus, a shopping mall, and a hospital complex. Experimental
results show that SignLoc reliably localizes the robot after observing only one
to two signs.

</details>


### [16] [Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning](https://arxiv.org/abs/2508.18627)
*Ziyuan Jiao,Yida Niu,Zeyu Zhang,Yangyang Wu,Yao Su,Yixin Zhu,Hangxin Liu,Song-Chun Zhu*

Main category: cs.RO

TL;DR: 提出了一种新的Sequential Mobile Manipulation Planning (SMMP)框架，通过将环境结构抽象为运动学模型，并结合机器人运动学，构建了统一的Augmented Configuration Space (A-Space)，显著提高了长期多步骤移动操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长期多步骤移动操作任务时，常因未统一导航和操作的约束而导致效率低下或失败。本文旨在通过统一的A-Space解决这一问题。

Method: 采用三层次规划框架：任务规划器生成符号动作序列，优化运动规划器计算连续轨迹，中间阶段选择能确保长期可行性的目标。

Result: 仿真显示A-Space规划比基线方法任务成功率提高84.6%；现实实验中成功应对7类物体和17种场景，完成最多14步的长期任务。

Conclusion: 将场景运动学建模为规划实体，而非任务特定约束，是一种可扩展且通用性强的复杂机器人操作方法。

Abstract: We present a Sequential Mobile Manipulation Planning (SMMP) framework that
can solve long-horizon multi-step mobile manipulation tasks with coordinated
whole-body motion, even when interacting with articulated objects. By
abstracting environmental structures as kinematic models and integrating them
with the robot's kinematics, we construct an Augmented Configuration Apace
(A-Space) that unifies the previously separate task constraints for navigation
and manipulation, while accounting for the joint reachability of the robot
base, arm, and manipulated objects. This integration facilitates efficient
planning within a tri-level framework: a task planner generates symbolic action
sequences to model the evolution of A-Space, an optimization-based motion
planner computes continuous trajectories within A-Space to achieve desired
configurations for both the robot and scene elements, and an intermediate plan
refinement stage selects action goals that ensure long-horizon feasibility. Our
simulation studies first confirm that planning in A-Space achieves an 84.6\%
higher task success rate compared to baseline methods. Validation on real
robotic systems demonstrates fluid mobile manipulation involving (i) seven
types of rigid and articulated objects across 17 distinct contexts, and (ii)
long-horizon tasks of up to 14 sequential steps. Our results highlight the
significance of modeling scene kinematics into planning entities, rather than
encoding task-specific constraints, offering a scalable and generalizable
approach to complex robotic manipulation.

</details>


### [17] [Engineering Automotive Digital Twins on Standardized Architectures: A Case Study](https://arxiv.org/abs/2508.18662)
*Stefan Ramdhan,Winnie Trandinh,Istvan David,Vera Pantelic,Mark Lawford*

Main category: cs.RO

TL;DR: 本文研究了ISO 23247参考架构在开发汽车数字孪生（DT）中的适用性，并通过案例研究总结了其优缺点和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 汽车行业对数字孪生技术的需求增长，但缺乏相关架构指南，ISO 23247是少数可行的起点，因此研究其适用性至关重要。

Method: 通过开发一个1/10比例自动驾驶车辆的自适应巡航控制数字孪生案例，分析ISO 23247架构的适用性。

Result: 研究揭示了ISO 23247架构的优点和局限性，为研究人员、从业者和标准开发者提供了未来发展方向。

Conclusion: ISO 23247架构在汽车数字孪生开发中具有潜力，但仍需改进以满足行业需求。

Abstract: Digital twin (DT) technology has become of interest in the automotive
industry. There is a growing need for smarter services that utilize the unique
capabilities of DTs, ranging from computer-aided remote control to cloud-based
fleet coordination. Developing such services starts with the software
architecture. However, the scarcity of DT architectural guidelines poses a
challenge for engineering automotive DTs. Currently, the only DT architectural
standard is the one defined in ISO 23247. Though not developed for automotive
systems, it is one of the few feasible starting points for automotive DTs. In
this work, we investigate the suitability of the ISO 23247 reference
architecture for developing automotive DTs. Through the case study of
developing an Adaptive Cruise Control DT for a 1/10\textsuperscript{th}-scale
autonomous vehicle, we identify some strengths and limitations of the reference
architecture and begin distilling future directions for researchers,
practitioners, and standard developers.

</details>


### [18] [Deep Sensorimotor Control by Imitating Predictive Models of Human Motion](https://arxiv.org/abs/2508.18691)
*Himanshu Gaurav Singh,Pieter Abbeel,Jitendra Malik,Antonio Loquercio*

Main category: cs.RO

TL;DR: 提出一种利用人类动作预测模型训练机器人传感器运动策略的新方法，无需梯度重定向或对抗损失，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 随着机器人与人类的交互能力差距缩小，利用人类与环境交互数据集训练机器人成为可能。

Method: 通过模仿人类动作预测模型，使用强化学习训练机器人策略，直接跟踪预测结果并优化稀疏任务奖励。

Result: 该方法在多种机器人及任务中表现优异，超越现有基线，且无需设计复杂的密集奖励。

Conclusion: 提出的技术有效利用了人类数据集，为机器人学习提供了新方向。

Abstract: As the embodiment gap between a robot and a human narrows, new opportunities
arise to leverage datasets of humans interacting with their surroundings for
robot learning. We propose a novel technique for training sensorimotor policies
with reinforcement learning by imitating predictive models of human motions.
Our key insight is that the motion of keypoints on human-inspired robot
end-effectors closely mirrors the motion of corresponding human body keypoints.
This enables us to use a model trained to predict future motion on human data
\emph{zero-shot} on robot data. We train sensorimotor policies to track the
predictions of such a model, conditioned on a history of past robot states,
while optimizing a relatively sparse task reward. This approach entirely
bypasses gradient-based kinematic retargeting and adversarial losses, which
limit existing methods from fully leveraging the scale and diversity of modern
human-scene interaction datasets. Empirically, we find that our approach can
work across robots and tasks, outperforming existing baselines by a large
margin. In addition, we find that tracking a human motion model can substitute
for carefully designed dense rewards and curricula in manipulation tasks. Code,
data and qualitative results available at
https://jirl-upenn.github.io/track_reward/.

</details>


### [19] [AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot](https://arxiv.org/abs/2508.18694)
*Jaehwan Jeong,Tuan-Anh Vu,Mohammad Jony,Shahab Ahmad,Md. Mukhlesur Rahman,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriChrono是一个新型机器人数据收集平台和多模态数据集，旨在捕捉真实农业环境的动态条件，弥补现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多为静态或受控环境下的采集，缺乏传感器多样性和时间跨度，无法反映真实农田的动态变化，导致模型在真实场景中鲁棒性和泛化能力不足。

Method: 通过集成多种传感器（RGB、深度、LiDAR和IMU）并实现远程时间同步采集，AgriChrono平台支持长期、高效、可重复的数据收集。

Result: 在AgriChrono数据集上对多种先进的3D重建模型进行基准测试，证实了其在动态环境下的挑战性，并展示了该数据集对提升模型泛化能力的研究价值。

Conclusion: AgriChrono填补了现有数据集的空白，为动态农业环境下的模型研究提供了重要资源，代码和数据集已公开。

Abstract: Existing datasets for precision agriculture have primarily been collected in
static or controlled environments such as indoor labs or greenhouses, often
with limited sensor diversity and restricted temporal span. These conditions
fail to reflect the dynamic nature of real farmland, including illumination
changes, crop growth variation, and natural disturbances. As a result, models
trained on such data often lack robustness and generalization when applied to
real-world field scenarios. In this paper, we present AgriChrono, a novel
robotic data collection platform and multi-modal dataset designed to capture
the dynamic conditions of real-world agricultural environments. Our platform
integrates multiple sensors and enables remote, time-synchronized acquisition
of RGB, Depth, LiDAR, and IMU data, supporting efficient and repeatable
long-term data collection across varying illumination and crop growth stages.
We benchmark a range of state-of-the-art 3D reconstruction models on the
AgriChrono dataset, highlighting the difficulty of reconstruction in real-world
field environments and demonstrating its value as a research asset for
advancing model generalization under dynamic conditions. The code and dataset
are publicly available at: https://github.com/StructuresComp/agri-chrono

</details>


### [20] [Enhancing Video-Based Robot Failure Detection Using Task Knowledge](https://arxiv.org/abs/2508.18705)
*Santosh Thoduka,Sebastian Houben,Juergen Gall,Paul G. Plöger*

Main category: cs.RO

TL;DR: 提出了一种基于视频的机器人任务失败检测方法，利用时空知识（机器人动作和任务相关物体）提升检测效果，并通过数据增强进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 机器人任务执行中的失败检测对安全操作和恢复策略至关重要，但现有方法在多种现实场景中表现不佳。

Method: 利用机器人动作和任务相关物体的时空信息进行失败检测，并采用可变帧率的数据增强方法优化性能。

Result: 在ARMBench数据集上，F1分数从77.9提升到80.0，测试时增强后进一步增至81.4。

Conclusion: 时空信息对失败检测至关重要，未来可进一步探索合适的启发式方法。

Abstract: Robust robotic task execution hinges on the reliable detection of execution
failures in order to trigger safe operation modes, recovery strategies, or task
replanning. However, many failure detection methods struggle to provide
meaningful performance when applied to a variety of real-world scenarios. In
this paper, we propose a video-based failure detection approach that uses
spatio-temporal knowledge in the form of the actions the robot performs and
task-relevant objects within the field of view. Both pieces of information are
available in most robotic scenarios and can thus be readily obtained. We
demonstrate the effectiveness of our approach on three datasets that we amend,
in part, with additional annotations of the aforementioned task-relevant
knowledge. In light of the results, we also propose a data augmentation method
that improves performance by applying variable frame rates to different parts
of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the
ARMBench dataset without additional computational expense and an additional
increase to 81.4 with test-time augmentation. The results emphasize the
importance of spatio-temporal information during failure detection and suggest
further investigation of suitable heuristics in future implementations. Code
and annotations are available.

</details>


### [21] [HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation](https://arxiv.org/abs/2508.18802)
*Li Sun,Jiefeng Wu,Feng Chen,Ruizhe Liu,Yanchao Yang*

Main category: cs.RO

TL;DR: 论文提出HyperTASR框架，通过超网络动态调整场景表示以适应任务目标和执行阶段，提升机器人操作的策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前方法使用任务无关的表示提取，无法模拟人类认知的动态适应能力，因此需要开发任务感知的场景表示方法。

Method: HyperTASR利用超网络根据任务目标和执行状态动态生成表示变换参数，保持与现有策略学习框架的兼容性。

Result: 实验表明，HyperTASR显著提升了性能，并通过消融研究和注意力可视化验证了其对任务相关信息的动态选择能力。

Conclusion: HyperTASR成功模拟了人类自适应感知，为机器人操作的场景表示提供了高效解决方案。

Abstract: Effective policy learning for robotic manipulation requires scene
representations that selectively capture task-relevant environmental features.
Current approaches typically employ task-agnostic representation extraction,
failing to emulate the dynamic perceptual adaptation observed in human
cognition. We present HyperTASR, a hypernetwork-driven framework that modulates
scene representations based on both task objectives and the execution phase.
Our architecture dynamically generates representation transformation parameters
conditioned on task specifications and progression state, enabling
representations to evolve contextually throughout task execution. This approach
maintains architectural compatibility with existing policy learning frameworks
while fundamentally reconfiguring how visual features are processed. Unlike
methods that simply concatenate or fuse task embeddings with task-agnostic
representations, HyperTASR establishes computational separation between
task-contextual and state-dependent processing paths, enhancing learning
efficiency and representational quality. Comprehensive evaluations in both
simulation and real-world environments demonstrate substantial performance
improvements across different representation paradigms. Through ablation
studies and attention visualization, we confirm that our approach selectively
prioritizes task-relevant scene information, closely mirroring human adaptive
perception during manipulation tasks. The project website is at
\href{https://lisunphil.github.io/HyperTASR_projectpage/}{lisunphil.github.io/HyperTASR\_projectpage}.

</details>


### [22] [Learning Real-World Acrobatic Flight from Human Preferences](https://arxiv.org/abs/2508.18817)
*Colin Merk,Ismail Geles,Jiaxu Xing,Angel Romero,Giorgia Ramponi,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文研究了基于偏好的强化学习（PbRL）在敏捷无人机控制中的应用，提出了一种名为Reward Ensemble under Confidence（REC）的改进方法，提升了偏好建模和学习稳定性。实验结果表明，该方法在真实无人机上成功实现了多种特技动作，且优于传统的奖励设计方法。


<details>
  <summary>Details</summary>
Motivation: 研究PbRL在无人机特技飞行控制中的应用，解决复杂、主观性强的任务目标难以形式化的问题。

Method: 基于Preference PPO，提出REC方法改进奖励学习目标，并在模拟和真实无人机上训练策略。

Result: REC方法在性能上达到88.4%的成型奖励效果，优于标准Preference PPO的55.2%，并在真实无人机上成功实现了多种特技动作。

Conclusion: PbRL能有效捕捉复杂、以人为中心的目标，在物理和仿真领域均表现出色，同时揭示了人工设计奖励的局限性。

Abstract: Preference-based reinforcement learning (PbRL) enables agents to learn
control policies without requiring manually designed reward functions, making
it well-suited for tasks where objectives are difficult to formalize or
inherently subjective. Acrobatic flight poses a particularly challenging
problem due to its complex dynamics, rapid movements, and the importance of
precise execution. In this work, we explore the use of PbRL for agile drone
control, focusing on the execution of dynamic maneuvers such as powerloops.
Building on Preference-based Proximal Policy Optimization (Preference PPO), we
propose Reward Ensemble under Confidence (REC), an extension to the reward
learning objective that improves preference modeling and learning stability.
Our method achieves 88.4% of the shaped reward performance, compared to 55.2%
with standard Preference PPO. We train policies in simulation and successfully
transfer them to real-world drones, demonstrating multiple acrobatic maneuvers
where human preferences emphasize stylistic qualities of motion. Furthermore,
we demonstrate the applicability of our probabilistic reward model in a
representative MuJoCo environment for continuous control. Finally, we highlight
the limitations of manually designed rewards, observing only 60.7% agreement
with human preferences. These results underscore the effectiveness of PbRL in
capturing complex, human-centered objectives across both physical and simulated
domains.

</details>


### [23] [AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy](https://arxiv.org/abs/2508.18820)
*Christian Henkel,Marco Lampacrescia,Michaela Klauck,Matteo Morelli*

Main category: cs.RO

TL;DR: 该论文提出了一种使用统计模型检查（SMC）在设计时验证自主机器人系统属性的新方法，通过扩展SCXML格式并开发AS2FM工具，将系统模型转换为JANI格式，验证了其在实际应用中的可行性和高效性。


<details>
  <summary>Details</summary>
Motivation: 设计能够在未知环境中自主行动的机器人系统是一个复杂任务，需要验证系统属性的可靠性。

Method: 提出扩展SCXML格式以建模ROS 2和行为树特征，并开发AS2FM工具将系统模型转换为JANI格式，利用SMC工具验证系统属性。

Result: 在ROS 2机器人操控案例中，成功识别问题且验证时间小于一秒，且验证运行时间随模型规模线性增长。

Conclusion: 该方法在系统特性支持和验证效率上优于现有技术，适用于实际机器人控制系统。

Abstract: Designing robotic systems to act autonomously in unforeseen environments is a
challenging task. This work presents a novel approach to use formal
verification, specifically Statistical Model Checking (SMC), to verify system
properties of autonomous robots at design-time. We introduce an extension of
the SCXML format, designed to model system components including both Robot
Operating System 2 (ROS 2) and Behavior Tree (BT) features. Further, we
contribute Autonomous Systems to Formal Models (AS2FM), a tool to translate the
full system model into JANI. The use of JANI, a standard format for
quantitative model checking, enables verification of system properties with
off-the-shelf SMC tools. We demonstrate the practical usability of AS2FM both
in terms of applicability to real-world autonomous robotic control systems, and
in terms of verification runtime scaling. We provide a case study, where we
successfully identify problems in a ROS 2-based robotic manipulation use case
that is verifiable in less than one second using consumer hardware.
Additionally, we compare to the state of the art and demonstrate that our
method is more comprehensive in system feature support, and that the
verification runtime scales linearly with the size of the model, instead of
exponentially.

</details>


### [24] [VisionSafeEnhanced VPC: Cautious Predictive Control with Visibility Constraints under Uncertainty for Autonomous Robotic Surgery](https://arxiv.org/abs/2508.18937)
*Wang Jiayin,Wei Yanran,Jiang Lei,Guo Xiaoyu,Zheng Ayong,Zhao Weidong,Li Zhongkui*

Main category: cs.RO

TL;DR: 提出了一种基于视觉预测控制（VPC）的鲁棒框架，用于自主腹腔镜控制，确保视野安全。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像视觉伺服控制（IBVS）中因复杂干扰（如参数化误差、测量噪声等）导致的安全性下降问题。

Method: 利用高斯过程回归（GPR）量化不确定性，提出带概率保障的安全轨迹优化框架，结合控制屏障函数（CBF）和机会约束。

Result: 在仿真和实验验证中，该框架实现了近乎完美的目标可见性（>99.9%），并减少了跟踪误差。

Conclusion: 提出的方法在自主腹腔镜控制中表现优异，显著提升手术安全性。

Abstract: Autonomous control of the laparoscope in robot-assisted Minimally Invasive
Surgery (MIS) has received considerable research interest due to its potential
to improve surgical safety. Despite progress in pixel-level Image-Based Visual
Servoing (IBVS) control, the requirement of continuous visibility and the
existence of complex disturbances, such as parameterization error, measurement
noise, and uncertainties of payloads, could degrade the surgeon's visual
experience and compromise procedural safety. To address these limitations, this
paper proposes VisionSafeEnhanced Visual Predictive Control (VPC), a robust and
uncertainty-adaptive framework for autonomous laparoscope control that
guarantees Field of View (FoV) safety under uncertainty. Firstly, Gaussian
Process Regression (GPR) is utilized to perform hybrid (deterministic +
stochastic) quantification of operational uncertainties including residual
model uncertainties, stochastic uncertainties, and external disturbances. Based
on uncertainty quantification, a novel safety aware trajectory optimization
framework with probabilistic guarantees is proposed, where a
uncertainty-adaptive safety Control Barrier Function (CBF) condition is given
based on uncertainty propagation, and chance constraints are simultaneously
formulated based on probabilistic approximation. This uncertainty aware
formulation enables adaptive control effort allocation, minimizing unnecessary
camera motion while maintaining robustness. The proposed method is validated
through comparative simulations and experiments on a commercial surgical robot
platform (MicroPort MedBot Toumai) performing a sequential multi-target lymph
node dissection. Compared with baseline methods, the framework maintains
near-perfect target visibility (>99.9%), reduces tracking e

</details>


### [25] [Enhanced UAV Path Planning Using the Tangent Intersection Guidance (TIG) Algorithm](https://arxiv.org/abs/2508.18967)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: 论文提出了一种名为TIG算法的无人机路径规划新方法，适用于静态和动态环境，通过椭圆切线交点生成路径，并使用二次贝塞尔曲线优化，实验表明其性能优于多种现有算法。


<details>
  <summary>Details</summary>
Motivation: 无人机的高效安全导航在作战支援、包裹投递和搜救等应用中至关重要，需要一种能在静态和动态环境中快速生成最优路径的算法。

Method: TIG算法利用椭圆切线交点方法生成初步路径，通过启发式规则选择最优子路径，并结合二次贝塞尔曲线优化路径平滑性。

Result: TIG算法在静态环境中生成最短路径时间低至0.01秒，且转向角度更少；在未知或部分已知环境中实时避障性能优于APF和Dynamic APPATT算法。

Conclusion: TIG算法在效率和路径质量上均优于现有算法，适用于多种无人机导航场景。

Abstract: Efficient and safe navigation of Unmanned Aerial Vehicles (UAVs) is critical
for various applications, including combat support, package delivery and Search
and Rescue Operations. This paper introduces the Tangent Intersection Guidance
(TIG) algorithm, an advanced approach for UAV path planning in both static and
dynamic environments. The algorithm uses the elliptic tangent intersection
method to generate feasible paths. It generates two sub-paths for each threat,
selects the optimal route based on a heuristic rule, and iteratively refines
the path until the target is reached. Considering the UAV kinematic and dynamic
constraints, a modified smoothing technique based on quadratic B\'ezier curves
is adopted to generate a smooth and efficient route. Experimental results show
that the TIG algorithm can generate the shortest path in less time, starting
from 0.01 seconds, with fewer turning angles compared to A*, PRM, RRT*, Tangent
Graph, and Static APPATT algorithms in static environments. Furthermore, in
completely unknown and partially known environments, TIG demonstrates efficient
real-time path planning capabilities for collision avoidance, outperforming APF
and Dynamic APPATT algorithms.

</details>


### [26] [HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots](https://arxiv.org/abs/2508.19002)
*Shipeng Lyu,Fangyuan Wang,Weiwei Lin,Luhao Zhu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: HuBE框架通过双层闭环设计生成拟人动作，解决人形机器人行为相似性和适当性挑战，并提升跨机器人兼容性。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人动作生成中行为相似性与适当性不足及跨机器人适应性差的问题。

Method: 提出HuBE双层闭环框架，结合机器人状态、目标位姿和上下文，并构建HPose数据集和骨骼缩放数据增强策略。

Result: 在多平台上显著提升动作相似性、行为适当性和计算效率，优于现有方法。

Conclusion: HuBE为跨人形机器人的可迁移拟人行为执行提供了坚实基础。

Abstract: Achieving both behavioral similarity and appropriateness in human-like motion
generation for humanoid robot remains an open challenge, further compounded by
the lack of cross-embodiment adaptability. To address this problem, we propose
HuBE, a bi-level closed-loop framework that integrates robot state, goal poses,
and contextual situations to generate human-like behaviors, ensuring both
behavioral similarity and appropriateness, and eliminating structural
mismatches between motion generation and execution. To support this framework,
we construct HPose, a context-enriched dataset featuring fine-grained
situational annotations. Furthermore, we introduce a bone scaling-based data
augmentation strategy that ensures millimeter-level compatibility across
heterogeneous humanoid robots. Comprehensive evaluations on multiple commercial
platforms demonstrate that HuBE significantly improves motion similarity,
behavioral appropriateness, and computational efficiency over state-of-the-art
baselines, establishing a solid foundation for transferable and human-like
behavior execution across diverse humanoid robots.

</details>


### [27] [An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees](https://arxiv.org/abs/2508.19074)
*ZhenDong Chen,ZhanShang Nie,ShiXing Wan,JunYi Li,YongTian Cheng,Shuai Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种自然语言与机器人语言翻译框架（NRTrans），通过验证和反馈机制提高LLM生成机器人控制程序的正确性，显著提升了轻量级LLM的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法虽然利用LLM从自然语言任务直接生成可执行程序，但由于LLM的不一致性和任务的高复杂性，生成的代码常存在大量错误，尤其是轻量级LLM效果更差。本文旨在解决这一问题。

Method: 提出了机器人技能语言（RSL）来抽象控制程序的复杂细节，并构建了RSL编译器和调试器，用于验证LLM生成的程序并提供错误反馈，通过反馈微调优化LLM的输出。

Result: 实验表明，NRTrans在多种LLM和任务上优于现有方法，尤其是轻量级LLM的成功率显著提高。

Conclusion: NRTrans框架通过验证和反馈机制，显著提升了LLM生成机器人控制程序的正确性和实用性，尤其是在轻量级LLM上的表现突出。

Abstract: The Large Language Models (LLM) are increasingly being deployed in robotics
to generate robot control programs for specific user tasks, enabling embodied
intelligence. Existing methods primarily focus on LLM training and prompt
design that utilize LLMs to generate executable programs directly from user
tasks in natural language. However, due to the inconsistency of the LLMs and
the high complexity of the tasks, such best-effort approaches often lead to
tremendous programming errors in the generated code, which significantly
undermines the effectiveness especially when the light-weight LLMs are applied.
This paper introduces a natural-robotic language translation framework that (i)
provides correctness verification for generated control programs and (ii)
enhances the performance of LLMs in program generation via feedback-based
fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is
proposed to abstract away from the intricate details of the control programs,
bridging the natural language tasks with the underlying robot skills. Then, the
RSL compiler and debugger are constructed to verify RSL programs generated by
the LLM and provide error feedback to the LLM for refining the outputs until
being verified by the compiler. This provides correctness guarantees for the
LLM-generated programs before being offloaded to the robots for execution,
significantly enhancing the effectiveness of LLM-powered robotic applications.
Experiments demonstrate NRTrans outperforms the existing method under a range
of LLMs and tasks, and achieves a high success rate for light-weight LLMs.

</details>


### [28] [DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning](https://arxiv.org/abs/2508.19114)
*Alkesh K. Srivastava,Jared Michael Levin,Alexander Derrico,Philip Dames*

Main category: cs.RO

TL;DR: DELIVER是一个自然语言驱动的多机器人协作框架，通过集成自然语言理解、空间分解、中继规划和运动执行，实现高效的无碰撞协调。


<details>
  <summary>Details</summary>
Motivation: 提高多机器人在现实场景中的协作效率和可扩展性，减少单机系统的工作量。

Method: 使用LLaMA3解析自然语言指令，基于Voronoi图划分空间，计算最优中继点，并通过有限状态机控制机器人行为。

Result: 在仿真和实际硬件测试中，DELIVER保持了任务成本的一致性，并减少了55%的单机工作量，同时展现出良好的可扩展性。

Conclusion: DELIVER的模块化架构在语言引导的多机器人协调中具有显著优势，推动了物理系统的集成前沿。

Abstract: We present DELIVER (Directed Execution of Language-instructed Item Via
Engineered Relay), a fully integrated framework for cooperative multi-robot
pickup and delivery driven by natural language commands. DELIVER unifies
natural language understanding, spatial decomposition, relay planning, and
motion execution to enable scalable, collision-free coordination in real-world
settings. Given a spoken or written instruction, a lightweight instance of
LLaMA3 interprets the command to extract pickup and delivery locations. The
environment is partitioned using a Voronoi tessellation to define
robot-specific operating regions. Robots then compute optimal relay points
along shared boundaries and coordinate handoffs. A finite-state machine governs
each robot's behavior, enabling robust execution. We implement DELIVER on the
MultiTRAIL simulation platform and validate it in both ROS2-based Gazebo
simulations and real-world hardware using TurtleBot3 robots. Empirical results
show that DELIVER maintains consistent mission cost across varying team sizes
while reducing per-agent workload by up to 55% compared to a single-agent
system. Moreover, the number of active relay agents remains low even as team
size increases, demonstrating the system's scalability and efficient agent
utilization. These findings underscore DELIVER's modular and extensible
architecture for language-guided multi-robot coordination, advancing the
frontiers of cyber-physical system integration.

</details>


### [29] [ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments](https://arxiv.org/abs/2508.19131)
*Shreya Gummadi,Mateus V. Gasparino,Gianluca Capezzuto,Marcelo Becker,Girish Chowdhary*

Main category: cs.RO

TL;DR: ZeST 是一种利用大语言模型视觉推理能力实时生成地形可穿越性地图的新方法，避免了机器人暴露于危险环境中的风险。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要将机器人置于危险环境中收集数据，存在设备和安全隐患。

Method: 利用大语言模型的视觉推理能力，零样本生成可穿越性地图。

Result: 实验表明，ZeST 在室内和室外环境中均能提供更安全的导航，并优于其他先进方法。

Conclusion: ZeST 是一种成本效益高、可扩展的解决方案，能加速高级导航系统的开发。

Abstract: The advancement of robotics and autonomous navigation systems hinges on the
ability to accurately predict terrain traversability. Traditional methods for
generating datasets to train these prediction models often involve putting
robots into potentially hazardous environments, posing risks to equipment and
safety. To solve this problem, we present ZeST, a novel approach leveraging
visual reasoning capabilities of Large Language Models (LLMs) to create a
traversability map in real-time without exposing robots to danger. Our approach
not only performs zero-shot traversability and mitigates the risks associated
with real-world data collection but also accelerates the development of
advanced navigation systems, offering a cost-effective and scalable solution.
To support our findings, we present navigation results, in both controlled
indoor and unstructured outdoor environments. As shown in the experiments, our
method provides safer navigation when compared to other state-of-the-art
methods, constantly reaching the final goal.

</details>


### [30] [Uncertainty-Resilient Active Intention Recognition for Robotic Assistants](https://arxiv.org/abs/2508.19150)
*Juan Carlos Saborío,Marc Vinci,Oscar Lima,Sebastian Stock,Lennart Niecksch,Martin Günther,Alexander Sung,Joachim Hertzberg,Martin Atzmüller*

Main category: cs.RO

TL;DR: 论文提出了一种能应对外部不确定性和传感器噪声的框架，用于提升机器人在人类意图识别中的自主性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人助手的行为往往依赖显式提示或假设完美信息，忽略了意图识别中的不确定性和感知误差。

Method: 采用基于意图识别的POMDP（部分可观测马尔可夫决策过程），结合实时传感器数据和多种规划器，提出一个集成框架。

Result: 框架在物理机器人上测试成功，表现出良好的性能。

Conclusion: 该研究为解决机器人意图识别中的不确定性问题提供了有效方法，具有实际应用潜力。

Abstract: Purposeful behavior in robotic assistants requires the integration of
multiple components and technological advances. Often, the problem is reduced
to recognizing explicit prompts, which limits autonomy, or is oversimplified
through assumptions such as near-perfect information. We argue that a critical
gap remains unaddressed -- specifically, the challenge of reasoning about the
uncertain outcomes and perception errors inherent to human intention
recognition. In response, we present a framework designed to be resilient to
uncertainty and sensor noise, integrating real-time sensor data with a
combination of planners. Centered around an intention-recognition POMDP, our
approach addresses cooperative planning and acting under uncertainty. Our
integrated framework has been successfully tested on a physical robot with
promising results.

</details>


### [31] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的视觉引导四足机器人运动控制方法QuadKAN，结合本体感觉和视觉，使用样条参数化策略提升稳健性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决视觉引导的四足机器人运动控制问题，强调了结合本体感觉和视觉对于鲁棒控制的必要性。

Method: 提出了QuadKAN框架，基于样条参数化的跨模态策略，利用Kolmogorov-Arnold Networks (KANs)实现，包括样条编码器和融合头，采用Multi-Modal Delay Randomization (MMDR)和PPO算法进行端到端训练。

Result: 在多样地形和障碍物场景下，QuadKAN表现优于现有方法，具有更高的回报、更远的移动距离和更少的碰撞。

Conclusion: 样条参数化策略为视觉引导的机器人运动提供了一种简单、有效且可解释的解决方案。

Abstract: We address vision-guided quadruped motion control with reinforcement learning
(RL) and highlight the necessity of combining proprioception with vision for
robust control. We propose QuadKAN, a spline-parameterized cross-modal policy
instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates
a spline encoder for proprioception and a spline fusion head for
proprioception-vision inputs. This structured function class aligns the
state-to-action mapping with the piecewise-smooth nature of gait, improving
sample efficiency, reducing action jitter and energy consumption, and providing
interpretable posture-action sensitivities. We adopt Multi-Modal Delay
Randomization (MMDR) and perform end-to-end training with Proximal Policy
Optimization (PPO). Evaluations across diverse terrains, including both even
and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate
that QuadKAN achieves consistently higher returns, greater distances, and fewer
collisions than state-of-the-art (SOTA) baselines. These results show that
spline-parameterized policies offer a simple, effective, and interpretable
alternative for robust vision-guided locomotion. A repository will be made
available upon acceptance.

</details>


### [32] [Real-time Testing of Satellite Attitude Control With a Reaction Wheel Hardware-In-the-Loop Platform](https://arxiv.org/abs/2508.19164)
*Morokot Sakal,George Nehma,Camilo Riano-Rios,Madhur Tiwari*

Main category: cs.RO

TL;DR: 提出了一种带有反作用轮健康估计能力的自适应卫星姿态控制系统的硬件在环（HIL）测试方法，以验证控制器在实际动量交换设备中的有效性。


<details>
  <summary>Details</summary>
Motivation: 通过HIL测试验证卫星姿态控制算法在实际硬件中的表现，弥补仿真和软件在环测试的不足。

Method: 测试平台包括无刷直流电机和驱动器（通过CAN总线通信）、嵌入式计算机（执行控制和自适应律）以及卫星模拟器（生成传感器数据和响应外部执行器动作）。

Result: 提出了人为诱导反作用轮故障的方法，并总结了相关问题和经验。

Conclusion: 该工作为航天器姿态控制算法的全面验证框架奠定了基础。

Abstract: We propose the Hardware-in-the-Loop (HIL) test of an adaptive satellite
attitude control system with reaction wheel health estimation capabilities.
Previous simulations and Software-in-the-Loop testing have prompted further
experiments to explore the validity of the controller with real momentum
exchange devices in the loop. This work is a step toward a comprehensive
testing framework for validation of spacecraft attitude control algorithms. The
proposed HIL testbed includes brushless DC motors and drivers that communicate
using a CAN bus, an embedded computer that executes control and adaptation
laws, and a satellite simulator that produces simulated sensor data, estimated
attitude states, and responds to actions of the external actuators. We propose
methods to artificially induce failures on the reaction wheels, and present
related issues and lessons learned.

</details>


### [33] [Direction Informed Trees (DIT*): Optimal Path Planning via Direction Filter and Direction Cost Heuristic](https://arxiv.org/abs/2508.19168)
*Liding Zhang,Kejia Chen,Kuanqi Cai,Yu Zhang,Yixuan Dang,Yansong Wu,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: 本文提出了一种名为DIT*的路径规划算法，通过优化搜索方向和提高探索效率，显著提升了路径规划的速度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的路径规划算法（如EIT*）在启发式搜索中难以同时实现准确性和计算效率，因此需要一种新的方法来解决这一问题。

Method: DIT*通过将边定义为广义向量并引入相似性索引，建立方向过滤器，以选择近邻和估计方向成本，从而优化探索方向。

Result: DIT*在R^4到R^16的测试问题中收敛速度优于现有单查询采样规划器，并在实际环境中验证了其有效性。

Conclusion: DIT*通过方向信息的有效共享，显著提升了路径规划的效率，适用于高维和实际环境中的规划任务。

Abstract: Optimal path planning requires finding a series of feasible states from the
starting point to the goal to optimize objectives. Popular path planning
algorithms, such as Effort Informed Trees (EIT*), employ effort heuristics to
guide the search. Effective heuristics are accurate and computationally
efficient, but achieving both can be challenging due to their conflicting
nature. This paper proposes Direction Informed Trees (DIT*), a sampling-based
planner that focuses on optimizing the search direction for each edge,
resulting in goal bias during exploration. We define edges as generalized
vectors and integrate similarity indexes to establish a directional filter that
selects the nearest neighbors and estimates direction costs. The estimated
direction cost heuristics are utilized in edge evaluation. This strategy allows
the exploration to share directional information efficiently. DIT* convergence
faster than existing single-query, sampling-based planners on tested problems
in R^4 to R^16 and has been demonstrated in real-world environments with
various planning tasks. A video showcasing our experimental results is
available at: https://youtu.be/2SX6QT2NOek

</details>


### [34] [From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity](https://arxiv.org/abs/2508.19172)
*Luca Grillotti,Lisa Coiffard,Oscar Pang,Maxence Faldor,Antoine Cully*

Main category: cs.RO

TL;DR: URSA通过自主发现和掌握多样化的技能，直接在现实世界中实现机器人学习，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决自主技能发现中手动定义技能空间和调整启发式的问题，提升现实世界适用性。

Method: 基于QDAC扩展的URSA框架，支持启发式驱动和完全无监督环境下的技能发现。

Result: 在四足机器人上成功实现多样化运动技能，并在模拟和现实中优于基线方法。

Conclusion: URSA为现实世界机器人学习提供新框架，减少人为干预，迈向更自主适应的机器人系统。

Abstract: Autonomous skill discovery aims to enable robots to acquire diverse behaviors
without explicit supervision. Learning such behaviors directly on physical
hardware remains challenging due to safety and data efficiency constraints.
Existing methods, including Quality-Diversity Actor-Critic (QDAC), require
manually defined skill spaces and carefully tuned heuristics, limiting
real-world applicability. We propose Unsupervised Real-world Skill Acquisition
(URSA), an extension of QDAC that enables robots to autonomously discover and
master diverse, high-performing skills directly in the real world. We
demonstrate that URSA successfully discovers diverse locomotion skills on a
Unitree A1 quadruped in both simulation and the real world. Our approach
supports both heuristic-driven skill discovery and fully unsupervised settings.
We also show that the learned skill repertoire can be reused for downstream
tasks such as real-world damage adaptation, where URSA outperforms all
baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios.
Our results establish a new framework for real-world robot learning that
enables continuous skill discovery with limited human intervention,
representing a significant step toward more autonomous and adaptable robotic
systems. Demonstration videos are available at
http://adaptive-intelligent-robotics.github.io/URSA .

</details>


### [35] [Real-Time Model Checking for Closed-Loop Robot Reactive Planning](https://arxiv.org/abs/2508.19186)
*Christopher Chandler,Bernd Porr,Giulia Lafratta,Alice Miller*

Main category: cs.RO

TL;DR: 论文提出了一种基于模型检查的实时多步规划与避障方法，适用于低功耗设备的自主机器人，性能优于单步规划的反应式代理。


<details>
  <summary>Details</summary>
Motivation: 旨在利用生物智能中的核心知识与注意力，发展一种无需预计算数据的实时规划方法，解决自主机器人局部避障问题。

Method: 开发小型专用模型检查算法，通过链式临时控制系统应对环境扰动，并结合2D LiDAR数据的离散化与深度优先搜索实现多步规划。

Result: 实验证明该方法能高效生成局部避障多步计划，性能优于单步规划的反应式代理。

Conclusion: 该研究为自动驾驶领域的安全、可靠且可解释的规划提供了示例和理论基础。

Abstract: We present a new application of model checking which achieves real-time
multi-step planning and obstacle avoidance on a real autonomous robot. We have
developed a small, purpose-built model checking algorithm which generates plans
in situ based on "core" knowledge and attention as found in biological agents.
This is achieved in real-time using no pre-computed data on a low-powered
device. Our approach is based on chaining temporary control systems which are
spawned to counteract disturbances in the local environment that disrupt an
autonomous agent from its preferred action (or resting state). A novel
discretization of 2D LiDAR data sensitive to bounded variations in the local
environment is used. Multi-step planning using model checking by forward
depth-first search is applied to cul-de-sac and playground scenarios. Both
empirical results and informal proofs of two fundamental properties of our
approach demonstrate that model checking can be used to create efficient
multi-step plans for local obstacle avoidance, improving on the performance of
a reactive agent which can only plan one step. Our approach is an instructional
case study for the development of safe, reliable and explainable planning in
the context of autonomous vehicles.

</details>


### [36] [AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot](https://arxiv.org/abs/2508.19191)
*Yue Wang,Wenjie Deng,Haotian Xue,Di Cui,Yiqi Chen,Mingchuan Zhou,Haochao Ying,Jian Wu*

Main category: cs.RO

TL;DR: 提出了一种基于模仿学习的自主眼外科手术系统AutoRing，解决了现有机器人系统手动操作的局限性，成功实现无校准条件下的毫米级精度操作。


<details>
  <summary>Details</summary>
Motivation: 现有眼外科手术机器人依赖手动操作，学习曲线陡峭，且存在运动缩放和远程运动中心点（RCM）变化的运动学不确定性，亟需自主化解决方案。

Method: 采用模仿学习框架AutoRing，结合动态RCM校准和RCM-ACT架构（动作分块变换器与实时运动学对齐），仅通过立体视觉数据和专家示范训练实现任务。

Result: AutoRing在生物仿生眼模型中成功完成环状物抓取与定位任务，无需显式深度感知，且在未校准显微镜条件下验证了端到端自主性。

Conclusion: AutoRing为复杂眼外科手术的智能系统开发提供了可行框架，展示了自主操作的潜力。

Abstract: Intraocular foreign body removal demands millimeter-level precision in
confined intraocular spaces, yet existing robotic systems predominantly rely on
manual teleoperation with steep learning curves. To address the challenges of
autonomous manipulation (particularly kinematic uncertainties from variable
motion scaling and variation of the Remote Center of Motion (RCM) point), we
propose AutoRing, an imitation learning framework for autonomous intraocular
foreign body ring manipulation. Our approach integrates dynamic RCM calibration
to resolve coordinate-system inconsistencies caused by intraocular instrument
variation and introduces the RCM-ACT architecture, which combines
action-chunking transformers with real-time kinematic realignment. Trained
solely on stereo visual data and instrument kinematics from expert
demonstrations in a biomimetic eye model, AutoRing successfully completes ring
grasping and positioning tasks without explicit depth sensing. Experimental
validation demonstrates end-to-end autonomy under uncalibrated microscopy
conditions. The results provide a viable framework for developing intelligent
eye-surgical systems capable of complex intraocular procedures.

</details>


### [37] [Planning-Query-Guided Model Generation for Model-Based Deformable Object Manipulation](https://arxiv.org/abs/2508.19199)
*Alex LaGrassa,Zixuan Huang,Dmitry Berenson,Oliver Kroemer*

Main category: cs.RO

TL;DR: 提出了一种自动生成任务特定、空间自适应动力学模型的方法，通过预测不同区域的分辨率需求，提高规划效率，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 高维度空间（如涉及可变形物体）的高效规划需要计算上可处理且表达能力强的动力学模型。

Method: 采用基于扩散的模型生成器，根据规划查询的起点和目标点云预测各区域的分辨率，使用两阶段数据收集过程优化分辨率。

Result: 在树木操纵任务中，规划速度提高了一倍，任务性能仅略有下降。

Conclusion: 该方法为利用历史规划数据生成高效且表达能力强的动力学模型提供了路径。

Abstract: Efficient planning in high-dimensional spaces, such as those involving
deformable objects, requires computationally tractable yet sufficiently
expressive dynamics models. This paper introduces a method that automatically
generates task-specific, spatially adaptive dynamics models by learning which
regions of the object require high-resolution modeling to achieve good task
performance for a given planning query. Task performance depends on the complex
interplay between the dynamics model, world dynamics, control, and task
requirements. Our proposed diffusion-based model generator predicts per-region
model resolutions based on start and goal pointclouds that define the planning
query. To efficiently collect the data for learning this mapping, a two-stage
process optimizes resolution using predictive dynamics as a prior before
directly optimizing using closed-loop performance. On a tree-manipulation task,
our method doubles planning speed with only a small decrease in task
performance over using a full-resolution model. This approach informs a path
towards using previous planning and control data to generate computationally
efficient yet sufficiently expressive dynamics models for new tasks.

</details>


### [38] [MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2508.19236)
*Hao Shi,Bin Xie,Yingfei Liu,Lin Sun,Fengrong Liu,Tiancai Wang,Erjin Zhou,Haoqiang Fan,Xiangyu Zhang,Gao Huang*

Main category: cs.RO

TL;DR: MemoryVLA是一个受人类记忆机制启发的机器人操作框架，通过工作记忆和感知-认知记忆库处理长期任务，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型往往忽视时间上下文，难以处理长期依赖任务。借鉴人类记忆机制（工作记忆和海马体系统），提出MemoryVLA以提高机器人操作性能。

Method: 采用Cognition-Memory-Action框架，工作记忆缓存短期信息，记忆库存储细节和语义，自适应融合并生成时间感知动作序列。

Result: 在仿真和真实任务中表现优异，分别达到71.9%、72.7%和96.5%的成功率，真实任务中84%成功率，长期任务提升26%。

Conclusion: MemoryVLA通过记忆机制显著提升了机器人长期任务的性能，验证了框架的有效性。

Abstract: Temporal context is essential for robotic manipulation because such tasks are
inherently non-Markovian, yet mainstream VLA models typically overlook it and
struggle with long-horizon, temporally dependent tasks. Cognitive science
suggests that humans rely on working memory to buffer short-lived
representations for immediate control, while the hippocampal system preserves
verbatim episodic details and semantic gist of past experience for long-term
memory. Inspired by these mechanisms, we propose MemoryVLA, a
Cognition-Memory-Action framework for long-horizon robotic manipulation. A
pretrained VLM encodes the observation into perceptual and cognitive tokens
that form working memory, while a Perceptual-Cognitive Memory Bank stores
low-level details and high-level semantics consolidated from it. Working memory
retrieves decision-relevant entries from the bank, adaptively fuses them with
current tokens, and updates the bank by merging redundancies. Using these
tokens, a memory-conditioned diffusion action expert yields temporally aware
action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks
across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it
achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming
state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on
Bridge. On 12 real-world tasks spanning general skills and long-horizon
temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon
tasks showing a +26 improvement over state-of-the-art baseline. Project Page:
https://shihao1895.github.io/MemoryVLA

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [39] [Lossless 4:2:0 Screen Content Coding Using Luma-Guided Soft Context Formation](https://arxiv.org/abs/2508.18968)
*Hannah Och,André Kaup*

Main category: eess.IV

TL;DR: 论文提出了一种改进的软上下文形成编码方法，支持YCbCr 4:2:0格式图像压缩，通过分析图像平面间的归一化互信息和增强色度预测，显著提升了压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有软上下文形成编码器虽然在某些格式（如RGB 4:4:4）上表现优异，但不支持常见的YCbCr 4:2:0格式。为了扩展其应用范围并提高压缩效率，需要对原有方法进行改进。

Method: 扩展了软上下文形成编码能力，支持4:2:0格式，通过分析归一化互信息依次编码Y和CbCr平面，增强色度预测，并传输亮色度组合的辅助信息以优化概率分布建模。

Result: 在大量屏幕内容图像数据集上测试，所提方法性能优于HEVC-SCC，HEVC-SCC的比特率比所提方法高5.66%。

Conclusion: 通过改进的软上下文形成编码方法，成功实现了对YCbCr 4:2:0格式的高效压缩，性能优于现有标准。

Abstract: The soft context formation coder is a pixel-wise state-of-the-art lossless
screen content coder using pattern matching and color palette coding in
combination with arithmetic coding. It achieves excellent compression
performance on screen content images in RGB 4:4:4 format with few distinct
colors. In contrast to many other lossless compression methods, it codes entire
color pixels at once, i.e., all color components of one pixel are coded
together. Consequently, it does not natively support image formats with
downsampled chroma, such as YCbCr 4:2:0, which is an often used chroma format
in video compression. In this paper, we extend the soft context formation
coding capabilities to 4:2:0 image compression, by successively coding Y and
CbCr planes based on an analysis of normalized mutual information between image
planes. Additionally, we propose an enhancement to the chroma prediction based
on the luminance plane. Furthermore, we propose to transmit side-information
about occurring luma-chroma combinations to improve chroma probability
distribution modelling. Averaged over a large screen content image dataset, our
proposed method outperforms HEVC-SCC, with HEVC-SCC needing 5.66% more bitrate
compared to our method.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [40] [Fast Multiagent Formation Stabilization with Sparse Universally Rigid Frameworks](https://arxiv.org/abs/2508.18483)
*Zhonggang Li,Geert Leus,Raj Thilak Rajan*

Main category: eess.SY

TL;DR: 提出了一种无需预定义刚性图的凸优化框架，用于设计AFC的应力矩阵，旨在减少通信链路数量同时保持快速收敛速度。


<details>
  <summary>Details</summary>
Motivation: AFC作为一种分布式网络控制系统，亟需一种无需预先定义刚性图的网络设计方法，以降低通信链路数量并保持高效性能。

Method: 采用凸优化框架设计应力矩阵，避免了预先定义刚性图的步骤，直接优化网络结构和收敛速度。

Result: 仿真结果表明，所提方法能生成更稀疏的图结构，同时收敛速度优于现有方案。

Conclusion: 该凸优化框架在AFC中实现了更高效的网络设计，为实际应用提供了可行的解决方案。

Abstract: Affine formation control (AFC) is a distributed networked control system that
has recently received increasing attention in various applications. AFC is
typically achieved using a generalized consensus system where the stress
matrix, which encodes the graph structure, is used instead of a graph
Laplacian. Universally rigid frameworks (URFs) guarantee the existence of the
stress matrix and have thus become the guideline for such a network design. In
this work, we propose a convex optimization framework to design the stress
matrix for AFC without predefining a rigid graph. We aim to find a resulting
network with a reduced number of communication links, but still with a fast
convergence speed. We show through simulations that our proposed solutions can
yield a more sparse graph, while admitting a faster convergence compared to the
state-of-the-art solutions.

</details>


### [41] [Safe Navigation under State Uncertainty: Online Adaptation for Robust Control Barrier Functions](https://arxiv.org/abs/2508.19159)
*Ersin Das,Rahal Nanayakkara,Xiao Tan,Ryan M. Bena,Joel W. Burdick,Paulo Tabuada,Aaron D. Ames*

Main category: eess.SY

TL;DR: 提出了一种改进的鲁棒控制屏障函数（R-CBF）方法，通过优化在线参数自适应方案减少保守性，并解决了双相对阶问题，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒控制屏障函数在存在估计误差时对输入施加严格条件，导致保守性、不可行性和高控制成本等问题，需要改进以减少这些负面影响。

Method: 采用基于优化的在线参数自适应方案，结合泊松方程将多个安全约束合并为统一的数值CBF，同时解决了车辆跟踪中的双相对阶问题。

Result: 实验表明，该方法显著减少了现有R-CBF的保守性，提升了整体性能，特别是在导航任务中。

Conclusion: 新方法通过优化参数和统一约束，有效解决了现有R-CBF的保守性和复杂性问题，为安全关键应用提供了更高效的解决方案。

Abstract: Measurements and state estimates are often imperfect in control practice,
posing challenges for safety-critical applications, where safety guarantees
rely on accurate state information. In the presence of estimation errors,
several prior robust control barrier function (R-CBF) formulations have imposed
strict conditions on the input. These methods can be overly conservative and
can introduce issues such as infeasibility, high control effort, etc. This work
proposes a systematic method to improve R-CBFs, and demonstrates its advantages
on a tracked vehicle that navigates among multiple obstacles. A primary
contribution is a new optimization-based online parameter adaptation scheme
that reduces the conservativeness of existing R-CBFs. In order to reduce the
complexity of the parameter optimization, we merge several safety constraints
into one unified numerical CBF via Poisson's equation. We further address the
dual relative degree issue that typically causes difficulty in vehicle
tracking. Experimental trials demonstrate the overall performance improvement
of our approach over existing formulations.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [42] [Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion](https://arxiv.org/abs/2508.18734)
*DongHoon Lim,YoungChae Kim,Dong-Hyun Kim,Da-Hee Yang,Joon-Hyuk Chang*

Main category: cs.CV

TL;DR: 提出了一种基于路由器门控跨模态特征融合的新型AVSR框架，动态调整音频和视觉特征的权重以提高在噪声环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有系统在噪声环境中难以准确估计音频可靠性并动态调整模态依赖，导致鲁棒性不足。

Method: 采用基于音频-视觉特征融合的路由器，通过令牌级声学腐败分数动态调整权重，并在解码器层中使用门控跨注意机制强化视觉线索。

Result: 在LRS3数据上，相比AV-HuBERT模型，词错误率相对降低了16.51-42.67%。

Conclusion: 路由器及其门控机制显著提升了模型在真实噪声环境下的鲁棒性。

Abstract: Robust audio-visual speech recognition (AVSR) in noisy environments remains
challenging, as existing systems struggle to estimate audio reliability and
dynamically adjust modality reliance. We propose router-gated cross-modal
feature fusion, a novel AVSR framework that adaptively reweights audio and
visual features based on token-level acoustic corruption scores. Using an
audio-visual feature fusion-based router, our method down-weights unreliable
audio tokens and reinforces visual cues through gated cross-attention in each
decoder layer. This enables the model to pivot toward the visual modality when
audio quality deteriorates. Experiments on LRS3 demonstrate that our approach
achieves an 16.51-42.67% relative reduction in word error rate compared to
AV-HuBERT. Ablation studies confirm that both the router and gating mechanism
contribute to improved robustness under real-world acoustic noise.

</details>


### [43] [Towards Training-Free Underwater 3D Object Detection from Sonar Point Clouds: A Comparison of Traditional and Deep Learning Approaches](https://arxiv.org/abs/2508.18293)
*M. Salman Shaukat,Yannik Käckenmeister,Sebastian Bader,Thomas Kirste*

Main category: cs.CV

TL;DR: 研究探讨了无需真实训练数据的水下3D物体检测方法，比较了基于物理模拟的合成数据训练神经网络和基于几何先验的模板匹配系统。


<details>
  <summary>Details</summary>
Motivation: 水下3D物体检测因复杂的声学环境和训练数据稀缺而面临巨大挑战，传统的深度学习方法需要大量标注数据，成本高昂且难以获取。

Method: 提出了两种无需真实训练数据的检测方法：1) 基于物理的声纳模拟生成合成数据训练神经网络；2) 利用目标几何先验的模型模板匹配系统。

Result: 神经网络在模拟数据上达到98%的mAP，但在真实数据上降至40%；模板匹配无需训练，在真实数据上保持83%的mAP，表现稳定。

Conclusion: 研究表明在数据稀缺的水下环境中，模型模板匹配优于依赖合成数据训练的神经网络，为水下3D检测提供了新的解决方案。

Abstract: Underwater 3D object detection remains one of the most challenging frontiers
in computer vision, where traditional approaches struggle with the harsh
acoustic environment and scarcity of training data. While deep learning has
revolutionized terrestrial 3D detection, its application underwater faces a
critical bottleneck: obtaining sufficient annotated sonar data is prohibitively
expensive and logistically complex, often requiring specialized vessels, expert
surveyors, and favorable weather conditions. This work addresses a fundamental
question: Can we achieve reliable underwater 3D object detection without
real-world training data? We tackle this challenge by developing and comparing
two paradigms for training-free detection of artificial structures in multibeam
echo-sounder point clouds. Our dual approach combines a physics-based sonar
simulation pipeline that generates synthetic training data for state-of-the-art
neural networks, with a robust model-based template matching system that
leverages geometric priors of target objects. Evaluation on real bathymetry
surveys from the Baltic Sea reveals surprising insights: while neural networks
trained on synthetic data achieve 98% mean Average Precision (mAP) on simulated
scenes, they drop to 40% mAP on real sonar data due to domain shift.
Conversely, our template matching approach maintains 83% mAP on real data
without requiring any training, demonstrating remarkable robustness to acoustic
noise and environmental variations. Our findings challenge conventional wisdom
about data-hungry deep learning in underwater domains and establish the first
large-scale benchmark for training-free underwater 3D detection. This work
opens new possibilities for autonomous underwater vehicle navigation, marine
archaeology, and offshore infrastructure monitoring in data-scarce environments
where traditional machine learning approaches fail.

</details>


### [44] [Are All Marine Species Created Equal? Performance Disparities in Underwater Object Detection](https://arxiv.org/abs/2508.18729)
*Melanie Wille,Tobias Fischer,Scarlett Raine*

Main category: cs.CV

TL;DR: 论文研究了水下物体检测中性能差异的成因，重点关注扇贝类的检测问题，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 解决水下物体检测中某些物种检测效果不佳的根本原因及如何系统性改进。

Method: 通过分割定位与分类任务，使用YOLO11和TIDE分析DUO数据集，研究扇贝类的检测性能。

Result: 定位阶段的前景-背景区分问题最突出，分类实验显示特征固有挑战。建议针对不同目标选择数据分布。

Conclusion: 改进低效类别的检测需聚焦算法优化，尤其是定位模块，并公开了代码与数据集。

Abstract: Underwater object detection is critical for monitoring marine ecosystems but
poses unique challenges, including degraded image quality, imbalanced class
distribution, and distinct visual characteristics. Not every species is
detected equally well, yet underlying causes remain unclear. We address two key
research questions: 1) What factors beyond data quantity drive class-specific
performance disparities? 2) How can we systematically improve detection of
under-performing marine species? We manipulate the DUO dataset to separate the
object detection task into localization and classification and investigate the
under-performance of the scallop class. Localization analysis using YOLO11 and
TIDE finds that foreground-background discrimination is the most problematic
stage regardless of data quantity. Classification experiments reveal persistent
precision gaps even with balanced data, indicating intrinsic feature-based
challenges beyond data scarcity and inter-class dependencies. We recommend
imbalanced distributions when prioritizing precision, and balanced
distributions when prioritizing recall. Improving under-performing classes
should focus on algorithmic advances, especially within localization modules.
We publicly release our code and datasets.

</details>


### [45] [PseudoMapTrainer: Learning Online Mapping without HD Maps](https://arxiv.org/abs/2508.18788)
*Christian Löwens,Thorben Funke,Jingchao Xie,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: 提出了一种无需高精地图训练在线地图模型的新方法PseudoMapTrainer，利用伪标签和半监督学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵且地理多样性不足的高精地图，限制了模型的泛化能力。

Method: 通过多视角图像和预训练分割网络生成伪标签，使用掩码感知的分配算法和损失函数处理部分掩码伪标签。

Result: 首次实现了无需真实地图的在线地图模型训练，并能利用大规模未标注数据进行半监督预训练。

Conclusion: PseudoMapTrainer为在线地图训练提供了一种高效且可扩展的解决方案。

Abstract: Online mapping models show remarkable results in predicting vectorized maps
from multi-view camera images only. However, all existing approaches still rely
on ground-truth high-definition maps during training, which are expensive to
obtain and often not geographically diverse enough for reliable generalization.
In this work, we propose PseudoMapTrainer, a novel approach to online mapping
that uses pseudo-labels generated from unlabeled sensor data. We derive those
pseudo-labels by reconstructing the road surface from multi-camera imagery
using Gaussian splatting and semantics of a pre-trained 2D segmentation
network. In addition, we introduce a mask-aware assignment algorithm and loss
function to handle partially masked pseudo-labels, allowing for the first time
the training of online mapping models without any ground-truth maps.
Furthermore, our pseudo-labels can be effectively used to pre-train an online
model in a semi-supervised manner to leverage large-scale unlabeled
crowdsourced data. The code is available at
github.com/boschresearch/PseudoMapTrainer.

</details>


### [46] [Interpretable Decision-Making for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.18898)
*Mona Mirzaie,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: 该论文提出了一种提升自动驾驶控制命令可解释性的方法，通过稀疏和局部化的特征图优化决策，且在CARLA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要可信赖的AI，但端到端模型的非线性决策边界导致难以解释，因此需要提升可解释性以优化控制命令。

Method: 提出新的损失函数，生成稀疏和局部化的特征图，通过特征激活解释预测的控制命令。

Result: 在CARLA基准测试中，单目非集成模型表现优于顶尖方法，降低了违规率并提升了路线完成率。

Conclusion: 该方法在提升可解释性的同时，优化了自动驾驶性能，为更安全的驾驶提供了可能。

Abstract: Trustworthy AI is mandatory for the broad deployment of autonomous vehicles.
Although end-to-end approaches derive control commands directly from raw data,
interpreting these decisions remains challenging, especially in complex urban
scenarios. This is mainly attributed to very deep neural networks with
non-linear decision boundaries, making it challenging to grasp the logic behind
AI-driven decisions. This paper presents a method to enhance interpretability
while optimizing control commands in autonomous driving. To address this, we
propose loss functions that promote the interpretability of our model by
generating sparse and localized feature maps. The feature activations allow us
to explain which image regions contribute to the predicted control command. We
conduct comprehensive ablation studies on the feature extraction step and
validate our method on the CARLA benchmarks. We also demonstrate that our
approach improves interpretability, which correlates with reducing infractions,
yielding a safer, high-performance driving model. Notably, our monocular,
non-ensemble model surpasses the top-performing approaches from the CARLA
Leaderboard by achieving lower infraction scores and the highest route
completion rate, all while ensuring interpretability.

</details>


### [47] [VibES: Induced Vibration for Persistent Event-Based Sensing](https://arxiv.org/abs/2508.19094)
*Vincenzo Polizzi,Stephen Yang,Quentin Clark,Jonathan Kelly,Igor Gilitschenski,David B. Lindell*

Main category: cs.CV

TL;DR: 提出了一种轻量级方法，通过旋转不平衡质量块诱导周期性振动运动，解决事件相机在静态或低运动场景下无法生成事件的问题。


<details>
  <summary>Details</summary>
Motivation: 事件相机在静态或低运动场景中无法生成事件，限制了其应用范围。

Method: 使用旋转不平衡质量块诱导振动，并结合运动补偿管道去除注入的运动。

Result: 方法可靠地恢复了运动参数，并改善了图像重建和边缘检测的效果。

Conclusion: 该轻量级方法有效解决了事件相机在静态场景中的局限性，提升了其感知任务的性能。

Abstract: Event cameras are a bio-inspired class of sensors that asynchronously measure
per-pixel intensity changes. Under fixed illumination conditions in static or
low-motion scenes, rigidly mounted event cameras are unable to generate any
events, becoming unsuitable for most computer vision tasks. To address this
limitation, recent work has investigated motion-induced event stimulation that
often requires complex hardware or additional optical components. In contrast,
we introduce a lightweight approach to sustain persistent event generation by
employing a simple rotating unbalanced mass to induce periodic vibrational
motion. This is combined with a motion-compensation pipeline that removes the
injected motion and yields clean, motion-corrected events for downstream
perception tasks. We demonstrate our approach with a hardware prototype and
evaluate it on real-world captured datasets. Our method reliably recovers
motion parameters and improves both image reconstruction and edge detection
over event-based sensing without motion induction.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [48] [Joint Time-Position Statistics and Fisher Information in Drift-Diffusion Molecular Channels](https://arxiv.org/abs/2508.18680)
*Yun-Feng Lo,Yen-Chi Lee*

Main category: cs.IT

TL;DR: 本文提出了一种在漂移条件下的扩散分子通信系统中首次到达时间（FAT）和首次到达位置（FAP）联合分布的闭式解，揭示了时间与位置的耦合关系。


<details>
  <summary>Details</summary>
Motivation: 先前的研究仅分别研究了FAT和FAP的统计特性，而未探讨它们的联合分布。本文旨在填补这一空白，为分子通信系统提供更全面的建模和参数估计能力。

Method: 在恒定漂移和各向同性扩散条件下，推导了任意空间维度中FAT和FAP的联合概率密度函数（PDF）。

Result: 结果显示了时间与横向位置的耦合关系，并扩展了已知的反高斯模型。通过计算Fisher信息矩阵（FIM），证明了联合观察可以提高对横向漂移和扩散系数的估计能力。

Conclusion: 本文的联合建模框架增强了分子通信系统的建模和推断能力，特别是在空间随机性信息不可忽略的场景中。

Abstract: This letter presents a closed-form characterization of the joint distribution
of first arrival time (FAT) and first arrival position (FAP) in diffusion-based
molecular communication (MC) systems with drift. Prior studies have
investigated FAT modeling via inverse Gaussian distributions [1] and applied
FAT statistics for parameter estimation and synchronization tasks [2], [3],
while more recent work has characterized FAP for spatial channel analysis [4].
In contrast, we derive an explicit joint probability density function (PDF)
under constant drift and isotropic diffusion in arbitrary spatial dimensions.
Our result reveals a nontrivial coupling between arrival time and lateral
position, generalizing known inverse Gaussian models. We further compute the
Fisher information matrix (FIM) with respect to key channel parameters, showing
that the joint observation enables estimation of lateral drift and improves
sensitivity to the diffusion coefficient -- capabilities not achievable with
time-only or position-only models. This joint framework enhances the modeling
and inference capabilities for molecular communication channels where spatial
randomness itself carries non-negligible information.

</details>


### [49] [Performance Analysis of IEEE 802.11bn with Coordinated TDMA on Real-Time Applications](https://arxiv.org/abs/2508.18755)
*Seungmin Lee,Changmin Lee,Si-Chan Noh,Joonsoo Lee*

Main category: cs.IT

TL;DR: 论文研究了Wi-Fi中协调TDMA（Co-TDMA）技术如何通过调度策略降低实时应用中的延迟和抖动，尤其是在高网络负载下。通过系统级仿真验证，Co-TDMA显著改进了最坏情况延迟和抖动，延迟改善约24%。


<details>
  <summary>Details</summary>
Motivation: 由于实时应用对低延迟通信的需求日益增长，论文旨在通过Wi-Fi技术（如IEEE 802.11bn中的多接入点协调技术）优化时间敏感流量的传输性能。

Method: 提出了一种协调TDMA（Co-TDMA）调度策略，并分析了该策略在网络拥堵和不同流量特征下对延迟和抖动的影响。通过系统级仿真验证了其有效性。

Result: 仿真结果表明，Co-TDMA显著降低了实时流量中的抖动和最坏情况延迟，特别是后者改善了约24%。

Conclusion: Co-TDMA是一种有效优化Wi-Fi实时通信性能的技术，尤其在高负载网络环境下，能够显著减少延迟和抖动。

Abstract: Wi-Fi plays a crucial role in connecting electronic devices and providing
communication services in everyday life. Recently, there has been a growing
demand for services that require low-latency communication, such as real-time
applications. The latest amendments to Wi-Fi, IEEE 802.11bn, are being
developed to address these demands with technologies such as the multiple
access point coordination (MAPC). In this paper, we demonstrate that
coordinated TDMA (Co-TDMA), one of the MAPC techniques, effectively reduces the
latency of transmitting time-sensitive traffic. In particular, we focus on
worst-case latency and jitter, which are key metrics for evaluating the
performance of real-time applications. We first introduce a Co-TDMA scheduling
strategy. We then investigate how this scheduling strategy impacts latency
under varying levels of network congestion and traffic volume characteristics.
Finally, we validate our findings through system-level simulations. Our
simulation results demonstrate that Co-TDMA effectively mitigates jitter and
worst-case latency for LL traffic, with the latter exhibiting an improvement of
approximately 24%.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [50] [Is Green Enough? A Remote Sensing Assessment of Environmental Impacts and Green Commitments at Beijing Daxing International Airport](https://arxiv.org/abs/2508.18274)
*Haorui Wang,Bo Zhao*

Main category: physics.soc-ph

TL;DR: 北京大兴国际机场作为中国生态现代化议程下的绿色基础设施典范，本研究通过多源遥感数据评估其环境影响，发现部分绿色倡议成效显著，但也存在植被减少、建筑表面增加及地表温度上升等问题。


<details>
  <summary>Details</summary>
Motivation: 评估北京大兴国际机场作为绿色基础设施的环境影响，验证其生态现代化承诺的实际效果。

Method: 使用包括NDVI、NDBI、地表温度（LST）、VIIRS夜间灯光和PM2.5在内的多源遥感数据（2014-2019年），进行空间和时间对比分析。

Result: 结果显示绿色倡议部分有效，但也存在植被损失、建筑表面增加和地表温度上升的负面影响。

Conclusion: 建议未来基础设施项目采用遥感监测框架，强化空间独立监测以确保环保责任。

Abstract: Beijing Daxing International Airport has been promoted as a model of green
infrastructure under China's ecological modernization agenda. Featuring
energy-efficient design, renewable energy systems, and smart environmental
controls, the airport embodies multiple green commitments. This study evaluates
its environmental outcomes using multi-source remote sensing data -- including
NDVI, NDBI, Land Surface Temperature (LST), VIIRS night-time lights, and PM2.5
-- from 2014 to 2019. Through spatial and temporal comparisons, we assess
landscape-level changes during and after construction. Findings indicate
partial gains from green initiatives but also reveal substantial vegetation
loss, increased built-up surfaces, and intensified surface temperatures. The
results suggest a gap between sustainable design and ecological impact. We
propose a remote-sensing-based framework for evaluating future infrastructure
projects, emphasizing the need for spatially explicit, independent monitoring
to ensure environmental accountability.

</details>
