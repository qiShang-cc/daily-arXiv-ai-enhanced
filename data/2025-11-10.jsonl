{"id": "2511.04777", "pdf": "https://arxiv.org/pdf/2511.04777", "abs": "https://arxiv.org/abs/2511.04777", "authors": ["Dawn Virginillo", "Asja Derviškadić", "Mario Paolone"], "title": "OPF-Based Optimal Power System Network Restoration Considering Frequency Dynamics", "categories": ["eess.SP"], "comment": null, "summary": "Due to recent blackout and system split incidents in power grids worldwide,\nas well as increased system complexity in view of the energy transition, there\nhas been increasing interest in re-evaluating existing Power System Restoration\n(PSR) plans. In restoration scenarios, due to low island inertia, it is\nnecessary to ensure not only the static, but also the dynamic stability of the\nsystem. In this paper, we pose and solve a formulation of the optimal PSR\nproblem including frequency dynamics. We validate the switching constraints for\nglobal optimality within a static version of the formulation using a\nbrute-force tree search method. We apply the dynamic problem formulation to the\nIEEE 9-Bus model, and show that the optimal switching sequence using the static\nformulation would violate dynamic constraints, illustrating the importance of\ndynamic considerations in PSR planning."}
{"id": "2511.04861", "pdf": "https://arxiv.org/pdf/2511.04861", "abs": "https://arxiv.org/abs/2511.04861", "authors": ["Nikoloz Vashakidze", "Chadi Assi", "Mohamed Elhattab", "Ali Ghrayeb", "Maurice J. Khabbaz"], "title": "Joint Power Allocation and Radiation Optimization in NOMA-Assisted Pinching Antenna Systems", "categories": ["eess.SP"], "comment": null, "summary": "This paper explores a joint optimization of transmit power allocation and\nradiation coefficients in a downlink Pinching Antenna SyStem (PASS) employing\nNon-Orthogonal Multiple Access (NOMA). By leveraging the PASS-enabled flexible\nchannel adjustment and NOMA's power allocation adaptability, a sum rate\nmaximization problem is formulated with the objective of simultaneously\noptimizing base station (BS)'s transmit power coefficients and pinching antenna\n(PA)'s radiation powers. Due to its non-convexity and complexity, the\nformulated optimization problem is challenging to solve directly. Hence, we\ndecompose the main problem into two sub-problems, namely transmit power\nallocation sub-problem and PA radiation power allocation sub-problem. In the\nfirst sub-problem, closed-form solutions are derived for the BS's power\nallocation among NOMA users. Meanwhile, in the second sub-problem, we optimize\nthe PA's radiation power utilizing successive convex approximation (SCA). These\ntwo sub-problems are solved alternatively using Alternating Optimization (AO)\nuntil convergence. It should be noted that decoding order plays a significant\nrole in NOMA-assisted PASS. Hence, two variations of decoding order are\nconsidered, namely: i) a high-complexity exhaustive search approach, and, ii) a\nlow-complexity alternative that utilizes pre-determined channel information.\nNumerical results show that our proposed approach substantially improves the\nsystem's sum-rate compared to widely adopted equal power allocation PASS\nschemes."}
{"id": "2511.04908", "pdf": "https://arxiv.org/pdf/2511.04908", "abs": "https://arxiv.org/abs/2511.04908", "authors": ["Haochen Wu", "Yuanbin Chen", "Yang Ming", "Zhaocheng Wang"], "title": "Two-timescale Beamforming Optimization for Downlink Multi-user Holographic MIMO Surfaces", "categories": ["eess.SP"], "comment": "This manuscript has been accepted by IEEE Transactions on Vehicular\n  Technology (IEEE TVT)", "summary": "Benefiting from the rapid development of metamaterials and metasurfaces, the\nholographic multiple-input and multiple-output surface (HMIMOS) has been\nregarded as a promising solution for future wireless networks recently. By\ndensely packing numerous radiation elements together, HMIMOS is capable of\nrealizing accurate beamforming with low hardware complexity. However, enormous\nradiation elements on the HMIMOS lead to high computational complexity and\nsignaling overhead when applying traditional beamforming schemes relying on\ninstantaneous channel state information (CSI). To tackle this problem, we\npropose a two-timescale optimization scheme to minimize the required\ntransmission power under the constraint of all users' quality-of-service (QoS).\nSpecifically, the beampatterns at the base station (BS) and the user equippment\n(UE) are optimized over the slowly changing statistical CSI based on the\nconstrained stochastic successive convex approximation (CSSCA) algorithm. Then,\nthe instantaneous CSI is utilized to design the precoding matrix in order to\nensure the system performance without significant increase in computational\ncost, due to the small number of feeds on the HMIMOS. Simulation results\ndemonstrate the effectiveness of our proposed method compared to other\nbaselines."}
{"id": "2511.04913", "pdf": "https://arxiv.org/pdf/2511.04913", "abs": "https://arxiv.org/abs/2511.04913", "authors": ["Haoyang Weng", "Haisu Wu", "Hong Ren", "Cunhua Pan", "Jiangzhou Wang"], "title": "4D Imaging in ISAC Systems: A Framework Based on 5G NR Downlink Signals", "categories": ["eess.SP"], "comment": "TVT", "summary": "Integrated sensing and communication (ISAC) has emerged as a key enabler for\nsixth-generation (6G) wireless networks, supporting spectrum sharing and\nhardware integration. Beyond communication enhancement, ISAC also enables\nhigh-accuracy environment reconstruction and imaging, which are crucial for\napplications such as autonomous driving and digital twins. This paper proposes\na 4D imaging framework fully compliant with the 5G New Radio (NR) protocol,\nensuring compatibility with cellular systems. Specifically, we develop an\nend-to-end processing chain that covers waveform generation, echo processing,\nand multi-BS point cloud fusion. Furthermore, we introduce Zoom-OMP, a\ncoarse-to-fine sparse recovery algorithm for high-resolution angle estimation\nthat achieves high accuracy with reduced computational cost. The simulation\nresults demonstrate that the proposed framework achieves robust 4D imaging\nperformance with superior spatial accuracy and reconstruction quality compared\nto conventional benchmarks, paving the way for practical ISAC-enabled\nenvironment reconstruction in 6G networks."}
{"id": "2511.04758", "pdf": "https://arxiv.org/pdf/2511.04758", "abs": "https://arxiv.org/abs/2511.04758", "authors": ["Caelan Garrett", "Fabio Ramos"], "title": "ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "Project website: https://schedulestream.github.io", "summary": "Bimanual and humanoid robots are appealing because of their human-like\nability to leverage multiple arms to efficiently complete tasks. However,\ncontrolling multiple arms at once is computationally challenging due to the\ngrowth in the hybrid discrete-continuous action space. Task and Motion Planning\n(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce\nplans, where only one arm is moving at a time, rather than schedules that allow\nfor parallel arm motion. In order to extend TAMP to produce schedules, we\npresent ScheduleStream, the first general-purpose framework for planning &\nscheduling with sampling operations. ScheduleStream models temporal dynamics\nusing hybrid durative actions, which can be started asynchronously and persist\nfor a duration that's a function of their parameters. We propose\ndomain-independent algorithms that solve ScheduleStream problems without any\napplication-specific mechanisms. We apply ScheduleStream to Task and Motion\nPlanning & Scheduling (TAMPAS), where we use GPU acceleration within samplers\nto expedite planning. We compare ScheduleStream algorithms to several ablations\nin simulation and find that they produce more efficient solutions. We\ndemonstrate ScheduleStream on several real-world bimanual robot tasks at\nhttps://schedulestream.github.io."}
{"id": "2511.04944", "pdf": "https://arxiv.org/pdf/2511.04944", "abs": "https://arxiv.org/abs/2511.04944", "authors": ["Zixiang Ren", "Juncong Zhou", "Jie Xu", "Ling Qiu", "Yong Zeng", "Han Hu", "Juyong Zhang", "Rui Zhang"], "title": "Channel Knowledge Map Construction: Recent Advances and Open Challenges", "categories": ["eess.SP"], "comment": null, "summary": "Channel knowledge map (CKM) has emerged as a pivotal technology for\nenvironment-aware wireless communications and sensing, which provides a priori\nlocation-specific channel knowledge to facilitate network optimization.\nEfficient CKM construction is an important technical problem for its effective\nimplementation. This article provides a comprehensive overview of recent\nadvances in CKM construction. First, we examine classical interpolation-based\nCKM construction methods, highlighting their limitations in practical\ndeployments. Next, we explore image processing and generative artificial\nintelligence (AI) techniques, which leverage feature extraction to construct\nCKMs based on environmental knowledge. Furthermore, we present emerging\nwireless radiance field (WRF) frameworks that exploit neural radiance fields or\nGaussian splatting to construct high-fidelity CKMs from sparse measurement\ndata. Finally, we outline various future research directions in real-time and\ncross-domain CKM construction, as well as cost-efficient deployment of CKMs."}
{"id": "2511.04769", "pdf": "https://arxiv.org/pdf/2511.04769", "abs": "https://arxiv.org/abs/2511.04769", "authors": ["Phat Nguyen", "Tsun-Hsuan Wang", "Zhang-Wei Hong", "Erfan Aasi", "Andrew Silva", "Guy Rosman", "Sertac Karaman", "Daniela Rus"], "title": "ReGen: Generative Robot Simulation via Inverse Design", "categories": ["cs.RO"], "comment": null, "summary": "Simulation plays a key role in scaling robot learning and validating\npolicies, but constructing simulations remains a labor-intensive process. This\npaper introduces ReGen, a generative simulation framework that automates\nsimulation design via inverse design. Given a robot's behavior -- such as a\nmotion trajectory or an objective function -- and its textual description,\nReGen infers plausible scenarios and environments that could have caused the\nbehavior. ReGen leverages large language models to synthesize scenarios by\nexpanding a directed graph that encodes cause-and-effect relationships,\nrelevant entities, and their properties. This structured graph is then\ntranslated into a symbolic program, which configures and executes a robot\nsimulation environment. Our framework supports (i) augmenting simulations based\non ego-agent behaviors, (ii) controllable, counterfactual scenario generation,\n(iii) reasoning about agent cognition and mental states, and (iv) reasoning\nwith distinct sensing modalities, such as braking due to faulty GPS signals. We\ndemonstrate ReGen in autonomous driving and robot manipulation tasks,\ngenerating more diverse, complex simulated environments compared to existing\nsimulations with high success rates, and enabling controllable generation for\ncorner cases. This approach enhances the validation of robot policies and\nsupports data or simulation augmentation, advancing scalable robot learning for\nimproved generalization and robustness. We provide code and example videos at:\nhttps://regen-sim.github.io/"}
{"id": "2511.05039", "pdf": "https://arxiv.org/pdf/2511.05039", "abs": "https://arxiv.org/abs/2511.05039", "authors": ["Jiuqi Yan", "Chendong Xu", "Dongyu Liu"], "title": "PECL: A Heterogeneous Parallel Multi-Domain Network for Radar-Based Human Activity Recognition", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Radar systems are increasingly favored for medical applications because they\nprovide non-intrusive monitoring with high privacy and robustness to lighting\nconditions. However, existing research typically relies on single-domain radar\nsignals and overlooks the temporal dependencies inherent in human activity,\nwhich complicates the classification of similar actions. To address this issue,\nwe designed the Parallel-EfficientNet-CBAM-LSTM (PECL) network to process data\nin three complementary domains: Range-Time, Doppler-Time, and Range-Doppler.\nPECL combines a channel-spatial attention module and temporal units to capture\nmore features and dynamic dependencies during action sequences, improving both\naccuracy and robustness. The experimental results show that PECL achieves an\naccuracy of 96.16% on the same dataset, outperforming existing methods by at\nleast 4.78%. PECL also performs best in distinguishing between easily confused\nactions. Despite its strong performance, PECL maintains moderate model\ncomplexity, with 23.42M parameters and 1324.82M FLOPs. Its parameter-efficient\ndesign further reduces computational cost."}
{"id": "2511.04812", "pdf": "https://arxiv.org/pdf/2511.04812", "abs": "https://arxiv.org/abs/2511.04812", "authors": ["Zixuan Huang", "Huaidian Hou", "Dmitry Berenson"], "title": "Unified Multimodal Diffusion Forcing for Forceful Manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Project website: https://unified-df.github.io", "summary": "Given a dataset of expert trajectories, standard imitation learning\napproaches typically learn a direct mapping from observations (e.g., RGB\nimages) to actions. However, such methods often overlook the rich interplay\nbetween different modalities, i.e., sensory inputs, actions, and rewards, which\nis crucial for modeling robot behavior and understanding task outcomes. In this\nwork, we propose Multimodal Diffusion Forcing, a unified framework for learning\nfrom multimodal robot trajectories that extends beyond action generation.\nRather than modeling a fixed distribution, MDF applies random partial masking\nand trains a diffusion model to reconstruct the trajectory. This training\nobjective encourages the model to learn temporal and cross-modal dependencies,\nsuch as predicting the effects of actions on force signals or inferring states\nfrom partial observations. We evaluate MDF on contact-rich, forceful\nmanipulation tasks in simulated and real-world environments. Our results show\nthat MDF not only delivers versatile functionalities, but also achieves strong\nperformance, and robustness under noisy observations. More visualizations can\nbe found on our website https://unified-df.github.io"}
{"id": "2511.05048", "pdf": "https://arxiv.org/pdf/2511.05048", "abs": "https://arxiv.org/abs/2511.05048", "authors": ["Zhenyu Xiao", "Xiangyu Pi", "Songqi Cao", "Lipeng Zhu", "Zhen Gao", "Xiang-Gen Xia", "Rui Zhang"], "title": "Fundamental Models and Signal Processing for Movable Antenna-Enhanced Wireless Communications and Sensing", "categories": ["eess.SP"], "comment": "20 pages, 6 figures, submitted to Chinese Journal of Electronics", "summary": "Movable antenna (MA) has been recognized as a promising technology for\nperformance enhancement in wireless communication and sensing systems by\nexploiting the spatial degrees of freedom (DoFs) in flexible antenna movement.\nHowever, the integration of MAs into next-generation wireless networks still\nfaces design challenges due to the paradigm shift from conventional\nfixed-position antennas (FPAs) to MAs, which motivates this paper to provide a\ncomprehensive overview of the models, scenarios, and signal processing\ntechniques for MA-enhanced wireless networks. First, we introduce several\nefficient methods to realize flexible antenna movement. Next, channel models\nbased on field response and spatial correlation are presented to characterize\nthe channel variations with respect to MA movement. Then, we discuss the\nadvantages and challenges of applying MAs to typical application scenarios of\nwireless communications and sensing. Moreover, we show the signal processing\ntechniques for MA-enhanced communication and sensing systems, including channel\nacquisition and antenna position optimization. Finally, we highlight promising\nresearch directions to inspire future investigations."}
{"id": "2511.04827", "pdf": "https://arxiv.org/pdf/2511.04827", "abs": "https://arxiv.org/abs/2511.04827", "authors": ["Tobias Fischer", "Wolf Vollprecht", "Bas Zalmstra", "Ruben Arts", "Tim de Jager", "Alejandro Fontan", "Adam D Hines", "Michael Milford", "Silvio Traversaro", "Daniel Claes", "Scarlett Raine"], "title": "Pixi: Unified Software Development and Distribution for Robotics and AI", "categories": ["cs.RO", "cs.SE"], "comment": "20 pages, 3 figures, 11 code snippets", "summary": "The reproducibility crisis in scientific computing constrains robotics\nresearch. Existing studies reveal that up to 70% of robotics algorithms cannot\nbe reproduced by independent teams, while many others fail to reach deployment\nbecause creating shareable software environments remains prohibitively complex.\nThese challenges stem from fragmented, multi-language, and hardware-software\ntoolchains that lead to dependency hell. We present Pixi, a unified\npackage-management framework that addresses these issues by capturing exact\ndependency states in project-level lockfiles, ensuring bit-for-bit\nreproducibility across platforms. Its high-performance SAT solver achieves up\nto 10x faster dependency resolution than comparable tools, while integration of\nthe conda-forge and PyPI ecosystems removes the need for multiple managers.\nAdopted in over 5,300 projects since 2023, Pixi reduces setup times from hours\nto minutes and lowers technical barriers for researchers worldwide. By enabling\nscalable, reproducible, collaborative research infrastructure, Pixi accelerates\nprogress in robotics and AI."}
{"id": "2511.05090", "pdf": "https://arxiv.org/pdf/2511.05090", "abs": "https://arxiv.org/abs/2511.05090", "authors": ["Xuan Chen", "Matthieu Crussière", "Luc Le Magoarou"], "title": "Average and Worst-case Analysis of MIMO Beamforming Loss due to Hardware Impairments", "categories": ["eess.SP"], "comment": null, "summary": "In this paper, we investigate the impact of hardware impairments in antenna\narrays on the beamforming performance of multi-input multi-output (MIMO)\ncommunication systems. We consider two types of imperfections: per-element gain\nmismatches and inter-element spacing deviations. We analytically determine the\nimpairment configurations that result in the worst-case degradation. In\naddition, the analytical expression of the average-case performance is also\nderived for comparison. Simulation and theoretical results show that the\naverage SNR degradation remains relatively limited, whereas the worst-case\nscenarios can exhibit substantially higher losses. These findings provide clear\ninsight into the robustness limits of MIMO systems under practical hardware\nimperfections."}
{"id": "2511.04831", "pdf": "https://arxiv.org/pdf/2511.04831", "abs": "https://arxiv.org/abs/2511.04831", "authors": ["NVIDIA", ":", "Mayank Mittal", "Pascal Roth", "James Tigue", "Antoine Richard", "Octi Zhang", "Peter Du", "Antonio Serrano-Muñoz", "Xinjie Yao", "René Zurbrügg", "Nikita Rudin", "Lukasz Wawrzyniak", "Milad Rakhsha", "Alain Denzler", "Eric Heiden", "Ales Borovicka", "Ossama Ahmed", "Iretiayo Akinola", "Abrar Anwar", "Mark T. Carlson", "Ji Yuan Feng", "Animesh Garg", "Renato Gasoto", "Lionel Gulich", "Yijie Guo", "M. Gussert", "Alex Hansen", "Mihir Kulkarni", "Chenran Li", "Wei Liu", "Viktor Makoviychuk", "Grzegorz Malczyk", "Hammad Mazhar", "Masoud Moghani", "Adithyavairavan Murali", "Michael Noseworthy", "Alexander Poddubny", "Nathan Ratliff", "Welf Rehberg", "Clemens Schwarke", "Ritvik Singh", "James Latham Smith", "Bingjie Tang", "Ruchik Thaker", "Matthew Trepte", "Karl Van Wyk", "Fangzhou Yu", "Alex Millane", "Vikram Ramasamy", "Remo Steiner", "Sangeeta Subramanian", "Clemens Volk", "CY Chen", "Neel Jawale", "Ashwin Varghese Kuruttukulam", "Michael A. Lin", "Ajay Mandlekar", "Karsten Patzwaldt", "John Welsh", "Huihua Zhao", "Fatima Anes", "Jean-Francois Lafleche", "Nicolas Moënne-Loccoz", "Soowan Park", "Rob Stepinski", "Dirk Van Gelder", "Chris Amevor", "Jan Carius", "Jumyung Chang", "Anka He Chen", "Pablo de Heras Ciechomski", "Gilles Daviet", "Mohammad Mohajerani", "Julia von Muralt", "Viktor Reutskyy", "Michael Sauter", "Simon Schirm", "Eric L. Shi", "Pierre Terdiman", "Kenny Vilella", "Tobias Widmer", "Gordon Yeoman", "Tiffany Chen", "Sergey Grizan", "Cathy Li", "Lotus Li", "Connor Smith", "Rafael Wiltz", "Kostas Alexis", "Yan Chang", "David Chu", "Linxi \"Jim\" Fan", "Farbod Farshidian", "Ankur Handa", "Spencer Huang", "Marco Hutter", "Yashraj Narang", "Soha Pouya", "Shiwei Sheng", "Yuke Zhu", "Miles Macklin", "Adam Moravanszky", "Philipp Reist", "Yunrong Guo", "David Hoeller", "Gavriel State"], "title": "Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning", "categories": ["cs.RO", "cs.AI"], "comment": "Code and documentation are available here:\n  https://github.com/isaac-sim/IsaacLab", "summary": "We present Isaac Lab, the natural successor to Isaac Gym, which extends the\nparadigm of GPU-native robotics simulation into the era of large-scale\nmulti-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,\nphotorealistic rendering, and a modular, composable architecture for designing\nenvironments and training robot policies. Beyond physics and rendering, the\nframework integrates actuator models, multi-frequency sensor simulation, data\ncollection pipelines, and domain randomization tools, unifying best practices\nfor reinforcement and imitation learning at scale within a single extensible\nplatform. We highlight its application to a diverse set of challenges,\nincluding whole-body control, cross-embodiment mobility, contact-rich and\ndexterous manipulation, and the integration of human demonstrations for skill\nacquisition. Finally, we discuss upcoming integration with the differentiable,\nGPU-accelerated Newton physics engine, which promises new opportunities for\nscalable, data-efficient, and gradient-based approaches to robot learning. We\nbelieve Isaac Lab's combination of advanced simulation capabilities, rich\nsensing, and data-center scale execution will help unlock the next generation\nof breakthroughs in robotics research."}
{"id": "2511.05132", "pdf": "https://arxiv.org/pdf/2511.05132", "abs": "https://arxiv.org/abs/2511.05132", "authors": ["Son Dinh-Van", "Nam Phuong Tran", "Matthew D. Higgins"], "title": "Near-optimal Reconfigurable Intelligent Surface Configuration: Blind Beamforming with Sensing", "categories": ["eess.SP"], "comment": "Under review for IEEE Transactions on Wireless Communications", "summary": "Blind beamforming has emerged as a promising approach to configure\nreconfigurable intelligent surfaces (RISs) without relying on channel state\ninformation (CSI) or geometric models, making it directly compatible with\ncommodity hardware. In this paper, we propose a new blind beamforming\nalgorithm, so-called Blind Optimal RIS Beamforming with Sensing\n(\\textsc{BORN}), that operates using only received signal strength (RSS). In\ncontrast to existing methods that rely on majority-voting mechanisms,\n\\textsc{BORN} exploits the intrinsic quadratic structure of the received\nsignal-to-noise ratio (SNR). The algorithm proceeds in two stages:\n\\emph{sensing}, where a quadratic model is estimated from RSS measurements, and\n\\emph{optimization}, where the RIS configuration is obtained using the\nestimated quadratic model. Our novelties are twofold. Firstly, we show for the\nfirst time, that \\textsc{BORN} can achieve provable near-optimal performance\nusing only $O(N \\log_2(N))$ samples, where $N$ is the number of RIS elements.\nAs a by-product of our analysis, we show that quadratic models are learnable\nunder Rademacher feature distributions when the second-order coefficient matrix\nis low-rank. This result, to our knowledge, has not been established in prior\nmatrix sensing literature. Secondly, extensive simulations and real-world field\ntests demonstrate that \\textsc{BORN} achieves near-optimal performance,\nsubstantially outperforming state-of-the-art blind beamforming algorithms,\nparticularly in scenarios with a weak background channel such as\nnon-line-of-sight (NLOS)."}
{"id": "2511.04835", "pdf": "https://arxiv.org/pdf/2511.04835", "abs": "https://arxiv.org/abs/2511.04835", "authors": ["Shubham Natraj", "Bruno Sinopoli", "Yiannis Kantaros"], "title": "Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning", "categories": ["cs.RO"], "comment": null, "summary": "Sampling-based motion planners (SBMPs) are widely used to compute dynamically\nfeasible robot paths. However, their reliance on uniform sampling often leads\nto poor efficiency and slow planning in complex environments. We introduce a\nnovel non-uniform sampling strategy that integrates into existing SBMPs by\nbiasing sampling toward `certified' regions. These regions are constructed by\n(i) generating an initial, possibly infeasible, path using any heuristic path\npredictor (e.g., A* or vision-language models) and (ii) applying conformal\nprediction to quantify the predictor's uncertainty. This process yields\nprediction sets around the initial-guess path that are guaranteed, with\nuser-specified probability, to contain the optimal solution. To our knowledge,\nthis is the first non-uniform sampling approach for SBMPs that provides such\nprobabilistically correct guarantees on the sampling regions. Extensive\nevaluations demonstrate that our method consistently finds feasible paths\nfaster and generalizes better to unseen environments than existing baselines."}
{"id": "2511.05195", "pdf": "https://arxiv.org/pdf/2511.05195", "abs": "https://arxiv.org/abs/2511.05195", "authors": ["Yunxin Li", "Fan Liu", "Haoqiu Xiong", "Zhenkun Wang", "Narengerile", "Christos Masouros"], "title": "Look Before Switch: Sensing-Assisted Handover in 5G NR V2I Networks", "categories": ["eess.SP"], "comment": "15 pages, 9 figures", "summary": "Integrated Sensing and Communication (ISAC) has emerged as a promising\nsolution in addressing the challenges of high-mobility scenarios in 5G NR\nVehicle-to-Infrastructure (V2I) communications. This paper proposes a novel\nsensing-assisted handover framework that leverages ISAC capabilities to enable\nprecise beamforming and proactive handover decisions. Two sensing-enabled\nhandover triggering algorithms are developed: a distance-based scheme that\nutilizes estimated spatial positioning, and a probability-based approach that\npredicts vehicle maneuvers using interacting multiple model extended Kalman\nfilter (IMM-EKF) tracking. The proposed methods eliminate the need for uplink\nfeedback and beam sweeping, thus significantly reducing signaling overhead and\nhandover interruption time. A sensing-assisted NR frame structure and\ncorresponding protocol design are also introduced to support rapid\nsynchronization and access under vehicular mobility. Extensive link-level\nsimulations using real-world map data demonstrate that the proposed framework\nreduces the average handover interruption time by over 50%, achieves lower\nhandover rates, and enhances overall communication performance."}
{"id": "2511.04837", "pdf": "https://arxiv.org/pdf/2511.04837", "abs": "https://arxiv.org/abs/2511.04837", "authors": ["Cameron Robinson", "Ganghee Jang"], "title": "Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions", "categories": ["cs.RO"], "comment": "4 pages, 3 figures (5 assets)", "summary": "Solar energy is used for many mission-critical applications including space\nexploration, sensor systems to monitor wildfires, etc. Their operation can be\nlimited or even terminated if solar panels are covered with dust or hit by\nspace debris. To address this issue, we designed panel cleaning mechanisms and\ntested protective materials. For cleaning mechanisms, we designed and compared\na wiper system and a rail system. For protective materials, we found through\ncollision tests that polycarbonate was very promising, though the most\nimportant factor was layering a soft material between the panel's surface and a\nhard material. In the cleaning system comparisons, the wiper-based system was\nmore efficient than the rail-based system in terms of cost, cleaning speed, and\ntotal power consumption."}
{"id": "2511.05204", "pdf": "https://arxiv.org/pdf/2511.05204", "abs": "https://arxiv.org/abs/2511.05204", "authors": ["Andrea Bedin", "Joerg Widmer", "Melanny Davila", "Marco Canil", "Rafael Ruiz"], "title": "Millimeter-Scale Absolute Carrier Phase-Based Localization in Multi-Band Systems", "categories": ["eess.SP"], "comment": "14 pages, 22 figures, Accepted for publication at SenSys 2026", "summary": "Localization is a key feature of future Sixth Generation (6G) net-works with\nforeseen accuracy requirements down to the millimeter level, to enable novel\napplications in the fields of telesurgery, high-precision manufacturing, and\nothers. Currently, such accuracy requirements are only achievable with\nspecialized or highly resource-demanding systems, rendering them impractical\nfor more wide-spread deployment. In this paper, we present the first system\nthat enables low-complexity and low-bandwidth absolute 3D localization with\nmillimeter-level accuracy in generic wireless networks. It performs a carrier\nphase-based wireless localization refinement of an initial location estimate\nbased on successive location-likelihood optimization across multiple bands.\nUnlike previous phase unwrapping methods, our solution is one-shot. We evaluate\nits performance collecting ~350, 000 measurements, showing an improvement of\nmore than one order of magnitude over classical localization techniques.\nFinally, we will open-source the low-cost, modular FR3 front-end that we\ndeveloped for the experimental campaign."}
{"id": "2511.04976", "pdf": "https://arxiv.org/pdf/2511.04976", "abs": "https://arxiv.org/abs/2511.04976", "authors": ["Xin Nie", "Zhiyuan Cheng", "Yuan Zhang", "Chao Ji", "Jiajia Wu", "Yuhan Zhang", "Jia Pan"], "title": "iFlyBot-VLM Technical Report", "categories": ["cs.RO"], "comment": null, "summary": "We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used\nto improve the domain of Embodied Intelligence. The central objective of\niFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional\nenvironmental perception and low-level robotic motion control. To this end, the\nmodel abstracts complex visual and spatial information into a body-agnostic and\ntransferable Operational Language, thereby enabling seamless perception-action\nclosed-loop coordination across diverse robotic platforms. The architecture of\niFlyBot-VLM is systematically designed to realize four key functional\ncapabilities essential for embodied intelligence: 1) Spatial Understanding and\nMetric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and\nControl Parameter Generation; 4) Task Planning and Skill Sequencing. We\nenvision iFlyBot-VLM as a scalable and generalizable foundation model for\nembodied AI, facilitating the progression from specialized task-oriented\nsystems toward generalist, cognitively capable agents. We conducted evaluations\non 10 current mainstream embodied intelligence-related VLM benchmark datasets,\nsuch as Blink and Where2Place, and achieved optimal performance while\npreserving the model's general capabilities. We will publicly release both the\ntraining data and model weights to foster further research and development in\nthe field of Embodied Intelligence."}
{"id": "2511.05298", "pdf": "https://arxiv.org/pdf/2511.05298", "abs": "https://arxiv.org/abs/2511.05298", "authors": ["Emiel Vanspranghels", "Raquel Marina Noguera Oishi", "Franco Minucci", "Sofie Pollin"], "title": "Location-Informed Interference Suppression Precoding Methods for Distributed Massive MIMO Systems", "categories": ["eess.SP"], "comment": "7 pages, 9 figures", "summary": "The evolution of mobile networks towards user-centric cell-free distributed\nMassive MIMO configurations requires the development of novel signal processing\ntechniques. More specifically, digital precoding algorithms have to be designed\nor adopted to enable distributed operation. Future deployments are expected to\nimprove coexistence between cellular generations, and between mobile networks\nand incumbent services such as radar. In dense cell-free deployments, it might\nalso not be possible to have full channel state information for all users at\nall antennas. To leverage location information in a dense deployment area, we\nsuggest and investigate several algorithmic alterations on existing precoding\nmethods, aimed at location-informed interference suppression, for usage in\nexisting and emerging systems where user locations are known. The proposed\nalgorithms are derived using a theoretical channel model and validated and\nnumerically evaluated using an empirical dataset containing channel\nmeasurements from an indoor distributed Massive MIMO testbed. When dealing with\nmeasured CSI, the impact of the hardware, in addition to the location-based\nchannel, needs to be compensated for. We propose a method to calibrate the\nhardware and achieve measurement-based evaluation of our location-based\ninterference suppression algorithms. The results demonstrate that the proposed\nmethods allow location-based interference suppression without explicit CSI\nknowledge at the transmitter, under certain realistic network conditions."}
{"id": "2511.04992", "pdf": "https://arxiv.org/pdf/2511.04992", "abs": "https://arxiv.org/abs/2511.04992", "authors": ["Bibekananda Patra", "Sandipan Bandyopadhyay"], "title": "A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces", "categories": ["cs.RO"], "comment": null, "summary": "This article presents a method for computing the largest singularity-free\nsphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a\nspecified orientation workspace. For a fixed orientation of the moving\nplatform, the SFS is computed analytically. This process is repeated over a set\nof samples generated within the orientation workspace, and the smallest among\nthem is designated as the desired SFS for the given orientation workspace.\nNumerical experiments are performed on four distinct architectures of the SGPM\nto understand their relative performances w.r.t. SFS volumes over the same\norientation workspace. This study demonstrates the potential utility of the\nproposed computational method both in analysis and design of SGPMs."}
{"id": "2511.04940", "pdf": "https://arxiv.org/pdf/2511.04940", "abs": "https://arxiv.org/abs/2511.04940", "authors": ["Jiachen Shen", "Jian Shi", "Lei Fan", "Chenye Wu", "Dan Wang", "Choong Seon Hong", "Zhu Han"], "title": "Strategic Decision-Making Under Uncertainty through Bi-Level Game Theory and Distributionally Robust Optimization", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": null, "summary": "In strategic scenarios where decision-makers operate at different\nhierarchical levels, traditional optimization methods are often inadequate for\nhandling uncertainties from incomplete information or unpredictable external\nfactors. To fill this gap, we introduce a mathematical framework that\nintegrates bi-level game theory with distributionally robust optimization\n(DRO), particularly suited for complex network systems. Our approach leverages\nthe hierarchical structure of bi-level games to model leader-follower\ninteractions while incorporating distributional robustness to guard against\nworst-case probability distributions. To ensure computational tractability, the\nKarush-Kuhn-Tucker (KKT) conditions are used to transform the bi-level\nchallenge into a more manageable single-level model, and the\ninfinite-dimensional DRO problem is reformulated into a finite equivalent. We\npropose a generalized algorithm to solve this integrated model. Simulation\nresults validate our framework's efficacy, demonstrating that under high\nuncertainty, the proposed model achieves up to a 22\\% cost reduction compared\nto traditional stochastic methods while maintaining a service level of over\n90\\%. This highlights its potential to significantly improve decision quality\nand robustness in networked systems such as transportation and communication\nnetworks."}
{"id": "2511.04994", "pdf": "https://arxiv.org/pdf/2511.04994", "abs": "https://arxiv.org/abs/2511.04994", "authors": ["Xingyuan Zhou", "Peter Paik", "S. Farokh Atashzar"], "title": "Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems", "categories": ["cs.RO"], "comment": null, "summary": "Maintaining system stability and accurate position tracking is imperative in\nnetworked robotic systems, particularly for haptics-enabled human-robot\ninteraction. Recent literature has integrated human biomechanics into the\nstabilizers implemented for teleoperation, enhancing force preservation while\nguaranteeing convergence and safety. However, position desynchronization due to\nimperfect communication and non-passive behaviors remains a challenge. This\npaper proposes a two-port biomechanics-aware passivity-based synchronizer and\nstabilizer, referred to as TBPS2. This stabilizer optimizes position\nsynchronization by leveraging human biomechanics while reducing the\nstabilizer's conservatism in its activation. We provide the mathematical design\nsynthesis of the stabilizer and the proof of stability. We also conducted a\nseries of grid simulations and systematic experiments, comparing their\nperformance with that of state-of-the-art solutions under varying time delays\nand environmental conditions."}
{"id": "2511.04983", "pdf": "https://arxiv.org/pdf/2511.04983", "abs": "https://arxiv.org/abs/2511.04983", "authors": ["Assma Habadi", "Milos Zefran", "Lijuan Yin", "Woojin Song", "Maria Caceres", "Elise Hu", "Naoko Muramatsu"], "title": "Predicting Cognitive Assessment Scores in Older Adults with Cognitive Impairment Using Wearable Sensors", "categories": ["q-bio.NC", "cs.LG", "eess.SP"], "comment": "40 pages, 2 figures, 3 tables; Supplementary Material: 3 tables\n  (S1-S3). Presented as a poster at the Gerontological Society of America (GSA)\n  Annual Scientific Meeting, November 2025", "summary": "Background and Objectives: This paper focuses on using AI to assess the\ncognitive function of older adults with mild cognitive impairment or mild\ndementia using physiological data provided by a wearable device. Cognitive\nscreening tools are disruptive, time-consuming, and only capture brief\nsnapshots of activity. Wearable sensors offer an attractive alternative by\ncontinuously monitoring physiological signals. This study investigated whether\nphysiological data can accurately predict scores on established cognitive\ntests. Research Design and Methods: We recorded physiological signals from 23\nolder adults completing three NIH Toolbox Cognitive Battery tests, which assess\nworking memory, processing speed, and attention. The Empatica EmbracePlus, a\nwearable device, measured blood volume pulse, skin conductance, temperature,\nand movement. Statistical features were extracted using wavelet-based and\nsegmentation methods. We then applied supervised learning and validated\npredictions via cross-validation, hold-out testing, and bootstrapping. Results:\nOur models showed strong performance with Spearman's \\rho of 0.73-0.82 and mean\nabsolute errors of 0.14-0.16, significantly outperforming a naive mean\npredictor. Sensor roles varied: heart-related signals combined with movement\nand temperature best predicted working memory, movement paired with skin\nconductance was most informative for processing speed, and heart in tandem with\nskin conductance worked best for attention. Discussion and Implications: These\nfindings suggest that wearable sensors paired with AI tools such as supervised\nlearning and feature engineering can noninvasively track specific cognitive\nfunctions in older adults, enabling continuous monitoring. Our study\ndemonstrates how AI can be leveraged when the data sample is small. This\napproach may support remote assessments and facilitate clinical interventions."}
{"id": "2511.05007", "pdf": "https://arxiv.org/pdf/2511.05007", "abs": "https://arxiv.org/abs/2511.05007", "authors": ["Baiye Cheng", "Tianhai Liang", "Suning Huang", "Maanping Shao", "Feihong Zhang", "Botian Xu", "Zhengrong Xue", "Huazhe Xu"], "title": "MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery", "categories": ["cs.RO"], "comment": null, "summary": "Diffusion policies have emerged as a powerful framework for robotic\nvisuomotor control, yet they often lack the robustness to recover from subtask\nfailures in long-horizon, multi-stage tasks and their learned representations\nof observations are often difficult to interpret. In this work, we propose the\nMixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is\nto insert a Mixture of Experts (MoE) layer between the visual encoder and the\ndiffusion model. This layer decomposes the policy's knowledge into a set of\nspecialized experts, which are dynamically activated to handle different phases\nof a task. We demonstrate through extensive experiments that MoE-DP exhibits a\nstrong capability to recover from disturbances, significantly outperforming\nstandard baselines in robustness. On a suite of 6 long-horizon simulation\ntasks, this leads to a 36% average relative improvement in success rate under\ndisturbed conditions. This enhanced robustness is further validated in the real\nworld, where MoE-DP also shows significant performance gains. We further show\nthat MoE-DP learns an interpretable skill decomposition, where distinct experts\ncorrespond to semantic task primitives (e.g., approaching, grasping). This\nlearned structure can be leveraged for inference-time control, allowing for the\nrearrangement of subtasks without any re-training.Our video and code are\navailable at the https://moe-dp-website.github.io/MoE-DP-Website/."}
{"id": "2511.05173", "pdf": "https://arxiv.org/pdf/2511.05173", "abs": "https://arxiv.org/abs/2511.05173", "authors": ["Sushil Kumar", "Soumya P. Dash", "George C. Alexandropoulos"], "title": "Performance Analysis of One- and Two-way DV-QKD with MIMO FSO Communication Systems", "categories": ["quant-ph", "eess.SP"], "comment": "6 pages, 3 figures", "summary": "This paper considers a multiple-input multiple-output (MIMO) wireless system\nwherein two legitimate users attempt to exchange secret keys over free-space\noptical (FSO) channels. Novel frameworks for the use of the one- and two-way\ndiscrete-variable quantum key distribution (DV-QKD) protocols, employing weak\ncoherent pulses and decoy states, are presented. Focusing on the case where a\nphoton-number-splitting attack is adopted by the eavesdropper and the\nlegitimate multi-antenna receiver using threshold detection for the key\nextraction, novel expressions for the secret key rate and quantum bit error\nrate for both one- and two-way protocols are derived. The performance gain with\nlarger MIMO configurations and the tradeoff between the performances with the\none- and the two-way protocols with respect to the transmission distance of the\nlegitimate FSO link are numerically assessed."}
{"id": "2511.05026", "pdf": "https://arxiv.org/pdf/2511.05026", "abs": "https://arxiv.org/abs/2511.05026", "authors": ["Xingyuan Zhou", "Peter Paik", "S. Farokh Atashzar"], "title": "Tunable Passivity Control for Centralized Multiport Networked Systems", "categories": ["cs.RO"], "comment": null, "summary": "Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key\narchitecture with applications in several complex network systems, such as\nmultilateral telerobotics and multi-agent control. These systems consist of a\nhub node/subsystem connecting with multiple remote nodes/subsystems via a\nnetworked architecture. One challenge for this system is stability, which can\nbe affected by non-ideal network artifacts. Conventional passivity-based\napproaches can stabilize the system under specialized applications like\nsmall-scale networked systems. However, those conventional passive stabilizers\nhave several restrictions, such as distributing compensation across subsystems\nin a decentralized manner, limiting flexibility, and, at the same time, relying\non the restrictive assumptions of node passivity. This paper synthesizes a\ncentralized optimal passivity-based stabilization framework for CMND systems.\nIt consists of a centralized passivity observer monitoring overall energy flow\nand an optimal passivity controller that distributes the just-needed\ndissipation among various nodes, guaranteeing strict passivity and, thus, L2\nstability. The proposed data-driven model-free approach, i.e., Tunable\nCentralized Optimal Passivity Control (TCoPC), optimizes total performance\nbased on the prescribed dissipation distribution strategy while ensuring\nstability. The controller can put high dissipation loads on some sub-networks\nwhile relaxing the dissipation on other nodes. Simulation results demonstrate\nthe proposed frameworks performance in a complex task under different\ntime-varying delay scenarios while relaxing the remote nodes minimum phase and\npassivity assumption, enhancing the scalability and generalizability."}
{"id": "2511.05228", "pdf": "https://arxiv.org/pdf/2511.05228", "abs": "https://arxiv.org/abs/2511.05228", "authors": ["Dhrumil Bhatt", "Vidushi Kumar"], "title": "Adaptive Entanglement-Aware Routing for Satellite Quantum Networks under Orbital and Atmospheric Variability", "categories": ["quant-ph", "eess.SP"], "comment": null, "summary": "The expansion of satellite-based quantum networks requires adaptive routing\nmechanisms that can sustain entanglement under dynamic orbital and atmospheric\nconditions. Conventional schemes, often tailored to static or idealised\ntopologies, fail to capture the combined effects of orbital motion, fading, and\ntrust variability in inter-satellite links. This work proposes an\n\\textit{adaptive entanglement-aware routing framework} that jointly accounts\nfor orbital geometry, atmospheric attenuation, and multi-parameter link\nevaluation. The routing metric integrates fidelity, trust, and key-rate weights\nto maintain connectivity and mitigate loss from turbulence and fading. Monte\nCarlo simulations across multiple orbital densities ($\\rho =\n10^{-6}$~km$^{-3}$) and environmental regimes, standard atmosphere, strong\nturbulence, and clear-sky LEO show up to a 275\\% improvement in key generation\nrate and a 15\\% increase in effective entanglement fidelity over existing\nadaptive methods. The framework achieves sub-linear path-length scaling with\nnetwork size and remains robust for fading variances up to\n$\\sigma_{\\mathrm{fade}}=0.1$, demonstrating strong potential for future global\nquantum constellations."}
{"id": "2511.05033", "pdf": "https://arxiv.org/pdf/2511.05033", "abs": "https://arxiv.org/abs/2511.05033", "authors": ["Jennifer K. Leestma", "Siddharth R. Nathella", "Christoph P. O. Nuesslein", "Snehil Mathur", "Gregory S. Sawicki", "Aaron J. Young"], "title": "Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems", "categories": ["cs.RO"], "comment": "11 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Epically Powerful is an open-source robotics infrastructure that streamlines\nthe underlying framework of wearable robotic systems - managing communication\nprotocols, clocking, actuator commands, visualization, sensor data acquisition,\ndata logging, and more - while also providing comprehensive guides for hardware\nselection, system assembly, and controller implementation. Epically Powerful\ncontains a code base enabling simplified user implementation via Python that\nseamlessly interfaces with various commercial state-of-the-art quasi-direct\ndrive (QDD) actuators, single-board computers, and common sensors, provides\nexample controllers, and enables real-time visualization. To further support\ndevice development, the package also includes a recommended parts list and\ncompatibility guide and detailed documentation on hardware and software\nimplementation. The goal of Epically Powerful is to lower the barrier to\ndeveloping and deploying custom wearable robotic systems without a\npre-specified form factor, enabling researchers to go from raw hardware to\nmodular, robust devices quickly and effectively. Though originally designed\nwith wearable robotics in mind, Epically Powerful is broadly applicable to\nother robotic domains that utilize QDD actuators, single-board computers, and\nsensors for closed-loop control."}
{"id": "2511.05052", "pdf": "https://arxiv.org/pdf/2511.05052", "abs": "https://arxiv.org/abs/2511.05052", "authors": ["Zihao Li", "Yiming Zhu", "Zhe Zhong", "Qinyuan Ren", "Yijiang Huang"], "title": "TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Robotic manipulation in complex, constrained spaces is vital for widespread\napplications but challenging, particularly when navigating narrow passages with\nelongated objects. Existing planning methods often fail in these low-clearance\nscenarios due to the sampling difficulties or the local minima. This work\nproposes Topology-Aware Planning for Object Manipulation (TAPOM), which\nexplicitly incorporates task-space topological analysis to enable efficient\nplanning. TAPOM uses a high-level analysis to identify critical pathways and\ngenerate guiding keyframes, which are utilized in a low-level planner to find\nfeasible configuration space trajectories. Experimental validation demonstrates\nsignificantly high success rates and improved efficiency over state-of-the-art\nmethods on low-clearance manipulation tasks. This approach offers broad\nimplications for enhancing manipulation capabilities of robots in complex\nreal-world environments."}
{"id": "2511.05129", "pdf": "https://arxiv.org/pdf/2511.05129", "abs": "https://arxiv.org/abs/2511.05129", "authors": ["Bin Fan", "Jianjian Jiang", "Zhuohao Li", "Yixiang He", "Xiaoming Wu", "Yihan Yang", "Shengbang Liu", "Weishi Zheng"], "title": "Decomposed Object Manipulation via Dual-Actor Policy", "categories": ["cs.RO"], "comment": "9 pages, 7 figures, 5 tables", "summary": "Object manipulation, which focuses on learning to perform tasks on similar\nparts across different types of objects, can be divided into an approaching\nstage and a manipulation stage. However, previous works often ignore this\ncharacteristic of the task and rely on a single policy to directly learn the\nwhole process of object manipulation. To address this problem, we propose a\nnovel Dual-Actor Policy, termed DAP, which explicitly considers different\nstages and leverages heterogeneous visual priors to enhance each stage.\nSpecifically, we introduce an affordance-based actor to locate the functional\npart in the manipulation task, thereby improving the approaching process.\nFollowing this, we propose a motion flow-based actor to capture the movement of\nthe component, facilitating the manipulation process. Finally, we introduce a\ndecision maker to determine the current stage of DAP and select the\ncorresponding actor. Moreover, existing object manipulation datasets contain\nfew objects and lack the visual priors needed to support training. To address\nthis, we construct a simulated dataset, the Dual-Prior Object Manipulation\nDataset, which combines the two visual priors and includes seven tasks,\nincluding two challenging long-term, multi-stage tasks. Experimental results on\nour dataset, the RoboTwin benchmark and real-world scenarios illustrate that\nour method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%\non average respectively."}
{"id": "2511.05158", "pdf": "https://arxiv.org/pdf/2511.05158", "abs": "https://arxiv.org/abs/2511.05158", "authors": ["Sahar Salimpour", "Iacopo Catalano", "Tomi Westerlund", "Mohsen Falahi", "Jorge Peña Queralta"], "title": "Follow-Me in Micro-Mobility with End-to-End Imitation Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Autonomous micro-mobility platforms face challenges from the perspective of\nthe typical deployment environment: large indoor spaces or urban areas that are\npotentially crowded and highly dynamic. While social navigation algorithms have\nprogressed significantly, optimizing user comfort and overall user experience\nover other typical metrics in robotics (e.g., time or distance traveled) is\nunderstudied. Specifically, these metrics are critical in commercial\napplications. In this paper, we show how imitation learning delivers smoother\nand overall better controllers, versus previously used manually-tuned\ncontrollers. We demonstrate how DAAV's autonomous wheelchair achieves\nstate-of-the-art comfort in follow-me mode, in which it follows a human\noperator assisting persons with reduced mobility (PRM). This paper analyzes\ndifferent neural network architectures for end-to-end control and demonstrates\ntheir usability in real-world production-level deployments."}
{"id": "2511.05185", "pdf": "https://arxiv.org/pdf/2511.05185", "abs": "https://arxiv.org/abs/2511.05185", "authors": ["Adrián Campazas-Vega", "Claudia Álvarez-Aparicio", "David Sobrín-Hidalgo", "Laura Inyesto-Alonso", "Francisco Javier Rodríguez-Lera", "Vicente Matellán-Olivera", "Ángel Manuel Guerrero-Higueras"], "title": "Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones", "categories": ["cs.RO", "cs.CR"], "comment": "32 pages, in Spanish language, 7 tables, 12 Figures. White paper\n  under the TESCAC project", "summary": "The deployment of autonomous systems has experienced remarkable growth in\nrecent years, driven by their integration into sectors such as industry,\nmedicine, logistics, and domestic environments. This expansion is accompanied\nby a series of security issues that entail significant risks due to the\ncritical nature of autonomous systems, especially those operating in\nhuman-interaction environments. Furthermore, technological advancement and the\nhigh operational and architectural complexity of autonomous systems have\nresulted in an increased attack surface. This article presents a specific\nsecurity auditing procedure for autonomous systems, based on a layer-structured\nmethodology, a threat taxonomy adapted to the robotic context, and a set of\nconcrete mitigation measures. The validity of the proposed approach is\ndemonstrated through four practical case studies applied to representative\nrobotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1\nrobot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,\nand the Pepper social robot from Aldebaran Robotics."}
{"id": "2511.05199", "pdf": "https://arxiv.org/pdf/2511.05199", "abs": "https://arxiv.org/abs/2511.05199", "authors": ["Yichen Zhu", "Feifei Feng"], "title": "Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation", "categories": ["cs.RO"], "comment": "Accepted by IROS 2025", "summary": "Robots operating in complex and uncertain environments face considerable\nchallenges. Advanced robotic systems often rely on extensive datasets to learn\nmanipulation tasks. In contrast, when humans are faced with unfamiliar tasks,\nsuch as assembling a chair, a common approach is to learn by watching video\ndemonstrations. In this paper, we propose a novel method for learning robot\npolicies by Retrieving-from-Video (RfV), using analogies from human\ndemonstrations to address manipulation tasks. Our system constructs a video\nbank comprising recordings of humans performing diverse daily tasks. To enrich\nthe knowledge from these videos, we extract mid-level information, such as\nobject affordance masks and hand motion trajectories, which serve as additional\ninputs to enhance the robot model's learning and generalization capabilities.\nWe further feature a dual-component system: a video retriever that taps into an\nexternal video bank to fetch task-relevant video based on task specification,\nand a policy generator that integrates this retrieved knowledge into the\nlearning cycle. This approach enables robots to craft adaptive responses to\nvarious scenarios and generalize to tasks beyond those in the training data.\nThrough rigorous testing in multiple simulated and real-world settings, our\nsystem demonstrates a marked improvement in performance over conventional\nrobotic systems, showcasing a significant breakthrough in the field of\nrobotics."}
{"id": "2511.05203", "pdf": "https://arxiv.org/pdf/2511.05203", "abs": "https://arxiv.org/abs/2511.05203", "authors": ["Linus Nwankwo", "Björn Ellensohn", "Christian Rauch", "Elmar Rueckert"], "title": "Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space", "categories": ["cs.RO"], "comment": null, "summary": "Today's autonomous agents can understand free-form natural language\ninstructions and execute long-horizon tasks in a manner akin to human-level\nreasoning. These capabilities are mostly driven by large-scale pre-trained\nfoundation models (FMs). However, the approaches with which these models are\ngrounded for human-robot interaction (HRI) perpetuate a master-apprentice\nmodel, where the apprentice (embodied agent) passively receives and executes\nthe master's (human's) commands without reciprocal learning. This reactive\ninteraction approach does not capture the co-adaptive dynamics inherent in\neveryday multi-turn human-human interactions. To address this, we propose a\nSymbiotic Interactive Learning (SIL) approach that enables both the master and\nthe apprentice to co-adapt through mutual, bidirectional interactions. We\nformalised SIL as a co-adaptation process within a shared latent task space,\nwhere the agent and human maintain joint belief states that evolve based on\ninteraction history. This enables the agent to move beyond reactive execution\nto proactive clarification, adaptive suggestions, and shared plan refinement.\nTo realise these novel behaviours, we leveraged pre-trained FMs for spatial\nperception and reasoning, alongside a lightweight latent encoder that grounds\nthe models' outputs into task-specific representations. Furthermore, to ensure\nstability as the tasks evolve, we augment SIL with a memory architecture that\nprevents the forgetting of learned task-space representations. We validate SIL\non both simulated and real-world embodied tasks, including instruction\nfollowing, information retrieval, query-oriented reasoning, and interactive\ndialogues. Demos and resources are public\nat:~\\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}."}
{"id": "2511.05234", "pdf": "https://arxiv.org/pdf/2511.05234", "abs": "https://arxiv.org/abs/2511.05234", "authors": ["Philipp Dahlinger", "Niklas Freymuth", "Tai Hoang", "Tobias Würth", "Michael Volpp", "Luise Kärger", "Gerhard Neumann"], "title": "Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning", "categories": ["cs.RO", "cs.LG"], "comment": "35 pages. Submitted to Transactions on Machine Learning Research\n  (TMLR)", "summary": "Simulating object deformations is a critical challenge across many scientific\ndomains, including robotics, manufacturing, and structural mechanics. Learned\nGraph Network Simulators (GNSs) offer a promising alternative to traditional\nmesh-based physics simulators. Their speed and inherent differentiability make\nthem particularly well suited for applications that require fast and accurate\nsimulations, such as robotic manipulation or manufacturing optimization.\nHowever, existing learned simulators typically rely on single-step\nobservations, which limits their ability to exploit temporal context. Without\nthis information, these models fail to infer, e.g., material properties.\nFurther, they rely on auto-regressive rollouts, which quickly accumulate error\nfor long trajectories. We instead frame mesh-based simulation as a\ntrajectory-level meta-learning problem. Using Conditional Neural Processes, our\nmethod enables rapid adaptation to new simulation scenarios from limited\ninitial data while capturing their latent simulation properties. We utilize\nmovement primitives to directly predict fast, stable and accurate simulations\nfrom a single model call. The resulting approach, Movement-primitive\nMeta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of\nthe runtime cost compared to state-of-the-art GNSs across several tasks."}
{"id": "2511.05275", "pdf": "https://arxiv.org/pdf/2511.05275", "abs": "https://arxiv.org/abs/2511.05275", "authors": ["Hokyun Im", "Euijin Jeong", "Jianlong Fu", "Andrey Kolobov", "Youngwoon Lee"], "title": "TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models", "categories": ["cs.RO", "cs.LG"], "comment": "Project webpage : https://jellyho.github.io/TwinVLA/", "summary": "Vision-language-action models (VLAs) trained on large-scale robotic datasets\nhave demonstrated strong performance on manipulation tasks, including bimanual\ntasks. However, because most public datasets focus on single-arm\ndemonstrations, adapting VLAs for bimanual tasks typically requires substantial\nadditional bimanual data and fine-tuning. To address this challenge, we\nintroduce TwinVLA, a modular framework that composes two copies of a pretrained\nsingle-arm VLA into a coordinated bimanual VLA. Unlike monolithic\ncross-embodiment models trained on mixtures of single-arm and bimanual data,\nTwinVLA improves both data efficiency and performance by composing pretrained\nsingle-arm policies. Across diverse bimanual tasks in real-world and simulation\nsettings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model\nwithout requiring any bimanual pretraining. Furthermore, it narrows the gap to\nstate-of-the-art model, $\\pi_0$ which rely on extensive proprietary bimanual\ndata and compute cost. These results establish our modular composition approach\nas a data-efficient and scalable path toward high-performance bimanual\nmanipulation, leveraging public single-arm data."}
{"id": "2511.05307", "pdf": "https://arxiv.org/pdf/2511.05307", "abs": "https://arxiv.org/abs/2511.05307", "authors": ["Akua K. Dickson", "Juan C. Pacheco Garcia", "Andrew P. Sabelhaus"], "title": "Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Soft robot manipulators have the potential for deployment in delicate\nenvironments to perform complex manipulation tasks. However, existing obstacle\ndetection and avoidance methods do not consider limits on the forces that\nmanipulators may exert upon contact with delicate obstacles. This work\nintroduces a framework that maps force safety criteria from task space (i.e.\npositions along the robot's body) to configuration space (i.e. the robot's\njoint angles) and enables real-time force safety detection. We incorporate\nlimits on allowable environmental contact forces for given task-space\nobstacles, and map them into configuration space (C-space) through the\nmanipulator's forward kinematics. This formulation ensures that configurations\nclassified as safe are provably below the maximum force thresholds, thereby\nallowing us to determine force-safe configurations of the soft robot\nmanipulator in real-time. We validate our approach in simulation and hardware\nexperiments on a two-segment pneumatic soft robot manipulator. Results\ndemonstrate that the proposed method accurately detects force safety during\ninteractions with deformable obstacles, thereby laying the foundation for\nreal-time safe planning of soft manipulators in delicate, cluttered\nenvironments."}
{"id": "2511.05379", "pdf": "https://arxiv.org/pdf/2511.05379", "abs": "https://arxiv.org/abs/2511.05379", "authors": ["Eric Godden", "Jacquie Groenewegen", "Matthew K. X. J. Pan"], "title": "ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "8 pages", "summary": "We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),\na dynamic encountered-type haptic display (ETHD) that enables natural physical\ncontact in virtual reality (VR) during social interactions such as handovers,\nfist bumps, and high-fives. The system integrates a torque-controlled robotic\nmanipulator with interchangeable passive props (silicone hand replicas and a\nbaton), marker-based physical-virtual registration via a ChArUco board, and a\nsafety monitor that gates motion based on the user's head and hand pose. We\nintroduce two control strategies: (i) a static mode that presents a stationary\nprop aligned with its virtual counterpart, consistent with prior ETHD\nbaselines, and (ii) a dynamic mode that continuously updates prop position by\nexponentially blending an initial mid-point trajectory with real-time hand\ntracking, generating a unique contact point for each interaction. Bench tests\nshow static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions\nachieved temporal alignment with an average contact latency of 28.53 +/- 31.21\nms across all interaction and control conditions. These results demonstrate the\nfeasibility of recreating socially meaningful haptics in VR. By incorporating\nessential safety and control mechanisms, ETHOS establishes a practical\nfoundation for high-fidelity, dynamic interpersonal interactions in virtual\nenvironments."}
{"id": "2511.05397", "pdf": "https://arxiv.org/pdf/2511.05397", "abs": "https://arxiv.org/abs/2511.05397", "authors": ["Samarth Chopra", "Alex McMoil", "Ben Carnovale", "Evan Sokolson", "Rajkumar Kubendran", "Samuel Dickerson"], "title": "EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Submitted to ICRA 2026", "summary": "While Vision-Language-Action (VLA) models map visual inputs and language\ninstructions directly to robot actions, they often rely on costly hardware and\nstruggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF\nmanipulator that can be assembled for under $300, capable of modest payloads\nand workspace. A single unified model jointly outputs discrete and continuous\nactions, and our adaptive-horizon ensemble monitors motion uncertainty to\ntrigger on-the-fly re-planning for safe, reliable operation. On LIBERO,\nEverydayVLA matches state-of-the-art success rates, and in real-world tests it\noutperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.\nBy combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA\ndemocratizes access to a robotic foundation model and paves the way for\neconomical use in homes and research labs alike. Experiment videos and details:\nhttps://everydayvla.github.io/"}
{"id": "2511.05402", "pdf": "https://arxiv.org/pdf/2511.05402", "abs": "https://arxiv.org/abs/2511.05402", "authors": ["Muhammad Saud Ul Hassan", "Derek Vasquez", "Hamza Asif", "Christian Hubicki"], "title": "Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications", "categories": ["cs.RO"], "comment": null, "summary": "In this paper, we present an energy-conservation based control architecture\nfor stable dynamic motion in quadruped robots. We model the robot as a\nSpring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the\nbouncing motion characteristic of running gaits observed in various biological\nquadrupeds and bio-inspired robotic systems. The model permits leg-orientation\ncontrol during flight and leg-length control during stance, a design choice\ninspired by natural quadruped behaviors and prevalent in robotic quadruped\nsystems. Our control algorithm uses the reduced-order SLIP dynamics of the\nquadruped to track a stable parabolic spline during stance, which is calculated\nusing the principle of energy conservation. Through simulations based on the\ndesign specifications of an actual quadruped robot, Ghost Robotics Minitaur, we\ndemonstrate that our control algorithm generates stable bouncing gaits.\nAdditionally, we illustrate the robustness of our controller by showcasing its\nability to maintain stable bouncing even when faced with up to a 10% error in\nsensor measurements."}
{"id": "2511.05426", "pdf": "https://arxiv.org/pdf/2511.05426", "abs": "https://arxiv.org/abs/2511.05426", "authors": ["Luca Girardi", "Gabriel Maquignaz", "Stefano Mintchev"], "title": "Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience", "categories": ["cs.RO", "J.2"], "comment": "26 pages, 12 figures, 2 tables, 9 videos (not yet disclosed, awaiting\n  peer review)", "summary": "Natural flyers use soft wings to seamlessly enable a wide range of flight\nbehaviours, including agile manoeuvres, squeezing through narrow passageways,\nand withstanding collisions. In contrast, conventional quadrotor designs rely\non rigid frames that support agile flight but inherently limit collision\nresilience and squeezability, thereby constraining flight capabilities in\ncluttered environments. Inspired by the anisotropic stiffness and distributed\nmass-energy structures observed in biological organisms, we introduce\nFlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.\nWe demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more\ncompliant than conventional quadrotors, yet capable of acrobatic manoeuvres\nwith peak speeds above 80 km/h and linear and angular accelerations exceeding 3\ng and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate\naccelerations of rigid counterparts up to a thrust-to-weight ratio of 8.\nSimultaneously, FlexiQuad exhibits fourfold higher collision resilience,\nsurviving frontal impacts at 5 m/s without damage and reducing destabilising\nforces in glancing collisions by a factor of 39. Its frame can fully compress,\nenabling flight through gaps as narrow as 70% of its nominal width. Our\nanalysis identifies an optimal structural softness range, from 0.006 to 0.77\nN/mm, comparable to that of natural flyers' wings, whereby agility,\nsqueezability, and collision resilience are jointly achieved for FlexiQuad\nmodels from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in\ncomplex environments, enabling robust physical interactions without\ncompromising flight performance."}
{"id": "2511.05005", "pdf": "https://arxiv.org/pdf/2511.05005", "abs": "https://arxiv.org/abs/2511.05005", "authors": ["Dongsu Lee", "Daehee Lee", "Amy Zhang"], "title": "Multi-agent Coordination via Flow Matching", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "This work presents MAC-Flow, a simple yet expressive framework for\nmulti-agent coordination. We argue that requirements of effective coordination\nare twofold: (i) a rich representation of the diverse joint behaviors present\nin offline data and (ii) the ability to act efficiently in real time. However,\nprior approaches often sacrifice one for the other, i.e., denoising\ndiffusion-based solutions capture complex coordination but are computationally\nslow, while Gaussian policy-based solutions are fast but brittle in handling\nmulti-agent interaction. MAC-Flow addresses this trade-off by first learning a\nflow-based representation of joint behaviors, and then distilling it into\ndecentralized one-step policies that preserve coordination while enabling fast\nexecution. Across four different benchmarks, including $12$ environments and\n$34$ datasets, MAC-Flow alleviates the trade-off between performance and\ncomputational cost, specifically achieving about $\\boldsymbol{\\times14.5}$\nfaster inference compared to diffusion-based MARL methods, while maintaining\ngood performance. At the same time, its inference speed is similar to that of\nprior Gaussian policy-based offline multi-agent reinforcement learning (MARL)\nmethods."}
{"id": "2511.05311", "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Raphaël Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities."}
{"id": "2511.05355", "pdf": "https://arxiv.org/pdf/2511.05355", "abs": "https://arxiv.org/abs/2511.05355", "authors": ["Tzu-Yuan Huang", "Armin Lederer", "Dai-Jie Wu", "Xiaobing Dai", "Sihua Zhang", "Stefan Sosnowski", "Shao-Hua Sun", "Sandra Hirche"], "title": "SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Flow matching (FM) has shown promising results in data-driven planning.\nHowever, it inherently lacks formal guarantees for ensuring state and action\nconstraints, whose satisfaction is a fundamental and crucial requirement for\nthe safety and admissibility of planned trajectories on various systems.\nMoreover, existing FM planners do not ensure the dynamical consistency, which\npotentially renders trajectories inexecutable. We address these shortcomings by\nproposing SAD-Flower, a novel framework for generating Safe, Admissible, and\nDynamically consistent trajectories. Our approach relies on an augmentation of\nthe flow with a virtual control input. Thereby, principled guidance can be\nderived using techniques from nonlinear control theory, providing formal\nguarantees for state constraints, action constraints, and dynamic consistency.\nCrucially, SAD-Flower operates without retraining, enabling test-time\nsatisfaction of unseen constraints. Through extensive experiments across\nseveral tasks, we demonstrate that SAD-Flower outperforms various\ngenerative-model-based baselines in ensuring constraint satisfaction."}
{"id": "2511.05396", "pdf": "https://arxiv.org/pdf/2511.05396", "abs": "https://arxiv.org/abs/2511.05396", "authors": ["Yiting He", "Zhishuai Liu", "Weixin Wang", "Pan Xu"], "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": "53 pages, 6 figures, 3 tables. Published in Proceedings of the 42nd\n  International Conference on Machine Learning (ICML 2025)", "summary": "Off-dynamics reinforcement learning (RL), where training and deployment\ntransition dynamics are different, can be formulated as learning in a robust\nMarkov decision process (RMDP) where uncertainties in transition dynamics are\nimposed. Existing literature mostly assumes access to generative models\nallowing arbitrary state-action queries or pre-collected datasets with a good\nstate coverage of the deployment environment, bypassing the challenge of\nexploration. In this work, we study a more realistic and challenging setting\nwhere the agent is limited to online interaction with the training environment.\nTo capture the intrinsic difficulty of exploration in online RMDPs, we\nintroduce the supremal visitation ratio, a novel quantity that measures the\nmismatch between the training dynamics and the deployment dynamics. We show\nthat if this ratio is unbounded, online learning becomes exponentially hard. We\npropose the first computationally efficient algorithm that achieves sublinear\nregret in online RMDPs with $f$-divergence based transition uncertainties. We\nalso establish matching regret lower bounds, demonstrating that our algorithm\nachieves optimal dependence on both the supremal visitation ratio and the\nnumber of interaction episodes. Finally, we validate our theoretical results\nthrough comprehensive numerical experiments."}
