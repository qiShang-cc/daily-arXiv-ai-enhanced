{"id": "2508.16055", "pdf": "https://arxiv.org/pdf/2508.16055", "abs": "https://arxiv.org/abs/2508.16055", "authors": ["Mengzhen Liu", "Ming Li", "Rang Liu", "Qian Liu"], "title": "Secure ISAC Systems Empowered by Compound Reconfigurable Antenna Arrays", "categories": ["eess.SP"], "comment": "13 pages, 9 figures", "summary": "In integrated sensing and communication (ISAC) systems, the use of\ndual-functional signals inherently exposes confidential communication\ninformation during radar sensing, particularly when the sensing target itself\nacts as an eavesdropper. Conventional physical-layer security solutions rely on\ndirectional beamforming or artificial noise injection implemented via signal\nprocessing in the baseband (BB) domain. However, these BB-domain approaches are\nconstrained by insufficient spatial resolution and the adverse effects of\nspatially correlated channels. To overcome these limitations, this paper\nproposes a novel secure ISAC framework empowered by compound reconfigurable\nantenna (CRA) arrays, which offer simultaneous reconfigurability of radiation\npatterns and polarization states in the electromagnetic (EM) domain.\nSpecifically, we develop a comprehensive channel model incorporating virtual\nangular domain, spatial domain, and depolarization effects, and formulate a\nmixed-integer nonlinear programming (MINLP) problem to jointly design EM-domain\nand BB-domain precoders and combiners. To efficiently solve this complex\noptimization problem, we propose an iterative decomposition-based algorithm\nleveraging fractional programming (FP), majorization-minimization (MM),\nsecond-order cone programming (SOCP), and penalty methods. Extensive simulation\nresults demonstrate that the CRA array architecture with proposed joint EM-and\nBB-domain design achieves significant performance improvements in secure ISAC\nsystems. In particular, radar sensing gains of up to 12dB are observed over\nconventional beamforming, while robust communication security is maintained.\nThese results highlight the considerable benefits attainable by jointly\nleveraging additional degrees of freedom (DoFs) in the EM domain for secure\nISAC system design.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u590d\u5408\u53ef\u91cd\u6784\u5929\u7ebf\u9635\u5217\u7684\u5b89\u5168ISAC\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u7535\u78c1\u57df\u548c\u57fa\u5e26\u57df\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u96f7\u8fbe\u611f\u77e5\u548c\u901a\u4fe1\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u5c42\u5b89\u5168\u65b9\u6cd5\u5728\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u76f8\u5173\u4fe1\u9053\u5f71\u54cd\u4e0a\u53d7\u9650\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6848\u6765\u63d0\u5347ISAC\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u7ed3\u5408FP\u3001MM\u3001SOCP\u548c\u60e9\u7f5a\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u8054\u5408\u7535\u78c1\u57df\u548c\u57fa\u5e26\u57df\u7684\u9884\u7f16\u7801\u5668\u548c\u7ec4\u5408\u5668\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u65b0\u6846\u67b6\u5728\u96f7\u8fbe\u611f\u77e5\u4e0a\u6bd4\u4f20\u7edf\u6ce2\u675f\u6210\u5f62\u63d0\u534712dB\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u4fe1\u5b89\u5168\u6027\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u5229\u7528\u7535\u78c1\u57df\u7684\u81ea\u7531\u5ea6\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5b89\u5168ISAC\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2508.16107", "pdf": "https://arxiv.org/pdf/2508.16107", "abs": "https://arxiv.org/abs/2508.16107", "authors": ["Amir Bouziane", "Huseyin Arslan"], "title": "FM OFDM Unifying High Mobility Communications and Sensing", "categories": ["eess.SP"], "comment": null, "summary": "Integrated Sensing and Communication (ISAC) is foundational to future sixth\ngeneration (6G) systems, demanding waveform co-design that supports both high\nthroughput data transmission and accurate environmental perception. While\nOrthogonal Frequency Division Multiplexing (OFDM) offers flexibility and\nbackward compatibility, its high Peak to Average Power Ratio (PAPR) poses\nsignificant challenges at higher frequency bands. To address this, we\ninvestigate Frequency Modulated Orthogonal Frequency Division Multiplexing (FM\nOFDM) a constant envelope waveform that facilitates robust joint sensing and\ncommunication under highly mobile, doubly dispersive channel conditions. We\nderive a comprehensive input output relationship for FM OFDM in time varying\nmultipath channels, including analytical expressions for Inter Carrier\nInterference (ICI), Doppler effects, and effective channel gains. Extensive\nsimulations comparing FM OFDM with conventional Cyclic Prefix Orthogonal\nFrequency Division Multiplexing (CP OFDM) and Constant Envelope Orthogonal\nFrequency Division Multiplexing (CE OFDM) demonstrate superior range and\nvelocity estimation accuracy of FM-OFDM, particularly at high Signal to Noise\nRatios (SNRs) and under high mobility, highlighting its suitability as a\nunified waveform for high frequency ISAC applications in 6G.", "AI": {"tldr": "FM OFDM\u4f5c\u4e3a\u4e00\u79cd\u6052\u5b9a\u5305\u7edc\u6ce2\u5f62\uff0c\u5728\u9ad8\u79fb\u52a8\u6027\u548c\u53cc\u8272\u6563\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u4e3a6G\u7cfb\u7edf\u7684\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "motivation": "\u672a\u67656G\u7cfb\u7edf\u9700\u8981\u652f\u6301\u9ad8\u541e\u5410\u91cf\u6570\u636e\u4f20\u8f93\u548c\u7cbe\u786e\u73af\u5883\u611f\u77e5\u7684\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u800cOFDM\u7684\u9ad8\u5cf0\u503c\u5e73\u5747\u529f\u7387\u6bd4\uff08PAPR\uff09\u5728\u9ad8\u9891\u6bb5\u5e26\u6765\u6311\u6218\u3002", "method": "\u7814\u7a76\u4e86FM OFDM\u4f5c\u4e3a\u6052\u5b9a\u5305\u7edc\u6ce2\u5f62\u7684\u6027\u80fd\uff0c\u63a8\u5bfc\u4e86\u5176\u5728\u65f6\u53d8\u591a\u5f84\u4fe1\u9053\u4e2d\u7684\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\uff0c\u5e76\u5206\u6790\u4e86\u8f7d\u6ce2\u95f4\u5e72\u6270\uff08ICI\uff09\u3001\u591a\u666e\u52d2\u6548\u5e94\u7b49\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\uff0cFM OFDM\u5728\u9ad8\u901f\u79fb\u52a8\u548c\u9ad8\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\uff0c\u6bd4CP OFDM\u548cCE OFDM\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u8ddd\u79bb\u548c\u901f\u5ea6\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "FM OFDM\u9002\u5408\u4f5c\u4e3a6G\u9ad8\u9891ISAC\u5e94\u7528\u7684\u7edf\u4e00\u6ce2\u5f62\u3002"}}
{"id": "2508.16169", "pdf": "https://arxiv.org/pdf/2508.16169", "abs": "https://arxiv.org/abs/2508.16169", "authors": ["Lukas Herrmann", "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez", "Edmund F. Brekke", "Egil Eide"], "title": "A Scalable Hybrid Track-Before-Detect Tracking System: Application to Coastal Maritime Radar Surveillance", "categories": ["eess.SP"], "comment": "Submitted for possible publication in IEEE Journal of Oceanic\n  Engineering (JOE)", "summary": "Despite their theoretical advantages, track-before-detect (TBD) methods\nremain largely absent from real-world multi-target tracking applications due to\ntheir computational complexity and limited scalability. This paper presents a\nscalable hybrid tracking framework that combines a TBD multi-target tracking\nalgorithm with a detection-based multi-target tracking algorithm for coastal\nradar surveillance. In particular, the approach uses an integrated existence\nPoisson histogram-probabilistic multi-hypothesis tracking (IE-PHPMHT)-based TBD\nmodule with a conventional Poisson multi-Bernoulli Mixture (PMBM) point\ntracker. The system processes raw radar data through land clutter suppression,\ncell-wise detection, and clustering-based feature extraction. High-threshold\ndetections are used to track strong targets via the point tracker, while\nlow-threshold detections are employed for adaptive birth in the TBD module,\nenabling early initiation and sustained tracking of weak or ambiguous targets.\nValidated using real X-band radar data from the Trondheim Fjord, Norway, the\napproach demonstrates robust multi-target tracking performance in a full-scale\napplication with a large observation area under resource constraints,\nhighlighting its suitability for operational deployment in complex maritime\nenvironments needed for coastal surveillance and to support autonomy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408TBD\u548c\u68c0\u6d4b\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u6846\u67b6\uff0c\u7528\u4e8e\u6d77\u5cb8\u96f7\u8fbe\u76d1\u89c6\uff0c\u5c55\u793a\u4e86\u5176\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1TBD\u65b9\u6cd5\u7406\u8bba\u4e0a\u6709\u4f18\u52bf\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u8ba1\u7b97\u590d\u6742\u548c\u53ef\u6269\u5c55\u6027\u5dee\u800c\u53d7\u9650\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u57fa\u4e8eIE-PHPMHT\u7684TBD\u6a21\u5757\u548cPMBM\u70b9\u8ddf\u8e2a\u5668\uff0c\u5904\u7406\u96f7\u8fbe\u6570\u636e\u5e76\u5b9e\u73b0\u5f3a\u5f31\u76ee\u6807\u7684\u8ddf\u8e2a\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u96f7\u8fbe\u6570\u636e\u9a8c\u8bc1\uff0c\u663e\u793a\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5927\u8303\u56f4\u89c2\u6d4b\u4e2d\u7684\u9c81\u68d2\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u9002\u5408\u590d\u6742\u6d77\u4e0a\u73af\u5883\u7684\u5b9e\u9645\u90e8\u7f72\uff0c\u652f\u6301\u6d77\u5cb8\u76d1\u89c6\u548c\u81ea\u4e3b\u7cfb\u7edf\u3002"}}
{"id": "2508.16218", "pdf": "https://arxiv.org/pdf/2508.16218", "abs": "https://arxiv.org/abs/2508.16218", "authors": ["Mintaek Oh", "Jinseok Choi"], "title": "Hybrid Precoding Revisited: Low-Dimensional Subspace Perspective for MU-MIMO Systems", "categories": ["eess.SP"], "comment": "5 pages, 2 figures", "summary": "This letter presents a low-complexity hybrid precoding framework for\nmultiuser multiple-input multiple-output (MIMO) systems by leveraging a\nlow-dimensional subspace property. Under the low-dimensional subspace\nperspective, we first identify an unconstrained optimal radio-frequency (RF)\nprecoder. We then optimize a hybrid precoder via a reduced-complexity precoding\nmethod. We further extend the proposed framework to (i) a dynamic-subarray\nantenna partitioning algorithm that adaptively allocates subsets of antennas\nassociated with RF chains, and (ii) a channel covariance-based approach to\nexploit statistical channel state information at a transmitter (CSIT), ensuring\nrobustness with partial CSIT. Simulations validate that our proposed algorithms\nachieve superior performance while significantly reducing complexity compared\nto existing methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u6df7\u5408\u9884\u7f16\u7801\u6846\u67b6\uff0c\u5229\u7528\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u7279\u6027\u4f18\u5316\u591a\u7528\u6237MIMO\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u591a\u7528\u6237MIMO\u7cfb\u7edf\u4e2d\u4f20\u7edf\u9884\u7f16\u7801\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u7279\u6027\u7684\u65b0\u6846\u67b6\u3002", "method": "\u9996\u5148\u8bc6\u522b\u4e86\u65e0\u7ea6\u675f\u7684\u6700\u4f18\u5c04\u9891\u9884\u7f16\u7801\u5668\uff0c\u7136\u540e\u901a\u8fc7\u964d\u590d\u6742\u5ea6\u9884\u7f16\u7801\u65b9\u6cd5\u4f18\u5316\u6df7\u5408\u9884\u7f16\u7801\u5668\uff0c\u5e76\u8fdb\u4e00\u6b65\u6269\u5c55\u4e3a\u52a8\u6001\u5b50\u9635\u5217\u5929\u7ebf\u5206\u533a\u548c\u7edf\u8ba1\u4fe1\u9053\u4fe1\u606f\u5229\u7528\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u663e\u8457\u964d\u4f4e\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u7528\u6237MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u9884\u7f16\u7801\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15874", "pdf": "https://arxiv.org/pdf/2508.15874", "abs": "https://arxiv.org/abs/2508.15874", "authors": ["Yijun Liu", "Yuwei Liu", "Yuan Meng", "Jieheng Zhang", "Yuwei Zhou", "Ye Li", "Jiacheng Jiang", "Kangye Ji", "Shijia Ge", "Zhi Wang", "Wenwu Zhu"], "title": "Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Vision-centric hierarchical embodied models have demonstrated strong\npotential for long-horizon robotic control. However, existing methods lack\nspatial awareness capabilities, limiting their effectiveness in bridging visual\nplans to actionable control in complex environments. To address this problem,\nwe propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic\nmanipulation framework via explicit spatial modeling and reasoning.\nSpecifically, we first design a spatial-conditioned embodied video generation\nmodule to model spatially guided predictions through a spatial plan table.\nThen, we propose a spatial-based action prediction module to infer executable\nactions with coordination. Finally, we propose a spatial reasoning feedback\npolicy to refine the spatial plan table via dual-stage replanning. Extensive\nexperiments show that SP significantly outperforms state-of-the-art baselines,\nachieving a 33.0% average improvement over the best baseline. With an 86.7%\naverage success rate across 11 diverse tasks, SP substantially enhances the\npracticality of embodied models for robotic control applications. Code and\ncheckpoints are maintained at\nhttps://plantpotatoonmoon.github.io/SpatialPolicy/.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u540d\u4e3aSpatial Policy (SP)\u7684\u7edf\u4e00\u7a7a\u95f4\u611f\u77e5\u89c6\u89c9\u8fd0\u52a8\u673a\u5668\u4eba\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u7a7a\u95f4\u5efa\u6a21\u548c\u63a8\u7406\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u7f3a\u4e4f\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u7684\u5206\u5c42\u5177\u8eab\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u73af\u5883\u4e2d\u5c06\u89c6\u89c9\u8ba1\u5212\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u63a7\u5236\u7684\u80fd\u529b\u3002\n", "method": "SP\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u6a21\u5757\uff1a1) \u7a7a\u95f4\u6761\u4ef6\u5177\u8eab\u89c6\u9891\u751f\u6210\u6a21\u5757\uff0c\u901a\u8fc7\u7a7a\u95f4\u8ba1\u5212\u8868\u5efa\u6a21\u7a7a\u95f4\u5bfc\u5411\u9884\u6d4b\uff1b2) \u57fa\u4e8e\u7a7a\u95f4\u7684\u52a8\u4f5c\u9884\u6d4b\u6a21\u5757\uff0c\u901a\u8fc7\u534f\u8c03\u63a8\u65ad\u53ef\u6267\u884c\u52a8\u4f5c\uff1b3) \u7a7a\u95f4\u63a8\u7406\u53cd\u9988\u7b56\u7565\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u91cd\u65b0\u89c4\u5212\u4f18\u5316\u7a7a\u95f4\u8ba1\u5212\u8868\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSP\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e73\u5747\u6539\u8fdb33.0%\uff0c\u572811\u9879\u591a\u6837\u4efb\u52a1\u4e2d\u5e73\u5747\u6210\u529f\u7387\u8fbe\u523086.7%\u3002", "conclusion": "SP\u6210\u529f\u63d0\u5347\u4e86\u5177\u8eab\u6a21\u578b\u5728\u673a\u5668\u4eba\u63a7\u5236\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u4ee3\u7801\u548c\u68c0\u67e5\u70b9\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.16544", "pdf": "https://arxiv.org/pdf/2508.16544", "abs": "https://arxiv.org/abs/2508.16544", "authors": ["Stephen Ekaputra Limantoro"], "title": "Parameter-Free Logit Distillation via Sorting Mechanism", "categories": ["eess.SP", "cs.LG", "eess.IV"], "comment": "Accepted in IEEE Signal Processing Letters 2025", "summary": "Knowledge distillation (KD) aims to distill the knowledge from the teacher\n(larger) to the student (smaller) model via soft-label for the efficient neural\nnetwork. In general, the performance of a model is determined by accuracy,\nwhich is measured with labels. However, existing KD approaches usually use the\nteacher with its original distribution, neglecting the potential of incorrect\nprediction. This may contradict the motivation of hard-label learning through\ncross-entropy loss, which may lead to sub-optimal knowledge distillation on\ncertain samples. To address this issue, we propose a novel logit processing\nscheme via a sorting mechanism. Specifically, our method has a two-fold goal:\n(1) fixing the incorrect prediction of the teacher based on the labels and (2)\nreordering the distribution in a natural way according to priority rank at\nonce. As an easy-to-use, plug-and-play pre-processing, our sort method can be\neffectively applied to existing logit-based KD methods. Extensive experiments\non the CIFAR-100 and ImageNet datasets demonstrate the effectiveness of our\nmethod.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6392\u5e8f\u673a\u5236\uff0c\u7528\u4e8e\u6539\u8fdb\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u4e2d\u6559\u5e08\u6a21\u578b\u7684\u4e0d\u6b63\u786e\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u91cd\u65b0\u6392\u5e8f\u5206\u5e03\u6765\u4f18\u5316\u77e5\u8bc6\u4f20\u9012\u3002", "motivation": "\u73b0\u6709KD\u65b9\u6cd5\u901a\u5e38\u76f4\u63a5\u4f7f\u7528\u6559\u5e08\u6a21\u578b\u7684\u539f\u59cb\u5206\u5e03\uff0c\u5ffd\u7565\u4e86\u9519\u8bef\u9884\u6d4b\u7684\u6f5c\u529b\uff0c\u8fd9\u53ef\u80fd\u5f71\u54cd\u77e5\u8bc6\u84b8\u998f\u7684\u6548\u679c\u3002", "method": "\u91c7\u7528\u6392\u5e8f\u673a\u5236\u5904\u7406logit\uff0c\u4fee\u6b63\u6559\u5e08\u6a21\u578b\u7684\u9519\u8bef\u9884\u6d4b\u5e76\u91cd\u65b0\u6392\u5e8f\u5206\u5e03\u3002", "result": "\u5728CIFAR-100\u548cImageNet\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6392\u5e8f\u673a\u5236\u662f\u4e00\u79cd\u6613\u4e8e\u4f7f\u7528\u7684\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u73b0\u6709KD\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2508.15972", "pdf": "https://arxiv.org/pdf/2508.15972", "abs": "https://arxiv.org/abs/2508.15972", "authors": ["Zhaodong Jiang", "Ashish Sinha", "Tongtong Cao", "Yuan Ren", "Bingbing Liu", "Binbin Xu"], "title": "UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation", "categories": ["cs.RO", "cs.CV"], "comment": "Published at the Conference on Robot Learning (CoRL) 2025. For more\n  details please visit https://frankzhaodong.github.io/UnPose", "summary": "Estimating the 6D pose of novel objects is a fundamental yet challenging\nproblem in robotics, often relying on access to object CAD models. However,\nacquiring such models can be costly and impractical. Recent approaches aim to\nbypass this requirement by leveraging strong priors from foundation models to\nreconstruct objects from single or multi-view images, but typically require\nadditional training or produce hallucinated geometry. To this end, we propose\nUnPose, a novel framework for zero-shot, model-free 6D object pose estimation\nand reconstruction that exploits 3D priors and uncertainty estimates from a\npre-trained diffusion model. Specifically, starting from a single-view RGB-D\nframe, UnPose uses a multi-view diffusion model to estimate an initial 3D model\nusing 3D Gaussian Splatting (3DGS) representation, along with pixel-wise\nepistemic uncertainty estimates. As additional observations become available,\nwe incrementally refine the 3DGS model by fusing new views guided by the\ndiffusion model's uncertainty, thereby continuously improving the pose\nestimation accuracy and 3D reconstruction quality. To ensure global\nconsistency, the diffusion prior-generated views and subsequent observations\nare further integrated in a pose graph and jointly optimized into a coherent\n3DGS field. Extensive experiments demonstrate that UnPose significantly\noutperforms existing approaches in both 6D pose estimation accuracy and 3D\nreconstruction quality. We further showcase its practical applicability in\nreal-world robotic manipulation tasks.", "AI": {"tldr": "UnPose\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u6837\u672c\u3001\u65e0\u6a21\u578b\u76846D\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u548c\u91cd\u5efa\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u76843D\u5148\u9a8c\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u9886\u57df\u4e2d\u65b0\u578b\u7269\u4f536D\u59ff\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u907f\u514d\u4f9d\u8d56CAD\u6a21\u578b\u6216\u989d\u5916\u8bad\u7ec3\u7684\u9700\u6c42\uff0c\u63d0\u5347\u5b9e\u7528\u6027\u548c\u6548\u7387\u3002", "method": "\u5229\u7528\u591a\u89c6\u56fe\u6269\u6563\u6a21\u578b\u548c3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u8868\u793a\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u89c6\u56fe\u878d\u5408\u9010\u6b65\u4f18\u53163D\u6a21\u578b\u548c\u59ff\u6001\u4f30\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cUnPose\u57286D\u59ff\u6001\u4f30\u8ba1\u7cbe\u5ea6\u548c3D\u91cd\u5efa\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9645\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "UnPose\u901a\u8fc7\u7ed3\u5408\u6269\u6563\u6a21\u578b\u7684\u5148\u9a8c\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u65e0\u6a21\u578b6D\u59ff\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.15795", "pdf": "https://arxiv.org/pdf/2508.15795", "abs": "https://arxiv.org/abs/2508.15795", "authors": ["Yanheng Liu", "Dalin Li", "Hao Wu", "Zemin Sun", "Weihong Qin", "Jun Li", "Hongyang Du", "Geng Sun"], "title": "Task Offloading and Resource Allocation for MEC-assisted Consumer Internet of Vehicle Systems", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Mobile edge computing (MEC)-assisted internet of vehicle (IoV) is emerging as\na promising paradigm to provide computing services for vehicles. However,\nmeeting the computing-sensitive and computation-intensive demands of vehicles\nposes several challenges, including the discrepancy between the limited\nresource provision and stringent computing requirement, the difficulty in\ncapturing and integrating the intricate features of the MEC-assisted IoV system\ninto the problem formulation, and the need for real-time processing and\nefficient resource management in the dynamic environment. In this work, we\nexplore the AI-enabled task offloading and resource allocation for MEC-assisted\nconsumer IoV systems. Specifically, we first present a multi-MEC-assisted\nconsumer IoV architecture that leverages the computational resources of MEC\nservers to provide offloading services close to vehicles. Subsequently, we\nformulate a system cost minimization optimization problem (SCMOP) by\nintegrating the service delay and energy consumption. To efficiently solve this\nproblem, we design a joint task offloading and computing resource allocation\napproach (JTOCRA) by applying the multi-agent deep deterministic policy\ngradient (MADDPG) algorithm. Finally, simulation results demonstrate that the\nproposed JTOCRA can achieve superior system performances and exhibits better\nscalability compared to other alternative approaches.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u8f85\u52a9\u7684\u8f66\u8054\u7f51\uff08IoV\uff09\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff0c\u4ee5\u4f18\u5316\u7cfb\u7edf\u6210\u672c\u548c\u6027\u80fd\u3002", "motivation": "\u8f66\u8054\u7f51\u5728\u6ee1\u8db3\u9ad8\u8ba1\u7b97\u9700\u6c42\u548c\u5b9e\u65f6\u5904\u7406\u65b9\u9762\u9762\u4e34\u8d44\u6e90\u4e0d\u8db3\u548c\u73af\u5883\u52a8\u6001\u6027\u7684\u6311\u6218\uff0c\u4f5c\u8005\u65e8\u5728\u901a\u8fc7AI\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u591aMEC\u8f85\u52a9\u7684\u8f66\u8054\u7f51\u67b6\u6784\uff0c\u5e76\u63d0\u51fa\u4e86\u8054\u5408\u4efb\u52a1\u5378\u8f7d\u548c\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\uff08JTOCRA\uff09\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08MADDPG\uff09\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cJTOCRA\u5728\u7cfb\u7edf\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "JTOCRA\u80fd\u6709\u6548\u4f18\u5316MEC\u8f85\u52a9\u8f66\u8054\u7f51\u7684\u7cfb\u7edf\u6210\u672c\uff0c\u9002\u5408\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8d44\u6e90\u7ba1\u7406\u3002"}}
{"id": "2508.15990", "pdf": "https://arxiv.org/pdf/2508.15990", "abs": "https://arxiv.org/abs/2508.15990", "authors": ["Hung-Jui Huang", "Mohammad Amin Mirzaee", "Michael Kaess", "Wenzhen Yuan"], "title": "GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System", "categories": ["cs.RO", "cs.CV"], "comment": "18 pages", "summary": "Accurately perceiving an object's pose and shape is essential for precise\ngrasping and manipulation. Compared to common vision-based methods, tactile\nsensing offers advantages in precision and immunity to occlusion when tracking\nand reconstructing objects in contact. This makes it particularly valuable for\nin-hand and other high-precision manipulation tasks. In this work, we present\nGelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to\nestimate object pose over long periods and reconstruct object shapes with high\nfidelity. Unlike traditional point cloud-based approaches, GelSLAM uses\ntactile-derived surface normals and curvatures for robust tracking and loop\nclosure. It can track object motion in real time with low error and minimal\ndrift, and reconstruct shapes with submillimeter accuracy, even for low-texture\nobjects such as wooden tools. GelSLAM extends tactile sensing beyond local\ncontact to enable global, long-horizon spatial perception, and we believe it\nwill serve as a foundation for many precise manipulation tasks involving\ninteraction with objects in hand. The video demo is available on our website:\nhttps://joehjhuang.github.io/gelslam.", "AI": {"tldr": "GelSLAM\u662f\u4e00\u79cd\u4ec5\u4f9d\u8d56\u89e6\u89c9\u4f20\u611f\u7684\u5b9e\u65f63D SLAM\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u548c\u5f62\u72b6\u91cd\u5efa\u3002", "motivation": "\u89e6\u89c9\u4f20\u611f\u5728\u7cbe\u786e\u6293\u53d6\u548c\u64cd\u4f5c\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u906e\u6321\u60c5\u51b5\u4e0b\u3002", "method": "\u5229\u7528\u89e6\u89c9\u884d\u751f\u7684\u8868\u9762\u6cd5\u7ebf\u548c\u66f2\u7387\u8fdb\u884c\u8ddf\u8e2a\u548c\u95ed\u73af\uff0c\u4f18\u4e8e\u4f20\u7edf\u70b9\u4e91\u65b9\u6cd5\u3002", "result": "\u5b9e\u65f6\u8ddf\u8e2a\u8bef\u5dee\u4f4e\u4e14\u6f02\u79fb\u5c0f\uff0c\u5f62\u72b6\u91cd\u5efa\u7cbe\u5ea6\u8fbe\u5230\u4e9a\u6beb\u7c73\u7ea7\u3002", "conclusion": "GelSLAM\u6269\u5c55\u4e86\u89e6\u89c9\u4f20\u611f\u7684\u5168\u5c40\u611f\u77e5\u80fd\u529b\uff0c\u4e3a\u9ad8\u7cbe\u5ea6\u64cd\u4f5c\u4efb\u52a1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.15867", "pdf": "https://arxiv.org/pdf/2508.15867", "abs": "https://arxiv.org/abs/2508.15867", "authors": ["Celik Boga", "Anke Henning"], "title": "Turbo Spin Echo Imaging at 7T with Bilateral Orthogonality Generative Acquisitions Method for Homogeneous T_1, T_2 and Proton Density Contrasts", "categories": ["eess.IV", "eess.SP", "physics.med-ph"], "comment": null, "summary": "Purpose: Bilateral Orthogonality Generative Acquisitions (BOGA) method, which\nwas initially implemented for T_2^* contrast via gradient echo acquisitions, is\nadapted for TSE imaging at 7T using parallel transmission (pTx) system for\nobtaining homogeneous T_1, T_2 and proton density weighted images. Theory and\nMethods: Multiple TSE images with complimentary RF modes and scan parameters\nare acquired as input images for the BOGA method where RF modes have\ncomplimentary transmit and receive field inhomogeneity patterns and scan\nparameters have varying echo and repetition times. With the application of the\nBOGA method using different subsets of the data acquisitions for each contrast,\nhomogeneous T_1, T_2 and proton density contrast in the final images obtained.\nFurthermore, to demonstrate the effect of the TSE factor, two TSE factors are\nused individually. Normalized intensity profiles and signal to noise ratio maps\nare utilized for the comparison of the CP mode images and the TSE factors\nrespectively.\n  Results: Homogeneous T_1, T_2 and proton density weighted images are obtained\nwith the TSE implementation of the BOGA method without the transmit and receive\nfield inhomogeneity effects. Furthermore, mixed contrast effects of the TSE\nacquisition are simultaneously resolved independently of the TSE factor.\n  Conclusion: TSE application of BOGA method results in homogeneous T_1, T_2\nand proton density contrasts at 7T, as the inhomogeneity effects are removed\nfrom the final contrast without any prior data acquisitions.", "AI": {"tldr": "BOGA\u65b9\u6cd5\u4ece\u68af\u5ea6\u56de\u6ce2\u91c7\u96c6\u6269\u5c55\u5230TSE\u6210\u50cf\uff0c\u7528\u4e8e7T\u78c1\u573a\u4e0b\u83b7\u53d6\u5747\u5300\u7684T1\u3001T2\u548c\u8d28\u5b50\u5bc6\u5ea6\u52a0\u6743\u56fe\u50cf\u3002", "motivation": "\u89e3\u51b37T\u78c1\u573a\u4e0bTSE\u6210\u50cf\u4e2d\u7684\u4e0d\u5747\u5300\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u7531\u5c04\u9891\u573a\u4e0d\u5747\u5300\u6027\u5f15\u8d77\u7684\u5bf9\u6bd4\u5ea6\u53d8\u5316\u3002", "method": "\u901a\u8fc7\u91c7\u96c6\u591a\u7ec4\u4e92\u8865\u5c04\u9891\u6a21\u5f0f\u548c\u626b\u63cf\u53c2\u6570\u7684TSE\u56fe\u50cf\uff0c\u5229\u7528BOGA\u65b9\u6cd5\u5904\u7406\u6570\u636e\u4ee5\u6d88\u9664\u4e0d\u5747\u5300\u6027\u5f71\u54cd\u3002", "result": "\u6210\u529f\u83b7\u5f97\u5747\u5300\u7684T1\u3001T2\u548c\u8d28\u5b50\u5bc6\u5ea6\u52a0\u6743\u56fe\u50cf\uff0c\u4e14\u4e0d\u53d7TSE\u56e0\u5b50\u7684\u5f71\u54cd\u3002", "conclusion": "BOGA\u65b9\u6cd5\u7684TSE\u5e94\u7528\u53ef\u57287T\u78c1\u573a\u4e0b\u83b7\u5f97\u5747\u5300\u7684\u5bf9\u6bd4\u5ea6\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\u91c7\u96c6\u3002"}}
{"id": "2508.16008", "pdf": "https://arxiv.org/pdf/2508.16008", "abs": "https://arxiv.org/abs/2508.16008", "authors": ["Bingchao Wang", "Adam A. Stokes"], "title": "Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a multifunctional connector based on electro-permanent\nmagnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid\ntransfer, and data communication within a compact SLA-3D printed structure.\nExperimental results demonstrate reliable self-alignment, efficient fluid\ntransfer in single-loop and dual-channel modes, and robust data transmission\nvia integrated electronic control. The connector exhibits high flexibility in\naccommodating axial, angular, and lateral misalignments while maintaining low\nenergy consumption. These features make it highly suitable for modular\nrobotics, electric vehicle charging, household robotic platforms, and aerospace\ndocking applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u7535\u6c38\u78c1\uff08EPM\uff09\u6280\u672f\u7684\u591a\u529f\u80fd\u8fde\u63a5\u5668\uff0c\u96c6\u6210\u4e86\u81ea\u5bf9\u51c6\u3001\u673a\u68b0\u8026\u5408\u3001\u6d41\u4f53\u4f20\u8f93\u548c\u6570\u636e\u901a\u4fe1\u529f\u80fd\u3002", "motivation": "\u89e3\u51b3\u6a21\u5757\u5316\u673a\u5668\u4eba\u3001\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7b49\u5e94\u7528\u4e2d\u7075\u6d3b\u6027\u548c\u591a\u529f\u80fd\u6027\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u7535\u6c38\u78c1\u6280\u672f\u548cSLA-3D\u6253\u5370\u7ed3\u6784\uff0c\u96c6\u6210\u591a\u79cd\u529f\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8fde\u63a5\u5668\u5177\u6709\u53ef\u9760\u7684\u81ea\u5bf9\u51c6\u3001\u9ad8\u6548\u6d41\u4f53\u4f20\u8f93\u548c\u7a33\u5065\u7684\u6570\u636e\u4f20\u8f93\u6027\u80fd\u3002", "conclusion": "\u8be5\u8fde\u63a5\u5668\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\uff0c\u4e14\u80fd\u8017\u4f4e\u3002"}}
{"id": "2508.15869", "pdf": "https://arxiv.org/pdf/2508.15869", "abs": "https://arxiv.org/abs/2508.15869", "authors": ["Christoph Sachs", "Martin Neuburger"], "title": "Konzepte zur Effizienzsteigerung von Traktionsmotoren in batterieelektrischen Fahrzeugen durch den Einsatz neuartiger teillastoptimierbarer Motor- und Invertertopologien", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": "in German language, Published in the conference proceedings of\n  Symposium Elektromagnetismus, 2025, February 27--28, K\\\"unzelsau, Germany\n  (ISBN-Nr.: 978-3-943563-55-9)", "summary": "To increase the efficiency of future electric vehicles, it is crucial to\nreduce drivetrain losses in battery-powered vehicles. This enables either an\nincrease in driving range or overall cost savings by reducing battery capacity\nwhile maintaining the same range. Harmonic motor losses account for an\navoidable share of more than 30% of the total eDrive losses in standard B6-2L\n300 kW iPMSM configurations. These losses result from high-frequency voltage\ndistortion across the motor windings, which can be reduced through various\napproaches. Of great importance is the classification of cost-neutral and\nlow-cost concepts for loss reduction. The following presents and categorizes\napproaches to loss reduction that have been developed by research and industry\nin recent years. In particular, novel part-load-capable motor and inverter\nconcepts are introduced, which enable motor switching or multilevel operation\nto reduce harmonic losses in the part-load range.", "AI": {"tldr": "\u4e3a\u4e86\u63d0\u9ad8\u7535\u52a8\u6c7d\u8f66\u7684\u6548\u7387\uff0c\u51cf\u5c11\u52a8\u529b\u4f20\u52a8\u7cfb\u7edf\u7684\u635f\u8017\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u8c10\u6ce2\u7535\u673a\u635f\u8017\uff0c\u5360\u6807\u51c6\u914d\u7f6e\u4e2d\u603b\u635f\u8017\u768430%\u4ee5\u4e0a\u3002", "motivation": "\u964d\u4f4e\u8c10\u6ce2\u7535\u673a\u635f\u8017\u53ef\u4ee5\u63d0\u5347\u7eed\u822a\u6216\u964d\u4f4e\u6210\u672c\uff0c\u540c\u65f6\u9700\u8981\u5206\u7c7b\u4f4e\u6210\u672c\u548c\u4e2d\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u548c\u884c\u4e1a\u5f00\u53d1\u4e86\u591a\u79cd\u964d\u4f4e\u635f\u8017\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u65b0\u578b\u90e8\u5206\u8d1f\u8f7d\u80fd\u529b\u7684\u7535\u673a\u548c\u9006\u53d8\u5668\u6982\u5ff5\uff0c\u5982\u7535\u673a\u5207\u6362\u6216\u591a\u7535\u5e73\u64cd\u4f5c\u3002", "result": "\u8fd9\u4e9b\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u90e8\u5206\u8d1f\u8f7d\u8303\u56f4\u5185\u7684\u8c10\u6ce2\u635f\u8017\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u5e76\u5206\u7c7b\u4e86\u8fd1\u5e74\u6765\u7684\u635f\u8017\u51cf\u5c11\u65b9\u6848\uff0c\u7279\u522b\u662f\u80fd\u591f\u9002\u5e94\u90e8\u5206\u8d1f\u8f7d\u7684\u65b0\u6982\u5ff5\uff0c\u4e3a\u7535\u52a8\u6c7d\u8f66\u6548\u7387\u63d0\u5347\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2508.16143", "pdf": "https://arxiv.org/pdf/2508.16143", "abs": "https://arxiv.org/abs/2508.16143", "authors": ["Akira Oyama", "Shoichi Hasegawa", "Akira Taniguchi", "Yoshinobu Hagiwara", "Tadahiro Taniguchi"], "title": "Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions", "categories": ["cs.RO", "cs.AI"], "comment": "See website at https://emergentsystemlabstudent.github.io/MIEL/.\n  Accepted at IEEE RO-MAN 2025", "summary": "Daily life support robots must interpret ambiguous verbal instructions\ninvolving demonstratives such as ``Bring me that cup,'' even when objects or\nusers are out of the robot's view. Existing approaches to exophora resolution\nprimarily rely on visual data and thus fail in real-world scenarios where the\nobject or user is not visible. We propose Multimodal Interactive Exophora\nresolution with user Localization (MIEL), which is a multimodal exophora\nresolution framework leveraging sound source localization (SSL), semantic\nmapping, visual-language models (VLMs), and interactive questioning with\nGPT-4o. Our approach first constructs a semantic map of the environment and\nestimates candidate objects from a linguistic query with the user's skeletal\ndata. SSL is utilized to orient the robot toward users who are initially\noutside its visual field, enabling accurate identification of user gestures and\npointing directions. When ambiguities remain, the robot proactively interacts\nwith the user, employing GPT-4o to formulate clarifying questions. Experiments\nin a real-world environment showed results that were approximately 1.3 times\nbetter when the user was visible to the robot and 2.0 times better when the\nuser was not visible to the robot, compared to the methods without SSL and\ninteractive questioning. The project website is\nhttps://emergentsystemlabstudent.github.io/MIEL/.", "AI": {"tldr": "MIEL\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u4ea4\u4e92\u5f0f\u6307\u4ee3\u6d88\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u58f0\u97f3\u5b9a\u4f4d\u3001\u8bed\u4e49\u5730\u56fe\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548cGPT-4o\u63d0\u95ee\uff0c\u89e3\u51b3\u673a\u5668\u4eba\u7406\u89e3\u6a21\u7cca\u6307\u4ee4\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u89c6\u89c9\u6570\u636e\uff0c\u65e0\u6cd5\u5904\u7406\u7528\u6237\u6216\u5bf9\u8c61\u4e0d\u5728\u89c6\u91ce\u7684\u60c5\u51b5\u3002MIEL\u7684\u76ee\u6807\u662f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u5347\u673a\u5668\u4eba\u5bf9\u6a21\u7cca\u6307\u4ee4\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u58f0\u97f3\u5b9a\u4f4d\uff08SSL\uff09\u3001\u8bed\u4e49\u5730\u56fe\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548cGPT-4o\u63d0\u95ee\uff0c\u9996\u5148\u6784\u5efa\u73af\u5883\u8bed\u4e49\u5730\u56fe\uff0c\u7136\u540e\u901a\u8fc7SSL\u5b9a\u4f4d\u7528\u6237\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u63d0\u95ee\u6d88\u9664\u6b67\u4e49\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cMIEL\u5728\u7528\u6237\u53ef\u89c1\u548c\u4e0d\u53ef\u89c1\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u5206\u522b\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u9ad8\u4e861.3\u500d\u548c2.0\u500d\u3002", "conclusion": "MIEL\u901a\u8fc7\u591a\u6a21\u6001\u4ea4\u4e92\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u5bf9\u6307\u4ee3\u6d88\u89e3\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u7528\u6237\u6216\u5bf9\u8c61\u4e0d\u53ef\u89c1\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.15924", "pdf": "https://arxiv.org/pdf/2508.15924", "abs": "https://arxiv.org/abs/2508.15924", "authors": ["Yinchen Li", "Chenhao Qi", "Shiwen Mao", "Octavia A. Dobre"], "title": "Tri-Hybrid Beamforming for Radiation-Center Reconfigurable Antenna Array: Spectral Efficiency and Energy Efficiency", "categories": ["cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "In this paper, we propose a tri-hybrid beamforming (THBF) architecture based\non the radiation-center (RC) reconfigurable antenna array (RCRAA), including\nthe digital beamforming, analog beamforming, and electromagnetic (EM)\nbeamforming, where the EM beamformer design is modeled as RC selection. Aiming\nat spectral efficiency (SE) maximization subject to the hardware and power\nconsumption constraints, we propose a tri-loop alternating optimization (TLAO)\nscheme for the THBF design, where the digital and analog beamformers are\noptimized based on the penalty dual decomposition in the inner and middle\nloops, and the RC selection is determined through the coordinate descent method\nin the outer loop. Aiming at energy-efficiency (EE) maximization, we develop a\ndual quadratic transform-based fractional programming (DQTFP) scheme, where the\nTLAO scheme is readily used for the THBF design. To reduce the computational\ncomplexity, we propose the Lagrange dual transform-based fractional programming\n(LDTFP) scheme, where each iteration has a closed-form solution. Simulation\nresults demonstrate the great potential of the RCRAA in improving both SE and\nEE. Compared to the DQTFP scheme, the LDTFP scheme significantly reduces the\ncomputational complexity with only minor performance loss.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u91cd\u6784\u5929\u7ebf\u9635\u5217\u7684\u4e09\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u67b6\u6784\uff0c\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u7684\u6700\u5927\u5316\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u6ce2\u675f\u6210\u5f62\u6280\u672f\u5728\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u4e0a\u7684\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u4e09\u6df7\u5408\u6ce2\u675f\u6210\u5f62\u67b6\u6784\uff0c\u7ed3\u5408\u6570\u5b57\u3001\u6a21\u62df\u548c\u7535\u78c1\u6ce2\u675f\u6210\u5f62\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u5faa\u73af\u4ea4\u66ff\u4f18\u5316\u65b9\u6848\uff0c\u5206\u522b\u4f18\u5316\u6570\u5b57\u548c\u6a21\u62df\u6ce2\u675f\u6210\u5f62\u5668\uff0c\u5e76\u901a\u8fc7\u5750\u6807\u4e0b\u964d\u6cd5\u786e\u5b9aRC\u9009\u62e9\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u57fa\u4e8e\u53cc\u4e8c\u6b21\u53d8\u6362\u7684\u5206\u6570\u89c4\u5212\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u67b6\u6784\u5728\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u63d0\u51fa\u7684\u590d\u6742\u5ea6\u4f18\u5316\u65b9\u6848\u6027\u80fd\u635f\u5931\u8f83\u5c0f\u3002", "conclusion": "RCRAA\u5728\u63d0\u5347\u6ce2\u675f\u6210\u5f62\u6027\u80fd\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u540c\u65f6\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.16459", "pdf": "https://arxiv.org/pdf/2508.16459", "abs": "https://arxiv.org/abs/2508.16459", "authors": ["Ali Emre Balc\u0131", "Erhan Ege Keyvan", "Emre \u00d6zkan"], "title": "GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks", "categories": ["cs.RO"], "comment": "Authors Ali Emre Balc{\\i} and Erhan Ege Keyvan contributed equally to\n  this work", "summary": "We present a novel Simultaneous Localization and Mapping (SLAM) method that\nemploys Gaussian Process (GP) based landmark (object) representations. Instead\nof conventional grid maps or point cloud registration, we model the environment\non a per object basis using GP based contour representations. These contours\nare updated online through a recursive scheme, enabling efficient memory usage.\nThe SLAM problem is formulated within a fully Bayesian framework, allowing\njoint inference over the robot pose and object based map. This representation\nprovides semantic information such as the number of objects and their areas,\nwhile also supporting probabilistic measurement to object associations.\nFurthermore, the GP based contours yield confidence bounds on object shapes,\noffering valuable information for downstream tasks like safe navigation and\nexploration. We validate our method on synthetic and real world experiments,\nand show that it delivers accurate localization and mapping performance across\ndiverse structured environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u7684\u65b0\u578bSLAM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u8c61\u8f6e\u5ed3\u5efa\u6a21\u73af\u5883\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u5728\u7ebf\u66f4\u65b0\u548c\u8bed\u4e49\u4fe1\u606f\u63d0\u53d6\u3002", "motivation": "\u4f20\u7edfSLAM\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u7f51\u683c\u5730\u56fe\u6216\u70b9\u4e91\u914d\u51c6\uff0c\u7f3a\u4e4f\u8bed\u4e49\u4fe1\u606f\u548c\u9ad8\u65af\u8fc7\u7a0b\u5e26\u6765\u7684\u5f62\u72b6\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "method": "\u91c7\u7528GP\u5efa\u6a21\u5bf9\u8c61\u8f6e\u5ed3\uff0c\u5e76\u7ed3\u5408\u8d1d\u53f6\u65af\u6846\u67b6\u8fdb\u884c\u673a\u5668\u4eba\u4f4d\u59ff\u548c\u5730\u56fe\u7684\u8054\u5408\u63a8\u65ad\u3002", "result": "\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u8868\u73b0\u51fa\u51c6\u786e\u7684\u5b9a\u4f4d\u548c\u5efa\u56fe\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u8bed\u4e49\u4fe1\u606f\uff0c\u8fd8\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u5b89\u5168\u5bfc\u822a\u548c\u63a2\u7d22\uff09\u3002"}}
{"id": "2508.15963", "pdf": "https://arxiv.org/pdf/2508.15963", "abs": "https://arxiv.org/abs/2508.15963", "authors": ["Celestin Nkundineza", "James Ndodana Njaji", "Samrawit Abubeker", "Omar Gatera", "Damien Hanyurwimfura"], "title": "Advancing rail safety: An onboard measurement system of rolling stock wheel flange wear based on dynamic machine learning algorithms", "categories": ["cs.LG", "cs.CE", "cs.SY", "eess.SP", "eess.SY", "physics.ins-det"], "comment": "Journal article published in Transportation Research Record: The\n  Journal of Transportation Research Board", "summary": "Rail and wheel interaction functionality is pivotal to the railway system\nsafety, requiring accurate measurement systems for optimal safety monitoring\noperation. This paper introduces an innovative onboard measurement system for\nmonitoring wheel flange wear depth, utilizing displacement and temperature\nsensors. Laboratory experiments are conducted to emulate wheel flange wear\ndepth and surrounding temperature fluctuations in different periods of time.\nEmploying collected data, the training of machine learning algorithms that are\nbased on regression models, is dynamically automated. Further experimentation\nresults, using standards procedures, validate the system's efficacy. To enhance\naccuracy, an infinite impulse response filter (IIR) that mitigates vehicle\ndynamics and sensor noise is designed. Filter parameters were computed based on\nspecifications derived from a Fast Fourier Transform analysis of locomotive\nsimulations and emulation experiments data. The results show that the dynamic\nmachine learning algorithm effectively counter sensor nonlinear response to\ntemperature effects, achieving an accuracy of 96.5 %, with a minimal runtime.\nThe real-time noise reduction via IIR filter enhances the accuracy up to 98.2\n%. Integrated with railway communication embedded systems such as Internet of\nThings devices, this advanced monitoring system offers unparalleled real-time\ninsights into wheel flange wear and track irregular conditions that cause it,\nensuring heightened safety and efficiency in railway systems operations.", "AI": {"tldr": "\u4ecb\u7ecd\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548cIIR\u6ee4\u6ce2\u7684\u5b9e\u65f6\u8f6e\u7f18\u78e8\u635f\u76d1\u6d4b\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u663e\u793a\u5176\u9ad8\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u94c1\u8def\u7cfb\u7edf\u5b89\u5168\u4f9d\u8d56\u8f6e\u8f68\u76f8\u4e92\u4f5c\u7528\u7684\u7cbe\u786e\u76d1\u6d4b\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u4f18\u5316\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u9ad8\u6548\u76d1\u63a7\u3002", "method": "\u7ed3\u5408\u4f4d\u79fb\u4e0e\u6e29\u5ea6\u4f20\u611f\u5668\u6570\u636e\uff0c\u52a8\u6001\u8bad\u7ec3\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1IIR\u6ee4\u6ce2\u964d\u566a\u3002", "result": "\u7cfb\u7edf\u7cbe\u5ea6\u8fbe96.5%\uff0c\u6ee4\u6ce2\u540e\u63d0\u5347\u81f398.2%\uff0c\u5b9e\u65f6\u76d1\u6d4b\u8f6e\u7f18\u78e8\u635f\u4e0e\u8f68\u9053\u5f02\u5e38\u3002", "conclusion": "\u8be5\u96c6\u6210\u7cfb\u7edf\u901a\u8fc7\u5b9e\u65f6\u6570\u636e\u5206\u6790\u548c\u6ee4\u6ce2\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u94c1\u8def\u5b89\u5168\u4e0e\u8fd0\u8425\u6548\u7387\u3002"}}
{"id": "2508.16460", "pdf": "https://arxiv.org/pdf/2508.16460", "abs": "https://arxiv.org/abs/2508.16460", "authors": ["Jiri Horyna", "Roland Jung", "Stephan Weiss", "Eliseo Ferrante", "Martin Saska"], "title": "Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot", "categories": ["cs.RO", "cs.MA"], "comment": "Accepted to IEEE RA-L on April 1, 2025", "summary": "In this paper, we present the Swarming Without an Anchor (SWA) approach to\nstate estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing\nego-localization dropout, where individual agents are laterally stabilized\nusing relative information only. We propose to fuse decentralized state\nestimation with robust mutual perception and onboard sensor data to maintain\naccurate state awareness despite intermittent localization failures. Thus, the\nrelative information used to estimate the lateral state of UAVs enables the\nidentification of the unambiguous state of UAVs with respect to the local\nconstellation. The resulting behavior reaches velocity consensus, as this task\ncan be referred to as the double integrator synchronization problem. All\ndisturbances and performance degradations except a uniform translation drift of\nthe swarm as a whole is attenuated which is enabling new opportunities in using\ntight cooperation for increasing reliability and resilience of multi-UAV\nsystems. Simulations and real-world experiments validate the effectiveness of\nour approach, demonstrating its capability to sustain cohesive swarm behavior\nin challenging conditions of unreliable or unavailable primary localization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSWA\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u65e0\u4eba\u673a\u7fa4\u4e2d\u5b9e\u73b0\u72b6\u6001\u4f30\u8ba1\uff0c\u901a\u8fc7\u878d\u5408\u5206\u6563\u7684\u72b6\u6001\u4f30\u8ba1\u3001\u9c81\u68d2\u76f8\u4e92\u611f\u77e5\u548c\u673a\u8f7d\u4f20\u611f\u5668\u6570\u636e\uff0c\u5e94\u5bf9\u5b9a\u4f4d\u5931\u6548\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65e0\u4eba\u673a\u7fa4\u5728\u5b9a\u4f4d\u5931\u6548\u60c5\u51b5\u4e0b\u5982\u4f55\u901a\u8fc7\u76f8\u5bf9\u4fe1\u606f\u7ef4\u6301\u7a33\u5b9a\u72b6\u6001\u7684\u95ee\u9898\u3002", "method": "\u878d\u5408\u5206\u6563\u7684\u72b6\u6001\u4f30\u8ba1\u3001\u9c81\u68d2\u76f8\u4e92\u611f\u77e5\u548c\u673a\u8f7d\u4f20\u611f\u5668\u6570\u636e\uff0c\u5229\u7528\u76f8\u5bf9\u4fe1\u606f\u8fdb\u884c\u6a2a\u5411\u72b6\u6001\u4f30\u8ba1\u3002", "result": "\u5b9e\u73b0\u4e86\u901f\u5ea6\u5171\u8bc6\uff0c\u6291\u5236\u4e86\u9664\u6574\u4f53\u5e73\u79fb\u6f02\u79fb\u5916\u7684\u6240\u6709\u5e72\u6270\uff0c\u63d0\u9ad8\u4e86\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u5f39\u6027\u3002", "conclusion": "\u6a21\u62df\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SWA\u65b9\u6cd5\u5728\u5b9a\u4f4d\u4e0d\u53ef\u9760\u6216\u5931\u6548\u60c5\u51b5\u4e0b\u7ef4\u6301\u7fa4\u4f53\u884c\u4e3a\u7684\u80fd\u529b\u3002"}}
{"id": "2508.16033", "pdf": "https://arxiv.org/pdf/2508.16033", "abs": "https://arxiv.org/abs/2508.16033", "authors": ["Jong-Hwan Jang", "Junho Song", "Yong-Yeon Jo"], "title": "CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics", "categories": ["cs.AI", "eess.SP"], "comment": "Demo paper, 5 pages", "summary": "Recognizing the need for explainable AI (XAI) approaches to enable the\nsuccessful integration of AI-based ECG prediction models (AI-ECG) into clinical\npractice, we introduce a framework generating \\textbf{Co}unter\\textbf{F}actual\n\\textbf{E}CGs (i,e., named CoFE) to illustrate how specific features, such as\namplitudes and intervals, influence the model's predictive decisions. To\ndemonstrate the applicability of the CoFE, we present two case studies: atrial\nfibrillation classification and potassium level regression models. The CoFE\nreveals feature changes in ECG signals that align with the established clinical\nknowledge. By clarifying both \\textbf{where valid features appear} in the ECG\nand \\textbf{how they influence the model's predictions}, we anticipate that our\nframework will enhance the interpretability of AI-ECG models and support more\neffective clinical decision-making. Our demonstration video is available at:\nhttps://www.youtube.com/watch?v=YoW0bNBPglQ.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCoFE\u7684\u6846\u67b6\uff0c\u751f\u6210\u53cd\u4e8b\u5b9e\u5fc3\u7535\u56fe\u4ee5\u89e3\u91caAI-ECG\u6a21\u578b\u7684\u9884\u6d4b\u903b\u8f91\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u5176\u4e34\u5e8a\u9002\u7528\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3AI-ECG\u6a21\u578b\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1CoFE\u6846\u67b6\uff0c\u751f\u6210\u53cd\u4e8b\u5b9e\u5fc3\u7535\u56fe\uff0c\u5206\u6790\u7279\u5f81\uff08\u5982\u632f\u5e45\u548c\u95f4\u9694\uff09\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "result": "CoFE\u63ed\u793a\u7684\u7279\u5f81\u53d8\u5316\u4e0e\u4e34\u5e8a\u77e5\u8bc6\u4e00\u81f4\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u3002", "conclusion": "CoFE\u6846\u67b6\u589e\u5f3a\u4e86AI-ECG\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u4e34\u5e8a\u51b3\u7b56\u3002"}}
{"id": "2508.16504", "pdf": "https://arxiv.org/pdf/2508.16504", "abs": "https://arxiv.org/abs/2508.16504", "authors": ["Sophie Villemure", "Jefferson Silveira", "Joshua A. Marshall"], "title": "Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing", "categories": ["cs.RO", "eess.SP"], "comment": null, "summary": "Quadrupedal mobile robots can traverse a wider range of terrain types than\ntheir wheeled counterparts but do not perform the same on all terrain types.\nThese robots are prone to undesirable behaviours like sinking and slipping on\nchallenging terrains. To combat this issue, we propose a terrain classifier\nthat provides information on terrain type that can be used in robotic systems\nto create a traversability map to plan safer paths for the robot to navigate.\nThe work presented here is a terrain classifier developed for a Boston Dynamics\nSpot robot. Spot provides over 100 measured proprioceptive signals describing\nthe motions of the robot and its four legs (e.g., foot penetration, forces,\njoint angles, etc.). The developed terrain classifier combines dimensionality\nreduction techniques to extract relevant information from the signals and then\napplies a classification technique to differentiate terrain based on\ntraversability. In representative field testing, the resulting terrain\nclassifier was able to identify three different terrain types with an accuracy\nof approximately 97%", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6ce2\u58eb\u987f\u52a8\u529bSpot\u673a\u5668\u4eba\u7684\u5730\u5f62\u5206\u7c7b\u5668\uff0c\u65e8\u5728\u89e3\u51b3\u56db\u8db3\u673a\u5668\u4eba\u5728\u590d\u6742\u5730\u5f62\u4e2d\u7684\u4e0b\u6c89\u548c\u6253\u6ed1\u95ee\u9898\uff0c\u51c6\u786e\u7387\u7ea6\u4e3a97%\u3002", "motivation": "\u56db\u8db3\u673a\u5668\u4eba\u867d\u7136\u5728\u591a\u79cd\u5730\u5f62\u4e2d\u8868\u73b0\u4f18\u4e8e\u8f6e\u5f0f\u673a\u5668\u4eba\uff0c\u4f46\u5728\u590d\u6742\u5730\u5f62\u4e2d\u5bb9\u6613\u51fa\u73b0\u4e0b\u6c89\u548c\u6253\u6ed1\u7b49\u4e0d\u826f\u884c\u4e3a\u3002\u901a\u8fc7\u5f00\u53d1\u5730\u5f62\u5206\u7c7b\u5668\uff0c\u53ef\u4ee5\u4e3a\u673a\u5668\u4eba\u751f\u6210\u53ef\u901a\u884c\u5730\u56fe\uff0c\u4ece\u800c\u89c4\u5212\u66f4\u5b89\u5168\u7684\u8def\u5f84\u3002", "method": "\u5229\u7528Spot\u673a\u5668\u4eba\u63d0\u4f9b\u7684100\u591a\u4e2a\u672c\u4f53\u611f\u53d7\u4fe1\u53f7\uff08\u5982\u811a\u90e8\u7a7f\u900f\u529b\u3001\u529b\u548c\u5173\u8282\u89d2\u5ea6\u7b49\uff09\uff0c\u7ed3\u5408\u964d\u7ef4\u6280\u672f\u63d0\u53d6\u5173\u952e\u4fe1\u606f\uff0c\u5e76\u4f7f\u7528\u5206\u7c7b\u6280\u672f\u6839\u636e\u53ef\u901a\u884c\u6027\u533a\u5206\u5730\u5f62\u3002", "result": "\u5728\u4ee3\u8868\u6027\u5b9e\u5730\u6d4b\u8bd5\u4e2d\uff0c\u5730\u5f62\u5206\u7c7b\u5668\u80fd\u591f\u4ee5\u7ea697%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u4e09\u79cd\u4e0d\u540c\u7684\u5730\u5f62\u7c7b\u578b\u3002", "conclusion": "\u8be5\u5730\u5f62\u5206\u7c7b\u5668\u80fd\u6709\u6548\u5e2e\u52a9\u56db\u8db3\u673a\u5668\u4eba\u8bc6\u522b\u590d\u6742\u5730\u5f62\uff0c\u63d0\u9ad8\u5176\u5728\u591a\u7c7b\u578b\u5730\u5f62\u4e2d\u7684\u5bfc\u822a\u5b89\u5168\u6027\u3002"}}
{"id": "2508.16179", "pdf": "https://arxiv.org/pdf/2508.16179", "abs": "https://arxiv.org/abs/2508.16179", "authors": ["Jamal Hwaidi", "Mohamed Chahine Ghanem"], "title": "Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "The brain-computer interface (BCI) establishes a non-muscle channel that\nenables direct communication between the human body and an external device.\nElectroencephalography (EEG) is a popular non-invasive technique for recording\nbrain signals. It is critical to process and comprehend the hidden patterns\nlinked to a specific cognitive or motor task, for instance, measured through\nthe motor imagery brain-computer interface (MI-BCI). A significant challenge is\npresented by classifying motor imagery-based electroencephalogram (MI-EEG)\ntasks, given that EEG signals exhibit nonstationarity, time-variance, and\nindividual diversity. Obtaining good classification accuracy is also very\ndifficult due to the growing number of classes and the natural variability\namong individuals. To overcome these issues, this paper proposes a novel method\nfor classifying EEG motor imagery signals that extracts features efficiently\nwith Minimally Random Convolutional Kernel Transform (MiniRocket), a linear\nclassifier then uses the extracted features for activity recognition.\nFurthermore, a novel deep learning based on Convolutional Neural Network (CNN)\nand Long Short Term Memory (LSTM) architecture to serve as a baseline was\nproposed and demonstrated that classification via MiniRocket's features\nachieves higher performance than the best deep learning models at lower\ncomputational cost. The PhysioNet dataset was used to evaluate the performance\nof the proposed approaches. The proposed models achieved mean accuracy values\nof 98.63% and 98.06% for the MiniRocket and CNN-LSTM, respectively. The\nfindings demonstrate that the proposed approach can significantly enhance motor\nimagery EEG accuracy and provide new insights into the feature extraction and\nclassification of MI-EEG.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMiniRocket\u548cCNN-LSTM\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u8fd0\u52a8\u60f3\u8c61\u8111\u7535\u4fe1\u53f7\uff08MI-EEG\uff09\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5e76\u5728\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u8111\u7535\u4fe1\u53f7\uff08EEG\uff09\u5177\u6709\u975e\u5e73\u7a33\u6027\u3001\u65f6\u95f4\u53d8\u5316\u6027\u548c\u4e2a\u4f53\u5dee\u5f02\u6027\uff0c\u5bfc\u81f4\u8fd0\u52a8\u60f3\u8c61\u4efb\u52a1\u7684\u5206\u7c7b\u5177\u6709\u6311\u6218\u6027\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u9ad8\u6548\u7684\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u65b9\u6cd5\u63d0\u5347MI-EEG\u7684\u5206\u7c7b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a1. \u4f7f\u7528MiniRocket\u8fdb\u884c\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\u5e76\u642d\u914d\u7ebf\u6027\u5206\u7c7b\u5668\uff1b2. \u6784\u5efaCNN-LSTM\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\u3002\u5b9e\u9a8c\u57fa\u4e8ePhysioNet\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "MiniRocket\u548cCNN-LSTM\u7684\u5e73\u5747\u5206\u7c7b\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523098.63%\u548c98.06%\uff0c\u8868\u660eMiniRocket\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u9ad8\u6548\u7684MI-EEG\u5206\u7c7b\u65b9\u6cd5\uff0c\u4e3a\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2508.16511", "pdf": "https://arxiv.org/pdf/2508.16511", "abs": "https://arxiv.org/abs/2508.16511", "authors": ["Otobong Jerome", "Alexandr Klimchik", "Alexander Maloletov", "Geesara Kulathunga"], "title": "On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach", "categories": ["cs.RO", "math.OC"], "comment": null, "summary": "This work casts the kinodynamic planning problem for car-like vehicles as an\noptimization task to compute a minimum-time trajectory and its associated\nvelocity profile, subject to boundary conditions on velocity, acceleration, and\nsteering. The approach simultaneously optimizes both the spatial path and the\nsequence of acceleration and steering controls, ensuring continuous motion from\na specified initial position and velocity to a target end position and\nvelocity.The method analyzes the admissible control space and terrain to avoid\nlocal minima. The proposed method operates efficiently in simplicial complex\nenvironments, a preferred terrain representation for capturing intricate 3D\nlandscapes. The problem is initially posed as a mixed-integer fractional\nprogram with quadratic constraints, which is then reformulated into a\nmixed-integer bilinear objective through a variable transformation and\nsubsequently relaxed to a mixed-integer linear program using McCormick\nenvelopes. Comparative simulations against planners such as MPPI and log-MPPI\ndemonstrate that the proposed approach generates solutions 104 times faster\nwhile strictly adhering to the specified constraints", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u6c7d\u8f66\u7c7b\u8f66\u8f86\u7684\u52a8\u529b\u5b66\u89c4\u5212\u95ee\u9898\u8f6c\u5316\u4e3a\u4f18\u5316\u4efb\u52a1\uff0c\u8ba1\u7b97\u6700\u5c0f\u65f6\u95f4\u8f68\u8ff9\u53ca\u5176\u901f\u5ea6\u5206\u5e03\uff0c\u540c\u65f6\u6ee1\u8db3\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u548c\u8f6c\u5411\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7a7a\u95f4\u8def\u5f84\u548c\u63a7\u5236\u5e8f\u5217\u786e\u4fdd\u8fd0\u52a8\u8fde\u7eed\u6027\u3002", "motivation": "\u89e3\u51b3\u6c7d\u8f66\u7c7b\u8f66\u8f86\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u52a8\u529b\u5b66\u89c4\u5212\u95ee\u9898\uff0c\u540c\u65f6\u4f18\u5316\u8def\u5f84\u548c\u63a7\u5236\u5e8f\u5217\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u5e76\u4e25\u683c\u9075\u5b88\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u5c06\u95ee\u9898\u521d\u59cb\u5316\u4e3a\u6df7\u5408\u6574\u6570\u5206\u6570\u89c4\u5212\uff0c\u901a\u8fc7\u53d8\u91cf\u53d8\u6362\u8f6c\u4e3a\u6df7\u5408\u6574\u6570\u53cc\u7ebf\u6027\u76ee\u6807\uff0c\u518d\u7528McCormick\u5305\u7edc\u677e\u5f1b\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u5206\u6790\u63a7\u5236\u7a7a\u95f4\u548c\u5730\u5f62\u907f\u514d\u5c40\u90e8\u6700\u5c0f\u503c\u3002", "result": "\u4eff\u771f\u6bd4\u8f83\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u6bd4MPPI\u548clog-MPPI\u5feb104\u500d\uff0c\u4e14\u4e25\u683c\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u89e3\u51b3\u4e86\u6c7d\u8f66\u7c7b\u8f66\u8f86\u7684\u52a8\u529b\u5b66\u89c4\u5212\u95ee\u9898\uff0c\u4e3a\u590d\u67423D\u73af\u5883\u4e2d\u7684\u8def\u5f84\u89c4\u5212\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16237", "pdf": "https://arxiv.org/pdf/2508.16237", "abs": "https://arxiv.org/abs/2508.16237", "authors": ["Patricia Amado-Caballero", "Luis M. San-Jos\u00e9-Revuelta", "Xinheng Wang", "Jos\u00e9 Ram\u00f3n Garmendia-Leiza", "Carlos Alberola-L\u00f3pez", "Pablo Casaseca-de-la-Higuera"], "title": "A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease", "categories": ["cs.LG", "cs.AI", "eess.AS", "eess.SP"], "comment": null, "summary": "This paper presents an explainable artificial intelligence (XAI)-based\nframework for the spectral analysis of cough sounds associated with chronic\nrespiratory diseases, with a particular focus on Chronic Obstructive Pulmonary\nDisease (COPD). A Convolutional Neural Network (CNN) is trained on\ntime-frequency representations of cough signals, and occlusion maps are used to\nidentify diagnostically relevant regions within the spectrograms. These\nhighlighted areas are subsequently decomposed into five frequency subbands,\nenabling targeted spectral feature extraction and analysis. The results reveal\nthat spectral patterns differ across subbands and disease groups, uncovering\ncomplementary and compensatory trends across the frequency spectrum.\nNoteworthy, the approach distinguishes COPD from other respiratory conditions,\nand chronic from non-chronic patient groups, based on interpretable spectral\nmarkers. These findings provide insight into the underlying pathophysiological\ncharacteristics of cough acoustics and demonstrate the value of\nfrequency-resolved, XAI-enhanced analysis for biomedical signal interpretation\nand translational respiratory disease diagnostics.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u6162\u6027\u547c\u5438\u9053\u75be\u75c5\uff08\u5c24\u5176\u662f\u6162\u6027\u963b\u585e\u6027\u80ba\u75c5\uff0cCOPD\uff09\u7684\u54b3\u55fd\u58f0\u97f3\u9891\u8c31\u3002\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u8bad\u7ec3\u54b3\u55fd\u4fe1\u53f7\u7684\u65f6\u9891\u8868\u793a\uff0c\u5e76\u5229\u7528\u906e\u6321\u56fe\u8bc6\u522b\u9891\u8c31\u56fe\u4e2d\u4e0e\u8bca\u65ad\u76f8\u5173\u7684\u533a\u57df\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u533a\u5206COPD\u548c\u5176\u4ed6\u547c\u5438\u7cfb\u7edf\u75be\u75c5\uff0c\u5e76\u4e3a\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u89e3\u91ca\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u6162\u6027\u547c\u5438\u9053\u75be\u75c5\uff08\u5982COPD\uff09\u7684\u54b3\u55fd\u58f0\u97f3\u5206\u6790\u5bf9\u8bca\u65ad\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7XAI\u6280\u672f\uff0c\u63d0\u4f9b\u4e00\u79cd\u900f\u660e\u4e14\u53ef\u89e3\u91ca\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528CNN\u8bad\u7ec3\u54b3\u55fd\u4fe1\u53f7\u7684\u65f6\u9891\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u906e\u6321\u56fe\u5b9a\u4f4d\u9891\u8c31\u56fe\u7684\u8bca\u65ad\u76f8\u5173\u533a\u57df\uff0c\u968f\u540e\u5206\u89e3\u4e3a\u4e94\u4e2a\u9891\u5e26\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0d\u540c\u9891\u5e26\u7684\u9891\u8c31\u6a21\u5f0f\u5728\u75be\u75c5\u7ec4\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u533a\u5206COPD\u548c\u5176\u4ed6\u547c\u5438\u7cfb\u7edf\u75be\u75c5\uff0c\u4ee5\u53ca\u6162\u6027\u4e0e\u975e\u6162\u6027\u60a3\u8005\u7ec4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u54b3\u55fd\u58f0\u5b66\u7684\u75c5\u7406\u751f\u7406\u7279\u5f81\uff0c\u8bc1\u660e\u4e86XAI\u5728\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u5206\u6790\u548c\u547c\u5438\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2508.16515", "pdf": "https://arxiv.org/pdf/2508.16515", "abs": "https://arxiv.org/abs/2508.16515", "authors": ["Hichem Cheriet", "Khellat Kihel Badra", "Chouraqui Samira"], "title": "Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The most crucial challenges for UAVs are planning paths and avoiding\nobstacles in their way. In recent years, a wide variety of path-planning\nalgorithms have been developed. These algorithms have successfully solved\npath-planning problems; however, they suffer from multiple challenges and\nlimitations. To test the effectiveness and efficiency of three widely used\nalgorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper\nconducts extensive experiments in 3D urban city environments cluttered with\nobstacles. Three experiments were designed with two scenarios each to test the\naforementioned algorithms. These experiments consider different city map sizes,\ndifferent altitudes, and varying obstacle densities and sizes in the\nenvironment. According to the experimental results, the A* algorithm\noutperforms the others in both computation efficiency and path quality. PSO is\nespecially suitable for tight turns and dense environments, and RRT* offers a\nbalance and works well across all experiments due to its randomized approach to\nfinding solutions.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86A*\u3001RRT*\u548cPSO\u7b97\u6cd5\u57283D\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u8def\u5f84\u89c4\u5212\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660eA*\u5728\u8ba1\u7b97\u6548\u7387\u548c\u8def\u5f84\u8d28\u91cf\u4e0a\u8868\u73b0\u6700\u4f18\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u548c\u907f\u969c\u4e2d\u7684\u7b97\u6cd5\u6548\u7387\u548c\u9002\u7528\u6027\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u79cd\u5b9e\u9a8c\uff0c\u57283D\u57ce\u5e02\u73af\u5883\u4e2d\u6d4b\u8bd5A*\u3001RRT*\u548cPSO\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5305\u62ec\u4e0d\u540c\u5730\u56fe\u5927\u5c0f\u3001\u9ad8\u5ea6\u548c\u969c\u788d\u7269\u5bc6\u5ea6\u3002", "result": "A*\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u8def\u5f84\u8d28\u91cf\u4e0a\u8868\u73b0\u6700\u4f73\uff0cPSO\u9002\u7528\u4e8e\u5bc6\u96c6\u73af\u5883\uff0cRRT*\u5728\u6240\u6709\u5b9e\u9a8c\u4e2d\u8868\u73b0\u5747\u8861\u3002", "conclusion": "A*\u7b97\u6cd5\u7efc\u5408\u8868\u73b0\u6700\u4f18\uff0c\u4e0d\u540c\u7b97\u6cd5\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\uff0c\u4e3a\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u63d0\u4f9b\u5b9e\u7528\u53c2\u8003\u3002"}}
{"id": "2508.16282", "pdf": "https://arxiv.org/pdf/2508.16282", "abs": "https://arxiv.org/abs/2508.16282", "authors": ["Khai Duc Minh Tran", "Hoa Van Nguyen", "Aimuni Binti Muhammad Rawi", "Hareeshrao Athinarayanarao", "Ba-Ngu Vo"], "title": "Robust Small Methane Plume Segmentation in Satellite Imagery", "categories": ["cs.CV", "eess.SP"], "comment": "6 pages, 3 figures. This paper is submitted to the International\n  Conference on Control, Automation and Information Sciences (ICCAIS) 2025,\n  Jeju, Korea", "summary": "This paper tackles the challenging problem of detecting methane plumes, a\npotent greenhouse gas, using Sentinel-2 imagery. This contributes to the\nmitigation of rapid climate change. We propose a novel deep learning solution\nbased on U-Net with a ResNet34 encoder, integrating dual spectral enhancement\ntechniques (Varon ratio and Sanchez regression) to optimise input features for\nheightened sensitivity. A key achievement is the ability to detect small plumes\ndown to 400 m2 (i.e., for a single pixel at 20 m resolution), surpassing\ntraditional methods limited to larger plumes. Experiments show our approach\nachieves a 78.39% F1-score on the validation set, demonstrating superior\nperformance in sensitivity and precision over existing remote sensing\ntechniques for automated methane monitoring, especially for small plumes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eU-Net\u548cResNet34\u7f16\u7801\u5668\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u53cc\u5149\u8c31\u589e\u5f3a\u6280\u672f\uff0c\u63d0\u9ad8\u4e86Sentinel-2\u5f71\u50cf\u4e2d\u7532\u70f7\u7fbd\u6d41\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5bf9\u5c0f\u7fbd\u6d41\u7684\u68c0\u6d4b\u6548\u679c\u663e\u8457\u3002", "motivation": "\u7532\u70f7\u662f\u4e00\u79cd\u5f3a\u6548\u6e29\u5ba4\u6c14\u4f53\uff0c\u5feb\u901f\u51c6\u786e\u5730\u68c0\u6d4b\u7532\u70f7\u7fbd\u6d41\u5bf9\u7f13\u89e3\u6c14\u5019\u53d8\u5316\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528\u4e86U-Net\u7f51\u7edc\u7ed3\u6784\uff0c\u914d\u5907ResNet34\u7f16\u7801\u5668\uff0c\u7ed3\u5408Varon\u6bd4\u548cSanchez\u56de\u5f52\u53cc\u5149\u8c31\u589e\u5f3a\u6280\u672f\uff0c\u4f18\u5316\u8f93\u5165\u7279\u5f81\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u7075\u654f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u5230\u4e8678.39%\u7684F1\u5206\u6570\uff0c\u5c24\u5176\u5bf9\u5c0f\u81f3400\u5e73\u65b9\u7c73\u7684\u7fbd\u6d41\u68c0\u6d4b\u6548\u679c\u663e\u8457\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u52a8\u5316\u7532\u70f7\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u654f\u611f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u68c0\u6d4b\u5c0f\u89c4\u6a21\u7fbd\u6d41\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2508.16574", "pdf": "https://arxiv.org/pdf/2508.16574", "abs": "https://arxiv.org/abs/2508.16574", "authors": ["Yizhi Wang", "Degang Xu", "Yongfang Xie", "Shuzhong Tan", "Xianan Zhou", "Peng Chen"], "title": "Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper presents a hierarchical decision-making framework for autonomous\nnavigation in four-wheel independent steering and driving (4WISD) systems. The\nproposed approach integrates deep reinforcement learning (DRL) for high-level\nnavigation with fuzzy logic for low-level control to ensure both task\nperformance and physical feasibility. The DRL agent generates global motion\ncommands, while the fuzzy logic controller enforces kinematic constraints to\nprevent mechanical strain and wheel slippage. Simulation experiments\ndemonstrate that the proposed framework outperforms traditional navigation\nmethods, offering enhanced training efficiency and stability and mitigating\nerratic behaviors compared to purely DRL-based solutions. Real-world\nvalidations further confirm the framework's ability to navigate safely and\neffectively in dynamic industrial settings. Overall, this work provides a\nscalable and reliable solution for deploying 4WISD mobile robots in complex,\nreal-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u56db\u8f6e\u72ec\u7acb\u8f6c\u5411\u548c\u9a71\u52a8\uff084WISD\uff09\u7cfb\u7edf\u7684\u5206\u5c42\u51b3\u7b56\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u548c\u6a21\u7cca\u903b\u8f91\uff0c\u63d0\u5347\u5bfc\u822a\u6548\u80fd\u4e0e\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b34WISD\u7cfb\u7edf\u5728\u9ad8\u52a8\u6001\u5de5\u4e1a\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u95ee\u9898\uff0c\u5e73\u8861\u4efb\u52a1\u6027\u80fd\u4e0e\u673a\u68b0\u9650\u5236\u3002", "method": "\u7ed3\u5408DRL\u8fdb\u884c\u9ad8\u7ea7\u5bfc\u822a\u51b3\u7b56\uff0c\u6a21\u7cca\u903b\u8f91\u63a7\u5236\u5668\u5904\u7406\u4f4e\u7ea7\u8fd0\u52a8\u7ea6\u675f\uff0c\u907f\u514d\u673a\u68b0\u635f\u4f24\u548c\u8f6e\u6ed1\u3002", "result": "\u4eff\u771f\u53ca\u5b9e\u9a8c\u8bc1\u660e\u6846\u67b6\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11DRL\u65b9\u6848\u7684\u5f02\u5e38\u884c\u4e3a\u3002", "conclusion": "\u4e3a\u590d\u6742\u5de5\u4e1a\u73af\u5883\u4e2d\u76844WISD\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16352", "pdf": "https://arxiv.org/pdf/2508.16352", "abs": "https://arxiv.org/abs/2508.16352", "authors": ["Nasir Khan", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil", "Sinem Coleri"], "title": "Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management", "categories": ["cs.AI", "eess.SP"], "comment": null, "summary": "Efficient and reliable beam alignment is a critical requirement for mmWave\nmultiple-input multiple-output (MIMO) systems, especially in 6G and beyond,\nwhere communication must be fast, adaptive, and resilient to real-world\nuncertainties. Existing deep learning (DL)-based beam alignment methods often\nneglect the underlying causal relationships between inputs and outputs, leading\nto limited interpretability, poor generalization, and unnecessary beam sweeping\noverhead. In this work, we propose a causally-aware DL framework that\nintegrates causal discovery into beam management pipeline. Particularly, we\npropose a novel two-stage causal beam selection algorithm to identify a minimal\nset of relevant inputs for beam prediction. First, causal discovery learns a\nBayesian graph capturing dependencies between received power inputs and the\noptimal beam. Then, this graph guides causal feature selection for the DL-based\nclassifier. Simulation results reveal that the proposed causal beam selection\nmatches the performance of conventional methods while drastically reducing\ninput selection time by 94.4% and beam sweeping overhead by 59.4% by focusing\nonly on causally relevant features.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u4e2d\u7684\u6ce2\u675f\u5bf9\u9f50\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8f93\u5165\u9009\u62e9\u65f6\u95f4\u548c\u6ce2\u675f\u626b\u63cf\u5f00\u9500\u3002", "motivation": "6G\u53ca\u4ee5\u540e\u901a\u4fe1\u9700\u8981\u9ad8\u6548\u3001\u53ef\u9760\u7684\u6ce2\u675f\u5bf9\u9f50\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5ffd\u89c6\u56e0\u679c\u5173\u7cfb\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u56e0\u679c\u6ce2\u675f\u9009\u62e9\u7b97\u6cd5\uff0c\u5148\u901a\u8fc7\u56e0\u679c\u53d1\u73b0\u5b66\u4e60\u8d1d\u53f6\u65af\u56fe\uff0c\u518d\u7528\u4e8e\u6307\u5bfc\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u7279\u5f81\u9009\u62e9\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8f93\u5165\u9009\u62e9\u65f6\u95f4\u51cf\u5c1194.4%\uff0c\u6ce2\u675f\u626b\u63cf\u5f00\u9500\u51cf\u5c1159.4%\u3002", "conclusion": "\u56e0\u679c\u611f\u77e5\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u6ce2\u675f\u5bf9\u9f50\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.15873", "pdf": "https://arxiv.org/pdf/2508.15873", "abs": "https://arxiv.org/abs/2508.15873", "authors": ["Sizhe Tian", "Yinoussa Adagolodjo", "Jeremie Dequidt"], "title": "Active Prostate Phantom with Multiple Chambers", "categories": ["physics.med-ph", "cs.RO"], "comment": null, "summary": "Prostate cancer is a major global health concern, requiring advancements in\nrobotic surgery and diagnostics to improve patient outcomes. A phantom is a\nspecially designed object that simulates human tissues or organs. It can be\nused for calibrating and testing a medical process, as well as for training and\nresearch purposes. Existing prostate phantoms fail to simulate dynamic\nscenarios. This paper presents a pneumatically actuated prostate phantom with\nmultiple independently controlled chambers, allowing for precise volumetric\nadjustments to replicate asymmetric and symmetric benign prostatic hyperplasia\n(BPH). The phantom is designed based on shape analysis of magnetic resonance\nimaging (MRI) datasets, modeled with finite element method (FEM), and validated\nthrough 3D reconstruction. The simulation results showed strong agreement with\nphysical measurements, achieving average errors of 3.47% in forward modeling\nand 1.41% in inverse modeling. These results demonstrate the phantom's\npotential as a platform for validating robotic-assisted systems and for further\ndevelopment toward realistic simulation-based medical training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6c14\u52a8\u9a71\u52a8\u7684\u591a\u8154\u524d\u5217\u817a\u6a21\u578b\uff0c\u7528\u4e8e\u52a8\u6001\u6a21\u62dfBPH\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u673a\u5668\u4eba\u624b\u672f\u548c\u533b\u5b66\u8bad\u7ec3\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u524d\u5217\u817a\u6a21\u578b\u65e0\u6cd5\u6a21\u62df\u52a8\u6001\u573a\u666f\uff0c\u9700\u6539\u8fdb\u4ee5\u652f\u6301\u673a\u5668\u4eba\u624b\u672f\u548c\u8bca\u65ad\u7684\u53d1\u5c55\u3002", "method": "\u57fa\u4e8eMRI\u5f62\u72b6\u5206\u6790\u548cFEM\u5efa\u6a21\uff0c\u8bbe\u8ba1\u591a\u8154\u72ec\u7acb\u63a7\u5236\u7684\u6c14\u52a8\u6a21\u578b\uff0c\u5e76\u901a\u8fc73D\u91cd\u5efa\u9a8c\u8bc1\u3002", "result": "\u5efa\u6a21\u8bef\u5dee\u4f4e\uff08\u6b63\u54113.47%\uff0c\u9006\u54111.41%\uff09\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u6709\u671b\u7528\u4e8e\u673a\u5668\u4eba\u7cfb\u7edf\u9a8c\u8bc1\u548c\u533b\u5b66\u8bad\u7ec3\uff0c\u63a8\u52a8\u52a8\u6001\u6a21\u62df\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.16026", "pdf": "https://arxiv.org/pdf/2508.16026", "abs": "https://arxiv.org/abs/2508.16026", "authors": ["Floris Erich", "Naoya Chiba", "Abdullah Mustafa", "Ryo Hanai", "Noriaki Ando", "Yusuke Yoshiyasu", "Yukiyasu Domae"], "title": "NeuralMeshing: Complete Object Mesh Extraction from Casual Captures", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "How can we extract complete geometric models of objects that we encounter in\nour daily life, without having access to commercial 3D scanners? In this paper\nwe present an automated system for generating geometric models of objects from\ntwo or more videos. Our system requires the specification of one known point in\nat least one frame of each video, which can be automatically determined using a\nfiducial marker such as a checkerboard or Augmented Reality (AR) marker. The\nremaining frames are automatically positioned in world space by using\nStructure-from-Motion techniques. By using multiple videos and merging results,\na complete object mesh can be generated, without having to rely on hole\nfilling. Code for our system is available from\nhttps://github.com/FlorisE/NeuralMeshing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u89c6\u9891\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7Structure-from-Motion\u6280\u672f\u751f\u6210\u5b8c\u6574\u7269\u4f53\u51e0\u4f55\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u5546\u4e1a3D\u626b\u63cf\u4eea\u3002", "motivation": "\u89e3\u51b3\u65e5\u5e38\u4e2d\u65e0\u6cd5\u4f7f\u7528\u5546\u4e1a3D\u626b\u63cf\u4eea\u65f6\uff0c\u5982\u4f55\u83b7\u53d6\u7269\u4f53\u5b8c\u6574\u51e0\u4f55\u6a21\u578b\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u591a\u89c6\u9891\u8f93\u5165\uff0c\u901a\u8fc7\u5df2\u77e5\u70b9\u548cStructure-from-Motion\u6280\u672f\u81ea\u52a8\u5b9a\u4f4d\u5e27\u5e76\u751f\u6210\u5b8c\u6574\u7f51\u683c\u6a21\u578b\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u751f\u6210\u5b8c\u6574\u7269\u4f53\u7f51\u683c\uff0c\u65e0\u9700\u4f9d\u8d56\u5b54\u6d1e\u586b\u5145\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u65e0\u5546\u4e1a3D\u626b\u63cf\u4eea\u65f6\u83b7\u53d6\u51e0\u4f55\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16553", "pdf": "https://arxiv.org/pdf/2508.16553", "abs": "https://arxiv.org/abs/2508.16553", "authors": ["Tim Langer", "Matthias Widra", "Volkhard Beyer"], "title": "TinyML Towards Industry 4.0: Resource-Efficient Process Monitoring of a Milling Machine", "categories": ["cs.LG", "cs.CV", "cs.ET", "cs.SY", "eess.SP", "eess.SY", "I.2.1; I.5.4; C.5.3; C.3"], "comment": "10 pages, 5 figures, 1 table", "summary": "In the context of industry 4.0, long-serving industrial machines can be\nretrofitted with process monitoring capabilities for future use in a smart\nfactory. One possible approach is the deployment of wireless monitoring\nsystems, which can benefit substantially from the TinyML paradigm. This work\npresents a complete TinyML flow from dataset generation, to machine learning\nmodel development, up to implementation and evaluation of a full preprocessing\nand classification pipeline on a microcontroller. After a short review on\nTinyML in industrial process monitoring, the creation of the novel MillingVibes\ndataset is described. The feasibility of a TinyML system for\nstructure-integrated process quality monitoring could be shown by the\ndevelopment of an 8-bit-quantized convolutional neural network (CNN) model with\n12.59kiB parameter storage. A test accuracy of 100.0% could be reached at\n15.4ms inference time and 1.462mJ per quantized CNN inference on an ARM Cortex\nM4F microcontroller, serving as a reference for future TinyML process\nmonitoring solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTinyML\u7684\u65e0\u7ebf\u76d1\u63a7\u7cfb\u7edf\uff0c\u7528\u4e8e\u5de5\u4e1a4.0\u4e2d\u7684\u8001\u65e7\u673a\u5668\u6539\u9020\uff0c\u5b9e\u73b0\u667a\u80fd\u5de5\u5382\u7684\u8fc7\u7a0b\u76d1\u63a7\u3002", "motivation": "\u5de5\u4e1a4.0\u80cc\u666f\u4e0b\uff0c\u8001\u65e7\u673a\u5668\u7f3a\u4e4f\u8fc7\u7a0b\u76d1\u63a7\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u652f\u6301\u667a\u80fd\u5de5\u5382\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528TinyML\u8303\u5f0f\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u96c6\u751f\u6210\u3001\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f00\u53d1\u3001\u4ee5\u53ca\u5728\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u548c\u8bc4\u4f30\u9884\u5904\u7406\u4e0e\u5206\u7c7b\u6d41\u6c34\u7ebf\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a8\u4f4d\u91cf\u5316\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6a21\u578b\uff0c\u53c2\u6570\u5b58\u50a8\u4e3a12.59kiB\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe100%\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a15.4ms\uff0c\u6bcf\u6b21\u63a8\u7406\u80fd\u80171.462mJ\u3002", "conclusion": "\u901a\u8fc7ARM Cortex M4F\u5fae\u63a7\u5236\u5668\u7684\u5b9e\u73b0\uff0c\u9a8c\u8bc1\u4e86TinyML\u5728\u7ed3\u6784\u96c6\u6210\u8fc7\u7a0b\u8d28\u91cf\u76d1\u63a7\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765\u7684\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2508.16104", "pdf": "https://arxiv.org/pdf/2508.16104", "abs": "https://arxiv.org/abs/2508.16104", "authors": ["Arturo Miguel Russell Bernal", "Maureen Petterson", "Pedro Antonio Alarcon Granadeno", "Michael Murphy", "James Mason", "Jane Cleland-Huang"], "title": "Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations", "categories": ["cs.SE", "cs.RO"], "comment": "Submitted to EDTconf 2025", "summary": "With the increasing deployment of small Unmanned Aircraft Systems (sUAS) in\nunfamiliar and complex environments, Environmental Digital Twins (EDT) that\ncomprise weather, airspace, and terrain data are critical for safe flight\nplanning and for maintaining appropriate altitudes during search and\nsurveillance operations. With the expansion of sUAS capabilities through edge\nand cloud computing, accurate EDT are also vital for advanced sUAS\ncapabilities, like geolocation. However, real-world sUAS deployment introduces\nsignificant sources of uncertainty, necessitating a robust validation process\nfor EDT components. This paper focuses on the validation of terrain models, one\nof the key components of an EDT, for real-world sUAS tasks. These models are\nconstructed by fusing U.S. Geological Survey (USGS) datasets and satellite\nimagery, incorporating high-resolution environmental data to support mission\ntasks. Validating both the terrain models and their operational use by sUAS\nunder real-world conditions presents significant challenges, including limited\ndata granularity, terrain discontinuities, GPS and sensor inaccuracies, visual\ndetection uncertainties, as well as onboard resources and timing constraints.\nWe propose a 3-Dimensions validation process grounded in software engineering\nprinciples, following a workflow across granularity of tests, simulation to\nreal world, and the analysis of simple to edge conditions. We demonstrate our\napproach using a multi-sUAS platform equipped with a Terrain-Aware Digital\nShadow.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\u7684\u4e09\u7ef4\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u7528\u4e8e\u9a8c\u8bc1\u73af\u5883\u6570\u5b57\u5b6a\u751f\uff08EDT\uff09\u4e2d\u7684\u5730\u5f62\u6a21\u578b\uff0c\u4ee5\u652f\u6301\u771f\u5b9e\u4e16\u754c\u4e2d\u5c0f\u578b\u65e0\u4eba\u673a\u7cfb\u7edf\uff08sUAS\uff09\u7684\u5b89\u5168\u98de\u884c\u89c4\u5212\u548c\u4efb\u52a1\u6267\u884c\u3002", "motivation": "\u968f\u7740\u5c0f\u578b\u65e0\u4eba\u673a\u7cfb\u7edf\uff08sUAS\uff09\u5728\u590d\u6742\u548c\u964c\u751f\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u7cbe\u786e\u7684\u73af\u5883\u6570\u5b57\u5b6a\u751f\uff08EDT\uff09\u5bf9\u5b89\u5168\u98de\u884c\u548c\u9ad8\u7ea7\u4efb\u52a1\u6267\u884c\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5b9e\u9645\u90e8\u7f72\u4e2d\u5f15\u5165\u7684\u4e0d\u786e\u5b9a\u6027\u9700\u8981\u5f3a\u5927\u7684\u9a8c\u8bc1\u6d41\u7a0b\u6765\u786e\u4fdd\u5730\u5f62\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u7ef4\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e86\u6d4b\u8bd5\u7c92\u5ea6\u3001\u4ece\u4eff\u771f\u5230\u771f\u5b9e\u4e16\u754c\u7684\u8fc7\u6e21\u4ee5\u53ca\u4ece\u7b80\u5355\u5230\u8fb9\u7f18\u6761\u4ef6\u7684\u5206\u6790\u3002\u540c\u65f6\uff0c\u5229\u7528\u878d\u5408USGS\u6570\u636e\u96c6\u548c\u536b\u661f\u5f71\u50cf\u7684\u9ad8\u5206\u8fa8\u7387\u73af\u5883\u6570\u636e\u6784\u5efa\u5730\u5f62\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u914d\u5907\u5730\u5f62\u611f\u77e5\u6570\u5b57\u9634\u5f71\u7684\u591asUAS\u5e73\u53f0\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5e94\u5bf9\u6570\u636e\u7c92\u5ea6\u4e0d\u8db3\u3001GPS\u548c\u4f20\u611f\u5668\u8bef\u5dee\u7b49\u6311\u6218\u3002", "conclusion": "\u8be5\u9a8c\u8bc1\u6d41\u7a0b\u4e3aEDT\u5730\u5f62\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u652f\u6301\uff0c\u63d0\u5347\u4e86sUAS\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6267\u884c\u80fd\u529b\u3002"}}
{"id": "2508.16292", "pdf": "https://arxiv.org/pdf/2508.16292", "abs": "https://arxiv.org/abs/2508.16292", "authors": ["Wen-Han Hsieh", "Elvis Hsieh", "Dantong Niu", "Trevor Darrell", "Roei Herzig", "David M. Chan"], "title": "Do What? Teaching Vision-Language-Action Models to Reject the Impossible", "categories": ["cs.AI", "cs.RO"], "comment": "9 pages, 2 figures, 1 table", "summary": "Recently, Vision-Language-Action (VLA) models have demonstrated strong\nperformance on a range of robotic tasks. These models rely on multimodal\ninputs, with language instructions playing a crucial role -- not only in\npredicting actions, but also in robustly interpreting user intent, even when\nthe requests are impossible to fulfill. In this work, we investigate how VLAs\ncan recognize, interpret, and respond to false-premise instructions: natural\nlanguage commands that reference objects or conditions absent from the\nenvironment. We propose Instruct-Verify-and-Act (IVA), a unified framework that\n(i) detects when an instruction cannot be executed due to a false premise, (ii)\nengages in language-based clarification or correction, and (iii) grounds\nplausible alternatives in perception and action. Towards this end, we construct\na large-scale instruction tuning setup with structured language prompts and\ntrain a VLA model capable of handling both accurate and erroneous requests. Our\napproach leverages a contextually augmented, semi-synthetic dataset containing\npaired positive and false-premise instructions, enabling robust detection and\nnatural language correction. Our experiments show that IVA improves false\npremise detection accuracy by 97.56% over baselines, while increasing\nsuccessful responses in false-premise scenarios by 50.78%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faIVA\u6846\u67b6\uff0c\u89e3\u51b3VLA\u6a21\u578b\u5904\u7406\u865a\u5047\u524d\u63d0\u6307\u4ee4\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u68c0\u6d4b\u3001\u8bed\u8a00\u6f84\u6e05\u548c\u6267\u884c\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u5728\u865a\u5047\u524d\u63d0\u6307\u4ee4\uff08\u5f15\u7528\u4e0d\u5b58\u5728\u7684\u5bf9\u8c61\u6216\u6761\u4ef6\uff09\u4e0b\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u5176\u8bc6\u522b\u4e0e\u54cd\u5e94\u80fd\u529b\u3002", "method": "\u63d0\u51faIVA\u6846\u67b6\uff1a\u68c0\u6d4b\u4e0d\u53ef\u6267\u884c\u6307\u4ee4\u3001\u8bed\u8a00\u4fee\u6b63\u3001\u57fa\u4e8e\u611f\u77e5\u548c\u52a8\u4f5c\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u901a\u8fc7\u534a\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u3002", "result": "IVA\u5c06\u865a\u5047\u524d\u63d0\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u534797.56%\uff0c\u865a\u5047\u524d\u63d0\u573a\u666f\u4e0b\u7684\u6210\u529f\u54cd\u5e94\u7387\u63d0\u9ad850.78%\u3002", "conclusion": "IVA\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86VLA\u6a21\u578b\u5904\u7406\u865a\u5047\u524d\u63d0\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.16410", "pdf": "https://arxiv.org/pdf/2508.16410", "abs": "https://arxiv.org/abs/2508.16410", "authors": ["Alvin Combrink", "Sabino Francesco Roselli", "Martin Fabian"], "title": "Sound and Solution-Complete CCBS", "categories": ["cs.MA", "cs.DM", "cs.RO"], "comment": "15 pages", "summary": "Continuous-time Conflict Based-Search (CCBS) has long been viewed as the\nde-facto optimal solver for multi-agent path finding in continuous time\n(MAPFR). Recent findings, however, show that the original theoretical variant\nof CCBS can suffer from non-termination, while the widely used implementation\ncan return sub-optimal solutions. We introduce an analytical framework that\nyields simple and sufficient conditions under which any CCBS-style algorithm is\nboth sound, i.e., returns only optimal solutions, and solution complete, i.e.,\nterminates on every solvable MAPFR instance. Investigating the publicly\navailable implementation of CCBS reveals that it violates these conditions.\nThough this merely indicates that CCBS might be unsound, this indication is\nsupported by counter-examples.\n  Leveraging the analytical framework, we propose a novel branching rule and\nprove that it satisfies the sufficient conditions, thereby restoring soundness\nand termination guarantees. Consequently, the resulting CCBS variant is both\nsound and solution complete, matching the guarantees of the discrete-time CBS\nfor the first time in the continuous domain. We experimentally apply standard\nCCBS and CCBS under our branching rule to an example problem, with our\nbranching rule returning a solution with lower sum-of-costs than standard CCBS.\nBecause the branching rule largely only affects the branching step, it can be\nadopted as a drop-in replacement in existing code-bases, as we show in our\nprovided implementation. Beyond CCBS, the analytical framework and termination\ncriterion provide a systematic way to evaluate other CCBS-like MAPFR solvers\nand future extensions.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u6790\u6846\u67b6\u63ed\u793a\u4e86CCBS\u7684\u975e\u7ec8\u6b62\u6027\u548c\u6b21\u4f18\u89e3\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u652f\u89c4\u5219\uff0c\u786e\u4fdd\u7b97\u6cd5\u7684\u5065\u5168\u6027\u548c\u7ec8\u6b62\u6027\uff0c\u4f18\u4e8e\u6807\u51c6CCBS\u3002", "motivation": "\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u4e2dCCBS\u7b97\u6cd5\u7684\u975e\u7ec8\u6b62\u6027\u548c\u6b21\u4f18\u89e3\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5206\u6790\u6846\u67b6\uff0c\u63d0\u51fa\u65b0\u5206\u652f\u89c4\u5219\u5e76\u9a8c\u8bc1\u5176\u6ee1\u8db3\u5065\u5168\u548c\u7ec8\u6b62\u6761\u4ef6\u3002", "result": "\u65b0\u5206\u652f\u89c4\u5219\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6CCBS\uff0c\u63d0\u4f9b\u66f4\u4f4e\u7684\u603b\u6210\u672c\u89e3\u3002", "conclusion": "\u65b0\u5206\u652f\u89c4\u5219\u6210\u529f\u4fee\u590dCCBS\u95ee\u9898\uff0c\u5206\u6790\u6846\u67b6\u4e3a\u672a\u6765\u7c7b\u4f3c\u7b97\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u7cfb\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2508.16465", "pdf": "https://arxiv.org/pdf/2508.16465", "abs": "https://arxiv.org/abs/2508.16465", "authors": ["Anilkumar Swamy", "Vincent Leroy", "Philippe Weinzaepfel", "Jean-S\u00e9bastien Franco", "Gr\u00e9gory Rogez"], "title": "HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "cs.RO"], "comment": "12 pages, 8 figures", "summary": "Hand-object 3D reconstruction has become increasingly important for\napplications in human-robot interaction and immersive AR/VR experiences. A\ncommon approach for object-agnostic hand-object reconstruction from RGB\nsequences involves a two-stage pipeline: hand-object 3D tracking followed by\nmulti-view 3D reconstruction. However, existing methods rely on keypoint\ndetection techniques, such as Structure from Motion (SfM) and hand-keypoint\noptimization, which struggle with diverse object geometries, weak textures, and\nmutual hand-object occlusions, limiting scalability and generalization. As a\nkey enabler to generic and seamless, non-intrusive applicability, we propose in\nthis work a robust, keypoint detector-free approach to estimating hand-object\n3D transformations from monocular motion video/images. We further integrate\nthis with a multi-view reconstruction pipeline to accurately recover\nhand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not rely\non pre-scanned object templates or camera intrinsics, and reaches\nstate-of-the-art performance for the tasks of object-agnostic hand-object 3D\ntransformation and shape estimation on the SHOWMe benchmark. We also experiment\non sequences from the HO3D dataset, demonstrating generalization to unseen\nobject categories.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHOSt3R\u7684\u65e0\u5173\u952e\u70b9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u5355\u76ee\u89c6\u9891/\u56fe\u50cf\u4e2d\u4f30\u8ba1\u624b-\u7269\u4f53\u76843D\u53d8\u6362\uff0c\u5e76\u7ed3\u5408\u591a\u89c6\u56fe\u91cd\u5efa\u51c6\u786e\u6062\u590d\u5f62\u72b6\u3002\u8be5\u65b9\u6cd5\u5728SHOWMe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6837\u7269\u4f53\u51e0\u4f55\u3001\u5f31\u7eb9\u7406\u548c\u624b-\u7269\u4f53\u906e\u6321\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u901a\u7528\u4e14\u65e0\u7f1d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u65b9\u6cd5HOSt3R\uff0c\u7ed3\u5408\u591a\u89c6\u56fe\u91cd\u5efa\u6280\u672f\uff0c\u4e0d\u4f9d\u8d56\u9884\u626b\u63cf\u7269\u4f53\u6a21\u677f\u6216\u76f8\u673a\u5185\u53c2\u3002", "result": "\u5728SHOWMe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u5728HO3D\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5bf9\u672a\u89c1\u7269\u4f53\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "HOSt3R\u662f\u4e00\u79cd\u9c81\u68d2\u4e14\u901a\u7528\u7684\u624b-\u7269\u4f533D\u91cd\u5efa\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\u3002"}}
