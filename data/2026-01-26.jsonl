{"id": "2601.16301", "pdf": "https://arxiv.org/pdf/2601.16301", "abs": "https://arxiv.org/abs/2601.16301", "authors": ["Sahar Golipoor", "Richard T. Brophy", "Ying Liu", "Reza Ghazalian", "Stephan Sigg"], "title": "Gesture Recognition from body-Worn RFID under Missing Data", "categories": ["eess.SP"], "comment": null, "summary": "We explore hand-gesture recognition through the use of passive body-worn reflective tags. A data processing pipeline is proposed to address the issue of missing data. Specifically, missing information is recovered through linear and exponential interpolation and extrapolation. Furthermore, imputation and proximity-based inference are employed. We represent tags as nodes in a temporal graph, with edges formed based on correlations between received signal strength (RSS) and phase values across successive timestamps, and we train a graph-based convolutional neural network that exploits graph-based self-attention. The system outperforms state-of-the-art methods with an accuracy of 98.13% for the recognition of 21 gestures. We achieve 89.28% accuracy under leave-one-person-out cross-validation. We further investigate the contribution of various body locations on the recognition accuracy. Removing tags from the arms reduces accuracy by more than 10%, while removing the wrist tag only reduces accuracy by around 2%. Therefore, tag placements on the arms are more expressive for gesture recognition than on the wrist."}
{"id": "2601.16303", "pdf": "https://arxiv.org/pdf/2601.16303", "abs": "https://arxiv.org/abs/2601.16303", "authors": ["Sahar Golipoor", "Reza Ghazalian", "Ines Lobato Mesquita", "Stephan Sigg"], "title": "Angle of Arrival Estimation for Gesture Recognition from reflective body-worn tags", "categories": ["eess.SP"], "comment": null, "summary": "We investigate hand gesture recognition by leveraging passive reflective tags worn on the body. Considering a large set of gestures, distinct patterns are difficult to be captured by learning algorithms using backscattered received signal strength (RSS) and phase signals. This is because these features often exhibit similarities across signals from different gestures. To address this limitation, we explore the estimation of Angle of Arrival (AoA) as a distinguishing feature, since AoA characteristically varies during body motion. To ensure reliable estimation in our system, which employs Smart Antenna Switching (SAS), we first validate AoA estimation using the Multiple SIgnal Classification (MUSIC) algorithm while the tags are fixed at specific angles. Building on this, we propose an AoA tracking method based on Kalman smoothing. Our analysis demonstrates that, while RSS and phase alone are insufficient for distinguishing certain gesture data, AoA tracking can effectively differentiate them. To evaluate the effectiveness of AoA tracking, we implement gesture recognition system benchmarks and show that incorporating AoA features significantly boosts their performance. Improvements of up to 15% confirm the value of AoA-based enhancement."}
{"id": "2601.16421", "pdf": "https://arxiv.org/pdf/2601.16421", "abs": "https://arxiv.org/abs/2601.16421", "authors": ["Gautham Reddy", "Ismail Guvenc", "Mihail L. Sichitiu", "Arupjyoti Bhuyan", "Bryton Petersen", "Jason Abrahamson"], "title": "TransfoREM: Transformer aided 3D Radio Environment Mapping", "categories": ["eess.SP"], "comment": "This paper has been submitted to IEEE ICC 2026", "summary": "Providing reliable cellular connectivity to Unmanned Aerial Vehicles (UAV) is a key challenge, as existing terrestrial networks are deployed mainly for ground-level coverage. The cellular network coverage may be available for a limited range from the antenna side lobes, with poor connectivity further exacerbated by UAV flight dynamics. In this work, we propose TransfoREM, a 3D Radio Environment Map (REM) generation method that combines deterministic channel models and real-world data to map terrestrial network coverage at higher altitudes. At the core of our solution is a transformer model that translates radio propagation mapping into a sequence prediction task to construct REMs. Our results demonstrate that TransfoREM offers improved interpolation capability on real-world data compared against conventional Kriging and other machine learning (ML) techniques. Furthermore, TransfoREM is designed for holistic integration into cellular networks at the base station (BS) level, where it can build REMs, which can then be leveraged for enhanced resource allocation, interference management, and spatial spectrum utilization."}
{"id": "2601.16442", "pdf": "https://arxiv.org/pdf/2601.16442", "abs": "https://arxiv.org/abs/2601.16442", "authors": ["Masahiro Yoshino", "Haruki Yokota", "Junya Hara", "Yuichi Tanaka", "Hiroshi Higashi"], "title": "Auditory Attention Decoding without Spatial Information: A Diotic EEG Study", "categories": ["eess.SP", "cs.HC", "cs.SD", "eess.AS"], "comment": null, "summary": "Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the \"cocktail party\" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method."}
{"id": "2601.16242", "pdf": "https://arxiv.org/pdf/2601.16242", "abs": "https://arxiv.org/abs/2601.16242", "authors": ["S. Yaqubi", "J. Mattila"], "title": "Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established."}
{"id": "2601.16543", "pdf": "https://arxiv.org/pdf/2601.16543", "abs": "https://arxiv.org/abs/2601.16543", "authors": ["Xingxiang Peng", "Qingqing Wu", "Ziyuan Zheng", "Yanze Zhu", "Wen Chen", "Penghui Huang", "Ying Gao", "Honghao Wang"], "title": "Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity", "categories": ["eess.SP"], "comment": "12 pages, 7 figures. Submitted to an IEEE journal for possible publication", "summary": "Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation results demonstrate that the proposed orientation-aware designs achieve a substantially higher worst-user rate than conventional beamforming-only benchmarks. Furthermore, larger antenna directivity enhances fairness with proper orientation but can degrade the worst-user performance otherwise."}
{"id": "2601.16327", "pdf": "https://arxiv.org/pdf/2601.16327", "abs": "https://arxiv.org/abs/2601.16327", "authors": ["Zubair Islam", "Mohamed El-Darieby"], "title": "DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "7 pages, 5 figures, 1 table. Demo videos and source code available", "summary": "This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp"}
{"id": "2601.16550", "pdf": "https://arxiv.org/pdf/2601.16550", "abs": "https://arxiv.org/abs/2601.16550", "authors": ["Eike-Manuel Edelmann"], "title": "Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques", "categories": ["eess.SP"], "comment": "PhD thesis (accepted, Karlsruhe Institute of Technology)", "summary": "Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers."}
{"id": "2601.16336", "pdf": "https://arxiv.org/pdf/2601.16336", "abs": "https://arxiv.org/abs/2601.16336", "authors": ["Zubair Islam", "Mohamed El-Darieby"], "title": "DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "9 pages, 4 figures, 5 tables, Submitted to IEEE IV 2026, Demo videos and source code available", "summary": "Simulating and validating coordination among multiple autonomous vehicles (AVs) is a challenging task as most existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents a Distributed Multi-AV Architecture (DMAVA) that enables synchronized, real-time autonomous driving simulation across multiple physical hosts. Each vehicle runs its own complete AV stack and operates independently from other AVs. The vehicles in the simulation maintain synchronized coordination through a low-latency data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support concurrent execution of multiple Autoware stacks within a shared Unity-based environment. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and fully synchronized closed-loop control. The DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture."}
{"id": "2601.16577", "pdf": "https://arxiv.org/pdf/2601.16577", "abs": "https://arxiv.org/abs/2601.16577", "authors": ["Gaël Pages", "Priot Benoît", "Guillaume Beaugendre"], "title": "Real-Time Evaluation of an Ultra-Tight GNSS/INS Integration Based on Adaptive PLL Bandwidth", "categories": ["eess.SP"], "comment": null, "summary": "In this contribution, we propose a GNSS/INS ultra-tight coupling in which the GNSS receiver architecture is based on a vector tracking loop type architecture. In the proposed approach, the phase lock loop bandwidth is adapted according to the inertial navigation system information. The latter has the advantage to be easily implementable on a System-on-Chip component such as an FPGA (Field-Programmable Gate Arrays), and can be implemented with minor modifications on an existing GNSS receiver platform. Moreover, compared to classical vector-based solutions, the proposed architecture decodes the navigation message in the loop, without the need to run scalar loops in parallel or having to store pre-downloaded ephemeris data. This architecture therefore does not increase the area occupied on the FPGA and does not use additional resources for storage. The proposed GNSS receiver architecture uses GPS L1/C and Galileo E1 signals and is composed of one acquisition module and 16 tracking channels (8 GPS and 8 Galileo) which are implemented within a FPGA (Zynq-Ultrascale)."}
{"id": "2601.16393", "pdf": "https://arxiv.org/pdf/2601.16393", "abs": "https://arxiv.org/abs/2601.16393", "authors": ["Keidai Iiyama", "Grace Gao"], "title": "GNSS-based Lunar Orbit and Clock Estimation With Stochastic Cloning UD Filter", "categories": ["cs.RO"], "comment": "Submitted to the Journal of Guidance, Control, and Dynamics", "summary": "This paper presents a terrestrial GNSS-based orbit and clock estimation framework for lunar navigation satellites. To enable high-precision estimation under the low-observability conditions encountered at lunar distances, we develop a stochastic-cloning UD-factorized filter and delayed-state smoother that provide enhanced numerical stability when processing precise time-differenced carrier phase (TDCP) measurements. A comprehensive dynamics and measurement model is formulated, explicitly accounting for relativistic coupling between orbital and clock states, lunar time-scale transformations, and signal propagation delays including ionospheric, plasmaspheric, and Shapiro effects. The proposed approach is evaluated using high-fidelity Monte-Carlo simulations incorporating realistic multi-constellation GNSS geometry, broadcast ephemeris errors, lunar satellite dynamics, and ionospheric and plasmaspheric delay computed from empirical electron density models. Simulation results demonstrate that combining ionosphere-free pseudorange and TDCP measurements achieves meter-level orbit accuracy and sub-millimeter-per-second velocity accuracy, satisfying the stringent signal-in-space error requirements of future Lunar Augmented Navigation Services (LANS)."}
{"id": "2601.16586", "pdf": "https://arxiv.org/pdf/2601.16586", "abs": "https://arxiv.org/abs/2601.16586", "authors": ["Benedikt Fesl", "Fatih Capar"], "title": "Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection", "categories": ["eess.SP", "cs.IT", "cs.LG"], "comment": null, "summary": "Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers."}
{"id": "2601.16405", "pdf": "https://arxiv.org/pdf/2601.16405", "abs": "https://arxiv.org/abs/2601.16405", "authors": ["Beining Wu", "Zihao Ding", "Leo Ostigaard", "Jun Huang"], "title": "Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted by RACS '25: International Conference on Research in Adaptive and Convergent Systems, November 16-19, 2025, Ho Chi Minh, Vietnam. 10 pages, 5 figures", "summary": "Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics."}
{"id": "2601.16606", "pdf": "https://arxiv.org/pdf/2601.16606", "abs": "https://arxiv.org/abs/2601.16606", "authors": ["Antonio Bracale", "Pasquale De Falco", "Piotr Kuwałek", "Grzegorz Wiczyński"], "title": "Assessment of Errors of Fundamental Frequency Estimation Methods in the Presence of Voltage Fluctuations and Distortions", "categories": ["eess.SP"], "comment": "5 pages, 7 figures, submitted to IEEE conferences", "summary": "The fundamental frequency is one of the parameters that define power quality. Correctly determining this parameter under the conditions that prevail in modern power grids is crucial. Diagnostic purposes often require an efficient estimation of this parameter within short time windows. Therefore, this article presents the results of numerical simulation studies that allow the assessment of errors in various fundamental frequency estimation methods, including the standard IEC 61000-4-30 method, when the analyzed signal has a form similar to that found in modern power grids. For the purposes of this study, a test signal was adopted recreating the states of the power grid, including the simultaneous occurrence of voltage fluctuations and distortions. Conclusions are presented based on conducted research."}
{"id": "2601.16424", "pdf": "https://arxiv.org/pdf/2601.16424", "abs": "https://arxiv.org/abs/2601.16424", "authors": ["Mingi Jeong", "Alberto Quattrini Li"], "title": "RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, 10 figure, 4 tables, AAAI 2026 (main track; oral acceptance)", "summary": "We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation."}
{"id": "2601.16662", "pdf": "https://arxiv.org/pdf/2601.16662", "abs": "https://arxiv.org/abs/2601.16662", "authors": ["Sahar Golipoor", "Lingyun Yao", "Martin Andraud", "Stephan Sigg"], "title": "Low-Power On-Device Gesture Recognition with Einsum Networks", "categories": ["eess.SP"], "comment": null, "summary": "We design a gesture-recognition pipeline for networks of distributed, resource constrained devices utilising Einsum Networks. Einsum Networks are probabilistic circuits that feature a tractable inference, explainability, and energy efficiency. The system is validated in a scenario of low-power, body-worn, passive Radio Frequency Identification-based gesture recognition. Each constrained device includes task-specific processing units responsible for Received Signal Strength (RSS) and phase processing or Angle of Arrival (AoA) estimation, along with feature extraction, as well as dedicated Einsum hardware that processes the extracted features. The output of all constrained devices is then fused in a decision aggregation module to predict gestures. Experimental results demonstrate that the method outperforms the benchmark models."}
{"id": "2601.16578", "pdf": "https://arxiv.org/pdf/2601.16578", "abs": "https://arxiv.org/abs/2601.16578", "authors": ["Julius Beerwerth", "Jianye Xu", "Simon Schäfer", "Fynn Belderink", "Bassam Alrifaee"], "title": "Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions."}
{"id": "2601.16664", "pdf": "https://arxiv.org/pdf/2601.16664", "abs": "https://arxiv.org/abs/2601.16664", "authors": ["Michael Negosanti", "Lorenzo Pucci", "Andrea Giorgetti"], "title": "OFDM-Based ISAC Imaging of Extended Targets via Inverse Virtual Aperture Processing", "categories": ["eess.SP", "eess.IV"], "comment": "6 pages; This paper was presented at the IEEE JC&S Symposium 2026", "summary": "This work investigates the performance of an integrated sensing and communication (ISAC) system exploiting inverse virtual aperture (IVA) for imaging moving extended targets in vehicular scenarios. A base station (BS) operates as a monostatic sensor using MIMO-OFDM waveforms. Echoes reflected by the target are processed through motion-compensation techniques to form an IVA range-Doppler (cross-range) image. A case study considers a 5G NR waveform in the upper mid-band, with the target model defined in 3GPP Release 19, representing a vehicle as a set of spatially distributed scatterers. Performance is evaluated in terms of image contrast (IC) and the root mean squared error (RMSE) of the estimated target-centroid range. Finally, the trade-off between sensing accuracy and communication efficiency is examined by varying the subcarrier allocation for IVA imaging. The results provide insights for designing effective sensing strategies in next-generation radio networks."}
{"id": "2601.16638", "pdf": "https://arxiv.org/pdf/2601.16638", "abs": "https://arxiv.org/abs/2601.16638", "authors": ["Philip Tobuschat", "Simon Duenser", "Markus Bambach", "Ivo Aschwanden"], "title": "A Unified Calibration Framework for High-Accuracy Articulated Robot Kinematics", "categories": ["cs.RO"], "comment": null, "summary": "Researchers have identified various sources of tool positioning errors for articulated industrial robots and have proposed dedicated compensation strategies. However, these typically require individual, specialized experiments with separate models and identification procedures. This article presents a unified approach to the static calibration of industrial robots that identifies a robot model, including geometric and non-geometric effects (compliant bending, thermal deformation, gear transmission errors), using only a single, straightforward experiment for data collection. The model augments the kinematic chain with virtual joints for each modeled effect and realizes the identification using Gauss-Newton optimization with analytic gradients. Fisher information spectra show that the estimation is well-conditioned and the parameterization near-minimal, whereas systematic temporal cross-validation and model ablations demonstrate robustness of the model identification. The resulting model is very accurate and its identification robust, achieving a mean position error of 26.8 $μm$ on a KUKA KR30 industrial robot compared to 102.3 $μm$ for purely geometric calibration."}
{"id": "2601.16727", "pdf": "https://arxiv.org/pdf/2601.16727", "abs": "https://arxiv.org/abs/2601.16727", "authors": ["Julian Block", "Andreas Könsgen", "Jens Dede", "Anna Förster"], "title": "Precise Low-Current Measurement Techniques for IoT Devices: A Case Study on MoleNet", "categories": ["eess.SP"], "comment": null, "summary": "Power consumption is a crucial aspect of IoT devices which often have to run on a battery for an extended period of time. Therefore, supply current measurements are crucial before deploying a device in the field. Multimeters and oscilloscopes are not well suited when it comes to measuring very small currents which occur e.g. when an IoT device is in sleep mode. In this report, we compare dedicated source measurement units (SMUs) which allow to measure very small currents with high precision. As an application example, we demonstrate current measurements on our MoleNet IoT sensor board."}
{"id": "2601.16667", "pdf": "https://arxiv.org/pdf/2601.16667", "abs": "https://arxiv.org/abs/2601.16667", "authors": ["Zhuohao Li", "Yinghao Li", "Jian-Jian Jiang", "Lang Zhou", "Tianyu Zhang", "Wei-Shi Zheng"], "title": "ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations."}
{"id": "2601.16792", "pdf": "https://arxiv.org/pdf/2601.16792", "abs": "https://arxiv.org/abs/2601.16792", "authors": ["Yingtong Zhou", "Yiang Zhou", "Zhengxian Qu", "Kang Liu", "Ting Tan"], "title": "A Dynamic Parametric Simulator for Fetal Heart Sounds", "categories": ["eess.SP"], "comment": null, "summary": "Research on fetal phonocardiogram (fPCG) is challenged by the limited number of abdominal recordings, substantial maternal interference, and marked transmissioninduced signal attenuation that complicate reproducible benchmarking. We present a reproducible dynamic parametric simulator that generates long abdominal fPCG sequences by combining cycle-level fetal S1/S2 event synthesis with a convolutional transmission module and configurable interference and background noise. Model parameters are calibrated cyclewise from real abdominal recordings to capture beat-to-beat variability and to define data-driven admissible ranges for controllable synthesis. The generated signals are validated against real recordings in terms of envelope-based temporal structure and frequency-domain characteristics. The simulator is released as open software to support rapid, reproducible evaluation of fPCG processing methods under controlled acquisition conditions."}
{"id": "2601.16677", "pdf": "https://arxiv.org/pdf/2601.16677", "abs": "https://arxiv.org/abs/2601.16677", "authors": ["Lucía Güitta-López", "Lionel Güitta-López", "Jaime Boal", "Álvaro Jesús López-López"], "title": "Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\\textsuperscript{\\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem."}
{"id": "2601.16847", "pdf": "https://arxiv.org/pdf/2601.16847", "abs": "https://arxiv.org/abs/2601.16847", "authors": ["Pantea Nadimi Goki", "Luca Potì"], "title": "Hierarchical Distribution Matcher Design for Probabilistic Constellation Shaping Based on a Novel Semi-Analytical Optimization Approach", "categories": ["eess.SP"], "comment": "The manuscript has been submitted for publication in the Journal of Lightwave Technologies (JLT)", "summary": "A novel design procedure for practical hierarchical distribution matchers (HiDMs) in probabilistically shaped constellation systems is presented. The proposed approach enables the determination of optimal parameters for any target distribution matcher rate. Specifically, lower bounds on energy loss, rate loss, and memory requirements are analytically estimated for HiDM architectures approximating the Maxwell Boltzmann (MB) distribution. A semi analytical optimization framework is employed to jointly optimize rate and energy loss, allowing the selection of the number of hierarchical layers, memory size, and block length required to optimize channel capacity. The accuracy of the proposed model is validated through probabilistic amplitude shaping of 16QAM (PAS 16QAM), showing good agreement between analytical predictions and simulated results. The proposed analytical tool facilitates the design of HiDM structures that are compatible with practical hardware and implementation constraints, such as those imposed by state-of-the-art application-specific integrated circuits (ASICs) and field-programmable gate arrays (FPGAs). Furthermore, the performance of the optimized HiDM structure, incorporating layer selection based on lower-bound energy loss, is evaluated over the AWGN channel in terms of normalized generalized mutual information (NGMI) as a function of the optical signal-to-noise ratio (OSNR). At a net data rate of 200 Gbps with 25% forward error correction (FEC) overhead, the proposed scheme achieves a shaping gain improvement of 2.8% compared to previously reported solutions."}
{"id": "2601.16686", "pdf": "https://arxiv.org/pdf/2601.16686", "abs": "https://arxiv.org/abs/2601.16686", "authors": ["Ning Liu", "Sen Shen", "Zheng Li", "Matthew D'Souza", "Jen Jen Chung", "Thomas Braunl"], "title": "Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation", "categories": ["cs.RO"], "comment": null, "summary": "This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git."}
{"id": "2601.16915", "pdf": "https://arxiv.org/pdf/2601.16915", "abs": "https://arxiv.org/abs/2601.16915", "authors": ["Aleksey S. Gvozdarev"], "title": "IRS Compensation of Hyper-Rayleigh Fading: How Many Elements Are Needed?", "categories": ["eess.SP"], "comment": null, "summary": "The letter introduces and studies the problem of defining the minimum number of Intelligent Reflecting Surface (IRS) elements needed to compensate for heavy fading conditions in multipath fading channels. The fading severity is quantified in terms of Hyper-Rayleigh Regimes (HRRs) (i.e., full-HRR (worst-case conditions), strong-, weak-, and no-HRR), and the channel model used (Inverse Power Lomax (IPL)) was chosen since it can account for all HRRs. The research presents the derived closed-form channel coefficient envelope statistics for the single IRS-element channel with IPL statistics in both subchannels and total IRS-assisted channel, as well as tight approximations for the channel coefficient and instantaneous signal-to-noise ratio (SNR) statistics for the latter. The derived expressions helped estimate channel parameters corresponding to the specific HRRs of the total channel and demonstrate that while both single links (i.e., ''source-IRS'' and ''IRS-destination'') are in full-HRR, the minimum number of IRS elements needed to bring the total IRS-assisted link (''source-IRS-destination'') out of full-HRR is no less than $6$ (for the whole range on the IPL scale parameter corresponding full-HRR). Furthermore, the minimum number of IRS elements required to bring the total IRS-assisted link into no-HRR is $14$ (under the same conditions)."}
{"id": "2601.16691", "pdf": "https://arxiv.org/pdf/2601.16691", "abs": "https://arxiv.org/abs/2601.16691", "authors": ["Siyuan Sun", "Eugene H. Lin", "Nathan Brown", "Hsin-Yi Hung", "Andrew Gordus", "Jochen Mueller", "Chen Li"], "title": "Creating a biologically more accurate spider robot to study active vibration sensing", "categories": ["cs.RO"], "comment": "8 pages, 12 figures", "summary": "Orb-weaving spiders detect prey on a web using vibration sensors at leg joints. They often dynamically crouch their legs during prey sensing, likely an active sensing strategy. However, how leg crouching enhances sensing is poorly understood, because measuring system vibrations in behaving animals is difficult. We use robophysical modeling to study this problem. Our previous spider robot had only four legs, simplified leg morphology, and a shallow crouching range of motion. Here, we developed a new spider robot, with eight legs, each with four joints that better approximated spider leg morphology. Leg exoskeletons were 3-D printed and joint stiffness was tuned using integrated silicone molding with variable materials and geometry. Tendon-driven actuation allowed a motor in the body to crouch all eight legs deeply as spiders do, while accelerometers at leg joints record leg vibrations. Experiments showed that our new spider robot reproduced key vibration features observed in the previous robot while improving biological accuracy. Our new robot provides a biologically more accurate robophysical model for studying how leg behaviors modulate vibration sensing on a web."}
{"id": "2601.16235", "pdf": "https://arxiv.org/pdf/2601.16235", "abs": "https://arxiv.org/abs/2601.16235", "authors": ["Thomas Serre", "Mathieu Fontaine", "Éric Benhaim", "Slim Essid"], "title": "Contrastive Knowledge Distillation for Embedding Refinement in Personalized Speech Enhancement", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": null, "summary": "Personalized speech enhancement (PSE) has shown convincing results when it comes to extracting a known target voice among interfering ones. The corresponding systems usually incorporate a representation of the target voice within the enhancement system, which is extracted from an enrollment clip of the target voice with upstream models. Those models are generally heavy as the speaker embedding's quality directly affects PSE performances. Yet, embeddings generated beforehand cannot account for the variations of the target voice during inference time. In this paper, we propose to perform on-thefly refinement of the speaker embedding using a tiny speaker encoder. We first introduce a novel contrastive knowledge distillation methodology in order to train a 150k-parameter encoder from complex embeddings. We then use this encoder within the enhancement system during inference and show that the proposed method greatly improves PSE performances while maintaining a low computational load."}
{"id": "2601.16712", "pdf": "https://arxiv.org/pdf/2601.16712", "abs": "https://arxiv.org/abs/2601.16712", "authors": ["Kartik Chari", "Raid Dokhan", "Anas Homsi", "Niklas Kueper", "Elsa Andrea Kirchner"], "title": "A Feature Extraction Pipeline for Enhancing Lightweight Neural Networks in sEMG-based Joint Torque Estimation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care."}
{"id": "2601.16323", "pdf": "https://arxiv.org/pdf/2601.16323", "abs": "https://arxiv.org/abs/2601.16323", "authors": ["Belal Korany", "Peerapol Tinnakornsrisuphap", "Saadallah Kassir", "Prashanth Hande", "Hyun Yong Lee", "Thomas Stockhammer", "Hemanth Sampath"], "title": "Multi-User Content Diversity in Wireless Networks", "categories": ["cs.NI", "eess.SP", "eess.SY"], "comment": "arXiv admin note: text overlap with arXiv:2505.04114", "summary": "Immersive applications such as eXtended Reality (XR), cloud gaming, and real-time video streaming are central to the vision of 6G networks. These applications require not only low latency and high data rates, but also consistent and high-quality User Experience (UX). Traditional rate allocation and congestion control mechanisms in wireless networks treat users uniformly based on channel conditions, rely only on network-centric Key Performance Indicators (KPIs), and ignore the content diversity, which can lead to inefficient resource utilization and degraded UX. In this paper, we introduce the concept of Multi-User Content Diversity, which recognizes that different users concurrently consume media with varying complexity, and therefore have different bitrate requirements to achieve satisfactory UX. We propose multiple different frameworks that exploit multi-user content diversity and lead to overall network-wide gains in terms of UX. For each framework, we demonstrate the required information exchange between Application Servers (ASs), Application Clients (ACs), and the network, and the algorithms that run in each of these components to optimize a network-wide UXbased objective. Simulation results demonstrate that exploiting multi-user content diversity leads to significant gains in UX capacity, UX fairness, and network utilization, when compared to conventional rate control methods. These findings highlight the potential of content-aware networking as a key enabler for emerging wireless systems."}
{"id": "2601.16866", "pdf": "https://arxiv.org/pdf/2601.16866", "abs": "https://arxiv.org/abs/2601.16866", "authors": ["Lucía Güitta-López", "Vincenzo Suriani", "Jaime Boal", "Álvaro J. López-López", "Daniele Nardi"], "title": "Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications."}
{"id": "2601.16332", "pdf": "https://arxiv.org/pdf/2601.16332", "abs": "https://arxiv.org/abs/2601.16332", "authors": ["Felipe Tobar", "Elsa Cazelles"], "title": "Efficient Gaussian process learning via subspace projections", "categories": ["cs.LG", "eess.SP"], "comment": "Accepted at IEEE ICASSP 2026", "summary": "We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \\emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes."}
{"id": "2601.16870", "pdf": "https://arxiv.org/pdf/2601.16870", "abs": "https://arxiv.org/abs/2601.16870", "authors": ["Guangping Liu", "Nicholas Hawkins", "Billy Madden", "Tipu Sultan", "Flavio Esposito", "Madi Babaiasl"], "title": "A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study", "categories": ["cs.RO"], "comment": null, "summary": "Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control."}
{"id": "2601.16472", "pdf": "https://arxiv.org/pdf/2601.16472", "abs": "https://arxiv.org/abs/2601.16472", "authors": ["Rui Meng", "Song Gao", "Bingxuan Xu", "Xiaodong Xu", "Jianqiao Chen", "Nan Ma", "Pei Xiao", "Ping Zhang", "Rahim Tafazolli"], "title": "Secure Intellicise Wireless Network: Agentic AI for Coverless Semantic Steganography Communication", "categories": ["cs.CR", "eess.SP"], "comment": "13 pages, 11 figures", "summary": "Semantic Communication (SemCom), leveraging its significant advantages in transmission efficiency and reliability, has emerged as a core technology for constructing future intellicise (intelligent and concise) wireless networks. However, intelligent attacks represented by semantic eavesdropping pose severe challenges to the security of SemCom. To address this challenge, Semantic Steganographic Communication (SemSteCom) achieves ``invisible'' encryption by implicitly embedding private semantic information into cover modality carriers. The state-of-the-art study has further introduced generative diffusion models to directly generate stega images without relying on original cover images, effectively enhancing steganographic capacity. Nevertheless, the recovery process of private images is highly dependent on the guidance of private semantic keys, which may be inferred by intelligent eavesdroppers, thereby introducing new security threats. To address this issue, we propose an Agentic AI-driven SemSteCom (AgentSemSteCom) scheme, which includes semantic extraction, digital token controlled reference image generation, coverless steganography, semantic codec, and optional task-oriented enhancement modules. The proposed AgentSemSteCom scheme obviates the need for both cover images and private semantic keys, thereby boosting steganographic capacity while reinforcing transmission security. The simulation results on open-source datasets verify that, AgentSemSteCom achieves better transmission quality and higher security levels than the baseline scheme."}
{"id": "2601.16806", "pdf": "https://arxiv.org/pdf/2601.16806", "abs": "https://arxiv.org/abs/2601.16806", "authors": ["Lu Yihe", "Barbara Webb"], "title": "An Efficient Insect-inspired Approach for Visual Point-goal Navigation", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations."}
{"id": "2601.16495", "pdf": "https://arxiv.org/pdf/2601.16495", "abs": "https://arxiv.org/abs/2601.16495", "authors": ["Shivani Singh", "Amudheesan Nakkeeran", "Prem Singh", "Ekant Sharma", "Jyotsna Bapat"], "title": "Load Balanced ISAC Systems for URLLC Users", "categories": ["cs.IT", "eess.SP"], "comment": null, "summary": "This paper presents an energy-efficient downlink cell-free massive multiple-input multiple-output (CF-mMIMO) integrated sensing and communication (ISAC) network that serves ultra-reliable low-latency communication (URLLC) users while simultaneously detecting a target. We propose a load-balancing algorithm that minimizes the total network power consumption; including transmit power, fixed static power, and traffic-dependent fronthaul power at the access points (APs) without degrading system performance. To this end, we formulate a mixed-integer non-convex optimization problem and introduce an iterative joint power allocation and AP load balancing (JPALB) algorithm. The algorithm aims to reduce total power usage while meeting both the communication quality-of-service (QoS) requirements of URLLC users and the sensing QoS needed for target detection. Proposed JPALB algorithm for ISAC systems was simulated with maximum-ratio transmission (MRT) and regularized zero-forcing (RZF) precoders. Simulation results show approximately 33% reduction in power consumption, using JPALB algorithm compared to a baseline with no load balancing, without compromising communication and sensing QoS requirements."}
{"id": "2601.16885", "pdf": "https://arxiv.org/pdf/2601.16885", "abs": "https://arxiv.org/abs/2601.16885", "authors": ["Yangfan Xu", "Lilian Zhang", "Xiaofeng He", "Pengdong Wu", "Wenqi Wu", "Jun Mao"], "title": "GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT."}
{"id": "2601.16602", "pdf": "https://arxiv.org/pdf/2601.16602", "abs": "https://arxiv.org/abs/2601.16602", "authors": ["Xinxin Xu", "Yann Gousseau", "Christophe Kervazo", "Saïd Ladjal"], "title": "Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images Using Fully Synthetic Training", "categories": ["eess.IV", "cs.GR", "eess.SP"], "comment": null, "summary": "Considerable work has been dedicated to hyperspectral single image super-resolution to improve the spatial resolution of hyperspectral images and fully exploit their potential. However, most of these methods are supervised and require some data with ground truth for training, which is often non-available. To overcome this problem, we propose a new unsupervised training strategy for the super-resolution of hyperspectral remote sensing images, based on the use of synthetic abundance data. Its first step decomposes the hyperspectral image into abundances and endmembers by unmixing. Then, an abundance super-resolution neural network is trained using synthetic abundances, which are generated using the dead leaves model in such a way as to faithfully mimic real abundance statistics. Next, the spatial resolution of the considered hyperspectral image abundances is increased using this trained network, and the high resolution hyperspectral image is finally obtained by recombination with the endmembers. Experimental results show the training potential of the synthetic images, and demonstrate the method effectiveness."}
{"id": "2601.16982", "pdf": "https://arxiv.org/pdf/2601.16982", "abs": "https://arxiv.org/abs/2601.16982", "authors": ["Basile Van Hoorick", "Dian Chen", "Shun Iwase", "Pavel Tokmakov", "Muhammad Zubair Irshad", "Igor Vasiljevic", "Swati Gupta", "Fangzhou Cheng", "Sergey Zakharov", "Vitor Campagnolo Guizilini"], "title": "AnyView: Synthesizing Any Novel View in Dynamic Scenes", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Project webpage: https://tri-ml.github.io/AnyView/", "summary": "Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \\textbf{AnyView}, a diffusion-based video generation framework for \\emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \\textbf{AnyViewBench}, a challenging new benchmark tailored towards \\emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \\emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/"}
{"id": "2601.16631", "pdf": "https://arxiv.org/pdf/2601.16631", "abs": "https://arxiv.org/abs/2601.16631", "authors": ["Ming Kang", "Fung Fung Ting", "Raphaël C. -W. Phan", "Zongyuan Ge", "Chee-Ming Ting"], "title": "PanopMamba: Vision State Space Modeling for Nuclei Panoptic Segmentation", "categories": ["eess.IV", "cs.CV", "eess.SP", "stat.AP"], "comment": "10 pages, 3 figures", "summary": "Nuclei panoptic segmentation supports cancer diagnostics by integrating both semantic and instance segmentation of different cell types to analyze overall tissue structure and individual nuclei in histopathology images. Major challenges include detecting small objects, handling ambiguous boundaries, and addressing class imbalance. To address these issues, we propose PanopMamba, a novel hybrid encoder-decoder architecture that integrates Mamba and Transformer with additional feature-enhanced fusion via state space modeling. We design a multiscale Mamba backbone and a State Space Model (SSM)-based fusion network to enable efficient long-range perception in pyramid features, thereby extending the pure encoder-decoder framework while facilitating information sharing across multiscale features of nuclei. The proposed SSM-based feature-enhanced fusion integrates pyramid feature networks and dynamic feature enhancement across different spatial scales, enhancing the feature representation of densely overlapping nuclei in both semantic and spatial dimensions. To the best of our knowledge, this is the first Mamba-based approach for panoptic segmentation. Additionally, we introduce alternative evaluation metrics, including image-level Panoptic Quality ($i$PQ), boundary-weighted PQ ($w$PQ), and frequency-weighted PQ ($fw$PQ), which are specifically designed to address the unique challenges of nuclei segmentation and thereby mitigate the potential bias inherent in vanilla PQ. Experimental evaluations on two multiclass nuclei segmentation benchmark datasets, MoNuSAC2020 and NuInsSeg, demonstrate the superiority of PanopMamba for nuclei panoptic segmentation over state-of-the-art methods. Consequently, the robustness of PanopMamba is validated across various metrics, while the distinctiveness of PQ variants is also demonstrated. Code is available at https://github.com/mkang315/PanopMamba."}
{"id": "2601.16689", "pdf": "https://arxiv.org/pdf/2601.16689", "abs": "https://arxiv.org/abs/2601.16689", "authors": ["Laura Ferrante", "Anna Boesendorfer", "Benedikt Baumgartner", "Manuel Catalano", "Antonio Bicchi", "Oskar Aszmann", "Dario Farina"], "title": "Neural Agonist-Antagonist Coupling in the Absence of Mechanical Coupling after Targeted Muscle Reinnervation", "categories": ["q-bio.NC", "eess.SP"], "comment": "arXiv admin note: substantial text overlap with arXiv:2410.10694", "summary": "Following limb amputation and targeted muscle reinnervation (TMR), nerves supplying agonist and antagonist muscles are rerouted into separate targeted muscles, disrupting natural neuromechanical coupling between muscle groups. Using high-density intramuscular microelectrode arrays in reinnervated muscles, we show that neural signals for agonist and antagonist tasks remain functionally coupled: motor units active during agonist tasks were also recruited during corresponding antagonist tasks, despite no visual feedback on coactivation being provided."}
{"id": "2601.16733", "pdf": "https://arxiv.org/pdf/2601.16733", "abs": "https://arxiv.org/abs/2601.16733", "authors": ["Yann Le Gall", "Nicolas Burlet", "Mathieu Simon", "Fabien Novella", "Samantha Dugelay", "Jean-Philippe Malkasse"], "title": "Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "Circular Synthetic Aperture Sonar (CSAS) provides a 360° azimuth view of the seabed, surpassing the limited aperture and mono-view image of conventional side-scan SAS. This makes CSAS a valuable tool for target recognition in mine warfare where the diversity of point of view is essential for reducing false alarms. CSAS processing typically produces a very high-resolution two-dimensional image. However, the parallax introduced by the circular displacement of the illuminator fill-in the shadow regions, and the shadow cast by an object on the seafloor is lost in favor of azimuth coverage and resolution. Yet the shadows provide complementary information on target shape useful for target recognition. In this paper, we explore a way to retrieve shadow information from CSAS data to improve target analysis and carry 3D reconstruction. Sub-aperture filtering is used to get a collection of images at various points of view along the circular trajectory and fixed focus shadow enhancement (FFSE) is applied to obtain sharp shadows. An interactive interface is also proposed to allow human operators to visualize these shadows along the circular trajectory. A space-carving reconstruction method is applied to infer the 3D shape of the object from the segmented shadows. The results demonstrate the potential of shadows in circular SAS for improving target analysis and 3D reconstruction."}
