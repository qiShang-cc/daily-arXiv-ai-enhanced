{"id": "2511.21864", "pdf": "https://arxiv.org/pdf/2511.21864", "abs": "https://arxiv.org/abs/2511.21864", "authors": ["Nicholas Vaiopoulos", "Alexander Vavoulas", "Harilaos G. Sandalidis", "Konstantinos K. Delibasis", "Dimitris Varoutas"], "title": "Internodal Distance Distributions for Static and Mobile Nodes in 2D/3D Wireless Networks", "categories": ["eess.SP"], "comment": "5 pages 2 figures, 9 tables", "summary": "This letter presents a unified analytical framework for internodal distance distributions in 2D and 3D wireless networks, with nodes confined to concentric circular or spherical regions. Four deployment scenarios are considered, covering all combinations of static (uniform) and mobile (random waypoint-based) nodes. For each scenario, closed-form expressions for the internodal distance probability density functions are derived, incorporating both geometric constraints and spatial effects introduced by mobility. Equal-radius cases are also addressed. Beta-distribution approximations and Monte Carlo simulations demonstrate the accuracy and validity of the analytical results."}
{"id": "2511.21997", "pdf": "https://arxiv.org/pdf/2511.21997", "abs": "https://arxiv.org/abs/2511.21997", "authors": ["Ranjeet K. Tiwari", "Daniel Sgarioto", "Peter Graham", "Alexei Skvortsov", "Sanjeev Arulampalam", "Damith C. Ranasinghe"], "title": "Joint Estimation of Sea State and Vessel Parameters Using a Mass-Spring-Damper Equivalence Model", "categories": ["eess.SP", "cs.AI", "eess.SY"], "comment": null, "summary": "Real-time sea state estimation is vital for applications like shipbuilding and maritime safety. Traditional methods rely on accurate wave-vessel transfer functions to estimate wave spectra from onboard sensors. In contrast, our approach jointly estimates sea state and vessel parameters without needing prior transfer function knowledge, which may be unavailable or variable. We model the wave-vessel system using pseudo mass-spring-dampers and develop a dynamic model for the system. This method allows for recursive modeling of wave excitation as a time-varying input, relaxing prior works' assumption of a constant input. We derive statistically consistent process noise covariance and implement a square root cubature Kalman filter for sensor data fusion. Further, we derive the Posterior Cramer-Rao lower bound to evaluate estimator performance. Extensive Monte Carlo simulations and data from a high-fidelity validated simulator confirm that the estimated wave spectrum matches methods assuming complete transfer function knowledge."}
{"id": "2511.22041", "pdf": "https://arxiv.org/pdf/2511.22041", "abs": "https://arxiv.org/abs/2511.22041", "authors": ["Thomas Choi", "Yuning Zhang", "Issei Kanno", "Masaaki Ito", "Andreas F. Molisch"], "title": "CUNEC: A Path Loss Model for Urban Cell-Free Massive MIMO Networks", "categories": ["eess.SP"], "comment": "Accepted to IEEE Transactions on Wireless Communications. Final version is 15 pages and includes 7 figures and 5 tables", "summary": "Accurate path loss (PL) modeling is essential for evaluating and optimizing cell-free massive MIMO systems, especially in dense urban environments where traditional models fail to capture the complexity of real-world propagation. This paper introduces CUNEC (Cell-free massive MIMO for Urban Non-stationary Environments with Correlations, a novel PL model that accounts for spatial non-stationarity, inter-access point (AP)/user equipment (UE) correlations, and urban-specific propagation phenomena such as corner diffraction and street canyon waveguiding.bCUNEC segments AP-UE paths by street order, models PL as a stochastic function of urban geometry, and integrates spatially correlated shadowing. The parameters are derived from large-scale ray tracing and validated against both additional ray tracing in New York, NY and real-world channel measurements in Los Angeles, CA. Compared to the conventional alpha-beta model, CUNEC significantly improves accuracy in the considered urban propagation scenarios. An open-source dataset comprising over 30,000 AP locations and 128 UE positions is also released to support reproducible research and future system development."}
{"id": "2511.22144", "pdf": "https://arxiv.org/pdf/2511.22144", "abs": "https://arxiv.org/abs/2511.22144", "authors": ["Zhongqin Wang", "J. Andrew Zhang", "Kai Wu", "Kuangda Chen", "Min Xu", "Y. Jay Guo"], "title": "Bistatic Passive Tracking via CSI Power", "categories": ["eess.SP"], "comment": null, "summary": "Accurate object tracking in Integrated Sensing and Communication (ISAC) applications remains challenging due to limited signal bandwidth, sparse antenna arrays, and clock asynchronism inherent in bistatic transceiver deployments. This paper proposes PowerSense, a real-time passive tracking framework that operates directly on the power of Channel State Information (CSI). Although CSI phase carries fine-grained information, its time-varying distortions require complex processing, which introduces additional interference during tracking. Instead, this work solely relies on CSI power for accurate sensing. We first remove all CSI phase offsets through a self-conjugate operation, yielding phase-independent CSI power. A cascaded Fast Fourier Transform (FFT) is then applied to extract delay, angle-of-arrival (AoA), and Doppler features, followed by object detection, outlier removal, and continuous trajectory estimation via an Extended Kalman Filter (EKF). To enable fine-grained motion sensing, the estimated target positions are further used to extract refined micro-Doppler signatures. Using 3.1 GHz LTE and 5 GHz WiFi bistatic signals with a 20 MHz bandwidth, our indoor experiments achieve a median tracking error of 0.4 m, without performing any pre-deployment system calibration, while simultaneously extracting clear and unambiguous micro-Doppler signatures of the tracked target."}
{"id": "2511.21886", "pdf": "https://arxiv.org/pdf/2511.21886", "abs": "https://arxiv.org/abs/2511.21886", "authors": ["Jingtian Yan", "Shuai Zhou", "Stephen F. Smith", "Jiaoyang Li"], "title": "Bridging Planning and Execution: Multi-Agent Path Finding Under Real-World Deadlines", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The Multi-Agent Path Finding (MAPF) problem aims to find collision-free paths for multiple agents while optimizing objectives such as the sum of costs or makespan. MAPF has wide applications in domains like automated warehouses, manufacturing systems, and airport logistics. However, most MAPF formulations assume a simplified robot model for planning, which overlooks execution-time factors such as kinodynamic constraints, communication latency, and controller variability. This gap between planning and execution is problematic for time-sensitive applications. To bridge this gap, we propose REMAP, an execution-informed MAPF planning framework that can be combined with leading search-based MAPF planners with minor changes. Our framework integrates the proposed ExecTimeNet to accurately estimate execution time based on planned paths. We demonstrate our method for solving MAPF with Real-world Deadlines (MAPF-RD) problem, where agents must reach their goals before a predefined wall-clock time. We integrate our framework with two popular MAPF methods, MAPF-LNS and CBS. Experiments show that REMAP achieves up to 20% improvement in solution quality over baseline methods (e.g., constant execution speed estimators) on benchmark maps with up to 300 agents."}
{"id": "2511.22201", "pdf": "https://arxiv.org/pdf/2511.22201", "abs": "https://arxiv.org/abs/2511.22201", "authors": ["Ruohai Guo", "Jiang Zhu", "Chengjie Yu", "Zhigang Wang", "Ning Zhang", "Fengzhong Qu", "Min Gong"], "title": "A Model and Data Dual-driven Approach for Multitargets Detection under Mainlobe Jamming", "categories": ["eess.SP"], "comment": null, "summary": "In modern radar systems, target detection and parameter estimation face significant challenges when confronted with mainlobe jamming. This paper presents a Diffusion-based Model and Data Dual-driven (DMDD) approach to estimate and detect multitargets and suppress structured jamming. In DMDD, the jamming prior is modeled through a score-based diffusion process with its score learned from the pure jamming data, enabling posterior sampling without requiring detailed knowledge of jamming. Meanwhile, the target signal is usually sparse in the range space, which can be modeled via a sparse Bayesian learning (SBL) framework, and hyperparameter is updated through the expectation-maximization (EM) algorithm. A single diffusion process is constructed for the jamming, while the state of targets are estimated through direct posterior inference, enhancing computational efficiency. The noise variance is also estimated through EM algorithm. Numerical experiments demonstrate the effectiveness of the proposed method in structured jamming scenarios. The proposed DMDD algorithm achieves superior target detection performance, compared with existing methods."}
{"id": "2511.21925", "pdf": "https://arxiv.org/pdf/2511.21925", "abs": "https://arxiv.org/abs/2511.21925", "authors": ["Alex Richardson", "Jonathan Sprinkle"], "title": "OpenTwinMap: An Open-Source Digital Twin Generator for Urban Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Digital twins of urban environments play a critical role in advancing autonomous vehicle (AV) research by enabling simulation, validation, and integration with emerging generative world models. While existing tools have demonstrated value, many publicly available solutions are tightly coupled to specific simulators, difficult to extend, or introduce significant technical overhead. For example, CARLA-the most widely used open-source AV simulator-provides a digital twin framework implemented entirely as an Unreal Engine C++ plugin, limiting flexibility and rapid prototyping. In this work, we propose OpenTwinMap, an open-source, Python-based framework for generating high-fidelity 3D urban digital twins. The completed framework will ingest LiDAR scans and OpenStreetMap (OSM) data to produce semantically segmented static environment assets, including road networks, terrain, and urban structures, which can be exported into Unreal Engine for AV simulation. OpenTwinMap emphasizes extensibility and parallelization, lowering the barrier for researchers to adapt and scale the pipeline to diverse urban contexts. We describe the current capabilities of the OpenTwinMap, which includes preprocessing of OSM and LiDAR data, basic road mesh and terrain generation, and preliminary support for CARLA integration."}
{"id": "2511.22222", "pdf": "https://arxiv.org/pdf/2511.22222", "abs": "https://arxiv.org/abs/2511.22222", "authors": ["Boxun Liu", "Xuanyu Liu", "Shijian Gao", "Xiang Cheng", "Liuqing Yang"], "title": "Foundation Model for Intelligent Wireless Communications", "categories": ["eess.SP"], "comment": null, "summary": "The evolution toward intelligent next-generation wireless systems promises unprecedented spectral efficiency and reliability but is hindered by a paradigm of narrow and data-hungry AI models. Breaking from this constraint, this work introduces WiFo-2, a revolutionary wireless foundation model that establishes a new state of the art for extensive channel state information (CSI)-based tasks. Uniquely architected as a sparse mixture of experts, WiFo-2 effectively manages heterogeneous data and tasks while enabling highly efficient inference. It is pretrained on a massive and diverse dataset of 11.6 billion CSI points, which enables the acquisition of profound and generalizable channel knowledge. WiFo-2 demonstrates remarkable zero-shot capabilities, not only matching but surpassing the full-shot performance of task-specific baselines on unseen configurations, all while providing reliable confidence estimates. Furthermore, the model achieves exceptional performance on eight key downstream tasks with minimal fine-tuning. A functional hardware prototype demonstrates its real-world deployment feasibility and significant system gains, highlighting WiFo-2's superiority and paving the way for a paradigm shift in AI-based wireless systems."}
{"id": "2511.21957", "pdf": "https://arxiv.org/pdf/2511.21957", "abs": "https://arxiv.org/abs/2511.21957", "authors": ["Cahit Ikbal Er", "Amin Kashiri", "Yasin Yazicioglu"], "title": "RSPECT: Robust and Scalable Planner for Energy-Aware Coordination of UAV-UGV Teams in Aerial Monitoring", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "We consider the robust planning of energy-constrained unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs), which act as mobile charging stations, to perform long-horizon aerial monitoring missions. More specifically, given a set of points to be visited by the UAVs and desired final positions of the UAV-UGV teams, the objective is to find a robust plan (the vehicle trajectories) that can be realized without a major revision in the face of uncertainty (e.g., unknown obstacles/terrain, wind) to complete this mission in minimum time. We provide a formal description of this problem as a mixed-integer program (MIP), which is NP-hard. Since exact solution methods are computationally intractable for such problems, we propose RSPECT, a scalable and efficient heuristic. We provide theoretical results on the complexity of our algorithm and the feasibility and robustness of resulting plans. We also demonstrate the performance of our method via simulations and experiments."}
{"id": "2511.22224", "pdf": "https://arxiv.org/pdf/2511.22224", "abs": "https://arxiv.org/abs/2511.22224", "authors": ["Qi Yang", "Kai Liu", "Jingjing Zhao", "Kaiquan Cai", "Xidong Mu", "Yuanwei Liu"], "title": "Pinching-Antenna Systems-Assisted SWIPT: A Rate-Energy Trade-off Perspective", "categories": ["eess.SP"], "comment": null, "summary": "This paper investigates the rate-energy trade-off for pinching-antenna systems (PASS)-assisted simultaneous wireless information and power transfer (SWIPT) systems. Both the single information user (IU)/energy user (EU) and multiple IUs/EUs scenarios are considered.1) For the single IU/EU scenario, a pinching beamforming optimization problem is formulated for simultaneously maximizing data rate and harvested energy. To tackle this problem, a two-stage algorithm is proposed. Specifically, the successive convex approximation (SCA) method is first invoked for minimizing the large-scale path loss, which is followed by the fine-tuning method for the phase alignment. 2) For the multiple IUs/EUs scenario, three multiple access schemes are considered, i.e., frequency division multiple access (FDMA), time division multiple access (TDMA), and non-orthogonal multiple access (NOMA). The corresponding multi-objective optimization problem (MOOP) that simultaneously maximizes the minimum data rate and minimum harvested energy is formulated for ensuring users' fairness. To address this problem, we adopt the $ε$-constraint method to first convert the intractable MOOPs to single-objective optimization problems (SOOPs). Then, for the SOOP under each multiple access protocol, the particle swarm optimization (PSO) and convex optimization methods are adopted for solving the pinching beamforming and resource allocation problems, respectively. Simulation results unveil that: i) PASS can achieve a significantly superior rate-energy region compared to conventional fixed-position antenna systems for pinching beamforming; and ii) by exploiting the time-switching feature, TDMA can outperform both NOMA and FDMA for the multiple IUs/EUs scenario."}
{"id": "2511.22042", "pdf": "https://arxiv.org/pdf/2511.22042", "abs": "https://arxiv.org/abs/2511.22042", "authors": ["Lei Li", "Jiale Gong", "Ziyang Li", "Hong Wang"], "title": "Constant-Volume Deformation Manufacturing for Material-Efficient Shaping", "categories": ["cs.RO"], "comment": "46 pages, 27 figures", "summary": "Additive and subtractive manufacturing enable complex geometries but rely on discrete stacking or local removal, limiting continuous and controllable deformation and causing volume loss and shape deviations. We present a volumepreserving digital-mold paradigm that integrates real-time volume-consistency modeling with geometry-informed deformation prediction and an error-compensation strategy to achieve highly predictable shaping of plastic materials. By analyzing deformation patterns and error trends from post-formed point clouds, our method corrects elastic rebound and accumulation errors, maintaining volume consistency and surface continuity. Experiments on five representative geometries demonstrate that the system reproduces target shapes with high fidelity while achieving over 98% material utilization. This approach establishes a digitally driven, reproducible pathway for sustainable, zero-waste shaping of user-defined designs, bridging digital modeling, real-time sensing, and adaptive forming, and advancing next-generation sustainable and customizable manufacturing."}
{"id": "2511.22328", "pdf": "https://arxiv.org/pdf/2511.22328", "abs": "https://arxiv.org/abs/2511.22328", "authors": ["Saeed Mohammadzadeh", "Kanapathippillai Cumanan", "Zhiguo Ding"], "title": "NOMA Assisted Downlink Power Allocation in Pinching Antenna Systems Using Convolutional Neural Network", "categories": ["eess.SP"], "comment": null, "summary": "In this paper, we consider a flexible-antenna architecture, referred to as a pinching-antenna (PA) system, in which multiple PAs realized by activating small dielectric particles along a dielectric waveguide are jointly employed to serve a single-antenna user. We investigate antenna placement and power allocation optimization in PA-assisted non-orthogonal multiple access (NOMA) systems using a convolutional neural network (CNN). An optimization strategy is developed to determine the PA locations that maximize achievable NOMA performance while satisfying physical and spatial constraints. The proposed method adopts a two-stage structure, combining a user-aware initialization with a gradient-based refinement, enabling near-optimal performance with significantly lower computational cost. A max-min fairness formulation is introduced for power allocation to balance the power budget among users with varying channel strengths, solved efficiently via quasi-linear programming and bisection search. Finally, a CNN-based learning framework is employed to capture the nonlinear mapping between channel conditions and the corresponding optimal power coefficients. This framework can infer near-optimal power allocations for unseen network configurations without retraining, offering scalability and adaptability. Simulation results show that the proposed CNN-based NOMA approach for PA systems improves sum rate and user fairness while reducing computational complexity."}
{"id": "2511.22043", "pdf": "https://arxiv.org/pdf/2511.22043", "abs": "https://arxiv.org/abs/2511.22043", "authors": ["Xuchen Liu", "Ruocheng Li", "Bin Xin", "Weijia Yao", "Qigeng Duan", "Jinqiang Cui", "Ben M. Chen", "Jie Chen"], "title": "SwordRiding: A Unified Navigation Framework for Quadrotors in Unknown Complex Environments via Online Guiding Vector Fields", "categories": ["cs.RO", "eess.SY"], "comment": "For an experimental demo, see https://www.youtube.com/watch?v=tKYCg266c4o. For the lemma proof, see https://github.com/SmartGroupSystems/GVF_close_loop_planning/blob/main/proofs.md", "summary": "Although quadrotor navigation has achieved high performance in trajectory planning and control, real-time adaptability in unknown complex environments remains a core challenge. This difficulty mainly arises because most existing planning frameworks operate in an open-loop manner, making it hard to cope with environmental uncertainties such as wind disturbances or external perturbations. This paper presents a unified real-time navigation framework for quadrotors in unknown complex environments, based on the online construction of guiding vector fields (GVFs) from discrete reference path points. In the framework, onboard perception modules build a Euclidean Signed Distance Field (ESDF) representation of the environment, which enables obstacle awareness and path distance evaluation. The system first generates discrete, collision-free path points using a global planner, and then parameterizes them via uniform B-splines to produce a smooth and physically feasible reference trajectory. An adaptive GVF is then synthesized from the ESDF and the optimized B-spline trajectory. Unlike conventional approaches, the method adopts a closed-loop navigation paradigm, which significantly enhances robustness under external disturbances. Compared with conventional GVF methods, the proposed approach directly accommodates discretized paths and maintains compatibility with standard planning algorithms. Extensive simulations and real-world experiments demonstrate improved robustness against external disturbances and superior real-time performance."}
{"id": "2511.22353", "pdf": "https://arxiv.org/pdf/2511.22353", "abs": "https://arxiv.org/abs/2511.22353", "authors": ["Zheyi Hang", "Denghan Xiong", "Pengo Xie", "Huan Hu"], "title": "A Bio-Inspired Whisker Sensor toward Underwater Flow Sensing in Darkness and Turbidity", "categories": ["eess.SP"], "comment": "5 pages, 10 figures, submitted to arXiv", "summary": "Underwater flow sensing is critical for unmanned underwater vehicles (UUVs) and environmental monitoring, yet existing sensors often suffer from low responsiveness, high detection thresholds, limited directional discrimination, complex packaging, and poor long-term stability, especially for navigation and target perception in turbid and cluttered waters. Previous solutions based on traditional strain gauges with limited detection accuracy or doped silicon sensors with limited detection height have shown feasibility but still face challenges in scalability, robustness under harsh aquatic conditions, and calibration complexity. This work presents a bio-inspired whisker sensor that provides a balanced solution by embedding high-gauge-factor silicon strain gauges into a flexible PDMS base, mimicking seal whiskers to offer both high sensitivity and simplified packaging. The device exhibits a linear force-resistance response with a limit of detection of 0.27 mN, maintains stability after 10,000 loading cycles, and shows minimal offset drift of less than 2 percent. It also demonstrates frequency matching in underwater dipole tests with clear longitudinal and transverse spatial response patterns. These results indicate a robust and scalable route for underwater flow sensing on UUV platforms in practical deployments."}
{"id": "2511.22087", "pdf": "https://arxiv.org/pdf/2511.22087", "abs": "https://arxiv.org/abs/2511.22087", "authors": ["Tai Inui", "Jee-Hwan Ryu"], "title": "SoftNash: Entropy-Regularized Nash Games for Non-Fighting Virtual Fixtures", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Virtual fixtures (VFs) improve precision in teleoperation but often ``fight'' the user, inflating mental workload and eroding the sense of agency. We propose Soft-Nash Virtual Fixtures, a game-theoretic shared-control policy that softens the classic two-player linear-quadratic (LQ) Nash solution by inflating the fixture's effort weight with a single, interpretable scalar parameter $τ$. This yields a continuous dial on controller assertiveness: $τ=0$ recovers a hard, performance-focused Nash / virtual fixture controller, while larger $τ$ reduce gains and pushback, yet preserve the equilibrium structure and continuity of closed-loop stability. We derive Soft-Nash from both a KL-regularized trust-region and a maximum-entropy viewpoint, obtaining a closed-form robot best response that shrinks authority and aligns the fixture with the operator's input as $τ$ grows. We implement Soft-Nash on a 6-DoF haptic device in 3D tracking task ($n=12$). Moderate softness ($τ\\approx 1-3$, especially $τ=2$) maintains tracking error statistically indistinguishable from a tuned classic VF while sharply reducing controller-user conflict, lowering NASA-TLX workload, and increasing Sense of Agency (SoAS). A composite BalancedScore that combines normalized accuracy and non-fighting behavior peaks near $τ=2-3$. These results show that a one-parameter Soft-Nash policy can preserve accuracy while improving comfort and perceived agency, providing a practical and interpretable pathway to personalized shared control in haptics and teleoperation."}
{"id": "2511.22458", "pdf": "https://arxiv.org/pdf/2511.22458", "abs": "https://arxiv.org/abs/2511.22458", "authors": ["Ali Al Khansa", "Youssef Bahannis"], "title": "Adaptive Dual-Windowing Strategies for Multi-Target Detection in OFDM ISAC", "categories": ["eess.SP"], "comment": null, "summary": "In Orthogonal Frequency Division Multiplexing (OFDM) Integrated Sensing and Communication (ISAC) systems, a key challenge is balancing sidelobe attenuation and resolution for multi-target detection scenarios. While windowing functions are typically used to manage this trade-off, state-of-the-art methods rely on a single, fixed window followed by a predefined detection strategy (e.g., Binary Successive Target Cancellation (BSTC) (low complexity) or Coherent Successive Target Cancellation (CSTC) (high performance)). This paper proposes a novel dual-window periodogram-based algorithm that leverages two complementary windows: one optimized for resolution and the other for sidelobe suppression. Then, a low-complexity detection algorithm (e.g., BSTC) is applied to both, and a decision mechanism compares the outputs. When results align, the resolution-optimized estimates are directly used; otherwise, high performance algorithm (e.g., CSTC) is triggered to resolve ambiguities. This adaptive approach dynamically balances the detection performance and the complexity, addressing limitations in existing fixed strategies. The Numerical results confirm that the proposed method achieves high performance while reducing the complexity, especially at a high Signal to Noise Ratio (SNR)."}
{"id": "2511.22100", "pdf": "https://arxiv.org/pdf/2511.22100", "abs": "https://arxiv.org/abs/2511.22100", "authors": ["Zelong Zhou", "Wenrui Chen", "Zeyun Hu", "Qiang Diao", "Qixin Gao", "Yaonan Wang"], "title": "Design of an Adaptive Modular Anthropomorphic Dexterous Hand for Human-like Manipulation", "categories": ["cs.RO"], "comment": "7 pages, 8 figures", "summary": "Biological synergies have emerged as a widely adopted paradigm for dexterous hand design, enabling human-like manipulation with a small number of actuators. Nonetheless, excessive coupling tends to diminish the dexterity of hands. This paper tackles the trade-off between actuation complexity and dexterity by proposing an anthropomorphic finger topology with 4 DoFs driven by 2 actuators, and by developing an adaptive, modular dexterous hand based on this finger topology. We explore the biological basis of hand synergies and human gesture analysis, translating joint-level coordination and structural attributes into a modular finger architecture. Leveraging these biomimetic mappings, we design a five-finger modular hand and establish its kinematic model to analyze adaptive grasping and in-hand manipulation. Finally, we construct a physical prototype and conduct preliminary experiments, which validate the effectiveness of the proposed design and analysis."}
{"id": "2511.22473", "pdf": "https://arxiv.org/pdf/2511.22473", "abs": "https://arxiv.org/abs/2511.22473", "authors": ["Ali Al Khansa"], "title": "Learning to Count Targets from Dual-Window: A CNN Approach for OFDM ISAC", "categories": ["eess.SP"], "comment": null, "summary": "Integrated Sensing and Communication (ISAC) with Orthogonal Frequency Division Multiplexing (OFDM) waveforms is a key enabler for next-generation wireless systems. Recent studies show that Convolutional Neural Networks (CNNs) can estimate the number of targets from two-dimensional (2D) range-Doppler periodogram maps, yet accuracy often degrades as scenes become denser. One significant factor is the classical resolution-sidelobe attenuation trade-off, which limits performance when targets are weak or closely spaced. While windowing is routinely applied to shape this trade-off, the choice is typically static. This paper proposes a new CNN method that uses two windowed range-Doppler periodograms and learns to fuse complementary views: one window optimized for resolution and one window optimized for sidelobe suppression. The design explicitly targets the resolution-sidelobe attenuation trade-off by exposing the model to complementary windowed maps and letting it learn when each is most informative. Numerical experiments show consistent gains over single-window CNN baselines, with better scaling in target density and greater robustness across different noise levels."}
{"id": "2511.22195", "pdf": "https://arxiv.org/pdf/2511.22195", "abs": "https://arxiv.org/abs/2511.22195", "authors": ["Zhiyang Liu", "Ruiteng Zhao", "Lei Zhou", "Chengran Yuan", "Yuwei Wu", "Sheng Guo", "Zhengshen Zhang", "Chenchen Liu", "Marcelo H Ang"], "title": "3D Affordance Keypoint Detection for Robotic Manipulation", "categories": ["cs.RO"], "comment": "Accepted to IROS 2024", "summary": "This paper presents a novel approach for affordance-informed robotic manipulation by introducing 3D keypoints to enhance the understanding of object parts' functionality. The proposed approach provides direct information about what the potential use of objects is, as well as guidance on where and how a manipulator should engage, whereas conventional methods treat affordance detection as a semantic segmentation task, focusing solely on answering the what question. To address this gap, we propose a Fusion-based Affordance Keypoint Network (FAKP-Net) by introducing 3D keypoint quadruplet that harnesses the synergistic potential of RGB and Depth image to provide information on execution position, direction, and extent. Benchmark testing demonstrates that FAKP-Net outperforms existing models by significant margins in affordance segmentation task and keypoint detection task. Real-world experiments also showcase the reliability of our method in accomplishing manipulation tasks with previously unseen objects."}
{"id": "2511.22525", "pdf": "https://arxiv.org/pdf/2511.22525", "abs": "https://arxiv.org/abs/2511.22525", "authors": ["Ziang Liu", "Wonjae Shin", "Bruno Clerckx"], "title": "Enabling Full-Duplex LEO Satellite Systems with Non-Reciprocal BD-RIS-Assisted Beamforming", "categories": ["eess.SP"], "comment": "Submitted to IEEE Journal", "summary": "Low Earth orbit (LEO) satellite is a promising technology for providing low-latency, high-data-rate, and wide-coverage communication services. However, the high mobility of LEO satellites necessitates fast and accurate beam steering to continuously serve ground devices. While large antenna arrays can address these challenges, strict constraints on power, size, and weight make such solutions difficult to implement. Furthermore, future non-terrestrial networks (NTNs) require high spectral efficiency, which motivates the adoption of in-band full-duplex (FD) systems. {To overcome these challenges, we propose an FD LEO satellite system, where the non-reciprocal beyond-diagonal reconfigurable intelligent surfaces (NR-BD-RIS) and multiple transmit and receive antennas are attached to the LEO satellite. The NR-BD-RIS reflects the downlink (DL) and uplink (UL) signals by passive beamforming.} By incorporating non-reciprocal components into the impedance network of RIS, the NR-BD-RIS breaks channel reciprocity, facilitating simultaneous support for multiple beam directions. To cover a wide coverage, we propose a time-sharing scheduling framework where, in each time slot, the NR-BD-RIS simultaneously serves multiple DL and multiple UL ground devices. An optimization problem is defined to maximize the weighted sum-rate over the entire scheduling period. Numerical results demonstrate that the proposed NR-BD-RIS significantly performs better than both conventional BD-RIS and diagonal RIS (D-RIS) regarding DL and UL sum-rate performance under both single-user (SU) and multiple-user (MU) cases. Additionally, the NR-BD-RIS requires less frequent reconfiguration compared to other two types of RIS, making it more practical for implementation."}
{"id": "2511.22225", "pdf": "https://arxiv.org/pdf/2511.22225", "abs": "https://arxiv.org/abs/2511.22225", "authors": ["Gabriel Aguirre", "Simay Atasoy Bingöl", "Heiko Hamann", "Jonas Kuckling"], "title": "Bayesian Decentralized Decision-making for Multi-Robot Systems: Sample-efficient Estimation of Event Rates", "categories": ["cs.RO", "cs.MA"], "comment": "7 pages, 3 figures, submitted to IEEE MRS 2025", "summary": "Effective collective decision-making in swarm robotics often requires balancing exploration, communication and individual uncertainty estimation, especially in hazardous environments where direct measurements are limited or costly. We propose a decentralized Bayesian framework that enables a swarm of simple robots to identify the safer of two areas, each characterized by an unknown rate of hazardous events governed by a Poisson process. Robots employ a conjugate prior to gradually predict the times between events and derive confidence estimates to adapt their behavior. Our simulation results show that the robot swarm consistently chooses the correct area while reducing exposure to hazardous events by being sample-efficient. Compared to baseline heuristics, our proposed approach shows better performance in terms of safety and speed of convergence. The proposed scenario has potential to extend the current set of benchmarks in collective decision-making and our method has applications in adaptive risk-aware sampling and exploration in hazardous, dynamic environments."}
{"id": "2511.22629", "pdf": "https://arxiv.org/pdf/2511.22629", "abs": "https://arxiv.org/abs/2511.22629", "authors": ["António Barros", "Christoph Studer"], "title": "Interference and Multipath Resilient ToA Estimation", "categories": ["eess.SP", "cs.IT"], "comment": "Presented at the 59th Asilomar Conference on Signals, Systems, and Computers", "summary": "We present a computationally-efficient algorithm for time-of-arrival (ToA) estimation that is robust under multipath propagation and strong interference. Our algorithm leverages multiple receive antennas to combine adaptive spatial filtering with autodifferentiation in order to super-resolve the tap of the first-arriving path at low computational complexity and without requiring model-order estimation. We use simulations with ray-traced indoor propagation channels to demonstrate significant performance improvements over conventional correlation-based ToA estimation methods and subspace techniques such as JADE."}
{"id": "2511.22238", "pdf": "https://arxiv.org/pdf/2511.22238", "abs": "https://arxiv.org/abs/2511.22238", "authors": ["Ryosuke Ofuchi", "Yuichiro Toda", "Naoki Masuyama", "Takayuki Matsuno"], "title": "MLATC: Fast Hierarchical Topological Mapping from 3D LiDAR Point Clouds Based on Adaptive Resonance Theory", "categories": ["cs.RO"], "comment": null, "summary": "This paper addresses the problem of building global topological maps from 3D LiDAR point clouds for autonomous mobile robots operating in large-scale, dynamic, and unknown environments. Adaptive Resonance Theory-based Topological Clustering with Different Topologies (ATC-DT) builds global topological maps represented as graphs while mitigating catastrophic forgetting during sequential processing. However, its winner selection mechanism relies on an exhaustive nearest-neighbor search over all existing nodes, leading to scalability limitations as the map grows. To address this challenge, we propose a hierarchical extension called Multi-Layer ATC (MLATC). MLATC organizes nodes into a hierarchy, enabling the nearest-neighbor search to proceed from coarse to fine resolutions, thereby drastically reducing the number of distance evaluations per query. The number of layers is not fixed in advance. MLATC employs an adaptive layer addition mechanism that automatically deepens the hierarchy when lower layers become saturated, keeping the number of user-defined hyperparameters low. Simulation experiments on synthetic large-scale environments show that MLATC accelerates topological map building compared to the original ATC-DT and exhibits a sublinear, approximately logarithmic scaling of search time with respect to the number of nodes. Experiments on campus-scale real-world LiDAR datasets confirm that MLATC maintains a millisecond-level per-frame runtime and enables real-time global topological map building in large-scale environments, significantly outperforming the original ATC-DT in terms of computational efficiency."}
{"id": "2511.22673", "pdf": "https://arxiv.org/pdf/2511.22673", "abs": "https://arxiv.org/abs/2511.22673", "authors": ["Arasti Afrasiabi", "Farough Rahimzadeh", "Alireza Keshavarzi"], "title": "Advances in electromagnetic techniques for subsurface infrastructure detection: A comprehensive review of methods, challenges, and innovations", "categories": ["eess.SP"], "comment": null, "summary": "This review paper explores the state-of-the-art in non-intrusive methods for detecting and characterising buried infrastructure, focusing on Electrical Resistivity Tomography (ERT), Infrared Thermography (IRT), and magnetometry, along with data fusion techniques and mathematical estimators. ERT and IRT offer distinct advantages in subsurface imaging, while magnetometry provides omnidirectional measurements ideal for detecting ferrous targets. Despite these benefits, each method has inherent limitations, such as challenges in depth estimation and difficulties in distinguishing between various subsurface objects. The integration of multiple sensing techniques through data fusion approaches has shown significant promise in overcoming these limitations and improving detection accuracy. Additionally, mathematical estimators, including Kalman filters and particle filters, play a crucial role in reducing noise and enhancing the precision of geophysical surveys. This review discusses the strengths, limitations, and future research needs of these techniques, offering a comprehensive understanding of their current and potential applications in buried infrastructure detection. The paper concludes by emphasising the importance of optimising sensor performance, refining fusion algorithms, and exploring hybrid models for real-time data processing in future research."}
{"id": "2511.22318", "pdf": "https://arxiv.org/pdf/2511.22318", "abs": "https://arxiv.org/abs/2511.22318", "authors": ["Yuki Origane", "Koya Cho", "Hideyuki Tsukagoshi"], "title": "Soft Fluidic Sheet Transistor for Soft Robotic System Enabling Fluid Logic Operations", "categories": ["cs.RO"], "comment": "7 pages, 16 figures", "summary": "Aiming to achieve both high functionality and flexibility in soft robot system, this paper presents a soft urethane sheet-like valve with an amplifier that can perform logical operations using only pneumatic signals. When the control chamber in the valve is pressurized, the main path is compressed along its central axis, buckling and being pressed,resulting in blockage. This allows control by a pressure signal smaller than that within the main channel. Furthermore, similar to transistors in electrical circuits, when combined, the proposed valve can perform a variety of logical operations. The basic type operates as a NOT logic element, which is named the fluidic sheet transistor (FST). By integrating multiple FSTs, logical operations such as positive logic, NAND, and NOR can be performed on a single sheet. This paper describes the operating principle, fabrication method, and characteristics of the FST,followed by a method for configuring logical operations.Moreover, we demonstrate the construction of a latch circuit(self-holding logic circuit) using FST, introducing a prototype of a fluid robot system that combines a tactile tube as a fluidic detector and fluid actuators. This demonstrates that it is possible to generate behavior that actively changes posture when hitting an obstacle using only air pressure from a single pipe, which verifies the effectiveness of the proposed methods."}
{"id": "2511.22703", "pdf": "https://arxiv.org/pdf/2511.22703", "abs": "https://arxiv.org/abs/2511.22703", "authors": ["Yunxin Li", "Ying Zhang", "Christos Masouros", "Sofie Pollin", "Fan Liu"], "title": "Rethinking Signaling Design for ISAC: From Pilot-Based to Payload-Based Sensing", "categories": ["eess.SP"], "comment": "9 pages, 6 figures", "summary": "Integrated Sensing and Communications (ISAC) is emerging as a key enabler for 6G networks, with signaling design at the core of its evolution. This paper reviews the paradigm shift of ISAC signaling designs from pilot-aided sensing to data payload-based approaches, with a particular focus on how these techniques can be realized within existing 5G NR structures. We commence with the reuse of pilots and reference signals that exploit existing 5G New Radio (NR) structures for sensing. Then, we extend to more advanced approaches that integrate the data payload through novel constellation shaping, modulation bases, and pulse shaping filters. We highlight the opportunities and tradeoffs that arise when extending sensing from sparse pilot and reference signal resources to the full communication frame, emphasizing how constellation properties and modulation choices directly determine sensing performance. To illustrate practical feasibility, a case study on sensing-assisted NR Vehicle-to-Infrastructure (V2I) networks demonstrates how exploiting both reference signals and payload echoes can reduce signaling overhead and enable proactive beam management and handover."}
{"id": "2511.22338", "pdf": "https://arxiv.org/pdf/2511.22338", "abs": "https://arxiv.org/abs/2511.22338", "authors": ["Denghan Xiong", "Yanzhe Zhao", "Yutong Chen", "Zichun Wang"], "title": "Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning", "categories": ["cs.RO", "eess.SY"], "comment": "14 pages, 5 figures, 1 table, submitted to arXiv", "summary": "Nonholonomic constraints restrict feasible velocities without reducing configuration-space dimension, which makes collision-free geometric paths generally non-executable for car-like robots. Ackermann steering further imposes curvature bounds and forbids in-place rotation, so escaping from narrow dead ends typically requires tightly sequenced forward and reverse maneuvers. Classical planners that decouple global search and local steering struggle in these settings because narrow passages occupy low-measure regions and nonholonomic reachability shrinks the set of valid connections, which degrades sampling efficiency and increases sensitivity to clearances. We study nonholonomic narrow dead-end escape for Ackermann vehicles and contribute three components. First, we construct a generator that samples multi-phase forward-reverse trajectories compatible with Ackermann kinematics and inflates their envelopes to synthesize families of narrow dead ends that are guaranteed to admit at least one feasible escape. Second, we construct a training environment that enforces kinematic constraints and train a policy using the soft actor-critic algorithm. Third, we evaluate against representative classical planners that combine global search with nonholonomic steering. Across parameterized dead-end families, the learned policy solves a larger fraction of instances, reduces maneuver count, and maintains comparable path length and planning time while under the same sensing and control limits. We provide our project as open source at https://github.com/gitagitty/cisDRL-RobotNav.git"}
{"id": "2511.22752", "pdf": "https://arxiv.org/pdf/2511.22752", "abs": "https://arxiv.org/abs/2511.22752", "authors": ["Zeyuan Li", "Wenyi Yan", "Lu Gan", "Guoquan Li", "Hongqing Liu"], "title": "FPGA-Enabled Modulo ADC with x100 Dynamic-Range Expansion: Hardware Design and Performance Evaluation", "categories": ["eess.SP"], "comment": null, "summary": "Conventional analog-to-digital converters (ADCs) fail to capture high-dynamic-range (HDR) signals due to clipping. Modulo ADCs circumvent this limitation by folding the input prior to quantization and algorithmically reconstructing the original waveform. This work presents a field-programmable gate array (FPGA)-based modulo ADC platform for systematic HDR performance evaluation. The mixed-signal architecture integrates a precision analog front end with a 200-MHz FPGA control loop that incorporates multi-bit updates and digital under-compensation calibration, ensuring stable folding and accurate feedback generation. The system achieves more than a hundred-fold dynamic-range expansion within a 400-kHz bandwidth while maintaining fidelity comparable to that of a conventional ADC. A system-on-chip (SoC)-like implementation enables on-board real-time recovery and supports benchmarking of state-of-the-art reconstruction algorithms, providing a compact and practical framework for HDR signal acquisition and evaluation."}
{"id": "2511.22354", "pdf": "https://arxiv.org/pdf/2511.22354", "abs": "https://arxiv.org/abs/2511.22354", "authors": ["Suraj Borate", "Bhavish Rai B", "Vipul Pardeshi", "Madhu Vadali"], "title": "LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning", "categories": ["cs.RO"], "comment": "submitted to ICRA 2026", "summary": "This paper introduces CoMuRoS (Collaborative Multi-Robot System), a generalizable hierarchical architecture for heterogeneous robot teams that unifies centralized deliberation with decentralized execution, and supports event-driven replanning. A Task Manager LLM interprets natural-language goals, classifies tasks, and allocates subtasks using static rules plus dynamic contexts (task, history, robot and task status, and events).Each robot runs a local LLM that composes executable Python code from primitive skills (ROS2 nodes, policies), while onboard perception (VLMs/image processing) continuously monitors events and classifies them into relevant or irrelevant to the task. Task failures or user intent changes trigger replanning, allowing robots to assist teammates, resume tasks, or request human help. Hardware studies demonstrate autonomous recovery from disruptive events, filtering of irrelevant distractions, and tightly coordinated transport with emergent human-robot cooperation (e.g., multirobot collaborative object recovery success rate: 9/10, coordinated transport: 8/8, human-assisted recovery: 5/5).Simulation studies show intention-aware replanning. A curated textual benchmark spanning 22 scenarios (3 tasks each, around 20 robots) evaluates task allocation, classification, IoU, executability, and correctness, with high average scores (e.g., correctness up to 0.91) across multiple LLMs, a separate replanning set (5 scenarios) achieves 1.0 correctness. Compared with prior LLM-based systems, CoMuRoS uniquely demonstrates runtime, event-driven replanning on physical robots, delivering robust, flexible multi-robot and human-robot collaboration."}
{"id": "2511.22757", "pdf": "https://arxiv.org/pdf/2511.22757", "abs": "https://arxiv.org/abs/2511.22757", "authors": ["Wenyi Yan", "Lu Gan", "Hongqing Liu", "Shaoqing Hu"], "title": "Moduli Selection in Robust Chinese Remainder Theorem: Closed-Form Solutions and Layered Design", "categories": ["eess.SP"], "comment": null, "summary": "We study the fundamental problem of \\emph{moduli selection} in the Robust Chinese Remainder Theorem (RCRT), where each residue may be perturbed by a bounded error. Consider $L$ moduli of the form $m_i = Γ_i m$ ($1 \\le i \\le L$), where $Γ_i$ are pairwise coprime integers and $m \\in \\mathbb{R}^+$ is a common scaling factor. For small $L$ ($L = 2, 3, 4$), we obtain exact solutions that maximize the robustness margin under dynamic-range and modulus-bound constraints. We also introduce a Fibonacci-inspired \\emph{layered} construction (for $L = 2$) that produces exactly $K$ robust decoding layers, enabling predictable trade-offs between error tolerance and dynamic range. We further analyze how robustness and range evolve across layers and provide a closed-form expression to estimate the success probability under common data and noise models. The results are promising for various applications, such as sub-Nyquist sampling, phase unwrapping, range estimation, modulo analog-to-digital converters (ADCs), and robust residue-number-system (RNS)-based accelerators for deep learning. Our framework thus establishes a general theory of moduli design for RCRT, complementing prior algorithmic work and underscoring the broad relevance of robust moduli design across diverse information-processing domains."}
{"id": "2511.22364", "pdf": "https://arxiv.org/pdf/2511.22364", "abs": "https://arxiv.org/abs/2511.22364", "authors": ["Seongwon Cho", "Daechul Ahn", "Donghyun Shin", "Hyeonbeom Choi", "San Kim", "Jonghyun Choi"], "title": "BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands", "categories": ["cs.RO", "cs.AI"], "comment": "12 pages, 8 figures", "summary": "Open-vocabulary mobile manipulation (OVMM) requires robots to follow language instructions, navigate, and manipulate while updating their world representation under dynamic environmental changes. However, most prior approaches update their world representation only at discrete update points such as navigation targets, waypoints, or the end of an action step, leaving robots blind between updates and causing cascading failures: overlooked objects, late error detection, and delayed replanning. To address this limitation, we propose BINDER (Bridging INstant and DEliberative Reasoning), a dual process framework that decouples strategic planning from continuous environment monitoring. Specifically, BINDER integrates a Deliberative Response Module (DRM, a multimodal LLM for task planning) with an Instant Response Module (IRM, a VideoLLM for continuous monitoring). The two modules play complementary roles: the DRM performs strategic planning with structured 3D scene updates and guides what the IRM attends to, while the IRM analyzes video streams to update memory, correct ongoing actions, and trigger replanning when necessary. Through this bidirectional coordination, the modules address the trade off between maintaining awareness and avoiding costly updates, enabling robust adaptation under dynamic conditions. Evaluated in three real world environments with dynamic object placement, BINDER achieves substantially higher success and efficiency than SoTA baselines, demonstrating its effectiveness for real world deployment."}
{"id": "2511.22845", "pdf": "https://arxiv.org/pdf/2511.22845", "abs": "https://arxiv.org/abs/2511.22845", "authors": ["Xiang Cheng", "Weibo Wen", "Haotian Zhang", "Boxun Liu", "Zonghui Yang", "Jianan Zhang", "Xuesong Cai"], "title": "Embodied Intelligent Wireless (EIW): Synesthesia of Machines Empowered Wireless Communications", "categories": ["eess.SP"], "comment": null, "summary": "The evolution toward the sixth-generation (6G) and beyond mobile communication systems is marked by a fundamental shift from merely connecting devices to enabling pervasive and embodied intelligence. While recent advances in artificial intelligence (AI)-native wireless communication designs have achieved remarkable progress, the prevailing paradigm remains limited to static, modular AI substitutions. This approach fails to meet the core requirements of future wireless networks: the ability to continuously perceive, adapt to, and interact with the dynamic wireless environment. To bridge this gap, this paper introduces Embodied Intelligent Wireless (EIW), a novel communication paradigm inspired by embodied intelligence, which redefines the communication node as an active, environment-aware, and evolving entity. EIW is built around an observation-decision-action paradigm, comprising: multi-dimensional observations for comprehensive awareness of the environment and system states, a unified decision module for orchestrating multiple wireless agents in an interpretable manner, and actions where wireless agents exert practical effects on both the environment and communication systems. Furthermore, two enabling technologies, wireless world models as well as self-update and self-evolution mechanisms, are introduced to support training efficiency improvement, counterfactual evaluation, and better adaptation. Unlike existing communication systems, EIW envisions future communication systems not as passive data pipelines, but as intelligent entities that continuously interact with and co-evolve alongside their environments. Finally, through simulations, we showcase the advantages of the proposed EIW paradigm and its enabling techniques in shaping the design of wireless communication nodes."}
{"id": "2511.22445", "pdf": "https://arxiv.org/pdf/2511.22445", "abs": "https://arxiv.org/abs/2511.22445", "authors": ["Yikai Tang", "Haoran Geng", "Sheng Zang", "Pieter Abbeel", "Jitendra Malik"], "title": "Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion", "categories": ["cs.RO"], "comment": null, "summary": "Imitation learning has emerged as a crucial ap proach for acquiring visuomotor skills from demonstrations, where designing effective observation encoders is essential for policy generalization. However, existing methods often struggle to generalize under spatial and visual randomizations, instead tending to overfit. To address this challenge, we propose Visual Geometry Diffusion Policy (VGDP), a multimodal imitation learning framework built around a Complementarity-Aware Fusion Module where modality-wise dropout enforces balanced use of RGB and point-cloud cues, with cross-attention serving only as a lightweight interaction layer. Our experiments show that the expressiveness of the fused latent space is largely induced by the enforced complementarity from modality-wise dropout, with cross-attention serving primarily as a lightweight interaction mechanism rather than the main source of robustness. Across a benchmark of 18 simulated tasks and 4 real-world tasks, VGDP outperforms seven baseline policies with an average performance improvement of 39.1%. More importantly, VGDP demonstrates strong robustness under visual and spatial per turbations, surpassing baselines with an average improvement of 41.5% in different visual conditions and 15.2% in different spatial settings."}
{"id": "2511.22910", "pdf": "https://arxiv.org/pdf/2511.22910", "abs": "https://arxiv.org/abs/2511.22910", "authors": ["Ahmet Muaz Aktas", "Sefa Kayraklik", "Sultangali Arzykulov", "Galymzhan Nauryzbayev", "Ibrahim Hokelek", "Ali Gorcin"], "title": "RIS-Assisted Physical Layer Security: Artificial Noise-Driven Optimization and Measurements", "categories": ["eess.SP"], "comment": "Submitted to possible IEEE publication", "summary": "Reconfigurable intelligent surface (RIS) has emerged as a key enabler for providing signal coverage, energy efficiency, reliable communication, and physical layer security (PLS) in next-generation wireless communication networks. This paper investigates an artificial noise (AN)-driven RIS-assisted secure communication system. The RIS is partitioned into two segments, where the first segment is configured to direct the communication signal (CS) toward the legitimate user (Bob), and the other one is configured to steer the AN toward the eavesdropper (Eve). To this end, iterative and discrete Fourier transform-based algorithms are developed for practical RIS phase shift optimization. The power allocation between the CS and the AN signals is optimized in such a way that the secrecy capacity (SC) is maximized while limiting Eve's channel capacity. The proposed PLS framework is evaluated through both simulations and software defined radio based testbed experiments. The results demonstrate promising improvements in the SC, highlighting the potential of AN-driven RIS-assisted PLS for practical deployments."}
{"id": "2511.22505", "pdf": "https://arxiv.org/pdf/2511.22505", "abs": "https://arxiv.org/abs/2511.22505", "authors": ["Xiujian Liang", "Jiacheng Liu", "Mingyang Sun", "Qichen He", "Cewu Lu", "Jianhua Sun"], "title": "RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Robot manipulation in the real world is fundamentally constrained by the visual sim2real gap, where depth observations collected in simulation fail to reflect the complex noise patterns inherent to real sensors. In this work, inspired by the denoising capability of diffusion models, we invert the conventional perspective and propose a clean-to-noisy paradigm that learns to synthesize noisy depth, thereby bridging the visual sim2real gap through purely simulation-driven robotic learning. Building on this idea, we introduce RealD$^2$iff, a hierarchical coarse-to-fine diffusion framework that decomposes depth noise into global structural distortions and fine-grained local perturbations. To enable progressive learning of these components, we further develop two complementary strategies: Frequency-Guided Supervision (FGS) for global structure modeling and Discrepancy-Guided Optimization (DGO) for localized refinement. To integrate RealD$^2$iff seamlessly into imitation learning, we construct a pipeline that spans six stages. We provide comprehensive empirical and experimental validation demonstrating the effectiveness of this paradigm. RealD$^2$iff enables two key applications: (1) generating real-world-like depth to construct clean-noisy paired datasets without manual sensor data collection. (2) Achieving zero-shot sim2real robot manipulation, substantially improving real-world performance without additional fine-tuning."}
{"id": "2511.22933", "pdf": "https://arxiv.org/pdf/2511.22933", "abs": "https://arxiv.org/abs/2511.22933", "authors": ["Onur Salan", "Burak Çırağ", "Onur Sever", "İbrahim Hökelek", "Ali Görçin", "Hakan Ali Çırpan"], "title": "RAG-Empowered LLM-Driven Dynamic Radio Resource Management in Open 6G RAN", "categories": ["eess.SP"], "comment": "Submitted to possible IEEE conferences", "summary": "Implications of the advancements in the area of artificial intelligence to the wireless communications is extremely significant, especially in terms of resource management. In this paper, a Retrieval-Augmented Generation (RAG)-empowered Large Language Model (ReLLM)-driven dynamic radio resource management framework for Open Radio Access Network (O-RAN) inspired 6G networks is proposed. The introduced methodology leverages the ReLLM framework to interpret both historical and real-time network data, enabling adaptive control of network slices. The ReLLM is founded on two specialized agents, one is responsible for proactively detecting service level agreement (SLA) violations by continuously monitoring and estimating slice-specific performance metrics, and the other one is responsible for dynamically reallocating physical resource blocks when the SLA violation probability exceeds a pre-defined threshold. The primary objective of this dual-agent design is to minimize unnecessary LLM inference calls while satisfying the SLA requirements of the slices, thereby improving computational and energy efficiency. The proposed ReLLM framework is implemented and validated on an end-to-end O-RAN testbed built upon open-source OpenAirInterface emulators. The experimental results demonstrate that the LLM approach with its reduced token consumption feature maintains a near-zero drop ratio for the low-priority slice while simultaneously satisfying acceptable latency performance for the high-priority slice. The ReLLM-driven design improves reliability and SLA compliance, confirming its practicality for real-world O-RAN testbeds and its potential applicability to future 6G networks."}
{"id": "2511.22541", "pdf": "https://arxiv.org/pdf/2511.22541", "abs": "https://arxiv.org/abs/2511.22541", "authors": ["Jinyang Li", "Marcello Farina", "Luca Mozzarelli", "Luca Cattaneo", "Panita Rattamasanaprapai", "Eleonora A. Tagarelli", "Matteo Corno", "Paolo Perego", "Giuseppe Andreoni", "Emanuele Lettieri"], "title": "BUDD-e: an autonomous robotic guide for visually impaired users", "categories": ["cs.RO", "eess.SY"], "comment": "14 pages", "summary": "This paper describes the design and the realization of a prototype of the novel guide robot BUDD-e for visually impaired users. The robot has been tested in a real scenario with the help of visually disabled volunteers at ASST Grande Ospedale Metropolitano Niguarda, in Milan. The results of the experimental campaign are throughly described in the paper, displaying its remarkable performance and user-acceptance."}
{"id": "2511.23028", "pdf": "https://arxiv.org/pdf/2511.23028", "abs": "https://arxiv.org/abs/2511.23028", "authors": ["Niko Lindvall", "Mikko Heino", "Robin Rajamäki", "Mikko Valkama", "Visa Koivunen"], "title": "DoA Estimation with Sparse Arrays: Effects of Antenna Element Patterns and Nonidealities", "categories": ["eess.SP"], "comment": null, "summary": "This paper studies the effects of directional antenna element complex gain patterns and nonidealities in direction of arrival (DoA) estimation. We compare sparse arrays and classical uniform linear arrays, harnessing EM simulation tools to accurately model the electromagnetic behavior of both patch and Vivaldi antenna element including mutual coupling effects. We show that with sparse array configurations, the performance impacts are significant in terms of DoA estimation accuracy and operable SNR ranges. Specifically, in the scenarios considered, both the usage of directional antenna elements and a sparse array result in over 90% reduction in average direction finding error, compared to a uniform omnidirectional array with the same number of elements (in this case eight), when estimating the directions of two sources using the MUSIC algorithm. For a fixed angular RMSE, the improvements in array sensitivity are shown to yield a 4 to 15-fold increase in one-way coverage distance (assuming free-space path loss). Among the studied options, the best performance was obtained using sparse arrays with either patch or Vivaldi elements for field of views of 100$^\\circ$ or 120$^\\circ$, respectively."}
{"id": "2511.22555", "pdf": "https://arxiv.org/pdf/2511.22555", "abs": "https://arxiv.org/abs/2511.22555", "authors": ["Yanbo Mao", "Jianlong Fu", "Ruoxuan Zhang", "Hongxia Xie", "Meibao Yao"], "title": "Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have enabled notable progress in general-purpose robotic manipulation, yet their learned policies often exhibit variable execution quality. We attribute this variability to the mixed-quality nature of human demonstrations, where the implicit principles that govern how actions should be carried out are only partially satisfied. To address this challenge, we introduce the LIBERO-Elegant benchmark with explicit criteria for evaluating execution quality. Using these criteria, we develop a decoupled refinement framework that improves execution quality without modifying or retraining the base VLA policy. We formalize Elegant Execution as the satisfaction of Implicit Task Constraints (ITCs) and train an Elegance Critic via offline Calibrated Q-Learning to estimate the expected quality of candidate actions. At inference time, a Just-in-Time Intervention (JITI) mechanism monitors critic confidence and intervenes only at decision-critical moments, providing selective, on-demand refinement. Experiments on LIBERO-Elegant and real-world manipulation tasks show that the learned Elegance Critic substantially improves execution quality, even on unseen tasks. The proposed model enables robotic control that values not only whether tasks succeed, but also how they are performed."}
{"id": "2511.23049", "pdf": "https://arxiv.org/pdf/2511.23049", "abs": "https://arxiv.org/abs/2511.23049", "authors": ["Priyadarshi Mukherjee", "Constantinos Psomas", "Ioannis Krikidis"], "title": "Harnessing Chaotic Signals for Wireless Information and Power Transfer", "categories": ["eess.SP"], "comment": "This work has been submitted to an IEEE journal for possible publication", "summary": "Chaotic dynamical systems have attracted considerable attention due to their inherent randomness and high sensitivity to initial conditions, which makes them ideal for secure wireless communications. Beyond security, these same characteristics also make chaotic signals particularly effective for wireless power transfer (WPT) applications. On the other hand, connectivity along with self-sustainability are the two cornerstones of the upcoming sixth generation (6G) standard for radio communications. Consequently, with the massive increase in wireless devices and sensors, the concept of self-sustainable wireless networks is becoming more relevant. The aspect of WPT to the widely spread wireless devices and simultaneous wireless information and power transfer (SWIPT) among these devices will play a crucial role in the 6G communication systems. In this context, it has been experimentally observed that chaotic signals result in better WPT performance as compared to the existing benchmark schemes. Hence, in this paper, we characterize the generalized WPT performance of the multi-dimensional chaotic signals and present the use case of the Lorenz and the Henon chaotic systems. Moreover, we provide a novel differential chaos shift keying (DCSK)-based WPT receiver architecture ideal for enhanced energy harvesting (EH). Furthermore, we propose DCSK-based transmit waveform designs for multi-antenna SWIPT architectures and investigate the impact of the rate-energy trade-off. Our goal is to explore these aspects of the chaotic signals and discuss their relevance in the context of both WPT and SWIPT."}
{"id": "2511.22685", "pdf": "https://arxiv.org/pdf/2511.22685", "abs": "https://arxiv.org/abs/2511.22685", "authors": ["Haoyi Wang", "Licheng Luo", "Yiannis Kantaros", "Bruno Sinopoli", "Mingyu Cai"], "title": "Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Multi-robot navigation in cluttered environments presents fundamental challenges in balancing reactive collision avoidance with long-range goal achievement. When navigating through narrow passages\n  or confined spaces, deadlocks frequently emerge that prevent agents from reaching their destinations, particularly when Reinforcement Learning (RL) control policies encounter novel configurations out of learning distribution. Existing RL-based approaches suffer from limited generalization capability in unseen environments. We propose a hybrid framework that seamlessly integrates RL-based reactive navigation with on-demand Multi-Agent Path Finding (MAPF) to explicitly resolve topological deadlocks. Our approach integrates a safety layer that monitors agent progress to detect deadlocks and, when detected, triggers a coordination controller for affected agents. The framework constructs globally feasible trajectories via MAPF and regulates waypoint progression to reduce inter-agent conflicts during navigation.\n  Extensive evaluation on dense multi-agent benchmarks shows that our method boosts task completion from marginal to near-universal success, markedly reducing deadlocks and collisions. When integrated with hierarchical task planning, it enables coordinated navigation for heterogeneous robots, demonstrating that coupling reactive RL navigation with selective MAPF intervention yields a robust, zero-shot performance."}
{"id": "2511.23072", "pdf": "https://arxiv.org/pdf/2511.23072", "abs": "https://arxiv.org/abs/2511.23072", "authors": ["Mikayil Mahmudlu", "Oktay Karakuş", "Hasan Arkadaş"], "title": "What If They Took the Shot? A Hierarchical Bayesian Framework for Counterfactual Expected Goals", "categories": ["eess.SP", "cs.AI", "stat.AP"], "comment": null, "summary": "This study develops a hierarchical Bayesian framework that integrates expert domain knowledge to quantify player-specific effects in expected goals (xG) estimation, addressing a limitation of standard models that treat all players as identical finishers. Using 9,970 shots from StatsBomb's 2015-16 data and Football Manager 2017 ratings, we combine Bayesian logistic regression with informed priors to stabilise player-level estimates, especially for players with few shots. The hierarchical model reduces posterior uncertainty relative to weak priors and achieves strong external validity: hierarchical and baseline predictions correlate at R2 = 0.75, while an XGBoost benchmark validated against StatsBomb xG reaches R2 = 0.833. The model uncovers interpretable specialisation profiles, including one-on-one finishing (Aguero, Suarez, Belotti, Immobile, Martial), long-range shooting (Pogba), and first-touch execution (Insigne, Salah, Gameiro). It also identifies latent ability in underperforming players such as Immobile and Belotti. The framework supports counterfactual \"what-if\" analysis by reallocating shots between players under identical contexts. Case studies show that Sansone would generate +2.2 xG from Berardi's chances, driven largely by high-pressure situations, while Vardy-Giroud substitutions reveal strong asymmetry: replacing Vardy with Giroud results in a large decline (about -7 xG), whereas the reverse substitution has only a small effect (about -1 xG). This work provides an uncertainty-aware tool for player evaluation, recruitment, and tactical planning, and offers a general approach for domains where individual skill and contextual factors jointly shape performance."}
{"id": "2511.22697", "pdf": "https://arxiv.org/pdf/2511.22697", "abs": "https://arxiv.org/abs/2511.22697", "authors": ["Chancharik Mitra", "Yusen Luo", "Raj Saravanan", "Dantong Niu", "Anirudh Pai", "Jesse Thomason", "Trevor Darrell", "Abrar Anwar", "Deva Ramanan", "Roei Herzig"], "title": "Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations", "categories": ["cs.RO", "cs.CL", "cs.CV"], "comment": null, "summary": "Vision-Language Action (VLAs) models promise to extend the remarkable success of vision-language models (VLMs) to robotics. Yet, unlike VLMs in the vision-language domain, VLAs for robotics require finetuning to contend with varying physical factors like robot embodiment, environment characteristics, and spatial relationships of each task. Existing fine-tuning methods lack specificity, adapting the same set of parameters regardless of a task's visual, linguistic, and physical characteristics. Inspired by functional specificity in neuroscience, we hypothesize that it is more effective to finetune sparse model representations specific to a given task. In this work, we introduce Robotic Steering, a finetuning approach grounded in mechanistic interpretability that leverages few-shot demonstrations to identify and selectively finetune task-specific attention heads aligned with the physical, visual, and linguistic requirements of robotic tasks. Through comprehensive on-robot evaluations with a Franka Emika robot arm, we demonstrate that Robotic Steering outperforms LoRA while achieving superior robustness under task variation, reduced computational cost, and enhanced interpretability for adapting VLAs to diverse robotic tasks."}
{"id": "2511.23079", "pdf": "https://arxiv.org/pdf/2511.23079", "abs": "https://arxiv.org/abs/2511.23079", "authors": ["Pigi P. Papanikolaou", "Dimitrios Bozanis", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "Panagiotis Sarigiannidis", "George K. Karagiannidis"], "title": "Physical Layer Security with Artificial Noise in MIMO Pinching-Antenna Systems", "categories": ["eess.SP"], "comment": "11 pages, 10 figures", "summary": "As next-generation wireless networks emerge, security is becoming a critical performance metric. However, conventional multiple-input-multiple-output (MIMO) systems often suffer from severe path loss and are vulnerable to nearby eavesdroppers due to their fixed-antenna configurations. Pinching-antenna systems (PASs) offer a promising alternative, leveraging reconfigurable pinching antennas (PAs) positioned along low-loss dielectric waveguides to enhance channel conditions and dynamically mitigate security threats. In this paper, we propose an artificial noise (AN)-aided beamforming framework for the PAS downlink that maximizes the secrecy rate (SR) by jointly optimizing the information beams, the AN covariance, and the PA positions. We examine both perfect and imperfect channel state information (CSI) for the eavesdropper's channel. For the latter, location errors are mapped via a Jacobian into an ellipsoidal channel uncertainty set to accurately formulate the problem. We derive a closed-form solution for the single-waveguide scenario, yielding the optimal PA location and an information/AN power-splitting rule. For multiple waveguides and users, we develop a deep neural network (DNN)-aided joint optimizer that outputs beams, AN, and PA placements. Numerical results demonstrate that the proposed scheme improves SR consistently over PAS baselines in single- and multi-user settings under both perfect and imperfect CSI."}
{"id": "2511.22705", "pdf": "https://arxiv.org/pdf/2511.22705", "abs": "https://arxiv.org/abs/2511.22705", "authors": ["Ian Lalonde", "Jeff Denis", "Mathieu Lamy", "Camille Martin", "Karina Lebel", "Alexandre Girard"], "title": "A Two Degrees-of-Freedom Floor-Based Robot for Transfer and Rehabilitation Applications", "categories": ["cs.RO", "eess.SY"], "comment": "13 pages, 16 figures", "summary": "The ability to accomplish a sit-to-stand (STS) motion is key to increase functional mobility and reduce rehospitalization risks. While raising aid (transfer) devices and partial bodyweight support (rehabilitation) devices exist, both are unable to adjust the STS training to different mobility levels. Therefore, We have developed an STS training device that allows various configurations of impedance and vertical/forward forces to adapt to many training needs while maintaining commercial raising aid transfer capabilities. Experiments with healthy adults (both men and women) of various heights and weights show that the device 1) has a low impact on the natural STS kinematics, 2) can provide precise weight unloading at the patient's center of mass and 3) can add a forward virtual spring to assist the transfer of the bodyweight to the feet for seat-off, at the start of the STS motion."}
{"id": "2511.23128", "pdf": "https://arxiv.org/pdf/2511.23128", "abs": "https://arxiv.org/abs/2511.23128", "authors": ["Yao Peng", "Tingting Liu", "Chenyang Yang"], "title": "Joint Optimization of Pilot Length, Pilot Assignment, and Power Allocation for Cell-free MIMO Systems with Graph Neural Networks", "categories": ["eess.SP"], "comment": null, "summary": "In user-centric cell-free multi-antenna systems, pilot contamination degrades spectral efficiency (SE) severely. To mitigate pilot contamination, existing works jointly optimize pilot assignment and power allocation by assuming fixed pilot length, which fail to balance pilot overhead against the contamination. To maximize net-SE, we jointly optimize pilot length, pilot assignment, and power allocation with deep learning. Since the pilot length is a variable, the size of pilot assignment matrix is unknown during the optimization. To cope with the challenge, we design size-generalizable graph neural networks (GNNs). We prove that pilot assignment policy is a one-to-many mapping, and improperly designed GNNs cannot learn the optimal policy. We tackle this issue by introducing feature enhancement. To improve learning performance, we design a contamination-aware attention mechanism for the GNNs. Given that pilot assignment and power allocation respectively depend on large- and small-scale channels, we develop a dual-timescale GNN framework to explore the potential. To reduce inference time, a single-timescale GNN is also designed. Simulation results show that the designed GNNs outperform existing methods in terms of net-SE, training complexity, and inference time, and can be well generalized across problem scales and channels."}
{"id": "2511.22744", "pdf": "https://arxiv.org/pdf/2511.22744", "abs": "https://arxiv.org/abs/2511.22744", "authors": ["Rémy Rahem", "Wael Suleiman"], "title": "Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion", "categories": ["cs.RO"], "comment": "12 pages, 6 figures, code available at https://anonymous.4open.science/r/multiview-parkour-6FB8", "summary": "Recent progress in legged locomotion has allowed highly dynamic and parkour-like behaviors for robots, similar to their biological counterparts. Yet, these methods mostly rely on egocentric (first-person) perception, limiting their performance, especially when the viewpoint of the robot is occluded. A promising solution would be to enhance the robot's environmental awareness by using complementary viewpoints, such as multiple actors exchanging perceptual information. Inspired by this idea, this work proposes a multi-view depth-based locomotion framework that combines egocentric and exocentric observations to provide richer environmental context during agile locomotion. Using a teacher-student distillation approach, the student policy learns to fuse proprioception with dual depth streams while remaining robust to real-world sensing imperfections. To further improve robustness, we introduce extensive domain randomization, including stochastic remote-camera dropouts and 3D positional perturbations that emulate aerial-ground cooperative sensing. Simulation results show that multi-viewpoints policies outperform single-viewpoint baseline in gap crossing, step descent, and other dynamic maneuvers, while maintaining stability when the exocentric camera is partially or completely unavailable. Additional experiments show that moderate viewpoint misalignment is well tolerated when incorporated during training. This study demonstrates that heterogeneous visual feedback improves robustness and agility in quadrupedal locomotion. Furthermore, to support reproducibility, the implementation accompanying this work is publicly available at https://anonymous.4open.science/r/multiview-parkour-6FB8"}
{"id": "2511.23135", "pdf": "https://arxiv.org/pdf/2511.23135", "abs": "https://arxiv.org/abs/2511.23135", "authors": ["Julian P. Merkofer", "Antonia Kaiser", "Anouk Schrantee", "Oliver J. Gurney-Champion", "Ruud J. G. van Sloun"], "title": "Strategies to Minimize Out-of-Distribution Effects in Data-Driven MRS Quantification", "categories": ["eess.SP", "physics.med-ph", "stat.ML"], "comment": "Submitted to MRM", "summary": "This study systematically compared data-driven and model-based strategies for metabolite quantification in magnetic resonance spectroscopy (MRS), focusing on resilience to out-of-distribution (OoD) effects and the balance between accuracy, robustness, and generalizability. A neural network designed for MRS quantification was trained using three distinct strategies: supervised regression, self-supervised learning, and test-time adaptation. These were compared against model-based fitting tools. Experiments combined large-scale simulated data, designed to probe metabolite concentration extrapolation and signal variability, with 1H single-voxel 7T in-vivo human brain spectra. In simulations, supervised learning achieved high accuracy for spectra similar to those in the training distribution, but showed marked degradation when extrapolated beyond the training distribution. Test-time adaptation proved more resilient to OoD effects, while self-supervised learning achieved intermediate performance. In-vivo experiments showed larger variance across the methods (data-driven and model-based) due to domain shift. Across all strategies, overlapping metabolites and baseline variability remained persistent challenges. While strong performance can be achieved by data-driven methods for MRS metabolite quantification, their reliability is contingent on careful consideration of the training distribution and potential OoD effects. When such conditions in the target distribution cannot be anticipated, test-time adaptation strategies ensure consistency between the quantification, the data, and the model, enabling reliable data-driven MRS pipelines."}
{"id": "2511.22773", "pdf": "https://arxiv.org/pdf/2511.22773", "abs": "https://arxiv.org/abs/2511.22773", "authors": ["Rui Heng Yang", "Xuan Zhao", "Leo Maxime Brunswic", "Montgomery Alban", "Mateo Clemente", "Tongtong Cao", "Jun Jin", "Amir Rasouli"], "title": "CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance", "categories": ["cs.RO", "cs.AI"], "comment": "4 tables, 9 figures", "summary": "In robotics, diffusion models can capture multi-modal trajectories from demonstrations, making them a transformative approach in imitation learning. However, achieving optimal performance following this regiment requires a large-scale dataset, which is costly to obtain, especially for challenging tasks, such as collision avoidance. In those tasks, generalization at test time demands coverage of many obstacles types and their spatial configurations, which are impractical to acquire purely via data. To remedy this problem, we propose Context-Aware diffusion policy via Proximal mode Expansion (CAPE), a framework that expands trajectory distribution modes with context-aware prior and guidance at inference via a novel prior-seeded iterative guided refinement procedure. The framework generates an initial trajectory plan and executes a short prefix trajectory, and then the remaining trajectory segment is perturbed to an intermediate noise level, forming a trajectory prior. Such a prior is context-aware and preserves task intent. Repeating the process with context-aware guided denoising iteratively expands mode support to allow finding smoother, less collision-prone trajectories. For collision avoidance, CAPE expands trajectory distribution modes with collision-aware context, enabling the sampling of collision-free trajectories in previously unseen environments while maintaining goal consistency. We evaluate CAPE on diverse manipulation tasks in cluttered unseen simulated and real-world settings and show up to 26% and 80% higher success rates respectively compared to SOTA methods, demonstrating better generalization to unseen environments."}
{"id": "2511.23177", "pdf": "https://arxiv.org/pdf/2511.23177", "abs": "https://arxiv.org/abs/2511.23177", "authors": ["Deyu Li", "Xinyuan Liao", "Shaowei Chen", "Shuai Zhao"], "title": "Data-Efficient Motor Condition Monitoring with Time Series Foundation Models", "categories": ["eess.SP", "eess.SY"], "comment": null, "summary": "Motor condition monitoring is essential for ensuring system reliability and preventing catastrophic failures. However, data-driven diagnostic methods often suffer from sparse fault labels and severe class imbalance, which limit their effectiveness in real-world applications. This paper proposes a motor condition monitoring framework that leverages the general features learned during pre-training of two time series foundation models, MOMENT and Mantis, to address these challenges. By transferring broad temporal representations from large-scale pre-training, the proposed approach significantly reduces dependence on labeled data while maintaining high diagnostic accuracy. Experimental results show that MOMENT achieves nearly twice the performance of conventional deep learning models using only 1\\% of the training data, whereas Mantis surpasses state-of-the-art baselines by 22\\%, reaching 90\\% accuracy with the same data ratio. These results demonstrate the strong generalization and data efficiency of time series foundation models in fault diagnosis, providing new insights into scalable and adaptive frameworks for intelligent motor condition monitoring."}
{"id": "2511.22777", "pdf": "https://arxiv.org/pdf/2511.22777", "abs": "https://arxiv.org/abs/2511.22777", "authors": ["Sajjad Pakdamansavoji", "Mozhgan Pourkeshavarz", "Adam Sigal", "Zhiyuan Li", "Rui Heng Yang", "Amir Rasouli"], "title": "Improving Robotic Manipulation Robustness via NICE Scene Surgery", "categories": ["cs.RO", "cs.AI"], "comment": "11 figures, 3 tables", "summary": "Learning robust visuomotor policies for robotic manipulation remains a challenge in real-world settings, where visual distractors can significantly degrade performance and safety. In this work, we propose an effective and scalable framework, Naturalistic Inpainting for Context Enhancement (NICE). Our method minimizes out-of-distribution (OOD) gap in imitation learning by increasing visual diversity through construction of new experiences using existing demonstrations. By utilizing image generative frameworks and large language models, NICE performs three editing operations, object replacement, restyling, and removal of distracting (non-target) objects. These changes preserve spatial relationships without obstructing target objects and maintain action-label consistency. Unlike previous approaches, NICE requires no additional robot data collection, simulator access, or custom model training, making it readily applicable to existing robotic datasets.\n  Using real-world scenes, we showcase the capability of our framework in producing photo-realistic scene enhancement. For downstream tasks, we use NICE data to finetune a vision-language model (VLM) for spatial affordance prediction and a vision-language-action (VLA) policy for object manipulation. Our evaluations show that NICE successfully minimizes OOD gaps, resulting in over 20% improvement in accuracy for affordance prediction in highly cluttered scenes. For manipulation tasks, success rate increases on average by 11% when testing in environments populated with distractors in different quantities. Furthermore, we show that our method improves visual robustness, lowering target confusion by 6%, and enhances safety by reducing collision rate by 7%."}
{"id": "2511.23187", "pdf": "https://arxiv.org/pdf/2511.23187", "abs": "https://arxiv.org/abs/2511.23187", "authors": ["Feng Xi", "Dehui Yang"], "title": "Near-Field Channel Estimation and Joint Angle-Range Recovery in XL-MIMO Systems: A Gridless Super-Resolution Approach", "categories": ["eess.SP"], "comment": null, "summary": "Existing near-field channel estimation methods for extremely large-scale MIMO (XL-MIMO) typically discretize angle and range parameters jointly, resulting in large polar-domain codebooks. This paper proposes a novel framework that formulates near-field channel estimation as a gridless super-resolution problem, eliminating the need for explicitly constructed codebooks. By employing a second-order approximation of spherical-wave steering vectors, the near-field channel is represented as a superposition of complex exponentials modulated by unknown waveforms. We demonstrate that these waveforms lie tightly in a common discrete chirp rate (DCR) subspace, with a dimension that scales as $Θ(\\sqrt{N})$ for an $N$-element array. By leveraging this structure and applying a lifting technique, we reformulate the non-convex problem as a convex program using regularized atomic norm minimization, which admits an equivalent semidefinite program. From the solution to the convex program, we obtain gridless angle estimates and derive closed-form coarse range estimates, followed by refinement under the exact spherical model using gradient-based nonlinear least squares. The proposed method avoids basis mismatch and exhaustive two-dimensional grid searches while enabling accurate joint angle-range estimation with pilot budgets that scale sublinearly with array size in sparse multipath regimes. Simulations demonstrate accurate channel reconstruction and user localization across representative near-field scenarios."}
{"id": "2511.22780", "pdf": "https://arxiv.org/pdf/2511.22780", "abs": "https://arxiv.org/abs/2511.22780", "authors": ["Amir Rasouli", "Montgomery Alban", "Sajjad Pakdamansavoji", "Zhiyuan Li", "Zhanguang Zhang", "Aaron Wu", "Xuan Zhao"], "title": "Distracted Robot: How Visual Clutter Undermine Robotic Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "12 figures, 2 tables", "summary": "In this work, we propose an evaluation protocol for examining the performance of robotic manipulation policies in cluttered scenes. Contrary to prior works, we approach evaluation from a psychophysical perspective, therefore we use a unified measure of clutter that accounts for environmental factors as well as the distractors quantity, characteristics, and arrangement. Using this measure, we systematically construct evaluation scenarios in both hyper-realistic simulation and real-world and conduct extensive experimentation on manipulation policies, in particular vision-language-action (VLA) models. Our experiments highlight the significant impact of scene clutter, lowering the performance of the policies, by as much as 34% and show that despite achieving similar average performance across the tasks, different VLA policies have unique vulnerabilities and a relatively low agreement on success scenarios. We further show that our clutter measure is an effective indicator of performance degradation and analyze the impact of distractors in terms of their quantity and occluding influence. At the end, we show that finetuning on enhanced data, although effective, does not equally remedy all negative impacts of clutter on performance."}
{"id": "2511.23201", "pdf": "https://arxiv.org/pdf/2511.23201", "abs": "https://arxiv.org/abs/2511.23201", "authors": ["Ali Waqar Azim", "Ahmad Bazzi", "Theodore S. Rappaport", "Marwa Chafii"], "title": "A Framework for Statistical Geometric Channel Model for ISAC Systems", "categories": ["eess.SP"], "comment": null, "summary": "This paper proposes a comprehensive framework for a geometry-based statistical model for integrated sensing and communication (ISAC) tailored for bistatic systems. Our dual-component model decomposes the ISAC channel into a target channel encompassing all multipath components produced by a sensing target parameterized by the target's radar cross-section and scattering points, and a background channel comprising all other propagation paths that do not interact with the sensing target. The framework extends TR38.901 via a hybrid clustering approach, integrating spatiotemporally consistent deterministic clusters with stochastic clusters to preserve channel reciprocity and absolute delay alignment for sensing parameter estimation. Extensive simulations across urban macro, urban micro, and indoor factory scenarios demonstrate that the model maintains communication performance parity with the standard TR38.901, validated through bit-error rate analysis obtained via simulated and measured ISAC channels and channel capacity assessment, while enabling sensing performance evaluation, such as target ranging error for localization and receiver operating characteristic curves for detection probability."}
{"id": "2511.22829", "pdf": "https://arxiv.org/pdf/2511.22829", "abs": "https://arxiv.org/abs/2511.22829", "authors": ["Zhen Tian", "Zhihao Lin"], "title": "Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "This paper presents a novel trajectory planning pipeline for complex driving scenarios like autonomous lane changing, by integrating risk-aware planning with guaranteed collision avoidance into a unified optimization framework. We first construct a dynamic risk fields (DRF) that captures both the static and dynamic collision risks from surrounding vehicles. Then, we develop a rigorous strategy for generating time-varying convex feasible spaces that ensure kinematic feasibility and safety requirements. The trajectory planning problem is formulated as a finite-horizon optimal control problem and solved using a constrained iterative Linear Quadratic Regulator (iLQR) algorithm that jointly optimizes trajectory smoothness, control effort, and risk exposure while maintaining strict feasibility. Extensive simulations demonstrate that our method outperforms traditional approaches in terms of safety and efficiency, achieving collision-free trajectories with shorter lane-changing distances (28.59 m) and times (2.84 s) while maintaining smooth and comfortable acceleration patterns. In dense roundabout environments the planner further demonstrates robust adaptability, producing larger safety margins, lower jerk, and superior curvature smoothness compared with APF, MPC, and RRT based baselines. These results confirm that the integrated DRF with convex feasible space and constrained iLQR solver provides a balanced solution for safe, efficient, and comfortable trajectory generation in dynamic and interactive traffic scenarios."}
{"id": "2511.23256", "pdf": "https://arxiv.org/pdf/2511.23256", "abs": "https://arxiv.org/abs/2511.23256", "authors": ["Guozheng Sun", "Lei Wang", "Yanhao Wang", "Jie Wang", "Yimin Liu"], "title": "Robust HRRP Recognition under Interrupted Sampling Repeater Jamming using a Prior Jamming Information-Guided Network", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Radar automatic target recognition (RATR) based on high-resolution range profile (HRRP) has attracted increasing attention due to its ability to capture fine-grained structural features. However, recognizing targets under electronic countermeasures (ECM), especially the mainstream interrupted-sampling repeater jamming (ISRJ), remains a significant challenge, as HRRPs often suffer from serious feature distortion. To address this, we propose a robust HRRP recognition method guided by prior jamming information. Specifically, we introduce a point spread function (PSF) as prior information to model the HRRP distortion induced by ISRJ. Based on this, we design a recognition network that leverages this prior through a prior-guided feature interaction module and a hybrid loss function to enhance the model's discriminative capability. With the aid of prior information, the model can learn invariant features within distorted HRRP under different jamming parameters. Both the simulated and measured-data experiments demonstrate that our method consistently outperforms state-of-the-art approaches and exhibits stronger generalization capabilities when facing unseen jamming parameters."}
{"id": "2511.22847", "pdf": "https://arxiv.org/pdf/2511.22847", "abs": "https://arxiv.org/abs/2511.22847", "authors": ["Yuying Zhang", "Na Fan", "Haowen Zheng", "Junning Liang", "Zongliang Pan", "Qifeng Chen", "Ximin Lyu"], "title": "Threat-Aware UAV Dodging of Human-Thrown Projectiles with an RGB-D Camera", "categories": ["cs.RO"], "comment": null, "summary": "Uncrewed aerial vehicles (UAVs) performing tasks such as transportation and aerial photography are vulnerable to intentional projectile attacks from humans. Dodging such a sudden and fast projectile poses a significant challenge for UAVs, requiring ultra-low latency responses and agile maneuvers. Drawing inspiration from baseball, in which pitchers' body movements are analyzed to predict the ball's trajectory, we propose a novel real-time dodging system that leverages an RGB-D camera. Our approach integrates human pose estimation with depth information to predict the attacker's motion trajectory and the subsequent projectile trajectory. Additionally, we introduce an uncertainty-aware dodging strategy to enable the UAV to dodge incoming projectiles efficiently. Our perception system achieves high prediction accuracy and outperforms the baseline in effective distance and latency. The dodging strategy addresses temporal and spatial uncertainties to ensure UAV safety. Extensive real-world experiments demonstrate the framework's reliable dodging capabilities against sudden attacks and its outstanding robustness across diverse scenarios."}
{"id": "2511.23258", "pdf": "https://arxiv.org/pdf/2511.23258", "abs": "https://arxiv.org/abs/2511.23258", "authors": ["Yunpeng Qu", "Yazhou Sun", "Bingyu Hui", "Jian Wang"], "title": "Hierarchical Feature Integration for Multi-Signal Automatic Modulation Recognition", "categories": ["eess.SP"], "comment": "5 pages, 5 figures", "summary": "Automatic modulation recognition (AMR) is a crucial step in wireless communication systems, which identifies the modulation scheme from detected signals to provide key information for further processing. However, previous work has mainly focused on the identification of a single signal, overlooking the phenomenon of multiple signal superposition in practical channels and the signal detection procedures that must be conducted beforehand. Considering the susceptibility of radio frequency (RF) signals to noise interference and significant spectral variations, we propose a novel Hierarchical Feature Integration (HIFI)-YOLO framework for multi-signal joint detection and modulation recognition. Our HIFI-YOLO framework, with its unique design of hierarchical feature integration, effectively enhances the representation capability of features in different modules, thereby improving detection performance. We construct a large-scale AMR dataset specifically tailored for scenarios of the coexistence or overlapping of multiple signals transmitted through channels with realistic propagation conditions, consisting of diverse digital and analog modulation schemes. Extensive experiments on our dataset demonstrate the excellent performance of HIFI-YOLO in multi-signal detection and modulation recognition as a joint approach."}
{"id": "2511.22860", "pdf": "https://arxiv.org/pdf/2511.22860", "abs": "https://arxiv.org/abs/2511.22860", "authors": ["Sacchin Sundar", "Atman Kikani", "Aaliya Alam", "Sumukh Shrote", "A. Nayeemulla Khan", "A. Shahina"], "title": "MARVO: Marine-Adaptive Radiance-aware Visual Odometry", "categories": ["cs.RO", "cs.CV"], "comment": "10 pages, 5 figures, 3 tables, Submitted to CVPR2026", "summary": "Underwater visual localization remains challenging due to wavelength-dependent attenuation, poor texture, and non-Gaussian sensor noise. We introduce MARVO, a physics-aware, learning-integrated odometry framework that fuses underwater image formation modeling, differentiable matching, and reinforcement-learning optimization. At the front-end, we extend transformer-based feature matcher with a Physics Aware Radiance Adapter that compensates for color channel attenuation and contrast loss, yielding geometrically consistent feature correspondences under turbidity. These semi dense matches are combined with inertial and pressure measurements inside a factor-graph backend, where we formulate a keyframe-based visual-inertial-barometric estimator using GTSAM library. Each keyframe introduces (i) Pre-integrated IMU motion factors, (ii) MARVO-derived visual pose factors, and (iii) barometric depth priors, giving a full-state MAP estimate in real time. Lastly, we introduce a Reinforcement-Learningbased Pose-Graph Optimizer that refines global trajectories beyond local minima of classical least-squares solvers by learning optimal retraction actions on SE(2)."}
{"id": "2511.23351", "pdf": "https://arxiv.org/pdf/2511.23351", "abs": "https://arxiv.org/abs/2511.23351", "authors": ["Daniele Gerosa", "Lauri Anttila", "Thomas Eriksson"], "title": "Compensation of correlated autoregressive clock jitter in arrays of Analog-to-Digital Converters", "categories": ["eess.SP"], "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "In modern communication systems, the fidelity of analog-to-digital converters (ADCs) is limited by sampling clock jitter, i.e., small random timing deviations that undermine ideal sampling. Traditional scalar models often treat jitter as independent Gaussian noise, which makes it essentially untrackable, whereas real ADCs also exhibit temporally correlated (spectrally colored) imperfections. Moreover, spatial cross-correlations between channels in multiple-input multiple-output (MIMO) ADCs are commonly neglected. This paper addresses the joint tracking and compensation of random, cross-correlated timing errors in ADC arrays by modeling jitter as a coupled vector autoregressive process of order one (VAR(1)). We propose a pilot-tone-based Kalman smoother to track and compensate the jitter, and simulations demonstrate substantial reductions in jitter-induced distortion across diverse scenarios."}
{"id": "2511.22865", "pdf": "https://arxiv.org/pdf/2511.22865", "abs": "https://arxiv.org/abs/2511.22865", "authors": ["Wonjeong Ryu", "Seungjun Yu", "Seokha Moon", "Hojun Choi", "Junsung Park", "Jinkyu Kim", "Hyunjung Shim"], "title": "SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "End-to-End (E2E) planning has become a powerful paradigm for autonomous driving, yet current systems remain fundamentally uncertainty-blind. They assume perception outputs are fully reliable, even in ambiguous or poorly observed scenes, leaving the planner without an explicit measure of uncertainty. To address this limitation, we propose a camera-only E2E framework that estimates aleatoric uncertainty directly in BEV space and incorporates it into planning. Our method produces a dense, uncertainty-aware drivability map that captures both semantic structure and geometric layout at pixel-level resolution. To further promote safe and rule-compliant behavior, we introduce a lane-following regularization that encodes lane structure and traffic norms. This prior stabilizes trajectory planning under normal conditions while preserving the flexibility needed for maneuvers such as overtaking or lane changes. Together, these components enable robust and interpretable trajectory planning, even under challenging uncertainty conditions. Evaluated on the NAVSIM benchmark, our method achieves state-of-the-art performance, delivering substantial gains on both the challenging NAVHARD and NAVSAFE subsets. These results demonstrate that our principled aleatoric uncertainty modeling combined with driving priors significantly advances the safety and reliability of camera-only E2E autonomous driving."}
{"id": "2511.23357", "pdf": "https://arxiv.org/pdf/2511.23357", "abs": "https://arxiv.org/abs/2511.23357", "authors": ["Sergi Liesegang", "Stefano Buzzi"], "title": "EMF-Compliant Power Control in Cell-Free Massive MIMO: Model-Based and Data-Driven Approaches", "categories": ["eess.SP", "cs.IT"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The impressive growth of wireless data networks has recently led to increased attention to the issue of electromagnetic pollution and the fulfillment of electromagnetic field (EMF) exposure limits. This paper tackles the problem of power control in user-centric cell-free massive multiple-input-multiple-output (CF-mMIMO) systems under EMF constraints. Specifically, the power allocation maximizing the minimum data rate across users is derived for both the uplink and the downlink. To solve such optimization problems, two approaches are proposed, i.e., model-based and data-driven. The proposed model-based solutions for the downlink utilize successive convex optimization and the log-sum-exp approximation for the minimum of a discrete set, whereas ordinary techniques are employed for the uplink. With regard to data-driven solutions, solutions based on both end-to-end architectures and deep unfolding techniques are explored. Extensive numerical results confirm that the proposed model-based solutions effectively fulfill the EMF constraints while ensuring very good performance; moreover, the results show that the proposed data-driven approaches can tightly approximate the performance of model-based solutions but with much lower computational complexity."}
{"id": "2511.22928", "pdf": "https://arxiv.org/pdf/2511.22928", "abs": "https://arxiv.org/abs/2511.22928", "authors": ["Jiaxin Liu", "Xiangyu Yan", "Liang Peng", "Lei Yang", "Lingjun Zhang", "Yuechen Luo", "Yueming Tao", "Ashton Yu Xuan Tan", "Mu Li", "Lei Zhang", "Ziqi Zhan", "Sai Guo", "Hong Wang", "Jun Li"], "title": "Seeing before Observable: Potential Risk Reasoning in Autonomous Driving via Vision Language Models", "categories": ["cs.RO"], "comment": null, "summary": "Ensuring safety remains a key challenge for autonomous vehicles (AVs), especially in rare and complex scenarios. One critical but understudied aspect is the \\textbf{potential risk} situations, where the risk is \\textbf{not yet observable} but can be inferred from subtle precursors, such as anomalous behaviors or commonsense violations. Recognizing these precursors requires strong semantic understanding and reasoning capabilities, which are often absent in current AV systems due to the scarcity of such cases in existing driving or risk-centric datasets. Moreover, current autonomous driving accident datasets often lack annotations of the causal reasoning chains behind incidents, which are essential for identifying potential risks before they become observable. To address these gaps, we introduce PotentialRiskQA, a novel vision-language dataset designed for reasoning about potential risks prior to observation. Each sample is annotated with structured scene descriptions, semantic precursors, and inferred risk outcomes. Based on this dataset, we further propose PR-Reasoner, a vision-language-model-based framework tailored for onboard potential risk reasoning. Experimental results show that fine-tuning on PotentialRiskQA enables PR-Reasoner to significantly enhance its performance on the potential risk reasoning task compared to baseline VLMs. Together, our dataset and model provide a foundation for developing autonomous systems with improved foresight and proactive safety capabilities, moving toward more intelligent and resilient AVs."}
{"id": "2511.21833", "pdf": "https://arxiv.org/pdf/2511.21833", "abs": "https://arxiv.org/abs/2511.21833", "authors": ["Lijie Huang", "Jingyi Yin", "Jingke Zhang", "U-Wai Lok", "Ryan M. DeRuiter", "Kaipeng Ji", "Yanzhe Zhao", "Tao Wu", "James D. Krier", "Xiang-yang Zhu", "Andrew J. Bentall", "Andrew D. Rule", "Thomas D. Atwell", "Lilach O. Lerman", "Shigao Chen", "Chengwu Huang"], "title": "Effective Hyper-clutter Artifacts Suppression for Ultrafast Ultrasound Doppler Imaging", "categories": ["physics.med-ph", "eess.SP"], "comment": null, "summary": "Objective: Hyper-clutter artifacts (HCA), arising from strong tissue reflections or physiological motion, present persistent challenges in ultrafast ultrasound Doppler imaging, often obscuring surrounding small vessel flow signals, especially in fascial regions such as the renal capsule. This study proposes U-profile-based decluttering (UPBD), a robust and computationally efficient method that exploits singular value decomposition (SVD)-derived spatial singular vectors to suppress HCA in ultrafast Doppler imaging. Methods: UPBD analyzes intensity profile of each pixel along the singular-order dimension of the SVD-derived left singular vectors U. A pixel-wise clutter-energy ratio is computed to derive a spatially adaptive declutter weighting map, which is applied to the SVD-filtered flow signals. Results: UPBD was evaluated on multiple in vivo datasets. Quantitative assessments based on contrast-to-noise ratio (CNR) and contrast-to-tissue ratio (CTR) demonstrated significant improvements over conventional SVD filtering. For example, UPBD enhanced CTR from 7.3 dB to 21.7 dB in contrast-free pig kidney, 17.8 dB to 42.1 dB in contrast-enhanced pig kidney, 8.2 dB to 32.8 dB in human kidney, and -4.9 dB to 3.7 dB in 3D human liver. Conclusion: The proposed UPBD method effectively suppresses HCA while preserving blood flow signals with minimal extra computational cost and no need for extensive parameter tuning. Significance: UPBD serves as a lightweight, easily integrated post-processing method that enhances HCA suppression, enabling broader application of SVD-based ultrafast Doppler imaging."}
{"id": "2511.22963", "pdf": "https://arxiv.org/pdf/2511.22963", "abs": "https://arxiv.org/abs/2511.22963", "authors": ["Zhirui Liu", "Kaiyang Ji", "Ke Yang", "Jingyi Yu", "Ye Shi", "Jingya Wang"], "title": "Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary", "categories": ["cs.RO", "cs.AI"], "comment": "Project page: https://humanoidlla.github.io/", "summary": "Enabling humanoid robots to follow free-form language commands is critical for seamless human-robot interaction, collaborative task execution, and general-purpose embodied intelligence. While recent advances have improved low-level humanoid locomotion and robot manipulation, language-conditioned whole-body control remains a significant challenge. Existing methods are often limited to simple instructions and sacrifice either motion diversity or physical plausibility. To address this, we introduce Humanoid-LLA, a Large Language Action Model that maps expressive language commands to physically executable whole-body actions for humanoid robots. Our approach integrates three core components: a unified motion vocabulary that aligns human and humanoid motion primitives into a shared discrete space; a vocabulary-directed controller distilled from a privileged policy to ensure physical feasibility; and a physics-informed fine-tuning stage using reinforcement learning with dynamics-aware rewards to enhance robustness and stability. Extensive evaluations in simulation and on a real-world Unitree G1 humanoid show that Humanoid-LLA delivers strong language generalization while maintaining high physical fidelity, outperforming existing language-conditioned controllers in motion naturalness, stability, and execution success rate."}
{"id": "2511.21940", "pdf": "https://arxiv.org/pdf/2511.21940", "abs": "https://arxiv.org/abs/2511.21940", "authors": ["Kiran Nair", "Hubert Cecotti"], "title": "Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection", "categories": ["cs.LG", "eess.SP", "q-bio.NC"], "comment": "20 Pages, prepared for a Journal", "summary": "Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems."}
{"id": "2511.22996", "pdf": "https://arxiv.org/pdf/2511.22996", "abs": "https://arxiv.org/abs/2511.22996", "authors": ["Ke Chen"], "title": "Analytical Inverse Kinematic Solution for \"Moz1\" NonSRS 7-DOF Robot arm with novel arm angle", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents an analytical solution to the inverse kinematic problem(IKP) for the seven degree-of-freedom (7-DOF) Moz1 Robot Arm with offsets on wrist. We provide closed-form solutions with the novel arm angle . it allow fully self-motion and solve the problem of algorithmic singularities within the workspace. It also provides information on how the redundancy is resolved in a new arm angle representation where traditional SEW angle faied to be defined and how singularities are handled. The solution is simple, fast and exact, providing full solution space (i.e. all 16 solutions) per pose."}
{"id": "2511.21970", "pdf": "https://arxiv.org/pdf/2511.21970", "abs": "https://arxiv.org/abs/2511.21970", "authors": ["Houbo He", "Yizhou Xu", "Lei Xia", "Yaolong Hu", "Fan Cai", "Taiyun Chi"], "title": "MOTIF-RF: Multi-template On-chip Transformer Synthesis Incorporating Frequency-domain Self-transfer Learning for RFIC Design Automation", "categories": ["cs.LG", "eess.SP"], "comment": "Accepted at ASP-DAC 2026", "summary": "This paper presents a systematic study on developing multi-template machine learning (ML) surrogate models and applying them to the inverse design of transformers (XFMRs) in radio-frequency integrated circuits (RFICs). Our study starts with benchmarking four widely used ML architectures, including MLP-, CNN-, UNet-, and GT-based models, using the same datasets across different XFMR topologies. To improve modeling accuracy beyond these baselines, we then propose a new frequency-domain self-transfer learning technique that exploits correlations between adjacent frequency bands, leading to around 30%-50% accuracy improvement in the S-parameters prediction. Building on these models, we further develop an inverse design framework based on the covariance matrix adaptation evolutionary strategy (CMA-ES) algorithm. This framework is validated using multiple impedance-matching tasks, all demonstrating fast convergence and trustworthy performance. These results advance the goal of AI-assisted specs-to-GDS automation for RFICs and provide RFIC designers with actionable tools for integrating AI into their workflows."}
{"id": "2511.23017", "pdf": "https://arxiv.org/pdf/2511.23017", "abs": "https://arxiv.org/abs/2511.23017", "authors": ["Elham Ahmadi", "Alireza Olama", "Petri Välisuo", "Heidi Kuusniemi"], "title": "Adaptive Factor Graph-Based Tightly Coupled GNSS/IMU Fusion for Robust Positionin", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Reliable positioning in GNSS-challenged environments remains a critical challenge for navigation systems. Tightly coupled GNSS/IMU fusion improves robustness but remains vulnerable to non-Gaussian noise and outliers. We present a robust and adaptive factor graph-based fusion framework that directly integrates GNSS pseudorange measurements with IMU preintegration factors and incorporates the Barron loss, a general robust loss function that unifies several m-estimators through a single tunable parameter. By adaptively down weighting unreliable GNSS measurements, our approach improves resilience positioning. The method is implemented in an extended GTSAM framework and evaluated on the UrbanNav dataset. The proposed solution reduces positioning errors by up to 41% relative to standard FGO, and achieves even larger improvements over extended Kalman filter (EKF) baselines in urban canyon environments. These results highlight the benefits of Barron loss in enhancing the resilience of GNSS/IMU-based navigation in urban and signal-compromised environments."}
{"id": "2511.21985", "pdf": "https://arxiv.org/pdf/2511.21985", "abs": "https://arxiv.org/abs/2511.21985", "authors": ["Alif Ilham Madani", "Riska A. Kuswati", "Alex M. Lechner", "Muhamad Risqi U. Saputra"], "title": "Digital Elevation Model Estimation from RGB Satellite Imagery using Generative Deep Learning", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "comment": "5 pages, 4 figures, accepted at IGARSS 2025 conference", "summary": "Digital Elevation Models (DEMs) are vital datasets for geospatial applications such as hydrological modeling and environmental monitoring. However, conventional methods to generate DEM, such as using LiDAR and photogrammetry, require specific types of data that are often inaccessible in resource-constrained settings. To alleviate this problem, this study proposes an approach to generate DEM from freely available RGB satellite imagery using generative deep learning, particularly based on a conditional Generative Adversarial Network (GAN). We first developed a global dataset consisting of 12K RGB-DEM pairs using Landsat satellite imagery and NASA's SRTM digital elevation data, both from the year 2000. A unique preprocessing pipeline was implemented to select high-quality, cloud-free regions and aggregate normalized RGB composites from Landsat imagery. Additionally, the model was trained in a two-stage process, where it was first trained on the complete dataset and then fine-tuned on high-quality samples filtered by Structural Similarity Index Measure (SSIM) values to improve performance on challenging terrains. The results demonstrate promising performance in mountainous regions, achieving an overall mean root-mean-square error (RMSE) of 0.4671 and a mean SSIM score of 0.2065 (scale -1 to 1), while highlighting limitations in lowland and residential areas. This study underscores the importance of meticulous preprocessing and iterative refinement in generative modeling for DEM generation, offering a cost-effective and adaptive alternative to conventional methods while emphasizing the challenge of generalization across diverse terrains worldwide."}
{"id": "2511.23030", "pdf": "https://arxiv.org/pdf/2511.23030", "abs": "https://arxiv.org/abs/2511.23030", "authors": ["Casimir Feldmann", "Maximum Wilder-Smith", "Vaishakh Patil", "Michael Oechsle", "Michael Niemeyer", "Keisuke Tateno", "Marco Hutter"], "title": "DiskChunGS: Large-Scale 3D Gaussian SLAM Through Chunk-Based Memory Management", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have demonstrated impressive results for novel view synthesis with real-time rendering capabilities. However, integrating 3DGS with SLAM systems faces a fundamental scalability limitation: methods are constrained by GPU memory capacity, restricting reconstruction to small-scale environments. We present DiskChunGS, a scalable 3DGS SLAM system that overcomes this bottleneck through an out-of-core approach that partitions scenes into spatial chunks and maintains only active regions in GPU memory while storing inactive areas on disk. Our architecture integrates seamlessly with existing SLAM frameworks for pose estimation and loop closure, enabling globally consistent reconstruction at scale. We validate DiskChunGS on indoor scenes (Replica, TUM-RGBD), urban driving scenarios (KITTI), and resource-constrained Nvidia Jetson platforms. Our method uniquely completes all 11 KITTI sequences without memory failures while achieving superior visual quality, demonstrating that algorithmic innovation can overcome the memory constraints that have limited previous 3DGS SLAM methods."}
{"id": "2511.22034", "pdf": "https://arxiv.org/pdf/2511.22034", "abs": "https://arxiv.org/abs/2511.22034", "authors": ["Batin Kurt", "Umut Orguner"], "title": "Performance of the Kalman Filter and Smoother for Benchmark Studies", "categories": ["eess.SY", "eess.SP"], "comment": null, "summary": "We propose analytical mean square error (MSE) expressions for the Kalman filter (KF) and the Kalman smoother (KS) for benchmark studies, where the true system dynamics are unknown or unavailable to the estimator. In such cases, as in benchmark evaluations for target tracking, the analysis relies on deterministic state trajectories. This setting introduces a model mismatch between the estimator and the system, causing the covariance estimates to no longer reflect the actual estimation errors. To enable accurate performance prediction for fixed state trajectories without relying on computationally intensive Monte Carlo simulations, we derive recursive MSE expressions with linear time complexity. The proposed framework also accounts for measurement model mismatch and provides an efficient tool for performance evaluation in benchmark studies with long trajectories. Simulation results confirm the accuracy and computational efficiency of the proposed method."}
{"id": "2511.23034", "pdf": "https://arxiv.org/pdf/2511.23034", "abs": "https://arxiv.org/abs/2511.23034", "authors": ["Zuolei Li", "Xingyu Gao", "Xiaofan Wang", "Jianlong Fu"], "title": "LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models", "categories": ["cs.RO"], "comment": "Project Page: https://mm-robot.github.io/distill_latent_action/", "summary": "Learning transferable latent actions from large-scale object manipulation videos can significantly enhance generalization in downstream robotics tasks, as such representations are agnostic to different robot embodiments. Existing approaches primarily rely on visual reconstruction objectives while neglecting physical priors, leading to sub-optimal performance in learning universal representations. To address these challenges, we propose a Universal Latent Action Learning framework that takes task instructions and multiple frames as inputs, and optimizes both future frame reconstruction and action sequence prediction. Unlike prior works, incorporating action predictions (e.g., gripper or hand trajectories and orientations) allows the model to capture richer physical priors such as real-world distances and orientations, thereby enabling seamless transferability to downstream tasks. We further decompose the latent actions into learnable motion and scene tokens to distinguish the robot's active movements from environmental changes, thus filtering out irrelevant dynamics. By distilling the learned latent actions into the latest VLA models, we achieve strong performance across both simulated (SIMPLER and LIBERO) and real-world robot settings. Notably, with only 10 real-world trajectories per task collected on a Franka robot, our approach successfully completes all five challenging tasks, demonstrating strong few-shot transferability in robotic manipulation."}
{"id": "2511.22096", "pdf": "https://arxiv.org/pdf/2511.22096", "abs": "https://arxiv.org/abs/2511.22096", "authors": ["Sandya Subramanian", "Bharath Ramsundar"], "title": "Density-based Neural Temporal Point Processes for Heartbeat Dynamics", "categories": ["q-bio.TO", "eess.SP", "stat.AP"], "comment": "9 pages, 4 figures, Presented as a Workshop Paper at TS4H@ICLR2024", "summary": "Temporal point processes (TPPs) provide a natural mathematical framework for modeling heartbeats due to capturing underlying physiological inductive biases. In this work, we apply density-based neural TPPs to model heartbeat dynamics from 18 subjects. We adapt a goodness-of-fit framework from classical point process literature to Neural TPPs and use it to optimize hyperparameters, identify appropriate training sequence lengths to capture temporal dependencies, and demonstrate zero-shot predictive capability on heartbeat data."}
{"id": "2511.23143", "pdf": "https://arxiv.org/pdf/2511.23143", "abs": "https://arxiv.org/abs/2511.23143", "authors": ["Enrico Saccon", "Davide De Martini", "Matteo Saveriano", "Edoardo Lamon", "Luigi Palopoli", "Marco Roveri"], "title": "Automated Generation of MDPs Using Logic Programming and LLMs for Robotic Applications", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, 11 figures, 2 tables, 2 algorithms, accepted for publication in IEEE Robotics and Automation Letters", "summary": "We present a novel framework that integrates Large Language Models (LLMs) with automated planning and formal verification to streamline the creation and use of Markov Decision Processes (MDP). Our system leverages LLMs to extract structured knowledge in the form of a Prolog knowledge base from natural language (NL) descriptions. It then automatically constructs an MDP through reachability analysis, and synthesises optimal policies using the Storm model checker. The resulting policy is exported as a state-action table for execution. We validate the framework in three human-robot interaction scenarios, demonstrating its ability to produce executable policies with minimal manual effort. This work highlights the potential of combining language models with formal methods to enable more accessible and scalable probabilistic planning in robotics."}
{"id": "2511.22293", "pdf": "https://arxiv.org/pdf/2511.22293", "abs": "https://arxiv.org/abs/2511.22293", "authors": ["Teysir Baoueb", "Xiaoyu Bie", "Mathieu Fontaine", "Gaël Richard"], "title": "GLA-Grad++: An Improved Griffin-Lim Guided Diffusion Model for Speech Synthesis", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "comment": null, "summary": "Recent advances in diffusion models have positioned them as powerful generative frameworks for speech synthesis, demonstrating substantial improvements in audio quality and stability. Nevertheless, their effectiveness in vocoders conditioned on mel spectrograms remains constrained, particularly when the conditioning diverges from the training distribution. The recently proposed GLA-Grad model introduced a phase-aware extension to the WaveGrad vocoder that integrated the Griffin-Lim algorithm (GLA) into the reverse process to reduce inconsistencies between generated signals and conditioning mel spectrogram. In this paper, we further improve GLA-Grad through an innovative choice in how to apply the correction. Particularly, we compute the correction term only once, with a single application of GLA, to accelerate the generation process. Experimental results demonstrate that our method consistently outperforms the baseline models, particularly in out-of-domain scenarios."}
{"id": "2511.23186", "pdf": "https://arxiv.org/pdf/2511.23186", "abs": "https://arxiv.org/abs/2511.23186", "authors": ["Runyu Jiao", "Matteo Bortolon", "Francesco Giuliari", "Alice Fasoli", "Sergio Povoli", "Guofeng Mei", "Yiming Wang", "Fabio Poiesi"], "title": "Obstruction reasoning for robotic grasping", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Successful robotic grasping in cluttered environments not only requires a model to visually ground a target object but also to reason about obstructions that must be cleared beforehand. While current vision-language embodied reasoning models show emergent spatial understanding, they remain limited in terms of obstruction reasoning and accessibility planning. To bridge this gap, we present UNOGrasp, a learning-based vision-language model capable of performing visually-grounded obstruction reasoning to infer the sequence of actions needed to unobstruct the path and grasp the target object. We devise a novel multi-step reasoning process based on obstruction paths originated by the target object. We anchor each reasoning step with obstruction-aware visual cues to incentivize reasoning capability. UNOGrasp combines supervised and reinforcement finetuning through verifiable reasoning rewards. Moreover, we construct UNOBench, a large-scale dataset for both training and benchmarking, based on MetaGraspNetV2, with over 100k obstruction paths annotated by humans with obstruction ratios, contact points, and natural-language instructions. Extensive experiments and real-robot evaluations show that UNOGrasp significantly improves obstruction reasoning and grasp success across both synthetic and real-world environments, outperforming generalist and proprietary alternatives. Project website: https://tev-fbk.github.io/UnoGrasp/."}
{"id": "2511.22920", "pdf": "https://arxiv.org/pdf/2511.22920", "abs": "https://arxiv.org/abs/2511.22920", "authors": ["Zheng Chang", "Siqi Zhang", "Wenqiang Huang", "Tian Tian", "Qichun Liu", "Tiefu Li", "Nan Qi", "Yuanjin Zheng", "Zhihua Wang", "Yanshu Guo", "Hanjun Jiang"], "title": "CO-QLink: Cryogenic Optical Link for Scalable Quantum Computing Systems and High-Performance Cryogenic Computing Systems", "categories": ["quant-ph", "eess.SP"], "comment": null, "summary": "Cryogenic systems necessitate extensive data transmission between room-temperature and cryogenic environments, as well as within the cryogenic temperature domain. High-speed, low-power data transmission is pivotal to enabling the deployment of larger-scale cryogenic systems, including the scalable quantum computing systems and the high-performance cryogenic computing systems fully immersed in liquid nitrogen. In contrast to wireline and microwave links, optical communication links are emerging as a solution characterized by high data rates, high energy efficiency, low signal attenuation, absence of thermal conduction, and superior scalability. In this work, a 4K heat-insulated high-speed (56Gbps) low-power (1.6pJ/b) transceiver (TRX) that achieves a complete link between 4K systems and room temperature (RT) equipment is presented. Copackaged with a PIN photodiode (PD), the RX uses an inverter-based analog front-end and an analog half-rate clock data recovery loop. Connecting to a Mach-Zehnder modulator (MZM), the TX contains a voltage-mode driver with current-mode injection for low-power output-swing-boosting and 3-tap feed-forward equalization (FFE). This link has been demonstrated in the control and readout of a complete superconducting quantum computing system."}
{"id": "2511.23193", "pdf": "https://arxiv.org/pdf/2511.23193", "abs": "https://arxiv.org/abs/2511.23193", "authors": ["Yuchen Shi", "Huaxin Pei", "Yi Zhang", "Danya Yao"], "title": "Fault-Tolerant MARL for CAVs under Observation Perturbations for Highway On-Ramp Merging", "categories": ["cs.RO", "cs.LG", "eess.SY"], "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) holds significant promise for enabling cooperative driving among Connected and Automated Vehicles (CAVs). However, its practical application is hindered by a critical limitation, i.e., insufficient fault tolerance against observational faults. Such faults, which appear as perturbations in the vehicles' perceived data, can substantially compromise the performance of MARL-based driving systems. Addressing this problem presents two primary challenges. One is to generate adversarial perturbations that effectively stress the policy during training, and the other is to equip vehicles with the capability to mitigate the impact of corrupted observations. To overcome the challenges, we propose a fault-tolerant MARL method for cooperative on-ramp vehicles incorporating two key agents. First, an adversarial fault injection agent is co-trained to generate perturbations that actively challenge and harden the vehicle policies. Second, we design a novel fault-tolerant vehicle agent equipped with a self-diagnosis capability, which leverages the inherent spatio-temporal correlations in vehicle state sequences to detect faults and reconstruct credible observations, thereby shielding the policy from misleading inputs. Experiments in a simulated highway merging scenario demonstrate that our method significantly outperforms baseline MARL approaches, achieving near-fault-free levels of safety and efficiency under various observation fault patterns."}
{"id": "2511.23243", "pdf": "https://arxiv.org/pdf/2511.23243", "abs": "https://arxiv.org/abs/2511.23243", "authors": ["Jonathan Ethier"], "title": "Heteroscedastic Neural Networks for Path Loss Prediction with Link-Specific Uncertainty", "categories": ["cs.LG", "eess.SP"], "comment": "Submitted to IEEE AWPL in December 2025. 5 pages, 2 figures, 4 tables", "summary": "Traditional and modern machine learning-based path loss models typically assume a constant prediction variance. We propose a neural network that jointly predicts the mean and link-specific variance by minimizing a Gaussian negative log-likelihood, enabling heteroscedastic uncertainty estimates. We compare shared, partially shared, and independent-parameter architectures using accuracy, calibration, and sharpness metrics on blind test sets from large public RF drive-test datasets. The shared-parameter architecture performs best, achieving an RMSE of 7.4 dB, 95.1 percent coverage for 95 percent prediction intervals, and a mean interval width of 29.6 dB. These uncertainty estimates further support link-specific coverage margins, improve RF planning and interference analyses, and provide effective self-diagnostics of model weaknesses."}
{"id": "2511.23215", "pdf": "https://arxiv.org/pdf/2511.23215", "abs": "https://arxiv.org/abs/2511.23215", "authors": ["Eduardo Sergio Oliveros-Mata", "Oleksandr V. Pylypovskyi", "Eleonora Raimondo", "Rico Illing", "Yevhen Zabila", "Lin Guo", "Guannan Mu", "Mónica Navarro López", "Xu Wang", "Georgios Tzortzinis", "Angelos Filippatos", "Gilbert Santiago Cañón Bermúdez", "Francesca Garescì", "Giovanni Finocchio", "Denys Makarov"], "title": "Field-programmable dynamics in a soft magnetic actuator enabling true random number generation and reservoir computing", "categories": ["cs.RO", "cond-mat.other", "cond-mat.str-el"], "comment": null, "summary": "Complex and even chaotic dynamics, though prevalent in many natural and engineered systems, has been largely avoided in the design of electromechanical systems due to concerns about wear and controlability. Here, we demonstrate that complex dynamics might be particularly advantageous in soft robotics, offering new functionalities beyond motion not easily achievable with traditional actuation methods. We designed and realized resilient magnetic soft actuators capable of operating in a tunable dynamic regime for tens of thousands cycles without fatigue. We experimentally demonstrated the application of these actuators for true random number generation and stochastic computing. {W}e validate soft robots as physical reservoirs capable of performing Mackey--Glass time series prediction. These findings show that exploring the complex dynamics in soft robotics would extend the application scenarios in soft computing, human-robot interaction and collaborative robots as we demonstrate with biomimetic blinking and randomized voice modulation."}
{"id": "2511.23347", "pdf": "https://arxiv.org/pdf/2511.23347", "abs": "https://arxiv.org/abs/2511.23347", "authors": ["Bowen Wang", "Matteo Zecchin", "Osvaldo Simeone"], "title": "Distributed Dynamic Associative Memory via Online Convex Optimization", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "An associative memory (AM) enables cue-response recall, and it has recently been recognized as a key mechanism underlying modern neural architectures such as Transformers. In this work, we introduce the concept of distributed dynamic associative memory (DDAM), which extends classical AM to settings with multiple agents and time-varying data streams. In DDAM, each agent maintains a local AM that must not only store its own associations but also selectively memorize information from other agents based on a specified interest matrix. To address this problem, we propose a novel tree-based distributed online gradient descent algorithm, termed DDAM-TOGD, which enables each agent to update its memory on the fly via inter-agent communication over designated routing trees. We derive rigorous performance guarantees for DDAM-TOGD, proving sublinear static regret in stationary environments and a path-length dependent dynamic regret bound in non-stationary environments. These theoretical results provide insights into how communication delays and network structure impact performance. Building on the regret analysis, we further introduce a combinatorial tree design strategy that optimizes the routing trees to minimize communication delays, thereby improving regret bounds. Numerical experiments demonstrate that the proposed DDAM-TOGD framework achieves superior accuracy and robustness compared to representative online learning baselines such as consensus-based distributed optimization, confirming the benefits of the proposed approach in dynamic, distributed environments."}
{"id": "2511.23236", "pdf": "https://arxiv.org/pdf/2511.23236", "abs": "https://arxiv.org/abs/2511.23236", "authors": ["Alex Richardson", "Azhar Hasan", "Gabor Karsai", "Jonathan Sprinkle"], "title": "Incorporating Ephemeral Traffic Waves in A Data-Driven Framework for Microsimulation in CARLA", "categories": ["cs.RO", "cs.ET"], "comment": "Submitted to IEEE IV 2026", "summary": "This paper introduces a data-driven traffic microsimulation framework in CARLA that reconstructs real-world wave dynamics using high-fidelity time-space data from the I-24 MOTION testbed. Calibration of road networks in microsimulators to reproduce ephemeral phenomena such as traffic waves for large-scale simulation is a process that is fraught with challenges. This work reconsiders the existence of the traffic state data as boundary conditions on an ego vehicle moving through previously recorded traffic data, rather than reproducing those traffic phenomena in a calibrated microsim. Our approach is to autogenerate a 1 mile highway segment corresponding to I-24, and use the I-24 data to power a cosimulation module that injects traffic information into the simulation. The CARLA and cosimulation simulations are centered around an ego vehicle sampled from the empirical data, with autogeneration of \"visible\" traffic within the longitudinal range of the ego vehicle. Boundary control beyond these visible ranges is achieved using ghost cells behind (upstream) and ahead (downstream) of the ego vehicle. Unlike prior simulation work that focuses on local car-following behavior or abstract geometries, our framework targets full time-space diagram fidelity as the validation objective. Leveraging CARLA's rich sensor suite and configurable vehicle dynamics, we simulate wave formation and dissipation in both low-congestion and high-congestion scenarios for qualitative analysis. The resulting emergent behavior closely mirrors that of real traffic, providing a novel cosimulation framework for evaluating traffic control strategies, perception-driven autonomy, and future deployment of wave mitigation solutions. Our work bridges microscopic modeling with physical experimental data, enabling the first perceptually realistic, boundary-driven simulation of empirical traffic wave phenomena in CARLA."}
{"id": "2511.23406", "pdf": "https://arxiv.org/pdf/2511.23406", "abs": "https://arxiv.org/abs/2511.23406", "authors": ["Mohamed Nomeir", "Alptug Aytekin", "Lei Hu", "Sennur Ulukus"], "title": "Quantum Private Distributed Matrix Multiplication With Degree Tables", "categories": ["cs.IT", "cs.CR", "cs.NI", "eess.SP", "quant-ph"], "comment": "The abstract here is trimmed due to the space limitations in the submission process", "summary": "In this paper, we explore how quantum resources can be used to increase the rate of private distributed matrix multiplication (PDMM). In PDMM, a user who has two high-dimensional matrices, $A$ and $B$, and lacks the computational capabilities to apply matrix multiplication locally, divides the matrices $A$ and $B$ into $K$ and $L$ sub-blocks, respectively. Then, the user sends them to $N$ servers to apply the required multiplication privately from any $T$ servers. The goal is to reduce the number of servers needed to perform the required matrix multiplication. In the quantum setting, we allow the servers to share an entangled state and respond over quantum channels. Upon receiving the qudits, the user applies measurements to obtain the required multiplication. There are two main regimes in the PDMM literature: The high-privacy regime and the low-privacy regime where $T$ is less than $K$ and $L$.\n  First, in the high-privacy regime, the state-of-the-art classical code is called the gap additive secure polynomial (GASP) code. We define a feasibility requirement in the quantum setting for the GASP code such that the highest performance is achieved when it is satisfied. When it is not satisfied, we address two main concerns. The first is to find a relation between the minimum privacy requirement and the dimensions of the two matrices needed for the feasibility condition to be satisfied. Second, we develop a new family of codes that can work in the quantum setting.\n  Second, since GASP does not work efficiently in the low-privacy regimes compared to cyclic-addition degree tables (CAT) and discretely optimized GASP (DOG), we show that the feasibility condition developed for GASP can be adopted for both CAT and DOG codes as well. In addition, we propose another set of codes that can be used in the low privacy regime in the quantum setting when the feasibility requirement is not satisfied."}
{"id": "2511.23300", "pdf": "https://arxiv.org/pdf/2511.23300", "abs": "https://arxiv.org/abs/2511.23300", "authors": ["Yara Mahmoud", "Jeffrin Sam", "Nguyen Khang", "Marcelino Fernando", "Issatay Tokmurziyev", "Miguel Altamirano Cabrera", "Muhammad Haris Khan", "Artem Lykov", "Dzmitry Tsetserukou"], "title": "SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot", "categories": ["cs.RO"], "comment": null, "summary": "Safe and trustworthy Human Robot Interaction (HRI) requires robots not only to complete tasks but also to regulate impedance and speed according to scene context and human proximity. We present SafeHumanoid, an egocentric vision pipeline that links Vision Language Models (VLMs) with Retrieval-Augmented Generation (RAG) to schedule impedance and velocity parameters for a humanoid robot. Egocentric frames are processed by a structured VLM prompt, embedded and matched against a curated database of validated scenarios, and mapped to joint-level impedance commands via inverse kinematics. We evaluate the system on tabletop manipulation tasks with and without human presence, including wiping, object handovers, and liquid pouring. The results show that the pipeline adapts stiffness, damping, and speed profiles in a context-aware manner, maintaining task success while improving safety. Although current inference latency (up to 1.4 s) limits responsiveness in highly dynamic settings, SafeHumanoid demonstrates that semantic grounding of impedance control is a viable path toward safer, standard-compliant humanoid collaboration."}
{"id": "2511.23372", "pdf": "https://arxiv.org/pdf/2511.23372", "abs": "https://arxiv.org/abs/2511.23372", "authors": ["Kanhaiya Lal Chaurasiya", "Ruchira Kumar Pradhan", "Yashaswi Sinha", "Shivam Gupta", "Ujjain Kumar Bidila", "Digambar Killedar", "Kapil Das Sahu", "Bishakh Bhattacharya"], "title": "Design, modelling and experimental validation of bipenniform shape memory alloy-based linear actuator integrable with hydraulic stroke amplification mechanism", "categories": ["cs.RO"], "comment": null, "summary": "The increasing industrial demand for alternative actuators over conventional electromagnetism-based systems having limited efficiency, bulky size, complex design due to in-built gear-train mechanisms, and high production and amortization costs necessitates the innovation in new actuator development. Integrating bio-inspired design principles into linear actuators could bring forth the next generation of adaptive and energy efficient smart material-based actuation systems. The present study amalgamates the advantages of bipenniform architecture, which generates high force in the given physiological region and a high power-to-weight ratio of shape memory alloy (SMA), into a novel bio-inspired SMA-based linear actuator. A mathematical model of a multi-layered bipenniform configuration-based SMA actuator was developed and validated experimentally. The current research also caters to the incorporation of failure mitigation strategies using design failure mode and effects analysis along with the experimental assessment of the performance of the developed actuator. The system has been benchmarked against an industry-developed stepper motor-driven actuator. It has shown promising results generating an actuation force of 257 N with 15 V input voltage, meeting the acceptable range for actuation operation. It further exhibits about 67% reduction in the weight of the drive mechanism, with 80% lesser component, 32% cost reduction, and 19% energy savings and similar envelope dimensions for assembly compatibility with dampers and louvers for easy onsite deployment. The study introduces SMA coil-based actuator as an advanced design that can be deployed for high force-high stroke applications. The bio-inspired SMA-based linear actuator has applications ranging from building automation controls to lightweight actuation systems for space robotics and medical prosthesis."}
{"id": "2511.23407", "pdf": "https://arxiv.org/pdf/2511.23407", "abs": "https://arxiv.org/abs/2511.23407", "authors": ["Jan Baumgärtner", "Malte Hansjosten", "David Hald", "Adrian Hauptmannl", "Alexander Puchta", "Jürgen Fleischer"], "title": "From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products", "categories": ["cs.RO"], "comment": null, "summary": "To support the circular economy, robotic systems must not only assemble new products but also disassemble end-of-life (EOL) ones for reuse, recycling, or safe disposal. Existing approaches to disassembly sequence planning often assume deterministic and fully observable product models, yet real EOL products frequently deviate from their initial designs due to wear, corrosion, or undocumented repairs. We argue that disassembly should therefore be formulated as a Partially Observable Markov Decision Process (POMDP), which naturally captures uncertainty about the product's internal state. We present a mathematical formulation of disassembly as a POMDP, in which hidden variables represent uncertain structural or physical properties. Building on this formulation, we propose a task and motion planning framework that automatically derives specific POMDP models from CAD data, robot capabilities, and inspection results. To obtain tractable policies, we approximate this formulation with a reinforcement-learning approach that operates on stochastic action outcomes informed by inspection priors, while a Bayesian filter continuously maintains beliefs over latent EOL conditions during execution. Using three products on two robotic systems, we demonstrate that this probabilistic planning framework outperforms deterministic baselines in terms of average disassembly time and variance, generalizes across different robot setups, and successfully adapts to deviations from the CAD model, such as missing or stuck parts."}
{"id": "2511.19221", "pdf": "https://arxiv.org/pdf/2511.19221", "abs": "https://arxiv.org/abs/2511.19221", "authors": ["Jianhua Han", "Meng Tian", "Jiangtong Zhu", "Fan He", "Huixin Zhang", "Sitong Guo", "Dechang Zhu", "Hao Tang", "Pei Xu", "Yuze Guo", "Minzhe Niu", "Haojie Zhu", "Qichao Dong", "Xuechao Yan", "Siyuan Dong", "Lu Hou", "Qingqiu Huang", "Xiaosong Jia", "Hang Xu"], "title": "Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Autonomous driving heavily relies on accurate and robust spatial perception. Many failures arise from inaccuracies and instability, especially in long-tail scenarios and complex interactions. However, current vision-language models are weak at spatial grounding and understanding, and VLA systems built on them therefore show limited perception and localization ability. To address these challenges, we introduce Percept-WAM, a perception-enhanced World-Awareness-Action Model that is the first to implicitly integrate 2D/3D scene understanding abilities within a single vision-language model (VLM). Instead of relying on QA-style spatial reasoning, Percept-WAM unifies 2D/3D perception tasks into World-PV and World-BEV tokens, which encode both spatial coordinates and confidence. We propose a grid-conditioned prediction mechanism for dense object perception, incorporating IoU-aware scoring and parallel autoregressive decoding, improving stability in long-tail, far-range, and small-object scenarios. Additionally, Percept-WAM leverages pretrained VLM parameters to retain general intelligence (e.g., logical reasoning) and can output perception results and trajectory control outputs directly. Experiments show that Percept-WAM matches or surpasses classical detectors and segmenters on downstream perception benchmarks, achieving 51.7/58.9 mAP on COCO 2D detection and nuScenes BEV 3D detection. When integrated with trajectory decoders, it further improves planning performance on nuScenes and NAVSIM, e.g., surpassing DiffusionDrive by 2.1 in PMDS on NAVSIM. Qualitative results further highlight its strong open-vocabulary and long-tail generalization."}
{"id": "2511.21750", "pdf": "https://arxiv.org/pdf/2511.21750", "abs": "https://arxiv.org/abs/2511.21750", "authors": ["Di Feng", "Kaixin Ma", "Feng Nan", "Haofeng Chen", "Bohan Zhai", "David Griffiths", "Mingfei Gao", "Zhe Gan", "Eshan Verma", "Yinfei Yang", "Zhifeng Chen", "Afshin Dehghan"], "title": "SO-Bench: A Structural Output Evaluation of Multimodal LLMs", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly deployed in real-world, agentic settings where outputs must not only be correct, but also conform to predefined data schemas. Despite recent progress in structured generation in textual domain, there is still no benchmark that systematically evaluates schema-grounded information extraction and reasoning over visual inputs. In this work, we conduct a comprehensive study of visual structural output capabilities for MLLMs with our carefully designed SO-Bench benchmark. Covering four visual domains, including UI screens, natural images, documents, and charts, SO-Bench is built from over 6.5K diverse JSON schemas and 1.8K curated image-schema pairs with human-verified quality. Benchmarking experiments on open-sourced and frontier proprietary models reveal persistent gaps in predicting accurate, schema compliant outputs, highlighting the need for better multimodal structured reasoning. Beyond benchmarking, we further conduct training experiments to largely improve the model's structured output capability. We plan to make the benchmark available to the community."}
{"id": "2511.21848", "pdf": "https://arxiv.org/pdf/2511.21848", "abs": "https://arxiv.org/abs/2511.21848", "authors": ["Eric Leonardis", "Akira Nagamori", "Ayesha Thanawalla", "Yuanjia Yang", "Joshua Park", "Hutton Saunders", "Eiman Azim", "Talmo Pereira"], "title": "Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics", "categories": ["cs.LG", "cs.RO", "q-bio.NC", "q-bio.QM"], "comment": "Accepted at NeurIPS 2025 Workshop Data on the Brain & Mind: Concrete Applications of AI to Neuroscience and Cognitive Science. 12 pages, 4 figures", "summary": "The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control."}
{"id": "2511.22134", "pdf": "https://arxiv.org/pdf/2511.22134", "abs": "https://arxiv.org/abs/2511.22134", "authors": ["Zhen Fang", "Zhuoyang Liu", "Jiaming Liu", "Hao Chen", "Yu Zeng", "Shiting Huang", "Zehui Chen", "Lin Chen", "Shanghang Zhang", "Feng Zhao"], "title": "DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "To build a generalizable Vision-Language-Action (VLA) model with strong reasoning ability, a common strategy is to first train a specialist VLA on robot demonstrations to acquire reliable manipulation skills, and then incorporate mixed annotated robot data together with multimodal data to restore broader reasoning capabilities. However, we observe that the resulting reasoning VLA often suffers from degraded action performance compared to the specialist model before fine-tuning, a phenomenon we refer to as action degeneration. To address this issue, we propose DualVLA, which enhances action performance through carefully designed post-training while still preserving reasoning capability. We first introduce a dual-layer data pruning method that removes redundant embodied reasoning, preventing it from adversely influencing action learning. To further strengthen action generation, we design a dual-teacher adaptive distillation strategy that assigns different supervision signals to different data domains while maintaining reasoning ability. To fill the evaluation gap for generalist VLAs, we also propose VLA Score, which decouples VLA capability into reasoning, intention, action, and alignment dimensions for a more fine-grained assessment. Experiments show that DualVLA achieves an average success rate of 61.0 in SimplerEnv and an average score of 65.4 across eight competitive multimodal benchmarks, demonstrating a stronger balance between precise action execution and multimodal understanding. Project Website: https://costaliya.github.io/DualVLA/."}
{"id": "2511.22155", "pdf": "https://arxiv.org/pdf/2511.22155", "abs": "https://arxiv.org/abs/2511.22155", "authors": ["Bernd J. Kröger"], "title": "Lips-Jaw and Tongue-Jaw Articulatory Tradeoff in DYNARTmo", "categories": ["cs.CL", "cs.RO"], "comment": "12 pages, 3 figures, supplementary material: python code", "summary": "This paper investigates how the dynamic articulatory model DYNARTmo accounts for articulatory tradeoffs between primary and secondary articulators, with a focus on lips-jaw and tongue-jaw coordination. While DYNARTmo does not implement full task-dynamic second-order biomechanics, it adopts first-order task-space gesture specifications comparable to those used in articulatory phonology and integrates a simplified mechanism for distributing articulatory effort across multiple articulators. We first outline the conceptual relationship between task dynamics and DYNARTmo, emphasizing the distinction between high-level task-space trajectories and their low-level articulatory execution. We then present simulation results for a set of CV syllables that illustrate how jaw displacement varies as a function of both place of articulation (labial, apical, dorsal) and vowel context (/a/, /i/, /u/). The model reproduces empirically attested patterns of articulatory synergy, including jaw-supported apical closures, lower-lip elevation in bilabial stops, tongue-jaw co-movement, and saturation effects in labial constrictions. These results demonstrate that even with computationally simplified assumptions, DYNARTmo can generate realistic spatio-temporal movement patterns that capture key aspects of articulatory tradeoff and synergy across a range of consonant-vowel combinations."}
{"id": "2511.22181", "pdf": "https://arxiv.org/pdf/2511.22181", "abs": "https://arxiv.org/abs/2511.22181", "authors": ["Maitrayee Keskar", "Mohan Trivedi", "Ross Greer"], "title": "MTR-VP: Towards End-to-End Trajectory Planning through Context-Driven Image Encoding and Multiple Trajectory Prediction", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "8 pages, 3 figures, 4 tables", "summary": "We present a method for trajectory planning for autonomous driving, learning image-based context embeddings that align with motion prediction frameworks and planning-based intention input. Within our method, a ViT encoder takes raw images and past kinematic state as input and is trained to produce context embeddings, drawing inspiration from those generated by the recent MTR (Motion Transformer) encoder, effectively substituting map-based features with learned visual representations. MTR provides a strong foundation for multimodal trajectory prediction by localizing agent intent and refining motion iteratively via motion query pairs; we name our approach MTR-VP (Motion Transformer for Vision-based Planning), and instead of the learnable intention queries used in the MTR decoder, we use cross attention on the intent and the context embeddings, which reflect a combination of information encoded from the driving scene and past vehicle states. We evaluate our methods on the Waymo End-to-End Driving Dataset, which requires predicting the agent's future 5-second trajectory in bird's-eye-view coordinates using prior camera images, agent pose history, and routing goals. We analyze our architecture using ablation studies, removing input images and multiple trajectory output. Our results suggest that transformer-based methods that are used to combine the visual features along with the kinetic features such as the past trajectory features are not effective at combining both modes to produce useful scene context embeddings, even when intention embeddings are augmented with foundation-model representations of scene context from CLIP and DINOv2, but that predicting a distribution over multiple futures instead of a single future trajectory boosts planning performance."}
{"id": "2511.22187", "pdf": "https://arxiv.org/pdf/2511.22187", "abs": "https://arxiv.org/abs/2511.22187", "authors": ["Qiang Li", "Yingwenqi Jiang", "Tuoxi Li", "Duyu Chen", "Xiang Feng", "Yucheng Ao", "Shangyue Liu", "Xingchen Yu", "Youcheng Cai", "Yumeng Liu", "Yuexin Ma", "Xin Hu", "Li Liu", "Yu Zhang", "Linkun Xu", "Bingtao Gao", "Xueyuan Wang", "Shuchang Zhou", "Xianming Liu", "Ligang Liu"], "title": "HybridWorldSim: A Scalable and Controllable High-fidelity Simulator for Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Realistic and controllable simulation is critical for advancing end-to-end autonomous driving, yet existing approaches often struggle to support novel view synthesis under large viewpoint changes or to ensure geometric consistency. We introduce HybridWorldSim, a hybrid simulation framework that integrates multi-traversal neural reconstruction for static backgrounds with generative modeling for dynamic agents. This unified design addresses key limitations of previous methods, enabling the creation of diverse and high-fidelity driving scenarios with reliable visual and spatial consistency. To facilitate robust benchmarking, we further release a new multi-traversal dataset MIRROR that captures a wide range of routes and environmental conditions across different cities. Extensive experiments demonstrate that HybridWorldSim surpasses previous state-of-the-art methods, providing a practical and scalable solution for high-fidelity simulation and a valuable resource for research and development in autonomous driving."}
{"id": "2511.22210", "pdf": "https://arxiv.org/pdf/2511.22210", "abs": "https://arxiv.org/abs/2511.22210", "authors": ["Junsung Park"], "title": "BiCQL-ML: A Bi-Level Conservative Q-Learning Framework for Maximum Likelihood Inverse Reinforcement Learning", "categories": ["cs.LG", "cs.RO"], "comment": "8 pages, 3 figures", "summary": "Offline inverse reinforcement learning (IRL) aims to recover a reward function that explains expert behavior using only fixed demonstration data, without any additional online interaction. We propose BiCQL-ML, a policy-free offline IRL algorithm that jointly optimizes a reward function and a conservative Q-function in a bi-level framework, thereby avoiding explicit policy learning. The method alternates between (i) learning a conservative Q-function via Conservative Q-Learning (CQL) under the current reward, and (ii) updating the reward parameters to maximize the expected Q-values of expert actions while suppressing over-generalization to out-of-distribution actions. This procedure can be viewed as maximum likelihood estimation under a soft value matching principle. We provide theoretical guarantees that BiCQL-ML converges to a reward function under which the expert policy is soft-optimal. Empirically, we show on standard offline RL benchmarks that BiCQL-ML improves both reward recovery and downstream policy performance compared to existing offline IRL baselines."}
{"id": "2511.22467", "pdf": "https://arxiv.org/pdf/2511.22467", "abs": "https://arxiv.org/abs/2511.22467", "authors": ["François Provost", "Faisal Hawlader", "Mehdi Testouri", "Raphaël Frank"], "title": "Motion-to-Motion Latency Measurement Framework for Connected and Autonomous Vehicle Teleoperation", "categories": ["cs.PF", "cs.RO"], "comment": null, "summary": "Latency is a key performance factor for the teleoperation of Connected and Autonomous Vehicles (CAVs). It affects how quickly an operator can perceive changes in the driving environment and apply corrective actions. Most existing work focuses on Glass-to-Glass (G2G) latency, which captures delays only in the video pipeline. However, there is no standard method for measuring Motion-to-Motion (M2M) latency, defined as the delay between the physical steering movement of the remote operator and the corresponding steering motion in the vehicle. This paper presents an M2M latency measurement framework that uses Hall-effect sensors and two synchronized Raspberry Pi~5 devices. The system records interrupt-based timestamps on both sides to estimate M2M latency, independently of the underlying teleoperation architecture. Precision tests show an accuracy of 10--15~ms, while field results indicate that actuator delays dominate M2M latency, with median values above 750~ms."}
{"id": "2511.22609", "pdf": "https://arxiv.org/pdf/2511.22609", "abs": "https://arxiv.org/abs/2511.22609", "authors": ["Bo Wang", "Jiehong Lin", "Chenzhi Liu", "Xinting Hu", "Yifei Yu", "Tianjia Liu", "Zhongrui Wang", "Xiaojuan Qi"], "title": "MG-Nav: Dual-Scale Visual Navigation via Sparse Spatial Memory", "categories": ["cs.CV", "cs.RO"], "comment": "10pages, 5 figures", "summary": "We present MG-Nav (Memory-Guided Navigation), a dual-scale framework for zero-shot visual navigation that unifies global memory-guided planning with local geometry-enhanced control. At its core is the Sparse Spatial Memory Graph (SMG), a compact, region-centric memory where each node aggregates multi-view keyframe and object semantics, capturing both appearance and spatial structure while preserving viewpoint diversity. At the global level, the agent is localized on SMG and a goal-conditioned node path is planned via an image-to-instance hybrid retrieval, producing a sequence of reachable waypoints for long-horizon guidance. At the local level, a navigation foundation policy executes these waypoints in point-goal mode with obstacle-aware control, and switches to image-goal mode when navigating from the final node towards the visual target. To further enhance viewpoint alignment and goal recognition, we introduce VGGT-adapter, a lightweight geometric module built on the pre-trained VGGT model, which aligns observation and goal features in a shared 3D-aware space. MG-Nav operates global planning and local control at different frequencies, using periodic re-localization to correct errors. Experiments on HM3D Instance-Image-Goal and MP3D Image-Goal benchmarks demonstrate that MG-Nav achieves state-of-the-art zero-shot performance and remains robust under dynamic rearrangements and unseen scene conditions."}
{"id": "2511.22810", "pdf": "https://arxiv.org/pdf/2511.22810", "abs": "https://arxiv.org/abs/2511.22810", "authors": ["Dongjae Lee", "Dimos V. Dimarogonas", "H. Jin Kim"], "title": "Switching control of underactuated multi-channel systems with input constraints for cooperative manipulation", "categories": ["eess.SY", "cs.RO"], "comment": "14 pages", "summary": "This work presents an event-triggered switching control framework for a class of nonlinear underactuated multi-channel systems with input constraints. These systems are inspired by cooperative manipulation tasks involving underactuation, where multiple underactuated agents collaboratively push or pull an object to a target pose. Unlike existing approaches for multi-channel systems, our method addresses underactuation and the potential loss of controllability by additionally addressing channel assignment of agents. To simultaneously account for channel assignment, input constraints, and stabilization, we formulate the control problem as a Mixed Integer Linear Programming and derive sufficient conditions for its feasibility. To improve real-time computation efficiency, we introduce an event-triggered control scheme that maintains stability even between switching events through a quadratic programming-based stabilizing controller. We theoretically establish the semi-global exponential stability of the proposed method and the asymptotic stability of its extension to nonprehensile cooperative manipulation under noninstantaneous switching. The proposed framework is further validated through numerical simulations on 2D and 3D free-flyer systems and multi-robot nonprehensile pushing tasks."}
{"id": "2511.22950", "pdf": "https://arxiv.org/pdf/2511.22950", "abs": "https://arxiv.org/abs/2511.22950", "authors": ["Haiyang Mei", "Qiming Huang", "Hai Ci", "Mike Zheng Shou"], "title": "RobotSeg: A Model and Dataset for Segmenting Robots in Image and Video", "categories": ["cs.CV", "cs.RO"], "comment": "Project page: https://github.com/showlab/RobotSeg", "summary": "Accurate robot segmentation is a fundamental capability for robotic perception. It enables precise visual servoing for VLA systems, scalable robot-centric data augmentation, accurate real-to-sim transfer, and reliable safety monitoring in dynamic human-robot environments. Despite the strong capabilities of modern segmentation models, surprisingly it remains challenging to segment robots. This is due to robot embodiment diversity, appearance ambiguity, structural complexity, and rapid shape changes. Embracing these challenges, we introduce RobotSeg, a foundation model for robot segmentation in image and video. RobotSeg is built upon the versatile SAM 2 foundation model but addresses its three limitations for robot segmentation, namely the lack of adaptation to articulated robots, reliance on manual prompts, and the need for per-frame training mask annotations, by introducing a structure-enhanced memory associator, a robot prompt generator, and a label-efficient training strategy. These innovations collectively enable a structure-aware, automatic, and label-efficient solution. We further construct the video robot segmentation (VRS) dataset comprising over 2.8k videos (138k frames) with diverse robot embodiments and environments. Extensive experiments demonstrate that RobotSeg achieves state-of-the-art performance on both images and videos, establishing a strong foundation for future advances in robot perception."}
{"id": "2511.22997", "pdf": "https://arxiv.org/pdf/2511.22997", "abs": "https://arxiv.org/abs/2511.22997", "authors": ["Minseong Kweon", "Janghyun Kim", "Ukcheol Shin", "Jinsun Park"], "title": "MrGS: Multi-modal Radiance Fields with 3D Gaussian Splatting for RGB-Thermal Novel View Synthesis", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted at Thermal Infrared in Robotics (TIRO) Workshop, ICRA 2025 (Best Poster Award)", "summary": "Recent advances in Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS) have achieved considerable performance in RGB scene reconstruction. However, multi-modal rendering that incorporates thermal infrared imagery remains largely underexplored. Existing approaches tend to neglect distinctive thermal characteristics, such as heat conduction and the Lambertian property. In this study, we introduce MrGS, a multi-modal radiance field based on 3DGS that simultaneously reconstructs both RGB and thermal 3D scenes. Specifically, MrGS derives RGB- and thermal-related information from a single appearance feature through orthogonal feature extraction and employs view-dependent or view-independent embedding strategies depending on the degree of Lambertian reflectance exhibited by each modality. Furthermore, we leverage two physics-based principles to effectively model thermal-domain phenomena. First, we integrate Fourier's law of heat conduction prior to alpha blending to model intensity interpolation caused by thermal conduction between neighboring Gaussians. Second, we apply the Stefan-Boltzmann law and the inverse-square law to formulate a depth-aware thermal radiation map that imposes additional geometric constraints on thermal rendering. Experimental results demonstrate that the proposed MrGS achieves high-fidelity RGB-T scene reconstruction while reducing the number of Gaussians."}
{"id": "2511.23022", "pdf": "https://arxiv.org/pdf/2511.23022", "abs": "https://arxiv.org/abs/2511.23022", "authors": ["Shubham Sawarkar", "Pushpak Jagtap"], "title": "Control Barrier Function for Unknown Systems: An Approximation-free Approach", "categories": ["eess.SY", "cs.RO", "math.OC"], "comment": null, "summary": "We study the prescribed-time reach-avoid (PT-RA) control problem for nonlinear systems with unknown dynamics operating in environments with moving obstacles. Unlike robust or learning based Control Barrier Function (CBF) methods, the proposed framework requires neither online model learning nor uncertainty bound estimation. A CBF-based Quadratic Program (CBF-QP) is solved on a simple virtual system to generate a safe reference satisfying PT-RA conditions with respect to time-varying, tightened obstacle and goal sets. The true system is confined to a Virtual Confinement Zone (VCZ) around this reference using an approximation-free feedback law. This construction guarantees real-time safety and prescribed-time target reachability under unknown dynamics and dynamic constraints without explicit model identification or offline precomputation. Simulation results illustrate reliable dynamic obstacle avoidance and timely convergence to the target set."}
{"id": "2511.23369", "pdf": "https://arxiv.org/pdf/2511.23369", "abs": "https://arxiv.org/abs/2511.23369", "authors": ["Haochen Tian", "Tianyu Li", "Haochen Liu", "Jiazhi Yang", "Yihang Qiu", "Guang Li", "Junli Wang", "Yinfeng Gao", "Zhang Zhang", "Liang Wang", "Hangjun Ye", "Tieniu Tan", "Long Chen", "Hongyang Li"], "title": "SimScale: Learning to Drive via Real-World Simulation at Scale", "categories": ["cs.CV", "cs.RO"], "comment": "Project page: https://opendrivelab.com/SimScale", "summary": "Achieving fully autonomous driving systems requires learning rational decisions in a wide span of scenarios, including safety-critical and out-of-distribution ones. However, such cases are underrepresented in real-world corpus collected by human experts. To complement for the lack of data diversity, we introduce a novel and scalable simulation framework capable of synthesizing massive unseen states upon existing driving logs. Our pipeline utilizes advanced neural rendering with a reactive environment to generate high-fidelity multi-view observations controlled by the perturbed ego trajectory. Furthermore, we develop a pseudo-expert trajectory generation mechanism for these newly simulated states to provide action supervision. Upon the synthesized data, we find that a simple co-training strategy on both real-world and simulated samples can lead to significant improvements in both robustness and generalization for various planning methods on challenging real-world benchmarks, up to +6.8 EPDMS on navhard and +2.9 on navtest. More importantly, such policy improvement scales smoothly by increasing simulation data only, even without extra real-world data streaming in. We further reveal several crucial findings of such a sim-real learning system, which we term SimScale, including the design of pseudo-experts and the scaling properties for different policy architectures. Our simulation data and code would be released."}
