{"id": "2512.17001", "pdf": "https://arxiv.org/pdf/2512.17001", "abs": "https://arxiv.org/abs/2512.17001", "authors": ["Rohit V. Nanavati", "Tim J. Glover", "Matthew J. Coombes", "Cunjia Liu"], "title": "Mr.MSTE: Multi-robot Multi-Source Term Estimation with Wind-Aware Coverage Control", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a Multi-Robot Multi-Source Term Estimation (MRMSTE) framework that enables teams of mobile robots to collaboratively sample gas concentrations and infer the parameters of an unknown number of airborne releases. The framework is built on a hybrid Bayesian inference scheme that represents the joint multi-source probability density and incorporates physics-informed state transitions, including source birth, removal, and merging induced by atmospheric dispersion. A superposition-based measurement model is naturally accommodated, allowing sparse concentration measurements to be exploited efficiently. To guide robot deployment, we introduce a wind-aware coverage control (WCC) strategy that integrates the evolving multi-source belief with local wind information to prioritize regions of high detection likelihood. Unlike conventional coverage control or information-theoretic planners, WCC explicitly accounts for anisotropic plume transport when modelling sensor performance, leading to more effective sensor placement for multi-source estimation. Monte Carlo studies demonstrate faster convergence and improved separation of individual source beliefs compared to traditional coverage-based strategies and small-scale static sensor networks. Real-world experiments with CO2 releases using TurtleBot platforms further validate the proposed approach, demonstrating its practicality for scalable multi-robot gas-sensing applications."}
{"id": "2512.17055", "pdf": "https://arxiv.org/pdf/2512.17055", "abs": "https://arxiv.org/abs/2512.17055", "authors": ["Brian Nelson", "Behrouz Farhang-Boroujeny"], "title": "Packet Detection in a Filter Bank-Based Ultra-Wideband Communication System", "categories": ["eess.SP"], "comment": "13 pages, 11 figures. Submitted for review to IEEE Transactions on Signal Processing on December 18, 2025", "summary": "Recently, filter bank multi-carrier spread spectrum (FBMC-SS) technology has been proposed for use in ultra-wideband (UWB) communication systems. It has been noted that, due to the spectral partitioning properties of the filter banks, a UWB signal can be synthesized and processed using a parallel set of signal processors operating at a moderate rate. This transceiver architecture can be used to generate UWB signals, without requiring a high-rate analog-to-digital and/or digital-to-analog converter. In this paper, beginning with a design operating on a single signal processor, we explore the development of a packet detector using the Rao score test. Taking advantage of the FBMC-SS signal structure, an effective detector design based on a cascade channelizer is proposed. We refer to this design as singe-radio band (SRB) detector. Given the typical bandwidth of UWB systems ($\\bf 500$~MHz or wider), the SRB detector has to operate at a fast sampling rate of greater than $\\bf 500$~MHz. This may be undesirable, as low cost analog-to-digital (ADC) and digital-to-analog (DAC) converters are often limited to a sampling rate of $\\bf 200$~MHz or lower. Taking note of this point, the proposed SRB detector is extended to a multi-radio band (MRB) detector, where a set of parallel signal processors operating at a moderate sampling rate are used for a more practical implementation of the detector. Through computer simulations, we show that SRB and MRB detectors have the same performance in typical UWB channels. Finally, we provide results from an over-the-air demonstration of a UWB design occupying $\\bf 1.28$~GHz of bandwidth. We find that reliable detection performance is possible in the harshest environments, at signal-to-noise ratios as low as $\\bf -40$~dB with a preamble length of approximately half the duration of longest preamble length recommended in the IEEE802.15.4 standard."}
{"id": "2512.17062", "pdf": "https://arxiv.org/pdf/2512.17062", "abs": "https://arxiv.org/abs/2512.17062", "authors": ["Muhayy Ud Din", "Jan Rosell", "Waseem Akram", "Irfan Hussain"], "title": "Lang2Manip: A Tool for LLM-Based Symbolic-to-Geometric Planning for Manipulation", "categories": ["cs.RO"], "comment": "Submitted to ICARA", "summary": "Simulation is essential for developing robotic manipulation systems, particularly for task and motion planning (TAMP), where symbolic reasoning interfaces with geometric, kinematic, and physics-based execution. Recent advances in Large Language Models (LLMs) enable robots to generate symbolic plans from natural language, yet executing these plans in simulation often requires robot-specific engineering or planner-dependent integration. In this work, we present a unified pipeline that connects an LLM-based symbolic planner with the Kautham motion planning framework to achieve generalizable, robot-agnostic symbolic-to-geometric manipulation. Kautham provides ROS-compatible support for a wide range of industrial manipulators and offers geometric, kinodynamic, physics-driven, and constraint-based motion planning under a single interface. Our system converts language instructions into symbolic actions and computes and executes collision-free trajectories using any of Kautham's planners without additional coding. The result is a flexible and scalable tool for language-driven TAMP that is generalized across robots, planning modalities, and manipulation tasks."}
{"id": "2512.17084", "pdf": "https://arxiv.org/pdf/2512.17084", "abs": "https://arxiv.org/abs/2512.17084", "authors": ["Hamed Ajorlou", "Gonzalo Mateos", "Luana Ruiz"], "title": "Dirichlet Meets Horvitz and Thompson: Estimating Homophily in Large Networks via Sampling", "categories": ["eess.SP", "cs.SI", "stat.ME"], "comment": null, "summary": "Assessing homophily in large-scale networks is central to understanding structural regularities in graphs, and thus inform the choice of models (such as graph neural networks) adopted to learn from network data. Evaluation of smoothness metrics requires access to the entire network topology and node features, which may be impractical in several large-scale, dynamic, resource-limited, or privacy-constrained settings. In this work, we propose a sampling-based framework to estimate homophily via the Dirichlet energy (Laplacian-based total variation) of graph signals, leveraging the Horvitz-Thompson (HT) estimator for unbiased inference from partial graph observations. The Dirichlet energy is a so-termed total (of squared nodal feature deviations) over graph edges; hence, estimable under general network sampling designs for which edge-inclusion probabilities can be analytically derived and used as weights in the proposed HT estimator. We establish that the Dirichlet energy can be consistently estimated from sampled graphs, and empirically study other heterophily measures as well. Experiments on several heterophilic benchmark datasets demonstrate the effectiveness of the proposed HT estimators in reliably capturing homophilic structure (or lack thereof) from sampled network measurements."}
{"id": "2512.17136", "pdf": "https://arxiv.org/pdf/2512.17136", "abs": "https://arxiv.org/abs/2512.17136", "authors": ["Chunyang Meng", "Eduardo B. Sandoval", "Ricardo Sosa", "Francisco Cruz"], "title": "Towards Senior-Robot Interaction: Reactive Robot Dog Gestures", "categories": ["cs.RO"], "comment": "Accepted at the Australasian Conference on Robotics and Automation (ACRA) 2025", "summary": "As the global population ages, many seniors face the problem of loneliness. Companion robots offer a potential solution. However, current companion robots often lack advanced functionality, while task-oriented robots are not designed for social interaction, limiting their suitability and acceptance by seniors. Our work introduces a senior-oriented system for quadruped robots that allows for more intuitive user input and provides more socially expressive output. For user input, we implemented a MediaPipe-based module for hand gesture and head movement recognition, enabling control without a remote. For output, we designed and trained robotic dog gestures using curriculum-based reinforcement learning in Isaac Gym, progressing from simple standing to three-legged balancing and leg extensions, and more. The final tests achieved over 95\\% success on average in simulation, and we validated a key social gesture (the paw-lift) on a Unitree robot. Real-world tests demonstrated the feasibility and social expressiveness of this framework, while also revealing sim-to-real challenges in joint compliance, load distribution, and balance control. These contributions advance the development of practical quadruped robots as social companions for the senior and outline pathways for sim-to-real adaptation and inform future user studies."}
{"id": "2512.17112", "pdf": "https://arxiv.org/pdf/2512.17112", "abs": "https://arxiv.org/abs/2512.17112", "authors": ["Ju Zhuoxuan", "Doroslovacki Milos"], "title": "Kalman Filter-based Mobile User-RIS Channel Estimation and User Localization", "categories": ["eess.SP"], "comment": "14 pages, Under review at IEEE Transactions on Wireless Communications (TWC)", "summary": "In communication networks, channel estimation and user localization are challenging problems in harsh environments or signal-blocked areas. This paper introduces a novel approach to minimize the Mean Squared Error (MSE) in channel estimation between mobile users and rectangular Reconfigurable Intelligent Surfaces (RIS) within wireless communication systems. Meanwhile, the user localization is realized based on the estimated Channel State Information (CSI). In this paper, we assume a non-linear, user's position-dependent system model, for a user with high mobility, an RIS with multiple elements, and a base station (BS) with multiple antennas. After that, we apply the Kalman Filtering (KF) like algorithms to reduce MSE in estimating parameters of this time-variant channel model. Additionally, we propose a Non-Circular Noise Kalman Filter (NCNKF) to address scenarios with non-circular complex state-space noise. Furthermore, we apply the Discrete Space Fourier Transform (DSFT) method, combined with the interpolation techniques to decrease the Root Mean Squared Error (RMSE) for the user localization based on the estimated CSI. Finally, we extend the single-user case into the multi-user situation. Results show that KF can achieve lower MSE in estimating the channel than other known approaches, while the NCNKF algorithm has better performance in non-circular state-space noise scenarios. At the same time, the DSFT interpolation outperforms the other approaches with lower complexity. The study concludes with numerical comparisons and an in-depth discussion of the performance improvements enabled by our approaches."}
{"id": "2512.17180", "pdf": "https://arxiv.org/pdf/2512.17180", "abs": "https://arxiv.org/abs/2512.17180", "authors": ["Maher Mesto", "Francisco Cruz"], "title": "Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors", "categories": ["cs.RO", "cs.AI"], "comment": "10 pages, 5 figures. Accepted at ACRA 2025 (Australasian Conference on Robotics and Automation)", "summary": "Interactive reinforcement learning (IRL) has shown promise in enabling autonomous agents and robots to learn complex behaviours from human teachers, yet the dynamics of teacher selection remain poorly understood. This paper reveals an unexpected phenomenon in IRL: when given a choice between teachers with different reward structures, learning agents overwhelmingly prefer conservative, low-reward teachers (93.16% selection rate) over those offering 20x higher rewards. Through 1,250 experimental runs in navigation tasks with multiple expert teachers, we discovered: (1) Conservative bias dominates teacher selection: agents systematically choose the lowest-reward teacher, prioritising consistency over optimality; (2) Critical performance thresholds exist at teacher availability rho >= 0.6 and accuracy omega >= 0.6, below which the framework fails catastrophically; (3) The framework achieves 159% improvement over baseline Q-learning under concept drift. These findings challenge fundamental assumptions about optimal teaching in RL and suggest potential implications for human-robot collaboration, where human preferences for safety and consistency may align with the observed agent selection behaviour, potentially informing training paradigms for safety-critical robotic applications."}
{"id": "2512.17125", "pdf": "https://arxiv.org/pdf/2512.17125", "abs": "https://arxiv.org/abs/2512.17125", "authors": ["Talha Akyildiz", "Hessam Mahdavifar"], "title": "Deep Learning-Enabled Multi-Tag Detection in Ambient Backscatter Communications", "categories": ["eess.SP"], "comment": null, "summary": "Ambient backscatter communication (AmBC) enables battery-free connectivity by letting passive tags modulate existing RF signals, but reliable detection of multiple tags is challenging due to strong direct link interference, very weak backscatter signals, and an exponentially large joint state space. Classical multi-hypothesis likelihood ratio tests (LRTs) are optimal for this task when perfect channel state information (CSI) is available, yet in AmBC such CSI is difficult to obtain and track because the RF source is uncooperative and the tags are low-power passive devices. We first derive analytical performance bounds for an LRT receiver with perfect CSI to serve as a benchmark. We then propose two complementary deep learning frameworks that relax the CSI requirement while remaining modulation-agnostic. EmbedNet is an end-to-end prototypical network that maps covariance features of the received signal directly to multi-tag states. ChanEstNet is a hybrid scheme in which a convolutional neural network estimates effective channel coefficients from pilot symbols and passes them to a conventional LRT for interpretable multi-hypothesis detection. Simulations over diverse ambient sources and system configurations show that the proposed methods substantially reduce bit error rate, closely track the LRT benchmark, and significantly outperform energy detection baselines, especially as the number of tags increases."}
{"id": "2512.17183", "pdf": "https://arxiv.org/pdf/2512.17183", "abs": "https://arxiv.org/abs/2512.17183", "authors": ["Gang Zhang"], "title": "Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots", "categories": ["cs.RO"], "comment": null, "summary": "We present an innovative end-to-end framework for synthesizing semantically meaningful co-speech gestures and deploying them in real-time on a humanoid robot. This system addresses the challenge of creating natural, expressive non-verbal communication for robots by integrating advanced gesture generation techniques with robust physical control. Our core innovation lies in the meticulous integration of a semantics-aware gesture synthesis module, which derives expressive reference motions from speech input by leveraging a generative retrieval mechanism based on large language models (LLMs) and an autoregressive Motion-GPT model. This is coupled with a high-fidelity imitation learning control policy, the MotionTracker, which enables the Unitree G1 humanoid robot to execute these complex motions dynamically and maintain balance. To ensure feasibility, we employ a robust General Motion Retargeting (GMR) method to bridge the embodiment gap between human motion data and the robot platform. Through comprehensive evaluation, we demonstrate that our combined system produces semantically appropriate and rhythmically coherent gestures that are accurately tracked and executed by the physical robot. To our knowledge, this work represents a significant step toward general real-world use by providing a complete pipeline for automatic, semantic-aware, co-speech gesture generation and synchronized real-time physical deployment on a humanoid robot."}
{"id": "2512.17133", "pdf": "https://arxiv.org/pdf/2512.17133", "abs": "https://arxiv.org/abs/2512.17133", "authors": ["Talha Akyildiz", "Hessam Mahdavifar"], "title": "Deep Reinforcement Learning-Aided Strategies for Big Data Offloading in Vehicular Networks", "categories": ["eess.SP"], "comment": null, "summary": "We consider vehicular networking scenarios where existing vehicle-to-vehicle (V2V) links can be leveraged for an effective uploading of large-size data to the network. In particular, we consider a group of vehicles where one vehicle can be designated as the \\textit{leader} and other \\textit{follower} vehicles can offload their data to the leader vehicle or directly upload it to the base station (or a combination of the two). In our proposed framework, the leader vehicle is responsible for receiving the data from other vehicles and processing it in order to remove the redundancy (deduplication) before uploading it to the base station. We present a mathematical framework of the considered network and formulate two separate optimization problems for minimizing (i) total time and (ii) total energy consumption by vehicles for uploading their data to the base station. We employ deep reinforcement learning (DRL) tools to obtain solutions in a dynamic vehicular network where network parameters (e.g., vehicle locations and channel coefficients) vary over time. Our results demonstrate that the application of DRL is highly beneficial, and data offloading with deduplication can significantly reduce the time and energy consumption. Furthermore, we present comprehensive numerical results to validate our findings and compare them with alternative approaches to show the benefits of the proposed DRL methods."}
{"id": "2512.17212", "pdf": "https://arxiv.org/pdf/2512.17212", "abs": "https://arxiv.org/abs/2512.17212", "authors": ["Yan Gao", "Jiliang Wang", "Ming Cheng", "Tianyun Huang"], "title": "Design and Research of a Self-Propelled Pipeline Robot Based on Force Analysis and Dynamic Simulation", "categories": ["cs.RO"], "comment": "7 pages, 14 figures", "summary": "In pipeline inspection, traditional tethered inspection robots are severely constrained by cable length and weight, which greatly limit their travel range and accessibility. To address these issues, this paper proposes a self-propelled pipeline robot design based on force analysis and dynamic simulation, with a specific focus on solving core challenges including vertical climbing failure and poor passability in T-branch pipes. Adopting a wheeled configuration and modular design, the robot prioritizes the core demand of body motion control. Specifically, 3D modeling of the robot was first completed using SolidWorks. Subsequently, the model was imported into ADAMS for dynamic simulation, which provided a basis for optimizing the drive module and motion control strategy.To verify the robot's dynamic performance, an experimental platform with acrylic pipes was constructed. Through adjusting its body posture to surmount obstacles and select directions, the robot has demonstrated its ability to stably traverse various complex pipeline scenarios. Notably, this work offers a technical feasibility reference for the application of pipeline robots in the inspection of medium and low-pressure urban gas pipelines."}
{"id": "2512.17138", "pdf": "https://arxiv.org/pdf/2512.17138", "abs": "https://arxiv.org/abs/2512.17138", "authors": ["Vinicius P. Campos", "Diego Szczupak", "Tales Santini", "Afonso C. Silva", "Alessandro Foi", "Marcelo A. C. Vieira", "Corey A. Baron"], "title": "BM4D-PC: nonlocal volumetric denoising of principal components of diffusion-weighted MR images", "categories": ["eess.SP"], "comment": "Submitted to Magnetic Resonance in Medicine", "summary": "Purpose: Noise in diffusion-weighted MRI (dMRI) is often spatially correlated due to different acquisition and reconstruction strategies, which is not fully accounted for in current denoising strategies. Thus, we propose a novel model-based denoising method for dMRI that effectively accounts for the different noise characteristics of data. Methods: We propose a denoising strategy that incorporates full noise statistics, including the noise power spectral density (PSD), by leveraging the BM4D algorithm. Furthermore, to exploit redundancy across the diffusion MRI dataset, BM4D is applied to principal components (PC) of diffusion-weighted images (DWI) obtained through principal component analysis (PCA) decomposition of the entire DWI dataset, an approach we refer to as BM4D-PC. Importantly, our method also allows for direct estimation of both the noise map and PSD. We evaluated BM4D-PC against four existing state-of-the-art methods using in-silico and in vivo datasets, including high-resolution human and marmoset acquisitions. Results: Overall, BM4D-PC presented the best results for the metrics PSNR, SSIM and RMSE on the in-silico experiments. The in-vivo studies also showed that BM4D-PC dramatically enhanced the image quality of raw DWIs, outperforming existing denoising methods in terms of noise suppression and detail preservation, leading to improved quality of diffusion metrics. Conclusion: The proposed BM4D-PC method demonstrated state-of-the-art denoising results for dMRI using datasets from various acquisition strategies and image resolutions, potentially supporting future advances in neuroscience research."}
{"id": "2512.17215", "pdf": "https://arxiv.org/pdf/2512.17215", "abs": "https://arxiv.org/abs/2512.17215", "authors": ["Yan Gao", "Jiliang Wang", "Minghan Wang", "Xiaohua Chen", "Demin Chen", "Zhiyong Ren", "Tian-Yun Huang"], "title": "Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 9 figures", "summary": "In the field of gas pipeline location, existing pipeline location methods mostly rely on pipeline location instruments. However, when faced with complex and curved pipeline scenarios, these methods often fail due to problems such as cable entanglement and insufficient equipment flexibility. To address this pain point, we designed a self-propelled pipeline robot. This robot can autonomously complete the location work of complex and curved pipelines in complex pipe networks without external dragging. In terms of pipeline mapping technology, traditional visual mapping and laser mapping methods are easily affected by lighting conditions and insufficient features in the confined space of pipelines, resulting in mapping drift and divergence problems. In contrast, the pipeline location method that integrates inertial navigation and wheel odometers is less affected by pipeline environmental factors. Based on this, this paper proposes a pipeline robot location method based on extended Kalman filtering (EKF). Firstly, the body attitude angle is initially obtained through an inertial measurement unit (IMU). Then, the extended Kalman filtering algorithm is used to improve the accuracy of attitude angle estimation. Finally, high-precision pipeline location is achieved by combining wheel odometers. During the testing phase, the roll wheels of the pipeline robot needed to fit tightly against the pipe wall to reduce slippage. However, excessive tightness would reduce the flexibility of motion control due to excessive friction. Therefore, a balance needed to be struck between the robot's motion capability and positioning accuracy. Experiments were conducted using the self-propelled pipeline robot in a rectangular loop pipeline, and the results verified the effectiveness of the proposed dead reckoning algorithm."}
{"id": "2512.17171", "pdf": "https://arxiv.org/pdf/2512.17171", "abs": "https://arxiv.org/abs/2512.17171", "authors": ["Hengyu Zhang", "Xuehan Wang", "Xu Shi", "Jintao Wang", "Zhaohui Yang"], "title": "RSMA-Assited and Transceiver-Coordinated ICI Management for MIMO-OFDM System", "categories": ["eess.SP"], "comment": null, "summary": "High-mobility scenarios are becoming increasingly critical in next-generation communication systems. While multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) stands as a prominent technology, its performance in such scenarios is fundamentally limited by Doppler-induced inter-carrier interference (ICI). Rate splitting multiple access (RSMA), recognized as a key multiple access technique for future communications, demonstrates superior interference management capabilities that we leverage to address this challenge. In specific, we propose a novel RSMA-assisted and transceiver-coordinated transmission scheme for ICI management in MIMO-OFDM system: (1) At the receiver side, we develop a hybrid successive interference cancellation (SIC) architecture with dynamic subcarrier clustering, which enables parallel intra-cluster and serial inter-cluster processing to balance complexity and performance. (2) At the transmitter~side, we design a matched hybrid precoding through formulated sum-rate maximization, solved via our proposed augmented boundary-compressed particle swarm optimization (ABC-PSO) algorithm for analog phase optimization and weighted minimum mean-square error (WMMSE)-based digital precoding iteration. Simulation results show that our scheme brings effective ICI suppression and enhanced system capacity with controlled complexity."}
{"id": "2512.17241", "pdf": "https://arxiv.org/pdf/2512.17241", "abs": "https://arxiv.org/abs/2512.17241", "authors": ["Suraj Nukala", "Meera Sushma", "Leimin Tian", "Akansel Cosgun", "Dana Kulic"], "title": "A Service Robot's Guide to Interacting with Busy Customers", "categories": ["cs.RO", "cs.HC"], "comment": "Presented at ACRA 2025. 10 pages, 4 figures. Includes a user study (N=24) using the Temi robot evaluating speech, visual, and micromotion modalities", "summary": "The growing use of service robots in hospitality highlights the need to understand how to effectively communicate with pre-occupied customers. This study investigates the efficacy of commonly used communication modalities by service robots, namely, acoustic/speech, visual display, and micromotion gestures in capturing attention and communicating intention with a user in a simulated restaurant scenario. We conducted a two-part user study (N=24) using a Temi robot to simulate delivery tasks, with participants engaged in a typing game (MonkeyType) to emulate a state of busyness. The participants' engagement in the typing game is measured by words per minute (WPM) and typing accuracy. In Part 1, we compared non-verbal acoustic cue versus baseline conditions to assess attention capture during a single-cup delivery task. In Part 2, we evaluated the effectiveness of speech, visual display, micromotion and their multimodal combination in conveying specific intentions (correct cup selection) during a two-cup delivery task. The results indicate that, while speech is highly effective in capturing attention, it is less successful in clearly communicating intention. Participants rated visual as the most effective modality for intention clarity, followed by speech, with micromotion being the lowest ranked.These findings provide insights into optimizing communication strategies for service robots, highlighting the distinct roles of attention capture and intention communication in enhancing user experience in dynamic hospitality settings."}
{"id": "2512.17274", "pdf": "https://arxiv.org/pdf/2512.17274", "abs": "https://arxiv.org/abs/2512.17274", "authors": ["Lin Chen", "Xiaojun Yuan", "Ying-Jun Angela Zhang"], "title": "Near-Field Position and Orientation Tracking With Hybrid ELAA Architecture", "categories": ["eess.SP"], "comment": null, "summary": "This paper investigates near-field (NF) position and orientation tracking of a multi-antenna mobile station (MS) using an extremely large antenna array (ELAA)-equipped base station (BS) with a limited number of radio frequency (RF) chains. Under this hybrid array architecture, the received uplink pilot signal at the BS is first combined by analog phase shifters, producing a low-dimensional observation before digital processing. Such analog compression provides only partial access to the ELAA measurement, making it essential to design an analog combiner that can preserve pose-relevant signal components despite channel uncertainty and unit-modulus hardware constraints. To address this, we propose a predictive analog combining-assisted extended Kalman filter (PAC-EKF) framework, where the analog combiner can leverage the temporal correlation in the MS pose variation to capture the most informative signal components predictively. We then analyze fundamental performance limits via Bayesian Cram√©r-Rao bound and Fisher information matrix, explicitly quantifying how the analog combiner, array size, signal-to-noise ratio, and MS pose influence the pose information contained in the uplink observation. Building on these insights, we develop two methods for designing a low-complexity analog combiner. Numerical results show that the proposed predictive analog combining approach significantly improves tracking accuracy, even with fewer RF chains and lower transmit power."}
{"id": "2512.17309", "pdf": "https://arxiv.org/pdf/2512.17309", "abs": "https://arxiv.org/abs/2512.17309", "authors": ["Asil Kaan Bozcuoglu", "Ziyuan Liu"], "title": "RecipeMasterLLM: Revisiting RoboEarth in the Era of Large Language Models", "categories": ["cs.RO"], "comment": null, "summary": "RoboEarth was a pioneering initiative in cloud robotics, establishing a foundational framework for robots to share and exchange knowledge about actions, objects, and environments through a standardized knowledge graph. Initially, this knowledge was predominantly hand-crafted by engineers using RDF triples within OWL Ontologies, with updates, such as changes in an object's pose, being asserted by the robot's control and perception routines. However, with the advent and rapid development of Large Language Models (LLMs), we believe that the process of knowledge acquisition can be significantly automated. To this end, we propose RecipeMasterLLM, a high-level planner, that generates OWL action ontologies based on a standardized knowledge graph in response to user prompts. This architecture leverages a fine-tuned LLM specifically trained to understand and produce action descriptions consistent with the RoboEarth standardized knowledge graph. Moreover, during the Retrieval-Augmented Generation (RAG) phase, environmental knowledge is supplied to the LLM to enhance its contextual understanding and improve the accuracy of the generated action descriptions."}
{"id": "2512.17283", "pdf": "https://arxiv.org/pdf/2512.17283", "abs": "https://arxiv.org/abs/2512.17283", "authors": ["Lin Chen", "Ahmed Elzanaty", "Mustafa A. Kishk", "Ying-Jun Angela Zhang"], "title": "Near-Field Multi-User Communications via Polar-Domain Beamfocusing: Analytical Framework and Performance Analysis", "categories": ["eess.SP"], "comment": null, "summary": "As wireless systems evolve toward higher frequencies and extremely large antenna arrays, near-field (NF) propagation becomes increasingly dominant. Unlike far-field (FF) communication, which relies on a planar-wavefront model and is limited to angular-domain beamsteering, NF propagation exhibits spherical wavefronts that enable beamfocusing in both angle and distance, i.e., the polar domain, offering new opportunities for spatial multiple access. This paper develops an analytical stochastic geometry (SG) framework for a multi-user system assisted by polar-domain beamfocusing, which jointly captures NF propagation characteristics and the spatial randomness of user locations. The intrinsic coupling between angle and distance in the NF antenna pattern renders inter-user interference analysis intractable. To address this challenge, we propose a tractable near-field multi-level antenna pattern (NF-MLAP) approximation, which enables computationally efficient expressions and tight upper bounds for key performance metrics, including coverage probability, spectrum efficiency, and area spectrum efficiency. Analytical and simulation results demonstrate that the proposed framework accurately captures performance trends and reveals fundamental trade-offs between hardware configuration (including the number of antennas and radio frequency chains) and system performance (in terms of spatial resource reuse and interference mitigation)."}
{"id": "2512.17321", "pdf": "https://arxiv.org/pdf/2512.17321", "abs": "https://arxiv.org/abs/2512.17321", "authors": ["Momina Liaqat Ali", "Muhammad Abid"], "title": "Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks", "categories": ["cs.RO"], "comment": null, "summary": "Although large language models (LLMs) have recently become effective tools for language-conditioned control in embodied systems, instability, slow convergence, and hallucinated actions continue to limit their direct application to continuous control. A modular neuro-symbolic control framework that clearly distinguishes between low-level motion execution and high-level semantic reasoning is proposed in this work. While a lightweight neural delta controller performs bounded, incremental actions in continuous space, a locally deployed LLM interprets symbolic tasks. We assess the suggested method in a planar manipulation setting with spatial relations between objects specified by language. Numerous tasks and local language models, such as Mistral, Phi, and LLaMA-3.2, are used in extensive experiments to compare LLM-only control, neural-only control, and the suggested LLM+DL framework. In comparison to LLM-only baselines, the results show that the neuro-symbolic integration consistently increases both success rate and efficiency, achieving average step reductions exceeding 70% and speedups of up to 8.83x while remaining robust to language model quality. The suggested framework enhances interpretability, stability, and generalization without any need of reinforcement learning or costly rollouts by controlling the LLM to symbolic outputs and allocating uninterpreted execution to a neural controller trained on artificial geometric data. These outputs show empirically that neuro-symbolic decomposition offers a scalable and principled way to integrate language understanding with ongoing control, this approach promotes the creation of dependable and effective language-guided embodied systems."}
{"id": "2512.17286", "pdf": "https://arxiv.org/pdf/2512.17286", "abs": "https://arxiv.org/abs/2512.17286", "authors": ["Lizhou Liu", "Xiaohui Chen", "Wenyi Zhang"], "title": "OpenPathNet: An Open-Source RF Multipath Data Generator for AI-Driven Wireless Systems", "categories": ["eess.SP"], "comment": "AI, dataset, environment-aware communication, multipath propagation, radio frequency (RF) map, ray tracing", "summary": "The convergence of artificial intelligence (AI) and sixth-generation (6G) wireless technologies is driving an urgent need for large-scale, high-fidelity, and reproducible radio frequency (RF) datasets. Existing resources, such as CKMImageNet, primarily provide preprocessed and image-based channel representations, which conceal the fine-grained physical characteristics of signal propagation that are essential for effective AI modeling. To bridge this gap, we present OpenPathNet, an open-source RF multipath data generator accompanied by a publicly released dataset for AI-driven wireless research. Distinct from prior datasets, OpenPathNet offers disaggregated and physically consistent multipath parameters, including per-path gain, time of arrival (ToA), and spatial angles, derived from high-precision ray tracing simulations constructed on real-world environment maps. By adopting a modular, parameterized pipeline, OpenPathNet enables reproducible generation of multipath data and can be readily extended to new environments and configurations, improving scalability and transparency. The released generator and accompanying dataset provide an extensible testbed that holds promise for advancing studies on channel modeling, beam prediction, environment-aware communication, and integrated sensing in AI-enabled 6G systems. The source code and dataset are publicly available at https://github.com/liu-lz/OpenPathNet."}
{"id": "2512.17349", "pdf": "https://arxiv.org/pdf/2512.17349", "abs": "https://arxiv.org/abs/2512.17349", "authors": ["Xijie Huang", "Jinhan Li", "Tianyue Wu", "Xin Zhou", "Zhichao Han", "Fei Gao"], "title": "Flying in Clutter on Monocular RGB by Learning in 3D Radiance Fields with Domain Adaptation", "categories": ["cs.RO"], "comment": "8 pages, 7 figures", "summary": "Modern autonomous navigation systems predominantly rely on lidar and depth cameras. However, a fundamental question remains: Can flying robots navigate in clutter using solely monocular RGB images? Given the prohibitive costs of real-world data collection, learning policies in simulation offers a promising path. Yet, deploying such policies directly in the physical world is hindered by the significant sim-to-real perception gap. Thus, we propose a framework that couples the photorealism of 3D Gaussian Splatting (3DGS) environments with Adversarial Domain Adaptation. By training in high-fidelity simulation while explicitly minimizing feature discrepancy, our method ensures the policy relies on domain-invariant cues. Experimental results demonstrate that our policy achieves robust zero-shot transfer to the physical world, enabling safe and agile flight in unstructured environments with varying illumination."}
{"id": "2512.17332", "pdf": "https://arxiv.org/pdf/2512.17332", "abs": "https://arxiv.org/abs/2512.17332", "authors": ["Yu Hua", "Yaru Fu", "Yalin Liu", "Zheng Shi", "Kevin Hung"], "title": "Content-Aware RSMA-Enabled Pinching-Antenna Systems for Latency Optimization in 6G Networks", "categories": ["eess.SP"], "comment": null, "summary": "The Pinching Antenna System (PAS) has emerged as a promising technology to dynamically reconfigure wireless propagation environments in 6G networks. By activating radiating elements at arbitrary positions along a dielectric waveguide, PAS can establish strong line-of-sight (LoS) links with users, significantly enhancing channel gain and deployment flexibility, particularly in high-frequency bands susceptible to severe path loss. To further improve multi-user performance, this paper introduces a novel content-aware transmission framework that integrates PAS with rate-splitting multiple access (RSMA). Unlike conventional RSMA, the proposed RSMA scheme enables users requesting the same content to share a unified private stream, thereby mitigating inter-user interference and reducing power fragmentation. We formulate a joint optimization problem aimed at minimizing the average system latency by dynamically adapting both antenna positioning and RSMA parameters according to channel conditions and user requests. A Content-Aware RSMA and Pinching-antenna Joint Optimization (CARP-JO) algorithm is developed, which decomposes the non-convex problem into tractable subproblems solved via bisection search, convex programming, and golden-section search. Simulation results demonstrate that the proposed CARP-JO scheme consistently outperforms Traditional RSMA, NOMA, and Fixed-antenna systems across diverse network scenarios in terms of latency, underscoring the effectiveness of co-designing physical-layer reconfigurability with intelligent communication strategies."}
{"id": "2512.17370", "pdf": "https://arxiv.org/pdf/2512.17370", "abs": "https://arxiv.org/abs/2512.17370", "authors": ["Deqing Liu", "Yinfeng Gao", "Deheng Qian", "Qichao Zhang", "Xiaoqing Ye", "Junyu Han", "Yupeng Zheng", "Xueyi Liu", "Zhongpu Xia", "Dawei Ding", "Yifeng Pan", "Dongbin Zhao"], "title": "TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component."}
{"id": "2512.17335", "pdf": "https://arxiv.org/pdf/2512.17335", "abs": "https://arxiv.org/abs/2512.17335", "authors": ["Xiao Tang", "Zhen Ma", "Bin Li", "Cong Li", "Qinghe Du", "Dusit Niyato", "Zhu Han"], "title": "Active RIS-Aided Anti-Jamming Wireless Communications: A Stackelberg Game Perspective", "categories": ["eess.SP", "cs.IT"], "comment": "Accepted @ IEEE TCOM", "summary": "The pervasive threat of jamming attacks, particularly from adaptive jammers capable of optimizing their strategies, poses a significant challenge to the security and reliability of wireless communications. This paper addresses this issue by investigating anti-jamming communications empowered by an active reconfigurable intelligent surface. The strategic interaction between the legitimate system and the adaptive jammer is modeled as a Stackelberg game, where the legitimate user, acting as the leader, proactively designs its strategy while anticipating the jammer's optimal response. We prove the existence of the Stackelberg equilibrium and derive it using a backward induction method. Particularly, the jammer's optimal strategy is embedded into the leader's problem, resulting in a bi-level optimization that jointly considers legitimate transmit power, transmit/receive beamformers, and active reflection. We tackle this complex, non-convex problem by using a block coordinate descent framework, wherein subproblems are iteratively solved via convex relaxation and successive convex approximation techniques. Simulation results demonstrate the significant superiority of the proposed active RIS-assisted scheme in enhancing legitimate transmissions and degrading jamming effects compared to baseline schemes across various scenarios. These findings highlight the effectiveness of combining active RIS technology with a strategic game-theoretic framework for anti-jamming communications."}
{"id": "2512.17425", "pdf": "https://arxiv.org/pdf/2512.17425", "abs": "https://arxiv.org/abs/2512.17425", "authors": ["Beatrice Luciani", "Katherine Lin Poggensee", "Heike Vallery", "Alex van den Berg", "Severin David Woernle", "Mostafa Mogharabi", "Stefano Dalla Gasperina", "Laura Marchal-Crespo"], "title": "Personalized Gait Patterns During Exoskeleton-Aided Training May Have Minimal Effect on User Experience. Insights from a Pilot Study", "categories": ["cs.RO"], "comment": null, "summary": "Robot-aided gait rehabilitation facilitates high-intensity and repeatable therapy. However, most exoskeletons rely on pre-recorded, non-personalized gait trajectories constrained to the sagittal plane, potentially limiting movement naturalness and user comfort. We present a data-driven gait personalization framework for an exoskeleton that supports multi-planar motion, including hip abduction/adduction and pelvic translation and rotation. Personalized trajectories to individual participants were generated using regression models trained on anthropometric, demographic, and walking speed data from a normative database. In a within-subject experiment involving ten unimpaired participants, these personalized trajectories were evaluated in regard to comfort, naturalness, and overall experience and compared against two standard patterns from the same database: one averaging all the trajectories, and one randomly selected. We did not find relevant differences across pattern conditions, despite all trajectories being executed with high accuracy thanks to a stiff position-derivative controller. We found, however, that pattern conditions in later trials were rated as more comfortable and natural than those in the first trial, suggesting that participants might have adapted to walking within the exoskeleton, regardless of the enforced gait pattern. Our findings highlight the importance of integrating subjective feedback when designing personalized gait controllers and accounting for user adaptation during experimentation."}
{"id": "2512.17423", "pdf": "https://arxiv.org/pdf/2512.17423", "abs": "https://arxiv.org/abs/2512.17423", "authors": ["Shunbo Jia", "Caizhi Liao"], "title": "SCAR: Semantic Cardiac Adversarial Representation via Spatiotemporal Manifold Optimization in ECG", "categories": ["eess.SP"], "comment": "13 pages, 5 figures", "summary": "Deep learning models for Electrocardiogram (ECG) analysis have achieved expert-level performance but remain vulnerable to adversarial attacks. However, applying Universal Adversarial Perturbations (UAP) to ECG signals presents a unique challenge: standard imperceptible noise constraints (e.g., 10 uV) fail to generate effective universal attacks due to the high inter-subject variability of cardiac waveforms. Furthermore, traditional \"invisible\" attacks are easily dismissed by clinicians as technical artifacts, failing to compromise the human-in-the-loop diagnostic pipeline. In this study, we propose SCAR (Semantic Cardiac Adversarial Representation), a novel UAP framework tailored to bypass the clinical \"Human Firewall.\" Unlike traditional approaches, SCAR integrates spatiotemporal smoothing (W=25, approx. 50ms), spectral consistency (<15 Hz), and anatomical amplitude constraints (<0.2 mV) directly into the gradient optimization manifold.\n  Results: We benchmarked SCAR against a rigorous baseline (Standard Universal DeepFool with post-hoc physiological filtering). While the baseline suffers a performance collapse (~16% success rate on transfer tasks), SCAR maintains robust transferability (58.09% on ResNet) and achieves 82.46% success on the source model. Crucially, clinical analysis reveals an emergent targeted behavior: SCAR specifically converges to forging Myocardial Infarction features (90.2% misdiagnosis) by mathematically reconstructing pathological ST-segment elevations. Finally, we demonstrate that SCAR serves a dual purpose: it not only functions as a robust data augmentation strategy for Hybrid Adversarial Training, offering optimal clinical defense, but also provides effective educational samples for training clinicians to recognize low-cost, AI-targeted semantic forgeries."}
{"id": "2512.17435", "pdf": "https://arxiv.org/pdf/2512.17435", "abs": "https://arxiv.org/abs/2512.17435", "authors": ["Teng Wang", "Xinxin Zhao", "Wenzhe Cai", "Changyin Sun"], "title": "ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination", "categories": ["cs.RO"], "comment": "17 pages, 10 figures. arXiv admin note: text overlap with arXiv:2410.09874", "summary": "Visual navigation is a fundamental capability for autonomous home-assistance robots, enabling long-horizon tasks such as object search. While recent methods have leveraged Large Language Models (LLMs) to incorporate commonsense reasoning and improve exploration efficiency, their planning remains constrained by textual representations, which cannot adequately capture spatial occupancy or scene geometry--critical factors for navigation decisions. We explore whether Vision-Language Models (VLMs) can achieve mapless visual navigation using only onboard RGB/RGB-D streams, unlocking their potential for spatial perception and planning. We achieve this through an imagination-powered navigation framework, ImagineNav++, which imagines future observation images from candidate robot views and translates navigation planning into a simple best-view image selection problem for VLMs. First, a future-view imagination module distills human navigation preferences to generate semantically meaningful viewpoints with high exploration potential. These imagined views then serve as visual prompts for the VLM to identify the most informative viewpoint. To maintain spatial consistency, we develop a selective foveation memory mechanism, which hierarchically integrates keyframe observations via a sparse-to-dense framework, constructing a compact yet comprehensive memory for long-term spatial reasoning. This approach transforms goal-oriented navigation into a series of tractable point-goal navigation tasks. Extensive experiments on open-vocabulary object and instance navigation benchmarks show that ImagineNav++ achieves SOTA performance in mapless settings, even surpassing most map-based methods, highlighting the importance of scene imagination and memory in VLM-based spatial reasoning."}
{"id": "2512.17434", "pdf": "https://arxiv.org/pdf/2512.17434", "abs": "https://arxiv.org/abs/2512.17434", "authors": ["Sasmita Dash", "Constantinos Psomas", "Ioannis Krikidis"], "title": "Sub-6 GHz Beam-Reconfigurable Microfluidic Antenna Using Graphene Liquid for 5G Network", "categories": ["eess.SP"], "comment": "8 Pages, 4 Figures", "summary": "As wireless communication systems continue to grow rapidly, high-performance antennas become increasingly crucial for expanding coverage, improving capacity, and enhancing transmission quality. In light of this, research has focused considerable attention on liquid antennas due to their unique characteristics, which include small size, flexibility, reconfigurability and transparency. Recently, graphene liquid has been explored for numerous applications due to its low cost, high conductivity, flexibility, and ease of processing. Specifically for antenna applications, graphene liquid performs better than conventional liquid metal. This paper presents a graphene-liquid antenna with beam reconfiguration ability for sub-6 GHz communication system. The graphene-liquid movement within the microfluidic channel is taken into consideration by the reconfiguration mechanism. The antenna achieves beam reconfiguration in 360¬∞ directions with 6 dBi of gain at 5.5 GHz, featuring a wideband impedance bandwidth of 24%. The antenna main beam is specifically reconfigured into six directions (0¬∞, 45¬∞, 135¬∞, 180¬∞, 225¬∞ and 315¬∞) at 5.5 GHz. Additionally, in all six reconfigurable scenarios at 5.5 GHz, the antenna provides a stable reflection coefficient. Therefore, for the next generation of wireless communication systems, this novel design of graphene-liquid-based reconfigurable sub-6 GHz antennas holds promise."}
{"id": "2512.17505", "pdf": "https://arxiv.org/pdf/2512.17505", "abs": "https://arxiv.org/abs/2512.17505", "authors": ["Ufuk Asil", "Efendi Nasibov"], "title": "Adaptive Covariance and Quaternion-Focused Hybrid Error-State EKF/UKF for Visual-Inertial Odometry", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This study presents an innovative hybrid Visual-Inertial Odometry (VIO) method for Unmanned Aerial Vehicles (UAVs) that is resilient to environmental challenges and capable of dynamically assessing sensor reliability. Built upon a loosely coupled sensor fusion architecture, the system utilizes a novel hybrid Quaternion-focused Error-State EKF/UKF (Qf-ES-EKF/UKF) architecture to process inertial measurement unit (IMU) data. This architecture first propagates the entire state using an Error-State Extended Kalman Filter (ESKF) and then applies a targeted Scaled Unscented Kalman Filter (SUKF) step to refine only the orientation. This sequential process blends the accuracy of SUKF in quaternion estimation with the overall computational efficiency of ESKF. The reliability of visual measurements is assessed via a dynamic sensor confidence score based on metrics, such as image entropy, intensity variation, motion blur, and inference quality, adapting the measurement noise covariance to ensure stable pose estimation even under challenging conditions. Comprehensive experimental analyses on the EuRoC MAV dataset demonstrate key advantages: an average improvement of 49% in position accuracy in challenging scenarios, an average of 57% in rotation accuracy over ESKF-based methods, and SUKF-comparable accuracy achieved with approximately 48% lower computational cost than a full SUKF implementation. These findings demonstrate that the presented approach strikes an effective balance between computational efficiency and estimation accuracy, and significantly enhances UAV pose estimation performance in complex environments with varying sensor reliability."}
{"id": "2512.17473", "pdf": "https://arxiv.org/pdf/2512.17473", "abs": "https://arxiv.org/abs/2512.17473", "authors": ["Atharva Awari", "Nicolas Gillis", "Arnaud Vandaele"], "title": "Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions", "categories": ["eess.SP", "cs.LG", "math.OC", "stat.ML"], "comment": "14 pages, 6 figures. Code available from https://gitlab.com/Atharva05/admm-for-nmd", "summary": "We present an algorithm based on the alternating direction method of multipliers (ADMM) for solving nonlinear matrix decompositions (NMD). Given an input matrix $X \\in \\mathbb{R}^{m \\times n}$ and a factorization rank $r \\ll \\min(m, n)$, NMD seeks matrices $W \\in \\mathbb{R}^{m \\times r}$ and $H \\in \\mathbb{R}^{r \\times n}$ such that $X \\approx f(WH)$, where $f$ is an element-wise nonlinear function. We evaluate our method on several representative nonlinear models: the rectified linear unit activation $f(x) = \\max(0, x)$, suitable for nonnegative sparse data approximation, the component-wise square $f(x) = x^2$, applicable to probabilistic circuit representation, and the MinMax transform $f(x) = \\min(b, \\max(a, x))$, relevant for recommender systems. The proposed framework flexibly supports diverse loss functions, including least squares, $\\ell_1$ norm, and the Kullback-Leibler divergence, and can be readily extended to other nonlinearities and metrics. We illustrate the applicability, efficiency, and adaptability of the approach on real-world datasets, highlighting its potential for a broad range of applications."}
{"id": "2512.17553", "pdf": "https://arxiv.org/pdf/2512.17553", "abs": "https://arxiv.org/abs/2512.17553", "authors": ["Guglielmo Del Col", "V√§in√∂ Karjalainen", "Teemu Hakala", "Yibo Zhang", "Eija Honkavaara"], "title": "Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous aerial navigation in dense natural environments remains challenging due to limited visibility, thin and irregular obstacles, GNSS-denied operation, and frequent perceptual degradation. This work presents an improved deep learning-based navigation framework that integrates semantically enhanced depth encoding with neural motion-primitive evaluation for robust flight in cluttered forests. Several modules are incorporated on top of the original sevae-ORACLE algorithm to address limitations observed during real-world deployment, including lateral control for sharper maneuvering, a temporal consistency mechanism to suppress oscillatory planning decisions, a stereo-based visual-inertial odometry solution for drift-resilient state estimation, and a supervisory safety layer that filters unsafe actions in real time. A depth refinement stage is included to improve the representation of thin branches and reduce stereo noise, while GPU optimization increases onboard inference throughput from 4 Hz to 10 Hz.\n  The proposed approach is evaluated against several existing learning-based navigation methods under identical environmental conditions and hardware constraints. It demonstrates higher success rates, more stable trajectories, and improved collision avoidance, particularly in highly cluttered forest settings. The system is deployed on a custom quadrotor in three boreal forest environments, achieving fully autonomous completion in all flights in moderate and dense clutter, and 12 out of 15 flights in highly dense underbrush. These results demonstrate improved reliability and safety over existing navigation methods in complex natural environments."}
{"id": "2512.17679", "pdf": "https://arxiv.org/pdf/2512.17679", "abs": "https://arxiv.org/abs/2512.17679", "authors": ["Zhou Lu", "Mohammed El-Hajjar", "Lie-liang Yang"], "title": "Augmented Affine Frequency Division Multiplexing for Both Low PAPR Signaling and Diversity Gain Protection", "categories": ["eess.SP"], "comment": null, "summary": "Research results on Affine Frequency Division Multiplexing (AFDM) reveal that it experiences the same Peak-to-Average Power Ratio (PAPR) problem as conventional Orthogonal Frequency-Division Multiplexing (OFDM). On the other side, some references and also our studies demonstrate that AFDM involves an unneeded matrix, which is based on a parameter typically represented by $c_2$, for signalling. Hence, in this paper, an augmented AFDM scheme, referred to as A$^2$FDM, is proposed to mitigate the PAPR problem of AFDM, which is achieved by replacing the $c_2$ matrix in AFDM by a new unitary matrix that performs both sub-block-based Discrete Fourier Transform (DFT) and symbol mapping. Two symbol mapping schemes, namely interleaved mapping and localized mapping, are proposed for implementing A$^2$FDM, yielding the Interleaved A$^2$FDM and Localized A$^2$FDM. The input-output relationships of these schemes are derived and the complexity and the effects of system parameters on the performance of A$^2$FDM along with AFDM systems are analyzed. Furthermore, simulation results are provided to demonstrate and compare comprehensively the performance of the considered schemes in conjunction with different system settings and various operational conditions. Our studies and results demonstrate that, while A$^2$FDM is capable of circumventing the PAPR problem faced by AFDM, it is capable of attaining the achievable diversity gain, when AFDM is operated in its undesirable conditions resulting in the loss of the diversity gain available."}
{"id": "2512.17560", "pdf": "https://arxiv.org/pdf/2512.17560", "abs": "https://arxiv.org/abs/2512.17560", "authors": ["M. Faroni", "A. Spano", "A. M. Zanchettin", "P. Rocco"], "title": "Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration", "categories": ["cs.RO"], "comment": "8 pages", "summary": "Ensuring human safety in collaborative robotics can compromise efficiency because traditional safety measures increase robot cycle time when human interaction is frequent. This paper proposes a safety-aware approach to mitigate efficiency losses without assuming prior knowledge of safety logic. Using a deep-learning model, the robot learns the relationship between system state and safety-induced speed reductions based on execution data. Our framework does not explicitly predict human motions but directly models the interaction effects on robot speed, simplifying implementation and enhancing generalizability to different safety logics. At runtime, the learned model optimizes task selection to minimize cycle time while adhering to safety requirements. Experiments on a pick-and-packaging scenario demonstrated significant reductions in cycle times."}
{"id": "2512.17831", "pdf": "https://arxiv.org/pdf/2512.17831", "abs": "https://arxiv.org/abs/2512.17831", "authors": ["Zixin Wang", "Ishfaq Aziz", "Mohamad Alipour"], "title": "Bridging simulation and reality in subsurface radar-based sensing: physics-guided hierarchical domain adaptation with deep adversarial learning", "categories": ["eess.SP"], "comment": null, "summary": "Accurate estimation of subsurface material properties, such as soil moisture, is critical for wildfire risk assessment and precision agriculture. Ground-penetrating radar (GPR) is a non-destructive geophysical technique widely used to characterize subsurface conditions. Data-driven parameter estimation methods typically require large amounts of labeled training data, which is expensive to obtain from real-world GPR scans under diverse subsurface conditions. A physics-based GPR model using the finite-difference time-domain (FDTD) method can be employed to generate large synthetic datasets through simulations across varying material parameters, which are then utilized to train data-driven models. A key limitation, however, is that simulated data (source domain) and real-world data (target domain) often follow different distributions, which can cause data-driven models trained on simulations to underperform in real-world scenarios. To address this challenge, this study proposes a novel physics-guided hierarchical domain adaptation framework with deep adversarial learning for robust subsurface material property estimation from GPR signals. The proposed framework is systematically evaluated through the laboratory tests for single- and two-layer materials, as well as the field tests for single- and two-layer materials, and is benchmarked against state-of-the-art methods, including the one-dimensional convolutional neural network (1D CNN) and domain adversarial neural network (DANN). The results demonstrate that the proposed framework achieves higher correlation coefficients R and lower Bias between the predicted and measured parameter values, along with smaller standard deviations in the estimations, thereby validating their effectiveness in bridging the domain gap between simulated and real-world radar signals and enabling efficient subsurface material property retrieval."}
{"id": "2512.17568", "pdf": "https://arxiv.org/pdf/2512.17568", "abs": "https://arxiv.org/abs/2512.17568", "authors": ["Kangchen Lv", "Mingrui Yu", "Yongyi Jia", "Chenyu Zhang", "Xiang Li"], "title": "Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation", "categories": ["cs.RO"], "comment": "The first two authors contributed equally. Project Website: https://kinematics-aware-diffusion-policy.github.io", "summary": "Whole-body control of robotic manipulators with awareness of full-arm kinematics is crucial for many manipulation scenarios involving body collision avoidance or body-object interactions, which makes it insufficient to consider only the end-effector poses in policy learning. The typical approach for whole-arm manipulation is to learn actions in the robot's joint space. However, the unalignment between the joint space and actual task space (i.e., 3D space) increases the complexity of policy learning, as generalization in task space requires the policy to intrinsically understand the non-linear arm kinematics, which is difficult to learn from limited demonstrations. To address this issue, this letter proposes a kinematics-aware imitation learning framework with consistent task, observation, and action spaces, all represented in the same 3D space. Specifically, we represent both robot states and actions using a set of 3D points on the arm body, naturally aligned with the 3D point cloud observations. This spatially consistent representation improves the policy's sample efficiency and spatial generalizability while enabling full-body control. Built upon the diffusion policy, we further incorporate kinematics priors into the diffusion processes to guarantee the kinematic feasibility of output actions. The joint angle commands are finally calculated through an optimization-based whole-body inverse kinematics solver for execution. Simulation and real-world experimental results demonstrate higher success rates and stronger spatial generalizability of our approach compared to existing methods in body-aware manipulation policy learning."}
{"id": "2512.17835", "pdf": "https://arxiv.org/pdf/2512.17835", "abs": "https://arxiv.org/abs/2512.17835", "authors": ["The Khai Nguyen", "Ebrahim Bedeer"], "title": "Novel Double-Chirp Preamble Design for Multiuser Asynchronous Massive MIMO LoRa Networks", "categories": ["eess.SP"], "comment": "13 pages, 12 figures", "summary": "This paper proposes a novel preamble design and detection method for multiuser asynchronous massive MIMO LoRa networks. Unlike existing works, which only consider the preamble detection for a single target end devices (ED), we proposed to simultaneously detect the preambles of multiple EDs that asynchronously transmit their uplink (UL) packets to a multiple-antenna gateway (GW). First we show that the preamble detection in multiuser LoRa networks with the conventional single-chirp preamble suffers from the so-called preamble resemblance effect. This means that the preamble of any single ED can resemble the preambles of all EDs in the network, and make it impossible to determine to which ED a preamble belongs. To address this problem, a novel double-chirp preamble design and a preamble assignment method are proposed, which can mitigate the preamble resemblance effect by making the preamble of each ED unique and recognizable. Next, a maximum-likelihood (ML) based detection scheme for the proposed double-chirp preamble is derived. Finally, since the proposed algorithm requires the calculation of the discrete Fourier transform (DFT) every sampling period, we proposed a low-complexity technique to calculate the DFT recursively to reduce the complexity of our proposed design. Simulation shows that the proposed preamble detection design and detection requires just about 2 dB more power to increase the number of EDs from one to 15 in the Rayleigh fading channel while achieving the same preamble detection error performance."}
{"id": "2512.17579", "pdf": "https://arxiv.org/pdf/2512.17579", "abs": "https://arxiv.org/abs/2512.17579", "authors": ["Marco Faroni", "Alessio Span√≤", "Andrea M. Zanchettin", "Paolo Rocco"], "title": "On Using Neural Networks to Learn Safety Speed Reduction in Human-Robot Collaboration: A Comparative Analysis", "categories": ["cs.RO"], "comment": "Accepted at IEEE Internation Conference on Emerging Technologies and Factory Automation (ETFA) 2025", "summary": "In Human-Robot Collaboration, safety mechanisms such as Speed and Separation Monitoring and Power and Force Limitation dynamically adjust the robot's speed based on human proximity. While essential for risk reduction, these mechanisms introduce slowdowns that makes cycle time estimation a hard task and impact job scheduling efficiency. Existing methods for estimating cycle times or designing schedulers often rely on predefined safety models, which may not accurately reflect real-world safety implementations, as these depend on case-specific risk assessments. In this paper, we propose a deep learning approach to predict the robot's safety scaling factor directly from process execution data. We analyze multiple neural network architectures and demonstrate that a simple feed-forward network effectively estimates the robot's slowdown. This capability is crucial for improving cycle time predictions and designing more effective scheduling algorithms in collaborative robotic environments."}
{"id": "2512.16929", "pdf": "https://arxiv.org/pdf/2512.16929", "abs": "https://arxiv.org/abs/2512.16929", "authors": ["Pranesh Sathish Kumar"], "title": "BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control", "categories": ["cs.LG", "eess.SP"], "comment": "12 pages, 8 figures", "summary": "Affordable upper-limb prostheses often lack intuitive control systems, limiting functionality and accessibility for amputees in low-resource settings. This project presents a low-cost, dual-mode neuro-muscular control system integrating electroencephalography (EEG) and electromyography (EMG) to enable real-time, multi-degree-of-freedom control of a prosthetic arm. EEG signals are acquired using the NeuroSky MindWave Mobile 2 and transmitted via ThinkGear Bluetooth packets to an ESP32 microcontroller running a lightweight classification model. The model was trained on 1500 seconds of recorded EEG data using a 6-frame sliding window with low-pass filtering, excluding poor-signal samples and using a 70/20/10 training--validation--test split. The classifier detects strong blink events, which toggle the hand between open and closed states. EMG signals are acquired using a MyoWare 2.0 sensor and SparkFun wireless shield and transmitted to a second ESP32, which performs threshold-based detection. Three activation bands (rest: 0--T1; extension: T1--T2; contraction: greater than T2) enable intuitive elbow control, with movement triggered only after eight consecutive frames in a movement class to improve stability. The EEG-controlled ESP32 actuates four finger servos, while the EMG-controlled ESP32 drives two elbow servos. A functional prototype was constructed using low-cost materials (total cost approximately 240 dollars), with most expense attributed to the commercial EEG headset. Future work includes transitioning to a 3D-printed chassis, integrating auto-regressive models to reduce EMG latency, and upgrading servo torque for improved load capacity and grip strength. This system demonstrates a feasible pathway to low-cost, biologically intuitive prosthetic control suitable for underserved and global health applications."}
{"id": "2512.17584", "pdf": "https://arxiv.org/pdf/2512.17584", "abs": "https://arxiv.org/abs/2512.17584", "authors": ["Christian Cella", "Sole Ester Sonnino", "Marco Faroni", "Andrea Zanchettin", "Paolo Rocco"], "title": "Optimized Scheduling and Positioning of Mobile Manipulators in Collaborative Applications", "categories": ["cs.RO"], "comment": "Accepted at The IFAC Joint Conference on Computers, Cognition and Communication (J3C) 2025", "summary": "The growing integration of mobile robots in shared workspaces requires efficient path planning and coordination between the agents, accounting for safety and productivity. In this work, we propose a digital model-based optimization framework for mobile manipulators in human-robot collaborative environments, in order to determine the sequence of robot base poses and the task scheduling for the robot. The complete problem is treated as black-box, and Particle Swarm Optimization (PSO) is employed to balance conflicting Key-Performance Indicators (KPIs). We demonstrate improvements in cycle time, task sequencing, and adaptation to human presence in a collaborative box-packing scenario."}
{"id": "2512.17107", "pdf": "https://arxiv.org/pdf/2512.17107", "abs": "https://arxiv.org/abs/2512.17107", "authors": ["Zenan Yang", "Yuanliang Li", "Jingwei Zhang", "Yongjie Liu", "Kun Ding"], "title": "Fault Diagnosis and Quantification for Photovoltaic Arrays based on Differentiable Physical Models", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Accurate fault diagnosis and quantification are essential for the reliable operation and intelligent maintenance of photovoltaic (PV) arrays. However, existing fault quantification methods often suffer from limited efficiency and interpretability. To address these challenges, this paper proposes a novel fault quantification approach for PV strings based on a differentiable fast fault simulation model (DFFSM). The proposed DFFSM accurately models I-V characteristics under multiple faults and provides analytical gradients with respect to fault parameters. Leveraging this property, a gradient-based fault parameters identification (GFPI) method using the Adahessian optimizer is developed to efficiently quantify partial shading, short-circuit, and series-resistance degradation. Experimental results on both simulated and measured I-V curves demonstrate that the proposed GFPI achieves high quantification accuracy across different faults, with the I-V reconstruction error below 3%, confirming the feasibility and effectiveness of the application of differentiable physical simulators for PV system fault diagnosis."}
{"id": "2512.17661", "pdf": "https://arxiv.org/pdf/2512.17661", "abs": "https://arxiv.org/abs/2512.17661", "authors": ["Yao Feng", "Chendong Xiang", "Xinyi Mao", "Hengkai Tan", "Zuyue Zhang", "Shuhe Huang", "Kaiwen Zheng", "Haitian Liu", "Hang Su", "Jun Zhu"], "title": "Vidarc: Embodied Video Diffusion Model for Closed-loop Control", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Robotic arm manipulation in data-scarce settings is a highly challenging task due to the complex embodiment dynamics and diverse contexts. Recent video-based approaches have shown great promise in capturing and transferring the temporal and physical interactions by pre-training on Internet-scale video data. However, such methods are often not optimized for the embodiment-specific closed-loop control, typically suffering from high latency and insufficient grounding. In this paper, we present Vidarc (Video Diffusion for Action Reasoning and Closed-loop Control), a novel autoregressive embodied video diffusion approach augmented by a masked inverse dynamics model. By grounding video predictions with action-relevant masks and incorporating real-time feedback through cached autoregressive generation, Vidarc achieves fast, accurate closed-loop control. Pre-trained on one million cross-embodiment episodes, Vidarc surpasses state-of-the-art baselines, achieving at least a 15% higher success rate in real-world deployment and a 91% reduction in latency. We also highlight its robust generalization and error correction capabilities across previously unseen robotic platforms."}
{"id": "2512.17421", "pdf": "https://arxiv.org/pdf/2512.17421", "abs": "https://arxiv.org/abs/2512.17421", "authors": ["Sourav Banerjee", "Neel Kanth Kundu"], "title": "Rydberg Atomic RF Sensor-based Quantum Radar", "categories": ["quant-ph", "eess.SP"], "comment": null, "summary": "Rydberg atom-based RF sensors offer distinct advantages over conventional dipole antennas for electric field detection. This paper presents a system model and performance analysis of a Rydberg atom-based quantum radar, which employs optical readout via lasers and photon detectors instead of circuit-based receivers. We derive the signal-to-noise ratio (SNR), compare it with classical radar, and estimate Doppler frequency using an invariant function-based method. Simulations show that the quantum radar achieves higher SNR and lower RMSE in velocity estimation than conventional radar."}
{"id": "2512.17680", "pdf": "https://arxiv.org/pdf/2512.17680", "abs": "https://arxiv.org/abs/2512.17680", "authors": ["Ana Stankovic", "Mohamed Khalil Ben-Larbi", "Wolfgang H. M√ºller"], "title": "A Dual Quaternion based RRT* Path Planning Approach for Satellite Rendezvous and Docking", "categories": ["cs.RO"], "comment": "6 pages, CAMSAT 2025, This work has been accepted to IFAC", "summary": "This paper proposes a sampling-based motion planner that employs a dual quaternion representation to generate smooth, collision-free six-degree-of-freedom pose trajectories for satellite rendezvous and docking under keep-out zone constraints. The proposed planner integrates the dual quaternion algebra directly into an RRT* framework, thereby enabling natural screw motion interpolation in SE(3). The dual quaternion-based RRT* has been implemented in Python and demonstrated on a representative multi-obstacle scenario. A comparison with a standard RRT* using separate translation and quaternion steering highlights the enhanced pose continuity and obstacle avoidance of the proposed method. The present approach is purely kinematic in nature and does not take into account relative orbital dynamics. Consequently, the resulting path provides a preliminary estimate for a subsequent optimisation-based trajectory planner, which will refine the motion with dynamic constraints for the purpose of practical satellite rendezvous and docking missions."}
{"id": "2512.17834", "pdf": "https://arxiv.org/pdf/2512.17834", "abs": "https://arxiv.org/abs/2512.17834", "authors": ["Darja Nonaca", "J√©r√©my Guichemerre", "Reinhard Wiesmayr", "Nihat Engin Tunali", "Christoph Studer"], "title": "A 14ns-Latency 9Gb/s 0.44mm$^2$ 62pJ/b Short-Blocklength LDPC Decoder ASIC in 22FDX", "categories": ["cs.AR", "eess.SP"], "comment": "Presented at the 2025 IEEE European Solid-State Electronics Research Conference (ESSERC)", "summary": "Ultra-reliable low latency communication (URLLC) is a key part of 5G wireless systems. Achieving low latency necessitates codes with short blocklengths for which polar codes with successive cancellation list (SCL) decoding typically outperform message-passing (MP)-based decoding of low-density parity-check (LDPC) codes. However, SCL decoders are known to exhibit high latency and poor area efficiency. In this paper, we propose a new short-blocklength multi-rate binary LDPC code that outperforms the 5G-LDPC code for the same blocklength and is suitable for URLLC applications using fully parallel MP. To demonstrate our code's efficacy, we present a 0.44mm$^2$ GlobalFoundries 22FDX LDPC decoder ASIC which supports three rates and achieves the lowest-in-class decoding latency of 14ns while reaching an information throughput of 9Gb/s at 62pJ/b energy efficiency for a rate-1/2 code with 128-bit blocklength."}
{"id": "2512.17764", "pdf": "https://arxiv.org/pdf/2512.17764", "abs": "https://arxiv.org/abs/2512.17764", "authors": ["Kangchen Lv", "Mingrui Yu", "Shihefeng Wang", "Xiangyang Ji", "Xiang Li"], "title": "UniStateDLO: Unified Generative State Estimation and Tracking of Deformable Linear Objects Under Occlusion for Constrained Manipulation", "categories": ["cs.RO"], "comment": "The first two authors contributed equally. Project page: https://unistatedlo.github.io", "summary": "Perception of deformable linear objects (DLOs), such as cables, ropes, and wires, is the cornerstone for successful downstream manipulation. Although vision-based methods have been extensively explored, they remain highly vulnerable to occlusions that commonly arise in constrained manipulation environments due to surrounding obstacles, large and varying deformations, and limited viewpoints. Moreover, the high dimensionality of the state space, the lack of distinctive visual features, and the presence of sensor noises further compound the challenges of reliable DLO perception. To address these open issues, this paper presents UniStateDLO, the first complete DLO perception pipeline with deep-learning methods that achieves robust performance under severe occlusion, covering both single-frame state estimation and cross-frame state tracking from partial point clouds. Both tasks are formulated as conditional generative problems, leveraging the strong capability of diffusion models to capture the complex mapping between highly partial observations and high-dimensional DLO states. UniStateDLO effectively handles a wide range of occlusion patterns, including initial occlusion, self-occlusion, and occlusion caused by multiple objects. In addition, it exhibits strong data efficiency as the entire network is trained solely on a large-scale synthetic dataset, enabling zero-shot sim-to-real generalization without any real-world training data. Comprehensive simulation and real-world experiments demonstrate that UniStateDLO outperforms all state-of-the-art baselines in both estimation and tracking, producing globally smooth yet locally precise DLO state predictions in real time, even under substantial occlusions. Its integration as the front-end module in a closed-loop DLO manipulation system further demonstrates its ability to support stable feedback control in complex, constrained 3-D environments."}
{"id": "2512.17890", "pdf": "https://arxiv.org/pdf/2512.17890", "abs": "https://arxiv.org/abs/2512.17890", "authors": ["Callum Deakin", "Xi Chen"], "title": "Spectro-temporal unitary transformations for coherent modulation: design trade-offs and practical considerations", "categories": ["physics.optics", "eess.SP"], "comment": "9 pages, 10 figures", "summary": "This paper analyzes the performance of spectro-temporal unitary transforms for coherent optical modulation. Unlike conventional IQ modulation, such transforms are based on a cascade of phase modulators and dispersive elements, so are theoretically lossless and not limited by the bandwidth of the constituent modulators. We analyse the performance limits and design trade-offs of this scheme: estimating how the number of stages, amount of dispersion, modulator bandwidth, symbol block length and electrical signal power impacts the achievable signal-to-distortion ratio (SDR). Importantly, we show that high (>30 dB) SDRs suitable for modern >200 GBd class coherent optical communications are achievable with a low (<6) number of stages and reasonable parameters for driver power, modulator bandwidth and on-chip dispersion. Finally we address the SDR penalties associated with potential phase, amplitude, or dispersion errors, and limited DAC resolution."}
{"id": "2512.17846", "pdf": "https://arxiv.org/pdf/2512.17846", "abs": "https://arxiv.org/abs/2512.17846", "authors": ["Carlos V√©lez Garc√≠a", "Miguel Cazorla", "Jorge Pomares"], "title": "Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present Planning as Descent (PaD), a framework for offline goal-conditioned reinforcement learning that grounds trajectory synthesis in verification. Instead of learning a policy or explicit planner, PaD learns a goal-conditioned energy function over entire latent trajectories, assigning low energy to feasible, goal-consistent futures. Planning is realized as gradient-based refinement in this energy landscape, using identical computation during training and inference to reduce train-test mismatch common in decoupled modeling pipelines.\n  PaD is trained via self-supervised hindsight goal relabeling, shaping the energy landscape around the planning dynamics. At inference, multiple trajectory candidates are refined under different temporal hypotheses, and low-energy plans balancing feasibility and efficiency are selected.\n  We evaluate PaD on OGBench cube manipulation tasks. When trained on narrow expert demonstrations, PaD achieves state-of-the-art 95\\% success, strongly outperforming prior methods that peak at 68\\%. Remarkably, training on noisy, suboptimal data further improves success and plan efficiency, highlighting the benefits of verification-driven planning. Our results suggest learning to evaluate and refine trajectories provides a robust alternative to direct policy learning for offline, reward-free planning."}
{"id": "2512.17853", "pdf": "https://arxiv.org/pdf/2512.17853", "abs": "https://arxiv.org/abs/2512.17853", "authors": ["Ran Gong", "Xiaohan Zhang", "Jinghuan Shang", "Maria Vittoria Minniti", "Jigarkumar Patel", "Valerio Pepe", "Riedana Yan", "Ahmet Gundogdu", "Ivan Kapelyukh", "Ali Abbas", "Xiaoqiang Yan", "Harsh Patel", "Laura Herlant", "Karl Schmeckpeper"], "title": "AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning", "categories": ["cs.RO", "cs.AI"], "comment": "28 pages, 25 figures. The first four authors contributed equally", "summary": "Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com ."}
{"id": "2512.16926", "pdf": "https://arxiv.org/pdf/2512.16926", "abs": "https://arxiv.org/abs/2512.16926", "authors": ["Oren Bell", "Harun Teper", "Mario G√ºnzel", "Chris Gill", "Jian-Jia Chen"], "title": "Fixed-Priority and EDF Schedules for ROS2 Graphs on Uniprocessor", "categories": ["cs.DC", "cs.OS", "cs.RO", "cs.SE"], "comment": "18 pages, 5 figure", "summary": "This paper addresses limitations of current scheduling methods in the Robot Operating System (ROS)2, focusing on scheduling tasks beyond simple chains and analyzing arbitrary Directed Acyclic Graphs (DAGs). While previous research has focused mostly on chain-based scheduling with ad-hoc response time analyses, we propose a novel approach using the events executor to implement fixed-job-level-priority schedulers for arbitrary ROS2 graphs on uniprocessor systems. We demonstrate that ROS 2 applications can be abstracted as forests of trees, enabling the mapping of ROS 2 applications to traditional real-time DAG task models. Our usage of the events executor requires a special implementation of the events queue and a communication middleware that supports LIFO-ordered message delivery, features not yet standard in ROS2. We show that our implementation generates the same schedules as a conventional fixed-priority DAG task scheduler, in spite of lacking access to the precedence information that usually is required. This further closes the gap between established real-time systems theory and ROS2 scheduling analyses."}
{"id": "2512.17091", "pdf": "https://arxiv.org/pdf/2512.17091", "abs": "https://arxiv.org/abs/2512.17091", "authors": ["Toshiaki Hori", "Jonathan DeCastro", "Deepak Gopinath", "Avinash Balachandran", "Guy Rosman"], "title": "Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "23 pages, 8 figures. Under review", "summary": "We propose a new approach for solving planning problems with a hierarchical structure, fusing reinforcement learning and MPC planning. Our formulation tightly and elegantly couples the two planning paradigms. It leverages reinforcement learning actions to inform the MPPI sampler, and adaptively aggregates MPPI samples to inform the value estimation. The resulting adaptive process leverages further MPPI exploration where value estimates are uncertain, and improves training robustness and the overall resulting policies. This results in a robust planning approach that can handle complex planning problems and easily adapts to different applications, as demonstrated over several domains, including race driving, modified Acrobot, and Lunar Lander with added obstacles. Our results in these domains show better data efficiency and overall performance in terms of both rewards and task success, with up to a 72% increase in success rate compared to existing approaches, as well as accelerated convergence (x2.1) compared to non-adaptive sampling."}
{"id": "2512.17129", "pdf": "https://arxiv.org/pdf/2512.17129", "abs": "https://arxiv.org/abs/2512.17129", "authors": ["Seong Ho Pahng", "Guoye Guan", "Benjamin Fefferman", "Sahand Hormoz"], "title": "DiffeoMorph: Learning to Morph 3D Shapes Using Differentiable Agent-Based Simulations", "categories": ["cs.LG", "cs.MA", "cs.RO", "q-bio.QM"], "comment": null, "summary": "Biological systems can form complex three-dimensional structures through the collective behavior of identical agents -- cells that follow the same internal rules and communicate without central control. How such distributed control gives rise to precise global patterns remains a central question not only in developmental biology but also in distributed robotics, programmable matter, and multi-agent learning. Here, we introduce DiffeoMorph, an end-to-end differentiable framework for learning a morphogenesis protocol that guides a population of agents to morph into a target 3D shape. Each agent updates its position and internal state using an attention-based SE(3)-equivariant graph neural network, based on its own internal state and signals received from other agents. To train this system, we introduce a new shape-matching loss based on the 3D Zernike polynomials, which compares the predicted and target shapes as continuous spatial distributions, not as discrete point clouds, and is invariant to agent ordering, number of agents, and rigid-body transformations. To enforce full SO(3) invariance -- invariant to rotations yet sensitive to reflections, we include an alignment step that optimally rotates the predicted Zernike spectrum to match the target before computing the loss. This results in a bilevel problem, with the inner loop optimizing a unit quaternion for the best alignment and the outer loop updating the agent model. We compute gradients through the alignment step using implicit differentiation. We perform systematic benchmarking to establish the advantages of our shape-matching loss over other standard distance metrics for shape comparison tasks. We then demonstrate that DiffeoMorph can form a range of shapes -- from simple ellipsoids to complex morphologies -- using only minimal spatial cues."}
{"id": "2512.17586", "pdf": "https://arxiv.org/pdf/2512.17586", "abs": "https://arxiv.org/abs/2512.17586", "authors": ["Mahesh Keswani", "Raunak Bhattacharyya"], "title": "Learning Safe Autonomous Driving Policies Using Predictive Safety Representations", "categories": ["cs.LG", "cs.RO"], "comment": "8 pages, 4 figures. Submitted to ICRA 2026", "summary": "Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving."}
{"id": "2512.17897", "pdf": "https://arxiv.org/pdf/2512.17897", "abs": "https://arxiv.org/abs/2512.17897", "authors": ["Tomer Borreda", "Fangqiang Ding", "Sanja Fidler", "Shengyu Huang", "Or Litany"], "title": "RadarGen: Automotive Radar Point Cloud Generation from Cameras", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project page: https://radargen.github.io/", "summary": "We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities."}
{"id": "2512.17900", "pdf": "https://arxiv.org/pdf/2512.17900", "abs": "https://arxiv.org/abs/2512.17900", "authors": ["Vongani H. Maluleke", "Kie Horiuchi", "Lea Wilken", "Evonne Ng", "Jitendra Malik", "Angjoo Kanazawa"], "title": "Diffusion Forcing for Multi-Agent Interaction Sequence Modeling", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Understanding and generating multi-person interactions is a fundamental challenge with broad implications for robotics and social computing. While humans naturally coordinate in groups, modeling such interactions remains difficult due to long temporal horizons, strong inter-agent dependencies, and variable group sizes. Existing motion generation methods are largely task-specific and do not generalize to flexible multi-agent generation. We introduce MAGNet (Multi-Agent Diffusion Forcing Transformer), a unified autoregressive diffusion framework for multi-agent motion generation that supports a wide range of interaction tasks through flexible conditioning and sampling. MAGNet performs dyadic prediction, partner inpainting, and full multi-agent motion generation within a single model, and can autoregressively generate ultra-long sequences spanning hundreds of v. Building on Diffusion Forcing, we introduce key modifications that explicitly model inter-agent coupling during autoregressive denoising, enabling coherent coordination across agents. As a result, MAGNet captures both tightly synchronized activities (e.g, dancing, boxing) and loosely structured social interactions. Our approach performs on par with specialized methods on dyadic benchmarks while naturally extending to polyadic scenarios involving three or more interacting people, enabled by a scalable architecture that is agnostic to the number of agents. We refer readers to the supplemental video, where the temporal dynamics and spatial coordination of generated interactions are best appreciated. Project page: https://von31.github.io/MAGNet/"}
