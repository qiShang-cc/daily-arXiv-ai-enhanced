<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [cs.RO](#cs.RO) [Total: 14]
- [cs.NI](#cs.NI) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems](https://arxiv.org/abs/2508.15257)
*Eduard E. Bahingayi,Shuying Lin,Murat Uysal,Marco Di Renzo,Le-Nam Tran*

Main category: eess.SP

TL;DR: 本文研究了基于堆叠智能超表面（SIM）的多用户MISO下行链路系统的总和率最大化问题，提出了改进交替优化（AO）框架的设计指南，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索堆叠智能超表面（SIM）在无线网络中的潜力，解决现有交替优化方法在固定SIM厚度下性能饱和的问题。

Method: 提出先优化SIM相位偏移，再使用迭代投影梯度（PG）方法优化数字预编码器，改进传统的交替优化框架。

Result: 通过提出的方法，系统的可实现总和率（ASR）提升了115.53%，显著优于基准方案。

Conclusion: 优化顺序和迭代PG方法对性能提升至关重要，为SIM系统的设计提供了实用指南。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive
technology for future wireless networks. To investigate their capabilities, we
study the sum rate maximization problem in an SIM-based multiuser (MU)
multiple-input single-output (MISO) downlink system. A vast majority of pioneer
studies, if not all, address this fundamental problem using the prevailing
alternating optimization (AO) framework, where the digital beamforming (DB) and
SIM phase shifts are optimized alternately. However, many of these approaches
suffer from suboptimal performance, quickly leading to performance saturation,
when the number of SIM layers increases assuming the \emph{fixed SIM
thickness}. In this letter, we demonstrate that significant performance gains
can still be achieved, and such saturation does not occur with the proposed
method in the considered setting. To this end, we provide practical design
guidelines to improve AO-based optimization of digital precoders and SIM phase
shifts. Specifically, we show that (i) optimizing the SIM phase shifts first
yields significant performance improvements, compared to optimizing the DB
first; and (ii) when applying projected gradient (PG) methods, which are
gradually becoming more popular to optimize the phase shifts thanks to their
scalability, we find that using an iterative PG method achieves better
performance than the single PG step, which is commonly used in existing
solutions. Based on these customizations, the proposed method achieves a higher
achievable sum rate (ASR) of up to $\ensuremath{115.53\%}$, compared to
benchmark schemes for the scenarios under consideration.

</details>


### [2] [Performance Analysis of RIS-Aided High-Mobility Wireless Systems](https://arxiv.org/abs/2508.15375)
*Hanwen Hu,Jiancheng An,Lu Gan,Chau Yuen*

Main category: eess.SP

TL;DR: 该论文研究了在高机动性场景中使用可重构智能表面（RIS）技术提升高速列车（HST）通信系统性能的方法。提出的BCD算法优化了RIS相位和发射波束成形，显著提高了信道增益。


<details>
  <summary>Details</summary>
Motivation: RIS技术有潜力解决高机动性场景（如高速列车）中的通信挑战，如多普勒频移和快速衰落。

Method: 采用块坐标下降（BCD）算法联合优化RIS相位和发射波束成形向量，以最大化信道增益。

Result: 数值结果表明，该算法使信道增益平均提高了15 dB，消除了中断概率，并改善了信道容量和误码率等关键指标。

Conclusion: RIS在提升高速列车通信系统性能中起到关键作用。

Abstract: Reconfigurable intelligent surface (RIS) technology holds immense potential
for increasing the performance of wireless networks. Therefore, RIS is also
regarded as one of the solutions to address communication challenges in
high-mobility scenarios, such as Doppler shift and fast fading. This paper
investigates a high-speed train (HST) multiple-input single-output (MISO)
communication system aided by a RIS. We propose a block coordinate descent
(BCD) algorithm to jointly optimize the RIS phase shifts and the transmit
beamforming vectors to maximize the channel gain. Numerical results are
provided to demonstrate that the proposed algorithm significantly enhances the
system performance, achieving an average channel gain improvement of 15 dB
compared to traditional schemes. Additionally, the introduction of RIS
eliminates outage probability and improves key performance metrics such as
achievable rate, channel capacity, and bit error rate (BER). These findings
highlight the critical role of RIS in enhancing HST communication systems.

</details>


### [3] [Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems](https://arxiv.org/abs/2508.15544)
*Pedro H. C. de Souza,Luiz A. M. Pereira,Faustino R. Gómez,Elsa M. Materón,Jorge Ricardo Mejía-Salazar*

Main category: eess.SP

TL;DR: 本文探讨了6G移动网络中可重构智能表面（RIS）面临的硬件不完美问题及其优化方案。


<details>
  <summary>Details</summary>
Motivation: RIS作为一种改善信号传播的技术，其硬件不完美可能影响实际应用，需分析并解决。

Method: 采用梯度下降优化方法，针对RIS辅助宽带通信系统中的硬件不完美进行补偿。

Result: 数值结果表明该方法能有效缓解相移噪声和表面形变等硬件问题。

Conclusion: 梯度下降优化为RIS的硬件不完美提供了可行的解决方案，有助于其实用化。

Abstract: Ongoing discussions about the future of wireless communications are reaching
a turning point as standardization activities for the sixth generation of
mobile networks (6G) become more mature. New technologies must now face renewed
scrutiny by the industry and academia in order to be ready for deployment in
the near future. Recently, reconfigurable intelligent surfaces (RISs) gained
attention as a promising solution for improving the propagation conditions of
signal transmission in general. The RIS is a planar array of tunable resonant
elements designed to dynamically and precisely manipulate the reflection of
incident electromagnetic waves. However, the physical structure of the RIS and
its components may be subject to practical limitations and imperfections. It is
imperative that the hardware imperfections (HWIs) associated with the RIS be
analyzed, so that it remains a feasible technology from a practical standpoint.
Moreover, solutions for mitigating the HWIs must be considered, as is discussed
in this work. More specifically, we introduce a gradient descent optimization
for mitigating HWIs in RIS-aided wideband communication systems. Numerical
results show that the proposed optimization is able to compensate for HWIs such
as the phase-shift noise (PSN) and RIS surface deformations.

</details>


### [4] [Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2508.15581)
*Pedro H. C. de Souza,Luciano Mendes*

Main category: eess.SP

TL;DR: 提出了一种针对宽带信号的可重构智能表面（RIS）频率选择性反射配置方法，解决了其带宽限制问题。


<details>
  <summary>Details</summary>
Motivation: RIS技术虽然能通过可控反射改善信号接收，但其对宽带信号的带宽限制可能阻碍其在下一代通信系统中的广泛应用。

Method: 研究提出了一种RIS配置方法，专门针对宽带信号实现频率选择性反射。

Result: 该方法有望解决RIS在处理宽带信号时的潜在带宽限制问题。

Conclusion: 提出的RIS配置方法为宽带信号提供了有效的频率选择性反射，有助于RIS在下一代通信系统中的成功应用。

Abstract: Recently, the reconfigurable intelligent surface (RIS) technology has ushered
in the prospect of control over the wireless propagation environment. By
establishing alternative propagation paths for the transmitted signals, and by
reflecting them in a controllable manner, the RIS is able to improve the signal
reception. However, an aspect often overlooked is the potential bandwidth
restrictions on the wideband signal reflected by the RIS. If not carefully
considered, this can become an impediment for the adoption of the RIS in the
next generation of communications systems. Therefore, in this work we propose a
RIS configuration method that provides frequency selective signal reflection
for wideband signals.

</details>


### [5] [On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems](https://arxiv.org/abs/2508.15599)
*P. H. C. de Souza,M. Khazaee,L. L. Mendes*

Main category: eess.SP

TL;DR: 本文讨论了可重构智能表面（RIS）技术在无线通信系统中的应用，以及其优化配置和扩展功能，如多普勒频移补偿和同时透射反射功能（STAR-RIS）带来的性能提升。


<details>
  <summary>Details</summary>
Motivation: 探索RIS技术在无线通信系统中的潜力，特别是在信道容量优化和多普勒频移补偿方面的应用。

Method: 通过神经网络优化RIS的相位组合配置，并提出STAR-RIS以解决反射限制问题。

Result: 优化后的RIS减少了重新配置的开销，STAR-RIS则提升了覆盖范围、能效和安全性等性能指标。

Conclusion: RIS及其扩展STAR-RIS技术为无线通信系统提供了显著的性能提升和应用潜力。

Abstract: The reconfigurable intelligent surface (RIS) technology for metasurfaces is
ushering in a new paradigm for wireless communication systems. It provides an
accessible way for controlling the interaction between electromagnetic waves
with the propagation medium. One particularly important aspect is the
configuration of the RIS elements or reflectors. Simply stated, the objective
of the RIS configuration is to choose the optimum phase-shift combination that
maximizes the channel capacity. Recently, neural networks (NNs) were proposed
for tackling this task and results have shown that the proposed NN promotes far
less reconfigurations of the RIS, consequently reducing the configuration
overhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift
in high-mobility communication systems. Despite not being its usual primary
goal, results have also demonstrated that the RIS can compensate for the
Doppler shift at a small cost in performance. However, the typical
reflection-only constraint for RIS systems limits the spatial coverage and
signal amplification potential achieved by such systems. Therefore, the
simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) can be employed to address these limitations by its dual
functionality of transmitting and reflecting signals concurrently. It can be
shown that the STAR-RIS can augment coverage, energy efficiency, and latency
reduction, while enhancing sum-rate and physical-layer security across several
wireless contexts.

</details>


### [6] [Discrete Radar based on Modulo Arithmetic](https://arxiv.org/abs/2508.15671)
*Nishant Mehrotra,Sandesh Rao Mattu,Saif Khan Mohammed,Ronny Hadani,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS是一种在延迟-多普勒（DD）域生成信号的调制方案，可用于雷达感知。通过波形设计和离散化处理，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 探索利用Zak-OTFS调制方案的相同架构实现高效的雷达感知，克服传统连续雷达信号处理的高复杂度问题。

Method: 在DD域形成雷达波形，并通过离散化的延迟和多普勒偏移设计波形，利用辛变换优化模糊度表面。

Result: 将计算复杂度从O(B²T²)降低到O(BT log T)，同时设计了峰值平均功率比小的最优雷达波形库。

Conclusion: 离散化的Heisenberg-Weyl群和辛变换为雷达波形设计提供了高效且灵活的解决方案。

Abstract: Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler
(DD) domain, converted to the time domain (DD) for transmission and reception,
then returned to the DD domain for processing. We describe how to use the same
architecture for radar sensing. The intended delay resolution is $\frac{1}{B}$
where $B$ is the radar bandwidth, and the intended Doppler resolution is
$\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in
the DD domain, illuminate the scattering environment, match filter the return,
then correlate with delay and Doppler shifts of the transmitted waveform. This
produces an image of the scattering environment, and the radar ambiguity
function expresses the blurriness of this image. The possible delay and Doppler
shifts generate the continuous Heisenberg-Weyl group which has been widely
studied in the theory of radar. We describe how to approach the problem of
waveform design, not from the perspective of this continuous group, but from
the perspective of a discrete group of delay and Doppler shifts, where the
discretization is determined by the intended delay and Doppler resolution of
the radar. We describe how to approach the problem of shaping the ambiguity
surface through symplectic transformations that normalize our discrete
Heisenberg-Weyl group. The complexity of traditional continuous radar signal
processing is $\mathcal{O}\big(B^2T^2\big)$. We describe how to reduce this
complexity to $\mathcal{O}\big(BT\log T\big)$ by choosing the radar waveform to
be a common eigenvector of a maximal commutative subgroup of our discrete
Heisenberg-Weyl group. The theory of symplectic transformations also enables
defining libraries of optimal radar waveforms with small peak-to-average power
ratios.

</details>


### [7] [A Grant-free Coded Random Access Scheme for Near-field Communications](https://arxiv.org/abs/2508.15673)
*Enrico Testi,Giulia Torcolacci,Nicolò Decarli,Davide Dardari,Enrico Paolini*

Main category: eess.SP

TL;DR: 论文提出了一种结合近场空间复用与编码随机接入（CRA）的新方法，以提高IIoT在6G网络中的可靠性和减少接入延迟。


<details>
  <summary>Details</summary>
Motivation: 工业物联网（IIoT）需要处理大规模和突发流量，现有技术如CRA虽能解决部分问题，但在近场传播和大MIMO阵列的应用场景中仍有优化空间。

Method: 通过极大规模天线阵列和近场空间复用，结合CRA的干扰抑制能力，提出了一种新型接入协议。

Result: 该方法显著提高了IIoT的可靠性，并降低了接入延迟。

Conclusion: 该研究为6G网络中的IIoT连接提供了更高效的框架，展示了近场技术与CRA结合的巨大潜力。

Abstract: The industrial Internet of things (IIoT) is revolutionizing industrial
processes by facilitating massive machine-type communications among countless
interconnected devices. To efficiently handle the resulting large-scale and
sporadic traffic, grant-free random access protocols-especially coded random
access (CRA)-have emerged as scalable and reliable solutions. At the same time,
advancements in wireless hardware, including extremely large-scale MIMO arrays
and high-frequency communication (e.g., mmWave, Terahertz), are pushing network
operations into the near-field propagation regime, allowing for dense
connectivity and enhanced spatial multiplexing. This paper proposes an
innovative approach that combines near-field spatial multiplexing with the
interference mitigation capabilities of CRA, utilizing an extremely large
aperture array at the access point. This integration improves reliability and
reduces access latency, offering a robust framework for IIoT connectivity in
next-generation 6G networks.

</details>


### [8] [Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings](https://arxiv.org/abs/2508.15687)
*Masoud Nateghi,Reza Sameni*

Main category: eess.SP

TL;DR: 研究探讨了振荡法测量血压的系统误差来源，提出了基于最小二乘和最大似然估计的校正方法，以提高测量精度。


<details>
  <summary>Details</summary>
Motivation: 振荡法作为无创血压测量的标准方法存在系统误差，影响临床准确性，因此需要研究误差来源并改进方法。

Method: 使用MIMIC数据库的血压波形数据，分析振荡法和呼吸波动导致的误差，提出最小二乘和最大似然估计框架校正测量。

Result: 最小二乘法支持多测量平均，最大似然法利用误差先验知识，表明统计先验可提升测量精度。

Conclusion: 提出的统计方法可显著改善无创血压监测的准确性，对心血管诊疗有潜在贡献。

Abstract: Oscillometry is the standard method for non-invasive, cuff-based blood
pressure (BP) measurement, but it introduces systematic errors that may impact
clinical accuracy. This study investigates the sources of these
errors--primarily the limitations of oscillometry itself and
respiration-induced fluctuations--using BP waveform data from the MIMIC
database. Oscillometry tends to underestimate systolic BP and overestimate
diastolic BP, while respiration introduces cyclical variations that further
degrade measurement precision. To mitigate these effects, we propose an
estimation-theoretic framework employing least squares (LS) and maximum
likelihood (ML) methods for correcting both single and repeated BP
measurements. LS estimation supports conventional multi-measurement averaging
protocols, whereas the ML approach incorporates prior knowledge of measurement
errors, offering improved performance. Our results demonstrate that leveraging
statistical priors across multiple readings can enhance the accuracy of
non-invasive BP monitoring, with potential implications for improving
cardiovascular diagnosis and treatment.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot](https://arxiv.org/abs/2508.14994)
*Murilo Vinicius da Silva,Matheus Hipolito Carvalho,Juliano Negri,Thiago Segreto,Gustavo J. G. Lahr,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种基于视觉姿态估计的直观远程控制系统，用于四足机器人臂的实时控制，通过映射操作者手腕动作，提高安全性和易用性。


<details>
  <summary>Details</summary>
Motivation: 在危险和远程环境中，四足机器人臂的远程操作存在障碍物检测不足和操作复杂的挑战，需提高安全性和易用性。

Method: 利用外部摄像头和机器学习模型检测操作者手腕位置，映射到机器人臂指令，并结合轨迹规划器避免碰撞。

Result: 系统在真实机器人上验证，展示了实时控制的鲁棒性能。

Conclusion: 该远程控制方案为工业应用提供了安全、精确且易用的解决方案，适用于高风险环境。

Abstract: In hazardous and remote environments, robotic systems perform critical tasks
demanding improved safety and efficiency. Among these, quadruped robots with
manipulator arms offer mobility and versatility for complex operations.
However, teleoperating quadruped robots is challenging due to the lack of
integrated obstacle detection and intuitive control methods for the robotic
arm, increasing collision risks in confined or dynamically changing workspaces.
Teleoperation via joysticks or pads can be non-intuitive and demands a high
level of expertise due to its complexity, culminating in a high cognitive load
on the operator. To address this challenge, a teleoperation approach that
directly maps human arm movements to the robotic manipulator offers a simpler
and more accessible solution. This work proposes an intuitive remote control by
leveraging a vision-based pose estimation pipeline that utilizes an external
camera with a machine learning-based model to detect the operator's wrist
position. The system maps these wrist movements into robotic arm commands to
control the robot's arm in real-time. A trajectory planner ensures safe
teleoperation by detecting and preventing collisions with both obstacles and
the robotic arm itself. The system was validated on the real robot,
demonstrating robust performance in real-time control. This teleoperation
approach provides a cost-effective solution for industrial applications where
safety, precision, and ease of use are paramount, ensuring reliable and
intuitive robotic control in high-risk environments.

</details>


### [10] [GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping](https://arxiv.org/abs/2508.15002)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 该论文提出了一种合成大规模、多样化且物理可行的抓握数据的方法，通过引入可微分的力闭合能量公式和优化方法（MALA*），显著提升了抓握多样性和稳定性，并提供了一个新的大规模抓握数据集。


<details>
  <summary>Details</summary>
Motivation: 现有抓握数据生成方法通常局限于力量抓握，缺乏多样性，难以支撑复杂的精确操作任务。为了充分利用多指灵巧手的潜力，需要更丰富和高质量的抓握数据。

Method: 通过定义基于二次规划（QP）的可微力闭合能量公式，并采用动态调整的优化方法（MALA*），生成多样化的抓握配置。

Result: 实验证明，该方法显著提升了抓握多样性和预测稳定性，并生成了包含5700个物体、五种夹具和三种抓握类型的大规模数据集。

Conclusion: 该方法为灵巧手的多样化抓握任务提供了高质量的数据支持，推动了抓握预测模型和任务规划的发展。

Abstract: Dexterous robotic hands enable versatile interactions due to the flexibility
and adaptability of multi-fingered designs, allowing for a wide range of
task-specific grasp configurations in diverse environments. However, to fully
exploit the capabilities of dexterous hands, access to diverse and high-quality
grasp data is essential -- whether for developing grasp prediction models from
point clouds, training manipulation policies, or supporting high-level task
planning with broader action options. Existing approaches for dataset
generation typically rely on sampling-based algorithms or simplified
force-closure analysis, which tend to converge to power grasps and often
exhibit limited diversity. In this work, we propose a method to synthesize
large-scale, diverse, and physically feasible grasps that extend beyond simple
power grasps to include refined manipulations, such as pinches and tri-finger
precision grasps. We introduce a rigorous, differentiable energy formulation of
force closure, implicitly defined through a Quadratic Program (QP).
Additionally, we present an adjusted optimization method (MALA*) that improves
performance by dynamically rejecting gradient steps based on the distribution
of energy values across all samples. We extensively evaluate our approach and
demonstrate significant improvements in both grasp diversity and the stability
of final grasp predictions. Finally, we provide a new, large-scale grasp
dataset for 5,700 objects from DexGraspNet, comprising five different grippers
and three distinct grasp types.
  Dataset and Code:https://graspqp.github.io/

</details>


### [11] [In-Context Iterative Policy Improvement for Dynamic Manipulation](https://arxiv.org/abs/2508.15021)
*Mark Van der Merwe,Devesh Jha*

Main category: cs.RO

TL;DR: 大型语言模型（LLM）通过上下文学习实现动态操作，解决高维度、复杂动态和部分可观察性等挑战，在低数据场景下表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 探索预训练语言模型在动态操作中的应用，尤其是通过上下文学习处理高维度、复杂动态和部分可观察性等挑战。

Method: 采用迭代方法，基于先前交互预测参数化策略的调整，利用上下文学习实现动态操作。

Result: 在仿真和物理机器人实验中，上下文学习方法在低数据场景下优于其他方法。

Conclusion: 上下文学习为动态操作提供了有效解决方案，尤其在数据稀缺情况下表现优异。

Abstract: Attention-based architectures trained on internet-scale language data have
demonstrated state of the art reasoning ability for various language-based
tasks, such as logic problems and textual reasoning. Additionally, these Large
Language Models (LLMs) have exhibited the ability to perform few-shot
prediction via in-context learning, in which input-output examples provided in
the prompt are generalized to new inputs. This ability furthermore extends
beyond standard language tasks, enabling few-shot learning for general
patterns. In this work, we consider the application of in-context learning with
pre-trained language models for dynamic manipulation. Dynamic manipulation
introduces several crucial challenges, including increased dimensionality,
complex dynamics, and partial observability. To address this, we take an
iterative approach, and formulate our in-context learning problem to predict
adjustments to a parametric policy based on previous interactions. We show
across several tasks in simulation and on a physical robot that utilizing
in-context learning outperforms alternative methods in the low data regime.
Video summary of this work and experiments can be found
https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.

</details>


### [12] [Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring](https://arxiv.org/abs/2508.15038)
*Makram Chahine,William Yang,Alaa Maalouf,Justin Siriska,Ninad Jadhav,Daniel Vogt,Stephanie Gil,Robert Wood,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的分散式多无人机系统，用于野生动物监测，兼具可扩展性和低带宽需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法多从群体视角出发或依赖手动操作，限制了规模和效率，需要更高效的并行部署解决方案。

Method: 开发了新型视觉协调与跟踪算法，仅需单机RGB摄像头，无需集中通信或控制。

Result: 实际实验中验证了系统在动态非结构化环境中的可靠部署能力。

Conclusion: 该系统在野生动物监测中表现出高效、可扩展和低带宽的优势。

Abstract: Wildlife field operations demand efficient parallel deployment methods to
identify and interact with specific individuals, enabling simultaneous
collective behavioral analysis, and health and safety interventions. Previous
robotics solutions approach the problem from the herd perspective, or are
manually operated and limited in scale. We propose a decentralized vision-based
multi-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,
and sensor-minimal (single onboard RGB camera). Our approach enables robust
identification and tracking of large species in their natural habitat. We
develop novel vision-based coordination and tracking algorithms designed for
dynamic, unstructured environments without reliance on centralized
communication or control. We validate our system through real-world
experiments, demonstrating reliable deployment in diverse field conditions.

</details>


### [13] [Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds](https://arxiv.org/abs/2508.15160)
*Hesam Azadjou,Suraj Chakravarthi Raja,Ali Marjaninejad,Francisco J. Valero-Cuevas*

Main category: cs.RO

TL;DR: 论文提出了一种仿生学习算法G2P，用于肌腱驱动的四足机器人，通过快速学习和适应实现动态控制。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在不完全了解自身结构和环境的情况下快速学习和适应的问题。

Method: 采用G2P算法，包括5分钟的通用运动探索和15次细化试验，模拟哺乳动物的探索-利用范式。

Result: 机器人能够在几分钟内学会功能性周期性非凸运动控制。

Conclusion: 该方法为机器人动态适应新环境和持续优化性能提供了新途径。

Abstract: Like mammals, robots must rapidly learn to control their bodies and interact
with their environment despite incomplete knowledge of their body structure and
surroundings. They must also adapt to continuous changes in both. This work
presents a bio-inspired learning algorithm, General-to-Particular (G2P),
applied to a tendon-driven quadruped robotic system developed and fabricated
in-house. Our quadruped robot undergoes an initial five-minute phase of
generalized motor babbling, followed by 15 refinement trials (each lasting 20
seconds) to achieve specific cyclical movements. This process mirrors the
exploration-exploitation paradigm observed in mammals. With each refinement,
the robot progressively improves upon its initial "good enough" solution. Our
results serve as a proof-of-concept, demonstrating the hardware-in-the-loop
system's ability to learn the control of a tendon-driven quadruped with
redundancies in just a few minutes to achieve functional and adaptive cyclical
non-convex movements. By advancing autonomous control in robotic locomotion,
our approach paves the way for robots capable of dynamically adjusting to new
environments, ensuring sustained adaptability and performance.

</details>


### [14] [Survey of Vision-Language-Action Models for Embodied Manipulation](https://arxiv.org/abs/2508.15201)
*Haoran Li,Yuhui Chen,Wenbo Cui,Weiheng Liu,Kai Liu,Mingcai Zhou,Zhengtao Zhang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 综述了视觉语言动作（VLA）模型在体感智能系统中的发展、关键维度的研究成果以及未来挑战与方向。


<details>
  <summary>Details</summary>
Motivation: 体感智能系统通过环境交互增强能力，VLA模型作为通用机器人控制框架，提升了交互能力，拓宽了应用场景。

Method: 梳理VLA架构发展历程，从模型结构、数据集、预训练、后训练和评估5个维度分析当前研究。

Result: 总结了VLA模型在体感智能中的关键挑战和实际部署中的问题。

Conclusion: 提出了VLA模型未来研究的方向，以进一步推动体感智能系统的发展。

Abstract: Embodied intelligence systems, which enhance agent capabilities through
continuous environment interactions, have garnered significant attention from
both academia and industry. Vision-Language-Action models, inspired by
advancements in large foundation models, serve as universal robotic control
frameworks that substantially improve agent-environment interaction
capabilities in embodied intelligence systems. This expansion has broadened
application scenarios for embodied AI robots. This survey comprehensively
reviews VLA models for embodied manipulation. Firstly, it chronicles the
developmental trajectory of VLA architectures. Subsequently, we conduct a
detailed analysis of current research across 5 critical dimensions: VLA model
structures, training datasets, pre-training methods, post-training methods, and
model evaluation. Finally, we synthesize key challenges in VLA development and
real-world deployment, while outlining promising future research directions.

</details>


### [15] [Mag-Match: Magnetic Vector Field Features for Map Matching and Registration](https://arxiv.org/abs/2508.15300)
*William McDonald,Cedric Le Gentil,Jennifer Wakulicz,Teresa Vidal-Calleja*

Main category: cs.RO

TL;DR: Mag-Match提出了一种基于磁力场地图的3D特征提取与描述方法，用于在恶劣环境下实现地图匹配与注册，无需重力对齐。


<details>
  <summary>Details</summary>
Motivation: 传统基于摄像头或LiDAR的方法在烟雾或灰尘等恶劣环境下表现不佳，而磁力计可以检测其他传感器无法捕捉的特征，且在这些条件下更鲁棒。

Method: 利用物理信息高斯过程递归推断磁力场及其高阶导数，提出一种对全局方向不变的特征描述符。

Result: 在仿真和现实实验中，Mag-Match表现优于基于SIFT的方法，能准确实现地图间、机器人与地图间的转换。

Conclusion: Mag-Match为恶劣环境下的地图匹配与注册提供了高效且鲁棒的解决方案。

Abstract: Map matching and registration are essential tasks in robotics for
localisation and integration of multi-session or multi-robot data. Traditional
methods rely on cameras or LiDARs to capture visual or geometric information
but struggle in challenging conditions like smoke or dust. Magnetometers, on
the other hand, detect magnetic fields, revealing features invisible to other
sensors and remaining robust in such environments. In this paper, we introduce
Mag-Match, a novel method for extracting and describing features in 3D magnetic
vector field maps to register different maps of the same area. Our feature
descriptor, based on higher-order derivatives of magnetic field maps, is
invariant to global orientation, eliminating the need for gravity-aligned
mapping. To obtain these higher-order derivatives map-wide given point-wise
magnetometer data, we leverage a physics-informed Gaussian Process to perform
efficient and recursive probabilistic inference of both the magnetic field and
its derivatives. We evaluate Mag-Match in simulated and real-world experiments
against a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,
and robot-to-robot transformations - even without initial gravitational
alignment.

</details>


### [16] [Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey](https://arxiv.org/abs/2508.15354)
*Chaoran Xiong,Yulong Huang,Fangwen Yu,Changhao Chen,Yue Wang,Songpengchen Xia,Ling Pei*

Main category: cs.RO

TL;DR: 这篇论文提出了一个名为TOFRA的五阶段框架，用于综合当前具身导航（EN）的技术现状、平台、评估指标和研究挑战。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖显式定位和预定义地图，而具身导航通过感知、社交和运动智能实现更复杂的任务，因此需要一个新的框架来总结和推动该领域的发展。

Method: 论文提出了一个五阶段的TOFRA框架（Transition、Observation、Fusion、Reward-policy construction、Action），用于系统化EN的研究。

Result: 对现有EN技术、平台和评估指标进行了全面的综述，并指出了关键的研究挑战。

Conclusion: TOFRA框架为EN研究提供了系统化的视角，有助于未来技术的进一步发展。

Abstract: Embodied navigation (EN) advances traditional navigation by enabling robots
to perform complex egocentric tasks through sensing, social, and motion
intelligence. In contrast to classic methodologies that rely on explicit
localization and pre-defined maps, EN leverages egocentric perception and
human-like interaction strategies. This survey introduces a comprehensive EN
formulation structured into five stages: Transition, Observation, Fusion,
Reward-policy construction, and Action (TOFRA). The TOFRA framework serves to
synthesize the current state of the art, provide a critical review of relevant
platforms and evaluation metrics, and identify critical open research
challenges. A list of studies is available at
https://github.com/Franky-X/Awesome-Embodied-Navigation.

</details>


### [17] [Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation](https://arxiv.org/abs/2508.15427)
*Huy Hoang Nguyen,Johannes Huemer,Markus Murschitz,Tobias Glueck,Minh Nhat Vu,Andreas Kugi*

Main category: cs.RO

TL;DR: 论文提出Lang2Lift框架，利用基础模型实现自然语言引导的托盘检测和6D位姿估计，以解决物流和建筑行业中托盘自动化搬运的挑战。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺、安全隐患以及在复杂环境下手动定位和提取托盘的效率低下，促使研究自动化托盘搬运的关键步骤。

Method: 集成Florence-2和SAM-2进行语言引导分割，结合FoundationPose实现杂乱户外场景中的稳健位姿估计，并通过运动规划模块实现完全自主的叉车操作。

Result: 在真实测试数据集上，Lang2Lift实现了0.76 mIoU的托盘分割准确率，时间和误差分析验证了系统的鲁棒性和部署可行性。

Conclusion: Lang2Lift展示了在物流和建筑环境中部署自动化托盘搬运系统的潜力，解决了复杂环境下的感知和操作难题。

Abstract: The logistics and construction industries face persistent challenges in
automating pallet handling, especially in outdoor environments with variable
payloads, inconsistencies in pallet quality and dimensions, and unstructured
surroundings. In this paper, we tackle automation of a critical step in pallet
transport: the pallet pick-up operation. Our work is motivated by labor
shortages, safety concerns, and inefficiencies in manually locating and
retrieving pallets under such conditions. We present Lang2Lift, a framework
that leverages foundation models for natural language-guided pallet detection
and 6D pose estimation, enabling operators to specify targets through intuitive
commands such as "pick up the steel beam pallet near the crane." The perception
pipeline integrates Florence-2 and SAM-2 for language-grounded segmentation
with FoundationPose for robust pose estimation in cluttered, multi-pallet
outdoor scenes under variable lighting. The resulting poses feed into a motion
planning module for fully autonomous forklift operation. We validate Lang2Lift
on the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet
segmentation accuracy on a real-world test dataset. Timing and error analysis
demonstrate the system's robustness and confirm its feasibility for deployment
in operational logistics and construction environments. Video demonstrations
are available at https://eric-nguyen1402.github.io/lang2lift.github.io/

</details>


### [18] [LLM-Driven Self-Refinement for Embodied Drone Task Planning](https://arxiv.org/abs/2508.15501)
*Deyu Zhang,Xicheng Zhang,Jiahao Li,Tingting Long,Xunhua Dai,Yongjian Fu,Jinrui Zhang,Ju Ren,Yaoxue Zhang*

Main category: cs.RO

TL;DR: SRDrone是一个用于工业级无人机任务规划的自我优化系统，通过连续状态评估和分层行为树改进模型提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机任务规划方法依赖单帧最终状态评估，无法适应连续动态操作，需要更鲁棒和自适应的解决方案。

Method: SRDrone采用连续状态评估方法和分层行为树改进模型，支持多级任务分析和结构化经验学习。

Result: 实验显示SRDrone相比基线方法成功率提升44.87%，实时优化后达到96.25%的成功率。

Conclusion: SRDrone将大型语言模型的通用推理能力与无人机的物理执行约束结合，为工业级任务规划提供了有效解决方案。

Abstract: We introduce SRDrone, a novel system designed for self-refinement task
planning in industrial-grade embodied drones. SRDrone incorporates two key
technical contributions: First, it employs a continuous state evaluation
methodology to robustly and accurately determine task outcomes and provide
explanatory feedback. This approach supersedes conventional reliance on
single-frame final-state assessment for continuous, dynamic drone operations.
Second, SRDrone implements a hierarchical Behavior Tree (BT) modification
model. This model integrates multi-level BT plan analysis with a constrained
strategy space to enable structured reflective learning from experience.
Experimental results demonstrate that SRDrone achieves a 44.87% improvement in
Success Rate (SR) over baseline methods. Furthermore, real-world deployment
utilizing an experience base optimized through iterative self-refinement
attains a 96.25% SR. By embedding adaptive task refinement capabilities within
an industrial-grade BT planning framework, SRDrone effectively integrates the
general reasoning intelligence of Large Language Models (LLMs) with the
stringent physical execution constraints inherent to embodied drones. Code is
available at https://github.com/ZXiiiC/SRDrone.

</details>


### [19] [Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation](https://arxiv.org/abs/2508.15663)
*Nikita Kachaev,Andrei Spiridonov,Andrey Gorodetsky,Kirill Muravyev,Nikita Oskolkov,Aditya Narendra,Vlad Shakhuro,Dmitry Makarov,Aleksandr I. Panov,Polina Fedotova,Alexey K. Kovalev*

Main category: cs.RO

TL;DR: Kitchen-R是一个新的基准测试，旨在统一评估任务规划和低级控制在模拟厨房环境中的表现，弥补了现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试在高级语言指令和低级机器人控制之间存在脱节，无法全面评估集成系统。Kitchen-R旨在解决这一问题。

Method: 利用Isaac Sim模拟器构建数字孪生厨房环境，包含500多条复杂语言指令，支持移动操作机器人。提供基于视觉语言模型的任务规划和扩散政策的低级控制策略。

Result: Kitchen-R提供了三种评估模式：独立评估规划模块、独立评估控制策略以及集成评估整个系统，填补了具体AI研究的关键空白。

Conclusion: Kitchen-R为语言引导的机器人代理提供了更全面和现实的基准测试框架。

Abstract: Benchmarks are crucial for evaluating progress in robotics and embodied AI.
However, a significant gap exists between benchmarks designed for high-level
language instruction following, which often assume perfect low-level execution,
and those for low-level robot control, which rely on simple, one-step commands.
This disconnect prevents a comprehensive evaluation of integrated systems where
both task planning and physical execution are critical. To address this, we
propose Kitchen-R, a novel benchmark that unifies the evaluation of task
planning and low-level control within a simulated kitchen environment. Built as
a digital twin using the Isaac Sim simulator and featuring more than 500
complex language instructions, Kitchen-R supports a mobile manipulator robot.
We provide baseline methods for our benchmark, including a task-planning
strategy based on a vision-language model and a low-level control policy based
on diffusion policy. We also provide a trajectory collection system. Our
benchmark offers a flexible framework for three evaluation modes: independent
assessment of the planning module, independent assessment of the control
policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R
bridges a key gap in embodied AI research, enabling more holistic and realistic
benchmarking of language-guided robotic agents.

</details>


### [20] [Exploiting Policy Idling for Dexterous Manipulation](https://arxiv.org/abs/2508.15669)
*Annie S. Chen,Philemon Brakel,Antonia Bronars,Annie Xie,Sandy Huang,Oliver Groth,Maria Bauza,Markus Wulfmeier,Nicolas Heess,Dushyant Rao*

Main category: cs.RO

TL;DR: 论文提出了一种名为Pause-Induced Perturbations（PIP）的方法，通过在检测到的闲置状态下施加扰动，帮助策略摆脱吸引力盆地，从而提升学习策略的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 学习基于的灵巧操作策略在实际应用中常因训练数据的局限性而出现闲置问题，导致策略在关键动作阶段停滞不前。现有方法通过过滤数据或调整控制频率来缓解，但可能影响其他性能。

Method: 提出PIP方法，通过在检测到的闲置状态施加扰动，帮助策略探索并摆脱局限性，无需额外的监督或训练。

Result: 在模拟双臂任务和真实世界插入任务中，PIP显著提升了策略的性能，绝对成功率提高了15-35%。

Conclusion: PIP是一种简单有效的方法，能够显著提升学习策略的鲁棒性和性能，尤其在关键任务阶段表现优异。

Abstract: Learning-based methods for dexterous manipulation have made notable progress
in recent years. However, learned policies often still lack reliability and
exhibit limited robustness to important factors of variation. One failure
pattern that can be observed across many settings is that policies idle, i.e.
they cease to move beyond a small region of states when they reach certain
states. This policy idling is often a reflection of the training data. For
instance, it can occur when the data contains small actions in areas where the
robot needs to perform high-precision motions, e.g., when preparing to grasp an
object or object insertion. Prior works have tried to mitigate this phenomenon
e.g. by filtering the training data or modifying the control frequency.
However, these approaches can negatively impact policy performance in other
ways. As an alternative, we investigate how to leverage the detectability of
idling behavior to inform exploration and policy improvement. Our approach,
Pause-Induced Perturbations (PIP), applies perturbations at detected idling
states, thus helping it to escape problematic basins of attraction. On a range
of challenging simulated dual-arm tasks, we find that this simple approach can
already noticeably improve test-time performance, with no additional
supervision or training. Furthermore, since the robot tends to idle at critical
points in a movement, we also find that learning from the resulting episodes
leads to better iterative policy improvement compared to prior approaches. Our
perturbation strategy also leads to a 15-35% improvement in absolute success
rate on a real-world insertion task that requires complex multi-finger
manipulation.

</details>


### [21] [Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing](https://arxiv.org/abs/2508.15732)
*Gargi Das,Daegyun Choi,Donghoon Kim*

Main category: cs.RO

TL;DR: 该研究提出了一种基于动态耦合的自由漂浮空间机械臂系统轨迹优化算法，通过利用动态耦合提升轨迹规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注最小化机械臂与基座的动态耦合，而忽视其潜在优势。本研究探索如何利用动态耦合改进轨迹规划。

Method: 采用动态耦合矩阵的奇异值分解识别主导耦合行为，并构建定量指标衡量其强度和方向性，融入轨迹优化框架。设计滑模控制器验证轨迹可行性。

Result: 仿真结果表明，显式考虑动态耦合可实现更高效的操作，为自由漂浮空间机械臂控制提供新方向。

Conclusion: 动态耦合的主动利用能优化轨迹规划，为系统控制开辟新途径。

Abstract: This study proposes a dynamic coupling-informed trajectory optimization
algorithm for free-floating space manipulator systems (SMSs). Dynamic coupling
between the base and the manipulator arms plays a critical role in influencing
the system's behavior. While prior research has predominantly focused on
minimizing this coupling, often overlooking its potential advantages, this work
investigates how dynamic coupling can instead be leveraged to improve
trajectory planning. Singular value decomposition (SVD) of the dynamic coupling
matrix is employed to identify the dominant components governing coupling
behavior. A quantitative metric is then formulated to characterize the strength
and directionality of the coupling and is incorporated into a trajectory
optimization framework. To assess the feasibility of the optimized trajectory,
a sliding mode control-based tracking controller is designed to generate the
required joint torque inputs. Simulation results demonstrate that explicitly
accounting for dynamic coupling in trajectory planning enables more informed
and potentially more efficient operation, offering new directions for the
control of free-floating SMSs.

</details>


### [22] [Neural Robot Dynamics](https://arxiv.org/abs/2508.15755)
*Jie Xu,Eric Heiden,Iretiayo Akinola,Dieter Fox,Miles Macklin,Yashraj Narang*

Main category: cs.RO

TL;DR: 本文提出了一种名为NeRD的神经机器人动力学模型，用于预测关节刚性机器人在接触约束下的未来状态，具有高泛化性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现代机器人由于高自由度和复杂机制，模拟精度和效率面临挑战。现有神经模拟器需针对特定任务训练且泛化能力不足。

Method: 提出NeRD模型，替代传统低层动力学和接触求解器，采用机器人中心化和空间不变的状态表示。

Result: 实验表明NeRD模拟器在千步模拟中稳定准确，能跨任务和环境泛化，并支持从现实数据微调。

Conclusion: NeRD模型显著提升了模拟器的泛化能力和实用性，能有效缩小仿真与现实的差距。

Abstract: Accurate and efficient simulation of modern robots remains challenging due to
their high degrees of freedom and intricate mechanisms. Neural simulators have
emerged as a promising alternative to traditional analytical simulators,
capable of efficiently predicting complex dynamics and adapting to real-world
data; however, existing neural simulators typically require
application-specific training and fail to generalize to novel tasks and/or
environments, primarily due to inadequate representations of the global state.
In this work, we address the problem of learning generalizable neural
simulators for robots that are structured as articulated rigid bodies. We
propose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models
for predicting future states for articulated rigid bodies under contact
constraints. NeRD uniquely replaces the low-level dynamics and contact solvers
in an analytical simulator and employs a robot-centric and spatially-invariant
simulation state representation. We integrate the learned NeRD models as an
interchangeable backend solver within a state-of-the-art robotics simulator. We
conduct extensive experiments to show that the NeRD simulators are stable and
accurate over a thousand simulation steps; generalize across tasks and
environment configurations; enable policy learning exclusively in a neural
engine; and, unlike most classical simulators, can be fine-tuned from
real-world data to bridge the gap between simulation and reality.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [23] [Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer](https://arxiv.org/abs/2508.15058)
*Kaiqiang Lin,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文提出了一种新型的空间-空中-地面-地下集成网络（SAGUIN）架构，结合LoRaWAN和无线能量传输技术，以支持可持续的地下大规模机器类型通信（mMTC），并通过模拟验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 地下无线传感器网络（WUSNs）在恶劣的地下环境中面临资源稀缺和通信覆盖受限的问题，难以支持可持续的大规模机器类型通信。

Method: 研究提出SAGUIN架构，整合卫星、空中平台、地面网络和地下通信，并集成LoRaWAN和无线能量传输技术。通过模拟评估其性能。

Result: 模拟结果表明，结合优化的时间分配策略和适当的LoRaWAN参数，SAGUIN系统可有效延长设备寿命，支持可持续地下mMTC。

Conclusion: SAGUIN系统结合LoRaWAN和无线能量传输技术，为解决地下通信挑战提供了可行方案，未来需进一步研究优化。

Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing
and monitoring of underground resources by underground devices (UDs), hold
great promise for delivering substantial social and economic benefits across
various verticals. However, due to the harsh subterranean environment, scarce
network resources, and restricted communication coverage, WUSNs face
significant challenges in supporting sustainable massive machine-type
communications (mMTC), particularly in remote, disaster-stricken, and
hard-to-reach areas. To complement this, we conceptualize in this study a novel
space-air-ground-underground integrated network (SAGUIN) architecture that
seamlessly incorporates satellite systems, aerial platforms, terrestrial
networks, and underground communications. On this basis, we integrate LoRaWAN
and wireless energy transfer (WET) technologies into SAGUIN to enable
sustainable subterranean mMTC. We begin by reviewing the relevant technical
background and presenting the architecture and implementation challenges of
SAGUIN. Then, we employ simulations to model a remote underground pipeline
monitoring scenario to evaluate the feasibility and performance of SAGUIN based
on LoRaWAN and WET technologies, focusing on the effects of parameters such as
underground conditions, time allocation, LoRaWAN spread factor (SF)
configurations, reporting periods, and harvested energy levels. Our results
evidence that the proposed SAGUIN system, when combined with the derived time
allocation strategy and an appropriate SF, can effectively extend the
operational lifetime of UDs, thereby facilitating sustainable subterranean
mMTC. Finally, we pinpoint key challenges and future research directions for
SAGUIN.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [24] [Discrete VHCs for Propeller Motion of a Devil-Stick using purely Impulsive Inputs](https://arxiv.org/abs/2508.15040)
*Aakash Khandelwal,Ranjan Mukherjee*

Main category: eess.SY

TL;DR: 本文研究了利用垂直于魔鬼棒的脉冲力实现其在垂直平面内螺旋桨运动的控制问题，提出了离散虚拟全纯约束（DVHC）的新概念。


<details>
  <summary>Details</summary>
Motivation: 解决魔鬼棒在垂直平面内螺旋桨运动的未充分驱动的机器人杂耍控制问题，填补了文献中的空白。

Method: 引入离散虚拟全纯约束（DVHC）和离散零动力学（DZD），设计控制器以强化DVHC，并基于脉冲控制的Poincaré映射方法实现轨道稳定。

Result: 通过仿真验证了轨迹设计和稳定控制方法的有效性，证明了该方法的可行性。

Conclusion: 提出的DVHC和DZD为未充分驱动系统的轨道稳定问题提供了新思路，仿真结果验证了方法的有效性。

Abstract: The control problem of realizing propeller motion of a devil-stick in the
vertical plane using impulsive forces applied normal to the stick is
considered. This problem is an example of underactuated robotic juggling and
has not been considered in the literature before. Inspired by virtual holonomic
constraints, the concept of discrete virtual holonomic constraints (DVHC) is
introduced for the first time to solve this orbital stabilization problem. At
the discrete instants when impulsive inputs are applied, the location of the
center-of-mass of the devil-stick is specified in terms of its orientation
angle. This yields the discrete zero dynamics (DZD), which provides conditions
for stable propeller motion. In the limiting case, when the rotation angle
between successive applications of impulsive inputs is chosen to be arbitrarily
small, the problem reduces to that of propeller motion under continuous
forcing. A controller that enforces the DVHC, and an orbit stabilizing
controller based on the impulse controlled Poincar\'e map approach are
presented. The efficacy of the approach to trajectory design and stabilization
is validated through simulations.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [25] [Scalable FPGA Framework for Real-Time Denoising in High-Throughput Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis](https://arxiv.org/abs/2508.14917)
*Weichien Liao*

Main category: cs.AR

TL;DR: 提出了一个基于FPGA的可扩展实时去噪预处理管道，通过HLS实现，优化了DRAM缓冲，降低延迟，适用于PRISM等高通量成像。


<details>
  <summary>Details</summary>
Motivation: 高通量成像（如PRISM）产生的数据超出了传统实时处理能力，需要一个高效的实时去噪解决方案。

Method: 采用FPGA架构，通过HLS实现，优化DRAM缓冲，利用burst-mode AXI4接口最小化延迟，直接在流数据上进行帧减法和平均。

Result: 内核操作低于帧间隔时间，实现了实时去噪并减少了下游CPU/GPU分析的数据集大小。

Conclusion: 该模块化FPGA框架为光谱和显微镜中延迟敏感的成像工作流程提供了实用解决方案。

Abstract: High-throughput imaging workflows, such as Parallel Rapid Imaging with
Spectroscopic Mapping (PRISM), generate data at rates that exceed conventional
real-time processing capabilities. We present a scalable FPGA-based
preprocessing pipeline for real-time denoising, implemented via High-Level
Synthesis (HLS) and optimized for DRAM-backed buffering. Our architecture
performs frame subtraction and averaging directly on streamed image data,
minimizing latency through burst-mode AXI4 interfaces. The resulting kernel
operates below the inter-frame interval, enabling inline denoising and reducing
dataset size for downstream CPU/GPU analysis. Validated under PRISM-scale
acquisition, this modular FPGA framework offers a practical solution for
latency-sensitive imaging workflows in spectroscopy and microscopy.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [26] [XAI-Driven Spectral Analysis of Cough Sounds for Respiratory Disease Characterization](https://arxiv.org/abs/2508.14949)
*Patricia Amado-Caballero,Luis Miguel San-José-Revuelta,María Dolores Aguilar-García,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera*

Main category: cs.SD

TL;DR: 本文提出了一种基于可解释人工智能（XAI）的方法，通过分析咳嗽声音来增强对呼吸系统疾病管理的理解。


<details>
  <summary>Details</summary>
Motivation: 旨在利用XAI技术提升咳嗽声音分析的诊断能力，为呼吸系统疾病（如COPD）提供更可解释的分析结果。

Method: 采用卷积神经网络（CNN）处理咳嗽频谱图，并通过遮挡图突出相关频谱区域；随后对加权频谱图进行光谱分析。

Result: 研究发现，COPD患者的咳嗽模式在特定频谱区域表现出更高变异性，而原始频谱图分析则未发现显著差异。

Conclusion: XAI技术能够揭示疾病特异性声学特征，提升咳嗽声音分析的诊断能力和结果可解释性。

Abstract: This paper proposes an eXplainable Artificial Intelligence (XAI)-driven
methodology to enhance the understanding of cough sound analysis for
respiratory disease management. We employ occlusion maps to highlight relevant
spectral regions in cough spectrograms processed by a Convolutional Neural
Network (CNN). Subsequently, spectral analysis of spectrograms weighted by
these occlusion maps reveals significant differences between disease groups,
particularly in patients with COPD, where cough patterns appear more variable
in the identified spectral regions of interest. This contrasts with the lack of
significant differences observed when analyzing raw spectrograms. The proposed
approach extracts and analyzes several spectral features, demonstrating the
potential of XAI techniques to uncover disease-specific acoustic signatures and
improve the diagnostic capabilities of cough sound analysis by providing more
interpretable results.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation](https://arxiv.org/abs/2508.14965)
*Hakjin Lee,Junghoon Seo,Jaehoon Sim*

Main category: cs.CV

TL;DR: YOPO是一个单阶段的查询式框架，通过将9-DoF姿态估计作为2D检测的自然扩展，实现了仅使用RGB图像和类别级姿态标签的高性能统一检测与姿态估计。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人学和自动化中从单幅RGB图像精准恢复未见实例的9-DoF姿态这一核心挑战，研究者提出了一种更简单的、仅依赖RGB数据的替代方法。

Method: YOPO在transformer检测器基础上增加了轻量级姿态头、边界框条件翻译模块和6D感知匈牙利匹配成本，实现了端到端的训练。

Result: 在REAL275数据集上，YOPO的IoU50达到79.6%，10°10cm指标达到54.1%，超越了现有RGB-only方法并接近RGB-D系统。

Conclusion: YOPO通过简约设计，在多个基准测试中实现了新的一流性能，证明了仅用RGB数据也能高效解决姿态估计问题。

Abstract: Accurately recovering the full 9-DoF pose of unseen instances within specific
categories from a single RGB image remains a core challenge for robotics and
automation. Most existing solutions still rely on pseudo-depth, CAD models, or
multi-stage cascades that separate 2D detection from pose estimation. Motivated
by the need for a simpler, RGB-only alternative that learns directly at the
category level, we revisit a longstanding question: Can object detection and
9-DoF pose estimation be unified with high performance, without any additional
data? We show that they can with our method, YOPO, a single-stage, query-based
framework that treats category-level 9-DoF estimation as a natural extension of
2D detection. YOPO augments a transformer detector with a lightweight pose
head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian
matching cost. The model is trained end-to-end only with RGB images and
category-level pose labels. Despite its minimalist design, YOPO sets a new
state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%
$\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing
prior RGB-only methods and closing much of the gap to RGB-D systems. The code,
models, and additional qualitative results can be found on our project.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [Learning ECG Representations via Poly-Window Contrastive Learning](https://arxiv.org/abs/2508.15225)
*Yi Yuan,Joseph Van Duyn,Runze Yan,Zhuoyi Huang,Sulaiman Vesal,Sergey Plis,Xiao Hu,Gloria Hyunjung Kwak,Ran Xiao,Alex Fedorov*

Main category: cs.LG

TL;DR: 本文提出了一种多窗口对比学习框架，通过利用ECG的丰富时间结构提升模型性能，结果显示在较少的预训练周期和计算时间下，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有自监督学习方法仅生成成对增强视图而未能充分利用ECG时间结构的问题，提高诊断效率和准确性。

Method: 提出多窗口对比学习框架，提取多个时间窗口构造正对，并通过统计方法最大化其一致性，同时利用慢特征分析原则学习时间不变的生理特征。

Result: 在PTB-XL数据集上，多窗口方法在多标签超类分类中表现优于传统方法（AUROC 0.891 vs. 0.888），且预训练周期减少四倍，总计算时间减少14.8%。

Conclusion: 多窗口对比学习为ECG分析提供了高效且可扩展的框架，适用于生物医学时间序列数据的自监督学习。

Abstract: Electrocardiogram (ECG) analysis is foundational for cardiovascular disease
diagnosis, yet the performance of deep learning models is often constrained by
limited access to annotated data. Self-supervised contrastive learning has
emerged as a powerful approach for learning robust ECG representations from
unlabeled signals. However, most existing methods generate only pairwise
augmented views and fail to leverage the rich temporal structure of ECG
recordings. In this work, we present a poly-window contrastive learning
framework. We extract multiple temporal windows from each ECG instance to
construct positive pairs and maximize their agreement via statistics. Inspired
by the principle of slow feature analysis, our approach explicitly encourages
the model to learn temporally invariant and physiologically meaningful features
that persist across time. We validate our approach through extensive
experiments and ablation studies on the PTB-XL dataset. Our results demonstrate
that poly-window contrastive learning consistently outperforms conventional
two-view methods in multi-label superclass classification, achieving higher
AUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to
four times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock
pre-training time reduction. Despite processing multiple windows per sample, we
achieve a significant reduction in the number of training epochs and total
computation time, making our method practical for training foundational models.
Through extensive ablations, we identify optimal design choices and demonstrate
robustness across various hyperparameters. These findings establish poly-window
contrastive learning as a highly efficient and scalable paradigm for automated
ECG analysis and provide a promising general framework for self-supervised
representation learning in biomedical time-series data.

</details>


### [29] [Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving](https://arxiv.org/abs/2508.14926)
*Dianzhao Li,Ostap Okhrin*

Main category: cs.LG

TL;DR: 本文提出了一种分层的安全强化学习框架，用于在自动驾驶中整合伦理考量，通过复合伦理风险成本训练智能体，结合动态经验回放机制，同时在执行层面使用路径规划和控制器确保轨迹平滑可行。实验表明该方法在真实交通场景中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在常规和紧急操作中如何嵌入伦理推理的问题，以减少交通事故并提升交通效率。

Method: 采用分层的安全强化学习框架，结合复合伦理风险成本和动态优先经验回放机制，用于决策生成；在执行层面使用多项式路径规划和PID、Stanley控制器实现轨迹规划。

Result: 在真实交通数据集上的验证表明，该方法在减少伦理风险和保持驾驶性能方面优于基线方法。

Conclusion: 该研究首次将安全强化学习应用于自动驾驶的伦理决策，展示了形式化控制理论与数据驱动学习结合在复杂人车混行环境中的潜力。

Abstract: Autonomous vehicles hold great promise for reducing traffic fatalities and
improving transportation efficiency, yet their widespread adoption hinges on
embedding robust ethical reasoning into routine and emergency maneuvers. Here,
we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that
explicitly integrates moral considerations with standard driving objectives. At
the decision level, a Safe RL agent is trained using a composite ethical risk
cost, combining collision probability and harm severity, to generate high-level
motion targets. A dynamic Prioritized Experience Replay mechanism amplifies
learning from rare but critical, high-risk events. At the execution level,
polynomial path planning coupled with Proportional-Integral-Derivative (PID)
and Stanley controllers translates these targets into smooth, feasible
trajectories, ensuring both accuracy and comfort. We train and validate our
approach on rich, real-world traffic datasets encompassing diverse vehicles,
cyclists, and pedestrians, and demonstrate that it outperforms baseline methods
in reducing ethical risk and maintaining driving performance. To our knowledge,
this is the first study of ethical decision-making for autonomous vehicles via
Safe RL in real-world scenarios. Our results highlight the potential of
combining formal control theory and data-driven learning to advance ethically
accountable autonomy in complex, human-mixed traffic environments.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [30] [High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering](https://arxiv.org/abs/2508.15639)
*Eito Kurihara,Hideki Ochiai*

Main category: cs.IT

TL;DR: 论文提出了一种基于非均匀概率和非均匀星座的BICM-OFDM系统设计，结合裁剪和滤波技术，实现了高容量、低PAPR和高频谱效率。


<details>
  <summary>Details</summary>
Motivation: 解决OFDM系统中的高峰均比问题，同时提升频谱效率和错误率性能。

Method: 采用截断高斯分布生成NENU星座，结合CAF降低PAPR，并优化星座设计以适应噪声消除技术。

Result: 仿真表明，该系统在AWGN和频率选择性瑞利衰落信道中均表现优异，显著优于单载波系统。

Conclusion: 通过星座整形与CAF、CNC的结合，系统成功实现了低PAPR和高频谱效率的双重目标。

Abstract: We address a design of high-capacity and low-peak-to-average power ratio
(PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on
bit-interleaved coded modulation (BICM) utilizing non-equiprobable and
non-uniform (NENU) constellations as well as clipping and filtering (CAF). The
proposed constellations are generated using a truncated Gaussian distribution,
and the merging of constellation points, where the former creates a non-uniform
constellation (NUC), and the latter decreases the number of signal points
without compromising the achievable bit-wise mutual information (BMI). Since
the proposed constellations are uniquely determined by only the two parameters,
each associated with NUC and cardinality, the complexity required for the
numerical optimization process can be significantly low. We focus on the
constellation design based on one dimension, i.e., pulse amplitude modulation
(PAM), which facilitates the reduction of demapping complexity for the BICM
receiver. The use of CAF at the transmitter can efficiently reduce the PAPR of
OFDM signals; however, it introduces clipping noise that may degrade error rate
performance, making the application of clipping noise cancellation (CNC) at the
receiver essential. Therefore, we optimize the NENU constellations in the
presence of CAF and CNC. Simulation results demonstrate that the combination of
constellation shaping with CAF and CNC enables BICM-OFDM systems to
simultaneously achieve low PAPR and high spectral efficiency over additive
white Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading
channels. Furthermore, comparative studies confirm that the proposed system
significantly outperforms the single-carrier counterpart (i.e., DFT-precoded
BICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading
channels.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [31] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 论文提出了Open-Universe Assistance Games (OU-AGs)框架，用于解决AI代理在开放性人类目标下的推理问题，并提出了一种名为GOOD的数据高效在线方法，通过自然语言交互提取用户目标。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决AI代理如何在未预先定义的人类目标和偏好下进行可解释推理和行动的问题。

Method: 提出了GOOD方法，通过LLM模拟用户对话来生成复杂意图，并进行目标概率推断，无需依赖大规模离线数据集。

Result: 在文本购物和模拟家庭机器人环境中，GOOD方法显著优于无明确目标跟踪的基线方法，并通过LLM和人类评估得到验证。

Conclusion: GOOD通过自然语言交互和不确定性估计，为开放性目标下的AI代理提供了一种高效且可扩展的解决方案。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>
