<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 17]
- [cs.RO](#cs.RO) [Total: 43]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.IT](#cs.IT) [Total: 4]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [eess.SY](#eess.SY) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation](https://arxiv.org/abs/2509.15475)
*Lioz Berman,Sharon Gannot,Tom Tirer*

Main category: eess.SP

TL;DR: 本文提出了一种深度学习技术（SP²-Net），用于从单个天线阵列的快照中估计多源的到达方向（DOAs），解决了传统Bartlett波束形成器在分辨率和精度上的局限性。


<details>
  <summary>Details</summary>
Motivation: 在单快照场景下，传统方法（如Bartlett波束形成器）因阵列孔径限制在分辨率和精度上表现不足，而最大似然估计和多快照协方差方法不适用。

Method: 通过设计新型深度学习架构和训练策略，训练一个深度神经网络，该网络以测量数据和假设角度为输入，输出与更宽阵列性能一致的分数。

Result: 实验表明，（SP²-Net）在单快照DOA估计任务中优于Bartlett波束形成器和基于稀疏性的方法。

Conclusion: 提出的深度学习技术显著提升了单快照DOA估计的分辨率和精度，适用于实际应用。

Abstract: We consider the problem of estimating the directions of arrival (DOAs) of
multiple sources from a single snapshot of an antenna array, a task with many
practical applications. In such settings, the classical Bartlett beamformer is
commonly used, as maximum likelihood estimation becomes impractical when the
number of sources is unknown or large, and spectral methods based on the sample
covariance are not applicable due to the lack of multiple snapshots. However,
the accuracy and resolution of the Bartlett beamformer are fundamentally
limited by the array aperture. In this paper, we propose a deep learning
technique, comprising a novel architecture and training strategy, for
generating a high-resolution spatial spectrum from a single snapshot.
Specifically, we train a deep neural network that takes the measurements and a
hypothesis angle as input and learns to output a score consistent with the
capabilities of a much wider array. At inference time, a heatmap can be
produced by scanning an arbitrary set of angles. We demonstrate the advantages
of our trained model, named (SP)$^2$-Net, over the Bartlett beamformer and
sparsity-based DOA estimation methods.

</details>


### [2] [CSIT-Free Downlink Transmission for mmWave MU-MISO Systems in High-Mobility Scenario](https://arxiv.org/abs/2509.15564)
*Jeongjae Lee,Wonseok Choi,Songnam Hong*

Main category: eess.SP

TL;DR: 研究毫米波MU-MISO系统下行链路传输，提出无需CSIT的新框架，利用信道相干时间完成传输，并通过仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对高速移动场景下毫米波MU-MISO系统，传统CSIT获取开销大，亟需无需CSIT的高效传输方法。

Method: 设计CSIT-free的酉预编码，结合符号检测与CSI及多普勒频移估计，消除干扰并实现全合并增益。

Result: 仿真表明，该方法在取消干扰和增益实现上优于现有基线。

Conclusion: 提出的无需CSIT的传输框架在高速移动场景下具有显著优势。

Abstract: This paper investigates the downlink (DL) transmission in millimeter-wave
(mmWave) multi-user multiple-input single-output (MU-MISO) systems especially
focusing on a high speed mobile scenario. To complete the DL transmission
within an extremely short channel coherence time, we propose a novel DL
transmission framework that eliminates the need for channel state information
at the transmitter (CSIT), of which acquisition process requires a substantial
overhead, instead fully exploiting the given channel coherence time. Harnessing
the characteristic of mmWave channel and uniquely designed CSIT-free unitary
precoding, we propose a symbol detection method along with the simultaneous CSI
at the receiver (CSIR) and Doppler shift estimation method to completely cancel
the interferences while achieving a full combining gain. Via simulations, we
demonstrate the effectiveness of the proposed method comparing with the
existing baselines.

</details>


### [3] [Twisting Signals for Joint Radar-Communications: An OAM Vortex Beam Approach](https://arxiv.org/abs/2509.15601)
*Wanghan Lv,Kumar Vijay Mishra,Jinsong Hu*

Main category: eess.SP

TL;DR: 该论文提出一种基于轨道角动量（OAM）的毫米波联合雷达-通信系统，通过OAM技术和新型天线阵列设计提升雷达与通信性能，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 利用OAM技术的独特特性（如螺旋相位前缘和正交性）提升无线通信和雷达系统的性能，尤其是在车辆通信与雷达中的应用。

Method: 采用均匀线性阵列（ULA）和行波天线设计OAM空间调制方案，构建双基地汽车OAM联合雷达-通信模型，并通过模式分复用（MDM）策略实现参数可辨识性。

Result: 通过数值实验验证了系统的有效性，包括目标参数估计的克拉美-罗下界（CRLB）和通信误码率（BER）的性能分析。

Conclusion: 提出的OAM联合雷达-通信系统在车辆通信和雷达应用中表现出色，为未来工程实现提供了理论基础。

Abstract: Orbital angular momentum (OAM) technology has attracted much research
interest in recent years because of its characteristic helical phase front
twisting around the propagation axis and natural orthogonality among different
OAM states to encode more degrees of freedom than classical planar beams.
Leveraging upon these features, OAM technique has been applied to wireless
communication systems to enhance spectral efficiency and radar systems to
distinguish spatial targets without beam scanning. Leveraging upon these unique
properties, we propose an OAM-based millimeter-wave joint radar-communications
(JRC) system comprising a bi-static automotive radar and vehicle-to-vehicle
(V2V) communications. Different from existing uniform circular array (UCA)
based OAM systems where each element is an isotropic antenna, an OAM spatial
modulation scheme utilizing a uniform linear array (ULA) is adopted with each
element being a traveling-wave antenna, producing multiple Laguerre-Gaussian
(LG) vortex beams simultaneously. Specifically, we first build a novel
bi-static automotive OAM-JRC model that embeds communication messages in a
radar signal, following which a target position and velocity parameters
estimation algorithm is designed with only radar frames. Then, an OAM-based
mode-division multiplexing (MDM) strategy between radar and JRC frames is
presented to ensure the JRC parameters identifiability and recovery.
Furthermore, we analyze the performance of the JRC system through deriving
recovery guarantees and Cram\'er-Rao lower bound (CRLB) of radar target
parameters and evaluating the bit error rate (BER) of communication,
respectively. Our numerical experiments validate the effectiveness of the
proposed OAM-based JRC system and parameter estimation method.

</details>


### [4] [Blind Source Separation of Radar Signals in Time Domain Using Deep Learning](https://arxiv.org/abs/2509.15603)
*Sven Hinderer*

Main category: eess.SP

TL;DR: 该论文提出了一种基于监督训练的神经网络方法，用于解决雷达信号在相同方向和频率下的解交织问题，并展示了其在单通道接收器中分离未知波形的能力。


<details>
  <summary>Details</summary>
Motivation: 在对抗环境中，雷达发射器的识别和分析需要检测和分离输入信号，尤其是来自相同方向和相似频率的信号。随着发射器能力的提升，这一问题变得更加重要。

Method: 将问题视为时域中的盲源分离，应用监督训练的神经网络从接收的混合信号中提取底层信号，并借鉴音频源分离领域的先进技术。

Result: 研究表明，该方法能够在给定频段内分离两个未知波形，且适用于单通道接收器。

Conclusion: 该方法为解决复杂环境下的雷达信号解交织问题提供了一种有效途径，尤其在处理高度重叠和连续波信号时表现出色。

Abstract: Identification and further analysis of radar emitters in a contested
environment requires detection and separation of incoming signals. If they
arrive from the same direction and at similar frequencies, deinterleaving them
remains challenging. A solution to overcome this limitation becomes
increasingly important with the advancement of emitter capabilities. We propose
treating the problem as blind source separation in time domain and apply
supervisedly trained neural networks to extract the underlying signals from the
received mixture. This allows us to handle highly overlapping and also
continuous wave (CW) signals from both radar and communication emitters. We
make use of advancements in the field of audio source separation and extend a
current state-of-the-art model with the objective of deinterleaving arbitrary
radio frequency (RF) signals. Results show, that our approach is capable of
separating two unknown waveforms in a given frequency band with a single
channel receiver.

</details>


### [5] [Wireless Sensing with Movable Intelligent Surface](https://arxiv.org/abs/2509.15627)
*Ziyuan Zheng,Qingqing Wu,Yanze Zhu,Wen Chen,Ying Gao,Honghao Wang*

Main category: eess.SP

TL;DR: 该论文提出了一种低成本的可移动智能表面（MIS）用于无线传感，通过机械重配置替代电子相位调谐，并开发了优化算法以提高传感性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决可重构智能表面（RIS）在无线传感中高昂的硬件成本和功耗问题，该研究引入了基于流体天线系统（MIS）的低成本方案。

Method: MIS通过固定和可移动的预相位超表面层合成不同相位模式，实现多目标检测。提出了Riemannian增广拉格朗日方法（RALM）和启发式波束转向设计。

Result: 仿真验证了MIS的波束模式重配置能力，RALM方案显著提升了传感信号干扰加噪声比（SINR），并揭示了波束模式的增益-多样性权衡。

Conclusion: MIS为无线传感提供了一种低成本且高效的解决方案，其优化设计在实际应用中具有潜力。

Abstract: Future wireless networks are envisioned to deliver not only gigabit
communications but also ubiquitous sensing. Reconfigurable intelligent surfaces
(RISs) have emerged to reshape radio propagation, recently showing considerable
promise for wireless sensing. Still, their per-element electronic tuning incurs
prohibitive hardware cost and power consumption. Motivated by the concept of
fluid antenna system (FAS), this paper introduces a low-cost movable
intelligent surface (MIS) for wireless sensing, which replaces element-wise
electronic phase tuning with panel-wise mechanical reconfiguration. The MIS
stacks a large fixed and a smaller movable pre-phased metasurface layers, whose
differential position shifts synthesize distinct composite phase patterns,
enabling multiple beam patterns for multi-target detection. We characterize a
MIS-enabled multi-hop echo signal model with multi-target interference and then
formulate a worst-case sensing signal-to-interference-plus-noise ratio (SINR)
maximization problem that jointly designs MIS phase shifts and schedules MS2's
position. A Riemannian Augmented Lagrangian Method (RALM)-based algorithm is
developed to solve the formulated mixed-integer non-convex problem. We also
derive a heuristic MIS beam steering design with closed-form phase distribution
and position scheduling. Simulations validate MIS's beam pattern
reconfiguration capability, show that the RALM-based scheme significantly
outperforms the closed-form scheme in improving sensing SINR, and uncover a
gain-diversity trade-off in beam patterns that informs the optimal choice of
MIS configuration.

</details>


### [6] [Optimizing Sparse Antenna Arrays for Localization and Sensing using Vector Spherical Wave Functions](https://arxiv.org/abs/2509.15636)
*Tobias Lafer,Erik Leitinger,Klaus Witrisal*

Main category: eess.SP

TL;DR: 论文提出了一种利用Cramér-Rao下限（CRLB）和向量球面波函数（VSWF）优化稀疏天线阵列的方法，以提升定位性能。


<details>
  <summary>Details</summary>
Motivation: 随着电子设备中宽频带无线电技术的广泛应用（如超宽带UWB），如何在有限的空间内优化天线阵列的布局和方向，以提升定位性能，成为一个关键挑战。

Method: 通过VSWF建立宽频信号模型，考虑频率、方向、极化特性及周围障碍物影响，并利用CRLB推导定位参数（如时延和到达角）的优化问题。

Result: 以三个交叉指数渐变缝隙天线（XETS）为例，验证了优化方法的有效性。

Conclusion: 该方法为稀疏天线阵列的优化提供了一种系统性解决方案，适用于移动和物联网设备的定位需求。

Abstract: In increasing number of electronic devices implement wideband radio
technologies for localization and sensing purposes, like ultra-wideband (UWB).
Such radio technologies benefit from a large number of antennas, but space for
antennas is often limited, especially in devices for mobile and IoT
applications. A common challenge is therefore to optimize the placement and
orientations of a small number of antenna elements inside a device, leading to
the best localization performance. We propose a method for systematically
approaching the optimization of such sparse arrays by means of Cram\'er-Rao
lower bounds (CRLBs) and vector spherical wave functions (VSWFs). The VSWFs
form the basis of a wideband signal model considering frequency, direction and
polarization-dependent characteristics of the antenna array under test (AUT),
together with mutual coupling and distortions from surrounding obstacles. We
derive the CRLBs for localization parameters like delay and angle-of-arrival
for this model under additive white Gaussian noise channel conditions, and
formulate optimization problems for determining optimal antenna positions and
orientations via minimization of the CRLBs. The proposed optimization procedure
is demonstrated by means of an exemplary arrangement of three Crossed
Exponentially Tapered Slot (XETS) antennas.

</details>


### [7] [Hybrid Baseband Simulation for Single-Channel Radar-Based Indoor Localization System](https://arxiv.org/abs/2509.15650)
*Sven Hinderer,Zheming Yin,Athanasios Papanikolaou,Jan Hesselbarth,Bin Yang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于毫米波啁啾序列雷达的室内定位系统，结合了射线追踪和实测数据以实现高精度低成本定位。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过单通道雷达和被动反射器实现高精度且低成本的室内定位。

Method: 提出了一种混合雷达基带信号模拟器，结合射线追踪通道模拟、雷达双向天线增益实测和反射器雷达截面精确模拟。

Result: 成功实现了复杂场景下基带接收信号的逼真建模。

Conclusion: 该方法为高精度低成本的室内定位系统提供了可行的技术路径。

Abstract: Indoor localization with chirp sequence radar at millimeter wavelength offers
high localization accuracy at low system cost. We propose a hybrid radar
baseband signal simulator for our novel single-channel radar-based indoor
localization system consisting of an active radar and passive reflectors as
references. By combining ray tracing channel simulations with real measurements
of the two-way antenna gain of the radar and accurate simulation of the radar
cross section of chosen reflectors, realistic modeling of the baseband receive
signal in complex scenarios is achieved.

</details>


### [8] [Extended k-u Fading Model in mmWave Communication: Statistical Properties and Performance Evaluations](https://arxiv.org/abs/2509.15681)
*Jiahuan Wu,Xinchun Yu,Xiao-Ping Zhang*

Main category: eess.SP

TL;DR: 本文提出了一种名为扩展k-u模型的小尺度衰落模型，通过在原有k-u模型基础上引入新参数来表征多径簇的不平衡性。该模型在毫米波频段的衰落特性表征上优于k-u模型，且在具有视距路径的场景中比扩展n-u模型更精确，同时在数学上比a-k-n-u模型更易处理。


<details>
  <summary>Details</summary>
Motivation: 为更准确地表征毫米波频段的小尺度衰落特性，尤其是在具有视距路径的场景中，需要一种新的数学模型来弥补现有模型的不足。

Method: 研究基于k-u模型引入新参数，提出了扩展k-u模型，并通过实验在28 GHz、65 GHz和92 GHz频段验证其性能。

Result: 实验结果表明，扩展k-u模型在所有场景中均表现出比k-u模型和扩展n-u模型更小的均方误差，并通过理论推导得到了概率密度函数等关键统计特性的闭式表达。

Conclusion: 扩展k-u模型在毫米波频段的衰落建模中表现优越，为通信系统的性能分析提供了更准确的统计基础。

Abstract: This study proposes a small-scale fading model, named the extended k-u model,
which incorporates the imbalance of multipath clusters by adding a new
parameter based on the original k-u model. The extended k-u model outperforms
the k-u model in characterizing small-scale fading in the millimeter-wave
(mmWave) band and has more accurate modeling capability than the extended n-u
model in scenarios with line-of-sight (LoS) paths. And it is mathematically
more tractable than the a-k-n-u model. Experiments are conducted for mmWave
communication scenarios with LoS paths, covering the outdoor 28 GHz band, the
indoor 65 GHz band, and the indoor 92 GHz band. The results demonstrate that
the extended k-u model achieves a smaller mean square error in fitting the
measured data compared to both the k-u model and the extended n-u model across
all scenarios. In addition, through theoretical derivations, closed-form
expressions are obtained for the key statistical characteristics of the
extended k-u model, including the probability density function, cumulative
distribution function, moments of arbitrary order, and moment generating
function. Based on these statistics, this study further derives and analyzes
the expressions for some performance metrics of the communication system,
including the amount of fading, the probability of outage, and the average bit
error rate.

</details>


### [9] [Distributed Multi-Task Learning for Joint Wireless Signal Enhancement and Recognition](https://arxiv.org/abs/2509.15718)
*Hao Zhang,Fuhui Zhou,Qihui Wu,Chau Yuen*

Main category: eess.SP

TL;DR: 论文提出了一种分布式多任务学习框架WSERNet结合FedProx+算法，用于无线信号增强与识别，显著提升了低信噪比和异构数据分布下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决非协作无线信号识别在低信噪比和分布式网络中的挑战。

Method: 整合WSERNet（使用ACBlock捕捉信号长程依赖）和FedProx+（通过近端项增强联邦学习的鲁棒性）。

Result: 实验表明，该框架在集中式和分布式（IID与非IID）场景下均优于现有方法。

Conclusion: 提出的框架有效解决了无线信号识别中的关键问题，性能优越。

Abstract: Wireless signal recognition (WSR) is crucial in modern and future wireless
communication networks since it aims to identify the properties of the received
signal in a no-collaborative manner. However, it is challenging to accurately
classify signals in low signal-to-noise ratio (SNR) conditions and distributed
network settings. In this paper, we propose a novel distributed multi-task
learning framework for joint wireless signal enhancement and recognition
(WSER), addressing the crucial need for non-collaborative signal identification
in modern wireless networks. Our approach integrates a wireless signal
enhancement and recognition network (WSERNet) with FedProx+, an enhanced
federated learning algorithm designed for heterogeneous data distributions.
Specifically, WSERNet leverages an asymmetric convolution block (ACBlock) to
capture long-range dependencies in the input signal and improve the performance
of the deep learning model. FedProx+ introduces a proximal term to the loss
function to encourage the model updates to be closer to the previous model,
enhancing the convergence speed and robustness of federated learning. Extensive
experiments demonstrate the effectiveness of the proposed framework for joint
WSER, achieving superior performance compared to state-of-the-art methods under
both centralized and distributed settings including independent and identically
distributed (IID) and non-IID data distributions.

</details>


### [10] [Explainable Deep Learning Based Adversarial Defense for Automatic Modulation Classification](https://arxiv.org/abs/2509.15766)
*Peihao Dong,Jingchun Wang,Shen Gao,Fuhui Zhou,Qihui Wu*

Main category: eess.SP

TL;DR: 该论文提出了一种基于SHAP的可解释深度学习防御方案（SHAP-AFT），用于对抗自动调制分类（AMC）网络的攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的AMC神经网络易受对抗攻击影响，且难以处理其泛化能力和计算成本问题。

Method: SHAP-AFT方案分为三个阶段：攻击检测、信息重要性评估和对抗性微调（AFT）。通过识别负Shapley值去除攻击影响，并基于修正后的数据模式进行网络微调。

Result: 仿真结果表明，SHAP值作为关键指标的有效性，以及SHAP-AFT方案在面对不同攻击类型和强度时的优越防御性能。

Conclusion: SHAP-AFT是一种有效的可解释防御方案，能够显著提升AMC网络的抗攻击能力。

Abstract: Deep learning (DL) has been widely applied to enhance automatic modulation
classification (AMC). However, the elaborate AMC neural networks are
susceptible to various adversarial attacks, which are challenging to handle due
to the generalization capability and computational cost. In this article, an
explainable DL based defense scheme, called SHapley Additive exPlanation
enhanced Adversarial Fine-Tuning (SHAP-AFT), is developed in the perspective of
disclosing the attacking impact on the AMC network. By introducing the concept
of cognitive negative information, the motivation of using SHAP for defense is
theoretically analyzed first. The proposed scheme includes three stages, i.e.,
the attack detection, the information importance evaluation, and the AFT. The
first stage indicates the existence of the attack. The second stage evaluates
contributions of the received data and removes those data positions using
negative Shapley values corresponding to the dominating negative information
caused by the attack. Then the AMC network is fine-tuned based on adversarial
adaptation samples using the refined received data pattern. Simulation results
show the effectiveness of the Shapley value as the key indicator as well as the
superior defense performance of the proposed SHAP-AFT scheme in face of
different attack types and intensities.

</details>


### [11] [Fundamental Limits of THz Inter-Satellite ISAC Under Hardware Impairments](https://arxiv.org/abs/2509.15902)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 论文提出了一个分析太赫兹（THz）低地球轨道（LEO）卫星间链路（ISL）集成感知与通信（ISAC）系统性能极限的理论框架，揭示感知精度随载频频率的二次改进以及硬件失真对容量的关键限制。


<details>
  <summary>Details</summary>
Motivation: 研究太赫兹LEO ISL ISAC系统的性能极限，以解决极端轨道动力学、硬件缺陷和微小波束指向误差的联合影响问题。

Method: 建立端到端信号模型，通过贝叶斯克拉美罗下界（BCRLB）分析感知精度，推导硬件限制下的通信容量上限。

Result: 研究表明，200-600 GHz亚太赫兹频段存在性能平衡点，功率放大器非线性是主要瓶颈。

Conclusion: 太赫兹频段在感知和通信性能间存在平衡点，硬件质量是关键限制因素。

Abstract: This paper establishes a theoretical framework for analyzing the fundamental
performance limits of terahertz (THz) Low Earth Orbit (LEO) inter-satellite
link (ISL) Integrated Sensing and Communications (ISAC) systems. We develop a
unified, end-to-end signal model that, jointly captures the effects of extreme
orbital dynamics, cascaded non-ideal hardware impairments, and micro-radian
beam pointing errors. Through Bayesian Cram\'er-Rao Lower Bound (BCRLB)
analysis, we derive the ultimate sensing accuracy for range and range-rate,
revealing a quadratic ($1/f_c^2$) improvement in estimation variance with
carrier frequency, which is ultimately floored by signal-dependent hardware
distortion. For communication, we show that system performance is not
power-limited but hardware-limited, deriving a closed-form capacity ceiling
under the joint effect of phase noise and PA nonlinearity: $C_{\text{sat}} =
\log_2(1 + e^{-\sigma_\phi^2}/\Gamma_{\text{eff}})$, where
$\Gamma_{\text{eff}}$ is a proposed hardware quality factor. Our numerical
results, based on state-of-the-art component data and the identified
trade-offs, suggest that favorable operational conditions may exist in the
sub-THz frequency range (200-600 GHz) where the quadratic sensing gain with
frequency is balanced against hardware quality degradation. Power Amplifier
(PA) nonlinearity emerges as the dominant performance bottleneck, exceeding
other impairments by one to two orders of magnitude.

</details>


### [12] [MoE-CE: Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework](https://arxiv.org/abs/2509.15964)
*Tianyu Li,Yan Xin,Jianzhong,Zhang*

Main category: eess.SP

TL;DR: MoE-CE是一种基于混合专家（MoE）框架的深度学习信道估计方法，旨在提升在多变无线环境中的泛化能力。通过动态选择专家子网络，它在多任务和零样本场景中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在多变信道条件下（如SNR、RB数量和信道配置文件）的泛化能力不足，尤其在多任务和零样本场景中表现不佳，因此需要一种更灵活的方法。

Method: 提出了MoE-CE框架，结合多个专家子网络和一个学习路由器，动态选择最适合输入的专家子网络，以提高模型容量和适应性。

Result: 实验表明，MoE-CE在多种SNR、RB数量和信道配置文件下的性能优于传统方法，且计算效率高。

Conclusion: MoE-CE通过动态路由和多专家设计，显著提升了信道估计的泛化能力和性能，适用于复杂无线环境。

Abstract: Reliable channel estimation (CE) is fundamental for robust communication in
dynamic wireless environments, where models must generalize across varying
conditions such as signal-to-noise ratios (SNRs), the number of resource blocks
(RBs), and channel profiles. Traditional deep learning (DL)-based methods
struggle to generalize effectively across such diverse settings, particularly
under multitask and zero-shot scenarios. In this work, we propose MoE-CE, a
flexible mixture-of-experts (MoE) framework designed to enhance the
generalization capability of DL-based CE methods. MoE-CE provides an
appropriate inductive bias by leveraging multiple expert subnetworks, each
specialized in distinct channel characteristics, and a learned router that
dynamically selects the most relevant experts per input. This architecture
enhances model capacity and adaptability without a proportional rise in
computational cost while being agnostic to the choice of the backbone model and
the learning algorithm. Through extensive experiments on synthetic datasets
generated under diverse SNRs, RB numbers, and channel profiles, including
multitask and zero-shot evaluations, we demonstrate that MoE-CE consistently
outperforms conventional DL approaches, achieving significant performance gains
while maintaining efficiency.

</details>


### [13] [Scalable Hessian-free Proximal Conjugate Gradient Method for Nonconvex and Nonsmooth Optimization](https://arxiv.org/abs/2509.15973)
*Yiming Zhou,Wei Dai*

Main category: eess.SP

TL;DR: 该论文研究了涉及可微函数q和非光滑函数h的复合最小化问题，提出了近端共轭梯度法（PCG），以解决大规模、病态和非凸性问题，并通过数值实验验证了其效率。


<details>
  <summary>Details</summary>
Motivation: 在信号处理和机器学习中，复合最小化问题（结合非凸和非光滑函数）的求解在大规模、病态和非凸性下仍面临效率挑战。

Method: 提出了一种近端共轭梯度法（PCG），利用共轭梯度迭代近似牛顿方向，并通过曲率感知和CG各向同性权重构建代理函数，保持代理函数在局部二阶模型上的优势。

Result: 通过自动微分实现的Hessian-向量乘积避免了显式计算Hessian矩阵，数值实验在非凸正则化的CS-MRI和字典学习中证明了该方法的效率。

Conclusion: PCG方法在保证快速收敛的同时降低了计算和内存复杂度，尤其适用于谱聚类的Hessian矩阵，且能收敛到一阶临界点。

Abstract: This work studies a composite minimization problem involving a differentiable
function q and a nonsmooth function h, both of which may be nonconvex. This
problem is ubiquitous in signal processing and machine learning yet remains
challenging to solve efficiently, particularly when large-scale instances, poor
conditioning, and nonconvexity coincide. To address these challenges, we
propose a proximal conjugate gradient method (PCG) that matches the fast
convergence of proximal (quasi-)Newton algorithms while reducing computation
and memory complexity, and is especially effective for spectrally clustered
Hessians. Our key innovation is to form, at each iteration, an approximation to
the Newton direction based on CG iterations to build a majorization surrogate.
We define this surrogate in a curvature-aware manner and equip it with a
CG-derived isotropic weight, guaranteeing majorization of a local second-order
model of q along the given direction. To better preserve majorization after the
proximal step and enable further approximation refinement, we scale the CG
direction by the ratio between the Cauchy step length and a step size derived
from the largest Ritz value of the CG tridiagonal. All curvature is accessed
via Hessian-vector products computed by automatic differentiation, keeping the
method Hessian-free. Convergence to first-order critical points is established.
Numerical experiments on CS-MRI with nonconvex regularization and on dictionary
learning, against benchmark methods, demonstrate the efficiency of the proposed
approach.

</details>


### [14] [Wireless Channel Foundation Model with Embedded Noise-Plus-Interference Suppression Structure](https://arxiv.org/abs/2509.15993)
*Yuwei Wang,Li Sun,Tingting Yang*

Main category: eess.SP

TL;DR: WCFM是一种通用的无线信道特征表示模型，但其训练依赖于完美CSI数据，而实际系统中的CSI存在噪声和干扰。本文提出了一种具有NPI抑制能力的增强型WCFM架构，通过估计和消除干扰提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有WCFM模型依赖完美CSI数据，而实际系统中CSI受到噪声和干扰影响，导致下游任务性能下降，需解决这一问题。

Method: 提出增强型WCFM架构，包括NPI估计和消除模块，以及CSI补全网络，生成干净的CSI用于特征提取。

Result: 仿真结果显示，相比现有方案，增强型WCFM在信道预测任务中表现更优。

Conclusion: 通过NPI抑制技术，增强型WCFM能够更好地适应实际系统中的噪声和干扰环境，提升下游任务性能。

Abstract: Wireless channel foundation model (WCFM) is a task-agnostic AI model that is
pretrained on large-scale wireless channel datasets to learn a universal
channel feature representation that can be used for a wide range of downstream
tasks related to communications and sensing. While existing works on WCFM have
demonstrated its great potentials in various tasks including beam prediction,
channel prediction, localization, etc, the models are all trained using perfect
(i.e., error-free and complete) channel information state (CSI) data which are
generated with simulation tools. However, in practical systems where the WCFM
is deployed, perfect CSI is not available. Instead, channel estimation needs to
be first performed based on pilot signals over a subset of the resource
elements (REs) to acquire a noisy version of the CSI (termed as degraded CSI),
which significantly differs from the perfect CSI in some real-world
environments with severe noise and interference. As a result, the feature
representation generated by the WCFM is unable to reflect the characteristics
of the true channel, yielding performance degradation in downstream tasks. To
address this issue, in this paper we propose an enhanced wireless channel
foundation model architecture with noise-plus-interference (NPI) suppression
capability. In our approach, coarse estimates of the CSIs are first obtained.
With these information, two projection matrices are computed to extract the NPI
terms in the received signals, which are further processed by a NPI estimation
and subtraction module. Finally, the resultant signal is passed through a CSI
completion network to get a clean version of the CSI, which is used for feature
extraction. Simulation results demonstrated that compared to the
state-of-the-art solutions, WCFM with NPI suppression structure achieves
improved performance on channel prediction task.

</details>


### [15] [Secure Multicast Communications with Pinching-Antenna Systems (PASS)](https://arxiv.org/abs/2509.16045)
*Shan Shan,Chongjun Ouyang,Yong Li,Yuanwei Liu*

Main category: eess.SP

TL;DR: 研究通过调整捏缩天线位置实现安全多播通信的系统（PASS），提出联合优化发射和捏缩波束成形以最大化保密多播速率的方法，并在多种场景下验证其性能优势。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过动态调整天线位置提升多播通信的安全性，尤其是在存在窃听者的场景下。

Method: 提出PASS框架，采用交替优化方法，包括元素级序列优化（单组）和MM框架（多组），结合SDR、ADMM和SOCP等技术。

Result: PASS在全场景下保密性能优于固定天线架构，且在较大服务区、更多天线和用户密度时优势更显著。

Conclusion: PASS通过动态天线调整显著提升多播安全性，是未来安全通信的有力候选方案。

Abstract: This article investigates secure multicast communications in pinching-antenna
systems (PASS), where pinching beamforming is enabled by adaptively adjusting
pinching antenna (PAs) positions along waveguides to improve multicast
security. Specifically, a PASS-based secure multicast framework is proposed, in
which joint optimization of transmit and pinching beamforming is conducted to
maximize the secrecy multicast rate. i) For the single-group multicast
scenario, an alternating optimization (AO) framework is employed, where the
pinching beamformer is updated via an element-wise sequential optimization
method. The transmit beamformer is designed via a semidefinite relaxation (SDR)
formulation for an upper-bound solution, while a Dinkelbach-alternating
direction method of multipliers (ADMM) offers a low-complexity alternative. ii)
For the multi-group multicast scenario, transmit and pinching beamformers are
alternately optimized under a majorization-minimization (MM) framework. The
transmit beamformer is obtained via SDR or an efficient second-order cone
programming (SOCP) method, while the pinching beamformer is updated through
MM-based element-wise sequential update strategy. Numerical results are
provided to demonstrate that: (i) PASS consistently outperform conventional
fixed-location antenna architectures in terms of secrecy performance across
various configurations; and (ii) the performance advantage of PASS over
fixed-location architectures becomes more significant with increased service
region, larger antenna arrays, and higher user and eavesdropper densities.

</details>


### [16] [In-Situ Fault Detection of Submerged Pump Impellers Using Encapsulated Accelerometers and Machine Learning](https://arxiv.org/abs/2509.16086)
*Sahil P. Wankhede,Xiangdong Xie,Ali H. Alshehri,Keith W Brashler,Mohammad Ba'adani,Doru C Turcan,Kamal Youcef-Toumi,Xian Du*

Main category: eess.SP

TL;DR: 研究首次在垂直涡轮泵的潜水叶轮上部署封装加速度计，实现在恶劣环境下的振动监测，实验室测试显示高准确性和可靠性，优于非潜水传感器。


<details>
  <summary>Details</summary>
Motivation: 传统电机安装的加速度计无法检测潜水叶轮故障，因此需要解决水下环境中的故障监测问题。

Method: 在实验室规模的泵装置中，直接安装封装加速度计于潜水叶轮上，收集正常和模拟故障状态的振动数据，并运用多种机器学习模型分析。

Result: 潜水叶轮安装的传感器平均准确率达91.3%，AUC-ROC为0.973，优于非潜水传感器，且封装对性能无显著影响。

Conclusion: 该方法能可靠检测潜水叶轮故障，实现早期故障检测，减少停机时间，优化石油和天然气行业井下系统的维护。

Abstract: Vertical turbine pumps in oil and gas operations rely on motor-mounted
accelerometers for condition monitoring. However, these sensors cannot detect
faults at submerged impellers exposed to harsh downhole environments. We
present the first study deploying encapsulated accelerometers mounted directly
on submerged impeller bowls, enabling in-situ vibration monitoring. Using a
lab-scale pump setup with 1-meter oil submergence, we collected vibration data
under normal and simulated fault conditions. The data were analyzed using a
suite of machine learning models -- spanning traditional and deep learning
methods -- to evaluate sensor effectiveness. Impeller-mounted sensors achieved
91.3% average accuracy and 0.973 AUC-ROC, outperforming the best non-submerged
sensor. Crucially, encapsulation caused no statistically significant
performance loss in sensor performance, confirming its viability for
oil-submerged environments. While the lab setup used shallow submergence,
real-world pump impellers operate up to hundreds of meters underground -- well
beyond the range of surface-mounted sensors. This first-of-its-kind in-situ
monitoring system demonstrates that impeller-mounted sensors -- encapsulated
for protection while preserving diagnostic fidelity -- can reliably detect
faults in critical submerged pump components. By capturing localized vibration
signatures that are undetectable from surface-mounted sensors, this approach
enables earlier fault detection, reduces unplanned downtime, and optimizes
maintenance for downhole systems in oil and gas operations.

</details>


### [17] [Xona Pulsar Compatibility with GNSS](https://arxiv.org/abs/2509.16183)
*Tyler G. R. Reid,Matteo Gala,Mathieu Favreau,Argyris Kriezis,Michael O'Meara,Andre Pant,Paul Tarantino,Christina Youn*

Main category: eess.SP

TL;DR: Xona的Pulsar卫星导航系统设计为与现有GNSS兼容，通过硬件测试证明其信号不会对GPS和伽利略造成干扰。


<details>
  <summary>Details</summary>
Motivation: 确保新兴的LEO卫星导航系统与现有GNSS的L波段兼容，以促进全球导航生态系统的成功部署。

Method: 通过理论分析和硬件测试，评估Pulsar的X1和X5信号对GPS和伽利略的C/N0性能影响。

Result: Pulsar信号不会对现有GNSS产生不良干扰，支持其与全球PNT生态系统的共存与集成。

Conclusion: Pulsar的设计和测试结果表明其与现有GNSS兼容，为未来的导航系统集成提供了可行性。

Abstract: At least ten emerging providers are developing satellite navigation systems
for low Earth orbit (LEO). Compatibility with existing GNSS in L-band is
critical to their successful deployment and for the larger ecosystem. Xona is
deploying Pulsar, a near 260-satellite LEO constellation offering dual L-band
navigation services near L1 and L5. Designed for interoperability, Pulsar
provides centimeter-level accuracy, resilience, and authentication, while
maintaining a format that existing GNSS receivers can support through a
firmware update. This study examines Pulsar's compatibility with GPS and
Galileo by evaluating C/N0 degradation caused by the introduction of its X1 and
X5 signals. Using spectrally compact QPSK modulation, Pulsar minimizes
interference despite higher signal power. Theoretical analysis is supported by
hardware testing across a range of commercial GNSS receivers in both lab-based
simulation and in-orbit live-sky conditions. The study confirms Pulsar causes
no adverse interference effects to existing GNSS, supporting coexistence and
integration within the global PNT ecosystem.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [18] [DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects](https://arxiv.org/abs/2509.15254)
*Ngoc Huy Nguyen,Kazuki Shibata,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文研究使用四足机器人和篮子实现空中物体捕捉，通过构建数据集和提出DIPP方法解决预测物体落点的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决空中物体捕捉中缺乏多样化数据集和早期轨迹预测难的问题。

Method: 构建包含8000条轨迹的真实数据集，并设计DIPP方法（包含DFE模块和两种IPP变体）。

Result: 数据集更复杂多样，DIPP方法在15种已知和5种未知物体上优于基线，早期预测提升捕捉成功率。

Conclusion: DIPP方法有效解决物体落点预测问题，并通过实验验证其性能。

Abstract: In this study, we address the problem of in-flight object catching using a
quadruped robot with a basket. Our objective is to accurately predict the
impact point, defined as the object's landing position. This task poses two key
challenges: the absence of public datasets capturing diverse objects under
unsteady aerodynamics, which are essential for training reliable predictors;
and the difficulty of accurate early-stage impact point prediction when
trajectories appear similar across objects. To overcome these issues, we
construct a real-world dataset of 8,000 trajectories from 20 objects, providing
a foundation for advancing in-flight object catching under complex
aerodynamics. We then propose the Discriminative Impact Point Predictor (DIPP),
consisting of two modules: (i) a Discriminative Feature Embedding (DFE) that
separates trajectories by dynamics to enable early-stage discrimination and
generalization, and (ii) an Impact Point Predictor (IPP) that estimates the
impact point from these features. Two IPP variants are implemented: an Neural
Acceleration Estimator (NAE)-based method that predicts trajectories and
derives the impact point, and a Direct Point Estimator (DPE)-based method that
directly outputs it. Experimental results show that our dataset is more diverse
and complex than existing dataset, and that our method outperforms baselines on
both 15 seen and 5 unseen objects. Furthermore, we show that improved
early-stage prediction enhances catching success in simulation and demonstrate
the effectiveness of our approach through real-world experiments. The
demonstration is available at
https://sites.google.com/view/robot-catching-2025.

</details>


### [19] [GiAnt: A Bio-Inspired Hexapod for Adaptive Terrain Navigation and Object Detection](https://arxiv.org/abs/2509.15264)
*Aasfee Mosharraf Bhuiyan,Md Luban Mehda,Md. Thawhid Hasan Puspo,Jubayer Amin Pritom*

Main category: cs.RO

TL;DR: 本文介绍了GiAnt的设计、开发与测试，这是一款受蚂蚁高效运动启发的经济型六足机器人，具有地形适应性强和能耗低的优势。


<details>
  <summary>Details</summary>
Motivation: 通过仿生蚂蚁的运动设计，GiAnt能够在复杂地形中高效移动，适用于户外应用。

Method: 采用轻量化的3D打印和激光切割结构，单自由度腿部设计，基于Arduino的控制系统，并结合机器学习与图像处理技术。

Result: GiAnt能够轻松攀爬8厘米高的障碍，并在实时监测中识别81种不同物体，展现了优越的地形适应性和控制简便性。

Conclusion: GiAnt为研究、勘探和测绘提供了经济且适应性强的六足机器人解决方案，展现了仿生设计的潜力。

Abstract: This paper presents the design, development and testing of GiAnt, an
affordable hexapod which is inspired by the efficient motions of ants. The
decision to model GiAnt after ants rather than other insects is rooted in ants'
natural adaptability to a variety of terrains. This bio-inspired approach gives
it a significant advantage in outdoor applications, offering terrain
flexibility along with efficient energy use. It features a lightweight
3D-printed and laser cut structure weighing 1.75 kg with dimensions of 310 mm x
200 mm x 120 mm. Its legs have been designed with a simple Single Degree of
Freedom (DOF) using a link and crank mechanism. It is great for conquering
challenging terrains such as grass, rocks, and steep surfaces. Unlike
traditional robots using four wheels for motion, its legged design gives
superior adaptability to uneven and rough surfaces. GiAnt's control system is
built on Arduino, allowing manual operation. An effective way of controlling
the legs of GiAnt was achieved by gait analysis. It can move up to 8 cm of
height easily with its advanced leg positioning system. Furthermore, equipped
with machine learning and image processing technology, it can identify 81
different objects in a live monitoring system. It represents a significant step
towards creating accessible hexapod robots for research, exploration, and
surveying, offering unique advantages in adaptability and control simplicity.

</details>


### [20] [Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI](https://arxiv.org/abs/2509.15273)
*Fei Ni,Min Zhang,Pengyi Li,Yifu Yuan,Lingfeng Zhang,Yuecheng Liu,Peilong Han,Longxin Kou,Shaojin Ma,Jinbin Qiao,David Gamaliel Arcos Bravo,Yuening Wang,Xiao Hu,Zhanguang Zhang,Xianze Yao,Yutong Li,Zhao Zhang,Ying Wen,Ying-Cong Chen,Xiaodan Liang,Liang Lin,Bin He,Haitham Bou-Ammar,He Wang,Huazhe Xu,Jiankang Deng,Shan Luo,Shuqiang Jiang,Wei Pan,Yang Gao,Stefanos Zafeiriou,Jan Peters,Yuzheng Zhuang,Yingxue Zhang,Yan Zheng,Hongyao Tang,Jianye Hao*

Main category: cs.RO

TL;DR: Embodied AI发展面临三大挑战：能力定义不清、评估系统不统一、数据获取困难。Embodied Arena平台提出系统性能力分类、标准化评估系统和自动化数据生成，推动领域进步。


<details>
  <summary>Details</summary>
Motivation: 解决Embodied AI研究中缺乏目标统一、评估分散和数据不足的问题。

Method: 构建系统化能力分类（3层级、7核心能力、25维度）、标准化评估系统和LLM驱动的自动化数据生成管道。

Result: 推出三大实时排行榜，总结九大发现，帮助明确研究方向。

Conclusion: Embodied Arena通过统一标准和自动化解决了关键挑战，推动了Embodied AI的发展。

Abstract: Embodied AI development significantly lags behind large foundation models due
to three critical challenges: (1) lack of systematic understanding of core
capabilities needed for Embodied AI, making research lack clear objectives; (2)
absence of unified and standardized evaluation systems, rendering
cross-benchmark evaluation infeasible; and (3) underdeveloped automated and
scalable acquisition methods for embodied data, creating critical bottlenecks
for model scaling. To address these obstacles, we present Embodied Arena, a
comprehensive, unified, and evolving evaluation platform for Embodied AI. Our
platform establishes a systematic embodied capability taxonomy spanning three
levels (perception, reasoning, task execution), seven core capabilities, and 25
fine-grained dimensions, enabling unified evaluation with systematic research
objectives. We introduce a standardized evaluation system built upon unified
infrastructure supporting flexible integration of 22 diverse benchmarks across
three domains (2D/3D Embodied Q&A, Navigation, Task Planning) and 30+ advanced
models from 20+ worldwide institutes. Additionally, we develop a novel
LLM-driven automated generation pipeline ensuring scalable embodied evaluation
data with continuous evolution for diversity and comprehensiveness. Embodied
Arena publishes three real-time leaderboards (Embodied Q&A, Navigation, Task
Planning) with dual perspectives (benchmark view and capability view),
providing comprehensive overviews of advanced model capabilities. Especially,
we present nine findings summarized from the evaluation results on the
leaderboards of Embodied Arena. This helps to establish clear research veins
and pinpoint critical research problems, thereby driving forward progress in
the field of Embodied AI.

</details>


### [21] [Measurement and Potential Field-Based Patient Modeling for Model-Mediated Tele-ultrasound](https://arxiv.org/abs/2509.15325)
*Ryan S. Yeung,David G. Black,Septimiu E. Salcudean*

Main category: cs.RO

TL;DR: 该论文提出了一种基于点云和势场模型的远程超声触觉反馈方法，通过测量力和位置更新模型，提高了力的反馈精度。


<details>
  <summary>Details</summary>
Motivation: 为了改善远程超声诊断中时间延迟对触觉反馈的影响，研究者尝试通过模型介导的远程操作提供更准确的力反馈。

Method: 论文提出了一种方法，通过点云模型和静态体素化体积更新患者的势场模型，利用凸二次优化结合拉普拉斯算子和测量力来计算势场，从而实现更透明的力反馈。

Result: 实验结果表明，该方法将力幅误差平均减少了7.23 N，力矢量角度误差平均减少了9.37°。

Conclusion: 通过引入测量力更新势场模型，该方法显著提高了远程超声力反馈的准确性。

Abstract: Teleoperated ultrasound can improve diagnostic medical imaging access for
remote communities. Having accurate force feedback is important for enabling
sonographers to apply the appropriate probe contact force to optimize
ultrasound image quality. However, large time delays in communication make
direct force feedback impractical. Prior work investigated using point
cloud-based model-mediated teleoperation and internal potential field models to
estimate contact forces and torques. We expand on this by introducing a method
to update the internal potential field model of the patient with measured
positions and forces for more transparent model-mediated tele-ultrasound. We
first generate a point cloud model of the patient's surface and transmit this
to the sonographer in a compact data structure. This is converted to a static
voxelized volume where each voxel contains a potential field value. These
values determine the forces and torques, which are rendered based on overlap
between the voxelized volume and a point shell model of the ultrasound
transducer. We solve for the potential field using a convex quadratic that
combines the spatial Laplace operator with measured forces. This was evaluated
on volunteer patients ($n=3$) by computing the accuracy of rendered forces.
Results showed the addition of measured forces to the model reduced the force
magnitude error by an average of 7.23 N and force vector angle error by an
average of 9.37$^{\circ}$ compared to using only Laplace's equation.

</details>


### [22] [Trust-Aware Embodied Bayesian Persuasion for Mixed-Autonomy](https://arxiv.org/abs/2509.15404)
*Shaoting Peng,Katherine Driggs-Campbell,Roy Dong*

Main category: cs.RO

TL;DR: 论文提出了一种基于信任的贝叶斯说服框架（TA-EBP），通过透明沟通提升自动驾驶车辆与人类驾驶车辆的交互安全与效率。


<details>
  <summary>Details</summary>
Motivation: 传统博弈论模型存在影响力衰减和操控性问题，可能削弱信任并导致人类驾驶行为变得更危险，因此需要一种更透明的交互框架。

Method: TA-EBP框架结合贝叶斯说服理论和信任参数，设计了连续且物理可解释的信号空间，并通过仿真验证其有效性。

Result: TA-EBP能有效说服人类驾驶车辆更谨慎，消除碰撞并改善交通流，表现优于忽略信任或缺乏沟通的基线方法。

Conclusion: TA-EBP提供了一种透明、非策略化的交互框架，显著提升了人与机器交互的安全性和效率。

Abstract: Safe and efficient interaction between autonomous vehicles (AVs) and
human-driven vehicles (HVs) is a critical challenge for future transportation
systems. While game-theoretic models capture how AVs influence HVs, they often
suffer from a long-term decay of influence and can be perceived as
manipulative, eroding the human's trust. This can paradoxically lead to riskier
human driving behavior over repeated interactions. In this paper, we address
this challenge by proposing the Trust-Aware Embodied Bayesian Persuasion
(TA-EBP) framework. Our work makes three key contributions: First, we apply
Bayesian persuasion to model communication at traffic intersections, offering a
transparent alternative to traditional game-theoretic models. Second, we
introduce a trust parameter to the persuasion framework, deriving a theorem for
the minimum trust level required for influence. Finally, we ground the abstract
signals of Bayesian persuasion theory into a continuous, physically meaningful
action space, deriving a second theorem for the optimal signal magnitude,
realized as an AV's forward nudge. Additionally, we validate our framework in a
mixed-autonomy traffic simulation, demonstrating that TA-EBP successfully
persuades HVs to drive more cautiously, eliminating collisions and improving
traffic flow compared to baselines that either ignore trust or lack
communication. Our work provides a transparent and non-strategic framework for
influence in human-robot interaction, enhancing both safety and efficiency.

</details>


### [23] [Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control](https://arxiv.org/abs/2509.15412)
*Easop Lee,Samuel A. Moore,Boyuan Chen*

Main category: cs.RO

TL;DR: Sym2Real是一种高效数据驱动的低级别自适应控制器训练框架，仅需约10条轨迹即可实现四旋翼和赛车的鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 解决符号回归在机器人领域应用中的噪声敏感性和模型退化问题，通过结合低仿真数据和实际残差学习提升数据效率。

Method: 利用低仿真数据和实际残差学习的策略组合，共享系统物理特性以实现高效适应。

Result: 在四旋翼和赛车平台上验证了数据高效适应性，并在5种真实场景中成功实现仿真到实际的迁移。

Conclusion: Sym2Real框架在数据效率和鲁棒性方面表现出色，适用于复杂控制任务。

Abstract: We present Sym2Real, a fully data-driven framework that provides a principled
way to train low-level adaptive controllers in a highly data-efficient manner.
Using only about 10 trajectories, we achieve robust control of both a quadrotor
and a racecar in the real world, without expert knowledge or simulation tuning.
Our approach achieves this data efficiency by bringing symbolic regression to
real-world robotics while addressing key challenges that prevent its direct
application, including noise sensitivity and model degradation that lead to
unsafe control. Our key observation is that the underlying physics is often
shared for a system regardless of internal or external changes. Hence, we
strategically combine low-fidelity simulation data with targeted real-world
residual learning. Through experimental validation on quadrotor and racecar
platforms, we demonstrate consistent data-efficient adaptation across six
out-of-distribution sim2sim scenarios and successful sim2real transfer across
five real-world conditions. More information and videos can be found at at
http://generalroboticslab.com/Sym2Real

</details>


### [24] [Online Slip Detection and Friction Coefficient Estimation for Autonomous Racing](https://arxiv.org/abs/2509.15423)
*Christopher Oeltjen,Carson Sobolewski,Saleh Faghfoorian,Lorant Domokos,Giancarlo Vidal,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 论文提出了一种轻量级的在线滑移检测和TRFC估计方法，仅需IMU、LiDAR和控制动作数据，无需依赖复杂模型或训练数据。实验验证了其精确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶赛车等高需求场景中，准确估计轮胎-路面摩擦系数对安全和性能至关重要，但现有方法依赖模型或大数据，难以实时实现。

Method: 通过比较实际与指令运动，实时检测滑移事件；在无滑移条件下直接利用观测加速度估计TRFC，无需模型或训练数据。

Result: 1:10比例自动驾驶赛车实验中，该方法实现了与真实值高度一致的滑移检测和摩擦系数估计。

Conclusion: 该方法简单、可部署且计算高效，适用于实时滑移监测和摩擦系数估计，展示了在自动驾驶中的潜力。

Abstract: Accurate knowledge of the tire-road friction coefficient (TRFC) is essential
for vehicle safety, stability, and performance, especially in autonomous
racing, where vehicles often operate at the friction limit. However, TRFC
cannot be directly measured with standard sensors, and existing estimation
methods either depend on vehicle or tire models with uncertain parameters or
require large training datasets. In this paper, we present a lightweight
approach for online slip detection and TRFC estimation. Our approach relies
solely on IMU and LiDAR measurements and the control actions, without special
dynamical or tire models, parameter identification, or training data. Slip
events are detected in real time by comparing commanded and measured motions,
and the TRFC is then estimated directly from observed accelerations under
no-slip conditions. Experiments with a 1:10-scale autonomous racing car across
different friction levels demonstrate that the proposed approach achieves
accurate and consistent slip detections and friction coefficients, with results
closely matching ground-truth measurements. These findings highlight the
potential of our simple, deployable, and computationally efficient approach for
real-time slip monitoring and friction coefficient estimation in autonomous
driving.

</details>


### [25] [Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning](https://arxiv.org/abs/2509.15443)
*Xingyu Chen,Hanyu Wu,Sikai Wu,Mingliang Zhou,Diyun Xiang,Haodong Zhang*

Main category: cs.RO

TL;DR: IKMR是一种高效可扩展的运动重定向框架，结合运动学与动力学，实现大规模实时运动转换与控制器训练。


<details>
  <summary>Details</summary>
Motivation: 当前逐帧运动重定向方法缺乏可扩展性，如何高效地将大规模人类运动转换为机器人可执行运动是一大挑战。

Method: IKMR框架在运动学部分预训练运动拓扑特征表示和双编码器-解码器结构；动力学部分结合模仿学习与重定向网络，优化运动为物理可行轨迹。

Result: 通过仿真和真实机器人实验验证，IKMR实现了大规模实时物理可行运动重定向，并可直接训练全身控制器。

Conclusion: IKMR框架在高效性和可扩展性上表现优越，为机器人运动学习和控制器部署提供了新思路。

Abstract: Human-to-humanoid imitation learning aims to learn a humanoid whole-body
controller from human motion. Motion retargeting is a crucial step in enabling
robots to acquire reference trajectories when exploring locomotion skills.
However, current methods focus on motion retargeting frame by frame, which
lacks scalability. Could we directly convert large-scale human motion into
robot-executable motion through a more efficient approach? To address this
issue, we propose Implicit Kinodynamic Motion Retargeting (IKMR), a novel
efficient and scalable retargeting framework that considers both kinematics and
dynamics. In kinematics, IKMR pretrains motion topology feature representation
and a dual encoder-decoder architecture to learn a motion domain mapping. In
dynamics, IKMR integrates imitation learning with the motion retargeting
network to refine motion into physically feasible trajectories. After
fine-tuning using the tracking results, IKMR can achieve large-scale physically
feasible motion retargeting in real time, and a whole-body controller could be
directly trained and deployed for tracking its retargeted trajectories. We
conduct our experiments both in the simulator and the real robot on a full-size
humanoid robot. Extensive experiments and evaluation results verify the
effectiveness of our proposed framework.

</details>


### [26] [Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems](https://arxiv.org/abs/2509.15491)
*Reza Pirayeshshirazinezhad,Nima Fathi*

Main category: cs.RO

TL;DR: 本文提出了一种可解释的AI增强监督控制框架，用于多智能体机器人系统，结合了时序自动机监督、鲁棒连续控制和可解释性预测器，验证了其在航天器和水下机器人中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体机器人系统中安全性和可解释性控制的挑战，提供一个透明且可移植的框架。

Method: 结合时序自动机监督、鲁棒连续控制（李雅普诺夫控制器和滑动模式控制器）以及通过蒙特卡洛优化的可解释性预测器。

Result: 在航天器和水下机器人测试中，该方法显著降低了跟踪误差（21.7%）和能量消耗（81.4%），并在随机扰动下保持了稳定性能。

Conclusion: 该框架在安全关键、资源受限的多智能体机器人系统中具有高度的可移植性和可解释性。

Abstract: We present an explainable AI-enhanced supervisory control framework for
multi-agent robotics that combines (i) a timed-automata supervisor for safe,
auditable mode switching, (ii) robust continuous control (Lyapunov-based
controller for large-angle maneuver; sliding-mode controller (SMC) with
boundary layers for precision and disturbance rejection), and (iii) an
explainable predictor that maps mission context to gains and expected
performance (energy, error). Monte Carlo-driven optimization provides the
training data, enabling transparent real-time trade-offs.
  We validated the approach in two contrasting domains, spacecraft formation
flying and autonomous underwater vehicles (AUVs). Despite different
environments (gravity/actuator bias vs. hydrodynamic drag/currents), both share
uncertain six degrees of freedom (6-DOF) rigid-body dynamics, relative motion,
and tight tracking needs, making them representative of general robotic
systems. In the space mission, the supervisory logic selects parameters that
meet mission criteria. In AUV leader-follower tests, the same SMC structure
maintains a fixed offset under stochastic currents with bounded steady error.
In spacecraft validation, the SMC controller achieved submillimeter alignment
with 21.7% lower tracking error and 81.4% lower energy consumption compared to
Proportional-Derivative PD controller baselines. At the same time, in AUV
tests, SMC maintained bounded errors under stochastic currents. These results
highlight both the portability and the interpretability of the approach for
safety-critical, resource-constrained multi-agent robotics.

</details>


### [27] [STARC: See-Through-Wall Augmented Reality Framework for Human-Robot Collaboration in Emergency Response](https://arxiv.org/abs/2509.15507)
*Shenghai Yuan,Weixiang Guo,Tianxin Hu,Yu Yang,Jinyu Chen,Rui Qian,Zhongyuan Liu,Lihua Xie*

Main category: cs.RO

TL;DR: STARC框架通过融合机器人LiDAR与救援人员的LiDAR数据，实现实时AR透视功能，提升紧急救援中的情境感知能力。


<details>
  <summary>Details</summary>
Motivation: 在紧急救援任务中，救援人员常因视线遮挡无法直接发现隐藏的危险或受害者，亟需技术提升情境感知。

Method: 结合移动机器人和救援人员头盔或手持LiDAR的感知数据，通过相对位姿估计实现LiDAR数据对齐，并通过AR低延迟渲染显示隐藏的人和危险。

Result: 在仿真、实验室和实地测试中，STARC展示了稳定的位姿对齐、可靠的目标检测和AR叠加效果。

Conclusion: STARC系统具有在消防、灾难救援等安全关键任务中的实际应用潜力，代码和设计将开源。

Abstract: In emergency response missions, first responders must navigate cluttered
indoor environments where occlusions block direct line-of-sight, concealing
both life-threatening hazards and victims in need of rescue. We present STARC,
a see-through AR framework for human-robot collaboration that fuses
mobile-robot mapping with responder-mounted LiDAR sensing. A ground robot
running LiDAR-inertial odometry performs large-area exploration and 3D human
detection, while helmet- or handheld-mounted LiDAR on the responder is
registered to the robot's global map via relative pose estimation. This
cross-LiDAR alignment enables consistent first-person projection of detected
humans and their point clouds - rendered in AR with low latency - into the
responder's view. By providing real-time visualization of hidden occupants and
hazards, STARC enhances situational awareness and reduces operator risk.
Experiments in simulation, lab setups, and tactical field trials confirm robust
pose alignment, reliable detections, and stable overlays, underscoring the
potential of our system for fire-fighting, disaster relief, and other
safety-critical operations. Code and design will be open-sourced upon
acceptance.

</details>


### [28] [Distribution Estimation for Global Data Association via Approximate Bayesian Inference](https://arxiv.org/abs/2509.15565)
*Yixuan Jia,Mason B. Peterson,Qingyuan Li,Yulun Tian,Jonathan P. How*

Main category: cs.RO

TL;DR: 提出了一种基于近似贝叶斯推断的数据关联框架，用于捕捉多模态解决方案以避免在歧义场景下过早确定单一解。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重复或对称数据关联中常因单一解依赖而失败，需要多模态解决方案。

Method: 使用假设解粒子化并通过确定性或随机更新规则覆盖底层解分布的多模态。

Result: 模拟和真实实验表明，该方法能正确估计点云或对象地图配准时的变换分布。

Conclusion: 新框架有效解决歧义数据关联问题，支持GPU并行优化。

Abstract: Global data association is an essential prerequisite for robot operation in
environments seen at different times or by different robots. Repetitive or
symmetric data creates significant challenges for existing methods, which
typically rely on maximum likelihood estimation or maximum consensus to produce
a single set of associations. However, in ambiguous scenarios, the distribution
of solutions to global data association problems is often highly multimodal,
and such single-solution approaches frequently fail. In this work, we introduce
a data association framework that leverages approximate Bayesian inference to
capture multiple solution modes to the data association problem, thereby
avoiding premature commitment to a single solution under ambiguity. Our
approach represents hypothetical solutions as particles that evolve according
to a deterministic or randomized update rule to cover the modes of the
underlying solution distribution. Furthermore, we show that our method can
incorporate optimization constraints imposed by the data association
formulation and directly benefit from GPU-parallelized optimization. Extensive
simulated and real-world experiments with highly ambiguous data show that our
method correctly estimates the distribution over transformations when
registering point clouds or object maps.

</details>


### [29] [Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios](https://arxiv.org/abs/2509.15582)
*Yuting Zeng,Zhiwen Zheng,You Zhou,JiaLing Xiao,Yongbin Yu,Manping Fan,Bo Gong,Liyong Ren*

Main category: cs.RO

TL;DR: 论文提出了一种动量约束混合启发式轨迹优化框架（MHHTOF），用于视觉障碍辅助导航，结合轨迹采样、优化和残差增强深度强化学习（DRL）提升效果。


<details>
  <summary>Details</summary>
Motivation: 旨在提升视觉障碍辅助导航的鲁棒性、安全性和实时性，通过混合启发式轨迹优化和强化学习优化轨迹选择。

Method: 分两阶段：首阶段在Frenet坐标系生成启发式轨迹采样簇（HTSC），第二阶段在笛卡尔坐标系用残差增强的LSTM-AC网络优化轨迹。

Result: 实验显示LSTM-ResB-PPO收敛速度更快，平均成本和方差分别降低30.3%和53.3%，舒适度和安全性提升77%。

Conclusion: MHHTOF框架在复杂辅助规划任务中显著提升了鲁棒性、安全性和实时可行性。

Abstract: This paper proposes a momentum-constrained hybrid heuristic trajectory
optimization framework (MHHTOF) tailored for assistive navigation in visually
impaired scenarios, integrating trajectory sampling generation, optimization
and evaluation with residual-enhanced deep reinforcement learning (DRL). In the
first stage, heuristic trajectory sampling cluster (HTSC) is generated in the
Frenet coordinate system using third-order interpolation with fifth-order
polynomials and momentum-constrained trajectory optimization (MTO) constraints
to ensure smoothness and feasibility. After first stage cost evaluation, the
second stage leverages a residual-enhanced actor-critic network with LSTM-based
temporal feature modeling to adaptively refine trajectory selection in the
Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with
weight transfer aligns semantic priorities across stages, supporting
human-centered optimization. Experimental results demonstrate that the proposed
LSTM-ResB-PPO achieves significantly faster convergence, attaining stable
policy performance in approximately half the training iterations required by
the PPO baseline, while simultaneously enhancing both reward outcomes and
training stability. Compared to baseline method, the selected model reduces
average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle
risks by over 77%. These findings validate the framework's effectiveness in
enhancing robustness, safety, and real-time feasibility in complex assistive
planning tasks.

</details>


### [30] [Bench-RNR: Dataset for Benchmarking Repetitive and Non-repetitive Scanning LiDAR for Infrastructure-based Vehicle Localization](https://arxiv.org/abs/2509.15583)
*Runxin Zhao,Chunxiang Wang,Hanyang Zhuang,Ming Yang*

Main category: cs.RO

TL;DR: 本文提出了一个基于基础设施的车辆定位数据集，比较了重复和非重复扫描LiDAR的性能，为选择合适的LiDAR扫描模式提供了参考。


<details>
  <summary>Details</summary>
Motivation: 研究探索非重复扫描LiDAR在路边感知和定位中的应用潜力，填补现有研究的空白。

Method: 通过收集重复和非重复扫描LiDAR的点云数据，建立基准数据集（5,445帧），并比较不同LiDAR扫描模式下的定位性能。

Result: 实验结果为选择最适合的LiDAR扫描模式提供了基准数据和实用见解。

Conclusion: 该数据集和研究成果为基础设施感知和车辆定位领域的进步提供了重要支持。

Abstract: Vehicle localization using roadside LiDARs can provide centimeter-level
accuracy for cloud-controlled vehicles while simultaneously serving multiple
vehicles, enhanc-ing safety and efficiency. While most existing studies rely on
repetitive scanning LiDARs, non-repetitive scanning LiDAR offers advantages
such as eliminating blind zones and being more cost-effective. However, its
application in roadside perception and localization remains limited. To address
this, we present a dataset for infrastructure-based vehicle localization, with
data collected from both repetitive and non-repetitive scanning LiDARs, in
order to benchmark the performance of different LiDAR scanning patterns. The
dataset contains 5,445 frames of point clouds across eight vehicle trajectory
sequences, with diverse trajectory types. Our experiments establish base-lines
for infrastructure-based vehicle localization and compare the performance of
these methods using both non-repetitive and repetitive scanning LiDARs. This
work offers valuable insights for selecting the most suitable LiDAR scanning
pattern for infrastruc-ture-based vehicle localization. Our dataset is a
signifi-cant contribution to the scientific community, supporting advancements
in infrastructure-based perception and vehicle localization. The dataset and
source code are publicly available at:
https://github.com/sjtu-cyberc3/BenchRNR.

</details>


### [31] [Distributed Nash Equilibrium Seeking Algorithm in Aggregative Games for Heterogeneous Multi-Robot Systems](https://arxiv.org/abs/2509.15597)
*Yi Dong,Zhongguo Li,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.RO

TL;DR: 提出一种分布式纳什均衡搜索算法，用于异构多机器人系统，通过分布式优化和输出控制实现均衡，并通过仿真和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决异构多机器人系统中纳什均衡的分布式搜索问题。

Method: 结合分布式优化算法和输出控制律，利用相邻机器人共享的信息计算均衡点。

Result: 算法保证收敛并能实现高效结果。

Conclusion: 方法通过仿真和实际机器人测试验证了其有效性。

Abstract: This paper develops a distributed Nash Equilibrium seeking algorithm for
heterogeneous multi-robot systems. The algorithm utilises distributed
optimisation and output control to achieve the Nash equilibrium by leveraging
information shared among neighbouring robots. Specifically, we propose a
distributed optimisation algorithm that calculates the Nash equilibrium as a
tailored reference for each robot and designs output control laws for
heterogeneous multi-robot systems to track it in an aggregative game. We prove
that our algorithm is guaranteed to converge and result in efficient outcomes.
The effectiveness of our approach is demonstrated through numerical simulations
and empirical testing with physical robots.

</details>


### [32] [ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation](https://arxiv.org/abs/2509.15600)
*Jinkai Qiu,Yungjun Kim,Gaurav Sethia,Tanmay Agarwal,Siddharth Ghodasara,Zackory Erickson,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: 本文提出了ORB机器人框架，用于自动化医院手术室中的物流任务，通过行为树架构整合多种功能，实现了高成功率的物品取放和补充。


<details>
  <summary>Details</summary>
Motivation: 提升手术室内物流效率，解决现有自动化系统的感知、效率和灭菌维护等挑战。

Method: 采用分层行为树架构，结合YOLOv7、SAM2和Grounded DINO的实时物体识别管道，并优化cuRobo框架实现移动操作。

Result: 物品取放成功率为80%，补充操作成功率为96%。

Conclusion: ORB系统具有可靠性和适应性，能够有效支持手术室的自动化物流。

Abstract: Efficiently delivering items to an ongoing surgery in a hospital operating
room can be a matter of life or death. In modern hospital settings, delivery
robots have successfully transported bulk items between rooms and floors.
However, automating item-level operating room logistics presents unique
challenges in perception, efficiency, and maintaining sterility. We propose the
Operating Room Bot (ORB), a robot framework to automate logistics tasks in
hospital operating rooms (OR). ORB leverages a robust, hierarchical behavior
tree (BT) architecture to integrate diverse functionalities of object
recognition, scene interpretation, and GPU-accelerated motion planning. The
contributions of this paper include: (1) a modular software architecture
facilitating robust mobile manipulation through behavior trees; (2) a novel
real-time object recognition pipeline integrating YOLOv7, Segment Anything
Model 2 (SAM2), and Grounded DINO; (3) the adaptation of the cuRobo
parallelized trajectory optimization framework to real-time, collision-free
mobile manipulation; and (4) empirical validation demonstrating an 80% success
rate in OR supply retrieval and a 96% success rate in restocking operations.
These contributions establish ORB as a reliable and adaptable system for
autonomous OR logistics.

</details>


### [33] [PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models](https://arxiv.org/abs/2509.15607)
*Ruiqi Wang,Dezhong Zhao,Ziqin Yuan,Tianyu Shao,Guohua Chen,Dominic Kao,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: PRIMT是一个基于偏好的强化学习框架，通过多模态合成反馈和轨迹合成克服了人类输入依赖和信用分配难题。


<details>
  <summary>Details</summary>
Motivation: 解决偏好强化学习中依赖人类输入和信用分配模糊的问题。

Method: 采用分层神经符号融合策略，结合语言模型和视觉语言模型，并引入前瞻轨迹生成和后瞻轨迹增强。

Result: 在多个基准测试中表现优于现有方法。

Conclusion: PRIMT显著提升了偏好强化学习的效率和可靠性。

Abstract: Preference-based reinforcement learning (PbRL) has emerged as a promising
paradigm for teaching robots complex behaviors without reward engineering.
However, its effectiveness is often limited by two critical challenges: the
reliance on extensive human input and the inherent difficulties in resolving
query ambiguity and credit assignment during reward learning. In this paper, we
introduce PRIMT, a PbRL framework designed to overcome these challenges by
leveraging foundation models (FMs) for multimodal synthetic feedback and
trajectory synthesis. Unlike prior approaches that rely on single-modality FM
evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy,
integrating the complementary strengths of large language models and
vision-language models in evaluating robot behaviors for more reliable and
comprehensive feedback. PRIMT also incorporates foresight trajectory
generation, which reduces early-stage query ambiguity by warm-starting the
trajectory buffer with bootstrapped samples, and hindsight trajectory
augmentation, which enables counterfactual reasoning with a causal auxiliary
loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6
manipulation tasks on various benchmarks, demonstrating superior performance
over FM-based and scripted baselines.

</details>


### [34] [Miniature soft robot with magnetically reprogrammable surgical functions](https://arxiv.org/abs/2509.15610)
*Chelsea Shan Xian Ng,Yu Xuan Yeoh,Nicholas Yong Wei Foo,Keerthana Radhakrishnan,Guo Zhan Lum*

Main category: cs.RO

TL;DR: 介绍了一种毫米级软机器人，具有可编程的磁化特性，可实现五种手术功能，并通过六自由度运动在不规则环境中操作。


<details>
  <summary>Details</summary>
Motivation: 现有磁性微型机器人因功能受限或自由度不足而难以应用于手术，需改进以实现更多功能且能在生物组织深处操作。

Method: 开发了一种毫米级软机器人，其磁化特性可编程，支持五种手术功能，并在弱磁场下实现六自由度运动。

Result: 机器人成功执行了手术功能，并在不规则环境中展示了优于五自由度机器人的移动能力。

Conclusion: 这项研究为软致动器的进步和微型机器人在微创手术中的应用提供了重要里程碑。

Abstract: Miniature robots are untethered actuators, which have significant potential
to make existing minimally invasive surgery considerably safer and painless,
and enable unprecedented treatments because they are much smaller and dexterous
than existing surgical robots. Of the miniature robots, the magnetically
actuated ones are the most functional and dexterous. However, existing magnetic
miniature robots are currently impractical for surgery because they are either
restricted to possessing at most two on-board functionalities or having limited
five degrees-of-freedom (DOF) locomotion. Some of these actuators are also only
operational under specialized environments where actuation from strong external
magnets must be at very close proximity (< 4 cm away). Here we present a
millimeter-scale soft robot where its magnetization profile can be reprogrammed
upon command to perform five surgical functionalities: drug-dispensing, cutting
through biological tissues (simulated with gelatin), gripping, storing
(biological) samples and remote heating. By possessing full six-DOF motions,
including the sixth-DOF rotation about its net magnetic moment, our soft robot
can also roll and two-anchor crawl across challenging unstructured
environments, which are impassable by its five-DOF counterparts. Because our
actuating magnetic fields are relatively uniform and weak (at most 65 mT and
1.5 T/m), such fields can theoretically penetrate through biological tissues
harmlessly and allow our soft robot to remain controllable within the depths of
the human body. We envision that this work marks a major milestone for the
advancement of soft actuators, and towards revolutionizing minimally invasive
treatments with untethered miniature robots that have unprecedented
functionalities.

</details>


### [35] [Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization](https://arxiv.org/abs/2509.15613)
*Sven Hinderer,Pascal Schlachter,Zhibin Yu,Xiaofeng Wu,Bin Yang*

Main category: cs.RO

TL;DR: 基于雷达反射器的低成本高精度室内定位系统


<details>
  <summary>Details</summary>
Motivation: 为自主移动机器人提供低成本、高精度的室内定位解决方案

Method: 结合简单反射器和FMCW雷达，并采用MO-PSO算法优化反射器布置

Result: 实现了高定位精度

Conclusion: 该系统在低成本下实现了高精度定位

Abstract: We extend our work on a novel indoor positioning system (IPS) for autonomous
mobile robots (AMRs) based on radar sensing of local, passive radar reflectors.
Through the combination of simple reflectors and a single-channel frequency
modulated continuous wave (FMCW) radar, high positioning accuracy at low system
cost can be achieved. Further, a multi-objective (MO) particle swarm
optimization (PSO) algorithm is presented that optimizes the 2D placement of
radar reflectors in complex room settings.

</details>


### [36] [Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion](https://arxiv.org/abs/2509.15673)
*Yinong Cao,Xin He,Yuwei Chen,Chenyang Zhang,Chengyu Pu,Bingtao Wang,Kaile Wu,Shouzheng Zhu,Fei Han,Shijie Liu,Chunlai Li,Jianyu Wang*

Main category: cs.RO

TL;DR: Omni-LIVO 是一种多相机 LiDAR-惯性-视觉里程计系统，解决了宽视场 LiDAR 与常规相机之间的视场不匹配问题，提高了精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有单相机 LIVO 系统在空间覆盖和鲁棒性上存在局限，多相机系统可以弥补这一不足。

Method: 引入跨视角直接跟踪策略和扩展的误差状态迭代卡尔曼滤波器（ESIKF），支持多视角更新和自适应协方差加权。

Result: 在公共基准和自定义数据集上表现优于现有 LIVO、LIO 和视觉惯性基线系统。

Conclusion: Omni-LIVO 通过多相机融合显著提升了系统的性能和稳健性。

Abstract: Wide field-of-view (FoV) LiDAR sensors provide dense geometry across large
environments, but most existing LiDAR-inertial-visual odometry (LIVO) systems
rely on a single camera, leading to limited spatial coverage and degraded
robustness. We present Omni-LIVO, the first tightly coupled multi-camera LIVO
system that bridges the FoV mismatch between wide-angle LiDAR and conventional
cameras. Omni-LIVO introduces a Cross-View direct tracking strategy that
maintains photometric consistency across non-overlapping views, and extends the
Error-State Iterated Kalman Filter (ESIKF) with multi-view updates and adaptive
covariance weighting. The system is evaluated on public benchmarks and our
custom dataset, showing improved accuracy and robustness over state-of-the-art
LIVO, LIO, and visual-inertial baselines. Code and dataset will be released
upon publication.

</details>


### [37] [Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference](https://arxiv.org/abs/2509.15717)
*Haoran Ding,Anqing Duan,Zezhou Sun,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 本文提出一种通过新视角合成（NVS）技术让机器人具备‘想象’手部视角的能力，以弥补硬件限制，提升视觉运动策略的表现。通过微调扩散模型，实现了在草莓采摘任务中的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决机器人因硬件限制无法配备手部摄像头时，视觉运动策略性能下降的问题。

Method: 基于LoRA微调的扩散模型（ZeroNVS），通过新视角合成技术生成手部视角图像。

Result: 在仿真和真实实验中，合成的手部视角显著提升了策略性能，接近于实际配备手部摄像头的效果。

Conclusion: 该方法为部署轻量级且鲁棒的视觉运动策略提供了可扩展的解决方案，展示了想象力视觉推理在机器人中的潜力。

Abstract: Visual observations from different viewpoints can significantly influence the
performance of visuomotor policies in robotic manipulation. Among these,
egocentric (in-hand) views often provide crucial information for precise
control. However, in some applications, equipping robots with dedicated in-hand
cameras may pose challenges due to hardware constraints, system complexity, and
cost. In this work, we propose to endow robots with imaginative perception -
enabling them to 'imagine' in-hand observations from agent views at inference
time. We achieve this via novel view synthesis (NVS), leveraging a fine-tuned
diffusion model conditioned on the relative pose between the agent and in-hand
views cameras. Specifically, we apply LoRA-based fine-tuning to adapt a
pretrained NVS model (ZeroNVS) to the robotic manipulation domain. We evaluate
our approach on both simulation benchmarks (RoboMimic and MimicGen) and
real-world experiments using a Unitree Z1 robotic arm for a strawberry picking
task. Results show that synthesized in-hand views significantly enhance policy
inference, effectively recovering the performance drop caused by the absence of
real in-hand cameras. Our method offers a scalable and hardware-light solution
for deploying robust visuomotor policies, highlighting the potential of
imaginative visual reasoning in embodied agents.

</details>


### [38] [GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation](https://arxiv.org/abs/2509.15733)
*Quanhao Qian,Guoyang Zhao,Gongjie Zhang,Jiuniu Wang,Ran Xu,Junlong Gao,Deli Zhao*

Main category: cs.RO

TL;DR: GP3是一种利用多视角输入的3D几何感知机器人操作策略，通过空间编码器从RGB观测推断深度和相机参数，结合语言指令生成连续动作，性能优于现有方法并能有效迁移到现实场景。


<details>
  <summary>Details</summary>
Motivation: 精确理解3D场景几何对机器人操作至关重要，而多视角观测是获取几何信息的直接方式。GP3旨在通过多视角输入实现高效的几何感知操作。

Method: GP3利用空间编码器从RGB观测推断密集空间特征，估计深度和相机参数，形成紧凑的3D场景表示，结合语言指令通过轻量策略头生成动作。

Result: GP3在模拟基准测试中优于现有方法，无需深度传感器或预构图即可有效迁移到现实机器人，仅需少量微调。

Conclusion: GP3是一种实用且传感器无关的几何感知机器人操作解决方案。

Abstract: Effective robotic manipulation relies on a precise understanding of 3D scene
geometry, and one of the most straightforward ways to acquire such geometry is
through multi-view observations. Motivated by this, we present GP3 -- a 3D
geometry-aware robotic manipulation policy that leverages multi-view input. GP3
employs a spatial encoder to infer dense spatial features from RGB
observations, which enable the estimation of depth and camera parameters,
leading to a compact yet expressive 3D scene representation tailored for
manipulation. This representation is fused with language instructions and
translated into continuous actions via a lightweight policy head. Comprehensive
experiments demonstrate that GP3 consistently outperforms state-of-the-art
methods on simulated benchmarks. Furthermore, GP3 transfers effectively to
real-world robots without depth sensors or pre-mapped environments, requiring
only minimal fine-tuning. These results highlight GP3 as a practical,
sensor-agnostic solution for geometry-aware robotic manipulation.

</details>


### [39] [SMART: Scalable Multi-Agent Reasoning and Trajectory Planning in Dense Environments](https://arxiv.org/abs/2509.15737)
*Heye Huang,Yibin Yang,Wang Chen,Tiantian Chen,Xiaopeng Li,Sikai Chen*

Main category: cs.RO

TL;DR: SMART框架通过优先级搜索和分布式优化实现高效的多车辆轨迹规划，解决了密集环境中非凸问题的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多车辆轨迹规划中非凸问题和高密度环境下的碰撞约束快速增加难题。

Method: 采用分层框架：上层使用强化学习和大步长混合A*搜索探索多样交互模式；下层通过并行凸优化细化解决方案。

Result: 实验显示，SMART在50×50米和100×100米地图上分别支持多达25辆和90辆车辆，成功率显著优于基线。

Conclusion: SMART通过车辆与基础设施协作，显著提升了规划的实时性、可扩展性和安全性。

Abstract: Multi-vehicle trajectory planning is a non-convex problem that becomes
increasingly difficult in dense environments due to the rapid growth of
collision constraints. Efficient exploration of feasible behaviors and
resolution of tight interactions are essential for real-time, large-scale
coordination. This paper introduces SMART, Scalable Multi-Agent Reasoning and
Trajectory Planning, a hierarchical framework that combines priority-based
search with distributed optimization to achieve efficient and feasible
multi-vehicle planning. The upper layer explores diverse interaction modes
using reinforcement learning-based priority estimation and large-step hybrid A*
search, while the lower layer refines solutions via parallelizable convex
optimization. By partitioning space among neighboring vehicles and constructing
robust feasible corridors, the method decouples the joint non-convex problem
into convex subproblems solved efficiently in parallel. This design alleviates
the step-size trade-off while ensuring kinematic feasibility and collision
avoidance. Experiments show that SMART consistently outperforms baselines. On
50 m x 50 m maps, it sustains over 90% success within 1 s up to 25 vehicles,
while baselines often drop below 50%. On 100 m x 100 m maps, SMART achieves
above 95% success up to 50 vehicles and remains feasible up to 90 vehicles,
with runtimes more than an order of magnitude faster than optimization-only
approaches. Built on vehicle-to-everything communication, SMART incorporates
vehicle-infrastructure cooperation through roadside sensing and agent
coordination, improving scalability and safety. Real-world experiments further
validate this design, achieving planning times as low as 0.014 s while
preserving cooperative behaviors.

</details>


### [40] [FlyKites: Human-centric Interactive Exploration and Assistance under Limited Communication](https://arxiv.org/abs/2509.15807)
*Yuyang Zhang,Zhuoli Tian,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: 提出了FlyKites框架，用于多机器人在有限通信下的交互式探索与辅助。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在极端环境下因通信受限而难以获得人类及时辅助的问题。

Method: 框架包含分布式探索与间歇通信（扩散模式）、中继拓扑与路径优化（中继模式）以及自适应人机交互执行。

Result: 通过大量模拟和硬件实验验证了框架的有效性。

Conclusion: FlyKites成功实现了多机器人在受限通信环境中的高效协作与人类辅助。

Abstract: Fleets of autonomous robots have been deployed for exploration of unknown
scenes for features of interest, e.g., subterranean exploration,
reconnaissance, search and rescue missions. During exploration, the robots may
encounter un-identified targets, blocked passages, interactive objects,
temporary failure, or other unexpected events, all of which require consistent
human assistance with reliable communication for a time period. This however
can be particularly challenging if the communication among the robots is
severely restricted to only close-range exchange via ad-hoc networks,
especially in extreme environments like caves and underground tunnels. This
paper presents a novel human-centric interactive exploration and assistance
framework called FlyKites, for multi-robot systems under limited communication.
It consists of three interleaved components: (I) the distributed exploration
and intermittent communication (called the "spread mode"), where the robots
collaboratively explore the environment and exchange local data among the fleet
and with the operator; (II) the simultaneous optimization of the relay
topology, the operator path, and the assignment of robots to relay roles
(called the "relay mode"), such that all requested assistance can be provided
with minimum delay; (III) the human-in-the-loop online execution, where the
robots switch between different roles and interact with the operator
adaptively. Extensive human-in-the-loop simulations and hardware experiments
are performed over numerous challenging scenes.

</details>


### [41] [Coordinated Multi-Drone Last-mile Delivery: Learning Strategies for Energy-aware and Timely Operations](https://arxiv.org/abs/2509.15830)
*Chuhao Qin,Arun Narayanan,Evangelos Pournaras*

Main category: cs.RO

TL;DR: 多无人机能量感知配送，优化路线以减少延迟和能耗，结合K-means聚类和强化学习，提升长期效率。


<details>
  <summary>Details</summary>
Motivation: 解决多包裹无人机配送中的能量限制和时间敏感需求问题。

Method: 分解为三个子问题：优化配送站位置（K-means聚类）、确定最佳飞行范围（强化学习）、多包裹路线规划（优化选择算法）。

Result: 实验表现优异，展示了经济效率和快速运营的优势。

Conclusion: 提出了结合深度强化学习的算法，为实际物流应用提供了战略指导。

Abstract: Drones have recently emerged as a faster, safer, and cost-efficient way for
last-mile deliveries of parcels, particularly for urgent medical deliveries
highlighted during the pandemic. This paper addresses a new challenge of
multi-parcel delivery with a swarm of energy-aware drones, accounting for
time-sensitive customer requirements. Each drone plans an optimal multi-parcel
route within its battery-restricted flight range to minimize delivery delays
and reduce energy consumption. The problem is tackled by decomposing it into
three sub-problems: (1) optimizing depot locations and service areas using
K-means clustering; (2) determining the optimal flight range for drones through
reinforcement learning; and (3) planning and selecting multi-parcel delivery
routes via a new optimized plan selection approach. To integrate these
solutions and enhance long-term efficiency, we propose a novel algorithm
leveraging actor-critic-based multi-agent deep reinforcement learning.
Extensive experimentation using realistic delivery datasets demonstrate an
exceptional performance of the proposed algorithm. We provide new insights into
economic efficiency (minimize energy consumption), rapid operations (reduce
delivery delays and overall execution time), and strategic guidance on depot
deployment for practical logistics applications.

</details>


### [42] [High-Bandwidth Tactile-Reactive Control for Grasp Adjustment](https://arxiv.org/abs/2509.15876)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 论文提出了一种仅依赖触觉反馈的抓握调整算法，无需物体几何信息或精确抓握姿势，显著提升了抓握稳定性。通过仿真和实验验证，该方法在感知误差存在时仍表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有视觉抓握系统因校准误差、传感器噪声和抓握姿势预测不准确而受限，导致接触不确定性。高带宽触觉反馈与触觉反应控制器的结合可提升抓握鲁棒性。

Method: 提出了一种纯触觉反馈的抓握调整算法，无需物体几何先验信息或精确初始抓握姿势，通过高频率触觉传感器实时调整抓握。

Result: 在15-DoF臂-手系统（配备200Hz触觉传感器）上，仿真和实验验证了该方法在提升抓握稳定性方面的有效性。

Conclusion: 触觉反应抓握框架可有效提升抓握稳定性，尤其在感知误差和初始配置不精确的情况下表现优异。

Abstract: Vision-only grasping systems are fundamentally constrained by calibration
errors, sensor noise, and grasp pose prediction inaccuracies, leading to
unavoidable contact uncertainty in the final stage of grasping. High-bandwidth
tactile feedback, when paired with a well-designed tactile-reactive controller,
can significantly improve robustness in the presence of perception errors. This
paper contributes to controller design by proposing a purely tactile-feedback
grasp-adjustment algorithm. The proposed controller requires neither prior
knowledge of the object's geometry nor an accurate grasp pose, and is capable
of refining a grasp even when starting from a crude, imprecise initial
configuration and uncertain contact points. Through simulation studies and
real-world experiments on a 15-DoF arm-hand system (featuring an 8-DoF hand)
equipped with fingertip tactile sensors operating at 200 Hz, we demonstrate
that our tactile-reactive grasping framework effectively improves grasp
stability.

</details>


### [43] [Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder](https://arxiv.org/abs/2509.15880)
*An Dinh Vuong,Minh Nhat Vu,Ian Reid*

Main category: cs.RO

TL;DR: 文章探讨了在机器人模仿学习中使用几何感知视觉编码器（如VGGT）的潜力，并提出了一种高效的变体eVGGT，显著提升了性能，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有RGB模仿学习方法缺乏显式的3D推理能力，几何感知视觉模型（如VGGT）为解决这一问题提供了可能。

Method: 将几何感知视觉编码器集成到模仿学习框架（如ACT和DP）中，并提出了高效版本eVGGT，通过蒸馏减少计算成本。

Result: 几何感知编码器在单臂和双臂操作任务中提升了6.5%的成功率，eVGGT在速度和模型大小上优于VGGT，保留了强3D推理能力。

Conclusion: 几何感知编码器有效提升模仿学习性能，eVGGT为实际部署提供了高效解决方案，代码和模型将公开以促进研究。

Abstract: Existing RGB-based imitation learning approaches typically employ traditional
vision encoders such as ResNet or ViT, which lack explicit 3D reasoning
capabilities. Recent geometry-grounded vision models, such as
VGGT~\cite{wang2025vggt}, provide robust spatial understanding and are
promising candidates to address this limitation. This work investigates the
integration of geometry-aware visual representations into robotic manipulation.
Our results suggest that incorporating the geometry-aware vision encoder into
imitation learning frameworks, including ACT and DP, yields up to 6.5%
improvement over standard vision encoders in success rate across single- and
bi-manual manipulation tasks in both simulation and real-world settings.
Despite these benefits, most geometry-grounded models require high
computational cost, limiting their deployment in practical robotic systems. To
address this challenge, we propose eVGGT, an efficient geometry-aware encoder
distilled from VGGT. eVGGT is nearly 9 times faster and 5 times smaller than
VGGT, while preserving strong 3D reasoning capabilities. Code and pretrained
models will be released to facilitate further research in geometry-aware
robotics.

</details>


### [44] [An MPC framework for efficient navigation of mobile robots in cluttered environments](https://arxiv.org/abs/2509.15917)
*Johannes Köhler,Daniel Zhang,Raffaele Soloperto,Andrea Carron,Melanie Zeilinger*

Main category: cs.RO

TL;DR: 提出了一种模型预测控制（MPC）框架，用于移动机器人在杂乱环境中的高效导航。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中实现高效导航，同时确保动态目标选择和避障。

Method: 结合有限段最短路径规划器和有限时域轨迹优化，适用于非线性动态和复杂环境。

Result: 硬件实验中，小型地面机器人成功在2-3秒内导航并到达新目标。

Conclusion: 该框架在复杂环境中表现出高效性和鲁棒性，适用于动态任务。

Abstract: We present a model predictive control (MPC) framework for efficient
navigation of mobile robots in cluttered environments. The proposed approach
integrates a finite-segment shortest path planner into the finite-horizon
trajectory optimization of the MPC. This formulation ensures convergence to
dynamically selected targets and guarantees collision avoidance, even under
general nonlinear dynamics and cluttered environments. The approach is
validated through hardware experiments on a small ground robot, where a human
operator dynamically assigns target locations. The robot successfully navigated
through complex environments and reached new targets within 2-3 seconds.

</details>


### [45] [A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning](https://arxiv.org/abs/2509.15937)
*Shaopeng Zhai,Qi Zhang,Tianyi Zhang,Fuxian Huang,Haoran Zhang,Ming Zhou,Shengzhe Zhang,Litao Liu,Sixu Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: VLAC是一种基于视觉-语言-动作模型的过程奖励模型，通过大规模异构数据集训练，消除了任务特定的奖励设计，提升了机器人真实世界的强化学习效率。


<details>
  <summary>Details</summary>
Motivation: 机器人真实世界的强化学习面临稀疏、手工设计的奖励和低效探索的问题，VLAC旨在解决这些挑战。

Method: VLAC基于InternVL构建，使用大规模异构数据集训练，通过生成密集进展信号和行动令牌，统一了批评者和策略角色。

Result: 在四个真实世界操纵任务中，VLAC将成功率从30%提升至90%，结合人类干预后样本效率提高50%，最终成功率可达100%。

Conclusion: VLAC通过统一奖励生成和行动策略的能力，显著提升了机器人强化学习的性能和效率。

Abstract: Robotic real-world reinforcement learning (RL) with vision-language-action
(VLA) models is bottlenecked by sparse, handcrafted rewards and inefficient
exploration. We introduce VLAC, a general process reward model built upon
InternVL and trained on large scale heterogeneous datasets. Given pairwise
observations and a language goal, it outputs dense progress delta and done
signal, eliminating task-specific reward engineering, and supports one-shot
in-context transfer to unseen tasks and environments. VLAC is trained on
vision-language datasets to strengthen perception, dialogic and reasoning
capabilities, together with robot and human trajectories data that ground
action generation and progress estimation, and additionally strengthened to
reject irrelevant prompts as well as detect regression or stagnation by
constructing large numbers of negative and semantically mismatched samples.
With prompt control, a single VLAC model alternately generating reward and
action tokens, unifying critic and policy. Deployed inside an asynchronous
real-world RL loop, we layer a graded human-in-the-loop protocol (offline
demonstration replay, return and explore, human guided explore) that
accelerates exploration and stabilizes early learning. Across four distinct
real-world manipulation tasks, VLAC lifts success rates from about 30\% to
about 90\% within 200 real-world interaction episodes; incorporating
human-in-the-loop interventions yields a further 50% improvement in sample
efficiency and achieves up to 100% final success.

</details>


### [46] [Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal](https://arxiv.org/abs/2509.15953)
*Chang Yu,Siyu Ma,Wenxin Du,Zeshun Zong,Han Xue,Wendi Chen,Cewu Lu,Yin Yang,Xuchen Han,Joseph Masterjohn,Alejandro Castro,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: 论文提出了一种名为Right-Side-Out的零样本仿真到现实框架，通过任务分解和高保真仿真，解决了服装翻转这一动态且视觉遮挡严重的任务。


<details>
  <summary>Details</summary>
Motivation: 服装翻转任务具有高度动态性、快速接触变化以及严重视觉遮挡的特点，传统方法难以应对。

Method: 将任务分解为Drag/Fling和Insert&Pull两个阶段，每个阶段采用深度推断的双手机械臂操作，并利用GPU并行的高保真材料点法（MPM）模拟器生成数据。

Result: 在真实硬件上部署时，仅使用单深度相机，实现了81.3%的成功率。

Conclusion: 通过任务分解和高保真仿真，无需繁琐的人类演示即可解决高度动态且遮挡严重的任务。

Abstract: Turning garments right-side out is a challenging manipulation task: it is
highly dynamic, entails rapid contact changes, and is subject to severe visual
occlusion. We introduce Right-Side-Out, a zero-shot sim-to-real framework that
effectively solves this challenge by exploiting task structures. We decompose
the task into Drag/Fling to create and stabilize an access opening, followed by
Insert&Pull to invert the garment. Each step uses a depth-inferred,
keypoint-parameterized bimanual primitive that sharply reduces the action space
while preserving robustness. Efficient data generation is enabled by our
custom-built, high-fidelity, GPU-parallel Material Point Method (MPM) simulator
that models thin-shell deformation and provides robust and efficient contact
handling for batched rollouts. Built on the simulator, our fully automated
pipeline scales data generation by randomizing garment geometry, material
parameters, and viewpoints, producing depth, masks, and per-primitive keypoint
labels without any human annotations. With a single depth camera, policies
trained entirely in simulation deploy zero-shot on real hardware, achieving up
to 81.3% success rate. By employing task decomposition and high fidelity
simulation, our framework enables tackling highly dynamic, severely occluded
tasks without laborious human demonstrations.

</details>


### [47] [Swarm Oracle: Trustless Blockchain Agreements through Robot Swarms](https://arxiv.org/abs/2509.15956)
*Alexandre Pacheco,Hanqing Zhao,Volker Strobel,Tarik Roukny,Gregory Dudek,Andreagiovanni Reina,Marco Dorigo*

Main category: cs.RO

TL;DR: Swarm Oracle利用机器人群体通过去中心化和容错性，为区块链提供现实世界数据，并结合拜占庭容错协议确保安全性。


<details>
  <summary>Details</summary>
Motivation: 区块链共识机制限制了现实世界数据的访问，现有解决方案可能降低自主性或透明度。

Method: 提出Swarm Oracle，由多利益方机器人群体通过传感器和P2P通信集体验证数据，结合拜占庭容错协议和声誉系统。

Result: 实验证明即使在攻击下也能达成共识，声誉系统支持自主恢复。

Conclusion: Swarm Oracle为区块链提供了安全、去中心化的现实数据解决方案。

Abstract: Blockchain consensus, rooted in the principle ``don't trust, verify'', limits
access to real-world data, which may be ambiguous or inaccessible to some
participants. Oracles address this limitation by supplying data to blockchains,
but existing solutions may reduce autonomy, transparency, or reintroduce the
need for trust. We propose Swarm Oracle: a decentralized network of autonomous
robots -- that is, a robot swarm -- that use onboard sensors and peer-to-peer
communication to collectively verify real-world data and provide it to smart
contracts on public blockchains. Swarm Oracle leverages the built-in
decentralization, fault tolerance and mobility of robot swarms, which can
flexibly adapt to meet information requests on-demand, even in remote
locations. Unlike typical cooperative robot swarms, Swarm Oracle integrates
robots from multiple stakeholders, protecting the system from single-party
biases but also introducing potential adversarial behavior. To ensure the
secure, trustless and global consensus required by blockchains, we employ a
Byzantine fault-tolerant protocol that enables robots from different
stakeholders to operate together, reaching social agreements of higher quality
than the estimates of individual robots. Through extensive experiments using
both real and simulated robots, we showcase how consensus on uncertain
environmental information can be achieved, despite several types of attacks
orchestrated by large proportions of the robots, and how a reputation system
based on blockchain tokens lets Swarm Oracle autonomously recover from faults
and attacks, a requirement for long-term operation.

</details>


### [48] [CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine](https://arxiv.org/abs/2509.15968)
*Shiyu Fang,Yiming Cui,Haoyang Liang,Chen Lv,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: CoReVLA是一种持续学习框架，通过数据收集和行为优化提升自动驾驶系统在长尾场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶在长尾安全关键场景中性能不足的问题。

Method: 分两阶段进行：先在开源驾驶数据集上微调，再通过CAVE模拟平台收集接管数据并使用DPO优化模型。

Result: 在Bench2Drive基准测试中，DS和SR分别达到72.18和50%，优于现有方法。

Conclusion: CoReVLA能持续改进性能，特别是在易失败的长尾场景中。

Abstract: Autonomous Driving (AD) systems have made notable progress, but their
performance in long-tail, safety-critical scenarios remains limited. These rare
cases contribute a disproportionate number of accidents. Vision-Language Action
(VLA) models have strong reasoning abilities and offer a potential solution,
but their effectiveness is limited by the lack of high-quality data and
inefficient learning in such conditions. To address these challenges, we
propose CoReVLA, a continual learning end-to-end autonomous driving framework
that improves the performance in long-tail scenarios through a dual-stage
process of data Collection and behavior Refinement. First, the model is jointly
fine-tuned on a mixture of open-source driving QA datasets, allowing it to
acquire a foundational understanding of driving scenarios. Next, CoReVLA is
deployed within the Cave Automatic Virtual Environment (CAVE) simulation
platform, where driver takeover data is collected from real-time interactions.
Each takeover indicates a long-tail scenario that CoReVLA fails to handle
reliably. Finally, the model is refined via Direct Preference Optimization
(DPO), allowing it to learn directly from human preferences and thereby avoid
reward hacking caused by manually designed rewards. Extensive open-loop and
closed-loop experiments demonstrate that the proposed CoReVLA model can
accurately perceive driving scenarios and make appropriate decisions. On the
Bench2Drive benchmark, CoReVLA achieves a Driving Score (DS) of 72.18 and a
Success Rate (SR) of 50%, outperforming state-of-the-art methods by 7.96 DS and
15% SR under long-tail, safety-critical scenarios. Furthermore, case studies
demonstrate the model's ability to continually improve its performance in
similar failure-prone scenarios by leveraging past takeover experiences. All
codea and preprocessed datasets are available at:
https://github.com/FanGShiYuu/CoReVLA

</details>


### [49] [Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning](https://arxiv.org/abs/2509.16006)
*Francesco Argenziano,Elena Umili,Francesco Leotta,Daniele Nardi*

Main category: cs.RO

TL;DR: 这篇论文提出了一种结合大型语言模型（LLMs）和自动化规划的架构，通过自然语言指定高级活动（如农业中的任务），并通过查询机器人监控执行过程。


<details>
  <summary>Details</summary>
Motivation: 在动态且不可预测的环境中（如工业和农业场景），自动化复杂任务的需求日益增长。这些任务的组合可能因情境而异，且人类监控高级活动的进展对于确保安全关键流程的正确执行至关重要。

Method: 论文提出了一种将大型语言模型（LLMs）与自动化规划相结合的通用架构，允许人类通过自然语言指定高级活动，并通过机器人查询监控执行过程。实现使用了最先进的组件。

Result: 该架构在真实的精准农业场景中进行了定量评估，展示了其有效性。

Conclusion: 结合LLM和自动化规划的架构能够有效支持人类在动态环境中指定和监控高级活动，为复杂任务的自动化提供了可行方案。

Abstract: Recent years have witnessed a growing interest in automating labor-intensive
and complex activities, i.e., those consisting of multiple atomic tasks, by
deploying robots in dynamic and unpredictable environments such as industrial
and agricultural settings. A key characteristic of these contexts is that
activities are not predefined: while they involve a limited set of possible
tasks, their combinations may vary depending on the situation. Moreover,
despite recent advances in robotics, the ability for humans to monitor the
progress of high-level activities - in terms of past, present, and future
actions - remains fundamental to ensure the correct execution of
safety-critical processes. In this paper, we introduce a general architecture
that integrates Large Language Models (LLMs) with automated planning, enabling
humans to specify high-level activities (also referred to as processes) using
natural language, and to monitor their execution by querying a robot. We also
present an implementation of this architecture using state-of-the-art
components and quantitatively evaluate the approach in a real-world precision
agriculture scenario.

</details>


### [50] [A Matter of Height: The Impact of a Robotic Object on Human Compliance](https://arxiv.org/abs/2509.16032)
*Michael Faber,Andrey Grishko,Julian Waksberg,David Pardo,Tomer Leivy,Yuval Hazan,Emanuel Talmansky,Benny Megidish,Hadas Erel*

Main category: cs.RO

TL;DR: 研究探讨了机器人高度对人机互动中服从行为的影响，发现短机器人比高机器人更有效，与人类互动模式相反。


<details>
  <summary>Details</summary>
Motivation: 探索机器人高度是否会影响人机互动中的服从行为，尤其是非人形机器人。

Method: 设计可调节高度的机器人，比较95cm和132cm两种高度下参与者完成繁琐问卷的自愿率。

Result: 短机器人比高机器人更能引发服从行为，与人类社交模式相反。

Conclusion: 机器人高度对人机互动有独特影响，设计时需要实际测试而非直接套用人类社交模式。

Abstract: Robots come in various forms and have different characteristics that may
shape the interaction with them. In human-human interactions, height is a
characteristic that shapes human dynamics, with taller people typically
perceived as more persuasive. In this work, we aspired to evaluate if the same
impact replicates in a human-robot interaction and specifically with a highly
non-humanoid robotic object. The robot was designed with modules that could be
easily added or removed, allowing us to change its height without altering
other design features. To test the impact of the robot's height, we evaluated
participants' compliance with its request to volunteer to perform a tedious
task. In the experiment, participants performed a cognitive task on a computer,
which was framed as the main experiment. When done, they were informed that the
experiment was completed. While waiting to receive their credits, the robotic
object, designed as a mobile robotic service table, entered the room, carrying
a tablet that invited participants to complete a 300-question questionnaire
voluntarily. We compared participants' compliance in two conditions: A Short
robot composed of two modules and 95cm in height and a Tall robot consisting of
three modules and 132cm in height. Our findings revealed higher compliance with
the Short robot's request, demonstrating an opposite pattern to human dynamics.
We conclude that while height has a substantial social impact on human-robot
interactions, it follows a unique pattern of influence. Our findings suggest
that designers cannot simply adopt and implement elements from human social
dynamics to robots without testing them first.

</details>


### [51] [Learning Safety for Obstacle Avoidance via Control Barrier Functions](https://arxiv.org/abs/2509.16037)
*Shuo Liu,Zhe Huang,Calin A. Belta*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的Local Safety Ball方法，用于复杂几何形状机器人的实时避障，解决了传统CBF方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统CBF方法在复杂几何形状机器人避障中存在计算不可行或近似方法低效的问题。

Method: 训练残差神经网络预测清除距离，定义Local Safety Ball，并结合优化框架和松弛技术确保安全性。

Result: 实验表明该方法能够处理任意几何形状，并实现毫秒级求解时间和高预测精度。

Conclusion: 该方法在安全性和效率上优于现有CBF方法，适用于复杂环境中的机器人导航。

Abstract: Obstacle avoidance is central to safe navigation, especially for robots with
arbitrary and nonconvex geometries operating in cluttered environments.
Existing Control Barrier Function (CBF) approaches often rely on analytic
clearance computations, which are infeasible for complex geometries, or on
polytopic approximations, which become intractable when robot configurations
are unknown. To address these limitations, this paper trains a residual neural
network on a large dataset of robot-obstacle configurations to enable fast and
tractable clearance prediction, even at unseen configurations. The predicted
clearance defines the radius of a Local Safety Ball (LSB), which ensures
continuous-time collision-free navigation. The LSB boundary is encoded as a
Discrete-Time High-Order CBF (DHOCBF), whose constraints are incorporated into
a nonlinear optimization framework. To improve feasibility, a novel relaxation
technique is applied. The resulting framework ensure that the robot's
rigid-body motion between consecutive time steps remains collision-free,
effectively bridging discrete-time control and continuous-time safety. We show
that the proposed method handles arbitrary, including nonconvex, robot
geometries and generates collision-free, dynamically feasible trajectories in
cluttered environments. Experiments demonstrate millisecond-level solve times
and high prediction accuracy, highlighting both safety and efficiency beyond
existing CBF-based methods.

</details>


### [52] [Compose by Focus: Scene Graph-based Atomic Skills](https://arxiv.org/abs/2509.16053)
*Han Qi,Changhe Chen,Heng Yang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于场景图表示的技能学习框架，结合图神经网络和扩散模仿学习，以提高机器人在复杂任务中的组合泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有视觉运动策略在场景组合引起的分布变化中表现不佳的问题。

Method: 使用场景图表示任务相关对象和关系，结合图神经网络与扩散模仿学习框架，并与视觉语言模型任务规划器集成。

Result: 实验显示该方法在仿真和实际任务中的成功率显著高于现有技术。

Conclusion: 提出的框架在长时任务中表现出更高的鲁棒性和组合泛化能力。

Abstract: A key requirement for generalist robots is compositional generalization - the
ability to combine atomic skills to solve complex, long-horizon tasks. While
prior work has primarily focused on synthesizing a planner that sequences
pre-learned skills, robust execution of the individual skills themselves
remains challenging, as visuomotor policies often fail under distribution
shifts induced by scene composition. To address this, we introduce a scene
graph-based representation that focuses on task-relevant objects and relations,
thereby mitigating sensitivity to irrelevant variation. Building on this idea,
we develop a scene-graph skill learning framework that integrates graph neural
networks with diffusion-based imitation learning, and further combine "focused"
scene-graph skills with a vision-language model (VLM) based task planner.
Experiments in both simulation and real-world manipulation tasks demonstrate
substantially higher success rates than state-of-the-art baselines,
highlighting improved robustness and compositional generalization in
long-horizon tasks.

</details>


### [53] [Latent Conditioned Loco-Manipulation Using Motion Priors](https://arxiv.org/abs/2509.16061)
*Maciej Stępień,Rafael Kourdis,Constant Roux,Olivier Stasse*

Main category: cs.RO

TL;DR: 本文提出一种多用途运动策略方法，通过模仿学习获取低级技能，并结合潜在空间控制高效解决复杂任务，适用于人形和四足机器人。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法主要关注单一技能，难以高效解决复杂任务，需考虑高级目标、机器人物理限制及运动风格。

Method: 提出先训练多用途运动策略，通过模仿获取低级技能并提供潜在空间控制；扩展方法以处理约束确保部署安全，并使用扩散判别器提升模仿质量。

Result: 在H1人形和Solo12四足机器人仿真中验证了方法有效性，并将策略部署在Solo12硬件上。

Conclusion: 该方法在人形和四足机器人的协同操作任务中表现出色，为复杂任务控制提供了高效解决方案。

Abstract: Although humanoid and quadruped robots provide a wide range of capabilities,
current control methods, such as Deep Reinforcement Learning, focus mainly on
single skills. This approach is inefficient for solving more complicated tasks
where high-level goals, physical robot limitations and desired motion style
might all need to be taken into account. A more effective approach is to first
train a multipurpose motion policy that acquires low-level skills through
imitation, while providing latent space control over skill execution. Then,
this policy can be used to efficiently solve downstream tasks. This method has
already been successful for controlling characters in computer graphics. In
this work, we apply the approach to humanoid and quadrupedal loco-manipulation
by imitating either simple synthetic motions or kinematically retargeted dog
motions. We extend the original formulation to handle constraints, ensuring
deployment safety, and use a diffusion discriminator for better imitation
quality. We verify our methods by performing loco-manipulation in simulation
for the H1 humanoid and Solo12 quadruped, as well as deploying policies on
Solo12 hardware. Videos and code are available at
https://gepetto.github.io/LaCoLoco/

</details>


### [54] [DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation](https://arxiv.org/abs/2509.16063)
*Yue Su,Chubin Zhang,Sijin Chen,Liufan Tan,Yansong Tang,Jianan Wang,Xihui Liu*

Main category: cs.RO

TL;DR: 提出DSPv2，一种新策略架构，通过融合3D空间特征和多视角2D语义特征，突破模仿学习中复杂观察处理、泛化和动作生成的难题。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习中复杂观察处理、泛化能力不足和动作生成不连贯等问题。

Method: 引入3D空间特征与多视角2D语义特征对齐的编码方案，扩展密集策略范式至全身移动操作领域。

Result: 实验表明，DSPv2在任务性能和泛化能力上显著优于现有方法。

Conclusion: DSPv2能有效提升机器人技能在多样环境中的适应性和精确操作能力。

Abstract: Learning whole-body mobile manipulation via imitation is essential for
generalizing robotic skills to diverse environments and complex tasks. However,
this goal is hindered by significant challenges, particularly in effectively
processing complex observation, achieving robust generalization, and generating
coherent actions. To address these issues, we propose DSPv2, a novel policy
architecture. DSPv2 introduces an effective encoding scheme that aligns 3D
spatial features with multi-view 2D semantic features. This fusion enables the
policy to achieve broad generalization while retaining the fine-grained
perception necessary for precise control. Furthermore, we extend the Dense
Policy paradigm to the whole-body mobile manipulation domain, demonstrating its
effectiveness in generating coherent and precise actions for the whole-body
robotic platform. Extensive experiments show that our method significantly
outperforms existing approaches in both task performance and generalization
ability. Project page is available at: https://selen-suyue.github.io/DSPv2Net/.

</details>


### [55] [I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models](https://arxiv.org/abs/2509.16072)
*Clemence Grislain,Hamed Rahimi,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 提出一种针对语言条件机器人操控中语义不对齐错误的检测方法，并推出开源框架I-FailSense，通过后训练和轻量级分类头提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉语言模型在语义不对齐错误检测上的不足，提升机器人任务执行的鲁棒性。

Method: 基于现有数据构建语义错误检测数据集，并在基础VLM上附加轻量级分类头（FS块），通过集成机制聚合预测。

Result: I-FailSense在语义错误检测上优于同类模型，并能泛化到更广泛的失败类别和不同环境。

Conclusion: I-FailSense有效提升了语义错误检测能力，且具备良好的泛化性和迁移性。

Abstract: Language-conditioned robotic manipulation in open-world settings requires not
only accurate task execution but also the ability to detect failures for robust
deployment in real-world environments. Although recent advances in
vision-language models (VLMs) have significantly improved the spatial reasoning
and task-planning capabilities of robots, they remain limited in their ability
to recognize their own failures. In particular, a critical yet underexplored
challenge lies in detecting semantic misalignment errors, where the robot
executes a task that is semantically meaningful but inconsistent with the given
instruction. To address this, we propose a method for building datasets
targeting Semantic Misalignment Failures detection, from existing
language-conditioned manipulation datasets. We also present I-FailSense, an
open-source VLM framework with grounded arbitration designed specifically for
failure detection. Our approach relies on post-training a base VLM, followed by
training lightweight classification heads, called FS blocks, attached to
different internal layers of the VLM and whose predictions are aggregated using
an ensembling mechanism. Experiments show that I-FailSense outperforms
state-of-the-art VLMs, both comparable in size and larger, in detecting
semantic misalignment errors. Notably, despite being trained only on semantic
misalignment detection, I-FailSense generalizes to broader robotic failure
categories and effectively transfers to other simulation environments and
real-world with zero-shot or minimal post-training. The datasets and models are
publicly released on HuggingFace (Webpage:
https://clemgris.github.io/I-FailSense/).

</details>


### [56] [Real-Time Planning and Control with a Vortex Particle Model for Fixed-Wing UAVs in Unsteady Flows](https://arxiv.org/abs/2509.16079)
*Ashwin Gupta,Kevin Wolfe,Gino Perrotta,Joseph Moore*

Main category: cs.RO

TL;DR: 该论文提出了一种实时规划和控制方法，能够处理非定常空气动力学效应，并展示了在模拟和硬件实验中提升飞行性能的效果。


<details>
  <summary>Details</summary>
Motivation: 非定常空气动力学效应对飞行器尤其在敏捷机动和复杂气流环境中的性能有显著影响。

Method: 采用轻量级涡粒子模型并结合GPU加速，以及基于采样的策略优化方法进行预测推理。

Result: 通过重新规划和非定常空气动力学模型，成功提升了在非定常环境气流干扰下的机动性能。

Conclusion: 该方法为提升飞行器在复杂气流环境中的性能提供了一种有效途径。

Abstract: Unsteady aerodynamic effects can have a profound impact on aerial vehicle
flight performance, especially during agile maneuvers and in complex
aerodynamic environments. In this paper, we present a real-time planning and
control approach capable of reasoning about unsteady aerodynamics. Our approach
relies on a lightweight vortex particle model, parallelized to allow GPU
acceleration, and a sampling-based policy optimization strategy capable of
leveraging the vortex particle model for predictive reasoning. We demonstrate,
through both simulation and hardware experiments, that by replanning with our
unsteady aerodynamics model, we can improve the performance of aggressive
post-stall maneuvers in the presence of unsteady environmental flow
disturbances.

</details>


### [57] [Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors](https://arxiv.org/abs/2509.16122)
*Carter Sifferman,Mohit Gupta,Michael Gleicher*

Main category: cs.RO

TL;DR: 提出了一种基于机器人臂上安装的微型飞行时间传感器的物体检测与定位方法，解决了传感器区分机器人自身与外部物体的挑战，并验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人臂上传感器在测量中难以区分机器人自身与外部物体的问题，同时提供更灵活的传感器配置方案。

Method: 利用现成的低分辨率飞行时间传感器的原始数据，构建机器人单独存在时的测量模型，实时检测附近物体。

Result: 方法能够检测机器人臂附近的小物体，并沿机器人臂长度精确定位物体，性能受物体类型、位置和环境光照影响。

Conclusion: 该方法在碰撞避障和安全人机交互中具有潜在应用价值。

Abstract: We provide a method for detecting and localizing objects near a robot arm
using arm-mounted miniature time-of-flight sensors. A key challenge when using
arm-mounted sensors is differentiating between the robot itself and external
objects in sensor measurements. To address this challenge, we propose a
computationally lightweight method which utilizes the raw time-of-flight
information captured by many off-the-shelf, low-resolution time-of-flight
sensor. We build an empirical model of expected sensor measurements in the
presence of the robot alone, and use this model at runtime to detect objects in
proximity to the robot. In addition to avoiding robot self-detections in common
sensor configurations, the proposed method enables extra flexibility in sensor
placement, unlocking configurations which achieve more efficient coverage of a
radius around the robot arm. Our method can detect small objects near the arm
and localize the position of objects along the length of a robot link to
reasonable precision. We evaluate the performance of the method with respect to
object type, location, and ambient light level, and identify limiting factors
on performance inherent in the measurement principle. The proposed method has
potential applications in collision avoidance and in facilitating safe
human-robot interaction.

</details>


### [58] [Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning](https://arxiv.org/abs/2509.16136)
*Changwei Yao,Xinzi Liu,Chen Li,Marios Savvides*

Main category: cs.RO

TL;DR: 该论文提出了RE-GoT，一种结合语言模型和图推理的双层框架，用于自动化设计强化学习中的奖励函数，通过实验证明了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 设计有效的奖励函数是强化学习中的一大挑战，传统方法依赖人工设计且效果有限，需要一种自动化且高效的方法。

Method: RE-GoT利用语言模型和图推理分解任务，并结合视觉语言模型生成和迭代优化奖励函数，无需人工干预。

Result: 在RoboGen和ManiSkill2任务上，RE-GoT显著提高了任务成功率，部分任务甚至超越人工设计的奖励函数。

Conclusion: 结合语言模型、视觉模型和图推理的方法为强化学习中奖励函数的自动化设计提供了可扩展且高效的解决方案。

Abstract: Designing effective reward functions remains a major challenge in
reinforcement learning (RL), often requiring considerable human expertise and
iterative refinement. Recent advances leverage Large Language Models (LLMs) for
automated reward design, but these approaches are limited by hallucinations,
reliance on human feedback, and challenges with handling complex, multi-step
tasks. In this work, we introduce Reward Evolution with Graph-of-Thoughts
(RE-GoT), a novel bi-level framework that enhances LLMs with structured
graph-based reasoning and integrates Visual Language Models (VLMs) for
automated rollout evaluation. RE-GoT first decomposes tasks into
text-attributed graphs, enabling comprehensive analysis and reward function
generation, and then iteratively refines rewards using visual feedback from
VLMs without human intervention. Extensive experiments on 10 RoboGen and 4
ManiSkill2 tasks demonstrate that RE-GoT consistently outperforms existing
LLM-based baselines. On RoboGen, our method improves average task success rates
by 32.25%, with notable gains on complex multi-step tasks. On ManiSkill2,
RE-GoT achieves an average success rate of 93.73% across four diverse
manipulation tasks, significantly surpassing prior LLM-based approaches and
even exceeding expert-designed rewards. Our results indicate that combining
LLMs and VLMs with graph-of-thoughts reasoning provides a scalable and
effective solution for autonomous reward evolution in RL.

</details>


### [59] [Modeling Elastic-Body Dynamics of Fish Swimming Using a Variational Framework](https://arxiv.org/abs/2509.16145)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本文介绍了基于哈密顿原理的鱼类游泳完整动力学模型，探究了颤振频率和身体刚度对游泳速度和运输成本的影响，并揭示了设计高效软体机器鱼的关键参数。


<details>
  <summary>Details</summary>
Motivation: 鱼启发的水下机器人因其高游泳效率和灵活性受到广泛关注，但需要准确且可解释的模型来优化设计和控制。

Method: 作者从哈密顿原理出发，建立了一个考虑连续分布弹性和流体-结构耦合的全身体动力学模型，能够模拟自推进运动。

Result: 研究发现，游泳速度和能量效率与尾拍频率呈相反趋势，身体刚度和长度存在最优值。

Conclusion: 这些结果为生物游泳机制提供了新见解，并对高性能软体机器鱼的设计具有指导意义。

Abstract: Fish-inspired aquatic robots are gaining increasing attention in research
communities due to their high swimming speeds and efficient propulsion enabled
by flexible bodies that generate undulatory motions. To support the design
optimizations and control of such systems, accurate, interpretable, and
computationally tractable modeling of the underlying swimming dynamics is
indispensable. In this letter, we present a full-body dynamics model for fish
swimming, rigorously derived from Hamilton's principle. The model captures the
continuously distributed elasticity of a deformable fish body undergoing large
deformations and incorporates fluid-structure coupling effects, enabling
self-propelled motion without prescribing kinematics. A preliminary parameter
study explores the influence of actuation frequency and body stiffness on
swimming speed and cost of transport (COT). Simulation results indicate that
swimming speed and energy efficiency exhibit opposing trends with tail-beat
frequency and that both body stiffness and body length have distinct optimal
values. These findings provide insights into biological swimming mechanisms and
inform the design of high-performance soft robotic swimmers.

</details>


### [60] [Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories](https://arxiv.org/abs/2509.16176)
*Yifan Lin,Sophie Ziyu Liu,Ran Qi,George Z. Xue,Xinping Song,Chao Qin,Hugh H. -T. Liu*

Main category: cs.RO

TL;DR: ACDC系统通过自然语言驱动无人机自动拍摄，解决了传统方法需要手动设置路径和视角的问题。


<details>
  <summary>Details</summary>
Motivation: 传统无人机拍摄需手动设置路径和视角，费时且效果不稳定。ACDC旨在通过自然语言提示实现自动化。

Method: 结合大语言模型和视觉基础模型，通过视觉-语言检索、偏好优化框架和运动规划器生成无人机轨迹。

Result: 在模拟和硬件实验中，ACDC能在多样化场景中生成专业质量的视频，无需机器人或摄影专业知识。

Conclusion: ACDC展示了通过自然语言实现自动化空中摄影的潜力，推动AI代理在实景中的应用。

Abstract: We present Agentic Aerial Cinematography: From Dialogue Cues to Cinematic
Trajectories (ACDC), an autonomous drone cinematography system driven by
natural language communication between human directors and drones. The main
limitation of previous drone cinematography workflows is that they require
manual selection of waypoints and view angles based on predefined human intent,
which is labor-intensive and yields inconsistent performance. In this paper, we
propose employing large language models (LLMs) and vision foundation models
(VFMs) to convert free-form natural language prompts directly into executable
indoor UAV video tours. Specifically, our method comprises a vision-language
retrieval pipeline for initial waypoint selection, a preference-based Bayesian
optimization framework that refines poses using aesthetic feedback, and a
motion planner that generates safe quadrotor trajectories. We validate ACDC
through both simulation and hardware-in-the-loop experiments, demonstrating
that it robustly produces professional-quality footage across diverse indoor
scenes without requiring expertise in robotics or cinematography. These results
highlight the potential of embodied AI agents to close the loop from
open-vocabulary dialogue to real-world autonomous aerial cinematography.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [61] [Differentiable Acoustic Radiance Transfer](https://arxiv.org/abs/2509.15946)
*Sungho Lee,Matteo Scerbo,Seungu Han,Min Jun Choi,Kyogu Lee,Enzo De Sena*

Main category: cs.SD

TL;DR: 论文介绍了DART，一种可微的高效声学辐射传输（ART）实现，用于梯度优化材料属性，并在声场学习中表现出优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为了更高效地模拟房间声学并优化材料属性，提出了一种可微的声学辐射传输方法。

Method: 通过离散化时间依赖的渲染方程，提出DART方法，实现了对材料属性的梯度优化。

Result: 实验表明，DART在稀疏测量场景下表现更好，且保持了系统的简单性和可解释性。

Conclusion: DART是一种高效且可解释的声学建模方法，适用于声场学习任务。

Abstract: Geometric acoustics is an efficient approach to room acoustics modeling,
governed by the canonical time-dependent rendering equation. Acoustic radiance
transfer (ART) solves the equation through discretization, modeling the time-
and direction-dependent energy exchange between surface patches given with
flexible material properties. We introduce DART, a differentiable and efficient
implementation of ART that enables gradient-based optimization of material
properties. We evaluate DART on a simpler variant of the acoustic field
learning task, which aims to predict the energy responses of novel
source-receiver settings. Experimental results show that DART exhibits
favorable properties, e.g., better generalization under a sparse measurement
scenario, compared to existing signal processing and neural network baselines,
while remaining a simple, fully interpretable system.

</details>


### [62] [Reverse Engineering of Music Mixing Graphs with Differentiable Processors and Iterative Pruning](https://arxiv.org/abs/2509.15948)
*Sungho Lee,Marco Martínez-Ramírez,Wei-Hsiang Liao,Stefan Uhlich,Giorgio Fabbro,Kyogu Lee,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 本文提出了一种反向工程音乐混音的方法，通过构建可微处理器图并优化参数，保留高质量的同时减少处理器数量，并支持高效并行计算。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示音乐混音中干信号的处理和组合方式，扩展了先前工作，以反映混音的组成性质。

Method: 构建混音台，应用所有可用处理器，通过梯度下降优化参数，逐步移除冗余处理器并微调剩余部分，同时采用批处理和利用干/湿参数加速搜索。

Result: 在保留混音台质量的前提下，移除了约三分之二的处理器，并通过定量和定性分析验证了方法的性能和计算效率。

Conclusion: 该方法不仅可用于分析音乐混音，还能为自动化混音等下游任务提供大规模图数据，高效实现是其中的关键。

Abstract: Reverse engineering of music mixes aims to uncover how dry source signals are
processed and combined to produce a final mix. We extend the prior works to
reflect the compositional nature of mixing and search for a graph of audio
processors. First, we construct a mixing console, applying all available
processors to every track and subgroup. With differentiable processor
implementations, we optimize their parameters with gradient descent. Then, we
repeat the process of removing negligible processors and fine-tuning the
remaining ones. This way, the quality of the full mixing console can be
preserved while removing approximately two-thirds of the processors. The
proposed method can be used not only to analyze individual music mixes but also
to collect large-scale graph data that can be used for downstream tasks, e.g.,
automatic mixing. Especially for the latter purpose, efficient implementation
of the search is crucial. To this end, we present an efficient batch-processing
method that computes multiple processors in parallel. We also exploit the
"dry/wet" parameter of the processors to accelerate the search. Extensive
quantitative and qualitative analyses are conducted to evaluate the proposed
method's performance, behavior, and computational cost.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [63] [Enhancing Physical Layer Security in IoT-Based RF-FSO Integrated Networks: Multi-RIS Structures and their Impact on Secure Communication](https://arxiv.org/abs/2509.15411)
*Anika Tabassum Biva,Md. Ibrahim,A. S. M. Badrudduza,Imran Shafique Ansari*

Main category: cs.IT

TL;DR: 论文研究多RIS辅助的RF-FSO混合通信模型，提升复杂环境中物联网应用的性能，分析窃听场景下的保密性能，并通过数值结果验证多RIS结构的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决6G无线通信和物联网网络中的传播环境控制问题，特别是在存在窃听者的复杂环境下提升保密性能。

Method: 采用多RIS辅助的RF-FSO混合通信模型，建模RF链路的Rician衰落和FSO链路的Málaga湍流及指向误差，推导保密性能的闭式解析表达式。

Result: 数值结果表明，多RIS结构显著提升保密性能（SOP提高47.67%），且外差检测有效缓解FSO链路指向误差的负面影响。

Conclusion: 多RIS结构在复杂环境中有效提升物联网通信的保密性能，理论结果通过蒙特卡罗仿真验证。

Abstract: Due to their ability to dynamically control the propagation environment,
reconfigurable intelligent surfaces (RISs) offer a promising solution to
address the challenges of $6$G wireless communication, especially in the
context of Internet of Things (IoT) networks. This paper investigates a mixed
communication model with multi-RIS-aided radio frequency (RF)-free space optics
(FSO) to enhance the performance of IoT applications in complex environments.
An eavesdropper is assumed to be present, attempting to intercept confidential
information transmitted over the RF link. All RF links are modeled using Rician
fading, while the FSO link accounts for M\'alaga turbulence with pointing
errors, capturing real-world propagation conditions. Closed-form analytical
expressions are derived for the secrecy outage probability, average secrecy
capacity, and effective secrecy throughput in terms of Meijer's G function. To
gain further insight, high signal-to-noise approximations of these metrics are
also presented. Numerical results highlight the importance of heterodyne
detection in mitigating the adverse effects of pointing errors on the FSO link.
Moreover, integrating a multi-RIS structure into the proposed model
significantly increases secrecy performance, achieving up to a $47.67\%$
improvement in SOP compared to conventional methods. Finally, the derived
analytical results are validated through Monte Carlo simulations.

</details>


### [64] [Interplay Between Belief Propagation and Transformer: Differential-Attention Message Passing Transformer](https://arxiv.org/abs/2509.15637)
*Chin Wa Lau,Xiang Shi,Ziyan Zheng,Haiwen Cao,Nian Guo*

Main category: cs.IT

TL;DR: 本文提出了一种结合经典置信传播原则与Transformer架构的新型解码器，通过可微分的校验子损失函数和差分注意力机制，提升了短到中等长度LDPC码的解码性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何将数据驱动的Transformer模型与传统置信传播原则结合，以优化纠错码的解码性能。

Method: 设计了结合经典置信传播的Transformer架构，引入了可微分的校验子损失函数和差分注意力机制。

Result: 新方法在短到中等长度LDPC码上表现优于现有Transformer解码器和传统置信传播解码器。

Conclusion: 这种混合架构为纠错码解码提供了高效且性能优越的新思路。

Abstract: Transformer-based neural decoders have emerged as a promising approach to
error correction coding, combining data-driven adaptability with efficient
modeling of long-range dependencies. This paper presents a novel decoder
architecture that integrates classical belief propagation principles with
transformer designs. We introduce a differentiable syndrome loss function
leveraging global codebook structure and a differential-attention mechanism
optimizing bit and syndrome embedding interactions. Experimental results
demonstrate consistent performance improvements over existing transformer-based
decoders, with our approach surpassing traditional belief propagation decoders
for short-to-medium length LDPC codes.

</details>


### [65] [Near-Field Beam Training Through Beam Diverging](https://arxiv.org/abs/2509.16035)
*Ran Li,Ziyi Xu,Ying-Jun Angela Zhang*

Main category: cs.IT

TL;DR: 本文研究了用于大规模天线阵列近场波束训练的波束发散技术，提出了低开销、高精度的训练方法，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有近场波束训练方法依赖波束聚焦，导致开销大且精度有限，需要改进。

Method: 设计散开码本和分层方法，结合RF链和增强技术，降低训练开销并提高准确性。

Result: 数值结果显示该方法开销低且精度接近最优，优于现有技术。

Conclusion: 提出的波束散开训练方法在近场大规模天线阵列中具有显著优势。

Abstract: This paper investigates beam training techniques for near-field (NF)
extremely large-scale antenna arrays (ELAAs). Existing NF beam training methods
predominantly rely on beam focusing, where the base station (BS) transmits
highly spatially selective beams to locate the user equipment (UE). However,
these beam-focusing-based schemes suffer from both high beam sweeping overhead
and limited accuracy in the NF, primarily due to the narrow beams' high
susceptibility to misalignment. To address this, we propose a novel NF beam
training paradigm using diverging beams. Specifically, we introduce the beam
diverging effect and exploit it for low-overhead, high-accuracy beam training.
First, we design a diverging codeword to induce the beam diverging effect with
a single radio frequency (RF) chain. Next, we develop a diverging polar-domain
codebook (DPC) along with a hierarchical method that enables angular-domain
localization of the UE with only 2 log_2(N) pilots, where N denotes the number
of antennas. Finally, we enhance beam training performance through two
additional techniques: a DPC angular range reduction strategy to improve the
effectiveness of beam diverging, and a pilot set expansion method to increase
overall beam training accuracy. Numerical results show that our algorithm
achieves near-optimal accuracy with a small pilot overhead, outperforming
existing methods.

</details>


### [66] [3D Near-Field Beam Training for Uniform Planar Arrays through Beam Diverging](https://arxiv.org/abs/2509.16055)
*Ran Li,Ziyi Xu,Ying-Jun Angela Zhang*

Main category: cs.IT

TL;DR: 6G通信系统中，大规模天线阵列的引入增加了波束训练的复杂性，尤其是在近场（NF）条件下。本文针对毫米波系统提出了一种新的波束训练方法，利用波束发散效应实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 大规模天线阵列在6G通信中虽然提升了信号强度和空间分辨率，但也增加了波束训练的复杂性。尤其是在近场条件下，现有方法对用户设备位置失配高度敏感，导致训练开销大。本文旨在解决这一问题。

Method: 提出了一种新的波束训练方法，利用波束发散效应构建分层码本进行粗略用户定位，并通过3D采样机制构建近场精细化码本以实现精确波束训练。

Result: 数值结果表明，该方法在保持低训练开销的同时，实现了优越的波束训练性能。

Conclusion: 通过利用波束发散效应和分层码本设计，本文提出的方法有效解决了大规模天线阵列在近场条件下的波束训练问题，同时降低了训练开销。

Abstract: In future 6G communication systems, large-scale antenna arrays promise
enhanced signal strength and spatial resolution, but they also increase the
complexity of beam training. Moreover, as antenna counts grow and carrier
wavelengths shrink, the channel model transits from far-field (FF) planar waves
to near-field (NF) spherical waves, further complicating the beam training
process. This paper focuses on millimeter-wave (mmWave) systems equipped with
large-scale uniform planar arrays (UPAs), which produce 3D beam patterns and
introduce additional challenges for NF beam training. Existing methods
primarily rely on either FF steering or NF focusing codewords, both of which
are highly sensitive to mismatches in user equipment (UE) location, leading to
high sensitivity to even slight mismatch and excessive training overhead. In
contrast, we introduce a novel beam training approach leveraging the
beam-diverging effect, which enables adjustable wide-beam coverage using only a
single radio frequency (RF) chain. Specifically, we first analyze the spatial
characteristics of this effect in UPA systems and leverage them to construct
hierarchical codebooks for coarse UE localization. Then, we develop a 3D
sampling mechanism to build an NF refinement codebook for precise beam
training. Numerical results demonstrate that the proposed algorithm achieves
superior beam training performance while maintaining low training overhead.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [67] [siDPT: siRNA Efficacy Prediction via Debiased Preference-Pair Transformer](https://arxiv.org/abs/2509.15664)
*Honggen Zhang,Xiangrui Gao,Lipeng Lai*

Main category: q-bio.GN

TL;DR: 提出了siDPT框架，通过偏好对数据集和去偏排序目标提升siRNA抑制预测和泛化能力。


<details>
  <summary>Details</summary>
Motivation: siRNA药物的设计和筛选成本高昂，数据驱动模型可利用大量siRNA数据改进预测。

Method: 构建偏好对数据集，设计siRNA-mRNA交互式Transformer，采用去偏排序目标。

Result: 在两个公共数据集和一个新收集专利数据集上，Pearson相关系数显著提升。

Conclusion: siDPT框架能有效提升siRNA抑制预测的准确性和泛化能力。

Abstract: Small interfering RNA (siRNA) is a short double-stranded RNA molecule (about
21-23 nucleotides) with the potential to cure diseases by silencing the
function of target genes. Due to its well-understood mechanism, many
siRNA-based drugs have been evaluated in clinical trials. However, selecting
effective binding regions and designing siRNA sequences requires extensive
experimentation, making the process costly. As genomic resources and publicly
available siRNA datasets continue to grow, data-driven models can be leveraged
to better understand siRNA-mRNA interactions. To fully exploit such data,
curating high-quality siRNA datasets is essential to minimize experimental
errors and noise. We propose siDPT: siRNA efficacy Prediction via Debiased
Preference-Pair Transformer, a framework that constructs a preference-pair
dataset and designs an siRNA-mRNA interactive transformer with debiased ranking
objectives to improve siRNA inhibition prediction and generalization. We
evaluate our approach using two public datasets and one newly collected patent
dataset. Our model demonstrates substantial improvement in Pearson correlation
and strong performance across other metrics.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [68] [How Good are Foundation Models in Step-by-Step Embodied Reasoning?](https://arxiv.org/abs/2509.15293)
*Dinura Dissanayake,Ahmed Heakl,Omkar Thawakar,Noor Ahsan,Ritesh Thawkar,Ketan More,Jean Lahoud,Rao Anwer,Hisham Cholakkal,Ivan Laptev,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 论文提出了一个名为FoMER的基准测试，用于评估大型多模态模型（LMMs）在复杂具身决策任务中的推理能力，揭示了其潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 探索大型多模态模型在具身环境中执行结构化推理的能力，以提升机器人在现实世界中的决策效果和安全性。

Method: 提出了FoMER基准测试，涵盖多样化任务，并结合新的评估框架，对多个领先的LMMs进行了实证分析。

Result: 研究发现LMMs在具身推理方面既展示了潜力，也存在局限性，为未来研究指明了方向。

Conclusion: FoMER基准测试为研究LMMs在具身推理中的应用提供了重要工具，并揭示了未来机器人智能发展的关键挑战和机遇。

Abstract: Embodied agents operating in the physical world must make decisions that are
not only effective but also safe, spatially coherent, and grounded in context.
While recent advances in large multimodal models (LMMs) have shown promising
capabilities in visual understanding and language generation, their ability to
perform structured reasoning for real-world embodied tasks remains
underexplored. In this work, we aim to understand how well foundation models
can perform step-by-step reasoning in embodied environments. To this end, we
propose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed to
evaluate the reasoning capabilities of LMMs in complex embodied decision-making
scenarios. Our benchmark spans a diverse set of tasks that require agents to
interpret multimodal observations, reason about physical constraints and
safety, and generate valid next actions in natural language. We present (i) a
large-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluation
framework that disentangles perceptual grounding from action reasoning, and
(iii) empirical analysis of several leading LMMs under this setting. Our
benchmark includes over 1.1k samples with detailed step-by-step reasoning
across 10 tasks and 8 embodiments, covering three different robot types. Our
results highlight both the potential and current limitations of LMMs in
embodied reasoning, pointing towards key challenges and opportunities for
future research in robot intelligence. Our data and code will be made publicly
available.

</details>


### [69] [SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models](https://arxiv.org/abs/2509.15536)
*Sen Wang,Jingyi Tian,Le Wang,Zhimin Liao,Jiayi Li,Huaiyi Dong,Kun Xia,Sanping Zhou,Wei Tang,Hua Gang*

Main category: cs.CV

TL;DR: SAMPO是一种混合框架，结合了视觉自回归建模和因果建模，解决了现有自回归世界模型在视觉连贯性和效率上的不足。通过双向空间注意力和动态表示优化，提升了时间一致性和生成质量，并在实验中获得显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有自回归世界模型在视觉预测中存在空间结构破坏、解码效率低和运动建模不足的问题。SAMPO旨在解决这些问题，提升时间一致性和生成效率。

Method: SAMPO结合了视觉自回归建模（帧内生成）和因果建模（帧间生成），采用双向空间注意力保护空间局部性，支持并行解码。还设计了非对称多尺度标记器和轨迹感知运动提示模块，优化动态场景理解和生成效率。

Result: SAMPO在动作条件视频预测和基于模型的控制中表现出色，生成质量提升且推理速度加快4.4倍。还展示了零样本泛化能力和模型扩展优势。

Conclusion: SAMPO通过混合建模和动态优化，显著提升了世界模型的视觉连贯性和效率，展现了广泛的应用潜力。

Abstract: World models allow agents to simulate the consequences of actions in imagined
environments for planning, control, and long-horizon decision-making. However,
existing autoregressive world models struggle with visually coherent
predictions due to disrupted spatial structure, inefficient decoding, and
inadequate motion modeling. In response, we propose \textbf{S}cale-wise
\textbf{A}utoregression with \textbf{M}otion \textbf{P}r\textbf{O}mpt
(\textbf{SAMPO}), a hybrid framework that combines visual autoregressive
modeling for intra-frame generation with causal modeling for next-frame
generation. Specifically, SAMPO integrates temporal causal decoding with
bidirectional spatial attention, which preserves spatial locality and supports
parallel decoding within each scale. This design significantly enhances both
temporal consistency and rollout efficiency. To further improve dynamic scene
understanding, we devise an asymmetric multi-scale tokenizer that preserves
spatial details in observed frames and extracts compact dynamic representations
for future frames, optimizing both memory usage and model performance.
Additionally, we introduce a trajectory-aware motion prompt module that injects
spatiotemporal cues about object and robot trajectories, focusing attention on
dynamic regions and improving temporal consistency and physical realism.
Extensive experiments show that SAMPO achieves competitive performance in
action-conditioned video prediction and model-based control, improving
generation quality with 4.4$\times$ faster inference. We also evaluate SAMPO's
zero-shot generalization and scaling behavior, demonstrating its ability to
generalize to unseen tasks and benefit from larger model sizes.

</details>


### [70] [CoPAD : Multi-source Trajectory Fusion and Cooperative Trajectory Prediction with Anchor-oriented Decoder in V2X Scenarios](https://arxiv.org/abs/2509.15984)
*Kangyu Wu,Jiaqi Qiao,Ya Zhang*

Main category: cs.CV

TL;DR: CoPAD是一种新型轻量级协同轨迹预测框架，结合匈牙利算法与卡尔曼滤波的融合模块，显著提升了自动驾驶中轨迹预测的完整性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前单车辆感知的不稳定性限制了轨迹预测的性能，因此需要一种多源数据协同预测的方法。

Method: 提出CoPAD框架，包含融合模块、历史轨迹注意力模块（PTA）、模式注意力模块和基于稀疏锚的解码器（AoD）。

Result: 在DAIR-V2X-Seq数据集上取得最优性能，验证了模型在V2X场景中的有效性。

Conclusion: CoPAD通过多源数据协同预测，显著提升了轨迹预测的准确性和多样性。

Abstract: Recently, data-driven trajectory prediction methods have achieved remarkable
results, significantly advancing the development of autonomous driving.
However, the instability of single-vehicle perception introduces certain
limitations to trajectory prediction. In this paper, a novel lightweight
framework for cooperative trajectory prediction, CoPAD, is proposed. This
framework incorporates a fusion module based on the Hungarian algorithm and
Kalman filtering, along with the Past Time Attention (PTA) module, mode
attention module and anchor-oriented decoder (AoD). It effectively performs
early fusion on multi-source trajectory data from vehicles and road
infrastructure, enabling the trajectories with high completeness and accuracy.
The PTA module can efficiently capture potential interaction information among
historical trajectories, and the mode attention module is proposed to enrich
the diversity of predictions. Additionally, the decoder based on sparse anchors
is designed to generate the final complete trajectories. Extensive experiments
show that CoPAD achieves the state-of-the-art performance on the DAIR-V2X-Seq
dataset, validating the effectiveness of the model in cooperative trajectory
prediction in V2X scenarios.

</details>


### [71] [Towards Sharper Object Boundaries in Self-Supervised Depth Estimation](https://arxiv.org/abs/2509.15987)
*Aurélien Cecille,Stefan Duffner,Franck Davoine,Rémi Agier,Thibault Neveu*

Main category: cs.CV

TL;DR: 提出了一种自监督的单目深度估计方法，通过混合分布建模像素深度，显著提升了边界清晰度和点云质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在物体边界处的深度估计常产生模糊和不准确的3D点，需要细粒度监督，本文旨在无需精细监督即可实现清晰边界。

Method: 将每个像素的深度建模为混合分布，通过方差感知损失函数和不确定性传播，无缝集成到现有管道中。

Result: 在KITTI和VKITTIv2数据集上，边界清晰度提升了35%，点云质量优于最先进基线。

Conclusion: 该方法仅需自监督即可实现清晰的深度边界，显著提升了深度估计的准确性和实用性。

Abstract: Accurate monocular depth estimation is crucial for 3D scene understanding,
but existing methods often blur depth at object boundaries, introducing
spurious intermediate 3D points. While achieving sharp edges usually requires
very fine-grained supervision, our method produces crisp depth discontinuities
using only self-supervision. Specifically, we model per-pixel depth as a
mixture distribution, capturing multiple plausible depths and shifting
uncertainty from direct regression to the mixture weights. This formulation
integrates seamlessly into existing pipelines via variance-aware loss functions
and uncertainty propagation. Extensive evaluations on KITTI and VKITTIv2 show
that our method achieves up to 35% higher boundary sharpness and improves point
cloud quality compared to state-of-the-art baselines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [72] [Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model](https://arxiv.org/abs/2509.15258)
*Zheng Yang,Guoxuan Chi,Chenshu Wu,Hanyu Liu,Yuchong Gao,Yunhao Liu,Jie Xu,Tony Xiao Han*

Main category: cs.LG

TL;DR: 论文探讨了生成式人工智能（GenAI）与无线传感系统的结合，分析了GenAI如何通过插件或直接求解的方式改进传感任务，并讨论了主流生成模型的适用性及其挑战。


<details>
  <summary>Details</summary>
Motivation: 研究GenAI在无线传感系统中的应用潜力，以提高设备定位、人类活动识别和环境监测等任务的性能。

Method: 通过两种互补视角分析GenAI与无线传感的结合：一是作为插件增强任务特定模型，二是直接解决传感任务；同时评估GANs、VAEs和扩散模型的适用性。

Result: GenAI能显著提升无线传感任务的效果，但应用中存在挑战，如模型选择和可扩展性。

Conclusion: 未来研究方向是构建统一的预训练无线基础模型，以实现高效、自适应的跨任务信号理解。

Abstract: Generative Artificial Intelligence (GenAI) has made significant advancements
in fields such as computer vision (CV) and natural language processing (NLP),
demonstrating its capability to synthesize high-fidelity data and improve
generalization. Recently, there has been growing interest in integrating GenAI
into wireless sensing systems. By leveraging generative techniques such as data
augmentation, domain adaptation, and denoising, wireless sensing applications,
including device localization, human activity recognition, and environmental
monitoring, can be significantly improved. This survey investigates the
convergence of GenAI and wireless sensing from two complementary perspectives.
First, we explore how GenAI can be integrated into wireless sensing pipelines,
focusing on two modes of integration: as a plugin to augment task-specific
models and as a solver to directly address sensing tasks. Second, we analyze
the characteristics of mainstream generative models, such as Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and diffusion
models, and discuss their applicability and unique advantages across various
wireless sensing tasks. We further identify key challenges in applying GenAI to
wireless sensing and outline a future direction toward a wireless foundation
model: a unified, pre-trained design capable of scalable, adaptable, and
efficient signal understanding across diverse sensing tasks.

</details>


### [73] [SolarCrossFormer: Improving day-ahead Solar Irradiance Forecasting by Integrating Satellite Imagery and Ground Sensors](https://arxiv.org/abs/2509.15827)
*Baptiste Schubnel,Jelena Simeunović,Corentin Tissier,Pierre-Jean Alet,Rafael E. Carrillo*

Main category: cs.LG

TL;DR: SolarCrossFormer是一种新型深度学习模型，结合卫星图像和地面气象站时间序列数据，用于提高太阳能辐照度预测的时空分辨率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大规模太阳能光伏系统并网需要高精度的日前辐照度预测，但现有方法缺乏足够的时空分辨率。

Method: 利用图神经网络挖掘输入数据的模态间和模态内相关性，结合卫星图像和时间序列数据。

Result: 在瑞士127个地点一年的数据上测试，预测误差为6.1%，性能与商业化数值天气预报服务相当。

Conclusion: SolarCrossFormer具有高分辨率和鲁棒性，支持实时数据更新和无输入数据地点的预测。

Abstract: Accurate day-ahead forecasts of solar irradiance are required for the
large-scale integration of solar photovoltaic (PV) systems into the power grid.
However, current forecasting solutions lack the temporal and spatial resolution
required by system operators. In this paper, we introduce SolarCrossFormer, a
novel deep learning model for day-ahead irradiance forecasting, that combines
satellite images and time series from a ground-based network of meteorological
stations. SolarCrossFormer uses novel graph neural networks to exploit the
inter- and intra-modal correlations of the input data and improve the accuracy
and resolution of the forecasts. It generates probabilistic forecasts for any
location in Switzerland with a 15-minute resolution for horizons up to 24 hours
ahead. One of the key advantages of SolarCrossFormer its robustness in real
life operations. It can incorporate new time-series data without retraining the
model and, additionally, it can produce forecasts for locations without input
data by using only their coordinates. Experimental results over a dataset of
one year and 127 locations across Switzerland show that SolarCrossFormer yield
a normalized mean absolute error of 6.1 % over the forecasting horizon. The
results are competitive with those achieved by a commercial numerical weather
prediction service.

</details>


### [74] [Targeted Fine-Tuning of DNN-Based Receivers via Influence Functions](https://arxiv.org/abs/2509.15950)
*Marko Tuononen,Heikki Penttinen,Ville Hautamäki*

Main category: cs.LG

TL;DR: 首次将影响函数应用于基于深度学习的无线接收器，揭示训练样本如何影响比特预测，并通过针对性微调提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索影响函数在深度学习无线接收器中的应用，以提高比特错误率的性能。

Method: 使用DeepRx全卷积接收器，通过损失相对影响分析和一阶更新方法进行针对性微调。

Result: 在单目标场景中，该方法优于随机微调，提高了比特错误率；多目标适应效果较差。

Conclusion: 影响函数不仅是解释工具，还为高效的接收器适应提供了基础。

Abstract: We present the first use of influence functions for deep learning-based
wireless receivers. Applied to DeepRx, a fully convolutional receiver,
influence analysis reveals which training samples drive bit predictions,
enabling targeted fine-tuning of poorly performing cases. We show that
loss-relative influence with capacity-like binary cross-entropy loss and
first-order updates on beneficial samples most consistently improves bit error
rate toward genie-aided performance, outperforming random fine-tuning in
single-target scenarios. Multi-target adaptation proved less effective,
underscoring open challenges. Beyond experiments, we connect influence to
self-influence corrections and propose a second-order, influence-aligned update
strategy. Our results establish influence functions as both an interpretability
tool and a basis for efficient receiver adaptation.

</details>


### [75] [Exploring multimodal implicit behavior learning for vehicle navigation in simulated cities](https://arxiv.org/abs/2509.15400)
*Eric Aislan Antonelo,Gustavo Claudio Karl Couto,Christian Möller*

Main category: cs.LG

TL;DR: 论文探讨了通过隐式行为克隆（IBC）和能量基模型（EBM）解决标准行为克隆（BC）在多模态驾驶决策中的不足，提出了数据增强IBC（DA-IBC），通过扰动专家动作和改进初始化方法，在CARLA模拟器中表现出优于标准IBC的性能。


<details>
  <summary>Details</summary>
Motivation: 标准行为克隆（BC）无法学习多模态驾驶决策，即在相同场景下存在多个有效动作的问题。为解决这一问题，论文探索了隐式行为克隆（IBC）结合能量基模型（EBM）的方法。

Method: 提出了数据增强IBC（DA-IBC），通过扰动专家动作形成IBC训练的反例，并使用改进的初始化方法进行无导数推断。

Result: 在CARLA模拟器的城市驾驶任务中，DA-IBC表现优于标准IBC，能够表示多模态动作分布。

Conclusion: DA-IBC在多模态行为学习任务中表现优异，弥补了BC的不足。

Abstract: Standard Behavior Cloning (BC) fails to learn multimodal driving decisions,
where multiple valid actions exist for the same scenario. We explore Implicit
Behavioral Cloning (IBC) with Energy-Based Models (EBMs) to better capture this
multimodality. We propose Data-Augmented IBC (DA-IBC), which improves learning
by perturbing expert actions to form the counterexamples of IBC training and
using better initialization for derivative-free inference. Experiments in the
CARLA simulator with Bird's-Eye View inputs demonstrate that DA-IBC outperforms
standard IBC in urban driving tasks designed to evaluate multimodal behavior
learning in a test environment. The learned energy landscapes are able to
represent multimodal action distributions, which BC fails to achieve.

</details>


### [76] [KoopCast: Trajectory Forecasting via Koopman Operators](https://arxiv.org/abs/2509.15513)
*Jungjin Lee,Jaeuk Shin,Gihwan Kim,Joonho Han,Insoon Yang*

Main category: cs.LG

TL;DR: KoopCast是一种轻量高效的轨迹预测模型，利用Koopman算子理论实现非线性动态的线性表示，兼具准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂动态环境中非线性轨迹预测的挑战，同时保持高效性和可解释性。

Method: 采用两阶段设计：神经目标估计器预测长期目标，Koopman算子细化模块结合意图和历史进行线性预测。

Result: 在多个数据集（ETH/UCY、Waymo、nuScenes）上表现优异，兼具高准确性、可解释性和低延迟。

Conclusion: KoopCast通过线性化非线性动态，实现了性能与效率的平衡，适用于复杂多智能体交互场景。

Abstract: We present KoopCast, a lightweight yet efficient model for trajectory
forecasting in general dynamic environments. Our approach leverages Koopman
operator theory, which enables a linear representation of nonlinear dynamics by
lifting trajectories into a higher-dimensional space. The framework follows a
two-stage design: first, a probabilistic neural goal estimator predicts
plausible long-term targets, specifying where to go; second, a Koopman
operator-based refinement module incorporates intention and history into a
nonlinear feature space, enabling linear prediction that dictates how to go.
This dual structure not only ensures strong predictive accuracy but also
inherits the favorable properties of linear operators while faithfully
capturing nonlinear dynamics. As a result, our model offers three key
advantages: (i) competitive accuracy, (ii) interpretability grounded in Koopman
spectral theory, and (iii) low-latency deployment. We validate these benefits
on ETH/UCY, the Waymo Open Motion Dataset, and nuScenes, which feature rich
multi-agent interactions and map-constrained nonlinear motion. Across
benchmarks, KoopCast consistently delivers high predictive accuracy together
with mode-level interpretability and practical efficiency.

</details>


### [77] [Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations](https://arxiv.org/abs/2509.15981)
*Yujie Zhu,Charles A. Hepburn,Matthew Thorpe,Giovanni Montana*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SPReD的框架，通过集合方法建模Q值分布，解决了何时模仿演示策略的问题，并在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在稀疏奖励的强化学习中，演示可以加速学习，但如何确定何时模仿演示策略仍是一个挑战。

Method: SPReD使用集合方法建模Q值分布，并提出两种不确定性感知方法：一种基于概率估计演示优势的可能性，另一种基于优势的比例模仿。

Result: 实验在八项机器人任务中表现出色，优于现有方法多达14倍，同时对演示质量和数量具有鲁棒性。

Conclusion: SPReD通过不确定性感知的方法有效地解决了模仿策略的时机问题，显著提升了学习效率和任务表现。

Abstract: In reinforcement learning with sparse rewards, demonstrations can accelerate
learning, but determining when to imitate them remains challenging. We propose
Smooth Policy Regularisation from Demonstrations (SPReD), a framework that
addresses the fundamental question: when should an agent imitate a
demonstration versus follow its own policy? SPReD uses ensemble methods to
explicitly model Q-value distributions for both demonstration and policy
actions, quantifying uncertainty for comparisons. We develop two complementary
uncertainty-aware methods: a probabilistic approach estimating the likelihood
of demonstration superiority, and an advantage-based approach scaling imitation
by statistical significance. Unlike prevailing methods (e.g. Q-filter) that
make binary imitation decisions, SPReD applies continuous,
uncertainty-proportional regularisation weights, reducing gradient variance
during training. Despite its computational simplicity, SPReD achieves
remarkable gains in experiments across eight robotics tasks, outperforming
existing approaches by up to a factor of 14 in complex tasks while maintaining
robustness to demonstration quality and quantity. Our code is available at
https://github.com/YujieZhu7/SPReD.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [78] [In-Ear Electrode EEG for Practical SSVEP BCI](https://arxiv.org/abs/2509.15449)
*Surej Mouli,Ramaswamy Palaniappan,Emmanuel Molefi,Ian McLoughlin*

Main category: cs.HC

TL;DR: 本文将传统的SSVEP脑机接口与新型耳内电极结合，验证了耳内电极在收集SSVEP数据上的可行性，提升了可穿戴BCI的实用性。


<details>
  <summary>Details</summary>
Motivation: 传统SSVEP方法通常需要使用头部电极，限制了可穿戴性和便捷性。本研究旨在探索耳内电极收集SSVEP数据的可行性，以推动更实用的可穿戴BCI发展。

Method: 研究采用耳内电极与传统的枕部头皮电极对比，收集五名参与者在四种不同闪烁频率下的SSVEP数据。

Result: 实验结果表明，耳内电极能够有效收集SSVEP数据，显著提升了可穿戴BCI的实用性。

Conclusion: 耳内电极为SSVEP-BCI提供了一种更便捷的方案，具有实际应用的潜力。

Abstract: Steady State Visual Evoked Potential (SSVEP) methods for brain computer
interfaces (BCI) are popular due to higher information transfer rate and easier
setup with minimal training, compared to alternative methods. With precisely
generated visual stimulus frequency, it is possible to translate brain signals
into external actions or signals. Traditionally, SSVEP data is collected from
the occipital region using electrodes with or without gel, normally mounted on
a head cap. In this experimental study, we develop an in ear electrode to
collect SSVEP data for four different flicker frequencies and compare against
occipital scalp electrode data. Data from five participants demonstrates the
feasibility of in-ear electrode based SSVEP, significantly enhancing the
practicability of wearable BCI applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [79] [A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation](https://arxiv.org/abs/2509.15730)
*Lukas Laakmann,Seyyid A. Ciftci,Christian Janiesch*

Main category: cs.AI

TL;DR: 该论文探讨了机器人流程自动化（RPA）与机器学习的结合，提出了智能RPA的分类法，涵盖八个维度。


<details>
  <summary>Details</summary>
Motivation: RPA在自动化规则化任务中表现优异，但在复杂任务中受限，因此研究如何通过机器学习扩展其能力。

Method: 通过文献综述，分析了RPA与机器学习的联系，并提出了包含八个维度的智能RPA分类法。

Result: 提出了智能RPA的分类法，包括RPA-ML集成与交互的两个元特征及其八个具体维度。

Conclusion: 智能RPA的分类法为RPA与机器学习的结合提供了系统化框架，扩展了自动化任务的潜力。

Abstract: Robotic process automation (RPA) is a lightweight approach to automating
business processes using software robots that emulate user actions at the
graphical user interface level. While RPA has gained popularity for its
cost-effective and timely automation of rule-based, well-structured tasks, its
symbolic nature has inherent limitations when approaching more complex tasks
currently performed by human agents. Machine learning concepts enabling
intelligent RPA provide an opportunity to broaden the range of automatable
tasks. In this paper, we conduct a literature review to explore the connections
between RPA and machine learning and organize the joint concept intelligent RPA
into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML
integration and RPA-ML interaction. Together, they comprise eight dimensions:
architecture and ecosystem, capabilities, data basis, intelligence level, and
technical depth of integration as well as deployment environment, lifecycle
phase, and user-robot relation.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [80] [Direct Estimation of Eigenvalues of Large Dimensional Precision Matrix](https://arxiv.org/abs/2509.15554)
*Jie Zhou,Junhao Xie,Jiaqi Chen*

Main category: math.ST

TL;DR: 该论文提出了一种直接估计精度矩阵特征值的新方法，避免了对协方差矩阵特征值的逆运算。通过随机矩阵理论工具，构建了一个改进的估计器，并证明了其在大维度渐进条件下的一致性。此外，还推导了估计器的渐进偏差项，并建立了中心极限定理来描述其波动。数值实验验证了该方法的优秀性能。


<details>
  <summary>Details</summary>
Motivation: 传统估计精度矩阵特征值的方法需要先估计协方差矩阵的特征值再进行逆运算，计算复杂且效率低。本文旨在直接估计精度矩阵特征值，简化流程并提高准确性。

Method: 利用随机矩阵理论工具，提出一种改进的估计器。通过分析样本协方差矩阵的谱的Stieltjes变换及其导数的收敛速率，推导估计器的渐进偏差项，并建立中心极限定理。

Result: 证明了新估计器在大维度渐进条件下的稳定性，其偏差项为O(1/K^2)，并通过数值实验验证了估计器的高效性。

Conclusion: 该研究提供了一种高效且准确的精度矩阵特征值估计方法，理论推导和数值实验均验证了其优越性。

Abstract: In this paper, we consider directly estimating the eigenvalues of precision
matrix, without inverting the corresponding estimator for the eigenvalues of
covariance matrix. We focus on a general asymptotic regime, i.e., the large
dimensional regime, where both the dimension $N$ and the sample size $K$ tend
to infinity whereas their quotient $N/K$ converges to a positive constant. By
utilizing tools from random matrix theory, we construct an improved estimator
for eigenvalues of precision matrix. We prove the consistency of the new
estimator under large dimensional regime. In order to obtain the asymptotic
bias term of the proposed estimator, we provide a theoretical result that
characterizes the convergence rate of the expected Stieltjes transform (with
its derivative) of the spectra of the sample covariance matrix. Using this
result, we prove that the asymptotic bias term of the proposed estimator is of
order $O(1/K^2)$. Additionally, we establish a central limiting theorem (CLT)
to describe the fluctuations of the new estimator. Finally, some numerical
examples are presented to validate the excellent performance of the new
estimator and to verify the accuracy of the CLT.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [81] [A CARLA-based Simulation of Electrically Driven Forklifts](https://arxiv.org/abs/2509.15909)
*David Claus,Christiane Thielemann,Hans-Georg Stark*

Main category: cs.CE

TL;DR: 论文介绍了一种在物流场景中模拟电动叉车车队运行的方法，使用开源仿真工具CARLA生成3D仓库场景并模拟任务。


<details>
  <summary>Details</summary>
Motivation: 探索CARLA在物流仿真中的创新应用，模拟电动叉车的运行及能源消耗。

Method: 利用CARLA生成3D仓库场景，模拟叉车运输任务、最短路径规划和定位数据回放，结合电池模型模拟能耗。

Result: 成功实现了叉车操作的仿真和能耗模拟，并展示了两个应用案例：高流量区域检测和充电站优化布局。

Conclusion: CARLA在物流仿真中具有广泛的应用潜力，能够有效支持叉车车队的运行优化。

Abstract: This paper presents the simulation of the operation of an electric forklift
fleet within an intralogistics scenario. For this purpose, the open source
simulation tool CARLA is used; according to our knowledge this is a novel
approach in the context of logistics simulation. First, CARLA is used to
generate and visualize a realistic 3D outdoor warehouse scenario, incorporating
a number of randomly moving forklifts. In a next step, intralogistics transport
tasks, such as pick-and-place, are simulated for the forklift fleet, including
shortest-path finding. Furthermore, the capability to play back localization
data, previously recorded from a ''real'' forklift fleet, is demonstrated.This
play back is done in the original recreated environment, thereby enabling the
visualization of the forklifts movements. Finally, the energy consumption of
the forklift trucks is simulated by integrating a physical battery model that
generates the state of charge (SOC) of each truck as a function of load and
activity. To demonstrate the wide range of possible applications for the CARLA
simulation platform, we describe two use cases. The first deals with the
problem of detecting regions with critically high traffic densities, the second
with optimal placement of charging stations for the forklift trucks. Both use
cases are calculated for an exemplary warehouse model.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [82] [Rec-RIR: Monaural Blind Room Impulse Response Identification via DNN-based Reverberant Speech Reconstruction in STFT Domain](https://arxiv.org/abs/2509.15628)
*Pengyu Wang,Xiaofei Li*

Main category: eess.AS

TL;DR: Rec-RIR利用卷积传递函数(CTF)近似和深度神经网络(DNN)实现单声道盲RIR识别，在RIR识别和声学参数估计中表现优异。


<details>
  <summary>Details</summary>
Motivation: 通过盲识别RIR来准确表征封闭空间中的声音传播过程，解决传统方法的局限性。

Method: 基于CTF近似在STFT域建模混响，设计DNN（含跨频带和窄频带块）估计CTF滤波器，并通过伪侵入测量转为时域RIR。

Result: 实验表明Rec-RIR在RIR识别和声学参数估计中达到SOTA性能。

Conclusion: Rec-RIR是一种高效的单声道盲RIR识别方法，具有实际应用潜力。

Abstract: Room impulse response (RIR) characterizes the complete propagation process of
sound in an enclosed space. This paper presents Rec-RIR for monaural blind RIR
identification. Rec-RIR is developed based on the convolutive transfer function
(CTF) approximation, which models reverberation effect within narrow-band
filter banks in the short-time Fourier transform (STFT) domain. Specifically,
we propose a deep neural network (DNN) with cross-band and narrow-band blocks
to estimate the CTF filter. The DNN is trained through reconstructing the
noise-free reverberant speech spectra. This objective enables stable and
straightforward supervised training. Subsequently, a pseudo intrusive
measurement process is employed to convert the CTF filter estimate into
time-domain RIR by simulating a common intrusive RIR measurement procedure.
Experimental results demonstrate that Rec-RIR achieves state-of-the-art (SOTA)
performance in both RIR identification and acoustic parameter estimation.
Open-source codes are available online at
https://github.com/Audio-WestlakeU/Rec-RIR.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [83] [All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control](https://arxiv.org/abs/2509.15778)
*Mohammad Bahari,Amir Hossein Barjini,Pauli Mustalahti,Jouni Mattila*

Main category: eess.SY

TL;DR: 本文提出了一个统一的框架，集成了建模、优化和无传感器控制，用于电动重型机械臂（HDRM），并实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 目标是开发一个集成化的方法，以实现高性能、安全和高效的电动重型机械臂控制。

Method: 结合电机模型、优化算法（NSGA-II）、深度学习模型和虚拟分解控制（VDC）框架。

Result: 实验证明了轨迹跟踪的准确性和无传感器控制的有效性。

Conclusion: 该框架为电动机械臂的优化和控制提供了综合解决方案，具有实际应用潜力。

Abstract: This paper presents a unified framework that integrates modeling,
optimization, and sensorless control of an all-electric heavy-duty robotic
manipulator (HDRM) driven by electromechanical linear actuators (EMLAs). An
EMLA model is formulated to capture motor electromechanics and
direction-dependent transmission efficiencies, while a mathematical model of
the HDRM, incorporating both kinematics and dynamics, is established to
generate joint-space motion profiles for prescribed TCP trajectories. A
safety-ensured trajectory generator, tailored to this model, maps Cartesian
goals to joint space while enforcing joint-limit and velocity margins. Based on
the resulting force and velocity demands, a multi-objective Non-dominated
Sorting Genetic Algorithm II (NSGA-II) is employed to select the optimal EMLA
configuration. To accelerate this optimization, a deep neural network, trained
with EMLA parameters, is embedded in the optimization process to predict
steady-state actuator efficiency from trajectory profiles. For the chosen EMLA
design, a physics-informed Kriging surrogate, anchored to the analytic model
and refined with experimental data, learns residuals of EMLA outputs to support
force and velocity sensorless control. The actuator model is further embedded
in a hierarchical virtual decomposition control (VDC) framework that outputs
voltage commands. Experimental validation on a one-degree-of-freedom EMLA
testbed confirms accurate trajectory tracking and effective sensorless control
under varying loads.

</details>


### [84] [Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control](https://arxiv.org/abs/2509.15799)
*Max Studt,Georg Schildbach*

Main category: eess.SY

TL;DR: 提出了一种结合强化学习的战术决策与模型预测控制的层次框架，在多智能体系统中优于端到端学习和基于屏蔽的强化学习基线。


<details>
  <summary>Details</summary>
Motivation: 解决动态约束环境中基于学习控制的样本效率低、可靠性和泛化性不足的问题。

Method: 采用层次化框架，高层通过强化学习选择目标，低层通过模型预测控制实现动态安全和可行运动。

Result: 在捕食者-猎物基准测试中，表现优于端到端和基于屏蔽的强化学习方法。

Conclusion: 结构化学习与模型控制结合在多智能体系统中具有显著优势。

Abstract: Achieving safe and coordinated behavior in dynamic, constraint-rich
environments remains a major challenge for learning-based control. Pure
end-to-end learning often suffers from poor sample efficiency and limited
reliability, while model-based methods depend on predefined references and
struggle to generalize. We propose a hierarchical framework that combines
tactical decision-making via reinforcement learning (RL) with low-level
execution through Model Predictive Control (MPC). For the case of multi-agent
systems this means that high-level policies select abstract targets from
structured regions of interest (ROIs), while MPC ensures dynamically feasible
and safe motion. Tested on a predator-prey benchmark, our approach outperforms
end-to-end and shielding-based RL baselines in terms of reward, safety, and
consistency, underscoring the benefits of combining structured learning with
model-based control.

</details>
